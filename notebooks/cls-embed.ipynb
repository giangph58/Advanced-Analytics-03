{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d14d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5314cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, ClassLabel\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import map_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710aae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the interim data directory\n",
    "data_path = \"data/interim/part-*.json\"\n",
    "json_files = glob.glob(data_path)\n",
    "papers_df = pd.concat([pd.read_json(file, lines=True) for file in json_files], ignore_index=True)\n",
    "\n",
    "papers_df[\"label\"] = papers_df[\"main_category\"].apply(map_category)\n",
    "papers_df[\"text\"] = papers_df[\"title\"] + \"\\n\" + papers_df[\"summary\"]\n",
    "papers_df = papers_df[[\"text\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20247f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 80% training, 20% temp (test + validation)\n",
    "train_df, temp_df = train_test_split(\n",
    "    papers_df, \n",
    "    test_size=0.2,\n",
    "    stratify=papers_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70946638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 7121 examples (80.0%)\n",
      "Validation set: 890 examples (10.0%)\n",
      "Test set: 891 examples (10.0%)\n",
      "Total categories to classify: 20\n",
      "\n",
      "Split: train\n",
      "Number of unique categories: 20\n",
      "Categories present: 20/20\n",
      "\n",
      "Split: validation\n",
      "Number of unique categories: 20\n",
      "Categories present: 20/20\n",
      "\n",
      "Split: test\n",
      "Number of unique categories: 20\n",
      "Categories present: 20/20\n"
     ]
    }
   ],
   "source": [
    "# Print split sizes to verify\n",
    "print(f\"Training set: {len(train_df)} examples ({len(train_df)/len(papers_df)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(val_df)} examples ({len(val_df)/len(papers_df)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(test_df)} examples ({len(test_df)/len(papers_df)*100:.1f}%)\")\n",
    "\n",
    "# Check category distribution across all splits using pandas\n",
    "print(f\"Total categories to classify: {len(papers_df['label'].unique())}\")\n",
    "\n",
    "# Dictionary of DataFrames for easy iteration\n",
    "split_dfs = {\n",
    "    \"train\": train_df,\n",
    "    \"validation\": val_df,\n",
    "    \"test\": test_df\n",
    "}\n",
    "\n",
    "for split_name, df in split_dfs.items():\n",
    "    # Get unique categories in this split\n",
    "    split_categories = set(df[\"label\"].unique())\n",
    "    \n",
    "    # Check if all categories are present\n",
    "    missing_categories = set(papers_df[\"label\"]) - split_categories\n",
    "    \n",
    "    print(f\"\\nSplit: {split_name}\")\n",
    "    print(f\"Number of unique categories: {len(split_categories)}\")\n",
    "    print(f\"Categories present: {len(split_categories)}/{len(papers_df['label'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f595f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7121\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 890\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 891\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3db86c31b54dc3a6b5ed3ff5f8c415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/7121 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaca03e819f4208ba318a2b890a79f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18639382f8c9496ba15efb571171660f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/891 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7121\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 890\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 891\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create the final DatasetDict with train, validation, and test splits\n",
    "data = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(test_df, preserve_index=False)\n",
    "})\n",
    "\n",
    "# Print the final split dataset structure\n",
    "print(data)\n",
    "\n",
    "labels = sorted(papers_df[\"label\"].unique())\n",
    "class_label = ClassLabel(names=labels)\n",
    "\n",
    "data = data.cast_column(\"label\", class_label)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f548f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b57e0e1a5f4d6a955555cffa551300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8efaac16654c87ad477d0a8858a475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297ece74a64a4a509c4036a50c610915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Convert text to embeddings\n",
    "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
    "valid_embeddings = model.encode(data[\"validation\"][\"text\"], show_progress_bar=True)\n",
    "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70c3f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        56\n",
      "           1       0.82      0.86      0.84        64\n",
      "           2       0.87      0.93      0.90       381\n",
      "           3       0.50      0.33      0.40         6\n",
      "           4       0.61      0.37      0.46        38\n",
      "           5       0.61      0.73      0.67        15\n",
      "           6       1.00      0.20      0.33         5\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.62      0.83      0.71        18\n",
      "           9       0.75      0.69      0.72        13\n",
      "          10       0.85      0.87      0.86       150\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       1.00      0.33      0.50         3\n",
      "          14       0.60      0.50      0.55         6\n",
      "          15       0.77      0.66      0.71        56\n",
      "          16       0.50      0.14      0.22         7\n",
      "          17       0.33      0.25      0.29         4\n",
      "          18       0.83      0.88      0.85        40\n",
      "          19       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.82       890\n",
      "   macro avg       0.60      0.51      0.52       890\n",
      "weighted avg       0.81      0.82      0.81       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "lr_clf.fit(train_embeddings, data[\"train\"][\"label\"])\n",
    "y_pred = lr_clf.predict(valid_embeddings)\n",
    "print(classification_report(data[\"validation\"][\"label\"], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da12ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92        56\n",
      "           1       0.79      0.83      0.81        64\n",
      "           2       0.95      0.78      0.86       381\n",
      "           3       0.50      0.67      0.57         6\n",
      "           4       0.36      0.68      0.47        38\n",
      "           5       0.62      0.87      0.72        15\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.80      0.89      0.84        18\n",
      "           9       0.53      0.77      0.62        13\n",
      "          10       0.84      0.82      0.83       150\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.50      0.25      0.33         4\n",
      "          13       1.00      0.67      0.80         3\n",
      "          14       0.80      0.67      0.73         6\n",
      "          15       0.65      0.73      0.69        56\n",
      "          16       0.27      0.43      0.33         7\n",
      "          17       0.50      0.75      0.60         4\n",
      "          18       0.81      0.88      0.84        40\n",
      "          19       0.36      0.71      0.48        17\n",
      "\n",
      "    accuracy                           0.79       890\n",
      "   macro avg       0.66      0.69      0.66       890\n",
      "weighted avg       0.83      0.79      0.80       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(random_state=42, class_weight=\"balanced\")\n",
    "svc_clf.fit(train_embeddings, data[\"train\"][\"label\"])\n",
    "y_pred = svc_clf.predict(valid_embeddings)\n",
    "print(classification_report(data[\"validation\"][\"label\"], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a31e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        56\n",
      "           1       0.79      0.81      0.80        64\n",
      "           2       0.87      0.94      0.90       381\n",
      "           3       0.38      0.50      0.43         6\n",
      "           4       0.65      0.29      0.40        38\n",
      "           5       0.67      0.67      0.67        15\n",
      "           6       1.00      0.40      0.57         5\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.57      0.67      0.62        18\n",
      "           9       0.69      0.69      0.69        13\n",
      "          10       0.84      0.87      0.86       150\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       1.00      0.33      0.50         3\n",
      "          14       0.50      0.33      0.40         6\n",
      "          15       0.64      0.61      0.62        56\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.50      0.50      0.50         4\n",
      "          18       0.81      0.85      0.83        40\n",
      "          19       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.81       890\n",
      "   macro avg       0.60      0.52      0.54       890\n",
      "weighted avg       0.80      0.81      0.80       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/processing/climate_llm/learn/aa/Advanced-Analytics-03/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    'max_depth': 7,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(labels),\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**params)\n",
    "xgb_clf.fit(train_embeddings, data[\"train\"][\"label\"])\n",
    "y_pred = xgb_clf.predict(valid_embeddings)\n",
    "print(classification_report(data[\"validation\"][\"label\"], y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
