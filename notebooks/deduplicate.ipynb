{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0072c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "spark_home = os.path.abspath(os.getcwd() + \"/spark/spark-3.5.5-bin-hadoop3\")\n",
    "hadoop_home = os.path.abspath(os.getcwd() + \"/spark/winutils\")\n",
    "# print(f\"I am using the following SPARK_HOME: {spark_home}\")\n",
    "if os.name == 'nt':\n",
    "    os.environ[\"HADOOP_HOME\"] = f\"{hadoop_home}\"\n",
    "    # print(f\"Windows detected: set HADOOP_HOME to: {os.environ['HADOOP_HOME']}\")\n",
    "    hadoop_bin = os.path.join(hadoop_home, \"bin\")\n",
    "    os.environ[\"PATH\"] = f\"{hadoop_bin};{os.environ['PATH']}\"\n",
    "    # print(f\"  Also added Hadoop bin directory to PATH: {hadoop_bin}\")\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "findspark.init(spark_home)\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f80463",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.read.json(\"data/raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68834bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2449ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define the schema for the nested JSON\n",
    "paper_schema = StructType([\n",
    "    StructField(\"aid\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"summary\", StringType()),\n",
    "    StructField(\"main_category\", StringType()),\n",
    "    StructField(\"categories\", StringType()),\n",
    "    StructField(\"published\", StringType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6955fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------+--------------------+\n",
      "|aid                              |title                                                                                                                                      |summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |main_category    |categories                     |published           |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------+--------------------+\n",
      "|http://arxiv.org/abs/2504.16517v1|Gravitational Equilibrium with Steady Flow and Relativistic Local\\n  Thermodynamics                                                        |A relativistic self-gravitating equilibrium system with steady flow as well\\nas spherical symmetry is discovered. The energy-momentum tensor contains the\\ncontribution of a current related to the flow and the metric tensor does an\\noff-diagonal component to balance with the flow momentum. The presence of the\\noff-diagonal component of the metric implies the radial motion of the reference\\nframe, which gives rise to a problem how the relativistic effect is included in\\nthermodynamic observables for such a general relativistic system. This problem\\nis solved by taking an instantaneously rest frame in which geometric\\nthermodynamic observables read as previously and giving them the special\\nrelativistic effect emerged from the inverse transformation to the original\\nframe pointwise. The solution of the thermodynamic observables in accord with\\nthe laws of thermodynamics and the theory of relativity is presented. Finally\\nthe relativistic structure equations for the equilibrium are derived, from\\nwhich the general relativistic Poisson equation as well as the heat conduction\\none are developed exactly.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |gr-qc            |gr-qc,astro-ph.SR,hep-ph,hep-th|2025-04-23T08:42:20Z|\n",
      "|http://arxiv.org/abs/2504.16534v1|Partitioning of multiple brain metastases improves dose gradients in\\n  single-isocenter radiosurgery                                      |Background: A growing number of cancer patients with brain metastases can\\nbenefit from stereotactic radiosurgery (SRS) thanks to recent advances in\\nsystemic therapies. With an increasing patient load, single-isocenter\\ntreatments on widely available C-arm linear accelerators are an attractive\\noption. However, the planning of such treatments is challenging for\\nmulti-target cases due to the island blocking problem, which occurs when the\\nmulti-leaf collimator cannot conform to all targets simultaneously.\\n  Purpose: We propose a multi-target partitioning algorithm that mitigates\\nexcessive exposure of normal tissue caused by the island blocking problem.\\n  Methods: The algorithm divides (partitions) the set of targets into subsets\\nto treat with separate arc passes, optimizing both subsets and collimator\\nangles to minimize island blocking. The algorithm was incorporated into a fully\\nautomated treatment planning script and evaluated on 20 simulated patient\\ncases, each with 10 brain metastases and 21 Gy prescriptions. It was also\\nretrospectively evaluated on six clinical cases.\\n  Results: Partitioning significantly improved the gradient index, global\\nefficiency index, and brain V12Gy compared to simultaneous treatment of all\\nmetastases. For example, the average gradient index improved from 5.9 to 3.3,\\nglobal efficiency index from 0.32 to 0.46, and normal brain V12Gy from 49 cm3\\nto 26 cm3 between 3 and 9 arcs. The proposed algorithm outperformed baselines\\nin utilizing a limited number of arcs. All target partitioning strategies\\nincreased the total number of monitor units (MUs).\\n  Conclusions: The dose gradient in single-isocenter VMAT plans can be\\nsubstantially improved by treating a smaller subset of metastases at a time.\\nThis requires more MUs and arcs, implying a trade-off between delivery time and\\nplan quality which can be explored using the algorithm proposed in this paper.|physics.med-ph   |physics.med-ph                 |2025-04-23T09:02:57Z|\n",
      "|http://arxiv.org/abs/2504.16550v1|A Collaborative Intrusion Detection System Using Snort IDS Nodes                                                                           |Intrusion Detection Systems (IDSs) are integral to safeguarding networks by\\ndetecting and responding to threats from malicious traffic or compromised\\ndevices. However, standalone IDS deployments often fall short when addressing\\nthe increasing complexity and scale of modern cyberattacks. This paper proposes\\na Collaborative Intrusion Detection System (CIDS) that leverages Snort, an\\nopen-source network intrusion detection system, to enhance detection accuracy\\nand reduce false positives. The proposed architecture connects multiple Snort\\nIDS nodes to a centralised node and integrates with a Security Information and\\nEvent Management (SIEM) platform to facilitate real-time data sharing,\\ncorrelation, and analysis. The CIDS design includes a scalable configuration of\\nSnort sensors, a centralised database for log storage, and LogScale SIEM for\\nadvanced analytics and visualisation. By aggregating and analysing intrusion\\ndata from multiple nodes, the system enables improved detection of distributed\\nand sophisticated attack patterns that standalone IDSs may miss. Performance\\nevaluation against simulated attacks, including Nmap port scans and ICMP flood\\nattacks, demonstrates our CIDS's ability to efficiently process large-scale\\nnetwork traffic, detect threats with higher accuracy, and reduce alert fatigue.\\nThis paper highlights the potential of CIDS in modern network environments and\\nexplores future enhancements, such as integrating machine learning for advanced\\nthreat detection and creating public datasets to support collaborative\\nresearch. The proposed CIDS framework provides a promising foundation for\\nbuilding more resilient and adaptive network security systems.                                                                                                                                                                                                                                |cs.CR            |cs.CR                          |2025-04-23T09:25:52Z|\n",
      "|http://arxiv.org/abs/2504.16519v1|Exciton Basis Description of Ultrafast Triplet Separation in\\n  Pentacene-(Tetracene)2-Pentacene Intramolecular Singlet Fission Chromophore|Precise understanding of the electronic structures of optically dark\\ntriplet-triplet multiexcitons that are the intermediate states in singlet\\nfission (SF) continues to be a challenge. This is particularly true for\\nintramolecular singlet fission (iSF) chromophores, that are oligomers of large\\nmonomer molecules. We have performed quantum many-body calculations of the\\ncomplete set of excited states relevant to iSF in\\nPentacene-(Tetracene)2-Pentacene oligomers, consisting of two terminal\\npentacene monomers linked by two tetracene monomers. Our computations use an\\nexciton basis that gives physical pictorial descriptions of all eigenstates,\\nand are performed over an active space of twenty-eight monomer molecular\\norbitals, including configuration interaction with all relevant quadruple\\nexcitations within the active space, thereby ensuring very high precision. We\\ndiscuss the many-electron structures of the optical predominantly intramonomer\\nspin-singlets, intermonomer charge-transfer excitations, and most importantly,\\nthe complete set of low energy covalent triplet-triplet multiexcitons. We are\\nable to explain the weak binding energy of the pentacene-tetracene\\ntriplet-triplet eigenstate that is generated following photoexcitation. We\\nexplain the increase in lifetime with increasing numbers of tetracene monomers\\nof the transient absorption associated with contiguous pentacene-tetracene\\ntriplet-triplet in this family of oligomers. We are consequently able to give a\\npictorial description of the triplet separation following generation of the\\ninitial triplet-triplet, leading to a state with individual triplets occupying\\nonly the two pentacene monomers. We expect many applications of our theoretical\\napproach to triplet separation.                                                                                                                                                           |cond-mat.mtrl-sci|cond-mat.mtrl-sci              |2025-04-23T08:44:23Z|\n",
      "|http://arxiv.org/abs/2504.16536v1|Synthesiz3 This: an SMT-Based Approach for Synthesis with Uncomputable\\n  Symbols                                                          |Program synthesis is the task of automatically constructing a program\\nconforming to a given specification. In this paper we focus on synthesis of\\nsingle-invocation recursion-free functions conforming to a specification given\\nas a logical formula in the presence of uncomputable symbols (i.e., symbols\\nused in the specification but not allowed in the resulting function). We\\napproach the problem via SMT-solving methods: we present a quantifier\\nelimination algorithm using model-based projections for both total and partial\\nfunction synthesis, working with theories of uninterpreted functions and linear\\narithmetic and their combination. For this purpose we also extend model-based\\nprojection to produce witnesses for these theories. Further, we present\\nprocedures tailored for the case of uniquely determined solutions. We\\nimplemented a prototype of the algorithms using the SMT-solver Z3,\\ndemonstrating their practicality.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.LO            |cs.LO                          |2025-04-23T09:06:26Z|\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse the nested JSON\n",
    "papers_df = raw_df.withColumn(\"paper_data\", \n",
    "                           from_json(col(\"value\"), paper_schema))\\\n",
    "                 .select(\"paper_data.*\")\n",
    "\n",
    "# Display sample data\n",
    "papers_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb987326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 31335\n"
     ]
    }
   ],
   "source": [
    "# Count records\n",
    "print(f\"Total number of rows: {papers_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994ad15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates based on all columns: 11143 papers remain\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on all columns instead of just \"aid\"\n",
    "papers_unique_df = papers_df.dropDuplicates([\"aid\"])\n",
    "print(f\"After removing duplicates based on all columns: {papers_unique_df.count()} papers remain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d60ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_unique_df.write.mode(\"overwrite\").json(\"data/interim\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
