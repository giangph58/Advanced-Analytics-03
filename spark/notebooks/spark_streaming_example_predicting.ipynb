{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "I am using the following SPARK_HOME: C:\\Users\\Seppe\\Desktop\\spark\\spark-3.5.5-bin-hadoop3\n",
                  "Windows detected: set HADOOP_HOME to: C:\\Users\\Seppe\\Desktop\\spark\\winutils\n"
               ]
            }
         ],
         "source": [
            "import os\n",
            "spark_home = os.path.abspath(os.getcwd() + \"/../spark-3.5.5-bin-hadoop3\")\n",
            "hadoop_home = os.path.abspath(os.getcwd() + \"/../winutils\")\n",
            "print(f\"I am using the following SPARK_HOME: {spark_home}\")\n",
            "if os.name == 'nt':\n",
            "    os.environ[\"HADOOP_HOME\"] = f\"{hadoop_home}\"\n",
            "    print(f\"Windows detected: set HADOOP_HOME to: {os.environ['HADOOP_HOME']}\")\n",
            "    hadoop_bin = os.path.join(hadoop_home, \"bin\")\n",
            "    os.environ[\"PATH\"] = f\"{hadoop_bin};{os.environ['PATH']}\"\n",
            "    print(f\"  Also added Hadoop bin directory to PATH: {hadoop_bin}\")\n",
            "\n",
            "import findspark\n",
            "import pyspark\n",
            "from pyspark.streaming import StreamingContext\n",
            "\n",
            "findspark.init(spark_home)\n",
            "sc = pyspark.SparkContext()\n",
            "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import threading\n",
            "\n",
            "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
            "        \n",
            "class StreamingThread(threading.Thread):\n",
            "    def __init__(self, ssc):\n",
            "        super().__init__()\n",
            "        self.ssc = ssc\n",
            "    def run(self):\n",
            "        self.ssc.start()\n",
            "        self.ssc.awaitTermination()\n",
            "    def stop(self):\n",
            "        print('----- Stopping... this may take a few seconds -----')\n",
            "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
            "        "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import random\n",
            "from pyspark.streaming import StreamingContext\n",
            "from pyspark.sql import Row\n",
            "from pyspark.sql.functions import udf, struct, array, col, lit\n",
            "from pyspark.sql.types import StringType\n",
            "\n",
            "import numpy as np\n",
            "import pickle\n",
            "import pandas as pd\n",
            "from pyspark.sql.functions import udf, col, concat_ws, lit\n",
            "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
            "from sentence_transformers import SentenceTransformer\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
            "lines.foreachRDD(process)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "ssc_t = StreamingThread(ssc)\n",
            "ssc_t.start()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "----- Stopping... this may take a few seconds -----\n"
               ]
            }
         ],
         "source": [
            "ssc_t.stop()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "assignment-03",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.11"
      },
      "toc": {
         "base_numbering": 1,
         "nav_menu": {},
         "number_sections": true,
         "sideBar": true,
         "skip_h1_title": false,
         "title_cell": "Table of Contents",
         "title_sidebar": "Contents",
         "toc_cell": false,
         "toc_position": {},
         "toc_section_display": true,
         "toc_window_display": false
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
