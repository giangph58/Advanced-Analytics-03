{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "I am using the following SPARK_HOME: d:\\OneDrive - CGIAR\\Master\\Advanced Analytics\\assignments\\assignment-03\\spark\\spark-3.5.5-bin-hadoop3\n",
                  "Windows detected: set HADOOP_HOME to: d:\\OneDrive - CGIAR\\Master\\Advanced Analytics\\assignments\\assignment-03\\spark\\winutils\n",
                  "  Also added Hadoop bin directory to PATH: d:\\OneDrive - CGIAR\\Master\\Advanced Analytics\\assignments\\assignment-03\\spark\\winutils\\bin\n"
               ]
            }
         ],
         "source": [
            "import os\n",
            "spark_home = os.path.abspath(os.getcwd() + \"/spark/spark-3.5.5-bin-hadoop3\")\n",
            "hadoop_home = os.path.abspath(os.getcwd() + \"/spark/winutils\")\n",
            "print(f\"I am using the following SPARK_HOME: {spark_home}\")\n",
            "if os.name == 'nt':\n",
            "    os.environ[\"HADOOP_HOME\"] = f\"{hadoop_home}\"\n",
            "    print(f\"Windows detected: set HADOOP_HOME to: {os.environ['HADOOP_HOME']}\")\n",
            "    hadoop_bin = os.path.join(hadoop_home, \"bin\")\n",
            "    os.environ[\"PATH\"] = f\"{hadoop_bin};{os.environ['PATH']}\"\n",
            "    print(f\"  Also added Hadoop bin directory to PATH: {hadoop_bin}\")\n",
            "\n",
            "import findspark\n",
            "import pyspark\n",
            "from pyspark.sql import SparkSession\n",
            "from pyspark.sql.functions import from_json, col, struct\n",
            "from pyspark.sql.types import StructType, StructField, StringType\n",
            "\n",
            "findspark.init(spark_home)\n",
            "spark = SparkSession.builder.appName(\"ArxivStreaming\").getOrCreate()\n",
            "sc = spark.sparkContext\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "import requests\n",
            "import time\n",
            "from collections import Counter\n",
            "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
            "from pyspark.sql.functions import udf, struct, col, collect_list\n",
            "from pyspark.sql.types import StringType, ArrayType\n",
            "from src.utils import map_category\n",
            "\n",
            "# Use Spark accumulators for tracking across batches\n",
            "batch_count_accumulator = sc.accumulator(0)        # Number of batches processed\n",
            "total_papers_accumulator = sc.accumulator(0)       # Total papers processed\n",
            "total_batch_time_accumulator = sc.accumulator(0.0) # Total time for all batches\n",
            "valid_predictions_accumulator = sc.accumulator(0)  # Valid predictions\n",
            "error_predictions_accumulator = sc.accumulator(0)  # Failed predictions\n",
            "\n",
            "predictions_log = []\n",
            "\n",
            "def predict_batch_api(papers_list):\n",
            "    \"\"\"Call FastAPI once for entire batch\"\"\"\n",
            "    start_time = time.time()\n",
            "    \n",
            "    try:\n",
            "        # Prepare batch payload\n",
            "        batch_data = [\n",
            "            {\"title\": str(paper.title), \"summary\": str(paper.summary)}\n",
            "            for paper in papers_list\n",
            "        ]\n",
            "        \n",
            "        response = requests.post(\"http://localhost:8000/predict_batch\", \n",
            "                               json={\"papers\": batch_data},\n",
            "                               timeout=30)\n",
            "        \n",
            "        batch_time = (time.time() - start_time) * 1000  # Total batch time in ms\n",
            "        \n",
            "        if response.status_code == 200:\n",
            "            result = response.json()\n",
            "            predictions = result[\"predictions\"]\n",
            "            api_inference_time = result.get(\"inference_time_ms\", batch_time)\n",
            "            \n",
            "            # Update accumulators correctly\n",
            "            batch_count_accumulator.add(1)\n",
            "            total_papers_accumulator.add(len(predictions))\n",
            "            total_batch_time_accumulator.add(batch_time)  # Total time including network\n",
            "            \n",
            "            # Count valid vs error predictions\n",
            "            valid_count = sum(1 for pred in predictions \n",
            "                            if pred not in [\"api_error\", \"timeout_error\", \"connection_error\"])\n",
            "            error_count = len(predictions) - valid_count\n",
            "            \n",
            "            valid_predictions_accumulator.add(valid_count)\n",
            "            error_predictions_accumulator.add(error_count)\n",
            "            \n",
            "            print(f\"Batch API: {len(predictions)} papers in {batch_time:.1f}ms (API: {api_inference_time:.1f}ms)\")\n",
            "            \n",
            "            return predictions\n",
            "        else:\n",
            "            print(f\"Batch API returned status: {response.status_code}\")\n",
            "            # Update accumulators for failed batch\n",
            "            batch_count_accumulator.add(1)\n",
            "            total_papers_accumulator.add(len(papers_list))\n",
            "            total_batch_time_accumulator.add(batch_time)\n",
            "            error_predictions_accumulator.add(len(papers_list))\n",
            "            \n",
            "            return [\"api_error\"] * len(papers_list)\n",
            "            \n",
            "    except requests.exceptions.Timeout:\n",
            "        batch_time = (time.time() - start_time) * 1000\n",
            "        print(f\"Batch API call timed out after {batch_time:.1f}ms\")\n",
            "        \n",
            "        # Update accumulators for timeout\n",
            "        batch_count_accumulator.add(1)\n",
            "        total_papers_accumulator.add(len(papers_list))\n",
            "        total_batch_time_accumulator.add(batch_time)\n",
            "        error_predictions_accumulator.add(len(papers_list))\n",
            "        \n",
            "        return [\"timeout_error\"] * len(papers_list)\n",
            "        \n",
            "    except requests.exceptions.ConnectionError:\n",
            "        batch_time = (time.time() - start_time) * 1000\n",
            "        print(f\"Cannot connect to batch API\")\n",
            "        \n",
            "        # Update accumulators for connection error\n",
            "        batch_count_accumulator.add(1)\n",
            "        total_papers_accumulator.add(len(papers_list))\n",
            "        total_batch_time_accumulator.add(batch_time)\n",
            "        error_predictions_accumulator.add(len(papers_list))\n",
            "        \n",
            "        return [\"connection_error\"] * len(papers_list)\n",
            "        \n",
            "    except Exception as e:\n",
            "        batch_time = (time.time() - start_time) * 1000\n",
            "        print(f\"Batch API call failed: {e}\")\n",
            "        \n",
            "        # Update accumulators for other errors\n",
            "        batch_count_accumulator.add(1)\n",
            "        total_papers_accumulator.add(len(papers_list))\n",
            "        total_batch_time_accumulator.add(batch_time)\n",
            "        error_predictions_accumulator.add(len(papers_list))\n",
            "        \n",
            "        return [\"api_error\"] * len(papers_list)\n",
            "\n",
            "map_category_udf = udf(map_category, StringType())\n",
            "\n",
            "def print_performance_metrics():\n",
            "    \"\"\"Print classification performance and inference speed metrics across ALL batches\"\"\"\n",
            "    \n",
            "    print(f\"\\n--- BATCH PROCESSING METRICS ---\")\n",
            "    print(f\"Total batches processed: {batch_count_accumulator.value}\")\n",
            "    print(f\"Total papers processed: {total_papers_accumulator.value}\")\n",
            "    print(f\"Valid predictions: {valid_predictions_accumulator.value}\")\n",
            "    print(f\"Failed predictions: {error_predictions_accumulator.value}\")\n",
            "    \n",
            "    if batch_count_accumulator.value > 0:\n",
            "        avg_batch_time = total_batch_time_accumulator.value / batch_count_accumulator.value\n",
            "        print(f\"Average batch processing time: {avg_batch_time:.1f}ms\")\n",
            "        \n",
            "        if total_papers_accumulator.value > 0:\n",
            "            avg_time_per_paper = total_batch_time_accumulator.value / total_papers_accumulator.value\n",
            "            print(f\"Average time per paper: {avg_time_per_paper:.1f}ms\")\n",
            "            \n",
            "            success_rate = (valid_predictions_accumulator.value / total_papers_accumulator.value) * 100\n",
            "            print(f\"Success rate: {success_rate:.1f}%\")\n",
            "    \n",
            "    print(f\"Driver-side log entries: {len(predictions_log)}\")\n",
            "    \n",
            "    # Classification performance from driver-side log\n",
            "    valid_preds = [p for p in predictions_log if p['true_label'] is not None]\n",
            "    \n",
            "    if len(valid_preds) < 2:\n",
            "        print(\"Need more valid predictions for detailed metrics\")\n",
            "        return\n",
            "    \n",
            "    # Extract predictions and true labels\n",
            "    preds = [p['prediction'] for p in valid_preds]\n",
            "    trues = [p['true_label'] for p in valid_preds]\n",
            "    \n",
            "    # Classification performance metrics\n",
            "    try:\n",
            "        macro_f1 = f1_score(trues, preds, average='macro', zero_division=0)\n",
            "        balanced_acc = balanced_accuracy_score(trues, preds)\n",
            "        \n",
            "        print(f\"\\n--- CLASSIFICATION PERFORMANCE ---\")\n",
            "        print(f\"Valid predictions for metrics: {len(valid_preds)}\")\n",
            "        print(f\"Macro F1: {macro_f1:.3f}\")\n",
            "        print(f\"Balanced Accuracy: {balanced_acc:.3f}\")\n",
            "        \n",
            "        # Show category distribution\n",
            "        pred_counter = Counter(preds)\n",
            "        print(f\"Prediction distribution: {dict(pred_counter)}\")\n",
            "        \n",
            "    except Exception as e:\n",
            "        print(f\"Error calculating metrics: {e}\")\n",
            "    \n",
            "    print(\"=\" * 50)\n",
            "\n",
            "def reset_metrics():\n",
            "    \"\"\"Reset all monitoring statistics\"\"\"\n",
            "    global predictions_log\n",
            "    predictions_log = []\n",
            "    \n",
            "    # Reset accumulators by recreating them\n",
            "    global batch_count_accumulator, total_papers_accumulator, total_batch_time_accumulator\n",
            "    global valid_predictions_accumulator, error_predictions_accumulator\n",
            "    \n",
            "    batch_count_accumulator = sc.accumulator(0)\n",
            "    total_papers_accumulator = sc.accumulator(0)\n",
            "    total_batch_time_accumulator = sc.accumulator(0.0)\n",
            "    valid_predictions_accumulator = sc.accumulator(0)\n",
            "    error_predictions_accumulator = sc.accumulator(0)\n",
            "    \n",
            "    print(\"Metrics reset!\")\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Structured Streaming Setup (keep the same schema)\n",
            "arxiv_schema = StructType([\n",
            "    StructField(\"title\", StringType(), True),\n",
            "    StructField(\"summary\", StringType(), True),\n",
            "    StructField(\"main_category\", StringType(), True),\n",
            "    StructField(\"published\", StringType(), True)\n",
            "])\n",
            "\n",
            "# Create streaming DataFrame\n",
            "stream_df = spark \\\n",
            "    .readStream \\\n",
            "    .format(\"socket\") \\\n",
            "    .option(\"host\", \"seppe.net\") \\\n",
            "    .option(\"port\", 7778) \\\n",
            "    .load()\n",
            "\n",
            "# Parse and add labels\n",
            "parsed_df = stream_df \\\n",
            "    .select(from_json(col(\"value\"), arxiv_schema).alias(\"data\")) \\\n",
            "    .select(\"data.*\") \\\n",
            "    .withColumn(\"label\", map_category_udf(col(\"main_category\")))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Structured Streaming started with batch API!\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "========= Batch 0 (Papers: 0) =========\n",
                  "========= Batch 1 (Papers: 60) =========\n",
                  "Batch API: 60 papers in 8835.7ms (API: 8817.6ms)\n",
                  "+--------------------+-------------+--------------------+--------+--------+\n",
                  "|               title|main_category|           published|   label|    pred|\n",
                  "+--------------------+-------------+--------------------+--------+--------+\n",
                  "|GL-PGENet: A Para...|        cs.CV|2025-05-28T06:37:06Z|      cs|      cs|\n",
                  "|Jailbreak Distill...|        cs.CL|2025-05-28T06:59:46Z|      cs|      cs|\n",
                  "|AudioGenie: A Tra...|        cs.SD|2025-05-28T07:23:53Z|      cs|      cs|\n",
                  "|Delayed-KD: Delay...|        cs.SD|2025-05-28T07:51:21Z|      cs|    eess|\n",
                  "|A High Accuracy S...|      math.NA|2025-05-28T06:38:20Z|    math|    math|\n",
                  "|Balanced Token Pr...|        cs.CV|2025-05-28T07:00:50Z|      cs|      cs|\n",
                  "|Voice Adaptation ...|        cs.CL|2025-05-28T07:24:40Z|      cs|      cs|\n",
                  "|Physical Reduced ...|     quant-ph|2025-05-28T07:52:37Z|quant-ph|quant-ph|\n",
                  "|Securing the Soft...|        cs.SE|2025-05-28T06:42:37Z|      cs|      cs|\n",
                  "|OmniAD: Detect an...|        cs.CV|2025-05-28T07:02:15Z|      cs|      cs|\n",
                  "+--------------------+-------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 1\n",
                  "Total papers processed: 60\n",
                  "Valid predictions: 60\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 8835.7ms\n",
                  "Average time per paper: 147.3ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 60\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 60\n",
                  "Macro F1: 0.767\n",
                  "Balanced Accuracy: 0.828\n",
                  "Prediction distribution: {'cs': 25, 'eess': 9, 'math': 9, 'quant-ph': 2, 'physics': 3, 'cond-mat': 3, 'math-ph': 1, 'astro-ph': 2, 'q-bio': 1, 'stat': 3, 'econ': 1, 'gr-qc': 1}\n",
                  "==================================================\n",
                  "========= Batch 2 (Papers: 150) =========\n",
                  "Batch API: 150 papers in 20346.7ms (API: 20317.7ms)\n",
                  "+--------------------+----------------+--------------------+--------+--------+\n",
                  "|               title|   main_category|           published|   label|    pred|\n",
                  "+--------------------+----------------+--------------------+--------+--------+\n",
                  "|Can Test-time Com...|           cs.LG|2025-05-28T08:01:25Z|      cs|      cs|\n",
                  "|From the Rose-DuB...|physics.plasm-ph|2025-05-28T08:18:42Z| physics| physics|\n",
                  "|THINK-Bench: Eval...|           cs.CL|2025-05-28T08:41:14Z|      cs|      cs|\n",
                  "|What Makes for Te...|           cs.CV|2025-05-28T08:54:04Z|      cs|      cs|\n",
                  "|Discrete stochast...|         math.AP|2025-05-28T09:05:15Z|    math|    math|\n",
                  "|Spectral indices ...|     astro-ph.GA|2025-05-28T09:24:58Z|astro-ph|astro-ph|\n",
                  "|Hydrogen-like str...|          hep-ph|2025-05-28T09:52:04Z|     hep|     hep|\n",
                  "|Physics-inspired ...|        quant-ph|2025-05-28T10:11:48Z|quant-ph|quant-ph|\n",
                  "|A Survey on Train...|           cs.CV|2025-05-28T10:37:52Z|      cs|      cs|\n",
                  "|Reflection Spectr...|     astro-ph.HE|2025-05-28T10:58:43Z|astro-ph|astro-ph|\n",
                  "+--------------------+----------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 2\n",
                  "Total papers processed: 210\n",
                  "Valid predictions: 210\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 14591.2ms\n",
                  "Average time per paper: 139.0ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 210\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 210\n",
                  "Macro F1: 0.759\n",
                  "Balanced Accuracy: 0.819\n",
                  "Prediction distribution: {'cs': 101, 'eess': 20, 'math': 21, 'quant-ph': 10, 'physics': 9, 'cond-mat': 11, 'math-ph': 2, 'astro-ph': 14, 'q-bio': 3, 'stat': 9, 'econ': 1, 'gr-qc': 2, 'hep': 5, 'nlin': 1, 'q-fin': 1}\n",
                  "==================================================\n",
                  "========= Batch 3 (Papers: 170) =========\n",
                  "Batch API: 170 papers in 21602.6ms (API: 21578.0ms)\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|               title|    main_category|           published|   label|    pred|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|Advancing Hearing...|            cs.SD|2025-05-28T11:06:22Z|      cs|    eess|\n",
                  "|Quantum Walk Comb...|         quant-ph|2025-05-28T11:28:29Z|quant-ph| physics|\n",
                  "|Ultrasonic spin p...|   cond-mat.other|2025-05-28T11:50:18Z|cond-mat|cond-mat|\n",
                  "|Learning Fine-Gra...|            cs.CV|2025-05-28T12:16:42Z|      cs|      cs|\n",
                  "|Engineering Ge pr...|cond-mat.mes-hall|2025-05-28T12:33:20Z|cond-mat|cond-mat|\n",
                  "|From Large AI Mod...|            cs.AI|2025-05-28T12:54:07Z|      cs|      cs|\n",
                  "|NLP for Social Go...|            cs.CL|2025-05-28T13:14:44Z|      cs|      cs|\n",
                  "|Empowering Intell...|          eess.SP|2025-05-28T13:27:07Z|    eess|      cs|\n",
                  "|Multiclass Loss G...|            cs.LG|2025-05-28T13:39:14Z|      cs|    stat|\n",
                  "|Pangu Embedded: A...|            cs.CL|2025-05-28T14:03:02Z|      cs|      cs|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 3\n",
                  "Total papers processed: 380\n",
                  "Valid predictions: 380\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 16928.4ms\n",
                  "Average time per paper: 133.6ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 380\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 380\n",
                  "Macro F1: 0.741\n",
                  "Balanced Accuracy: 0.817\n",
                  "Prediction distribution: {'cs': 173, 'eess': 34, 'math': 43, 'quant-ph': 15, 'physics': 22, 'cond-mat': 25, 'math-ph': 3, 'astro-ph': 21, 'q-bio': 5, 'stat': 19, 'econ': 2, 'gr-qc': 5, 'hep': 7, 'nlin': 3, 'q-fin': 1, 'nucl': 2}\n",
                  "==================================================\n",
                  "========= Batch 4 (Papers: 170) =========\n",
                  "Batch API: 170 papers in 25185.4ms (API: 25175.2ms)\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|               title|    main_category|           published|   label|    pred|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|Facial Age Estima...|            cs.CY|2025-05-28T14:28:31Z|      cs|      cs|\n",
                  "|High-Dimensional ...|          math.ST|2025-05-28T14:43:44Z|    math|    econ|\n",
                  "|Enantiosensitive ...|cond-mat.mes-hall|2025-05-28T14:56:48Z|cond-mat| physics|\n",
                  "|Private Lossless ...|            cs.CR|2025-05-28T15:10:27Z|      cs|      cs|\n",
                  "|Single Domain Gen...|            cs.CV|2025-05-28T15:18:16Z|      cs|    eess|\n",
                  "|Hypothesis Testin...|          stat.ML|2025-05-28T15:29:43Z|    stat|    stat|\n",
                  "|Fully Packed and ...|            cs.RO|2025-05-28T15:47:43Z|      cs|      cs|\n",
                  "|Strengthening Pro...|            cs.GT|2025-05-28T16:02:52Z|      cs|      cs|\n",
                  "|Discrete Boltzman...|          math-ph|2025-05-28T16:15:31Z| math-ph| math-ph|\n",
                  "|The Optical Desig...|   physics.optics|2025-05-28T16:25:29Z| physics|astro-ph|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 4\n",
                  "Total papers processed: 550\n",
                  "Valid predictions: 550\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 18992.6ms\n",
                  "Average time per paper: 138.1ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 550\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 550\n",
                  "Macro F1: 0.740\n",
                  "Balanced Accuracy: 0.833\n",
                  "Prediction distribution: {'cs': 236, 'eess': 50, 'math': 68, 'quant-ph': 25, 'physics': 34, 'cond-mat': 37, 'math-ph': 5, 'astro-ph': 27, 'q-bio': 7, 'stat': 32, 'econ': 4, 'gr-qc': 6, 'hep': 11, 'nlin': 3, 'q-fin': 1, 'nucl': 4}\n",
                  "==================================================\n",
                  "========= Batch 5 (Papers: 195) =========\n",
                  "Batch API: 195 papers in 25684.7ms (API: 25672.5ms)\n",
                  "+--------------------+-------------+--------------------+-----+-----+\n",
                  "|               title|main_category|           published|label| pred|\n",
                  "+--------------------+-------------+--------------------+-----+-----+\n",
                  "|Agent-UniRAG: A T...|        cs.CL|2025-05-28T16:46:31Z|   cs|   cs|\n",
                  "|Bayesian Non-Para...|      stat.ME|2025-05-28T16:59:09Z| stat| stat|\n",
                  "|Oscillating subal...|      math.LO|2025-05-28T17:17:39Z| math| math|\n",
                  "|Smart Contracts f...|        cs.SE|2025-05-28T17:40:21Z|   cs|   cs|\n",
                  "|Learning Composab...|        cs.CL|2025-05-28T17:51:10Z|   cs|   cs|\n",
                  "|Sherlock: Self-Co...|        cs.CV|2025-05-28T17:58:03Z|   cs|   cs|\n",
                  "|Walking the Weigh...|        cs.LG|2025-05-29T02:03:29Z|   cs|q-bio|\n",
                  "|SeG-SR: Integrati...|        cs.CV|2025-05-29T02:38:34Z|   cs|   cs|\n",
                  "|Context Robust Kn...|        cs.CL|2025-05-29T03:11:53Z|   cs|   cs|\n",
                  "|From Theory to Ap...|        cs.LG|2025-05-29T03:40:20Z|   cs| eess|\n",
                  "+--------------------+-------------+--------------------+-----+-----+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 5\n",
                  "Total papers processed: 745\n",
                  "Valid predictions: 745\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 20331.0ms\n",
                  "Average time per paper: 136.4ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 745\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 745\n",
                  "Macro F1: 0.713\n",
                  "Balanced Accuracy: 0.837\n",
                  "Prediction distribution: {'cs': 336, 'eess': 63, 'math': 88, 'quant-ph': 34, 'physics': 40, 'cond-mat': 45, 'math-ph': 5, 'astro-ph': 38, 'q-bio': 10, 'stat': 48, 'econ': 6, 'gr-qc': 9, 'hep': 14, 'nlin': 3, 'q-fin': 2, 'nucl': 4}\n",
                  "==================================================\n",
                  "========= Batch 6 (Papers: 179) =========\n",
                  "Batch API: 179 papers in 26504.2ms (API: 26488.1ms)\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|               title|    main_category|           published|   label|    pred|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "|LeMoRe: Learn Mor...|            cs.CV|2025-05-29T04:55:10Z|      cs|      cs|\n",
                  "|Identification of...|            cs.CV|2025-05-29T05:23:12Z|      cs|   q-bio|\n",
                  "|Interturn Fault D...|          eess.SY|2025-05-29T05:47:01Z|    eess|    eess|\n",
                  "|Random Field Repr...|          math.PR|2025-05-29T06:29:58Z|    math|    math|\n",
                  "|Rotationally symm...|          math.DG|2025-05-29T06:49:54Z|    math|    math|\n",
                  "|Pseudo Multi-Sour...|            cs.LG|2025-05-29T07:11:54Z|      cs|      cs|\n",
                  "|TrackVLA: Embodie...|            cs.RO|2025-05-29T07:28:09Z|      cs|      cs|\n",
                  "|Certified algorit...|            cs.DM|2025-05-29T07:44:32Z|      cs|      cs|\n",
                  "|The Chemical Cloc...|      astro-ph.GA|2025-05-29T08:05:27Z|astro-ph|astro-ph|\n",
                  "|Optical Controlla...|cond-mat.mtrl-sci|2025-05-29T08:39:07Z|cond-mat|cond-mat|\n",
                  "+--------------------+-----------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 6\n",
                  "Total papers processed: 924\n",
                  "Valid predictions: 924\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 21359.9ms\n",
                  "Average time per paper: 138.7ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 924\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 924\n",
                  "Macro F1: 0.716\n",
                  "Balanced Accuracy: 0.849\n",
                  "Prediction distribution: {'cs': 420, 'eess': 85, 'math': 116, 'quant-ph': 38, 'physics': 46, 'cond-mat': 54, 'math-ph': 6, 'astro-ph': 42, 'q-bio': 12, 'stat': 56, 'econ': 6, 'gr-qc': 13, 'hep': 20, 'nlin': 3, 'q-fin': 3, 'nucl': 4}\n",
                  "==================================================\n",
                  "========= Batch 7 (Papers: 176) =========\n",
                  "Batch API: 176 papers in 22533.8ms (API: 22504.8ms)\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "|               title|main_category|           published|label|pred|\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "|Are MLMs Trapped ...|        cs.CV|2025-05-29T09:20:12Z|   cs|  cs|\n",
                  "|Sobolev regularit...|      math.AP|2025-05-29T09:40:12Z| math|math|\n",
                  "|Generalized Categ...|        cs.CL|2025-05-29T10:02:04Z|   cs|  cs|\n",
                  "|Efficient Paramet...|        cs.LG|2025-05-29T10:30:13Z|   cs|stat|\n",
                  "|Distributional Co...|      econ.GN|2025-05-29T10:54:29Z| econ|econ|\n",
                  "|Synthetic Generat...|      eess.IV|2025-05-29T11:22:48Z| eess|eess|\n",
                  "|Dynamic Spectral ...|        cs.LG|2025-05-29T11:47:50Z|   cs|stat|\n",
                  "|Associators for A...|       hep-th|2025-05-29T12:09:15Z|  hep| hep|\n",
                  "|Agent Interpolati...|        cs.LO|2025-05-29T12:39:47Z|   cs|  cs|\n",
                  "|Toward Effective ...|        cs.SE|2025-05-29T13:07:45Z|   cs|  cs|\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 7\n",
                  "Total papers processed: 1100\n",
                  "Valid predictions: 1100\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 21527.6ms\n",
                  "Average time per paper: 137.0ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 1100\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 1100\n",
                  "Macro F1: 0.716\n",
                  "Balanced Accuracy: 0.820\n",
                  "Prediction distribution: {'cs': 502, 'eess': 99, 'math': 145, 'quant-ph': 42, 'physics': 57, 'cond-mat': 60, 'math-ph': 6, 'astro-ph': 51, 'q-bio': 17, 'stat': 64, 'econ': 8, 'gr-qc': 14, 'hep': 25, 'nlin': 3, 'q-fin': 3, 'nucl': 4}\n",
                  "==================================================\n",
                  "========= Batch 8 (Papers: 170) =========\n",
                  "Batch API: 170 papers in 22662.8ms (API: 22647.4ms)\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "|               title|main_category|           published|label|pred|\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "|CMIE: Combining M...|        cs.MM|2025-05-29T13:56:21Z|   cs|  cs|\n",
                  "|Semantics-Aware H...|        cs.SD|2025-05-29T14:16:27Z|   cs|  cs|\n",
                  "|PhysicsNeRF: Phys...|        cs.CV|2025-05-29T14:30:17Z|   cs|  cs|\n",
                  "|Hermitian modular...|      math.NT|2025-05-29T14:46:23Z| math|math|\n",
                  "|An Analysis of Ps...|      math.DS|2025-05-29T14:55:36Z| math|econ|\n",
                  "|Subgraph Gaussian...|        cs.LG|2025-05-29T15:07:22Z|   cs|  cs|\n",
                  "|Analysis of a one...|      math.AP|2025-05-29T15:23:14Z| math|math|\n",
                  "|Merge Hijacking: ...|        cs.CR|2025-05-29T15:37:23Z|   cs|  cs|\n",
                  "|On the Convergenc...|      math.OC|2025-05-29T15:48:13Z| math|math|\n",
                  "|Position: Federat...|        cs.LG|2025-05-29T16:04:39Z|   cs|  cs|\n",
                  "+--------------------+-------------+--------------------+-----+----+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 8\n",
                  "Total papers processed: 1270\n",
                  "Valid predictions: 1270\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 21669.5ms\n",
                  "Average time per paper: 136.5ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 1270\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 1270\n",
                  "Macro F1: 0.717\n",
                  "Balanced Accuracy: 0.817\n",
                  "Prediction distribution: {'cs': 582, 'eess': 114, 'math': 166, 'quant-ph': 47, 'physics': 64, 'cond-mat': 70, 'math-ph': 7, 'astro-ph': 57, 'q-bio': 18, 'stat': 77, 'econ': 9, 'gr-qc': 16, 'hep': 31, 'nlin': 3, 'q-fin': 4, 'nucl': 5}\n",
                  "==================================================\n",
                  "========= Batch 9 (Papers: 149) =========\n",
                  "Batch API: 149 papers in 22060.7ms (API: 22058.1ms)\n",
                  "+--------------------+---------------+--------------------+--------+--------+\n",
                  "|               title|  main_category|           published|   label|    pred|\n",
                  "+--------------------+---------------+--------------------+--------+--------+\n",
                  "|Few-Shot Speech D...|          cs.SD|2025-05-29T16:26:32Z|      cs|    eess|\n",
                  "|Expressivity of b...|          cs.LO|2025-05-29T16:44:36Z|      cs|    math|\n",
                  "|Merge-Friendly Po...|          cs.LG|2025-05-29T17:00:56Z|      cs|      cs|\n",
                  "|Fortune: Formula-...|          cs.AI|2025-05-29T17:13:40Z|      cs|      cs|\n",
                  "|Learning Composit...|          cs.LG|2025-05-29T17:22:00Z|      cs|      cs|\n",
                  "|Dyn-HTE: High-tem...|cond-mat.str-el|2025-05-29T17:37:38Z|cond-mat|cond-mat|\n",
                  "|AnySplat: Feed-fo...|          cs.CV|2025-05-29T17:49:56Z|      cs|      cs|\n",
                  "|EmotionRankCLAP: ...|          cs.LG|2025-05-29T17:56:55Z|      cs|    eess|\n",
                  "|Distortion of AI ...|          cs.LG|2025-05-29T17:59:20Z|      cs|      cs|\n",
                  "|From Chat Logs to...|          cs.CL|2025-05-29T17:59:55Z|      cs|      cs|\n",
                  "+--------------------+---------------+--------------------+--------+--------+\n",
                  "only showing top 10 rows\n",
                  "\n",
                  "\n",
                  "--- BATCH PROCESSING METRICS ---\n",
                  "Total batches processed: 9\n",
                  "Total papers processed: 1419\n",
                  "Valid predictions: 1419\n",
                  "Failed predictions: 0\n",
                  "Average batch processing time: 21712.9ms\n",
                  "Average time per paper: 137.7ms\n",
                  "Success rate: 100.0%\n",
                  "Driver-side log entries: 1419\n",
                  "\n",
                  "--- CLASSIFICATION PERFORMANCE ---\n",
                  "Valid predictions for metrics: 1419\n",
                  "Macro F1: 0.717\n",
                  "Balanced Accuracy: 0.817\n",
                  "Prediction distribution: {'cs': 672, 'eess': 126, 'math': 174, 'quant-ph': 51, 'physics': 70, 'cond-mat': 75, 'math-ph': 7, 'astro-ph': 65, 'q-bio': 23, 'stat': 84, 'econ': 9, 'gr-qc': 19, 'hep': 32, 'nlin': 3, 'q-fin': 4, 'nucl': 5}\n",
                  "==================================================\n"
               ]
            }
         ],
         "source": [
            "def process_batch(batch_df, batch_id):\n",
            "    paper_count = batch_df.count()\n",
            "    print(f\"========= Batch {batch_id} (Papers: {paper_count}) =========\")\n",
            "    \n",
            "    if paper_count > 0:\n",
            "        # Collect all papers for batch prediction\n",
            "        papers = batch_df.collect()\n",
            "        \n",
            "        if papers:\n",
            "            # Call batch API once\n",
            "            predictions = predict_batch_api(papers)\n",
            "            \n",
            "            # Create DataFrame with results\n",
            "            results_data = []\n",
            "            for i, paper in enumerate(papers):\n",
            "                prediction = predictions[i] if i < len(predictions) else \"api_error\"\n",
            "                results_data.append({\n",
            "                    'title': paper.title,\n",
            "                    'main_category': paper.main_category,\n",
            "                    'published': paper.published,\n",
            "                    'label': paper.label,\n",
            "                    'pred': prediction\n",
            "                })\n",
            "            \n",
            "            # Create results DataFrame and show\n",
            "            results_df = spark.createDataFrame(results_data)\n",
            "            results_df.select(\"title\", \"main_category\", \"published\", \"label\", \"pred\").show(10, truncate=True)\n",
            "            \n",
            "            # Log for metrics\n",
            "            for result in results_data:\n",
            "                if (result['label'] and result['pred'] and \n",
            "                    result['pred'] not in [\"api_error\", \"timeout_error\", \"connection_error\"]):\n",
            "                    predictions_log.append({\n",
            "                        'prediction': result['pred'],\n",
            "                        'true_label': result['label']\n",
            "                    })\n",
            "            \n",
            "            print_performance_metrics()\n",
            "\n",
            "# Start streaming with the new batch processing\n",
            "query = parsed_df.writeStream \\\n",
            "    .foreachBatch(process_batch) \\\n",
            "    .option(\"checkpointLocation\", \"/tmp/arxiv_checkpoint\") \\\n",
            "    .trigger(processingTime='2 seconds') \\\n",
            "    .start()\n",
            "\n",
            "print(\"Structured Streaming started with batch API!\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "query.stop()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Cleared checkpoint: /tmp/arxiv_checkpoint\n"
               ]
            }
         ],
         "source": [
            "# Restart checkpoint to batch 0 for fresh monitoring\n",
            "\n",
            "# import shutil\n",
            "# import os\n",
            "\n",
            "# # Clear checkpoint directory\n",
            "# checkpoint_path = \"/tmp/arxiv_checkpoint\"\n",
            "# if os.path.exists(checkpoint_path):\n",
            "#     shutil.rmtree(checkpoint_path)\n",
            "#     print(f\"Cleared checkpoint: {checkpoint_path}\")\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "assignment-03",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "undefined.undefined.undefined"
      },
      "toc": {
         "base_numbering": 1,
         "nav_menu": {},
         "number_sections": true,
         "sideBar": true,
         "skip_h1_title": false,
         "title_cell": "Table of Contents",
         "title_sidebar": "Contents",
         "toc_cell": false,
         "toc_position": {},
         "toc_section_display": true,
         "toc_window_display": false
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
