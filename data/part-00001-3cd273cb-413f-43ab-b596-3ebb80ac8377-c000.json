{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06124v1\", \"title\": \"Safe Interaction via Monte Carlo Linear-Quadratic Games\", \"summary\": \"Safety is critical during human-robot interaction. But -- because people are\\ninherently unpredictable -- it is often difficult for robots to plan safe\\nbehaviors. Instead of relying on our ability to anticipate humans, here we\\nidentify robot policies that are robust to unexpected human decisions. We\\nachieve this by formulating human-robot interaction as a zero-sum game, where\\n(in the worst case) the human's actions directly conflict with the robot's\\nobjective. Solving for the Nash Equilibrium of this game provides robot\\npolicies that maximize safety and performance across a wide range of human\\nactions. Existing approaches attempt to find these optimal policies by\\nleveraging Hamilton-Jacobi analysis (which is intractable) or linear-quadratic\\napproximations (which are inexact). By contrast, in this work we propose a\\ncomputationally efficient and theoretically justified method that converges\\ntowards the Nash Equilibrium policy. Our approach (which we call MCLQ)\\nleverages linear-quadratic games to obtain an initial guess at safe robot\\nbehavior, and then iteratively refines that guess with a Monte Carlo search.\\nNot only does MCLQ provide real-time safety adjustments, but it also enables\\nthe designer to tune how conservative the robot is -- preventing the system\\nfrom focusing on unrealistic human behaviors. Our simulations and user study\\nsuggest that this approach advances safety in terms of both computation time\\nand expected performance. See videos of our experiments here:\\nhttps://youtu.be/KJuHeiWVuWY.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-08T15:18:38Z\"}"}
