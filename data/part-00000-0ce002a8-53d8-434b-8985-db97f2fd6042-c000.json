{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24000v1\", \"title\": \"Rethinking Key-Value Cache Compression Techniques for Large Language\\n  Model Serving\", \"summary\": \"Key-Value cache (\\\\texttt{KV} \\\\texttt{cache}) compression has emerged as a\\npromising technique to optimize Large Language Model (LLM) serving. It\\nprimarily decreases the memory consumption of \\\\texttt{KV} \\\\texttt{cache} to\\nreduce the computation cost. Despite the development of many compression\\nalgorithms, their applications in production environments are still not\\nprevalent. In this paper, we revisit mainstream \\\\texttt{KV} \\\\texttt{cache}\\ncompression solutions from a practical perspective. Our contributions are\\nthree-fold. First, we comprehensively review existing algorithmic designs and\\nbenchmark studies for \\\\texttt{KV} \\\\texttt{cache} compression and identify\\nmissing pieces in their performance measurement, which could hinder their\\nadoption in practice. Second, we empirically evaluate representative\\n\\\\texttt{KV} \\\\texttt{cache} compression methods to uncover two key issues that\\naffect the computational efficiency: (1) while compressing \\\\texttt{KV}\\n\\\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\\nFlashAttention, PagedAttention) do not optimize for production-level LLM\\nserving, resulting in suboptimal throughput performance; (2) compressing\\n\\\\texttt{KV} \\\\texttt{cache} may lead to longer outputs, resulting in increased\\nend-to-end latency. We further investigate the accuracy performance of\\nindividual samples rather than the overall performance, revealing the intrinsic\\nlimitations in \\\\texttt{KV} \\\\texttt{cache} compression when handling specific\\nLLM tasks. Third, we provide tools to shed light on future \\\\texttt{KV}\\n\\\\texttt{cache} compression studies and facilitate their practical deployment in\\nproduction. They are open-sourced in\\n\\\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-03-31T12:23:31Z\"}"}
