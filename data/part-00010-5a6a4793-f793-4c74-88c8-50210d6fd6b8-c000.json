{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06672v1\", \"title\": \"RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism\", \"summary\": \"Video generation is experiencing rapid growth, driven by advances in\\ndiffusion models and the development of better and larger datasets. However,\\nproducing high-quality videos remains challenging due to the high-dimensional\\ndata and the complexity of the task. Recent efforts have primarily focused on\\nenhancing visual quality and addressing temporal inconsistencies, such as\\nflickering. Despite progress in these areas, the generated videos often fall\\nshort in terms of motion complexity and physical plausibility, with many\\noutputs either appearing static or exhibiting unrealistic motion. In this work,\\nwe propose a framework to improve the realism of motion in generated videos,\\nexploring a complementary direction to much of the existing literature.\\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\\nthe generation phase. The retrieved videos act as grounding signals, providing\\nthe model with demonstrations of how the objects move. Our pipeline is designed\\nto apply to any text-to-video diffusion model, conditioning a pretrained model\\non the retrieved samples with minimal fine-tuning. We demonstrate the\\nsuperiority of our approach through established metrics, recently proposed\\nbenchmarks, and qualitative results, and we highlight additional applications\\nof the framework.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T08:14:05Z\"}"}
