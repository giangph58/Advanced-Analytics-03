{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07560v1\", \"title\": \"PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data\\n  Generation\", \"summary\": \"Magnetic resonance imaging (MRI) raw data, or k-Space data, is\\ncomplex-valued, containing both magnitude and phase information. However,\\nclinical and existing Artificial Intelligence (AI)-based methods focus only on\\nmagnitude images, discarding the phase data despite its potential for\\ndownstream tasks, such as tumor segmentation and classification. In this work,\\nwe introduce $\\\\textit{PhaseGen}$, a novel complex-valued diffusion model for\\ngenerating synthetic MRI raw data conditioned on magnitude images, commonly\\nused in clinical practice. This enables the creation of artificial\\ncomplex-valued raw data, allowing pretraining for models that require k-Space\\ninformation. We evaluate PhaseGen on two tasks: skull-stripping directly in\\nk-Space and MRI reconstruction using the publicly available FastMRI dataset.\\nOur results show that training with synthetic phase data significantly improves\\ngeneralization for skull-stripping on real-world data, with an increased\\nsegmentation accuracy from $41.1\\\\%$ to $80.1\\\\%$, and enhances MRI\\nreconstruction when combined with limited real-world data. This work presents a\\nstep forward in utilizing generative AI to bridge the gap between\\nmagnitude-based datasets and the complex-valued nature of MRI raw data. This\\napproach allows researchers to leverage the vast amount of avaliable image\\ndomain data in combination with the information-rich k-Space data for more\\naccurate and efficient diagnostic tasks. We make our code publicly\\n$\\\\href{https://github.com/TIO-IKIM/PhaseGen}{\\\\text{available here}}$.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV,cs.LG\", \"published\": \"2025-04-10T08:44:19Z\"}"}
