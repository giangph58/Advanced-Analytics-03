{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05276v1\", \"title\": \"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\\n  Generation\", \"summary\": \"Short answer assessment is a vital component of science education, allowing\\nevaluation of students' complex three-dimensional understanding. Large language\\nmodels (LLMs) that possess human-like ability in linguistic tasks are\\nincreasingly popular in assisting human graders to reduce their workload.\\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\\ntask-specific requirements and hinder their ability to achieve satisfactory\\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\\nsolution by enabling LLMs to access relevant domain-specific knowledge during\\nassessment. In this work, we propose an adaptive RAG framework for automated\\ngrading that dynamically retrieves and incorporates domain-specific knowledge\\nbased on the question and student answer context. Our approach combines\\nsemantic search and curated educational sources to retrieve valuable reference\\nmaterials. Experimental results in a science education dataset demonstrate that\\nour system achieves an improvement in grading accuracy compared to baseline LLM\\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\\nreliable support with efficient performance gains.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-07T17:17:41Z\"}"}
