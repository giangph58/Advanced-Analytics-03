{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06752v1\", \"title\": \"Compass Control: Multi Object Orientation Control for Text-to-Image\\n  Generation\", \"summary\": \"Existing approaches for controlling text-to-image diffusion models, while\\npowerful, do not allow for explicit 3D object-centric control, such as precise\\ncontrol of object orientation. In this work, we address the problem of\\nmulti-object orientation control in text-to-image diffusion models. This\\nenables the generation of diverse multi-object scenes with precise orientation\\ncontrol for each object. The key idea is to condition the diffusion model with\\na set of orientation-aware \\\\textbf{compass} tokens, one for each object, along\\nwith text tokens. A light-weight encoder network predicts these compass tokens\\ntaking object orientation as the input. The model is trained on a synthetic\\ndataset of procedurally generated scenes, each containing one or two 3D assets\\non a plain background. However, direct training this framework results in poor\\norientation control as well as leads to entanglement among objects. To mitigate\\nthis, we intervene in the generation process and constrain the cross-attention\\nmaps of each compass token to its corresponding object regions. The trained\\nmodel is able to achieve precise orientation control for a) complex objects not\\nseen during training and b) multi-object scenes with more than two objects,\\nindicating strong generalization capabilities. Further, when combined with\\npersonalization methods, our method precisely controls the orientation of the\\nnew object in diverse contexts. Our method achieves state-of-the-art\\norientation control and text alignment, quantified with extensive evaluations\\nand a user study.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T10:15:15Z\"}"}
