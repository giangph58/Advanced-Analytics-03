{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24009v1\", \"title\": \"Learning 3D-Gaussian Simulators from RGB Videos\", \"summary\": \"Learning physics simulations from video data requires maintaining spatial and\\ntemporal consistency, a challenge often addressed with strong inductive biases\\nor ground-truth 3D information -- limiting scalability and generalization. We\\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\\nrepresentation, propagates dynamics via a transformer, and renders frames using\\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\\nproperties into point-wise latent vectors without enforcing explicit\\nconnectivity constraints. This enables the model to capture diverse physical\\nbehaviors, from rigid to elastic and cloth-like interactions, along with\\nrealistic lighting effects that also generalize to unseen multi-body\\ninteractions and novel scene edits.\", \"main_category\": \"cs.GR\", \"categories\": \"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO\", \"published\": \"2025-03-31T12:33:59Z\"}"}
