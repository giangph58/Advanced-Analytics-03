{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02522v1\", \"title\": \"Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic\\n  Assessment\", \"summary\": \"The capacity of Vision transformers (ViTs) to handle variable-sized inputs is\\noften constrained by computational complexity and batch processing limitations.\\nConsequently, ViTs are typically trained on small, fixed-size images obtained\\nthrough downscaling or cropping. While reducing computational burden, these\\nmethods result in significant information loss, negatively affecting tasks like\\nimage aesthetic assessment. We introduce Charm, a novel tokenization approach\\nthat preserves Composition, High-resolution, Aspect Ratio, and Multi-scale\\ninformation simultaneously. Charm prioritizes high-resolution details in\\nspecific regions while downscaling others, enabling shorter fixed-size input\\nsequences for ViTs while incorporating essential information. Charm is designed\\nto be compatible with pre-trained ViTs and their learned positional embeddings.\\nBy providing multiscale input and introducing variety to input tokens, Charm\\nimproves ViT performance and generalizability for image aesthetic assessment.\\nWe avoid cropping or changing the aspect ratio to further preserve information.\\nExtensive experiments demonstrate significant performance improvements on\\nvarious image aesthetic and quality assessment datasets (up to 8.1 %) using a\\nlightweight ViT backbone. Code and pre-trained models are available at\\nhttps://github.com/FBehrad/Charm.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T12:19:04Z\"}"}
