{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21757v1\", \"title\": \"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck\", \"summary\": \"In this work, we aim to compress the vision tokens of a Large Vision Language\\nModel (LVLM) into a representation that is simultaneously suitable for (a)\\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\\nthat uses the LVLM itself to compress the visual information in a task-agnostic\\nmanner. At the core of Fwd2bot there exists a \\\"double-forward pass\\\" training\\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\\na bottleneck by condensing the visual information into a small number of\\nsummary tokens. Then, using the same LLM, the second forward pass processes the\\nlanguage instruction(s) alongside the summary tokens, used as a direct\\nreplacement for the image ones. The training signal is provided by two losses:\\nan autoregressive one applied after the second pass that provides a direct\\noptimization objective for compression, and a contrastive loss, applied after\\nthe first pass, that further boosts the representation strength, especially for\\ndiscriminative tasks. The training is further enhanced by stage-specific\\nadapters. We accompany the proposed method by an in-depth ablation study.\\nOverall, Fwd2Bot results in highly-informative compressed representations\\nsuitable for both generative and discriminative tasks. For generative tasks, we\\noffer a 2x higher compression rate without compromising the generative\\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\\nwe set a new state-of-the-art on image retrieval and compositionality.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-03-27T17:57:07Z\"}"}
