{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01404v1\", \"title\": \"LLM4SZZ: Enhancing SZZ Algorithm with Context-Enhanced Assessment on\\n  Large Language Models\", \"summary\": \"The SZZ algorithm is the dominant technique for identifying bug-inducing\\ncommits and serves as a foundation for many software engineering studies, such\\nas bug prediction and static code analysis. Researchers have proposed many\\nvariants to enhance the SZZ algorithm's performance since its introduction. The\\nmajority of them rely on static techniques or heuristic assumptions, making\\nthem easy to implement, but their performance improvements are often limited.\\nRecently, a deep learning-based SZZ algorithm has been introduced to enhance\\nthe original SZZ algorithm. However, it requires complex preprocessing and is\\nrestricted to a single programming language. Additionally, while it enhances\\nprecision, it sacrifices recall. Furthermore, most of variants overlook crucial\\ninformation, such as commit messages and patch context, and are limited to\\nbug-fixing commits involving deleted lines. The emergence of large language\\nmodels (LLMs) offers an opportunity to address these drawbacks. In this study,\\nwe investigate the strengths and limitations of LLMs and propose LLM4SZZ, which\\nemploys two approaches (i.e., rank-based identification and context-enhanced\\nidentification) to handle different types of bug-fixing commits. We determine\\nwhich approach to adopt based on the LLM's ability to comprehend the bug and\\nidentify whether the bug is present in a commit. The context-enhanced\\nidentification provides the LLM with more context and requires it to find the\\nbug-inducing commit among a set of candidate commits. In rank-based\\nidentification, we ask the LLM to select buggy statements from the bug-fixing\\ncommit and rank them based on their relevance to the root cause. Experimental\\nresults show that LLM4SZZ outperforms all baselines across three datasets,\\nimproving F1-score by 6.9% to 16.0% without significantly sacrificing recall.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-02T06:40:57Z\"}"}
