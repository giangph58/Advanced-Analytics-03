{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02310v1\", \"title\": \"Improving Harmful Text Detection with Joint Retrieval and External\\n  Knowledge\", \"summary\": \"Harmful text detection has become a crucial task in the development and\\ndeployment of large language models, especially as AI-generated content\\ncontinues to expand across digital platforms. This study proposes a joint\\nretrieval framework that integrates pre-trained language models with knowledge\\ngraphs to improve the accuracy and robustness of harmful text detection.\\nExperimental results demonstrate that the joint retrieval approach\\nsignificantly outperforms single-model baselines, particularly in low-resource\\ntraining scenarios and multilingual environments. The proposed method\\neffectively captures nuanced harmful content by leveraging external contextual\\ninformation, addressing the limitations of traditional detection models. Future\\nresearch should focus on optimizing computational efficiency, enhancing model\\ninterpretability, and expanding multimodal detection capabilities to better\\ntackle evolving harmful content patterns. This work contributes to the\\nadvancement of AI safety, ensuring more trustworthy and reliable content\\nmoderation systems.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-03T06:37:55Z\"}"}
