{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04809v1\", \"title\": \"Select Me! When You Need a Tool: A Black-box Text Attack on Tool\\n  Selection\", \"summary\": \"Tool learning serves as a powerful auxiliary mechanism that extends the\\ncapabilities of large language models (LLMs), enabling them to tackle complex\\ntasks requiring real-time relevance or high precision operations. Behind its\\npowerful capabilities lie some potential security issues. However, previous\\nwork has primarily focused on how to make the output of the invoked tools\\nincorrect or malicious, with little attention given to the manipulation of tool\\nselection. To fill this gap, we introduce, for the first time, a black-box\\ntext-based attack that can significantly increase the probability of the target\\ntool being selected in this paper. We propose a two-level text perturbation\\nattack witha coarse-to-fine granularity, attacking the text at both the word\\nlevel and the character level. We conduct comprehensive experiments that\\ndemonstrate the attacker only needs to make some perturbations to the tool's\\ntextual information to significantly increase the possibility of the target\\ntool being selected and ranked higher among the candidate tools. Our research\\nreveals the vulnerability of the tool selection process and paves the way for\\nfuture research on protecting this process.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-04-07T08:04:23Z\"}"}
