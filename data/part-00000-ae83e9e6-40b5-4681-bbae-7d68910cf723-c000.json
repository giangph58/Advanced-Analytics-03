{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06996v1\", \"title\": \"Neural Signal Compression using RAMAN tinyML Accelerator for BCI\\n  Applications\", \"summary\": \"High-quality, multi-channel neural recording is indispensable for\\nneuroscience research and clinical applications. Large-scale brain recordings\\noften produce vast amounts of data that must be wirelessly transmitted for\\nsubsequent offline analysis and decoding, especially in brain-computer\\ninterfaces (BCIs) utilizing high-density intracortical recordings with hundreds\\nor thousands of electrodes. However, transmitting raw neural data presents\\nsignificant challenges due to limited communication bandwidth and resultant\\nexcessive heating. To address this challenge, we propose a neural signal\\ncompression scheme utilizing Convolutional Autoencoders (CAEs), which achieves\\na compression ratio of up to 150 for compressing local field potentials (LFPs).\\nThe CAE encoder section is implemented on RAMAN, an energy-efficient tinyML\\naccelerator designed for edge computing, and subsequently deployed on an Efinix\\nTi60 FPGA with 37.3k LUTs and 8.6k register utilization. RAMAN leverages\\nsparsity in activation and weights through zero skipping, gating, and weight\\ncompression techniques. Additionally, we employ hardware-software\\nco-optimization by pruning CAE encoder model parameters using a hardware-aware\\nbalanced stochastic pruning strategy, resolving workload imbalance issues and\\neliminating indexing overhead to reduce parameter storage requirements by up to\\n32.4%. Using the proposed compact depthwise separable convolutional autoencoder\\n(DS-CAE) model, the compressed neural data from RAMAN is reconstructed offline\\nwith superior signal-to-noise and distortion ratios (SNDR) of 22.6 dB and 27.4\\ndB, along with R2 scores of 0.81 and 0.94, respectively, evaluated on two\\nmonkey neural recordings.\", \"main_category\": \"cs.AR\", \"categories\": \"cs.AR,cs.HC,cs.LG\", \"published\": \"2025-04-09T16:09:00Z\"}"}
