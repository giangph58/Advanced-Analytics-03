{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24210v1\", \"title\": \"DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D\\n  Gaussian Splatting\", \"summary\": \"Reconstructing sharp 3D representations from blurry multi-view images are\\nlong-standing problem in computer vision. Recent works attempt to enhance\\nhigh-quality novel view synthesis from the motion blur by leveraging\\nevent-based cameras, benefiting from high dynamic range and microsecond\\ntemporal resolution. However, they often reach sub-optimal visual quality in\\neither restoring inaccurate color or losing fine-grained details. In this\\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\\nintroduce the novel framework to constraint 3DGS with event double integral,\\nachieving both accurate color and well-defined details. Additionally, we\\npropose a simple technique to leverage diffusion prior to further enhance the\\nedge details. Qualitative and quantitative results on both synthetic and\\nreal-world data demonstrate that our DiET-GS is capable of producing\\nsignificantly better quality of novel views compared to the existing baselines.\\nOur project page is https://diet-gs.github.io\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.MM\", \"published\": \"2025-03-31T15:27:07Z\"}"}
