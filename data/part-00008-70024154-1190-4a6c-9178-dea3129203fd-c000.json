{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06660v1\", \"title\": \"Robust and Noise-resilient Long-Term Prediction of Spatiotemporal Data\\n  Using Variational Mode Graph Neural Networks with 3D Attention\", \"summary\": \"This paper focuses on improving the robustness of spatiotemporal long-term\\nprediction using a variational mode graph convolutional network (VMGCN) by\\nintroducing 3D channel attention. The deep learning network for this task\\nrelies on historical data inputs, yet real-time data can be corrupted by sensor\\nnoise, altering its distribution. We model this noise as independent and\\nidentically distributed (i.i.d.) Gaussian noise and incorporate it into the\\nLargeST traffic volume dataset, resulting in data with both inherent and\\nadditive noise components. Our approach involves decomposing the corrupted\\nsignal into modes using variational mode decomposition, followed by feeding the\\ndata into a learning pipeline for prediction. We integrate a 3D attention\\nmechanism encompassing spatial, temporal, and channel attention. The spatial\\nand temporal attention modules learn their respective correlations, while the\\nchannel attention mechanism is used to suppress noise and highlight the\\nsignificant modes in the spatiotemporal signals. Additionally, a learnable soft\\nthresholding method is implemented to exclude unimportant modes from the\\nfeature vector, and a feature reduction method based on the signal-to-noise\\nratio (SNR) is applied. We compare the performance of our approach against\\nbaseline models, demonstrating that our method achieves superior long-term\\nprediction accuracy, robustness to noise, and improved performance with mode\\ntruncation compared to the baseline models. The code of the paper is available\\nat https://github.com/OsamaAhmad369/VMGCN.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-09T07:49:45Z\"}"}
