{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05074v1\", \"title\": \"On the Performance of an Explainable Language Model on PubMedQA\", \"summary\": \"Large language models (LLMs) have shown significant abilities in retrieving\\nmedical knowledge, reasoning over it and answering medical questions comparably\\nto physicians. However, these models are not interpretable, hallucinate, are\\ndifficult to maintain and require enormous compute resources for training and\\ninference. In this paper, we report results from Gyan, an explainable language\\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\\nLLM is a compositional language model and the model is decoupled from\\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\\nrequire significant training or compute resources. Gyan is easily transferable\\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\\nDeepMind). We will be reporting results for other medical data sets - MedQA,\\nMedMCQA, MMLU - Medicine in the future.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-07T13:42:02Z\"}"}
