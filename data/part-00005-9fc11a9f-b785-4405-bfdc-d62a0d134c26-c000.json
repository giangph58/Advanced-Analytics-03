{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01957v1\", \"title\": \"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\\n  Estimation via Gaussian Splatting\", \"summary\": \"Bird's-eye view (BEV) perception has gained significant attention because it\\nprovides a unified representation to fuse multiple view images and enables a\\nwide range of down-stream autonomous driving tasks, such as forecasting and\\nplanning. Recent state-of-the-art models utilize projection-based methods which\\nformulate BEV perception as query learning to bypass explicit depth estimation.\\nWhile we observe promising advancements in this paradigm, they still fall short\\nof real-world applications because of the lack of uncertainty modeling and\\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\\nnovel uncertainty-aware BEV perception framework that revisits\\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\\nand enhances them with depth un-certainty modeling. GaussianLSS represents\\nspatial dispersion by learning a soft depth mean and computing the variance of\\nthe depth distribution, which implicitly captures object extents. We then\\ntransform the depth distribution into 3D Gaussians and rasterize them to\\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\\nnuScenes dataset, achieving state-of-the-art performance compared to\\nunprojection-based methods. In particular, it provides significant advantages\\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\\ncompared to projection-based methods, while achieving competitive performance\\nwith only a 0.4% IoU difference.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T17:59:38Z\"}"}
