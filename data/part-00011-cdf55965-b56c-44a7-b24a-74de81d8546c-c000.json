{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02524v1\", \"title\": \"SelfMedHPM: Self Pre-training With Hard Patches Mining Masked\\n  Autoencoders For Medical Image Segmentation\", \"summary\": \"In recent years, deep learning methods such as convolutional neural network\\n(CNN) and transformers have made significant progress in CT multi-organ\\nsegmentation. However, CT multi-organ segmentation methods based on masked\\nimage modeling (MIM) are very limited. There are already methods using MAE for\\nCT multi-organ segmentation task, we believe that the existing methods do not\\nidentify the most difficult areas to reconstruct. To this end, we propose a MIM\\nself-training framework with hard patches mining masked autoencoders for CT\\nmulti-organ segmentation tasks (selfMedHPM). The method performs ViT\\nself-pretraining on the training set of the target data and introduces an\\nauxiliary loss predictor, which first predicts the patch loss and determines\\nthe location of the next mask. SelfMedHPM implementation is better than various\\ncompetitive methods in abdominal CT multi-organ segmentation and body CT\\nmulti-organ segmentation. We have validated the performance of our method on\\nthe Multi Atlas Labeling Beyond The Cranial Vault (BTCV) dataset for abdomen\\nmult-organ segmentation and the SinoMed Whole Body (SMWB) dataset for body\\nmulti-organ segmentation tasks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T12:28:21Z\"}"}
