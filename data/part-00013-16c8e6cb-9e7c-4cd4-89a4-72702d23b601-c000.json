{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05265v1\", \"title\": \"From Sparse Signal to Smooth Motion: Real-Time Motion Generation with\\n  Rolling Prediction Models\", \"summary\": \"In extended reality (XR), generating full-body motion of the users is\\nimportant to understand their actions, drive their virtual avatars for social\\ninteraction, and convey a realistic sense of presence. While prior works\\nfocused on spatially sparse and always-on input signals from motion\\ncontrollers, many XR applications opt for vision-based hand tracking for\\nreduced user friction and better immersion. Compared to controllers, hand\\ntracking signals are less accurate and can even be missing for an extended\\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\\nModel (RPM), an online and real-time approach that generates smooth full-body\\nmotion from temporally and spatially sparse input signals. Our model generates\\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\\nplausible motion when inputs are missing (i.e., synthesis mode). More\\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\\nvice versa. To demonstrate the practical importance of handling noisy and\\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\\nfrom a commercial virtual reality (VR) headset with paired high quality body\\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\\nusing motion controllers (spatially sparse) and hand tracking (spatially and\\ntemporally sparse). We benchmark RPM against the state of the art on both\\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\\napplications with a realistic dataset and by handling unreliable input signals.\\nOur code, pretrained models, and GORP dataset are available in the project\\nwebpage.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T17:00:34Z\"}"}
