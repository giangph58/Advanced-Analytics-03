{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06719v1\", \"title\": \"Masked Scene Modeling: Narrowing the Gap Between Supervised and\\n  Self-Supervised Learning in 3D Scene Understanding\", \"summary\": \"Self-supervised learning has transformed 2D computer vision by enabling\\nmodels trained on large, unannotated datasets to provide versatile\\noff-the-shelf features that perform similarly to models trained with labels.\\nHowever, in 3D scene understanding, self-supervised methods are typically only\\nused as a weight initialization step for task-specific fine-tuning, limiting\\ntheir utility for general-purpose feature extraction. This paper addresses this\\nshortcoming by proposing a robust evaluation protocol specifically designed to\\nassess the quality of self-supervised features for 3D scene understanding. Our\\nprotocol uses multi-resolution feature sampling of hierarchical models to\\ncreate rich point-level representations that capture the semantic capabilities\\nof the model and, hence, are suitable for evaluation with linear probing and\\nnearest-neighbor methods. Furthermore, we introduce the first self-supervised\\nmodel that performs similarly to supervised models when only off-the-shelf\\nfeatures are used in a linear probing setup. In particular, our model is\\ntrained natively in 3D with a novel self-supervised approach based on a Masked\\nScene Modeling objective, which reconstructs deep features of masked patches in\\na bottom-up manner and is specifically tailored to hierarchical 3D models. Our\\nexperiments not only demonstrate that our method achieves competitive\\nperformance to supervised models, but also surpasses existing self-supervised\\napproaches by a large margin. The model and training code can be found at our\\nGithub repository (https://github.com/phermosilla/msm).\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-09T09:19:49Z\"}"}
