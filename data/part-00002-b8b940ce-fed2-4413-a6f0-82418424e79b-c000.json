{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01534v1\", \"title\": \"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\\n  Domain-Adaptive Pretraining and Match Metadata\", \"summary\": \"The detrimental effects of toxicity in competitive online video games are\\nwidely acknowledged, prompting publishers to monitor player chat conversations.\\nThis is challenging due to the context-dependent nature of toxicity, often\\nspread across multiple messages or informed by non-textual interactions.\\nTraditional toxicity detectors focus on isolated messages, missing the broader\\ncontext needed for accurate moderation. This is especially problematic in video\\ngames, where interactions involve specialized slang, abbreviations, and typos,\\nmaking it difficult for standard models to detect toxicity, especially given\\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\\ngames, integrating both textual and non-textual context. By enhancing\\npretrained embeddings with metadata and addressing the unique slang and\\nlanguage quirks through domain adaptive pretraining, our method better captures\\nthe nuances of player interactions. Using two gaming datasets - from Defense of\\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\\\circledR$: Modern\\nWarfare$^\\\\circledR$III (MWIII) we demonstrate which sources of context\\n(metadata, prior interactions...) are most useful, how to best leverage them to\\nboost performance, and the conditions conducive to doing so. This work\\nunderscores the importance of context-aware and domain-specific approaches for\\nproactive moderation.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-02T09:21:41Z\"}"}
