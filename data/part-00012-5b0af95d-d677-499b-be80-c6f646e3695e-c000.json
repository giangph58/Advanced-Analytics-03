{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01521v1\", \"title\": \"Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion\\n  Model\", \"summary\": \"Recent advancements in diffusion models have revolutionized generative\\nmodeling. However, the impressive and vivid outputs they produce often come at\\nthe cost of significant model scaling and increased computational demands.\\nConsequently, building personalized diffusion models based on off-the-shelf\\nmodels has emerged as an appealing alternative. In this paper, we introduce a\\nnovel perspective on conditional generation for transferring a pre-trained\\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\\ntransfer approach that leverages pre-trained knowledge to guide the sampling\\nprocess toward the target domain. Domain Guidance shares a formulation similar\\nto advanced classifier-free guidance, facilitating better domain alignment and\\nhigher-quality generations. We provide both empirical and theoretical analyses\\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\\nits substantial effectiveness across various transfer benchmarks, achieving\\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\\\text{DINOv2}$\\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\\nseamlessly integrate Domain Guidance to leverage these benefits, without\\nadditional training.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CV\", \"published\": \"2025-04-02T09:07:55Z\"}"}
