{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06903v1\", \"title\": \"Network Cross-Validation and Model Selection via Subsampling\", \"summary\": \"Complex and larger networks are becoming increasingly prevalent in scientific\\napplications in various domains. Although a number of models and methods exist\\nfor such networks, cross-validation on networks remains challenging due to the\\nunique structure of network data. In this paper, we propose a general\\ncross-validation procedure called NETCROP (NETwork CRoss-Validation using\\nOverlapping Partitions). The key idea is to divide the original network into\\nmultiple subnetworks with a shared overlap part, producing training sets\\nconsisting of the subnetworks and a test set with the node pairs between the\\nsubnetworks. This train-test split provides the basis for a network\\ncross-validation procedure that can be applied on a wide range of model\\nselection and parameter tuning problems for networks. The method is\\ncomputationally efficient for large networks as it uses smaller subnetworks for\\nthe training step. We provide methodological details and theoretical guarantees\\nfor several model selection and parameter tuning tasks using NETCROP. Numerical\\nresults demonstrate that NETCROP performs accurate cross-validation on a\\ndiverse set of network model selection and parameter tuning problems. The\\nresults also indicate that NETCROP is computationally much faster while being\\noften more accurate than the existing methods for network cross-validation.\", \"main_category\": \"stat.ME\", \"categories\": \"stat.ME,stat.CO\", \"published\": \"2025-04-09T14:03:40Z\"}"}
