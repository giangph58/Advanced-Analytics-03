{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01523v1\", \"title\": \"Adapting Knowledge Prompt Tuning for Enhanced Automated Program Repair\", \"summary\": \"Automated Program Repair (APR) aims to enhance software reliability by\\nautomatically generating bug-fixing patches. Recent work has improved the\\nstate-of-the-art of APR by fine-tuning pre-trained large language models\\n(LLMs), such as CodeT5, for APR. However, the effectiveness of fine-tuning\\nbecomes weakened in data scarcity scenarios, and data scarcity can be a common\\nissue in practice, limiting fine-tuning performance. To alleviate this\\nlimitation, this paper adapts prompt tuning for enhanced APR and conducts a\\ncomprehensive study to evaluate its effectiveness in data scarcity scenarios,\\nusing three LLMs of different sizes and six diverse datasets across four\\nprogramming languages. Prompt tuning rewrites the input to a model by adding\\nextra prompt tokens and tunes both the model and the prompts on a small\\ndataset. These tokens provide task-specific knowledge that can improve the\\nmodel for APR, which is especially critical in data scarcity scenarios.\\nMoreover, domain knowledge has proven crucial in many code intelligence tasks,\\nbut existing studies fail to leverage domain knowledge during the prompt tuning\\nfor APR. To close this gap, we introduce knowledge prompt tuning, an approach\\nthat adapts prompt tuning with six distinct types of code- or bug-related\\ndomain knowledge for APR. Our work, to the best of our knowledge, is the first\\nto adapt and evaluate prompt tuning and the effectiveness of code- or\\nbug-related domain knowledge for APR, particularly under data scarcity\\nsettings. Our evaluation results demonstrate that prompt tuning with knowledge\\ngenerally outperforms fine-tuning under various experimental settings,\\nachieving an average improvement of 87.33% over fine-tuning in data scarcity\\nscenarios.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-02T09:10:02Z\"}"}
