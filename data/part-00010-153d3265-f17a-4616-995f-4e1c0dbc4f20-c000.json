{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06984v1\", \"title\": \"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\\n  Theory\", \"summary\": \"The masses of data now available have opened up the prospect of discovering\\nweak signals using machine-learning algorithms, with a view to predictive or\\ninterpretation tasks. As this survey of recent results attempts to show,\\nbringing multivariate extreme value theory and statistical learning theory\\ntogether in a common, non-parametric and non-asymptotic framework makes it\\npossible to design and analyze new methods for exploiting the scarce\\ninformation located in distribution tails in these purposes. This article\\nreviews recently proved theoretical tools for establishing guarantees for\\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\\nThese are mainly exponential maximal deviation inequalities tailored to\\nlow-probability regions and concentration results for stochastic processes\\nempirically describing the behavior of extreme observations, their dependence\\nstructure in particular. Under appropriate assumptions of regular variation,\\nseveral illustrative applications are then examined: classification,\\nregression, anomaly detection, model selection via cross-validation. For these,\\ngeneralization results are established inspired by the classical bounds in\\nstatistical learning theory. In the same spirit, it is also shown how to adapt\\nthe popular high-dimensional lasso technique in the context of extreme values\\nfor the covariates with generalization guarantees.\", \"main_category\": \"math.ST\", \"categories\": \"math.ST,stat.TH\", \"published\": \"2025-04-09T15:41:40Z\"}"}
