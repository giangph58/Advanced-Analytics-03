{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05923v1\", \"title\": \"Uncovering Fairness through Data Complexity as an Early Indicator\", \"summary\": \"Fairness constitutes a concern within machine learning (ML) applications.\\nCurrently, there is no study on how disparities in classification complexity\\nbetween privileged and unprivileged groups could influence the fairness of\\nsolutions, which serves as a preliminary indicator of potential unfairness. In\\nthis work, we investigate this gap, specifically, we focus on synthetic\\ndatasets designed to capture a variety of biases ranging from historical bias\\nto measurement and representational bias to evaluate how various complexity\\nmetrics differences correlate with group fairness metrics. We then apply\\nassociation rule mining to identify patterns that link disproportionate\\ncomplexity differences between groups with fairness-related outcomes, offering\\ndata-centric indicators to guide bias mitigation. Our findings are also\\nvalidated by their application in real-world problems, providing evidence that\\nquantifying group-wise classification complexity can uncover early indicators\\nof potential fairness challenges. This investigation helps practitioners to\\nproactively address bias in classification tasks.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.DS\", \"published\": \"2025-04-08T11:28:40Z\"}"}
