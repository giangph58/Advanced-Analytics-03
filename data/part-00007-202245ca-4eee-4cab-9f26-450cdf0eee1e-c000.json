{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02623v1\", \"title\": \"Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents\\n  through Related and Dynamic Missions\", \"summary\": \"Large language models (LLMs) demonstrate strong potential as agents for tool\\ninvocation due to their advanced comprehension and planning capabilities. Users\\nincreasingly rely on LLM-based agents to solve complex missions through\\niterative interactions. However, existing benchmarks predominantly access\\nagents in single-mission scenarios, failing to capture real-world complexity.\\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\\neach test case comprises multiple interrelated missions. This design requires\\nagents to dynamically adapt to evolving demands. Moreover, the proposed\\nbenchmark explores all possible mission-switching patterns within a fixed\\nmission number. Specifically, we propose a multi-agent data generation\\nframework to construct the benchmark. We also propose a novel method to\\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\\ncritical factors influencing agent robustness and provide actionable insights\\nto the tool invocation society.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-03T14:21:33Z\"}"}
