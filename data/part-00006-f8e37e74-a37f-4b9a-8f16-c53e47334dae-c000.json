{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07095v1\", \"title\": \"Neural Motion Simulator: Pushing the Limit of World Models in\\n  Reinforcement Learning\", \"summary\": \"An embodied system must not only model the patterns of the external world but\\nalso understand its own motion dynamics. A motion dynamic model is essential\\nfor efficient skill acquisition and effective planning. In this work, we\\nintroduce the neural motion simulator (MoSim), a world model that predicts the\\nfuture physical state of an embodied system based on current observations and\\nactions. MoSim achieves state-of-the-art performance in physical state\\nprediction and provides competitive performance across a range of downstream\\ntasks. This works shows that when a world model is accurate enough and performs\\nprecise long-horizon predictions, it can facilitate efficient skill acquisition\\nin imagined worlds and even enable zero-shot reinforcement learning.\\nFurthermore, MoSim can transform any model-free reinforcement learning (RL)\\nalgorithm into a model-based approach, effectively decoupling physical\\nenvironment modeling from RL algorithm development. This separation allows for\\nindependent advancements in RL algorithms and world modeling, significantly\\nimproving sample efficiency and enhancing generalization capabilities. Our\\nfindings highlight that world models for motion dynamics is a promising\\ndirection for developing more versatile and capable embodied systems.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.RO\", \"published\": \"2025-04-09T17:59:32Z\"}"}
