{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01533v1\", \"title\": \"LightDefense: A Lightweight Uncertainty-Driven Defense against\\n  Jailbreaks via Shifted Token Distribution\", \"summary\": \"Large Language Models (LLMs) face threats from jailbreak prompts. Existing\\nmethods for defending against jailbreak attacks are primarily based on\\nauxiliary models. These strategies, however, often require extensive data\\ncollection or training. We propose LightDefense, a lightweight defense\\nmechanism targeted at white-box models, which utilizes a safety-oriented\\ndirection to adjust the probabilities of tokens in the vocabulary, making\\nsafety disclaimers appear among the top tokens after sorting tokens by\\nprobability in descending order. We further innovatively leverage LLM's\\nuncertainty about prompts to measure their harmfulness and adaptively adjust\\ndefense strength, effectively balancing safety and helpfulness. The\\neffectiveness of LightDefense in defending against 5 attack methods across 2\\ntarget LLMs, without compromising helpfulness to benign user queries,\\nhighlights its potential as a novel and lightweight defense mechanism,\\nenhancing security of LLMs.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.CY\", \"published\": \"2025-04-02T09:21:26Z\"}"}
