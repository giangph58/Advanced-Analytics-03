{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06129v1\", \"title\": \"Knowledge Graph Completion with Relation-Aware Anchor Enhancement\", \"summary\": \"Text-based knowledge graph completion methods take advantage of pre-trained\\nlanguage models (PLM) to enhance intrinsic semantic connections of raw triplets\\nwith detailed text descriptions. Typical methods in this branch map an input\\nquery (textual descriptions associated with an entity and a relation) and its\\ncandidate entities into feature vectors, respectively, and then maximize the\\nprobability of valid triples. These methods are gaining promising performance\\nand increasing attention for the rapid development of large language models.\\nAccording to the property of the language models, the more related and specific\\ncontext information the input query provides, the more discriminative the\\nresultant embedding will be. In this paper, through observation and validation,\\nwe find a neglected fact that the relation-aware neighbors of the head entities\\nin queries could act as effective contexts for more precise link prediction.\\nDriven by this finding, we propose a relation-aware anchor enhanced knowledge\\ngraph completion method (RAA-KGC). Specifically, in our method, to provide a\\nreference of what might the target entity be like, we first generate anchor\\nentities within the relation-aware neighborhood of the head entity. Then, by\\npulling the query embedding towards the neighborhoods of the anchors, it is\\ntuned to be more discriminative for target entity matching. The results of our\\nextensive experiments not only validate the efficacy of RAA-KGC but also reveal\\nthat by integrating our relation-aware anchor enhancement strategy, the\\nperformance of current leading methods can be notably enhanced without\\nsubstantial modifications.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-08T15:22:08Z\"}"}
