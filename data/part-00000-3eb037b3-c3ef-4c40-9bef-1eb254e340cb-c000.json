{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24007v1\", \"title\": \"CITRAS: Covariate-Informed Transformer for Time Series Forecasting\", \"summary\": \"Covariates play an indispensable role in practical time series forecasting,\\noffering rich context from the past and sometimes extending into the future.\\nHowever, their availability varies depending on the scenario, and situations\\noften involve multiple target variables simultaneously. Moreover, the\\ncross-variate dependencies between them are multi-granular, with some\\ncovariates having a short-term impact on target variables and others showing\\nlong-term correlations. This heterogeneity and the intricate dependencies\\narising in covariate-informed forecasting present significant challenges to\\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\\nTransformer that flexibly leverages multiple targets and covariates covering\\nboth the past and the future forecasting horizon. While preserving the strong\\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\\ncovariates into the forecasting of target variables based on their concurrent\\ndependencies. Additionally, Attention Score Smoothing transforms locally\\naccurate patch-wise cross-variate dependencies into global variate-level\\ndependencies by smoothing the past series of attention scores. Experimentally,\\nCITRAS achieves state-of-the-art performance in both covariate-informed and\\nmultivariate forecasting, demonstrating its versatile ability to leverage\\ncross-variate dependency for improved forecasting accuracy.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-03-31T12:32:23Z\"}"}
