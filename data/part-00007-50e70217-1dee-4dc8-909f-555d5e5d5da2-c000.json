{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06237v1\", \"title\": \"Monitoring Viewer Attention During Online Ads\", \"summary\": \"Nowadays, video ads spread through numerous online platforms, and are being\\nwatched by millions of viewers worldwide. Big brands gauge the liking and\\npurchase intent of their new ads, by analyzing the facial responses of viewers\\nrecruited online to watch the ads from home or work. Although this approach\\ncaptures naturalistic responses, it is susceptible to distractions inherent in\\nthe participants' environments, such as a movie playing on TV, a colleague\\nspeaking, or mobile notifications. Inattentive participants should get flagged\\nand eliminated to avoid skewing the ad-testing process. In this paper we\\nintroduce an architecture for monitoring viewer attention during online ads.\\nLeveraging two behavior analysis toolkits; AFFDEX 2.0 and SmartEye SDK, we\\nextract low-level facial features encompassing facial expressions, head pose,\\nand gaze direction. These features are then combined to extract high-level\\nfeatures that include estimated gaze on the screen plane, yawning, speaking,\\netc -- this enables the identification of four primary distractors; off-screen\\ngaze, drowsiness, speaking, and unattended screen. Our architecture tailors the\\ngaze settings according to the device type (desktop or mobile). We validate our\\narchitecture first on datasets annotated for specific distractors, and then on\\na real-world ad testing dataset with various distractors. The proposed\\narchitecture shows promising results in detecting distraction across both\\ndesktop and mobile devices.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-08T17:34:02Z\"}"}
