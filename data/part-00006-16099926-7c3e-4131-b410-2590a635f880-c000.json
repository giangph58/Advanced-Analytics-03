{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02647v1\", \"title\": \"Adaptive Frequency Enhancement Network for Remote Sensing Image Semantic\\n  Segmentation\", \"summary\": \"Semantic segmentation of high-resolution remote sensing images plays a\\ncrucial role in land-use monitoring and urban planning. Recent remarkable\\nprogress in deep learning-based methods makes it possible to generate\\nsatisfactory segmentation results. However, existing methods still face\\nchallenges in adapting network parameters to various land cover distributions\\nand enhancing the interaction between spatial and frequency domain features. To\\naddress these challenges, we propose the Adaptive Frequency Enhancement Network\\n(AFENet), which integrates two key components: the Adaptive Frequency and\\nSpatial feature Interaction Module (AFSIM) and the Selective feature Fusion\\nModule (SFM). AFSIM dynamically separates and modulates high- and low-frequency\\nfeatures according to the content of the input image. It adaptively generates\\ntwo masks to separate high- and low-frequency components, therefore providing\\noptimal details and contextual supplementary information for ground object\\nfeature representation. SFM selectively fuses global context and local detailed\\nfeatures to enhance the network's representation capability. Hence, the\\ninteractions between frequency and spatial features are further enhanced.\\nExtensive experiments on three publicly available datasets demonstrate that the\\nproposed AFENet outperforms state-of-the-art methods. In addition, we also\\nvalidate the effectiveness of AFSIM and SFM in managing diverse land cover\\ntypes and complex scenarios. Our codes are available at\\nhttps://github.com/oucailab/AFENet.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-03T14:42:49Z\"}"}
