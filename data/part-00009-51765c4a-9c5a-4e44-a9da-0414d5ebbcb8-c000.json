{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01506v1\", \"title\": \"MLKV: Efficiently Scaling up Large Embedding Model Training with\\n  Disk-based Key-Value Storage\", \"summary\": \"Many modern machine learning (ML) methods rely on embedding models to learn\\nvector representations (embeddings) for a set of entities (embedding tables).\\nAs increasingly diverse ML applications utilize embedding models and embedding\\ntables continue to grow in size and number, there has been a surge in the\\nad-hoc development of specialized frameworks targeted to train large embedding\\nmodels for specific tasks. Although the scalability issues that arise in\\ndifferent embedding model training tasks are similar, each of these frameworks\\nindependently reinvents and customizes storage components for specific tasks,\\nleading to substantial duplicated engineering efforts in both development and\\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\\ndata storage framework designed to address the scalability challenges in\\nembedding model training, specifically data stall and staleness. MLKV augments\\ndisk-based key-value storage by democratizing optimizations that were\\npreviously exclusive to individual specialized frameworks and provides\\neasy-to-use interfaces for embedding model training tasks. Extensive\\nexperiments on open-source workloads, as well as applications in eBay's payment\\ntransaction risk detection and seller payment risk detection, show that MLKV\\noutperforms offloading strategies built on top of industrial-strength key-value\\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-02T08:57:01Z\"}"}
