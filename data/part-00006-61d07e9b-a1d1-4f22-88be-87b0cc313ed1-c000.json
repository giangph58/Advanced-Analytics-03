{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01400v1\", \"title\": \"ToolACE-R: Tool Learning with Adaptive Self-Refinement\", \"summary\": \"Tool learning, which allows Large Language Models (LLMs) to leverage external\\ntools for solving complex user tasks, has emerged as a promising avenue for\\nextending model capabilities. However, current approaches primarily focus on\\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\\nignoring how to fully stimulate the potential of the model. In this paper, we\\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\\ntool invocations. Our approach features a model-aware iterative training\\nprocedure that progressively incorporates more training samples based on the\\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\\nrefine their tool calls, optimizing performance without requiring external\\nfeedback. To further enhance computational efficiency, we integrate an adaptive\\nmechanism when scaling the inference time, enabling the model to autonomously\\ndetermine when to stop the refinement process. We conduct extensive experiments\\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\\nperformance compared to advanced API-based models, even without any refinement.\\nFurthermore, its performance can be further improved efficiently through\\nadaptive self-refinement. Our results demonstrate the effectiveness of the\\nproposed method, which is compatible with base models of various sizes,\\noffering a promising direction for more efficient tool learning.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-04-02T06:38:56Z\"}"}
