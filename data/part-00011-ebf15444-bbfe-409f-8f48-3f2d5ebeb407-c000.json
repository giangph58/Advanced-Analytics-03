{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02386v1\", \"title\": \"VoiceCraft-Dub: Automated Video Dubbing with Neural Codec Language\\n  Models\", \"summary\": \"We present VoiceCraft-Dub, a novel approach for automated video dubbing that\\nsynthesizes high-quality speech from text and facial cues. This task has broad\\napplications in filmmaking, multimedia creation, and assisting voice-impaired\\nindividuals. Building on the success of Neural Codec Language Models (NCLMs)\\nfor speech synthesis, our method extends their capabilities by incorporating\\nvideo features, ensuring that synthesized speech is time-synchronized and\\nexpressively aligned with facial movements while preserving natural prosody. To\\ninject visual cues, we design adapters to align facial features with the NCLM\\ntoken space and introduce audio-visual fusion layers to merge audio-visual\\ninformation within the NCLM framework. Additionally, we curate CelebV-Dub, a\\nnew dataset of expressive, real-world videos specifically designed for\\nautomated video dubbing. Extensive experiments show that our model achieves\\nhigh-quality, intelligible, and natural speech synthesis with accurate lip\\nsynchronization, outperforming existing methods in human perception and\\nperforming favorably in objective evaluations. We also adapt VoiceCraft-Dub for\\nthe video-to-speech task, demonstrating its versatility for various\\napplications.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.AS\", \"published\": \"2025-04-03T08:24:47Z\"}"}
