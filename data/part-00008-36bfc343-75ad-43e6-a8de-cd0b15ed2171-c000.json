{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02662v1\", \"title\": \"Integrating Human Knowledge Through Action Masking in Reinforcement\\n  Learning for Operations Research\", \"summary\": \"Reinforcement learning (RL) provides a powerful method to address problems in\\noperations research. However, its real-world application often fails due to a\\nlack of user acceptance and trust. A possible remedy is to provide managers\\nwith the possibility of altering the RL policy by incorporating human expert\\nknowledge. In this study, we analyze the benefits and caveats of including\\nhuman knowledge via action masking. While action masking has so far been used\\nto exclude invalid actions, its ability to integrate human expertise remains\\nunderexplored. Human knowledge is often encapsulated in heuristics, which\\nsuggest reasonable, near-optimal actions in certain situations. Enforcing such\\nactions should hence increase trust among the human workforce to rely on the\\nmodel's decisions. Yet, a strict enforcement of heuristic actions may also\\nrestrict the policy from exploring superior actions, thereby leading to overall\\nlower performance. We analyze the effects of action masking based on three\\nproblems with different characteristics, namely, paint shop scheduling, peak\\nload management, and inventory management. Our findings demonstrate that\\nincorporating human knowledge through action masking can achieve substantial\\nimprovements over policies trained without action masking. In addition, we find\\nthat action masking is crucial for learning effective policies in constrained\\naction spaces, where certain actions can only be performed a limited number of\\ntimes. Finally, we highlight the potential for suboptimal outcomes when action\\nmasks are overly restrictive.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,math.OC\", \"published\": \"2025-04-03T15:00:04Z\"}"}
