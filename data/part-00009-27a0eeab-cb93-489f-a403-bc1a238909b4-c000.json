{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07749v1\", \"title\": \"NorEval: A Norwegian Language Understanding and Generation Evaluation\\n  Benchmark\", \"summary\": \"This paper introduces NorEval, a new and comprehensive evaluation suite for\\nlarge-scale standardized benchmarking of Norwegian generative language models\\n(LMs). NorEval consists of 24 high-quality human-created datasets -- of which\\nfive are created from scratch. In contrast to existing benchmarks for\\nNorwegian, NorEval covers a broad spectrum of task categories targeting\\nNorwegian language understanding and generation, establishes human baselines,\\nand focuses on both of the official written standards of the Norwegian\\nlanguage: Bokm{\\\\aa}l and Nynorsk. All our datasets and a collection of over 100\\nhuman-written prompts are integrated into LM Evaluation Harness, ensuring\\nflexible and reproducible evaluation. We describe the NorEval design and\\npresent the results of benchmarking 19 open-source pre-trained and\\ninstruction-tuned LMs for Norwegian in various scenarios. Our benchmark,\\nevaluation framework, and annotation materials are publicly available.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-10T13:44:55Z\"}"}
