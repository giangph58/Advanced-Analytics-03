{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07954v1\", \"title\": \"Perception-R1: Pioneering Perception Policy with Reinforcement Learning\", \"summary\": \"Inspired by the success of DeepSeek-R1, we explore the potential of\\nrule-based reinforcement learning (RL) in MLLM post-training for perception\\npolicy learning. While promising, our initial experiments reveal that\\nincorporating a thinking process through RL does not consistently lead to\\nperformance gains across all visual perception tasks. This leads us to delve\\ninto the essential role of RL in the context of visual perception. In this\\nwork, we return to the fundamentals and explore the effects of RL on different\\nperception tasks. We observe that the perceptual complexity is a major factor\\nin determining the effectiveness of RL. We also observe that reward design\\nplays a crucial role in further approching the upper limit of model perception.\\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\\na strong baseline for perception policy learning.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL\", \"published\": \"2025-04-10T17:58:27Z\"}"}
