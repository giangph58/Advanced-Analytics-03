{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01449v1\", \"title\": \"Multimodal Point Cloud Semantic Segmentation With Virtual Point\\n  Enhancement\", \"summary\": \"LiDAR-based 3D point cloud recognition has been proven beneficial in various\\napplications. However, the sparsity and varying density pose a significant\\nchallenge in capturing intricate details of objects, particularly for\\nmedium-range and small targets. Therefore, we propose a multi-modal point cloud\\nsemantic segmentation method based on Virtual Point Enhancement (VPE), which\\nintegrates virtual points generated from images to address these issues. These\\nvirtual points are dense but noisy, and directly incorporating them can\\nincrease computational burden and degrade performance. Therefore, we introduce\\na spatial difference-driven adaptive filtering module that selectively extracts\\nvaluable pseudo points from these virtual points based on density and distance,\\nenhancing the density of medium-range targets. Subsequently, we propose a\\nnoise-robust sparse feature encoder that incorporates noise-robust feature\\nextraction and fine-grained feature enhancement. Noise-robust feature\\nextraction exploits the 2D image space to reduce the impact of noisy points,\\nwhile fine-grained feature enhancement boosts sparse geometric features through\\ninner-voxel neighborhood point aggregation and downsampled voxel aggregation.\\nThe results on the SemanticKITTI and nuScenes, two large-scale benchmark data\\nsets, have validated effectiveness, significantly improving 2.89\\\\% mIoU with\\nthe introduction of 7.7\\\\% virtual points on nuScenes.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T08:02:06Z\"}"}
