{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24320v1\", \"title\": \"Can Test-Time Scaling Improve World Foundation Model?\", \"summary\": \"World foundation models, which simulate the physical world by predicting\\nfuture states from current observations and inputs, have become central to many\\napplications in physical intelligence, including autonomous driving and\\nrobotics. However, these models require substantial computational resources for\\npretraining and are further constrained by available data during post-training.\\nAs such, scaling computation at test time emerges as both a critical and\\npractical alternative to traditional model enlargement or re-training. In this\\nwork, we introduce SWIFT, a test-time scaling framework tailored for WFMs.\\nSWIFT integrates our extensible WFM evaluation toolkit with process-level\\ninference strategies, including fast tokenization, probability-based Top-K\\npruning, and efficient beam search. Empirical results on the COSMOS model\\ndemonstrate that test-time scaling exists even in a compute-optimal way. Our\\nfindings reveal that test-time scaling laws hold for WFMs and that SWIFT\\nprovides a scalable and effective pathway for improving WFM inference without\\nretraining or increasing model size. The code is available at\\nhttps://github.com/Mia-Cong/SWIFT.git.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T17:07:37Z\"}"}
