{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07567v1\", \"title\": \"Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf\\n  Foundation Models, Fine-Tuning Strategies and Practical Trade-offs\", \"summary\": \"We benchmark foundation models image embeddings for classification and\\nretrieval in e-Commerce, evaluating their suitability for real-world\\napplications. Our study spans embeddings from pre-trained convolutional and\\ntransformer models trained via supervised, self-supervised, and text-image\\ncontrastive learning. We assess full fine-tuning and transfer learning\\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\\nfood, and retail. Results show full fine-tuning consistently performs well,\\nwhile text-image and self-supervised embeddings can match its performance with\\nless training. While supervised embeddings remain stable across architectures,\\nSSL and contrastive embeddings vary significantly, often benefiting from\\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\\nreducing computational costs. We also explore cross-tuning, noting its impact\\ndepends on dataset characteristics. Our findings offer practical guidelines for\\nembedding selection and fine-tuning strategies, balancing efficiency and\\nperformance.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CE,cs.IR,cs.LG\", \"published\": \"2025-04-10T08:57:28Z\"}"}
