{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23796v1\", \"title\": \"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\\n  Generation for Mobile Devices\", \"summary\": \"We present On-device Sora, the first model training-free solution for\\ndiffusion-based on-device text-to-video generation that operates efficiently on\\nsmartphone-grade devices. To address the challenges of diffusion-based\\ntext-to-video generation on computation- and memory-limited mobile devices, the\\nproposed On-device Sora applies three novel techniques to pre-trained video\\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\\ndenoising steps required in video diffusion through an efficient leap-based\\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\\ntoken-processing computation in attention layers by merging consecutive tokens\\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\\ninto memory for concurrent model inference, effectively addressing the\\nchallenges of limited device memory. We implement On-device Sora on the iPhone\\n15 Pro, and the experimental evaluations show that it is capable of generating\\nhigh-quality videos on the device, comparable to those produced by high-end\\nGPUs. These results show that On-device Sora enables efficient and high-quality\\nvideo generation on resource-constrained mobile devices. We envision the\\nproposed On-device Sora as a significant first step toward democratizing\\nstate-of-the-art generative technologies, enabling video generation on\\ncommodity mobile and embedded devices without resource-intensive re-training\\nfor model optimization (compression). The code implementation is available at a\\nGitHub repository(https://github.com/eai-lab/On-device-Sora).\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T07:19:09Z\"}"}
