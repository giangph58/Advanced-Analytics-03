{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05007v1\", \"title\": \"Measuring the right thing: justifying metrics in AI impact assessments\", \"summary\": \"AI Impact Assessments are only as good as the measures used to assess the\\nimpact of these systems. It is therefore paramount that we can justify our\\nchoice of metrics in these assessments, especially for difficult to quantify\\nethical and social values. We present a two-step approach to ensure metrics are\\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\\nfairness or fairness as solidarity) and then a metric can be fitted to that\\nconception. Both steps require separate justifications, as conceptions can be\\njudged on how well they fit with the function of, for example, fairness. We\\nargue that conceptual engineering offers helpful tools for this step. Second,\\nmetrics need to be fitted to a conception. We illustrate this process through\\nan examination of competing fairness metrics to illustrate that here the\\nadditional content that a conception offers helps us justify the choice for a\\nspecific metric. We thus advocate that impact assessments are not only clear on\\ntheir metrics, but also on the conceptions that motivate those metrics.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY,cs.AI,cs.ET\", \"published\": \"2025-04-07T12:32:41Z\"}"}
