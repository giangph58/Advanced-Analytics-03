{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06683v1\", \"title\": \"Hyperparameter Optimisation with Practical Interpretability and\\n  Explanation Methods in Probabilistic Curriculum Learning\", \"summary\": \"Hyperparameter optimisation (HPO) is crucial for achieving strong performance\\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\\ncurriculum learning strategy designed to improve RL performance by structuring\\nthe agent's learning process, yet effective hyperparameter tuning remains\\nchallenging and computationally demanding. In this paper, we provide an\\nempirical analysis of hyperparameter interactions and their effects on the\\nperformance of a PCL algorithm within standard RL tasks, including point-maze\\nnavigation and DC motor control. Using the AlgOS framework integrated with\\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\\nAdditionally, we introduce a novel SHAP-based interpretability approach\\ntailored specifically for analysing hyperparameter impacts, offering clear\\ninsights into how individual hyperparameters and their interactions influence\\nRL performance. Our work contributes practical guidelines and interpretability\\ntools that significantly improve the effectiveness and computational\\nfeasibility of hyperparameter optimisation in reinforcement learning.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-09T08:41:27Z\"}"}
