{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07001v1\", \"title\": \"Leveraging GCN-based Action Recognition for Teleoperation in Daily\\n  Activity Assistance\", \"summary\": \"Caregiving of older adults is an urgent global challenge, with many older\\nadults preferring to age in place rather than enter residential care. However,\\nproviding adequate home-based assistance remains difficult, particularly in\\ngeographically vast regions. Teleoperated robots offer a promising solution,\\nbut conventional motion-mapping teleoperation imposes unnatural movement\\nconstraints on operators, leading to muscle fatigue and reduced usability. This\\npaper presents a novel teleoperation framework that leverages action\\nrecognition to enable intuitive remote robot control. Using our simplified\\nSpatio-Temporal Graph Convolutional Network (S-ST-GCN), the system recognizes\\nhuman actions and executes corresponding preset robot trajectories, eliminating\\nthe need for direct motion synchronization. A finite-state machine (FSM) is\\nintegrated to enhance reliability by filtering out misclassified actions. Our\\nexperiments demonstrate that the proposed framework enables effortless operator\\nmovement while ensuring accurate robot execution. This proof-of-concept study\\nhighlights the potential of teleoperation with action recognition for enabling\\ncaregivers to remotely assist older adults during activities of daily living\\n(ADLs). Future work will focus on improving the S-ST-GCN's recognition accuracy\\nand generalization, integrating advanced motion planning techniques to further\\nenhance robotic autonomy in older adult care, and conducting a user study to\\nevaluate the system's telepresence and ease of control.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.HC\", \"published\": \"2025-04-09T16:14:55Z\"}"}
