{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04798v1\", \"title\": \"TabRep: Training Tabular Diffusion Models with a Simple and Effective\\n  Continuous Representation\", \"summary\": \"Diffusion models have been the predominant generative model for tabular data\\ngeneration. However, they face the conundrum of modeling under a separate\\nversus a unified data representation. The former encounters the challenge of\\njointly modeling all multi-modal distributions of tabular data in one model.\\nWhile the latter alleviates this by learning a single representation for all\\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\\nnecessitates additional computation costs. In this work, we address the latter\\nby presenting TabRep, a tabular diffusion architecture trained with a unified\\ncontinuous representation. To motivate the design of our representation, we\\nprovide geometric insights into how the data manifold affects diffusion models.\\nThe key attributes of our representation are composed of its density,\\nflexibility to provide ample separability for nominal features, and ability to\\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\\neffective approach for training tabular diffusion models under a continuous\\ndata manifold. Our results showcase that TabRep achieves superior performance\\nacross a broad suite of evaluations. It is the first to synthesize tabular data\\nthat exceeds the downstream quality of the original datasets while preserving\\nprivacy and remaining computationally efficient.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-07T07:44:27Z\"}"}
