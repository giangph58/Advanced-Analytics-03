{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23721v1\", \"title\": \"Unimodal-driven Distillation in Multimodal Emotion Recognition with\\n  Dynamic Fusion\", \"summary\": \"Multimodal Emotion Recognition in Conversations (MERC) identifies emotional\\nstates across text, audio and video, which is essential for intelligent\\ndialogue systems and opinion analysis. Existing methods emphasize heterogeneous\\nmodal fusion directly for cross-modal integration, but often suffer from\\ndisorientation in multimodal learning due to modal heterogeneity and lack of\\ninstructive guidance. In this work, we propose SUMMER, a novel heterogeneous\\nmultimodal integration framework leveraging Mixture of Experts with\\nHierarchical Cross-modal Fusion and Interactive Knowledge Distillation. Key\\ncomponents include a Sparse Dynamic Mixture of Experts (SDMoE) for capturing\\ndynamic token-wise interactions, a Hierarchical Cross-Modal Fusion (HCMF) for\\neffective fusion of heterogeneous modalities, and Interactive Knowledge\\nDistillation (IKD), which uses a pre-trained unimodal teacher to guide\\nmultimodal fusion in latent and logit spaces. Experiments on IEMOCAP and MELD\\nshow SUMMER outperforms state-of-the-art methods, particularly in recognizing\\nminority and semantically similar emotions.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-03-31T04:43:10Z\"}"}
