{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01933v1\", \"title\": \"Hessian-aware Training for Enhancing DNNs Resilience to Parameter\\n  Corruptions\", \"summary\": \"Deep neural networks are not resilient to parameter corruptions: even a\\nsingle-bitwise error in their parameters in memory can cause an accuracy drop\\nof over 10%, and in the worst cases, up to 99%. This susceptibility poses great\\nchallenges in deploying models on computing platforms, where adversaries can\\ninduce bit-flips through software or bitwise corruptions may occur naturally.\\nMost prior work addresses this issue with hardware or system-level approaches,\\nsuch as integrating additional hardware components to verify a model's\\nintegrity at inference. However, these methods have not been widely deployed as\\nthey require infrastructure or platform-wide modifications.\\n  In this paper, we propose a new approach to addressing this issue: training\\nmodels to be more resilient to bitwise corruptions to their parameters. Our\\napproach, Hessian-aware training, promotes models with $flatter$ loss surfaces.\\nWe show that, while there have been training methods, designed to improve\\ngeneralization through Hessian-based approaches, they do not enhance resilience\\nto parameter corruptions. In contrast, models trained with our method\\ndemonstrate increased resilience to parameter corruptions, particularly with a\\n20$-$50% reduction in the number of bits whose individual flipping leads to a\\n90$-$100% accuracy drop. Moreover, we show the synergy between ours and\\nexisting hardware and system-level defenses.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.LG\", \"published\": \"2025-04-02T17:42:31Z\"}"}
