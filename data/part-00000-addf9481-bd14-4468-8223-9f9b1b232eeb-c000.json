{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24387v1\", \"title\": \"Consistent Subject Generation via Contrastive Instantiated Concepts\", \"summary\": \"While text-to-image generative models can synthesize diverse and faithful\\ncontents, subject variation across multiple creations limits the application in\\nlong content generation. Existing approaches require time-consuming tuning,\\nreferences for all subjects, or access to other creations. We introduce\\nContrastive Concept Instantiation (CoCoIns) to effectively synthesize\\nconsistent subjects across multiple independent creations. The framework\\nconsists of a generative model and a mapping network, which transforms input\\nlatent codes into pseudo-words associated with certain instances of concepts.\\nUsers can generate consistent subjects with the same latent codes. To construct\\nsuch associations, we propose a contrastive learning approach that trains the\\nnetwork to differentiate the combination of prompts and latent codes. Extensive\\nevaluations of human faces with a single subject show that CoCoIns performs\\ncomparably to existing methods while maintaining higher flexibility. We also\\ndemonstrate the potential of extending CoCoIns to multiple subjects and other\\nobject categories.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T17:59:51Z\"}"}
