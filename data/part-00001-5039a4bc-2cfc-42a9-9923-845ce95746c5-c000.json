{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23806v1\", \"title\": \"Bridge the Gap Between Visual and Linguistic Comprehension for\\n  Generalized Zero-shot Semantic Segmentation\", \"summary\": \"Generalized zero-shot semantic segmentation (GZS3) aims to achieve the\\nhuman-level capability of segmenting not only seen classes but also novel class\\nregions unseen in the training data through introducing the bridge of semantic\\nrepresentations, e.g., word vector. While effective, the way of utilizing one\\nsemantic representation to associate the corresponding class and to enable the\\nknowledge transfer from seen to unseen classes is insufficient as well as\\nincompatible with human cognition. Inspired by the observation that humans\\noften use some `part' and `state' information to comprehend the seen objects\\nand imagine unseen classes, we decouple each class into detailed descriptions,\\nincluding object parts and states. Based on the decoupling formulation, we\\npropose a Decoupled Vision-Language Matching (DeVLMatch) framework, composed of\\nspatial-part (SPMatch) and channel-state (CSMatch) matching modules, for GZS3.\\nIn SPMatch, we comprehend objects with spatial part information from both\\nvisual and linguistic perspectives and perform graph matching to bridge the\\ngap. In CSMatch, states of objects from the linguistic perspective are matched\\nto compatible channel information from the visual perspective. By decoupling\\nand matching objects across visual and linguistic comprehension, we can\\nexplicitly introspect the relationship between seen and unseen classes in\\nfine-grained object part and state levels, thereby facilitating the knowledge\\ntransfer from seen to unseen classes in visual space. The proposed DeVLMatch\\nframework surpasses the previous GZS3 methods on standard benchmarks, including\\nPASCAL VOC, COCO-Stuff, and CATARACTS, demonstrating its effectiveness.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T07:39:14Z\"}"}
