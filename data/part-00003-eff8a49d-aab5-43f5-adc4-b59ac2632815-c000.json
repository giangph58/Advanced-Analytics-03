{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23803v1\", \"title\": \"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\\n  Scaling Test-Time Compute\", \"summary\": \"Recent advancements in software engineering agents have demonstrated\\npromising capabilities in automating program improvements. However, their\\nreliance on closed-source or resource-intensive models introduces significant\\ndeployment challenges in private environments, prompting a critical question:\\n\\\\textit{How can personally deployable open-source LLMs achieve comparable code\\nreasoning performance?}\\n  To this end, we propose a unified Test-Time Compute scaling framework that\\nleverages increased inference-time computation instead of larger models. Our\\nframework incorporates two complementary strategies: internal TTC and external\\nTTC. Internally, we introduce a \\\\textit{development-contextualized trajectory\\nsynthesis} method leveraging real-world software repositories to bootstrap\\nmulti-stage reasoning processes, such as fault localization and patch\\ngeneration. We further enhance trajectory quality through rejection sampling,\\nrigorously evaluating trajectories along accuracy and complexity. Externally,\\nwe propose a novel \\\\textit{development-process-based search} strategy guided by\\nreward models and execution verification. This approach enables targeted\\ncomputational allocation at critical development decision points, overcoming\\nlimitations of existing \\\"end-point only\\\" verification methods.\\n  Evaluations on SWE-bench Verified demonstrate our \\\\textbf{32B model achieves\\na 46\\\\% issue resolution rate}, surpassing significantly larger models such as\\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\\nthat \\\\textbf{models dynamically allocate more tokens to increasingly\\nchallenging problems}, effectively enhancing reasoning capabilities. We\\npublicly release all training data, models, and code to facilitate future\\nresearch. https://github.com/yingweima2022/SWE-Reasoner\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.AI\", \"published\": \"2025-03-31T07:31:32Z\"}"}
