{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01349v1\", \"title\": \"Tasks and Roles in Legal AI: Data Curation, Annotation, and Verification\", \"summary\": \"The application of AI tools to the legal field feels natural: large legal\\ndocument collections could be used with specialized AI to improve workflow\\nefficiency for lawyers and ameliorate the \\\"justice gap\\\" for underserved\\nclients. However, legal documents differ from the web-based text that underlies\\nmost AI systems. The challenges of legal AI are both specific to the legal\\ndomain, and confounded with the expectation of AI's high performance in\\nhigh-stakes settings. We identify three areas of special relevance to\\npractitioners: data curation, data annotation, and output verification. First,\\nit is difficult to obtain usable legal texts. Legal collections are\\ninconsistent, analog, and scattered for reasons technical, economic, and\\njurisdictional. AI tools can assist document curation efforts, but the lack of\\nexisting data also limits AI performance. Second, legal data annotation\\ntypically requires significant expertise to identify complex phenomena such as\\nmodes of judicial reasoning or controlling precedents. We describe case studies\\nof AI systems that have been developed to improve the efficiency of human\\nannotation in legal contexts and identify areas of underperformance. Finally,\\nAI-supported work in the law is valuable only if results are verifiable and\\ntrustworthy. We describe both the abilities of AI systems to support evaluation\\nof their outputs, as well as new approaches to systematic evaluation of\\ncomputational systems in complex domains. We call on both legal and AI\\npractitioners to collaborate across disciplines and to release open access\\nmaterials to support the development of novel, high-performing, and reliable AI\\ntools for legal applications.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-02T04:34:58Z\"}"}
