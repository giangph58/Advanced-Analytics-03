{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01324v1\", \"title\": \"On Data Synthesis and Post-training for Visual Abstract Reasoning\", \"summary\": \"This paper is a pioneering work attempting to address abstract visual\\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\\ngreat breakthrough since almost all previous VLMs fail or show nearly random\\nperformance on representative AVR benchmarks. Our key success is our innovative\\ndata synthesis and post-training process, aiming to fully relieve the task\\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\\nshown to be behave well on AVR without sacrificing common multimodal\\ncomprehension abilities. We hope our paper could serve as an early effort in\\nthis area and would inspire further research in abstract visual reasoning.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL\", \"published\": \"2025-04-02T03:18:24Z\"}"}
