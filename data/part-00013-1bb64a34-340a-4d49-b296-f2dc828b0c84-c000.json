{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02438v1\", \"title\": \"Scaling Video-Language Models to 10K Frames via Hierarchical\\n  Differential Distillation\", \"summary\": \"Long-form video processing fundamentally challenges vision-language models\\n(VLMs) due to the high computational costs of handling extended temporal\\nsequences. Existing token pruning and feature merging methods often sacrifice\\ncritical temporal dependencies or dilute semantic information. We introduce\\ndifferential distillation, a principled approach that systematically preserves\\ntask-relevant information while suppressing redundancy. Based on this\\nprinciple, we develop ViLaMP, a hierarchical video-language model that\\nprocesses hour-long videos at ``mixed precision'' through two key mechanisms:\\n(1) differential keyframe selection that maximizes query relevance while\\nmaintaining temporal distinctiveness at the frame level and (2) differential\\nfeature merging that preserves query-salient features in non-keyframes at the\\npatch level. Hence, ViLaMP retains full information in keyframes while reducing\\nnon-keyframes to their most salient features, resembling mixed-precision\\ntraining. Extensive experiments demonstrate ViLaMP's superior performance\\nacross four video understanding benchmarks, particularly on long-form content.\\nNotably, ViLaMP can process ultra-long videos (up to 10K frames) on a single\\nNVIDIA A100 GPU, achieving substantial computational efficiency while\\nmaintaining state-of-the-art performance.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-03T09:55:09Z\"}"}
