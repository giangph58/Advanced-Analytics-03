{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05786v1\", \"title\": \"How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM\", \"summary\": \"3D spatial understanding is essential in real-world applications such as\\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\\nLarge Language Models (LLMs), having demonstrated remarkable success across\\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\\npotential to surpass traditional computer vision methods. In this survey, we\\npresent a comprehensive review of methods integrating LLMs with 3D spatial\\nunderstanding. We propose a taxonomy that categorizes existing methods into\\nthree branches: image-based methods deriving 3D understanding from 2D visual\\ndata, point cloud-based methods working directly with 3D representations, and\\nhybrid modality-based methods combining multiple data streams. We\\nsystematically review representative methods along these categories, covering\\ndata representations, architectural modifications, and training strategies that\\nbridge textual and 3D modalities. Finally, we discuss current limitations,\\nincluding dataset scarcity and computational challenges, while highlighting\\npromising research directions in spatial perception, multi-modal fusion, and\\nreal-world applications.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-08T08:11:39Z\"}"}
