{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01947v1\", \"title\": \"Efficient Federated Learning Tiny Language Models for Mobile Network\\n  Feature Prediction\", \"summary\": \"In telecommunications, Autonomous Networks (ANs) automatically adjust\\nconfigurations based on specific requirements (e.g., bandwidth) and available\\nresources. These networks rely on continuous monitoring and intelligent\\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\\nequipped with NNs - to collaboratively train models while preserving data\\nprivacy. However, FL requires frequent transmission of large neural data and\\nthus an efficient, standardized compression strategy for reliable\\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\\nnovel FL framework that integrates tiny language models (TLMs) for various\\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\\nachieves transparent compression (i.e., negligible performance loss) while\\nreducing communication overhead to below 1%, showing the effectiveness of\\ncombining NNC with FL in collaboratively learned autonomous mobile networks.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.DC,eess.SP\", \"published\": \"2025-04-02T17:54:06Z\"}"}
