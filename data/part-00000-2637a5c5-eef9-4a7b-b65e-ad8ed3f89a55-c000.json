{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01943v1\", \"title\": \"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding\", \"summary\": \"Since the advent of reasoning-based large language models, many have found\\ngreat success from distilling reasoning capabilities into student models. Such\\ntechniques have significantly bridged the gap between reasoning and standard\\nLLMs on coding tasks. Despite this, much of the progress on distilling\\nreasoning models remains locked behind proprietary datasets or lacks details on\\ndata curation, filtering and subsequent training. To address this, we construct\\na superior supervised fine-tuning (SFT) dataset that we use to achieve\\nstate-of-the-art coding capability results in models of various sizes. Our\\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\\nCodeContests, surpassing alternatives trained with reinforcement learning. We\\nthen perform analysis on the data sources used to construct our dataset, the\\nimpact of code execution filtering, and the importance of instruction/solution\\ndiversity. We observe that execution filtering negatively affected benchmark\\naccuracy, leading us to prioritize instruction diversity over solution\\ncorrectness. Finally, we also analyze the token efficiency and reasoning\\npatterns utilized by these models. We will open-source these datasets and\\ndistilled models to the community.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-02T17:50:31Z\"}"}
