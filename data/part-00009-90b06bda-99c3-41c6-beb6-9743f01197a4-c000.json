{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06958v1\", \"title\": \"VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement\\n  Fine-Tuning\", \"summary\": \"Recent advancements in reinforcement learning have significantly advanced the\\nreasoning capabilities of multimodal large language models (MLLMs). While\\napproaches such as Group Relative Policy Optimization (GRPO) and rule-based\\nreward mechanisms demonstrate promise in text and image domains, their\\napplication to video understanding remains limited. This paper presents a\\nsystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for video\\nMLLMs, aiming to enhance spatio-temporal perception while maintaining general\\ncapabilities. Our experiments reveal that RFT is highly data-efficient for\\ntask-specific improvements. Through multi-task RFT on spatio-temporal\\nperception objectives with limited samples, we develop VideoChat-R1, a powerful\\nvideo MLLM that achieves state-of-the-art performance on spatio-temporal\\nperception tasks without sacrificing chat ability, while exhibiting emerging\\nspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1\\nboosts performance several-fold in tasks like temporal grounding (+31.8) and\\nobject tracking (+31.2). Additionally, it significantly improves on general QA\\nbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).\\nOur findings underscore the potential of RFT for specialized task enhancement\\nof Video MLLMs. We hope our work offers valuable insights for future RL\\nresearch in video MLLMs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T15:09:27Z\"}"}
