{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05642v1\", \"title\": \"Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using\\n  Large Language Models\", \"summary\": \"We propose a novel three-step prompt-tuning method for Bengali Grammatical\\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\\nidentifying and categorizing grammatical errors in Bengali sentences,\\ngenerating corrected versions of the sentences, and providing natural language\\nexplanations for each identified error. We evaluate the performance of our BGEE\\nsystem using both automated evaluation metrics and human evaluation conducted\\nby experienced Bengali language experts. Our proposed prompt-tuning approach\\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\\nimprovement in exact match. Furthermore, compared to the previous baseline,\\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\\n26.27% in wrong error explanation. However, the results still lag behind the\\nhuman baseline.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-08T03:38:01Z\"}"}
