{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04903v1\", \"title\": \"Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level\\n  Vision\", \"summary\": \"We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\\nacross four major categories: image restoration, image enhancement,\\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\\nand visual prompts to offer flexible and user-friendly interactions. Built on\\nDiffusion Transformer (DiT)-based generative priors, our framework supports\\narbitrary resolutions -- achieving optimal performance at 1K resolution --\\nwhile preserving fine-grained details and high fidelity. Through extensive\\nexperiments, we demonstrate that separately encoding text and visual\\ninstructions, combined with co-training using shallow feature control, is\\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\\nfindings also reveal that integrating high-level generative tasks into\\nlow-level vision models can compromise detail-sensitive restoration. These\\ninsights pave the way for more robust and generalizable low-level vision\\nsystems.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T10:22:00Z\"}"}
