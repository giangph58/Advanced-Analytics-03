{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11825v1\", \"title\": \"TextDiffSeg: Text-guided Latent Diffusion Model for 3d Medical Images\\n  Segmentation\", \"summary\": \"Diffusion Probabilistic Models (DPMs) have demonstrated significant potential\\nin 3D medical image segmentation tasks. However, their high computational cost\\nand inability to fully capture global 3D contextual information limit their\\npractical applications. To address these challenges, we propose a novel\\ntext-guided diffusion model framework, TextDiffSeg. This method leverages a\\nconditional diffusion framework that integrates 3D volumetric data with natural\\nlanguage descriptions, enabling cross-modal embedding and establishing a shared\\nsemantic space between visual and textual modalities. By enhancing the model's\\nability to recognize complex anatomical structures, TextDiffSeg incorporates\\ninnovative label embedding techniques and cross-modal attention mechanisms,\\neffectively reducing computational complexity while preserving global 3D\\ncontextual integrity. Experimental results demonstrate that TextDiffSeg\\nconsistently outperforms existing methods in segmentation tasks involving\\nkidney and pancreas tumors, as well as multi-organ segmentation scenarios.\\nAblation studies further validate the effectiveness of key components,\\nhighlighting the synergistic interaction between text fusion, image feature\\nextractor, and label encoder. TextDiffSeg provides an efficient and accurate\\nsolution for 3D medical image segmentation, showcasing its broad applicability\\nin clinical diagnosis and treatment planning.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-16T07:17:36Z\"}"}
