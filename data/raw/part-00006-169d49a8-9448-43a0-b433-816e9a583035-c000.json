{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10972v1\", \"title\": \"AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained\\n  Representation in Radiographic Images\", \"summary\": \"Current self-supervised methods, such as contrastive learning, predominantly\\nfocus on global discrimination, neglecting the critical fine-grained anatomical\\ndetails required for accurate radiographic analysis. To address this challenge,\\nwe propose an Anatomy-driven self-supervised framework for enhancing\\nFine-grained Representation in radiographic image analysis (AFiRe). The core\\nidea of AFiRe is to align the anatomical consistency with the unique\\ntoken-processing characteristics of Vision Transformer. Specifically, AFiRe\\nsynergistically performs two self-supervised schemes: (i) Token-wise\\nanatomy-guided contrastive learning, which aligns image tokens based on\\nstructural and categorical consistency, thereby enhancing fine-grained\\nspatial-anatomical discrimination; (ii) Pixel-level anomaly-removal\\nrestoration, which particularly focuses on local anomalies, thereby refining\\nthe learned discrimination with detailed geometrical information. Additionally,\\nwe propose Synthetic Lesion Mask to enhance anatomical diversity while\\npreserving intra-consistency, which is typically corrupted by traditional data\\naugmentations, such as Cropping and Affine transformations. Experimental\\nresults show that AFiRe: (i) provides robust anatomical discrimination,\\nachieving more cohesive feature clusters compared to state-of-the-art\\ncontrastive learning methods; (ii) demonstrates superior generalization,\\nsurpassing 7 radiography-specific self-supervised methods in multi-label\\nclassification tasks with limited labeling; and (iii) integrates fine-grained\\ninformation, enabling precise anomaly detection using only image-level\\nannotations.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T08:29:54Z\"}"}
