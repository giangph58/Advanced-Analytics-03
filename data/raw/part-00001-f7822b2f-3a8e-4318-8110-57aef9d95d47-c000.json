{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12867v1\", \"title\": \"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\\n  Prompting\", \"summary\": \"Human speech goes beyond the mere transfer of information; it is a profound\\nexchange of emotions and a connection between individuals. While Text-to-Speech\\n(TTS) models have made huge progress, they still face challenges in controlling\\nthe emotional expression in the generated speech. In this work, we propose\\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\\ncontrol, and a phoneme boost variant design that makes the model output phoneme\\ntokens and audio tokens in parallel to enhance content consistency, inspired by\\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\\nexpressive speech and fine-grained emotion labels with natural language\\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\\nSecap test set using our in-house data. We further investigate the reliability\\nof existing emotion evaluation metrics and their alignment with human\\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\\nGemini to assess emotional speech. Demo samples are available at\\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\\nwill be released.\", \"main_category\": \"eess.AS\", \"categories\": \"eess.AS,cs.AI,cs.CL\", \"published\": \"2025-04-17T11:50:04Z\"}"}
