{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11844v1\", \"title\": \"Evaluating the Goal-Directedness of Large Language Models\", \"summary\": \"To what extent do LLMs use their capabilities towards their given goal? We\\ntake this as a measure of their goal-directedness. We evaluate\\ngoal-directedness on tasks that require information gathering, cognitive\\neffort, and plan execution, where we use subtasks to infer each model's\\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\\nand Anthropic show that goal-directedness is relatively consistent across\\ntasks, differs from task performance, and is only moderately sensitive to\\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\\nour goal-directedness evaluations will enable better monitoring of LLM\\nprogress, and enable more deliberate design choices of agentic properties in\\nLLMs.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL,cs.LG\", \"published\": \"2025-04-16T08:07:08Z\"}"}
