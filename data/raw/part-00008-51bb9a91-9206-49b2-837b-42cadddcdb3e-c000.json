{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16082v1\", \"title\": \"MR. Video: \\\"MapReduce\\\" is the Principle for Long Video Understanding\", \"summary\": \"We propose MR. Video, an agentic long video understanding framework that\\ndemonstrates the simple yet effective MapReduce principle for processing long\\nvideos: (1) Map: independently and densely perceiving short video clips, and\\n(2) Reduce: jointly aggregating information from all clips. Compared with\\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\\nshort video perception without being limited by context length. Compared with\\nexisting video agents that typically rely on sequential key segment selection,\\nthe Map operation enables simpler and more scalable sequence parallel\\nperception of short video segments. Its Reduce step allows for more\\ncomprehensive context aggregation and reasoning, surpassing explicit key\\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\\nvideo agents, and we use LLM agents to validate its effectiveness.\\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\\ngenerating captions for short video clips (map), then standardizing repeated\\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\\nquestion, analyzing relevant information from individual short videos (map),\\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\\naccuracy improvement on the challenging LVBench compared to state-of-the-art\\nVLMs and video agents.\\n  Code is available at: https://github.com/ziqipang/MR-Video\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-22T17:59:41Z\"}"}
