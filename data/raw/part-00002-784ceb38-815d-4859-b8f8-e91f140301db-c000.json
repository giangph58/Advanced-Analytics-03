{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10852v1\", \"title\": \"Enhancing Features in Long-tailed Data Using Large Vision Mode\", \"summary\": \"Language-based foundation models, such as large language models (LLMs) or\\nlarge vision-language models (LVLMs), have been widely studied in long-tailed\\nrecognition. However, the need for linguistic data is not applicable to all\\npractical tasks. In this study, we aim to explore using large vision models\\n(LVMs) or visual foundation models (VFMs) to enhance long-tailed data features\\nwithout any language information. Specifically, we extract features from the\\nLVM and fuse them with features in the baseline network's map and latent space\\nto obtain the augmented features. Moreover, we design several prototype-based\\nlosses in the latent space to further exploit the potential of the augmented\\nfeatures. In the experimental section, we validate our approach on two\\nbenchmark datasets: ImageNet-LT and iNaturalist2018.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T04:21:50Z\"}"}
