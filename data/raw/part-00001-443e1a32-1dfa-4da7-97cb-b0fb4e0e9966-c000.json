{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19888v1\", \"title\": \"Enhancing breast cancer detection on screening mammogram using\\n  self-supervised learning and a hybrid deep model of Swin Transformer and\\n  Convolutional Neural Network\", \"summary\": \"Purpose: The scarcity of high-quality curated labeled medical training data\\nremains one of the major limitations in applying artificial intelligence (AI)\\nsystems to breast cancer diagnosis. Deep models for mammogram analysis and mass\\n(or micro-calcification) detection require training with a large volume of\\nlabeled images, which are often expensive and time-consuming to collect. To\\nreduce this challenge, we proposed a novel method that leverages\\nself-supervised learning (SSL) and a deep hybrid model, named \\\\textbf{HybMNet},\\nwhich combines local self-attention and fine-grained feature extraction to\\nenhance breast cancer detection on screening mammograms.\\n  Approach: Our method employs a two-stage learning process: (1) SSL\\nPretraining: We utilize EsViT, a SSL technique, to pretrain a Swin Transformer\\n(Swin-T) using a limited set of mammograms. The pretrained Swin-T then serves\\nas the backbone for the downstream task. (2) Downstream Training: The proposed\\nHybMNet combines the Swin-T backbone with a CNN-based network and a novel\\nfusion strategy. The Swin-T employs local self-attention to identify\\ninformative patch regions from the high-resolution mammogram, while the\\nCNN-based network extracts fine-grained local features from the selected\\npatches. A fusion module then integrates global and local information from both\\nnetworks to generate robust predictions. The HybMNet is trained end-to-end,\\nwith the loss function combining the outputs of the Swin-T and CNN modules to\\noptimize feature extraction and classification performance.\\n  Results: The proposed method was evaluated for its ability to detect breast\\ncancer by distinguishing between benign (normal) and malignant mammograms.\\nLeveraging SSL pretraining and the HybMNet model, it achieved AUC of 0.864 (95%\\nCI: 0.852, 0.875) on the CMMD dataset and 0.889 (95% CI: 0.875, 0.903) on the\\nINbreast dataset, highlighting its effectiveness.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T15:23:28Z\"}"}
