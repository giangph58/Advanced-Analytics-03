{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10107v1\", \"title\": \"Enhancing LLM-based Recommendation through Semantic-Aligned\\n  Collaborative Knowledge\", \"summary\": \"Large Language Models (LLMs) demonstrate remarkable capabilities in\\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\\nfor recommendation tasks. However, a notable limitation lies in their inability\\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\\nlearn distinctive user-item representations and creating a performance\\nbottleneck. Prior studies indicate that integrating collaborative knowledge\\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\\nrecommendation performance. Nevertheless, the significant discrepancy in\\nknowledge distribution and semantic space between LLMs and Collab. presents\\nsubstantial challenges for effective knowledge transfer. To tackle these\\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\\nfosters effective knowledge fusion, mitigating the influence of discriminative\\nnoise and facilitating the deep integration of knowledge from diverse models.\\nSpecifically, three special tokens with collaborative knowledge are embedded\\ninto the LLM's semantic space through a hybrid projection layer and integrated\\ninto task-specific prompts to guide the recommendation process. Experiments\\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-14T11:15:30Z\"}"}
