{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05101v1\", \"title\": \"MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via\\n  Diffusion Models\", \"summary\": \"Multi-object editing aims to modify multiple objects or regions in complex\\nscenes while preserving structural coherence. This task faces significant\\nchallenges in scenarios involving overlapping or interacting objects: (1)\\nInaccurate localization of target objects due to attention misalignment,\\nleading to incomplete or misplaced edits; (2) Attribute-object mismatch, where\\ncolor or texture changes fail to align with intended regions due to\\ncross-attention leakage, creating semantic conflicts (\\\\textit{e.g.}, color\\nbleeding into non-target areas). Existing methods struggle with these\\nchallenges: approaches relying on global cross-attention mechanisms suffer from\\nattention dilution and spatial interference between objects, while mask-based\\nmethods fail to bind attributes to geometrically accurate regions due to\\nfeature entanglement in multi-object scenarios. To address these limitations,\\nwe propose a training-free, inference-stage optimization approach that enables\\nprecise localized image manipulation in complex multi-object scenes, named\\nMDE-Edit. MDE-Edit optimizes the noise latent feature in diffusion models via\\ntwo key losses: Object Alignment Loss (OAL) aligns multi-layer cross-attention\\nwith segmentation masks for precise object positioning, and Color Consistency\\nLoss (CCL) amplifies target attribute attention within masks while suppressing\\nleakage to adjacent regions. This dual-loss design ensures localized and\\ncoherent multi-object edits. Extensive experiments demonstrate that MDE-Edit\\noutperforms state-of-the-art methods in editing accuracy and visual quality,\\noffering a robust solution for complex multi-object image manipulation tasks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T10:01:14Z\"}"}
