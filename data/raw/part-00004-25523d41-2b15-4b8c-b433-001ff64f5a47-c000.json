{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13167v1\", \"title\": \"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from\\n  Monocular Videos\", \"summary\": \"Creating a photorealistic scene and human reconstruction from a single\\nmonocular in-the-wild video figures prominently in the perception of a\\nhuman-centric 3D world. Recent neural rendering advances have enabled holistic\\nhuman-scene reconstruction but require pre-calibrated camera and human poses,\\nand days of training time. In this work, we introduce a novel unified framework\\nthat simultaneously performs camera tracking, human pose estimation and\\nhuman-scene reconstruction in an online fashion. 3D Gaussian Splatting is\\nutilized to learn Gaussian primitives for humans and scenes efficiently, and\\nreconstruction-based camera tracking and human pose estimation modules are\\ndesigned to enable holistic understanding and effective disentanglement of pose\\nand appearance. Specifically, we design a human deformation module to\\nreconstruct the details and enhance generalizability to out-of-distribution\\nposes faithfully. Aiming to learn the spatial correlation between human and\\nscene accurately, we introduce occlusion-aware human silhouette rendering and\\nmonocular geometric priors, which further improve reconstruction quality.\\nExperiments on the EMDB and NeuMan datasets demonstrate superior or on-par\\nperformance with existing methods in camera tracking, human pose estimation,\\nnovel view synthesis and runtime. Our project page is at\\nhttps://eth-ait.github.io/ODHSR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,I.4.5\", \"published\": \"2025-04-17T17:59:02Z\"}"}
