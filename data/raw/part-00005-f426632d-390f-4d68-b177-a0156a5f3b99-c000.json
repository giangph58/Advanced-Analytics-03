{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20911v1\", \"title\": \"An Empirical Study on the Capability of LLMs in Decomposing Bug Reports\", \"summary\": \"Background: Bug reports are essential to the software development life cycle.\\nThey help developers track and resolve issues, but are often difficult to\\nprocess due to their complexity, which can delay resolution and affect software\\nquality. Aims: This study investigates whether large language models (LLMs) can\\nassist developers in automatically decomposing complex bug reports into\\nsmaller, self-contained units, making them easier to understand and address.\\nMethod: We conducted an empirical study on 127 resolved privacy-related bug\\nreports collected from Apache Jira. We evaluated ChatGPT and DeepSeek using\\ndifferent prompting strategies. We first tested both LLMs with zero-shot\\nprompts, then applied improved prompts with demonstrations (using few-shot\\nprompting) to measure their abilities in bug decomposition. Results: Our\\nfindings show that LLMs are capable of decomposing bug reports, but their\\noverall performance still requires further improvement and strongly depends on\\nthe quality of the prompts. With zero-shot prompts, both studied LLMs (ChatGPT\\nand DeepSeek) performed poorly. After prompt tuning, ChatGPT's true\\ndecomposition rate increased by 140\\\\% and DeepSeek's by 163.64\\\\%. Conclusions:\\nLLMs show potential in helping developers analyze and decompose complex bug\\nreports, but they still need improvement in terms of accuracy and bug\\nunderstanding.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-29T16:29:12Z\"}"}
