{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05018v1\", \"title\": \"Joint Pedestrian and Vehicle Traffic Optimization in Urban Environments\\n  using Reinforcement Learning\", \"summary\": \"Reinforcement learning (RL) holds significant promise for adaptive traffic\\nsignal control. While existing RL-based methods demonstrate effectiveness in\\nreducing vehicular congestion, their predominant focus on vehicle-centric\\noptimization leaves pedestrian mobility needs and safety challenges\\nunaddressed. In this paper, we present a deep RL framework for adaptive control\\nof eight traffic signals along a real-world urban corridor, jointly optimizing\\nboth pedestrian and vehicular efficiency. Our single-agent policy is trained\\nusing real-world pedestrian and vehicle demand data derived from Wi-Fi logs and\\nvideo analysis. The results demonstrate significant performance improvements\\nover traditional fixed-time signals, reducing average wait times per pedestrian\\nand per vehicle by up to 67% and 52%, respectively, while simultaneously\\ndecreasing total accumulated wait times for both groups by up to 67% and 53%.\\nAdditionally, our results demonstrate generalization capabilities across\\nvarying traffic demands, including conditions entirely unseen during training,\\nvalidating RL's potential for developing transportation systems that serve all\\nroad users.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.MA\", \"published\": \"2025-04-07T12:41:58Z\"}"}
