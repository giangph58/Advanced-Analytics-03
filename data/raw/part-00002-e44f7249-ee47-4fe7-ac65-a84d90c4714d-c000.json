{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05064v1\", \"title\": \"WaterDrum: Watermarking for Data-centric Unlearning Metric\", \"summary\": \"Large language model (LLM) unlearning is critical in real-world applications\\nwhere it is necessary to efficiently remove the influence of private,\\ncopyrighted, or harmful data from some users. However, existing utility-centric\\nunlearning metrics (based on model utility) may fail to accurately evaluate the\\nextent of unlearning in realistic settings such as when (a) the forget and\\nretain set have semantically similar content, (b) retraining the model from\\nscratch on the retain set is impractical, and/or (c) the model owner can\\nimprove the unlearning metric without directly performing unlearning on the\\nLLM. This paper presents the first data-centric unlearning metric for LLMs\\ncalled WaterDrum that exploits robust text watermarking for overcoming these\\nlimitations. We also introduce new benchmark datasets for LLM unlearning that\\ncontain varying levels of similar data points and can be used to rigorously\\nevaluate unlearning algorithms using WaterDrum. Our code is available at\\nhttps://github.com/lululu008/WaterDrum and our new benchmark datasets are\\nreleased at https://huggingface.co/datasets/Glow-AI/WaterDrum-Ax.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-08T08:56:46Z\"}"}
