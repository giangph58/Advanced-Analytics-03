{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20642v1\", \"title\": \"Decision-centric fairness: Evaluation and optimization for resource\\n  allocation problems\", \"summary\": \"Data-driven decision support tools play an increasingly central role in\\ndecision-making across various domains. In this work, we focus on binary\\nclassification models for predicting positive-outcome scores and deciding on\\nresource allocation, e.g., credit scores for granting loans or churn propensity\\nscores for targeting customers with a retention campaign. Such models may\\nexhibit discriminatory behavior toward specific demographic groups through\\ntheir predicted scores, potentially leading to unfair resource allocation. We\\nfocus on demographic parity as a fairness metric to compare the proportions of\\ninstances that are selected based on their positive outcome scores across\\ngroups. In this work, we propose a decision-centric fairness methodology that\\ninduces fairness only within the decision-making region -- the range of\\nrelevant decision thresholds on the score that may be used to decide on\\nresource allocation -- as an alternative to a global fairness approach that\\nseeks to enforce parity across the entire score distribution. By restricting\\nthe induction of fairness to the decision-making region, the proposed\\ndecision-centric approach avoids imposing overly restrictive constraints on the\\nmodel, which may unnecessarily degrade the quality of the predicted scores. We\\nempirically compare our approach to a global fairness approach on multiple\\n(semi-synthetic) datasets to identify scenarios in which focusing on fairness\\nwhere it truly matters, i.e., decision-centric fairness, proves beneficial.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CY\", \"published\": \"2025-04-29T11:12:36Z\"}"}
