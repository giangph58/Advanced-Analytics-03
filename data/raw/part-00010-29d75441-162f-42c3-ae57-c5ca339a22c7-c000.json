{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16616v1\", \"title\": \"EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for\\n  Hybrid Event Stream Perception\", \"summary\": \"Event cameras, with microsecond temporal resolution and high dynamic range\\n(HDR) characteristics, emit high-speed event stream for perception tasks.\\nDespite the recent advancement in GNN-based perception methods, they are prone\\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\\nspace where they struggle to capture long-range dependencies and fail to\\neffectively characterize the inherent hierarchical structures of non-uniformly\\ndistributed event stream. To this end, in this paper we propose a novel\\napproach named EHGCN, which is a pioneer to perceive event stream in both\\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\\nmotion state transition probabilities, thereby eliminating cross-target\\nspurious associations and providing critically topological priors while\\ncapturing long-range dependencies between events. Finally, we propose a\\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\\nrespectively, to achieve hybrid event perception. Experimental results on event\\nperception tasks such as object detection and recognition validate the\\neffectiveness of our approach.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-23T11:01:03Z\"}"}
