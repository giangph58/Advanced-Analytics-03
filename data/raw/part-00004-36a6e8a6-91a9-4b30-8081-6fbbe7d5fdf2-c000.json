{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05091v1\", \"title\": \"DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions\", \"summary\": \"Deep learning (DL) has surpassed human performance on standard benchmarks,\\ndriving its widespread adoption in computer vision tasks. One such task is\\ndisparity estimation, estimating the disparity between matching pixels in\\nstereo image pairs, which is crucial for safety-critical applications like\\nmedical surgeries and autonomous navigation. However, DL-based disparity\\nestimation methods are highly susceptible to distribution shifts and\\nadversarial attacks, raising concerns about their reliability and\\ngeneralization. Despite these concerns, a standardized benchmark for evaluating\\nthe robustness of disparity estimation methods remains absent, hindering\\nprogress in the field.\\n  To address this gap, we introduce DispBench, a comprehensive benchmarking\\ntool for systematically assessing the reliability of disparity estimation\\nmethods. DispBench evaluates robustness against synthetic image corruptions\\nsuch as adversarial attacks and out-of-distribution shifts caused by 2D Common\\nCorruptions across multiple datasets and diverse corruption scenarios. We\\nconduct the most extensive performance and robustness analysis of disparity\\nestimation methods to date, uncovering key correlations between accuracy,\\nreliability, and generalization. Open-source code for DispBench:\\nhttps://github.com/shashankskagnihotri/benchmarking_robustness/tree/disparity_estimation/final/disparity_estimation\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-05-08T09:40:17Z\"}"}
