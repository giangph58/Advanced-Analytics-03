{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02445v1\", \"title\": \"Improved universal approximation with neural networks studied via\\n  affine-invariant subspaces of $L_2(\\\\mathbb{R}^n)$\", \"summary\": \"We show that there are no non-trivial closed subspaces of $L_2(\\\\mathbb{R}^n)$\\nthat are invariant under invertible affine transformations. We apply this\\nresult to neural networks showing that any nonzero $L_2(\\\\mathbb{R})$ function\\nis an adequate activation function in a one hidden layer neural network in\\norder to approximate every function in $L_2(\\\\mathbb{R})$ with any desired\\naccuracy. This generalizes the universal approximation properties of neural\\nnetworks in $L_2(\\\\mathbb{R})$ related to Wiener's Tauberian Theorems. Our\\nresults extend to the spaces $L_p(\\\\mathbb{R})$ with $p>1$.\", \"main_category\": \"math.FA\", \"categories\": \"math.FA,cs.IT,math.IT\", \"published\": \"2025-04-03T10:00:40Z\"}"}
