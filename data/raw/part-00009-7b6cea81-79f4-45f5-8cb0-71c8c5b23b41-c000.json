{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11874v1\", \"title\": \"Factor-MCLS: Multi-agent learning system with reward factor matrix and\\n  multi-critic framework for dynamic portfolio optimization\", \"summary\": \"Typical deep reinforcement learning (DRL) agents for dynamic portfolio\\noptimization learn the factors influencing portfolio return and risk by\\nanalyzing the output values of the reward function while adjusting portfolio\\nweights within the training environment. However, it faces a major limitation\\nwhere it is difficult for investors to intervene in the training based on\\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\\narises from another limitation: existing DRL agents may not develop a thorough\\nunderstanding of the factors responsible for the portfolio return and risk by\\nonly learning from the output of the reward function. As a result, the strategy\\nfor determining the target portfolio weights is entirely dependent on the DRL\\nagents themselves. To address these limitations, we propose a reward factor\\nmatrix for elucidating the return and risk of each asset in the portfolio.\\nAdditionally, we propose a novel learning system named Factor-MCLS using a\\nmulti-critic framework that facilitates learning of the reward factor matrix.\\nIn this way, our DRL-based learning system can effectively learn the factors\\ninfluencing portfolio return and risk. Moreover, based on the critic networks\\nwithin the multi-critic framework, we develop a risk constraint term in the\\ntraining objective function of the policy function. This risk constraint term\\nallows investors to intervene in the training of the DRL agent according to\\ntheir individual levels of risk aversion towards the portfolio assets.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-16T08:51:09Z\"}"}
