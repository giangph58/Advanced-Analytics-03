{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02618v1\", \"title\": \"Variational Online Mirror Descent for Robust Learning in Schr\\u00f6dinger\\n  Bridge\", \"summary\": \"Sch\\\\\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\\ngenerative models. In practice, however, estimated learning signals are often\\nuncertain, and the reliability promised by existing methods is often based on\\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\\nalgorithm through mirror descent (MD) have gained attention, revealing\\ngeometric insights into solution acquisition of the SB problems. In this paper,\\nwe propose a variational online MD (OMD) framework for the SB problems, which\\nprovides further stability to SB solvers. We formally prove convergence and a\\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\\npropose a simulation-free SB algorithm called Variational Mirrored\\nSchr\\\\\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\\nthe Gaussian mixture parameterization for Schr\\\\\\\"odinger potentials. Based on\\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\\ndynamics that precisely approximate each OMD step. In experiments, we validate\\nthe performance of the proposed VMSB algorithm across an extensive suite of\\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\\nSB problems, demonstrating the robustness predicted by our theory.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-03T14:18:47Z\"}"}
