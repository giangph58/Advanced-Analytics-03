{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16691v1\", \"title\": \"Rethinking Vision Transformer for Large-Scale Fine-Grained Image\\n  Retrieval\", \"summary\": \"Large-scale fine-grained image retrieval (FGIR) aims to retrieve images\\nbelonging to the same subcategory as a given query by capturing subtle\\ndifferences in a large-scale setting. Recently, Vision Transformers (ViT) have\\nbeen employed in FGIR due to their powerful self-attention mechanism for\\nmodeling long-range dependencies. However, most Transformer-based methods focus\\nprimarily on leveraging self-attention to distinguish fine-grained details,\\nwhile overlooking the high computational complexity and redundant dependencies\\ninherent to these models, limiting their scalability and effectiveness in\\nlarge-scale FGIR. In this paper, we propose an Efficient and Effective\\nViT-based framework, termed \\\\textbf{EET}, which integrates token pruning module\\nwith a discriminative transfer strategy to address these limitations.\\nSpecifically, we introduce a content-based token pruning scheme to enhance the\\nefficiency of the vanilla ViT, progressively removing background or\\nlow-discriminative tokens at different stages by exploiting feature responses\\nand self-attention mechanism. To ensure the resulting efficient ViT retains\\nstrong discriminative power, we further present a discriminative transfer\\nstrategy comprising both \\\\textit{discriminative knowledge transfer} and\\n\\\\textit{discriminative region guidance}. Using a distillation paradigm, these\\ncomponents transfer knowledge from a larger ``teacher'' ViT to a more efficient\\n``student'' model, guiding the latter to focus on subtle yet crucial regions in\\na cost-free manner. Extensive experiments on two widely-used fine-grained\\ndatasets and four large-scale fine-grained datasets demonstrate the\\neffectiveness of our method. Specifically, EET reduces the inference latency of\\nViT-Small by 42.7\\\\% and boosts the retrieval performance of 16-bit hash codes\\nby 5.15\\\\% on the challenging NABirds dataset.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM\", \"published\": \"2025-04-23T13:23:56Z\"}"}
