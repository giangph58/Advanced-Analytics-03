{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12996v1\", \"title\": \"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained\\n  Unlearning for Large Language Models via Knowledge Isolation\", \"summary\": \"Large language models (LLMs) frequently memorize sensitive information during\\ntraining, posing risks when deploying publicly accessible models. Current\\nmachine unlearning methods struggle to selectively remove specific data\\nassociations without degrading overall model capabilities. This paper presents\\nour solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a\\ntwo-stage methodology that combines causal mediation analysis with\\nlayer-specific optimization. Through systematic causal tracing experiments on\\nOLMo architectures (1B and 7B parameters), we identify the critical role of the\\nfirst few transformer layers (layers 0-5) in storing subject-attribute\\nassociations within MLP modules. Building on this insight, we develop a\\nconstrained optimization approach that freezes upper layers while applying a\\nnovel joint loss function to lower layers-simultaneously maximizing forget set\\nloss via output token cross-entropy penalties and minimizing retain set\\ndeviation through adaptive regularization. Our method achieves 2nd place in the\\n1B model track, demonstrating strong task performance while maintaining 88% of\\nbaseline MMLU accuracy. These results establish causal-informed layer\\noptimization as a promising paradigm for efficient, precise unlearning in LLMs,\\noffering a significant step forward in addressing data privacy concerns in AI\\nsystems.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-17T15:05:40Z\"}"}
