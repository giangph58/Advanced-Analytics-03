{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01838v1\", \"title\": \"Prompting Medical Vision-Language Models to Mitigate Diagnosis Bias by\\n  Generating Realistic Dermoscopic Images\", \"summary\": \"Artificial Intelligence (AI) in skin disease diagnosis has improved\\nsignificantly, but a major concern is that these models frequently show biased\\nperformance across subgroups, especially regarding sensitive attributes such as\\nskin color. To address these issues, we propose a novel generative AI-based\\nframework, namely, Dermatology Diffusion Transformer (DermDiT), which leverages\\ntext prompts generated via Vision Language Models and multimodal text-image\\nlearning to generate new dermoscopic images. We utilize large vision language\\nmodels to generate accurate and proper prompts for each dermoscopic image which\\nhelps to generate synthetic images to improve the representation of\\nunderrepresented groups (patient, disease, etc.) in highly imbalanced datasets\\nfor clinical diagnoses. Our extensive experimentation showcases the large\\nvision language models providing much more insightful representations, that\\nenable DermDiT to generate high-quality images. Our code is available at\\nhttps://github.com/Munia03/DermDiT\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T15:44:12Z\"}"}
