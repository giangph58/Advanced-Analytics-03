{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16723v1\", \"title\": \"Detecting and Understanding Hateful Contents in Memes Through Captioning\\n  and Visual Question-Answering\", \"summary\": \"Memes are widely used for humor and cultural commentary, but they are\\nincreasingly exploited to spread hateful content. Due to their multimodal\\nnature, hateful memes often evade traditional text-only or image-only detection\\nsystems, particularly when they employ subtle or coded references. To address\\nthese challenges, we propose a multimodal hate detection framework that\\nintegrates key components: OCR to extract embedded text, captioning to describe\\nvisual content neutrally, sub-label classification for granular categorization\\nof hateful content, RAG for contextually relevant retrieval, and VQA for\\niterative analysis of symbolic and contextual cues. This enables the framework\\nto uncover latent signals that simpler pipelines fail to detect. Experimental\\nresults on the Facebook Hateful Memes dataset reveal that the proposed\\nframework exceeds the performance of unimodal and conventional multimodal\\nmodels in both accuracy and AUC-ROC.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-23T13:52:14Z\"}"}
