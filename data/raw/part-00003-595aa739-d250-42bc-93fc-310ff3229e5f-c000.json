{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12704v1\", \"title\": \"SmartFreeEdit: Mask-Free Spatial-Aware Image Editing with Complex\\n  Instruction Understanding\", \"summary\": \"Recent advancements in image editing have utilized large-scale multimodal\\nmodels to enable intuitive, natural instruction-driven interactions. However,\\nconventional methods still face significant challenges, particularly in spatial\\nreasoning, precise region segmentation, and maintaining semantic consistency,\\nespecially in complex scenes. To overcome these challenges, we introduce\\nSmartFreeEdit, a novel end-to-end framework that integrates a multimodal large\\nlanguage model (MLLM) with a hypergraph-enhanced inpainting architecture,\\nenabling precise, mask-free image editing guided exclusively by natural\\nlanguage instructions. The key innovations of SmartFreeEdit include:(1)the\\nintroduction of region aware tokens and a mask embedding paradigm that enhance\\nthe spatial understanding of complex scenes;(2) a reasoning segmentation\\npipeline designed to optimize the generation of editing masks based on natural\\nlanguage instructions;and (3) a hypergraph-augmented inpainting module that\\nensures the preservation of both structural integrity and semantic coherence\\nduring complex edits, overcoming the limitations of local-based image\\ngeneration. Extensive experiments on the Reason-Edit benchmark demonstrate that\\nSmartFreeEdit surpasses current state-of-the-art methods across multiple\\nevaluation metrics, including segmentation accuracy, instruction adherence, and\\nvisual quality preservation, while addressing the issue of local information\\nfocus and improving global consistency in the edited image. Our project will be\\navailable at https://github.com/smileformylove/SmartFreeEdit.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.MM\", \"published\": \"2025-04-17T07:17:49Z\"}"}
