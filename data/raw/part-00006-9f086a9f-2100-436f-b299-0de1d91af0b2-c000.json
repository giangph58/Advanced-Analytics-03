{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04318v1\", \"title\": \"Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of\\n  Fit Testing\", \"summary\": \"As the adoption of deep learning models has grown beyond human capacity for\\nverification, meta-algorithms are needed to ensure reliable model inference.\\nConcept drift detection is a field dedicated to identifying statistical shifts\\nthat is underutilized in monitoring neural networks that may encounter\\ninference data with distributional characteristics diverging from their\\ntraining data. Given the wide variety of model architectures, applications, and\\ndatasets, it is important that concept drift detection algorithms are adaptable\\nto different inference scenarios. In this paper, we introduce an application of\\nthe $\\\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\\nnetwork, and a transformer trained for machine vision as they are exposed to\\nsimulated drift during inference. To that end, we demonstrate how unexpected\\ndrops in accuracy due to concept drift can be detected without directly\\nexamining the inference outputs. Our approach enhances safety by ensuring\\nmodels are continually evaluated for reliability across varying conditions.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,eess.IV\", \"published\": \"2025-05-07T11:04:47Z\"}"}
