{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16656v1\", \"title\": \"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning\", \"summary\": \"We present Skywork R1V2, a next-generation multimodal reasoning model and a\\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\\nintroduces a hybrid reinforcement learning paradigm that harmonizes\\nreward-model guidance with rule-based strategies, thereby addressing the\\nlong-standing challenge of balancing sophisticated reasoning capabilities with\\nbroad generalization. To further enhance training efficiency, we propose the\\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\\n(GRPO) by prioritizing high-value samples throughout the optimization process.\\nNotably, we observe that excessive reinforcement signals can induce visual\\nhallucinations--a phenomenon we systematically monitor and mitigate through\\ncalibrated reward thresholds throughout the training process. Empirical results\\naffirm the exceptional capability of R1V2, with benchmark-leading performances\\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\\n74.0 on MMMU. These results underscore R1V2's superiority over existing\\nopen-source models and demonstrate significant progress in closing the\\nperformance gap with premier proprietary systems, including Gemini 2.5 and\\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\\npromote openness and reproducibility\\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-23T12:24:10Z\"}"}
