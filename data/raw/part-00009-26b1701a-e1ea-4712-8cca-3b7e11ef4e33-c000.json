{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20964v1\", \"title\": \"OSVBench: Benchmarking LLMs on Specification Generation Tasks for\\n  Operating System Verification\", \"summary\": \"We introduce OSVBench, a new benchmark for evaluating Large Language Models\\n(LLMs) in generating complete specification code pertaining to operating system\\nkernel verification tasks. The benchmark first defines the specification\\ngeneration problem into a program synthesis problem within a confined scope of\\nsyntax and semantics by providing LLMs with the programming model. The LLMs are\\nrequired to understand the provided verification assumption and the potential\\nsyntax and semantics space to search for, then generate the complete\\nspecification for the potentially buggy operating system code implementation\\nunder the guidance of the high-level functional description of the operating\\nsystem. This benchmark is built upon a real-world operating system kernel,\\nHyperkernel, and consists of 245 complex specification generation tasks in\\ntotal, each is a long context task of about 20k-30k tokens. Our comprehensive\\nevaluation of 12 LLMs exhibits the limited performance of the current LLMs on\\nthe specification generation tasks for operating system verification.\\nSignificant disparities in their performance on the benchmark highlight\\ndifferences in their ability to handle long-context code generation tasks. The\\nevaluation toolkit and benchmark are available at\\nhttps://github.com/lishangyu-hkust/OSVBench.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.OS,cs.PL,cs.SE\", \"published\": \"2025-04-29T17:34:49Z\"}"}
