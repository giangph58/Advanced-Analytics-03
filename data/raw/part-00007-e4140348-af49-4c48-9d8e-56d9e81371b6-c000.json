{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09993v1\", \"title\": \"AimTS: Augmented Series and Image Contrastive Learning for Time Series\\n  Classification\", \"summary\": \"Time series classification (TSC) is an important task in time series\\nanalysis. Existing TSC methods mainly train on each single domain separately,\\nsuffering from a degradation in accuracy when the samples for training are\\ninsufficient in certain domains. The pre-training and fine-tuning paradigm\\nprovides a promising direction for solving this problem. However, time series\\nfrom different domains are substantially divergent, which challenges the\\neffective pre-training on multi-source data and the generalization ability of\\npre-trained models. To handle this issue, we introduce Augmented Series and\\nImage Contrastive Learning for Time Series Classification (AimTS), a\\npre-training framework that learns generalizable representations from\\nmulti-source time series data. We propose a two-level prototype-based\\ncontrastive learning method to effectively utilize various augmentations in\\nmulti-source pre-training, which learns representations for TSC that can be\\ngeneralized to different domains. In addition, considering augmentations within\\nthe single time series modality are insufficient to fully address\\nclassification problems with distribution shift, we introduce the image\\nmodality to supplement structural information and establish a series-image\\ncontrastive learning to improve the generalization of the learned\\nrepresentations for TSC tasks. Extensive experiments show that after\\nmulti-source pre-training, AimTS achieves good generalization performance,\\nenabling efficient learning and even few-shot learning on various downstream\\nTSC datasets.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-14T08:55:16Z\"}"}
