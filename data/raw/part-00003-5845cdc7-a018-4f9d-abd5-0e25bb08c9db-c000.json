{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04945v1\", \"title\": \"A Llama walks into the 'Bar': Efficient Supervised Fine-Tuning for Legal\\n  Reasoning in the Multi-state Bar Exam\", \"summary\": \"Legal reasoning tasks present unique challenges for large language models\\n(LLMs) due to the complexity of domain-specific knowledge and reasoning\\nprocesses. This paper investigates how effectively smaller language models\\n(Llama 2 7B and Llama 3 8B) can be fine-tuned with a limited dataset of 1,514\\nMulti-state Bar Examination (MBE) questions to improve legal question answering\\naccuracy. We evaluate these models on the 2022 MBE questions licensed from JD\\nAdvising, the same dataset used in the 'GPT-4 passes the Bar exam' study. Our\\nmethodology involves collecting approximately 200 questions per legal domain\\nacross 7 domains. We distill the dataset using Llama 3 (70B) to transform\\nexplanations into a structured IRAC (Issue, Rule, Application, Conclusion)\\nformat as a guided reasoning process to see if it results in better performance\\nover the non-distilled dataset. We compare the non-fine-tuned models against\\ntheir supervised fine-tuned (SFT) counterparts, trained for different sample\\nsizes per domain, to study the effect on accuracy and prompt adherence. We also\\nanalyse option selection biases and their mitigation following SFT. In\\naddition, we consolidate the performance across multiple variables: prompt type\\n(few-shot vs zero-shot), answer ordering (chosen-option first vs\\ngenerated-explanation first), response format (Numbered list vs Markdown vs\\nJSON), and different decoding temperatures. Our findings show that\\ndomain-specific SFT helps some model configurations achieve close to human\\nbaseline performance, despite limited computational resources and a relatively\\nsmall dataset. We release both the gathered SFT dataset and the family of\\nSupervised Fine-tuned (SFT) adapters optimised for MBE performance. This\\nestablishes a practical lower bound on resources needed towards achieving\\neffective legal question answering in smaller LLMs.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CL\", \"published\": \"2025-04-07T11:31:22Z\"}"}
