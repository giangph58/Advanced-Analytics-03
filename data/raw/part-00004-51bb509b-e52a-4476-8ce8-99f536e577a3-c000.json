{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03193v1\", \"title\": \"A study on audio synchronous steganography detection and distributed\\n  guide inference model based on sliding spectral features and intelligent\\n  inference drive\", \"summary\": \"With the rise of short video platforms in global communication, embedding\\nsteganographic data in audio synchronization streams has emerged as a new\\ncovert communication method. To address the limitations of traditional\\ntechniques in detecting synchronized steganography, this paper proposes a\\ndetection and distributed guidance reconstruction model based on short video\\n\\\"Yupan\\\" samples released by China's South Sea Fleet on TikTok. The method\\nintegrates sliding spectrum feature extraction and intelligent inference\\nmechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is\\nused to extract the main frequency trajectory and construct the synchronization\\nframe detection model (M1), identifying a frame flag \\\"FFFFFFFFFFFFFFFFFF80\\\".\\nThe subsequent 32-byte payload is decoded by a structured model (M2) to infer\\ndistributed guidance commands. Analysis reveals a low-entropy, repetitive byte\\nsequence in the 36 to 45 second audio segment with highly concentrated spectral\\nenergy, confirming the presence of synchronization frames. Although plaintext\\nsemantics are not restored, the consistency in command field layout suggests\\nfeatures of military communication protocols. The multi-segment splicing model\\nfurther shows cross-video embedding and centralized decoding capabilities. The\\nproposed framework validates the effectiveness of sliding spectral features for\\nsynchronized steganography detection and builds an extensible inference model\\nfor covert communication analysis and tactical guidance simulation on open\\nplatforms.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.AI,cs.CR,eess.AS\", \"published\": \"2025-05-06T05:24:11Z\"}"}
