{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05058v1\", \"title\": \"Not All Data Are Unlearned Equally\", \"summary\": \"Machine unlearning is concerned with the task of removing knowledge learned\\nfrom particular data points from a trained model. In the context of large\\nlanguage models (LLMs), unlearning has recently received increased attention,\\nparticularly for removing knowledge about named entities from models for\\nprivacy purposes. While various approaches have been proposed to address the\\nunlearning problem, most existing approaches treat all data points to be\\nunlearned equally, i.e., unlearning that Montreal is a city in Canada is\\ntreated exactly the same as unlearning the phone number of the first author of\\nthis paper. In this work, we show that this all data is equal assumption does\\nnot hold for LLM unlearning. We study how the success of unlearning depends on\\nthe frequency of the knowledge we want to unlearn in the pre-training data of a\\nmodel and find that frequency strongly affects unlearning, i.e., more frequent\\nknowledge is harder to unlearn. Additionally, we uncover a misalignment between\\nprobability and generation-based evaluations of unlearning and show that this\\nproblem worsens as models become larger. Overall, our experiments highlight the\\nneed for better evaluation practices and novel methods for LLM unlearning that\\ntake the training data of models into account.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-07T13:29:02Z\"}"}
