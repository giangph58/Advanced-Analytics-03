{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04203v1\", \"title\": \"ELGAR: Expressive Cello Performance Motion Generation for Audio\\n  Rendition\", \"summary\": \"The art of instrument performance stands as a vivid manifestation of human\\ncreativity and emotion. Nonetheless, generating instrument performance motions\\nis a highly challenging task, as it requires not only capturing intricate\\nmovements but also reconstructing the complex dynamics of the\\nperformer-instrument interaction. While existing works primarily focus on\\nmodeling partial body motions, we propose Expressive ceLlo performance motion\\nGeneration for Audio Rendition (ELGAR), a state-of-the-art diffusion-based\\nframework for whole-body fine-grained instrument performance motion generation\\nsolely from audio. To emphasize the interactive nature of the instrument\\nperformance, we introduce Hand Interactive Contact Loss (HICL) and Bow\\nInteractive Contact Loss (BICL), which effectively guarantee the authenticity\\nof the interplay. Moreover, to better evaluate whether the generated motions\\nalign with the semantic context of the music audio, we design novel metrics\\nspecifically for string instrument performance motion generation, including\\nfinger-contact distance, bow-string distance, and bowing score. Extensive\\nevaluations and ablation studies are conducted to validate the efficacy of the\\nproposed methods. In addition, we put forward a motion generation dataset\\nSPD-GEN, collated and normalized from the MoCap dataset SPD. As demonstrated,\\nELGAR has shown great potential in generating instrument performance motions\\nwith complicated and fast interactions, which will promote further development\\nin areas such as animation, music education, interactive art creation, etc.\", \"main_category\": \"cs.GR\", \"categories\": \"cs.GR,cs.SD,eess.AS\", \"published\": \"2025-05-07T07:57:08Z\"}"}
