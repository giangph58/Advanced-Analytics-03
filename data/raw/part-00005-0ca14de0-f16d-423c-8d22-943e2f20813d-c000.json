{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21749v1\", \"title\": \"Common3D: Self-Supervised Learning of 3D Morphable Models for Common\\n  Objects in Neural Feature Space\", \"summary\": \"3D morphable models (3DMMs) are a powerful tool to represent the possible\\nshapes and appearances of an object category. Given a single test image, 3DMMs\\ncan be used to solve various tasks, such as predicting the 3D shape, pose,\\nsemantic correspondence, and instance segmentation of an object. Unfortunately,\\n3DMMs are only available for very few object categories that are of particular\\ninterest, like faces or human bodies, as they require a demanding 3D data\\nacquisition and category-specific training process. In contrast, we introduce a\\nnew method, Common3D, that learns 3DMMs of common objects in a fully\\nself-supervised manner from a collection of object-centric videos. For this\\npurpose, our model represents objects as a learned 3D template mesh and a\\ndeformation field that is parameterized as an image-conditioned neural network.\\nDifferent from prior works, Common3D represents the object appearance with\\nneural features instead of RGB colors, which enables the learning of more\\ngeneralizable representations through an abstraction from pixel intensities.\\nImportantly, we train the appearance features using a contrastive objective by\\nexploiting the correspondences defined through the deformable template mesh.\\nThis leads to higher quality correspondence features compared to related works\\nand a significantly improved model performance at estimating 3D object pose and\\nsemantic correspondence. Common3D is the first completely self-supervised\\nmethod that can solve various vision tasks in a zero-shot manner.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T15:42:23Z\"}"}
