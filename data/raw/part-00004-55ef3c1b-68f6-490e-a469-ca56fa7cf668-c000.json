{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03623v1\", \"title\": \"Bounding Box-Guided Diffusion for Synthesizing Industrial Images and\\n  Segmentation Map\", \"summary\": \"Synthetic dataset generation in Computer Vision, particularly for industrial\\napplications, is still underexplored. Industrial defect segmentation, for\\ninstance, requires highly accurate labels, yet acquiring such data is costly\\nand time-consuming. To address this challenge, we propose a novel\\ndiffusion-based pipeline for generating high-fidelity industrial datasets with\\nminimal supervision. Our approach conditions the diffusion model on enriched\\nbounding box representations to produce precise segmentation masks, ensuring\\nrealistic and accurately localized defect synthesis. Compared to existing\\nlayout-conditioned generative methods, our approach improves defect consistency\\nand spatial accuracy. We introduce two quantitative metrics to evaluate the\\neffectiveness of our method and assess its impact on a downstream segmentation\\ntask trained on real and synthetic data. Our results demonstrate that\\ndiffusion-based synthesis can bridge the gap between artificial and real-world\\nindustrial data, fostering more reliable and cost-efficient segmentation\\nmodels. The code is publicly available at\\nhttps://github.com/covisionlab/diffusion_labeling.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T15:21:36Z\"}"}
