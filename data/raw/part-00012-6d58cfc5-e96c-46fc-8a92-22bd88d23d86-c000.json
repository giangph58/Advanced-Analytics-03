{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04606v1\", \"title\": \"OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue\\n  Resolution\", \"summary\": \"The GitHub issue resolution task aims to resolve issues reported in\\nrepositories automatically. With advances in large language models (LLMs), this\\ntask has gained increasing attention, and several benchmarks are proposed to\\nevaluate the issue resolution ability of LLMs. However, existing benchmarks\\nhave three main limitations. First, current benchmarks focus on a single\\nprogramming language, limiting the evaluation of issues from repositories\\nacross different languages. Second, they usually cover a narrow range of\\ndomains, which may fail to represent the diversity of real-world issues. Third,\\nexisting benchmarks rely solely on textual information in issue descriptions,\\noverlooking multimodal information such as images in issues. In this paper, we\\npropose OmniGIRL, a GitHub Issue ResoLution benchmark that is multilingual,\\nmultimodal, and multi-domain. OmniGIRL includes 959 task instances, which are\\ncollected from repositories across four programming languages (i.e., Python,\\nJavaScript, TypeScript, and Java) and eight different domains. Our evaluation\\nshows that current LLMs show limited performances on OmniGIRL. Notably, the\\nbest-performing model, GPT-4o, resolves only 8.6% of the issues. Besides, we\\nfind that current LLMs struggle to resolve issues requiring understanding\\nimages. The best performance is achieved by Claude-3.5-Sonnet, which resolves\\nonly 10.5% of the issues with image information. Finally, we analyze the\\nreasons behind current LLMs' failure on OmniGIRL, providing insights for future\\nimprovements.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-05-07T17:51:10Z\"}"}
