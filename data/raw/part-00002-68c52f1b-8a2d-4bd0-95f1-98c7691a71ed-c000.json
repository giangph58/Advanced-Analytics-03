{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20797v1\", \"title\": \"Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning\", \"summary\": \"Current mainstream deep learning techniques exhibit an over-reliance on\\nextensive training data and a lack of adaptability to the dynamic world,\\nmarking a considerable disparity from human intelligence. To bridge this gap,\\nFew-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous\\nlearning of new categories with limited samples without forgetting old\\nknowledge. Existing FSCIL studies typically use a single model to learn\\nknowledge across all sessions, inevitably leading to the stability-plasticity\\ndilemma. Unlike machines, humans store varied knowledge in different cerebral\\ncortices. Inspired by this characteristic, our paper aims to develop a method\\nthat learns independent models for each session. It can inherently prevent\\ncatastrophic forgetting. During the testing stage, our method integrates\\nUncertainty Quantification (UQ) for model deployment. Our method provides a\\nfresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on\\nCIFAR-100 and mini-ImageNet datasets.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-29T14:11:06Z\"}"}
