{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13140v1\", \"title\": \"PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition\", \"summary\": \"Human action recognition (HAR) has achieved impressive results with deep\\nlearning models, but their decision-making process remains opaque due to their\\nblack-box nature. Ensuring interpretability is crucial, especially for\\nreal-world applications requiring transparency and accountability. Existing\\nvideo XAI methods primarily rely on feature attribution or static textual\\nconcepts, both of which struggle to capture motion dynamics and temporal\\ndependencies essential for action understanding. To address these challenges,\\nwe propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR),\\na novel concept bottleneck framework that introduces human pose sequences as\\nmotion-aware, structured concepts for video action recognition. Unlike methods\\nbased on pixel-level features or static textual descriptions, PCBEAR leverages\\nhuman skeleton poses, which focus solely on body movements, providing robust\\nand interpretable explanations of motion dynamics. We define two types of\\npose-based concepts: static pose concepts for spatial configurations at\\nindividual frames, and dynamic pose concepts for motion patterns across\\nmultiple frames. To construct these concepts, PCBEAR applies clustering to\\nvideo pose sequences, allowing for automatic discovery of meaningful concepts\\nwithout manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500,\\nshowing that it achieves high classification performance while offering\\ninterpretable, motion-driven explanations. Our method provides both strong\\npredictive performance and human-understandable insights into the model's\\nreasoning process, enabling test-time interventions for debugging and improving\\nmodel behavior.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T17:50:07Z\"}"}
