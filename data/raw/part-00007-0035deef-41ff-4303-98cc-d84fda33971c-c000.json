{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21716v1\", \"title\": \"LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in\\n  Household Robotics\", \"summary\": \"We present an embodied robotic system with an LLM-driven agent-orchestration\\narchitecture for autonomous household object management. The system integrates\\nmemory-augmented task planning, enabling robots to execute high-level user\\ncommands while tracking past actions. It employs three specialized agents: a\\nrouting agent, a task planning agent, and a knowledge base agent, each powered\\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\\nneed for explicit model training. RAG enables the system to retrieve context\\nfrom past interactions, enhancing long-term object tracking. A combination of\\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\\nsemantic scene understanding for task planning. Evaluation across three\\nhousehold scenarios demonstrates high task planning accuracy and an improvement\\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\\navailable at: https://github.com/marc1198/chat-hsr.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.CL\", \"published\": \"2025-04-30T15:00:20Z\"}"}
