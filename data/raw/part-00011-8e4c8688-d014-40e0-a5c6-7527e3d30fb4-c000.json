{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17401v1\", \"title\": \"StereoMamba: Real-time and Robust Intraoperative Stereo Disparity\\n  Estimation via Long-range Spatial Dependencies\", \"summary\": \"Stereo disparity estimation is crucial for obtaining depth information in\\nrobot-assisted minimally invasive surgery (RAMIS). While current deep learning\\nmethods have made significant advancements, challenges remain in achieving an\\noptimal balance between accuracy, robustness, and inference speed. To address\\nthese challenges, we propose the StereoMamba architecture, which is\\nspecifically designed for stereo disparity estimation in RAMIS. Our approach is\\nbased on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances\\nlong-range spatial dependencies both within and across stereo images. To\\neffectively integrate multi-scale features from FE-Mamba, we then introduce a\\nnovel Multidimensional Feature Fusion (MFF) module. Experiments against the\\nstate-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba\\nachieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the\\nsecond-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining\\nan inference speed of 21.28 FPS for a pair of high-resolution images\\n(1280*1024), striking the optimum balance between accuracy, robustness, and\\nefficiency. Furthermore, by comparing synthesized right images, generated from\\nwarping left images using the generated disparity maps, with the actual right\\nimage, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761),\\nexhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS\\ndatasets.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-24T09:46:15Z\"}"}
