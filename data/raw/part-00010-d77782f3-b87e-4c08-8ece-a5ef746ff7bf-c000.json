{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20630v1\", \"title\": \"ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting\", \"summary\": \"Multimodal immersive spatial drama generation focuses on creating continuous\\nmulti-speaker binaural speech with dramatic prosody based on multimodal\\nprompts, with potential applications in AR, VR, and others. This task requires\\nsimultaneous modeling of spatial information and dramatic prosody based on\\nmultimodal inputs, with high data collection costs. To the best of our\\nknowledge, our work is the first attempt to address these challenges. We\\nconstruct MRSDrama, the first multimodal recorded spatial drama dataset,\\ncontaining binaural drama audios, scripts, videos, geometric poses, and textual\\nprompts. Then, we propose ISDrama, the first immersive spatial drama generation\\nmodel through multimodal prompting. ISDrama comprises these primary components:\\n1) Multimodal Pose Encoder, based on contrastive learning, considering the\\nDoppler effect caused by moving speakers to extract unified pose information\\nfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-based\\nmamba-transformer model that generates high-quality drama, incorporating\\nDrama-MOE to select proper experts for enhanced prosody and pose control. We\\nalso design a context-consistent classifier-free guidance strategy to\\ncoherently generate complete drama. Experimental results show that ISDrama\\noutperforms baseline models on objective and subjective metrics. The demos and\\ndataset are available at https://aaronz345.github.io/ISDramaDemo.\", \"main_category\": \"eess.AS\", \"categories\": \"eess.AS,cs.MM,cs.SD\", \"published\": \"2025-04-29T10:56:44Z\"}"}
