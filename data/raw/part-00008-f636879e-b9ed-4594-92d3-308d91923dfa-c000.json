{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20752v1\", \"title\": \"Grokking in the Wild: Data Augmentation for Real-World Multi-Hop\\n  Reasoning with Transformers\", \"summary\": \"Transformers have achieved great success in numerous NLP tasks but continue\\nto exhibit notable gaps in multi-step factual reasoning, especially when\\nreal-world knowledge is sparse. Recent advances in grokking have demonstrated\\nthat neural networks can transition from memorizing to perfectly generalizing\\nonce they detect underlying logical patterns - yet these studies have primarily\\nused small, synthetic tasks. In this paper, for the first time, we extend\\ngrokking to real-world factual data and address the challenge of dataset\\nsparsity by augmenting existing knowledge graphs with carefully designed\\nsynthetic data to raise the ratio $\\\\phi_r$ of inferred facts to atomic facts\\nabove the threshold required for grokking. Surprisingly, we find that even\\nfactually incorrect synthetic data can strengthen emergent reasoning circuits\\nrather than degrade accuracy, as it forces the model to rely on relational\\nstructure rather than memorization. When evaluated on multi-hop reasoning\\nbenchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -\\nsubstantially improving over strong baselines and matching or exceeding current\\nstate-of-the-art results. We further provide an in-depth analysis of how\\nincreasing $\\\\phi_r$ drives the formation of generalizing circuits inside\\nTransformers. Our findings suggest that grokking-based data augmentation can\\nunlock implicit multi-hop reasoning capabilities, opening the door to more\\nrobust and interpretable factual reasoning in large-scale language models.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-04-29T13:33:29Z\"}"}
