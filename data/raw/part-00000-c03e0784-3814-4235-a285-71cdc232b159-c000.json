{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04964v1\", \"title\": \"CAG-VLM: Fine-Tuning of a Large-Scale Model to Recognize Angiographic\\n  Images for Next-Generation Diagnostic Systems\", \"summary\": \"Coronary angiography (CAG) is the gold-standard imaging modality for\\nevaluating coronary artery disease, but its interpretation and subsequent\\ntreatment planning rely heavily on expert cardiologists. To enable AI-based\\ndecision support, we introduce a two-stage, physician-curated pipeline and a\\nbilingual (Japanese/English) CAG image-report dataset. First, we sample 14,686\\nframes from 539 exams and annotate them for key-frame detection and left/right\\nlaterality; a ConvNeXt-Base CNN trained on this data achieves 0.96 F1 on\\nlaterality classification, even on low-contrast frames. Second, we apply the\\nCNN to 243 independent exams, extract 1,114 key frames, and pair each with its\\npre-procedure report and expert-validated diagnostic and treatment summary,\\nyielding a parallel corpus. We then fine-tune three open-source VLMs\\n(PaliGemma2, Gemma3, and ConceptCLIP-enhanced Gemma3) via LoRA and evaluate\\nthem using VLScore and cardiologist review. Although PaliGemma2 w/LoRA attains\\nthe highest VLScore, Gemma3 w/LoRA achieves the top clinician rating (mean\\n7.20/10); we designate this best-performing model as CAG-VLM. These results\\ndemonstrate that specialized, fine-tuned VLMs can effectively assist\\ncardiologists in generating clinical reports and treatment recommendations from\\nCAG images.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T05:44:52Z\"}"}
