{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15903v1\", \"title\": \"Impact of Noise on LLM-Models Performance in Abstraction and Reasoning\\n  Corpus (ARC) Tasks with Model Temperature Considerations\", \"summary\": \"Recent advancements in Large Language Models (LLMs) have generated growing\\ninterest in their structured reasoning capabilities, particularly in tasks\\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\\ntesting how well AI models generalize to novel problems. While GPT-4o\\ndemonstrates strong performance by solving all ARC tasks under zero-noise\\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\\nsuggesting limitations in their ability to reason beyond simple pattern\\nmatching. To explore this gap, we systematically evaluate these models across\\ndifferent noise levels and temperature settings. Our results reveal that the\\nintroduction of noise consistently impairs model performance, regardless of\\narchitecture. This decline highlights a shared vulnerability: current LLMs,\\ndespite showing signs of abstract reasoning, remain highly sensitive to input\\nperturbations. Such fragility raises concerns about their real-world\\napplicability, where noise and uncertainty are common. By comparing how\\ndifferent model architectures respond to these challenges, we offer insights\\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\\nunderscores the need for developing more robust and adaptable AI systems\\ncapable of handling the ambiguity and variability inherent in real-world\\nscenarios. Our findings aim to guide future research toward enhancing model\\ngeneralization, robustness, and alignment with human-like cognitive\\nflexibility.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-22T13:43:58Z\"}"}
