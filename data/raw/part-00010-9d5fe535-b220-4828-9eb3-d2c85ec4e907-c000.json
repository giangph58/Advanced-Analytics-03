{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05651v1\", \"title\": \"Measuring D\\u00e9j\\u00e0 vu Memorization Efficiently\", \"summary\": \"Recent research has shown that representation learning models may\\naccidentally memorize their training data. For example, the d\\\\'ej\\\\`a vu method\\nshows that for certain representation learning models and training images, it\\nis sometimes possible to correctly predict the foreground label given only the\\nrepresentation of the background - better than through dataset-level\\ncorrelations. However, their measurement method requires training two models -\\none to estimate dataset-level correlations and the other to estimate\\nmemorization. This multiple model setup becomes infeasible for large\\nopen-source models. In this work, we propose alternative simple methods to\\nestimate dataset-level correlations, and show that these can be used to\\napproximate an off-the-shelf model's memorization ability without any\\nretraining. This enables, for the first time, the measurement of memorization\\nin pre-trained open-source image representation and vision-language\\nrepresentation models. Our results show that different ways of measuring\\nmemorization yield very similar aggregate results. We also find that\\nopen-source models typically have lower aggregate memorization than similar\\nmodels trained on a subset of the data. The code is available both for vision\\nand vision language models.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-08T03:55:20Z\"}"}
