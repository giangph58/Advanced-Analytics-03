{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11154v1\", \"title\": \"SAR-to-RGB Translation with Latent Diffusion for Earth Observation\", \"summary\": \"Earth observation satellites like Sentinel-1 (S1) and Sentinel-2 (S2) provide\\ncomplementary remote sensing (RS) data, but S2 images are often unavailable due\\nto cloud cover or data gaps. To address this, we propose a diffusion model\\n(DM)-based approach for SAR-to-RGB translation, generating synthetic optical\\nimages from SAR inputs. We explore three different setups: two using Standard\\nDiffusion, which reconstruct S2 images by adding and removing noise (one\\nwithout and one with class conditioning), and one using Cold Diffusion, which\\nblends S2 with S1 before removing the SAR signal. We evaluate the generated\\nimages in downstream tasks, including land cover classification and cloud\\nremoval. While generated images may not perfectly replicate real S2 data, they\\nstill provide valuable information. Our results show that class conditioning\\nimproves classification accuracy, while cloud removal performance remains\\ncompetitive despite our approach not being optimized for it. Interestingly,\\ndespite exhibiting lower perceptual quality, the Cold Diffusion setup performs\\nwell in land cover classification, suggesting that traditional quantitative\\nevaluation metrics may not fully reflect the practical utility of generated\\nimages. Our findings highlight the potential of DMs for SAR-to-RGB translation\\nin RS applications where RGB images are missing.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-15T12:58:30Z\"}"}
