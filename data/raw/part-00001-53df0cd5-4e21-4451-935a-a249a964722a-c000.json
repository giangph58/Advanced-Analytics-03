{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05309v1\", \"title\": \"Augmented Deep Contexts for Spatially Embedded Video Coding\", \"summary\": \"Most Neural Video Codecs (NVCs) only employ temporal references to generate\\ntemporal-only contexts and latent prior. These temporal-only NVCs fail to\\nhandle large motions or emerging objects due to limited contexts and misaligned\\nlatent prior. To relieve the limitations, we propose a Spatially Embedded Video\\nCodec (SEVC), in which the low-resolution video is compressed for spatial\\nreferences. Firstly, our SEVC leverages both spatial and temporal references to\\ngenerate augmented motion vectors and hybrid spatial-temporal contexts.\\nSecondly, to address the misalignment issue in latent prior and enrich the\\nprior information, we introduce a spatial-guided latent prior augmented by\\nmultiple temporal latent representations. At last, we design a joint\\nspatial-temporal optimization to learn quality-adaptive bit allocation for\\nspatial references, further boosting rate-distortion performance. Experimental\\nresults show that our SEVC effectively alleviates the limitations in handling\\nlarge motions or emerging objects, and also reduces 11.9% more bitrate than the\\nprevious state-of-the-art NVC while providing an additional low-resolution\\nbitstream. Our code and model are available at https://github.com/EsakaK/SEVC.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-05-08T14:57:52Z\"}"}
