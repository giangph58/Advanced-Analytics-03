{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15812v1\", \"title\": \"Fusing Reward and Dueling Feedback in Stochastic Bandits\", \"summary\": \"This paper investigates the fusion of absolute (reward) and relative\\n(dueling) feedback in stochastic bandits, where both feedback types are\\ngathered in each decision round. We derive a regret lower bound, demonstrating\\nthat an efficient algorithm may incur only the smaller among the reward and\\ndueling-based regret for each individual arm. We propose two fusion approaches:\\n(1) a simple elimination fusion algorithm that leverages both feedback types to\\nexplore all arms and unifies collected information by sharing a common\\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\\nmore effective feedback to explore the corresponding arms and randomly assigns\\none feedback type for exploration and the other for exploitation in each round.\\nThe elimination fusion experiences a suboptimal multiplicative term of the\\nnumber of arms in regret due to the intrinsic suboptimality of dueling\\nelimination. In contrast, the decomposition fusion achieves regret matching the\\nlower bound up to a constant under a common assumption. Extensive experiments\\nconfirm the efficacy of our algorithms and theoretical results.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-22T11:51:20Z\"}"}
