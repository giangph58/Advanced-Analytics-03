{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12229v1\", \"title\": \"Watermarking Needs Input Repetition Masking\", \"summary\": \"Recent advancements in Large Language Models (LLMs) raised concerns over\\npotential misuse, such as for spreading misinformation. In response two counter\\nmeasures emerged: machine learning-based detectors that predict if text is\\nsynthetic, and LLM watermarking, which subtly marks generated text for\\nidentification and attribution. Meanwhile, humans are known to adjust language\\nto their conversational partners both syntactically and lexically. By\\nimplication, it is possible that humans or unwatermarked LLMs could\\nunintentionally mimic properties of LLM generated text, making counter measures\\nunreliable. In this work we investigate the extent to which such conversational\\nadaptation happens. We call the concept $\\\\textit{mimicry}$ and demonstrate that\\nboth humans and LLMs end up mimicking, including the watermarking signal even\\nin seemingly improbable settings. This challenges current academic assumptions\\nand suggests that for long-term watermarking to be reliable, the likelihood of\\nfalse positives needs to be significantly lower, while longer word sequences\\nshould be used for seeding watermarking mechanisms.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CL,cs.CR\", \"published\": \"2025-04-16T16:25:26Z\"}"}
