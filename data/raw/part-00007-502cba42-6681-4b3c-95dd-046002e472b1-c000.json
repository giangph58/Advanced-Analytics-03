{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21581v1\", \"title\": \"Make Both Ends Meet: A Synergistic Optimization Infrared Small Target\\n  Detection with Streamlined Computational Overhead\", \"summary\": \"Infrared small target detection(IRSTD) is widely recognized as a challenging\\ntask due to the inherent limitations of infrared imaging, including low\\nsignal-to-noise ratios, lack of texture details, and complex background\\ninterference. While most existing methods model IRSTD as a semantic\\nsegmentation task, but they suffer from two critical drawbacks: (1)blurred\\ntarget boundaries caused by long-distance imaging dispersion; and (2) excessive\\ncomputational overhead due to indiscriminate feature stackin. To address these\\nissues, we propose the Lightweight Efficiency Infrared Small Target Detection\\n(LE-IRSTD), a lightweight and efficient framework based on YOLOv8n, with\\nfollowing key innovations. Firstly, we identify that the multiple bottleneck\\nstructures within the C2f component of the YOLOv8-n backbone contribute to an\\nincreased computational burden. Therefore, we implement the Mobile Inverted\\nBottleneck Convolution block (MBConvblock) and Bottleneck Structure block\\n(BSblock) in the backbone, effectively balancing the trade-off between\\ncomputational efficiency and the extraction of deep semantic information.\\nSecondly, we introduce the Attention-based Variable Convolution Stem (AVCStem)\\nstructure, substituting the final convolution with Variable Kernel Convolution\\n(VKConv), which allows for adaptive convolutional kernels that can transform\\ninto various shapes, facilitating the receptive field for the extraction of\\ntargets. Finally, we employ Global Shuffle Convolution (GSConv) to shuffle the\\nchannel dimension features obtained from different convolutional approaches,\\nthereby enhancing the robustness and generalization capabilities of our method.\\nExperimental results demonstrate that our LE-IRSTD method achieves compelling\\nresults in both accuracy and lightweight performance, outperforming several\\nstate-of-the-art deep learning methods.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV\", \"published\": \"2025-04-30T12:38:42Z\"}"}
