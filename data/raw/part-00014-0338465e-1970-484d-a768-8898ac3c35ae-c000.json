{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04311v1\", \"title\": \"How the Misuse of a Dataset Harmed Semantic Clone Detection\", \"summary\": \"BigCloneBench is a well-known and widely used large-scale dataset for the\\nevaluation of recall of clone detection tools. It has been beneficial for\\nresearch on clone detection and has become a standard in evaluating the\\nperformance of clone detection tools. More recently, it has also been widely\\nused as a dataset to evaluate machine learning approaches to semantic clone\\ndetection or code similarity detection for functional or semantic similarity.\\n  This paper demonstrates that BigCloneBench is problematic to use as ground\\ntruth for learning or evaluating semantic code similarity, and highlights the\\naspects of BigCloneBench that affect the ground truth quality. A manual\\ninvestigation of a statistically significant random sample of 406 Weak\\nType-3/Type-4 clone pairs revealed that 93% of them do not have a similar\\nfunctionality and are therefore mislabelled. In a literature review of 179\\npapers that use BigCloneBench as a dataset, we found 139 papers that used\\nBigCloneBench to evaluate semantic clone detection and where the results are\\nthreatened in their validity by the mislabelling. As such, these papers often\\nreport high F1 scores (e.g., above 0.9), which indicates overfitting to\\ndataset-specific artefacts rather than genuine semantic similarity detection.\\n  We emphasise that using BigCloneBench remains valid for the intended purpose\\nof evaluating syntactic or textual clone detection of Type-1, Type-2, and\\nType-3 clones. We acknowledge the important contributions of BigCloneBench to\\ntwo decades of traditional clone detection research. However, the usage of\\nBigCloneBench beyond the intended purpose without careful consideration of its\\nlimitations has led to misleading results and conclusions, and potentially\\nharmed the field of semantic clone detection.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-05-07T10:52:28Z\"}"}
