{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11919v1\", \"title\": \"Rethinking the Generation of High-Quality CoT Data from the Perspective\\n  of LLM-Adaptive Question Difficulty Grading\", \"summary\": \"Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its\\nexcellent reasoning ability in complex tasks and has publiclyshared its\\nmethodology. This provides potentially high-quality chain-of-thought (CoT) data\\nfor stimulating the reasoning abilities of small-sized large language models\\n(LLMs). To generate high-quality CoT data for different LLMs, we seek an\\nefficient method for generating high-quality CoT data with LLM-Adaptive\\nquestiondifficulty levels. First, we grade the difficulty of the questions\\naccording to the reasoning ability of the LLMs themselves and construct a\\nLLM-Adaptive question database. Second, we sample the problem database based on\\na distribution of difficulty levels of the questions and then use DeepSeek-R1\\n(671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality\\nCoT data with correct answers. Thanks to the construction of CoT data with\\nLLM-Adaptive difficulty levels, we have significantly reduced the cost of data\\ngeneration and enhanced the efficiency of model supervised fine-tuning (SFT).\\nFinally, we have validated the effectiveness and generalizability of the\\nproposed method in the fields of complex mathematical competitions and code\\ngeneration tasks. Notably, with only 2k high-quality mathematical CoT data, our\\nZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly,\\nwith only 2k high-quality code CoT data, our ZCode-32B surpasses\\nDeepSeek-Distill-32B in code reasoning tasks.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-16T09:55:34Z\"}"}
