{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12984v1\", \"title\": \"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM\\n  Serving\", \"summary\": \"Serving Large Language Models (LLMs) is critical for AI-powered applications\\nbut demands substantial computational resources, particularly in memory\\nbandwidth and computational throughput. Low-precision computation has emerged\\nas a key technique to improve efficiency while reducing resource consumption.\\nExisting approaches for generating low-precision kernels are limited to weight\\nbit widths that are powers of two and suffer from suboptimal performance due to\\nhigh-level GPU programming abstractions. These abstractions restrict critical\\noptimizations, such as fine-grained register management and optimized memory\\naccess patterns, which are essential for efficient low-precision computations.\\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\\nGPU (GPGPU) computing, enabling support for low-precision data types with\\narbitrary bit widths while maintaining GPU programmability. The proposed VM\\nfeatures a thread-block-level programming model, a hierarchical memory space, a\\nnovel algebraic layout system, and extensive support for diverse low-precision\\ndata types. VM programs are compiled into highly efficient GPU programs with\\nautomatic vectorization and instruction selection. Extensive experiments\\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\\ndata types, and outperforms state-of-the-art low-precision kernels on their\\nsupported types. Compared to existing compilers like Triton and Ladder, as well\\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.PL\", \"published\": \"2025-04-17T14:45:03Z\"}"}
