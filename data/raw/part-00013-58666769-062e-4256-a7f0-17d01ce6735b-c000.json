{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20509v1\", \"title\": \"MambaMoE: Mixture-of-Spectral-Spatial-Experts State Space Model for\\n  Hyperspectral Image Classification\", \"summary\": \"The Mamba model has recently demonstrated strong potential in hyperspectral\\nimage (HSI) classification, owing to its ability to perform context modeling\\nwith linear computational complexity. However, existing Mamba-based methods\\nusually neglect the spectral and spatial directional characteristics related to\\nheterogeneous objects in hyperspectral scenes, leading to limited\\nclassification performance. To address these issues, we propose MambaMoE, a\\nnovel spectral-spatial mixture-of-experts framework, representing the first\\nMoE-based approach in the HSI classification community. Specifically, we design\\na Mixture of Mamba Expert Block (MoMEB) that leverages sparse expert activation\\nto enable adaptive spectral-spatial modeling. Furthermore, we introduce an\\nuncertainty-guided corrective learning (UGCL) strategy to encourage the model's\\nattention toward complex regions prone to prediction ambiguity. Extensive\\nexperiments on multiple public HSI benchmarks demonstrate that MambaMoE\\nachieves state-of-the-art performance in both accuracy and efficiency compared\\nto existing advanced approaches, especially for Mamba-based methods. Code will\\nbe released.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-29T07:50:36Z\"}"}
