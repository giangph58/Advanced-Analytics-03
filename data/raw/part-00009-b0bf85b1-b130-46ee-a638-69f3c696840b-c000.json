{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19933v1\", \"title\": \"Automated decision-making for dynamic task assignment at scale\", \"summary\": \"The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\\ntasks in real time while minimizing some objectives, like resource costs or\\ntask cycle time. In this work, we consider a DTAP variant where every task is a\\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\\ninvolves the decision of which employee to assign to which activity to process\\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\\nresearch is limited to solving small-scale, synthetic problems, neglecting the\\nchallenges posed by real-world use cases. To bridge this gap, this work\\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\\nTo this end, we introduce a DRL agent with two novel elements: a graph\\nstructure for observations and actions that can effectively represent any DTAP\\nand a reward function that is provably equivalent to the objective of\\nminimizing the average cycle time of tasks. The combination of these two\\nnovelties allows the agent to learn effective and generalizable assignment\\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\\ninstances whose parameters are extracted from real-world logs through process\\nmining. The experimental evaluation shows how the proposed DRL agent matches or\\noutperforms the best baseline in all DTAP instances and generalizes on\\ndifferent time horizons and across instances.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.LG,math.OC\", \"published\": \"2025-04-28T16:08:35Z\"}"}
