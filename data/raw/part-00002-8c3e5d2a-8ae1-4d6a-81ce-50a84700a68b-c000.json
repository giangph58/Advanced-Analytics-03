{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12753v1\", \"title\": \"Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges\\n  Domain Generalized Semantic Segmentation\", \"summary\": \"Vision Foundation Models (VFMs) have delivered remarkable performance in\\nDomain Generalized Semantic Segmentation (DGSS). However, recent methods often\\noverlook the fact that visual cues are susceptible, whereas the underlying\\ngeometry remains stable, rendering depth information more robust. In this\\npaper, we investigate the potential of integrating depth information with\\nfeatures from VFMs, to improve the geometric consistency within an image and\\nboost the generalization performance of VFMs. We propose a novel fine-tuning\\nDGSS framework, named DepthForge, which integrates the visual cues from frozen\\nDINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of\\nthe VFMs, we incorporate depth-aware learnable tokens to continuously decouple\\ndomain-invariant visual and spatial information, thereby enhancing depth\\nawareness and attention of the VFMs. Finally, we develop a depth refinement\\ndecoder and integrate it into the model architecture to adaptively refine\\nmulti-layer VFM features and depth-aware learnable tokens. Extensive\\nexperiments are conducted based on various DGSS settings and five different\\ndatsets as unseen target domains. The qualitative and quantitative results\\ndemonstrate that our method significantly outperforms alternative approaches\\nwith stronger performance, steadier visual-spatial attention, and superior\\ngeneralization ability. In particular, DepthForge exhibits outstanding\\nperformance under extreme conditions (e.g., night and snow). Code is available\\nat https://github.com/anonymouse-xzrptkvyqc/DepthForge.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T08:45:33Z\"}"}
