{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05016v1\", \"title\": \"The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based\\n  Aggregation for Group Recommendations\", \"summary\": \"Large Language Models (LLMs) are increasingly applied in recommender systems\\naimed at both individuals and groups. Previously, Group Recommender Systems\\n(GRS) often used social choice-based aggregation strategies to derive a single\\nrecommendation based on the preferences of multiple people. In this paper, we\\ninvestigate under which conditions language models can perform these strategies\\ncorrectly based on zero-shot learning and analyse whether the formatting of the\\ngroup scenario in the prompt affects accuracy. We specifically focused on the\\nimpact of group complexity (number of users and items), different LLMs,\\ndifferent prompting conditions, including In-Context learning or generating\\nexplanations, and the formatting of group preferences. Our results show that\\nperformance starts to deteriorate when considering more than 100 ratings.\\nHowever, not all language models were equally sensitive to growing group\\ncomplexity. Additionally, we showed that In-Context Learning (ICL) can\\nsignificantly increase the performance at higher degrees of group complexity,\\nwhile adding other prompt modifications, specifying domain cues or prompting\\nfor explanations, did not impact accuracy. We conclude that future research\\nshould include group complexity as a factor in GRS evaluation due to its effect\\non LLM performance. Furthermore, we showed that formatting the group scenarios\\ndifferently, such as rating lists per user or per item, affected accuracy. All\\nin all, our study implies that smaller LLMs are capable of generating group\\nrecommendations under the right conditions, making the case for using smaller\\nmodels that require less computing power and costs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.IR\", \"published\": \"2025-05-08T07:43:01Z\"}"}
