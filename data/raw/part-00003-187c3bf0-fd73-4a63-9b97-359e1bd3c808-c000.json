{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05190v1\", \"title\": \"Revealing Weaknesses in Text Watermarking Through Self-Information\\n  Rewrite Attacks\", \"summary\": \"Text watermarking aims to subtly embed statistical signals into text by\\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\\nwatermark detectors to verify that the output was generated by the specified\\nmodel. The robustness of these watermarking algorithms has become a key factor\\nin evaluating their effectiveness. Current text watermarking algorithms embed\\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\\nreveal that this seemingly benign design can be exploited by attackers, posing\\na significant risk to the robustness of the watermark. We introduce a generic\\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\\nwhich leverages the vulnerability by calculating the self-information of each\\ntoken to identify potential pattern tokens and perform targeted attack. Our\\nwork exposes a widely prevalent vulnerability in current watermarking\\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\\nmillion tokens cost. Our approach does not require any access to the watermark\\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\\nattack model, even mobile-level models. Our findings highlight the urgent need\\nfor more robust watermarking.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CL,cs.CR\", \"published\": \"2025-05-08T12:39:00Z\"}"}
