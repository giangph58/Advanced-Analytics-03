{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10167v1\", \"title\": \"C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination\\n  Evaluation\", \"summary\": \"Despite the rapid advancement of large language models, they remain highly\\nsusceptible to generating hallucinations, which significantly hinders their\\nwidespread application. Hallucination research requires dynamic and\\nfine-grained evaluation. However, most existing hallucination benchmarks\\n(especially in Chinese language) rely on human annotations, making automatical\\nand cost-effective hallucination evaluation challenging. To address this, we\\nintroduce HaluAgent, an agentic framework that automatically constructs\\nfine-grained QA dataset based on some knowledge documents. Our experiments\\ndemonstrate that the manually designed rules and prompt optimization can\\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\\nChinese QA hallucination benchmark created from 1,399 knowledge documents\\nobtained from web scraping, totaling 60,702 entries. We comprehensively\\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\\nexperimental results and analysis.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-14T12:21:55Z\"}"}
