{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03563v1\", \"title\": \"Say It Another Way: A Framework for User-Grounded Paraphrasing\", \"summary\": \"Small changes in how a prompt is worded can lead to meaningful differences in\\nthe behavior of large language models (LLMs), raising concerns about the\\nstability and reliability of their evaluations. While prior work has explored\\nsimple formatting changes, these rarely capture the kinds of natural variation\\nseen in real-world language use. We propose a controlled paraphrasing framework\\nbased on a taxonomy of minimal linguistic transformations to systematically\\ngenerate natural prompt variations. Using the BBQ dataset, we validate our\\nmethod with both human annotations and automated checks, then use it to study\\nhow LLMs respond to paraphrased prompts in stereotype evaluation tasks. Our\\nanalysis shows that even subtle prompt modifications can lead to substantial\\nchanges in model behavior. These results highlight the need for robust,\\nparaphrase-aware evaluation protocols.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-05-06T14:17:30Z\"}"}
