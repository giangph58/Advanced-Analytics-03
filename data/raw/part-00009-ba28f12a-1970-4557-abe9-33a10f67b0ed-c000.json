{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20469v1\", \"title\": \"Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large\\n  Language Models\", \"summary\": \"Understanding how news narratives frame entities is crucial for studying\\nmedia's impact on societal perceptions of events. In this paper, we evaluate\\nthe zero-shot capabilities of large language models (LLMs) in classifying\\nframing roles. Through systematic experimentation, we assess the effects of\\ninput context, prompting strategies, and task decomposition. Our findings show\\nthat a hierarchical approach of first identifying broad roles and then\\nfine-grained roles, outperforms single-step classification. We also demonstrate\\nthat optimal input contexts and prompts vary across task levels, highlighting\\nthe need for subtask-specific strategies. We achieve a Main Role Accuracy of\\n89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our\\napproach. Our findings emphasize the importance of tailored prompt design and\\ninput context optimization for improving LLM performance in entity framing.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CY,I.2.7\", \"published\": \"2025-04-29T07:10:53Z\"}"}
