{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14857v1\", \"title\": \"SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor\\n  Policy Learning in Surgical Subtasks\", \"summary\": \"Behavior cloning facilitates the learning of dexterous manipulation skills,\\nyet the complexity of surgical environments, the difficulty and expense of\\nobtaining patient data, and robot calibration errors present unique challenges\\nfor surgical robot learning. We provide an enhanced surgical digital twin with\\nphotorealistic human anatomical organs, integrated into a comprehensive\\nsimulator designed to generate high-quality synthetic data to solve fundamental\\ntasks in surgical autonomy. We present SuFIA-BC: visual Behavior Cloning\\npolicies for Surgical First Interactive Autonomy Assistants. We investigate\\nvisual observation spaces including multi-view cameras and 3D visual\\nrepresentations extracted from a single endoscopic camera view. Through\\nsystematic evaluation, we find that the diverse set of photorealistic surgical\\ntasks introduced in this work enables a comprehensive evaluation of prospective\\nbehavior cloning models for the unique challenges posed by surgical\\nenvironments. We observe that current state-of-the-art behavior cloning\\ntechniques struggle to solve the contact-rich and complex tasks evaluated in\\nthis work, regardless of their underlying perception or control architectures.\\nThese findings highlight the importance of customizing perception pipelines and\\ncontrol architectures, as well as curating larger-scale synthetic datasets that\\nmeet the specific demands of surgical tasks. Project website:\\nhttps://orbit-surgical.github.io/sufia-bc/\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-21T04:50:24Z\"}"}
