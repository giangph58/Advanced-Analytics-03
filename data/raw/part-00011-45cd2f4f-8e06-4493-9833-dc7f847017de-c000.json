{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04879v1\", \"title\": \"Mixed memories in Hopfield networks\", \"summary\": \"We consider the class of Hopfield models of associative memory with\\nactivation function $F$ and state space $\\\\{-1,1\\\\}^N$, where each vertex of the\\ncube describes a configuration of $N$ binary neurons. $M$ randomly chosen\\nconfigurations, called patterns, are stored using an energy function designed\\nto make them local minima. If they are, which is known to depend on how $M$\\nscales with $N$, then they can be retrieved using a dynamics that decreases the\\nenergy. However, storing the patterns in the energy function also creates\\nunintended local minima, and thus false memories. Although this has been known\\nsince the earliest work on the subject, it has only been supported by numerical\\nsimulations and non-rigorous calculations, except in elementary cases.\\n  Our results are twofold. For a generic function $F$, we explicitly construct\\na set of configurations, called mixed memories, whose properties are intended\\nto characterise the local minima of the energy function. For three prominent\\nmodels, namely the classical, the dense and the modern Hopfield models,\\nobtained for quadratic, polynomial and exponential functions $F$ respectively,\\nwe give conditions on the growth rate of $M$ which guarantee that, as $N$\\ndiverges, mixed memories are fixed points of the retrieval dynamics and thus\\nexact minima of the energy. We conjecture that in this regime, all local minima\\nare mixed memories.\", \"main_category\": \"math.PR\", \"categories\": \"math.PR\", \"published\": \"2025-04-07T09:41:49Z\"}"}
