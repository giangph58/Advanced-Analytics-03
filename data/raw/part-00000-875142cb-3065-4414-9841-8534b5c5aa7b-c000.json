{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12681v1\", \"title\": \"GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in\\n  LLMs\", \"summary\": \"Large Language Models (LLMs) trained on extensive datasets often learn\\nsensitive information, which raises significant social and legal concerns under\\nprinciples such as the \\\"Right to be forgotten.\\\" Retraining entire models from\\nscratch to remove undesired information is both costly and impractical.\\nFurthermore, existing single-domain unlearning methods fail to address\\nmulti-domain scenarios, where knowledge is interwoven across domains such as\\nprivacy and copyright, creating overlapping representations that lead to\\nexcessive knowledge removal or degraded performance. To tackle these issues, we\\npropose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain\\nunlearning framework. GRAIL leverages gradient information from multiple\\ndomains to precisely distinguish the unlearning scope from the retention scope,\\nand applies an adaptive parameter-wise localization strategy to selectively\\nremove targeted knowledge while preserving critical parameters for each domain.\\nExperimental results on unlearning benchmarks show that GRAIL achieves\\nunlearning success on par with the existing approaches, while also\\ndemonstrating up to 17% stronger knowledge retention success compared to the\\nprevious state-of-art method. Our findings establish a new paradigm for\\neffectively managing and regulating sensitive information in large-scale\\npre-trained language models.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-17T06:16:32Z\"}"}
