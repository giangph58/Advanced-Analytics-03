{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11101v1\", \"title\": \"Consensus Entropy: Harnessing Multi-VLM Agreement for Self-Verifying and\\n  Self-Improving OCR\", \"summary\": \"The Optical Character Recognition (OCR) task is important for evaluating\\nVision-Language Models (VLMs) and providing high-quality data sources for LLM\\ntraining data. While state-of-the-art VLMs show improved average OCR accuracy,\\nthey still struggle with sample-level quality degradation and lack reliable\\nautomatic detection of low-quality outputs. We introduce Consensus Entropy\\n(CE), a training-free post-inference method that quantifies OCR uncertainty by\\naggregating outputs from multiple VLMs. Our approach exploits a key insight:\\ncorrect VLM OCR predictions converge in output space while errors diverge. We\\ndevelop a lightweight multi-model framework that effectively identifies\\nproblematic samples, selects the best outputs and combines model strengths.\\nExperiments across multiple OCR benchmarks and VLMs demonstrate that CE\\noutperforms VLM-as-judge approaches and single-model baselines at the same cost\\nand achieves state-of-the-art results across multiple metrics. For instance,\\nour solution demonstrates: achieving 15.2\\\\% higher F1 scores than VLM-as-judge\\nmethods in quality verification, delivering 6.0\\\\% accuracy gains on\\nmathematical calculation tasks, and requiring rephrasing only 7.3\\\\% of inputs\\nwhile maintaining overall performance. Notably, the entire process requires\\nneither training nor supervision while maintaining plug-and-play functionality\\nthroughout.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.MM\", \"published\": \"2025-04-15T11:51:18Z\"}"}
