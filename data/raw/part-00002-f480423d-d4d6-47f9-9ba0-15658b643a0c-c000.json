{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11457v1\", \"title\": \"Aligning Generative Denoising with Discriminative Objectives Unleashes\\n  Diffusion for Visual Perception\", \"summary\": \"With the success of image generation, generative diffusion models are\\nincreasingly adopted for discriminative tasks, as pixel generation provides a\\nunified perception interface. However, directly repurposing the generative\\ndenoising process for discriminative objectives reveals critical gaps rarely\\naddressed previously. Generative models tolerate intermediate sampling errors\\nif the final distribution remains plausible, but discriminative tasks require\\nrigorous accuracy throughout, as evidenced in challenging multi-modal tasks\\nlike referring image segmentation. Motivated by this gap, we analyze and\\nenhance alignment between generative diffusion processes and perception tasks,\\nfocusing on how perception quality evolves during denoising. We find: (1)\\nearlier denoising steps contribute disproportionately to perception quality,\\nprompting us to propose tailored learning objectives reflecting varying\\ntimestep contributions; (2) later denoising steps show unexpected perception\\ndegradation, highlighting sensitivity to training-denoising distribution\\nshifts, addressed by our diffusion-tailored data augmentation; and (3)\\ngenerative processes uniquely enable interactivity, serving as controllable\\nuser interfaces adaptable to correctional prompts in multi-round interactions.\\nOur insights significantly improve diffusion-based perception models without\\narchitectural changes, achieving state-of-the-art performance on depth\\nestimation, referring image segmentation, and generalist perception tasks. Code\\navailable at https://github.com/ziqipang/ADDP.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T17:59:54Z\"}"}
