{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02478v1\", \"title\": \"MG-MotionLLM: A Unified Framework for Motion Comprehension and\\n  Generation across Multiple Granularities\", \"summary\": \"Recent motion-aware large language models have demonstrated promising\\npotential in unifying motion comprehension and generation. However, existing\\napproaches primarily focus on coarse-grained motion-text modeling, where text\\ndescribes the overall semantics of an entire motion sequence in just a few\\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\\nsuch as understanding and controlling the movements of specific body parts. To\\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\\nmodel for multi-granular motion comprehension and generation. We further\\nintroduce a comprehensive multi-granularity training scheme by incorporating a\\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\\nsegments via detailed text as well as motion detailed captioning, to facilitate\\nmutual reinforcement for motion-text modeling across various levels of\\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\\npotential in novel fine-grained motion comprehension and editing tasks. Project\\npage: CVI-SZU/MG-MotionLLM\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T10:53:41Z\"}"}
