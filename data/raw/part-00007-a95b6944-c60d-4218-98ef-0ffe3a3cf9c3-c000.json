{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10139v1\", \"title\": \"Conditional Distribution Compression via the Kernel Conditional Mean\\n  Embedding\", \"summary\": \"Existing distribution compression methods, like Kernel Herding (KH), were\\noriginally developed for unlabelled data. However, no existing approach\\ndirectly compresses the conditional distribution of labelled data. To address\\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\\n(AMCMD), a natural metric for comparing conditional distributions. We then\\nderive a consistent estimator for the AMCMD and establish its rate of\\nconvergence. Next, we make a key observation: in the context of distribution\\ncompression, the cost of constructing a compressed set targeting the AMCMD can\\nbe reduced from $\\\\mathcal{O}(n^3)$ to $\\\\mathcal{O}(n)$. Building on this, we\\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\\nlinear-time greedy algorithm that constructs a compressed set targeting the\\nAMCMD. To better understand the advantages of directly compressing the\\nconditional distribution rather than doing so via the joint distribution, we\\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\\ndesigned to compress the joint distribution of labelled data. While herding\\nmethods provide a simple and interpretable selection process, they rely on a\\ngreedy heuristic. To explore alternative optimisation strategies, we propose\\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\\nlinear complexity. Experiments show that directly preserving conditional\\ndistributions with ACKIP outperforms both joint distribution compression (via\\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\\nconsistently outperforms JKH.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG,stat.CO,stat.ME\", \"published\": \"2025-04-14T11:53:29Z\"}"}
