{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05022v1\", \"title\": \"SOAP: Style-Omniscient Animatable Portraits\", \"summary\": \"Creating animatable 3D avatars from a single image remains challenging due to\\nstyle limitations (realistic, cartoon, anime) and difficulties in handling\\naccessories or hairstyles. While 3D diffusion models advance single-view\\nreconstruction for general objects, outputs often lack animation controls or\\nsuffer from artifacts because of the domain gap. We propose SOAP, a\\nstyle-omniscient framework to generate rigged, topology-consistent avatars from\\nany portrait. Our method leverages a multiview diffusion model trained on 24K\\n3D heads with multiple styles and an adaptive optimization pipeline to deform\\nthe FLAME mesh while maintaining topology and rigging via differentiable\\nrendering. The resulting textured avatars support FACS-based animation,\\nintegrate with eyeballs and teeth, and preserve details like braided hair or\\naccessories. Extensive experiments demonstrate the superiority of our method\\nover state-of-the-art techniques for both single-view head modeling and\\ndiffusion-based generation of Image-to-3D. Our code and data are publicly\\navailable for research purposes at https://github.com/TingtingLiao/soap.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T07:56:16Z\"}"}
