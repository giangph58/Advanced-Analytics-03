{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20026v1\", \"title\": \"LIRM: Large Inverse Rendering Model for Progressive Reconstruction of\\n  Shape, Materials and View-dependent Radiance Fields\", \"summary\": \"We present Large Inverse Rendering Model (LIRM), a transformer architecture\\nthat jointly reconstructs high-quality shape, materials, and radiance fields\\nwith view-dependent effects in less than a second. Our model builds upon the\\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\\nsparse-view reconstruction quality. However, existing LRMs struggle to\\nreconstruct unseen parts accurately and cannot recover glossy appearance or\\ngenerate relightable 3D contents that can be consumed by standard Graphics\\nengines. To address these limitations, we make three key technical\\ncontributions to build a more practical multi-view 3D reconstruction framework.\\nFirst, we introduce an update model that allows us to progressively add more\\ninput views to improve our reconstruction. Second, we propose a hexa-plane\\nneural SDF representation to better recover detailed textures, geometry and\\nmaterial parameters. Third, we develop a novel neural directional-embedding\\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\\nachieves compelling results. It compares favorably to optimization-based\\ndense-view inverse rendering methods in terms of geometry and relighting\\naccuracy, while requiring only a fraction of the inference time.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-28T17:48:58Z\"}"}
