{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05223v1\", \"title\": \"Multi-Objective Reinforcement Learning for Adaptive Personalized\\n  Autonomous Driving\", \"summary\": \"Human drivers exhibit individual preferences regarding driving style.\\nAdapting autonomous vehicles to these preferences is essential for user trust\\nand satisfaction. However, existing end-to-end driving approaches often rely on\\npredefined driving styles or require continuous user feedback for adaptation,\\nlimiting their ability to support dynamic, context-dependent preferences. We\\npropose a novel approach using multi-objective reinforcement learning (MORL)\\nwith preference-driven optimization for end-to-end autonomous driving that\\nenables runtime adaptation to driving style preferences. Preferences are\\nencoded as continuous weight vectors to modulate behavior along interpretable\\nstyle objectives$\\\\unicode{x2013}$including efficiency, comfort, speed, and\\naggressiveness$\\\\unicode{x2013}$without requiring policy retraining. Our\\nsingle-policy agent integrates vision-based perception in complex mixed-traffic\\nscenarios and is evaluated in diverse urban environments using the CARLA\\nsimulator. Experimental results demonstrate that the agent dynamically adapts\\nits driving behavior according to changing preferences while maintaining\\nperformance in terms of collision avoidance and route completion.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.CV,cs.LG\", \"published\": \"2025-05-08T13:16:37Z\"}"}
