{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04787v1\", \"title\": \"Dynamic Vision Mamba\", \"summary\": \"Mamba-based vision models have gained extensive attention as a result of\\nbeing computationally more efficient than attention-based models. However,\\nspatial redundancy still exists in these models, represented by token and block\\nredundancy. For token redundancy, we analytically find that early token pruning\\nmethods will result in inconsistency between training and inference or\\nintroduce extra computation for inference. Therefore, we customize token\\npruning to fit the Mamba structure by rearranging the pruned sequence before\\nfeeding it into the next Mamba block. For block redundancy, we allow each image\\nto select SSM blocks dynamically based on an empirical observation that the\\ninference speed of Mamba-based vision models is largely affected by the number\\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\\\%\\nFLOPs with only a loss of accuracy of 1.7\\\\% on Vim-S. It also generalizes well\\nacross different Mamba vision model architectures and different vision tasks.\\nOur code will be made public.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T07:31:28Z\"}"}
