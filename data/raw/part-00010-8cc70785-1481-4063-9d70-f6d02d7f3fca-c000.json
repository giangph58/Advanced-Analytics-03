{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00333v1\", \"title\": \"Communication-Efficient Wireless Federated Fine-Tuning for Large-Scale\\n  AI Models\", \"summary\": \"Transformer-based large language models (LLMs) have achieved remarkable\\nsuccess across various tasks. Yet, fine-tuning such massive models in federated\\nlearning (FL) settings poses significant challenges due to resource constraints\\nand communication overhead. Low-Rank Adaptation (LoRA) addresses these issues\\nby training compact, low-rank matrices instead of fully fine-tuning large\\nmodels. This paper introduces a wireless federated LoRA fine-tuning framework\\nthat optimizes both learning performance and communication efficiency. We\\nprovide a novel convergence analysis, revealing how LoRA rank and covariance\\neffects influence FL training dynamics. Leveraging these insights, we propose\\nSparsified Orthogonal Fine-Tuning (\\\\textbf{SOFT}), an adaptive sparsification\\nmethod that streamlines parameter updates without expensive matrix\\nmultiplications and singular value decomposition (SVD) operations.\\nAdditionally, we present a Two Stage Federated Algorithm (\\\\textbf{TSFA})\\nalgorithm that pre-determines key parameters offline and dynamically adjusts\\nbandwidth and sparsification online, ensuring efficient training under latency\\nconstraints. Experiments on benchmark datasets show that our approach achieves\\naccuracy comparable to ideal scenario models while significantly reducing\\ncommunication overhead. Our framework thus enables scalable, resource-efficient\\ndeployment of large models in real-world wireless FL scenarios.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,eess.SP\", \"published\": \"2025-05-01T06:15:38Z\"}"}
