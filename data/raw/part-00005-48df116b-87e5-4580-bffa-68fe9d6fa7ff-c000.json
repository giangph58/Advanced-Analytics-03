{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20974v1\", \"title\": \"Equivariant non-linear maps for neural networks on homogeneous spaces\", \"summary\": \"This paper presents a novel framework for non-linear equivariant neural\\nnetwork layers on homogeneous spaces. The seminal work of Cohen et al. on\\nequivariant $G$-CNNs on homogeneous spaces characterized the representation\\ntheory of such layers in the linear setting, finding that they are given by\\nconvolutions with kernels satisfying so-called steerability constraints.\\nMotivated by the empirical success of non-linear layers, such as self-attention\\nor input dependent kernels, we set out to generalize these insights to the\\nnon-linear setting. We derive generalized steerability constraints that any\\nsuch layer needs to satisfy and prove the universality of our construction. The\\ninsights gained into the symmetry-constrained functional dependence of\\nequivariant operators on feature maps and group elements informs the design of\\nfuture equivariant neural network layers. We demonstrate how several common\\nequivariant network architectures - $G$-CNNs, implicit steerable kernel\\nnetworks, conventional and relative position embedded attention based\\ntransformers, and LieTransformers - may be derived from our framework.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,math.RT,stat.ML\", \"published\": \"2025-04-29T17:42:56Z\"}"}
