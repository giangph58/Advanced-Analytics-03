{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14882v1\", \"title\": \"Some Optimizers are More Equal: Understanding the Role of Optimizers in\\n  Group Fairness\", \"summary\": \"We study whether and how the choice of optimization algorithm can impact\\ngroup fairness in deep neural networks. Through stochastic differential\\nequation analysis of optimization dynamics in an analytically tractable setup,\\nwe demonstrate that the choice of optimization algorithm indeed influences\\nfairness outcomes, particularly under severe imbalance. Furthermore, we show\\nthat when comparing two categories of optimizers, adaptive methods and\\nstochastic methods, RMSProp (from the adaptive category) has a higher\\nlikelihood of converging to fairer minima than SGD (from the stochastic\\ncategory). Building on this insight, we derive two new theoretical guarantees\\nshowing that, under appropriate conditions, RMSProp exhibits fairer parameter\\nupdates and improved fairness in a single optimization step compared to SGD. We\\nthen validate these findings through extensive experiments on three publicly\\navailable datasets, namely CelebA, FairFace, and MS-COCO, across different\\ntasks as facial expression recognition, gender classification, and multi-label\\nclassification, using various backbones. Considering multiple fairness\\ndefinitions including equalized odds, equal opportunity, and demographic\\nparity, adaptive optimizers like RMSProp and Adam consistently outperform SGD\\nin terms of group fairness, while maintaining comparable predictive accuracy.\\nOur results highlight the role of adaptive updates as a crucial yet overlooked\\nmechanism for promoting fair outcomes.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV,stat.ML\", \"published\": \"2025-04-21T06:20:50Z\"}"}
