{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05084v1\", \"title\": \"Speech-to-Trajectory: Learning Human-Like Verbal Guidance for Robot\\n  Motion\", \"summary\": \"Full integration of robots into real-life applications necessitates their\\nability to interpret and execute natural language directives from untrained\\nusers. Given the inherent variability in human language, equivalent directives\\nmay be phrased differently, yet require consistent robot behavior. While Large\\nLanguage Models (LLMs) have advanced language understanding, they often falter\\nin handling user phrasing variability, rely on predefined commands, and exhibit\\nunpredictable outputs. This letter introduces the Directive Language Model\\n(DLM), a novel speech-to-trajectory framework that directly maps verbal\\ncommands to executable motion trajectories, bypassing predefined phrases. DLM\\nutilizes Behavior Cloning (BC) on simulated demonstrations of human-guided\\nrobot motion. To enhance generalization, GPT-based semantic augmentation\\ngenerates diverse paraphrases of training commands, labeled with the same\\nmotion trajectory. DLM further incorporates a diffusion policy-based trajectory\\ngeneration for adaptive motion refinement and stochastic sampling. In contrast\\nto LLM-based methods, DLM ensures consistent, predictable motion without\\nextensive prompt engineering, facilitating real-time robotic guidance. As DLM\\nlearns from trajectory data, it is embodiment-agnostic, enabling deployment\\nacross diverse robotic platforms. Experimental results demonstrate DLM's\\nimproved command generalization, reduced dependence on structured phrasing, and\\nachievement of human-like motion.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-07T13:54:08Z\"}"}
