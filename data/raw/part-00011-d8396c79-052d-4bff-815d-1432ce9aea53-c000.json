{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12151v1\", \"title\": \"Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment\\n  Analysis\", \"summary\": \"Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\\nof interpretability in the decision logic of multimodal fusion and modality\\nimbalance caused by disparities in inter-modal information density. To address\\nthese issues, we propose KAN-MCP, a novel framework that integrates the\\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\\nunivariate function decomposition to achieve transparent analysis of\\ncross-modal interactions. This structural design allows direct inspection of\\nfeature transformations without relying on external interpretation tools,\\nthereby ensuring both high expressiveness and interpretability. Second, the\\nproposed MCPareto enhances robustness by addressing modality imbalance and\\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\\nand reduces feature dimensionality. This approach provides KAN with\\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\\ndynamically balances gradient contributions across modalities using the\\npurified features output by DRD-MIB, ensuring lossless transmission of\\nauxiliary signals and effectively alleviating modality imbalance. This synergy\\nof interpretability and robustness not only achieves superior performance on\\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\\nan intuitive visualization interface through KAN's interpretable architecture.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-16T15:00:06Z\"}"}
