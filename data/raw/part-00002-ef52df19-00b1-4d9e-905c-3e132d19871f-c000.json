{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20040v1\", \"title\": \"MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion\", \"summary\": \"While Structure-from-Motion (SfM) has seen much progress over the years,\\nstate-of-the-art systems are prone to failure when facing extreme viewpoint\\nchanges in low-overlap, low-parallax or high-symmetry scenarios. Because\\ncapturing images that avoid these pitfalls is challenging, this severely limits\\nthe wider use of SfM, especially by non-expert users. We overcome these\\nlimitations by augmenting the classical SfM paradigm with monocular depth and\\nnormal priors inferred by deep neural networks. Thanks to a tight integration\\nof monocular and multi-view constraints, our approach significantly outperforms\\nexisting ones under extreme viewpoint changes, while maintaining strong\\nperformance in standard conditions. We also show that monocular priors can help\\nreject faulty associations due to symmetries, which is a long-standing problem\\nfor SfM. This makes our approach the first capable of reliably reconstructing\\nchallenging indoor environments from few images. Through principled uncertainty\\npropagation, it is robust to errors in the priors, can handle priors inferred\\nby different models with little tuning, and will thus easily benefit from\\nfuture progress in monocular depth and normal estimation. Our code is publicly\\navailable at https://github.com/cvg/mpsfm.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-04-28T17:59:52Z\"}"}
