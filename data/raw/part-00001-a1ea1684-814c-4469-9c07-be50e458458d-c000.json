{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04728v1\", \"title\": \"Exploring Kernel Transformations for Implicit Neural Representations\", \"summary\": \"Implicit neural representations (INRs), which leverage neural networks to\\nrepresent signals by mapping coordinates to their corresponding attributes,\\nhave garnered significant attention. They are extensively utilized for image\\nrepresentation, with pixel coordinates as input and pixel values as output. In\\ncontrast to prior works focusing on investigating the effect of the model's\\ninside components (activation function, for instance), this work pioneers the\\nexploration of the effect of kernel transformation of input/output while\\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\\neffective method that combines scale and shift to significantly boost INR with\\nnegligible computation overhead. Moreover, we present two perspectives, depth\\nand normalization, to interpret the performance benefits caused by scale and\\nshift transformation. Overall, our work provides a new avenue for future works\\nto understand and improve INR through the lens of kernel transformation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T04:43:50Z\"}"}
