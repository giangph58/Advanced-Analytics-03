{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20814v1\", \"title\": \"Secure Coding with AI, From Creation to Inspection\", \"summary\": \"While prior studies have explored security in code generated by ChatGPT and\\nother Large Language Models, they were conducted in controlled experimental\\nsettings and did not use code generated or provided from actual developer\\ninteractions. This paper not only examines the security of code generated by\\nChatGPT based on real developer interactions, curated in the DevGPT dataset,\\nbut also assesses ChatGPT's capability to find and fix these vulnerabilities.\\nWe analysed 1,586 C, C++, and C# code snippets using static scanners, which\\ndetected potential issues in 124 files. After manual analysis, we selected 26\\nfiles with 32 confirmed vulnerabilities for further investigation.\\n  We submitted these files to ChatGPT via the OpenAI API, asking it to detect\\nsecurity issues, identify the corresponding Common Weakness Enumeration\\nnumbers, and propose fixes. The responses and modified code were manually\\nreviewed and re-scanned for vulnerabilities. ChatGPT successfully detected 18\\nout of 32 security issues and resolved 17 issues but failed to recognize or fix\\nthe remainder. Interestingly, only 10 vulnerabilities were resulted from the\\nuser prompts, while 22 were introduced by ChatGPT itself.\\n  We highlight for developers that code generated by ChatGPT is more likely to\\ncontain vulnerabilities compared to their own code. Furthermore, at times\\nChatGPT reports incorrect information with apparent confidence, which may\\nmislead less experienced developers. Our findings confirm previous studies in\\ndemonstrating that ChatGPT is not sufficiently reliable for generating secure\\ncode nor identifying all vulnerabilities, highlighting the continuing\\nimportance of static scanners and manual review.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.CR\", \"published\": \"2025-04-29T14:30:14Z\"}"}
