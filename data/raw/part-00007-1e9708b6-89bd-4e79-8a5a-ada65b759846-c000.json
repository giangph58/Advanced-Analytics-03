{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01466v1\", \"title\": \"Mesh Mamba: A Unified State Space Model for Saliency Prediction in\\n  Non-Textured and Textured Meshes\", \"summary\": \"Mesh saliency enhances the adaptability of 3D vision by identifying and\\nemphasizing regions that naturally attract visual attention. To investigate the\\ninteraction between geometric structure and texture in shaping visual\\nattention, we establish a comprehensive mesh saliency dataset, which is the\\nfirst to systematically capture the differences in saliency distribution under\\nboth textured and non-textured visual conditions. Furthermore, we introduce\\nmesh Mamba, a unified saliency prediction model based on a state space model\\n(SSM), designed to adapt across various mesh types. Mesh Mamba effectively\\nanalyzes the geometric structure of the mesh while seamlessly incorporating\\ntexture features into the topological framework, ensuring coherence throughout\\nappearance-enhanced modeling. More importantly, by subgraph embedding and a\\nbidirectional SSM, the model enables global context modeling for both local\\ngeometry and texture, preserving the topological structure and improving the\\nunderstanding of visual details and structural complexity. Through extensive\\ntheoretical and empirical validation, our model not only improves performance\\nacross various mesh types but also demonstrates high scalability and\\nversatility, particularly through cross validations of various visual features.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T08:22:25Z\"}"}
