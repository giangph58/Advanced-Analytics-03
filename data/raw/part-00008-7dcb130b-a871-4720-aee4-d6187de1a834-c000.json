{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05391v1\", \"title\": \"EDmamba: A Simple yet Effective Event Denoising Method with State Space\\n  Model\", \"summary\": \"Event cameras excel in high-speed vision due to their high temporal\\nresolution, high dynamic range, and low power consumption. However, as dynamic\\nvision sensors, their output is inherently noisy, making efficient denoising\\nessential to preserve their ultra-low latency and real-time processing\\ncapabilities. Existing event denoising methods struggle with a critical\\ndilemma: computationally intensive approaches compromise the sensor's\\nhigh-speed advantage, while lightweight methods often lack robustness across\\nvarying noise levels. To address this, we propose a novel event denoising\\nframework based on State Space Models (SSMs). Our approach represents events as\\n4D event clouds and includes a Coarse Feature Extraction (CFE) module that\\nextracts embedding features from both geometric and polarity-aware subspaces.\\nThe model is further composed of two essential components: A Spatial Mamba\\n(S-SSM) that models local geometric structures and a Temporal Mamba (T-SSM)\\nthat captures global temporal dynamics, efficiently propagating spatiotemporal\\nfeatures across events. Experiments demonstrate that our method achieves\\nstate-of-the-art accuracy and efficiency, with 88.89K parameters, 0.0685s per\\n100K events inference time, and a 0.982 accuracy score, outperforming\\nTransformer-based methods by 2.08% in denoising accuracy and 36X faster.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T16:27:27Z\"}"}
