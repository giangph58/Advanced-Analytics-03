{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17364v1\", \"title\": \"I-INR: Iterative Implicit Neural Representations\", \"summary\": \"Implicit Neural Representations (INRs) have revolutionized signal processing\\nand computer vision by modeling signals as continuous, differentiable functions\\nparameterized by neural networks. However, their inherent formulation as a\\nregression problem makes them prone to regression to the mean, limiting their\\nability to capture fine details, retain high-frequency information, and handle\\nnoise effectively. To address these challenges, we propose Iterative Implicit\\nNeural Representations (I-INRs) a novel plug-and-play framework that enhances\\nsignal reconstruction through an iterative refinement process. I-INRs\\neffectively recover high-frequency details, improve robustness to noise, and\\nachieve superior reconstruction quality. Our framework seamlessly integrates\\nwith existing INR architectures, delivering substantial performance gains\\nacross various tasks. Extensive experiments show that I-INRs outperform\\nbaseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision\\napplications such as image restoration, image denoising, and object occupancy\\nprediction.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T08:27:22Z\"}"}
