{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21403v1\", \"title\": \"Static or Dynamic: Towards Query-Adaptive Token Selection for Video\\n  Question Answering\", \"summary\": \"Video question answering benefits from the rich information available in\\nvideos, enabling a wide range of applications. However, the large volume of\\ntokens generated from longer videos presents significant challenges to memory\\nefficiency and model performance. To alleviate this issue, existing works\\npropose to compress video inputs, but usually overlooking the varying\\nimportance of static and dynamic information across different queries, leading\\nto inefficient token usage within limited budgets. To tackle this, we propose a\\nnovel token selection strategy, EXPLORE-THEN-SELECT, that adaptively adjust\\nstatic and dynamic information needed based on question requirements. Our\\nframework first explores different token allocations between static frames,\\nwhich preserve spatial details, and dynamic frames, which capture temporal\\nchanges. Next, it employs a query-aware attention-based metric to select the\\noptimal token combination without model updates. Our proposed framework is\\nplug-and-play that can be seamlessly integrated within diverse video-language\\nmodels. Extensive experiments show that our method achieves significant\\nperformance improvements (up to 5.8%) among various video question answering\\nbenchmarks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T08:03:54Z\"}"}
