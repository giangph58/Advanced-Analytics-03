{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00496v1\", \"title\": \"Out of the Loop Again: How Dangerous is Weaponizing Automated Nuclear\\n  Systems?\", \"summary\": \"Are nuclear weapons useful for coercion, and, if so, what factors increase\\nthe credibility and effectiveness of nuclear threats? While prominent scholars\\nlike Thomas Schelling argue that nuclear brinkmanship, or the manipulation of\\nnuclear risk, can effectively coerce adversaries, others contend nuclear\\nweapons are not effective tools of coercion, especially coercion designed to\\nachieve offensive and revisionist objectives. Simultaneously, there is broad\\ndebate about the incorporation of artificial intelligence (AI) into military\\nsystems, especially nuclear command and control. We develop a theoretical\\nargument that explicit nuclear threats implemented with automated nuclear\\nlaunch systems are potentially more credible compared to ambiguous nuclear\\nthreats or explicit nuclear threats implemented via non-automated means. By\\nreducing human control over nuclear use, leaders can more effectively tie their\\nhands and thus signal resolve. While automated nuclear weapons launch systems\\nmay seem like something out of science fiction, the Soviet Union deployed such\\na system during the Cold War and the technology necessary to automate the use\\nof force has developed considerably in recent years due to advances in AI.\\nPreregistered survey experiments on an elite sample of United Kingdom Members\\nof Parliament and two public samples of UK citizens provide support for these\\nexpectations, showing that, in a limited set of circumstances, nuclear threats\\nbacked by AI integration have credibility advantages, no matter how dangerous\\nthey may be. Our findings contribute to the literatures on coercive bargaining,\\nweapons of mass destruction, and emerging technology.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY\", \"published\": \"2025-05-01T12:51:06Z\"}"}
