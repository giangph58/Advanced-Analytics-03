{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07540v1\", \"title\": \"PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and\\n  Merkle Proofs\", \"summary\": \"We present a design called \\\\emph{Proof of Gradient Optimization} (PoGO) for\\nblockchain consensus, where miners produce verifiable evidence of training\\nlarge-scale machine-learning models. Building on previous work, we incorporate\\n\\\\emph{quantized gradients} (4-bit precision) to reduce storage and computation\\nrequirements, while still preserving the ability of verifiers to check that\\nreal progress has been made on lowering the model's loss. Additionally, we\\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\\nand to enable random leaf checks with minimal on-chain data. We illustrate\\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\\nto smaller but high-performance models (e.g., \\\\emph{Gemma~3} with 27B\\nparameters). We provide an empirical cost analysis showing that verification is\\nsignificantly cheaper than training, thanks in part to quantization and\\nsampling. We also discuss the necessity of longer block times (potentially\\nhours) when incorporating meaningful training steps, the trade-offs when using\\nspecialized GPU hardware, and how binary diffs may incrementally optimize\\nupdates. Finally, we note that fine-tuning can be handled in a similar manner,\\nmerely changing the dataset and the manner of sampling but preserving the\\noverall verification flow. Our protocol allows verifiers to issue either\\n\\\\emph{positive} or \\\\emph{negative} attestations; these are aggregated at\\nfinalization to either confirm the update or slash the miner.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-10T08:09:34Z\"}"}
