{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15699v1\", \"title\": \"Advancing Embodied Agent Security: From Safety Benchmarks to Input\\n  Moderation\", \"summary\": \"Embodied agents exhibit immense potential across a multitude of domains,\\nmaking the assurance of their behavioral safety a fundamental prerequisite for\\ntheir widespread deployment. However, existing research predominantly\\nconcentrates on the security of general large language models, lacking\\nspecialized methodologies for establishing safety benchmarks and input\\nmoderation tailored to embodied agents. To bridge this gap, this paper\\nintroduces a novel input moderation framework, meticulously designed to\\nsafeguard embodied agents. This framework encompasses the entire pipeline,\\nincluding taxonomy definition, dataset curation, moderator architecture, model\\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\\nmeticulously crafted safety benchmark engineered to facilitate both the\\ntraining and stringent assessment of moderators specifically designed for\\nembodied agents. Furthermore, we propose Pinpoint, an innovative\\nprompt-decoupled input moderation scheme that harnesses a masked attention\\nmechanism to effectively isolate and mitigate the influence of functional\\nprompts on moderation tasks. Extensive experiments conducted on diverse\\nbenchmark datasets and models validate the feasibility and efficacy of the\\nproposed approach. The results demonstrate that our methodologies achieve an\\nimpressive average detection accuracy of 94.58%, surpassing the performance of\\nexisting state-of-the-art techniques, alongside an exceptional moderation\\nprocessing time of merely 0.002 seconds per instance.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-22T08:34:35Z\"}"}
