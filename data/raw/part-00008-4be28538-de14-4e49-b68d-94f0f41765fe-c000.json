{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00381v1\", \"title\": \"Proximal gradient-type method with generalized distance and convergence\\n  analysis without global descent lemma\", \"summary\": \"We consider solving nonconvex composite optimization problems in which the\\nsum of a smooth function and a nonsmooth function is minimized. Many of\\nconvergence analyses of proximal gradient-type methods rely on global descent\\nproperty between the smooth term and its proximal term. On the other hand, the\\nability to efficiently solve the subproblem depends on the compatibility\\nbetween the nonsmooth term and the proximal term. Selecting an appropriate\\nproximal term by considering both factors simultaneously is generally\\ndifficult. We overcome this issue by providing convergence analyses for\\nproximal gradient-type methods with general proximal terms, without requiring\\nglobal descent property of the smooth term. As a byproduct, new convergence\\nresults of the interior gradient methods for conic optimization are also\\nprovided.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC\", \"published\": \"2025-05-01T08:15:51Z\"}"}
