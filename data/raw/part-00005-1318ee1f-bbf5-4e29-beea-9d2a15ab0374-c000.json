{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21774v1\", \"title\": \"Is Intermediate Fusion All You Need for UAV-based Collaborative\\n  Perception?\", \"summary\": \"Collaborative perception enhances environmental awareness through inter-agent\\ncommunication and is regarded as a promising solution to intelligent\\ntransportation systems. However, existing collaborative methods for Unmanned\\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\\nperspective, resulting in substantial communication overhead. To address this\\nissue, we propose a novel communication-efficient collaborative perception\\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\\nexchange informative and compact detection results and shift the fusion stage\\nto the feature representation level. In particular, we leverage vision-guided\\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\\neffectively integrate complementary information from various agents.\\nAdditionally, we innovatively introduce an uncertainty-driven communication\\nmechanism that uses uncertainty evaluation to select high-quality and reliable\\nshared areas. Experimental results demonstrate that our LIF achieves superior\\nperformance with minimal communication bandwidth, proving its effectiveness and\\npracticality. Code and models are available at https://github.com/uestchjw/LIF.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-30T16:22:14Z\"}"}
