{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02213v1\", \"title\": \"Secure Generalization through Stochastic Bidirectional Parameter Updates\\n  Using Dual-Gradient Mechanism\", \"summary\": \"Federated learning (FL) has gained increasing attention due to\\nprivacy-preserving collaborative training on decentralized clients, mitigating\\nthe need to upload sensitive data to a central server directly. Nonetheless,\\nrecent research has underscored the risk of exposing private data to\\nadversaries, even within FL frameworks. In general, existing methods sacrifice\\nperformance while ensuring resistance to privacy leakage in FL. We overcome\\nthese issues and generate diverse models at a global server through the\\nproposed stochastic bidirectional parameter update mechanism. Using diverse\\nmodels, we improved the generalization and feature representation in the FL\\nsetup, which also helped to improve the robustness of the model against privacy\\nleakage without hurting the model's utility. We use global models from past FL\\nrounds to follow systematic perturbation in parameter space at the server to\\nensure model generalization and resistance against privacy attacks. We generate\\ndiverse models (in close neighborhoods) for each client by using systematic\\nperturbations in model parameters at a fine-grained level (i.e., altering each\\nconvolutional filter across the layers of the model) to improve the\\ngeneralization and security perspective. We evaluated our proposed approach on\\nfour benchmark datasets to validate its superiority. We surpassed the\\nstate-of-the-art methods in terms of model utility and robustness towards\\nprivacy leakage. We have proven the effectiveness of our method by evaluating\\nperformance using several quantitative and qualitative results.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-03T02:06:57Z\"}"}
