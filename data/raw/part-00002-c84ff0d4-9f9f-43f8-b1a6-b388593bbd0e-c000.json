{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14856v1\", \"title\": \"Transparentize the Internal and External Knowledge Utilization in LLMs\\n  with Trustworthy Citation\", \"summary\": \"While hallucinations of large language models could been alleviated through\\nretrieval-augmented generation and citation generation, how the model utilizes\\ninternal knowledge is still opaque, and the trustworthiness of its generated\\nanswers remains questionable. In this work, we introduce Context-Prior\\nAugmented Citation Generation task, requiring models to generate citations\\nconsidering both external and internal knowledge while providing trustworthy\\nreferences, with 5 evaluation metrics focusing on 3 aspects: answer\\nhelpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the\\nparadigm for our task, and also design INTRALIGN, an integrated method\\ncontaining customary data generation and an alignment algorithm. Our\\nexperimental results show that our method achieves a better cross-scenario\\nperformance with regard to other baselines. Our extended experiments further\\nreveal that retrieval quality, question types, and model knowledge have\\nconsiderable influence on the trustworthiness in citation generation.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-21T04:50:16Z\"}"}
