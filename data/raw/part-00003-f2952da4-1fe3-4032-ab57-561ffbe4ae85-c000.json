{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10112v1\", \"title\": \"Benchmarking Practices in LLM-driven Offensive Security: Testbeds,\\n  Metrics, and Experiment Design\", \"summary\": \"Large Language Models (LLMs) have emerged as a powerful approach for driving\\noffensive penetration-testing tooling. This paper analyzes the methodology and\\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\\nresearch papers detailing 15 prototypes and their respective testbeds.\\n  We detail our findings and provide actionable recommendations for future\\nresearch, emphasizing the importance of extending existing testbeds, creating\\nbaselines, and including comprehensive metrics and qualitative analysis. We\\nalso note the distinction between security research and practice, suggesting\\nthat CTF-based challenges may not fully represent real-world penetration\\ntesting scenarios.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.AI\", \"published\": \"2025-04-14T11:21:33Z\"}"}
