{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07072v1\", \"title\": \"Kaleidoscope: In-language Exams for Massively Multilingual Vision\\n  Evaluation\", \"summary\": \"The evaluation of vision-language models (VLMs) has mainly relied on\\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\\nmulticultural coverage. While multilingual benchmarks have expanded, both in\\nsize and languages, many rely on translations of English datasets, failing to\\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\\ncomprehensive exam benchmark to date for the multilingual evaluation of\\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\\ntotal of 20,911 multiple-choice questions. Built through an open science\\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\\nensures linguistic and cultural authenticity. We evaluate top-performing\\nmultilingual vision-language models and find that they perform poorly on\\nlow-resource languages and in complex multimodal scenarios. Our results\\nhighlight the need for progress on culturally inclusive multimodal evaluation\\nframeworks.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CV\", \"published\": \"2025-04-09T17:43:16Z\"}"}
