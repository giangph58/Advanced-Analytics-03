{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03222v1\", \"title\": \"A Stochastic Gradient Descent Method with Global Convergence for\\n  Minimizing Nearly Convex Functions\", \"summary\": \"This paper proposes a stochastic gradient descent method with an adaptive\\nGaussian noise term for minimizing nonconvex differentiable functions. The\\nnoise term in the algorithm, independent of the gradient, is determined by the\\ndifference between the function value at the current step and a lower bound\\nestimate of the optimal value. In both probability space and state space, our\\ntheoretical analysis shows that for a class of nonconvex functions, represented\\nby nearly convex functions, the proposed algorithm converges linearly to a\\ncertain neighborhood of the global optimal solution whose diameter depends on\\nthe variance of the gradient and the deviation between the estimated lower\\nbound and the optimal value. Specifically, when full gradient information is\\nutilized and the sharp lower bound of the objective function is available, the\\nalgorithm converges linearly to the global optimal solution. Furthermore, we\\npropose a double-loop method that alternatively updates the lower bound\\nestimate of the optimal value and the sequence, achieving the convergence to a\\nneighborhood of the global optimal solution depending only on the variance of\\nthe gradient, provided that the lower bound estimate is asymptotically\\naccurate. Numerical experiments on several concrete problems demonstrate the\\neffectiveness of the proposed algorithm and validate the theoretical findings.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC\", \"published\": \"2025-05-06T06:29:06Z\"}"}
