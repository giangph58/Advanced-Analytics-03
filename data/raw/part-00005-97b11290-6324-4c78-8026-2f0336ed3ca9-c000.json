{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17695v1\", \"title\": \"PICO: Reconstructing 3D People In Contact with Objects\", \"summary\": \"Recovering 3D Human-Object Interaction (HOI) from single color images is\\nchallenging due to depth ambiguities, occlusions, and the huge variation in\\nobject shape and appearance. Thus, past work requires controlled settings such\\nas known object shapes and contacts, and tackles only limited object classes.\\nInstead, we need methods that generalize to natural images and novel object\\nclasses. We tackle this in two main ways: (1) We collect PICO-db, a new dataset\\nof natural images uniquely paired with dense 3D contact on both body and object\\nmeshes. To this end, we use images from the recent DAMON dataset that are\\npaired with contacts, but these contacts are only annotated on a canonical 3D\\nbody. In contrast, we seek contact labels on both the body and the object. To\\ninfer these given an image, we retrieve an appropriate 3D object mesh from a\\ndatabase by leveraging vision foundation models. Then, we project DAMON's body\\ncontact patches onto the object via a novel method needing only 2 clicks per\\npatch. This minimal human input establishes rich contact correspondences\\nbetween bodies and objects. (2) We exploit our new dataset of contact\\ncorrespondences in a novel render-and-compare fitting method, called PICO-fit,\\nto recover 3D body and object meshes in interaction. PICO-fit infers contact\\nfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db\\nfor that object, and uses the contact to iteratively fit the 3D body and object\\nmeshes to image evidence via optimization. Uniquely, PICO-fit works well for\\nmany object categories that no existing method can tackle. This is crucial to\\nenable HOI understanding to scale in the wild. Our data and code are available\\nat https://pico.is.tue.mpg.de.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T16:03:11Z\"}"}
