{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12817v1\", \"title\": \"Explainable Scene Understanding with Qualitative Representations and\\n  Graph Neural Networks\", \"summary\": \"This paper investigates the integration of graph neural networks (GNNs) with\\nQualitative Explainable Graphs (QXGs) for scene understanding in automated\\ndriving. Scene understanding is the basis for any further reactive or proactive\\ndecision-making. Scene understanding and related reasoning is inherently an\\nexplanation task: why is another traffic participant doing something, what or\\nwho caused their actions? While previous work demonstrated QXGs' effectiveness\\nusing shallow machine learning models, these approaches were limited to\\nanalysing single relation chains between object pairs, disregarding the broader\\nscene context. We propose a novel GNN architecture that processes entire graph\\nstructures to identify relevant objects in traffic scenes. We evaluate our\\nmethod on the nuScenes dataset enriched with DriveLM's human-annotated\\nrelevance labels. Experimental results show that our GNN-based approach\\nachieves superior performance compared to baseline methods. The model\\neffectively handles the inherent class imbalance in relevant object\\nidentification tasks while considering the complete spatial-temporal\\nrelationships between all objects in the scene. Our work demonstrates the\\npotential of combining qualitative representations with deep learning\\napproaches for explainable scene understanding in autonomous driving systems.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.CV\", \"published\": \"2025-04-17T10:21:30Z\"}"}
