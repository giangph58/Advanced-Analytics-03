{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10865v1\", \"title\": \"Understanding the theoretical properties of projected Bellman equation,\\n  linear Q-learning, and approximate value iteration\", \"summary\": \"In this paper, we study the theoretical properties of the projected Bellman\\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\\napproximate value iteration (AVI). We consider two sufficient conditions for\\nthe existence of a solution to PBE : strictly negatively row dominating\\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\\nand its relationship with the convergence of AVI is examined. Lastly, several\\ninteresting observations on the solution of PBE are provided when using\\n$\\\\epsilon$-greedy policy.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.LG\", \"published\": \"2025-04-15T04:56:33Z\"}"}
