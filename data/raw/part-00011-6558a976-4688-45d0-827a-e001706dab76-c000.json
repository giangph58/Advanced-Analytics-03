{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15013v1\", \"title\": \"Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation\\n  with LLMs\", \"summary\": \"The process of creating educational materials is both time-consuming and\\ndemanding for educators. This research explores the potential of Large Language\\nModels (LLMs) to streamline this task by automating the generation of extended\\nreading materials and relevant course suggestions. Using the TED-Ed Dig Deeper\\nsections as an initial exploration, we investigate how supplementary articles\\ncan be enriched with contextual knowledge and connected to additional learning\\nresources. Our method begins by generating extended articles from video\\ntranscripts, leveraging LLMs to include historical insights, cultural examples,\\nand illustrative anecdotes. A recommendation system employing semantic\\nsimilarity ranking identifies related courses, followed by an LLM-based\\nrefinement process to enhance relevance. The final articles are tailored to\\nseamlessly integrate these recommendations, ensuring they remain cohesive and\\ninformative. Experimental evaluations demonstrate that our model produces\\nhigh-quality content and accurate course suggestions, assessed through metrics\\nsuch as Hit Rate, semantic similarity, and coherence. Our experimental analysis\\nhighlight the nuanced differences between the generated and existing materials,\\nunderscoring the model's capacity to offer more engaging and accessible\\nlearning experiences. This study showcases how LLMs can bridge the gap between\\ncore content and supplementary learning, providing students with additional\\nrecommended resources while also assisting teachers in designing educational\\nmaterials.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-21T10:35:48Z\"}"}
