{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16875v1\", \"title\": \"Hybrid Reinforcement Learning and Model Predictive Control for Adaptive\\n  Control of Hydrogen-Diesel Dual-Fuel Combustion\", \"summary\": \"Reinforcement Learning (RL) and Machine Learning Integrated Model Predictive\\nControl (ML-MPC) are promising approaches for optimizing hydrogen-diesel\\ndual-fuel engine control, as they can effectively control multiple-input\\nmultiple-output systems and nonlinear processes. ML-MPC is advantageous for\\nproviding safe and optimal controls, ensuring the engine operates within\\npredefined safety limits. In contrast, RL is distinguished by its adaptability\\nto changing conditions through its learning-based approach. However, the\\npractical implementation of either method alone poses challenges. RL requires\\nhigh variance in control inputs during early learning phases, which can pose\\nrisks to the system by potentially executing unsafe actions, leading to\\nmechanical damage. Conversely, ML-MPC relies on an accurate system model to\\ngenerate optimal control inputs and has limited adaptability to system drifts,\\nsuch as injector aging, which naturally occur in engine applications. To\\naddress these limitations, this study proposes a hybrid RL and ML-MPC approach\\nthat uses an ML-MPC framework while incorporating an RL agent to dynamically\\nadjust the ML-MPC load tracking reference in response to changes in the\\nenvironment. At the same time, the ML-MPC ensures that actions stay safe\\nthroughout the RL agent's exploration. To evaluate the effectiveness of this\\napproach, fuel pressure is deliberately varied to introduce a model-plant\\nmismatch between the ML-MPC and the engine test bench. The result of this\\nmismatch is a root mean square error (RMSE) in indicated mean effective\\npressure of 0.57 bar when running the ML-MPC. The experimental results\\ndemonstrate that RL successfully adapts to changing boundary conditions by\\naltering the tracking reference while ML-MPC ensures safe control inputs. The\\nquantitative improvement in load tracking by implementing RL is an RSME of 0.44\\nbar.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-23T16:51:49Z\"}"}
