{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21605v1\", \"title\": \"RDF-Based Structured Quality Assessment Representation of Multilingual\\n  LLM Evaluations\", \"summary\": \"Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\\nsystematically assessing their reliability with conflicting information remains\\ndifficult. We propose an RDF-based framework to assess multilingual LLM\\nquality, focusing on knowledge conflicts. Our approach captures model responses\\nacross four distinct context conditions (complete, incomplete, conflicting, and\\nno-context information) in German and English. This structured representation\\nenables the comprehensive analysis of knowledge leakage-where models favor\\ntraining data over provided context-error detection, and multilingual\\nconsistency. We demonstrate the framework through a fire safety domain\\nexperiment, revealing critical patterns in context prioritization and\\nlanguage-specific performance, and demonstrating that our vocabulary was\\nsufficient to express every assessment facet encountered in the 28-question\\nstudy.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.IR\", \"published\": \"2025-04-30T13:06:40Z\"}"}
