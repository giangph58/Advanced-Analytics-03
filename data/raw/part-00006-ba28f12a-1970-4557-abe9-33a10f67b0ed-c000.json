{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20466v1\", \"title\": \"LMM4Gen3DHF: Benchmarking and Evaluating Multimodal 3D Human Face\\n  Generation with LMMs\", \"summary\": \"The rapid advancement in generative artificial intelligence have enabled the\\ncreation of 3D human faces (HFs) for applications including media production,\\nvirtual reality, security, healthcare, and game development, etc. However,\\nassessing the quality and realism of these AI-generated 3D human faces remains\\na significant challenge due to the subjective nature of human perception and\\ninnate perceptual sensitivity to facial features. To this end, we conduct a\\ncomprehensive study on the quality assessment of AI-generated 3D human faces.\\nWe first introduce Gen3DHF, a large-scale benchmark comprising 2,000 videos of\\nAI-Generated 3D Human Faces along with 4,000 Mean Opinion Scores (MOS)\\ncollected across two dimensions, i.e., quality and authenticity, 2,000\\ndistortion-aware saliency maps and distortion descriptions. Based on Gen3DHF,\\nwe propose LMME3DHF, a Large Multimodal Model (LMM)-based metric for Evaluating\\n3DHF capable of quality and authenticity score prediction, distortion-aware\\nvisual question answering, and distortion-aware saliency prediction.\\nExperimental results show that LMME3DHF achieves state-of-the-art performance,\\nsurpassing existing methods in both accurately predicting quality scores for\\nAI-generated 3D human faces and effectively identifying distortion-aware\\nsalient regions and distortion types, while maintaining strong alignment with\\nhuman perceptual judgments. Both the Gen3DHF database and the LMME3DHF will be\\nreleased upon the publication.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-29T07:00:06Z\"}"}
