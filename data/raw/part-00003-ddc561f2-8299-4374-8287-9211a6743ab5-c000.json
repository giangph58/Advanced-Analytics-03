{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11808v1\", \"title\": \"Federated Spectral Graph Transformers Meet Neural Ordinary Differential\\n  Equations for Non-IID Graphs\", \"summary\": \"Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\\ncapacity to learn distributed representations from graph-structured data.\\nHowever, centralizing large volumes of real-world graph data for GNN training\\nis often impractical due to privacy concerns, regulatory restrictions, and\\ncommercial competition. Federated learning (FL), a distributed learning\\nparadigm, offers a solution by preserving data privacy with collaborative model\\ntraining. Despite progress in training huge vision and language models,\\nfederated learning for GNNs remains underexplored. To address this challenge,\\nwe present a novel method for federated learning on GNNs based on spectral GNNs\\nequipped with neural ordinary differential equations (ODE) for better\\ninformation capture, showing promising results across both homophilic and\\nheterophilic graphs. Our approach effectively handles non-Independent and\\nIdentically Distributed (non-IID) data, while also achieving performance\\ncomparable to existing methods that only operate on IID data. It is designed to\\nbe privacy-preserving and bandwidth-optimized, making it suitable for\\nreal-world applications such as social network analysis, recommendation\\nsystems, and fraud detection, which often involve complex, non-IID, and\\nheterophilic graph structures. Our results in the area of federated learning on\\nnon-IID heterophilic graphs demonstrate significant improvements, while also\\nachieving better performance on homophilic graphs. This work highlights the\\npotential of federated learning in diverse and challenging graph settings.\\nOpen-source code available on GitHub\\n(https://github.com/SpringWiz11/Fed-GNODEFormer).\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-16T06:43:20Z\"}"}
