{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03378v1\", \"title\": \"Noisy HQNNs: A Comprehensive Analysis of Noise Robustness in Hybrid\\n  Quantum Neural Networks\", \"summary\": \"Hybrid Quantum Neural Networks (HQNNs) offer promising potential of quantum\\ncomputing while retaining the flexibility of classical deep learning. However,\\nthe limitations of Noisy Intermediate-Scale Quantum (NISQ) devices introduce\\nsignificant challenges in achieving ideal performance due to noise\\ninterference, such as decoherence, gate errors, and readout errors. This paper\\npresents an extensive comparative analysis of two HQNN algorithms, Quantum\\nConvolutional Neural Network (QCNN) and Quanvolutional Neural Network (QuanNN),\\nassessing their noise resilience across diverse image classification tasks. We\\nsystematically inject noise into variational quantum circuits using five\\nquantum noise channels: Phase Flip, Bit Flip, Phase Damping, Amplitude Damping,\\nand Depolarizing Noise. By varying noise probabilities from 0.1 to 1.0, we\\nevaluate the correlation between noise robustness and model behavior across\\ndifferent noise levels.\\n  Our findings demonstrate that different noise types and levels significantly\\ninfluence HQNN performance. The QuanNN shows robust performance across most\\nnoise channels for low noise levels (0.1 - 0.4), but succumbs to diverse\\neffects of depolarizing and amplitude damping noise at probabilities between\\n(0.5 - 1.0). However, the QuanNN exhibits robustness to bit flip noise at high\\nprobabilities (0.9 - 1.0). On the other hand, the QCNN tends to benefit from\\nthe noise injection by outperforming noise-free models for bit flip, phase\\nflip, and phase damping at high noise probabilities. However, for other noise\\ntypes, the QCNN shows gradual performance degradation as noise increases. These\\ninsights aim to guide future research in error mitigation strategies to enhance\\nHQNN models in the NISQ era.\", \"main_category\": \"quant-ph\", \"categories\": \"quant-ph\", \"published\": \"2025-05-06T09:54:14Z\"}"}
