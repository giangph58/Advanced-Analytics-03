{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12747v1\", \"title\": \"Privacy Protection Against Personalized Text-to-Image Synthesis via\\n  Cross-image Consistency Constraints\", \"summary\": \"The rapid advancement of diffusion models and personalization techniques has\\nmade it possible to recreate individual portraits from just a few publicly\\navailable images. While such capabilities empower various creative\\napplications, they also introduce serious privacy concerns, as adversaries can\\nexploit them to generate highly realistic impersonations. To counter these\\nthreats, anti-personalization methods have been proposed, which add adversarial\\nperturbations to published images to disrupt the training of personalization\\nmodels. However, existing approaches largely overlook the intrinsic multi-image\\nnature of personalization and instead adopt a naive strategy of applying\\nperturbations independently, as commonly done in single-image settings. This\\nneglects the opportunity to leverage inter-image relationships for stronger\\nprivacy protection. Therefore, we advocate for a group-level perspective on\\nprivacy protection against personalization. Specifically, we introduce\\nCross-image Anti-Personalization (CAP), a novel framework that enhances\\nresistance to personalization by enforcing style consistency across perturbed\\nimages. Furthermore, we develop a dynamic ratio adjustment strategy that\\nadaptively balances the impact of the consistency loss throughout the attack\\niterations. Extensive experiments on the classical CelebHQ and VGGFace2\\nbenchmarks show that CAP substantially improves existing methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T08:39:32Z\"}"}
