{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04253v1\", \"title\": \"LLM-Independent Adaptive RAG: Let the Question Speak for Itself\", \"summary\": \"Large Language Models~(LLMs) are prone to hallucinations, and\\nRetrieval-Augmented Generation (RAG) helps mitigate this, but at a high\\ncomputational cost while risking misinformation. Adaptive retrieval aims to\\nretrieve only when necessary, but existing approaches rely on LLM-based\\nuncertainty estimation, which remain inefficient and impractical. In this\\nstudy, we introduce lightweight LLM-independent adaptive retrieval methods\\nbased on external information. We investigated 27 features, organized into 7\\ngroups, and their hybrid combinations. We evaluated these methods on 6 QA\\ndatasets, assessing the QA performance and efficiency. The results show that\\nour approach matches the performance of complex LLM-based methods while\\nachieving significant efficiency gains, demonstrating the potential of external\\ninformation for adaptive retrieval.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.LG\", \"published\": \"2025-05-07T08:58:52Z\"}"}
