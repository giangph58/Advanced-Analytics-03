{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17279v1\", \"title\": \"Evaluating and Mitigating Bias in AI-Based Medical Text Generation\", \"summary\": \"Artificial intelligence (AI) systems, particularly those based on deep\\nlearning models, have increasingly achieved expert-level performance in medical\\napplications. However, there is growing concern that such AI systems may\\nreflect and amplify human bias, and reduce the quality of their performance in\\nhistorically under-served populations. The fairness issue has attracted\\nconsiderable research interest in the medical imaging classification field, yet\\nit remains understudied in the text generation domain. In this study, we\\ninvestigate the fairness problem in text generation within the medical field\\nand observe significant performance discrepancies across different races,\\nsexes, and age groups, including intersectional groups, various model scales,\\nand different evaluation metrics. To mitigate this fairness issue, we propose\\nan algorithm that selectively optimizes those underperformed groups to reduce\\nbias. The selection rules take into account not only word-level accuracy but\\nalso the pathology accuracy to the target reference, while ensuring that the\\nentire process remains fully differentiable for effective model training. Our\\nevaluations across multiple backbones, datasets, and modalities demonstrate\\nthat our proposed algorithm enhances fairness in text generation without\\ncompromising overall performance. Specifically, the disparities among various\\ngroups across different metrics were diminished by more than 30% with our\\nalgorithm, while the relative change in text generation accuracy was typically\\nwithin 2%. By reducing the bias generated by deep learning models, our proposed\\napproach can potentially alleviate concerns about the fairness and reliability\\nof text generation diagnosis in medical domain.\\n  Our code is publicly available to facilitate further research at\\nhttps://github.com/iriscxy/GenFair.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-24T06:10:40Z\"}"}
