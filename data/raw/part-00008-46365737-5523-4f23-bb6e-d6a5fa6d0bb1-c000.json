{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04948v1\", \"title\": \"Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized\\n  Recommendations\", \"summary\": \"Recommender systems are essential for delivering personalized content across\\ndigital platforms by modeling user preferences and behaviors. Recently, large\\nlanguage models (LLMs) have been adopted for prompt-based recommendation due to\\ntheir ability to generate personalized outputs without task-specific training.\\nHowever, LLM-based methods face limitations such as limited context window\\nsize, inefficient pointwise and pairwise prompting, and difficulty handling\\nlistwise ranking due to token constraints. LLMs can also be sensitive to\\nposition bias, as they may overemphasize earlier items in the prompt regardless\\nof their true relevance. To address and investigate these issues, we propose a\\nhybrid framework that combines a traditional recommendation model with an LLM\\nfor reranking top-k items using structured prompts. We evaluate the effects of\\nuser history reordering and instructional prompts for mitigating position bias.\\nExperiments on MovieLens-100K show that randomizing user history improves\\nranking quality, but LLM-based reranking does not outperform the base model.\\nExplicit instructions to reduce position bias are also ineffective. Our\\nevaluations reveal limitations in LLMs' ability to model ranking context and\\nmitigate bias. Our code is publicly available at\\nhttps://github.com/aminul7506/LLMForReRanking.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.CL\", \"published\": \"2025-05-08T05:01:44Z\"}"}
