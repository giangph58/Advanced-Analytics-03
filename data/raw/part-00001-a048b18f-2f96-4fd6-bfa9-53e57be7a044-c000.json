{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07570v1\", \"title\": \"Exploring Human-Like Thinking in Search Simulations with Large Language\\n  Models\", \"summary\": \"Simulating user search behavior is a critical task in information retrieval,\\nwhich can be employed for user behavior modeling, data augmentation, and system\\nevaluation. Recent advancements in large language models (LLMs) have opened up\\nnew possibilities for generating human-like actions including querying,\\nbrowsing, and clicking. In this work, we explore the integration of human-like\\nthinking into search simulations by leveraging LLMs to simulate users' hidden\\ncognitive processes. Specifically, given a search task and context, we prompt\\nLLMs to first think like a human before executing the corresponding action. As\\nexisting search datasets do not include users' thought processes, we conducted\\na user study to collect a new dataset enriched with users' explicit thinking.\\nWe investigate the impact of incorporating such human-like thinking on\\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\\nemulate both human thinking and actions. Our experiments span two dimensions in\\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\\ndemonstrate the feasibility and potential of incorporating human-like thinking\\nin user simulations, though performance improvements on some metrics remain\\nmodest. We believe this exploration provides new avenues and inspirations for\\nadvancing user behavior modeling in search simulations.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-10T09:04:58Z\"}"}
