{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10316v1\", \"title\": \"ESCT3D: Efficient and Selectively Controllable Text-Driven 3D Content\\n  Generation with Gaussian Splatting\", \"summary\": \"In recent years, significant advancements have been made in text-driven 3D\\ncontent generation. However, several challenges remain. In practical\\napplications, users often provide extremely simple text inputs while expecting\\nhigh-quality 3D content. Generating optimal results from such minimal text is a\\ndifficult task due to the strong dependency of text-to-3D models on the quality\\nof input prompts. Moreover, the generation process exhibits high variability,\\nmaking it difficult to control. Consequently, multiple iterations are typically\\nrequired to produce content that meets user expectations, reducing generation\\nefficiency. To address this issue, we propose GPT-4V for self-optimization,\\nwhich significantly enhances the efficiency of generating satisfactory content\\nin a single attempt. Furthermore, the controllability of text-to-3D generation\\nmethods has not been fully explored. Our approach enables users to not only\\nprovide textual descriptions but also specify additional conditions, such as\\nstyle, edges, scribbles, poses, or combinations of multiple conditions,\\nallowing for more precise control over the generated 3D content. Additionally,\\nduring training, we effectively integrate multi-view information, including\\nmulti-view depth, masks, features, and images, to address the common Janus\\nproblem in 3D content generation. Extensive experiments demonstrate that our\\nmethod achieves robust generalization, facilitating the efficient and\\ncontrollable generation of high-quality 3D content.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T15:25:21Z\"}"}
