{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04260v1\", \"title\": \"Steerable Chatbots: Personalizing LLMs with Preference-Based Activation\\n  Steering\", \"summary\": \"As large language models (LLMs) improve in their capacity to serve as\\npersonal AI assistants, their ability to output uniquely tailored, personalized\\nresponses that align with the soft preferences of their users is essential for\\nenhancing user satisfaction and retention. However, untrained lay users have\\npoor prompt specification abilities and often struggle with conveying their\\nlatent preferences to AI assistants. To address this, we leverage activation\\nsteering to guide LLMs to align with interpretable preference dimensions during\\ninference. In contrast to memory-based personalization methods that require\\nlonger user history, steering is extremely lightweight and can be easily\\ncontrolled by the user via an linear strength factor. We embed steering into\\nthree different interactive chatbot interfaces and conduct a within-subjects\\nuser study (n=14) to investigate how end users prefer to personalize their\\nconversations. The results demonstrate the effectiveness of preference-based\\nsteering for aligning real-world conversations with hidden user preferences,\\nand highlight further insights on how diverse values around control, usability,\\nand transparency lead users to prefer different interfaces.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC,cs.AI\", \"published\": \"2025-05-07T09:10:51Z\"}"}
