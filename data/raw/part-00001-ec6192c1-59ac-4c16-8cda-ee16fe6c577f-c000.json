{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10150v1\", \"title\": \"HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation\\n  with User History Encoding and Compression\", \"summary\": \"While large language models (LLMs) have proven effective in leveraging\\ntextual data for recommendations, their application to multimodal\\nrecommendation tasks remains relatively underexplored. Although LLMs can\\nprocess multimodal information through projection functions that map visual\\nfeatures into their semantic space, recommendation tasks often require\\nrepresenting users' history interactions through lengthy prompts combining text\\nand visual elements, which not only hampers training and inference efficiency\\nbut also makes it difficult for the model to accurately capture user\\npreferences from complex and extended prompts, leading to reduced\\nrecommendation performance. To address this challenge, we introduce HistLLM, an\\ninnovative multimodal recommendation framework that integrates textual and\\nvisual features through a User History Encoding Module (UHEM), compressing\\nmultimodal user history interactions into a single token representation,\\neffectively facilitating LLMs in processing user preferences. Extensive\\nexperiments demonstrate the effectiveness and efficiency of our proposed\\nmechanism.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.MM\", \"published\": \"2025-04-14T12:01:11Z\"}"}
