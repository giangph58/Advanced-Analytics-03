{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09910v1\", \"title\": \"Learning to Erase Private Knowledge from Multi-Documents for\\n  Retrieval-Augmented Large Language Models\", \"summary\": \"Retrieval-Augmented Generation (RAG) is a promising technique for applying\\nLLMs to proprietary domains. However, retrieved documents may contain sensitive\\nknowledge, posing risks of privacy leakage in generative results. Thus,\\neffectively erasing private information from retrieved documents is a key\\nchallenge for RAG. Unlike traditional text anonymization, RAG should consider:\\n(1) the inherent multi-document reasoning may face de-anonymization attacks;\\n(2) private knowledge varies by scenarios, so users should be allowed to\\ncustomize which information to erase; (3) preserving sufficient publicly\\navailable knowledge for generation tasks. This paper introduces the privacy\\nerasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which\\neffectively removes user-defined private knowledge from documents while\\npreserving sufficient public knowledge for generation. Specifically, we first\\nconstruct a global knowledge graph to identify potential knowledge across\\ndocuments, aiming to defend against de-anonymization attacks. Then we randomly\\nsplit it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite\\nthe retrieved documents excluding private triples. Finally, PPO algorithm\\noptimizes the rewriting model to minimize private triples and maximize public\\ntriples retention. Experiments on four QA datasets demonstrate that Eraser4RAG\\nachieves superior erase performance than GPT-4o.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-14T06:10:31Z\"}"}
