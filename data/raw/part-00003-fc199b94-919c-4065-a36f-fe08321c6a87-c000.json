{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15756v1\", \"title\": \"DSDNet: Raw Domain Demoir\\u00e9ing via Dual Color-Space Synergy\", \"summary\": \"With the rapid advancement of mobile imaging, capturing screens using\\nsmartphones has become a prevalent practice in distance learning and conference\\nrecording. However, moir\\\\'e artifacts, caused by frequency aliasing between\\ndisplay screens and camera sensors, are further amplified by the image signal\\nprocessing pipeline, leading to severe visual degradation. Existing sRGB domain\\ndemoir\\\\'eing methods struggle with irreversible information loss, while recent\\ntwo-stage raw domain approaches suffer from information bottlenecks and\\ninference inefficiency. To address these limitations, we propose a single-stage\\nraw domain demoir\\\\'eing framework, Dual-Stream Demoir\\\\'eing Network (DSDNet),\\nwhich leverages the synergy of raw and YCbCr images to remove moir\\\\'e while\\npreserving luminance and color fidelity. Specifically, to guide luminance\\ncorrection and moir\\\\'e removal, we design a raw-to-YCbCr mapping pipeline and\\nintroduce the Synergic Attention with Dynamic Modulation (SADM) module. This\\nmodule enriches the raw-to-sRGB conversion with cross-domain contextual\\nfeatures. Furthermore, to better guide color fidelity, we develop a\\nLuminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance\\nand chrominance representations. Extensive experiments demonstrate that DSDNet\\noutperforms state-of-the-art methods in both visual quality and quantitative\\nevaluation, and achieves an inference speed $\\\\mathrm{\\\\textbf{2.4x}}$ faster\\nthan the second-best method, highlighting its practical advantages. We provide\\nan anonymous online demo at https://xxxxxxxxdsdnet.github.io/DSDNet/.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-22T10:09:33Z\"}"}
