{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12189v1\", \"title\": \"Leave-One-Out Stable Conformal Prediction\", \"summary\": \"Conformal prediction (CP) is an important tool for distribution-free\\npredictive uncertainty quantification. Yet, a major challenge is to balance\\ncomputational efficiency and prediction accuracy, particularly for multiple\\npredictions. We propose Leave-One-Out Stable Conformal Prediction (LOO-StabCP),\\na novel method to speed up full conformal using algorithmic stability without\\nsample splitting. By leveraging leave-one-out stability, our method is much\\nfaster in handling a large number of prediction requests compared to existing\\nmethod RO-StabCP based on replace-one stability. We derived stability bounds\\nfor several popular machine learning tools: regularized loss minimization (RLM)\\nand stochastic gradient descent (SGD), as well as kernel method, neural\\nnetworks and bagging. Our method is theoretically justified and demonstrates\\nsuperior numerical performance on synthetic and real-world data. We applied our\\nmethod to a screening problem, where its effective exploitation of training\\ndata led to improved test power compared to state-of-the-art method based on\\nsplit conformal.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG\", \"published\": \"2025-04-16T15:44:24Z\"}"}
