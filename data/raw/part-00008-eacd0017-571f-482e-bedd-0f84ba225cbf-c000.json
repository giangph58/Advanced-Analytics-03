{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05075v1\", \"title\": \"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\\n  Video Recognition\", \"summary\": \"Point cloud video perception has become an essential task for the realm of 3D\\nvision. Current 4D representation learning techniques typically engage in\\niterative processing coupled with dense query operations. Although effective in\\ncapturing temporal features, this approach leads to substantial computational\\nredundancy. In this work, we propose a framework, named as PvNeXt, for\\neffective yet efficient point cloud video recognition, via personalized\\none-shot query operation. Specially, PvNeXt consists of two key modules, the\\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\\nMotion Imitator, is designed to capture the temporal dynamics inherent in\\nsequences of point clouds, thus generating the virtual motion corresponding to\\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\\nassociating point cloud of each frame with its corresponding virtual motion\\nframe, thereby extracting motion cues from point cloud sequences and capturing\\ntemporal dynamics across the entire sequence. Through the integration of these\\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\\neffectively eliminating the need for frame-specific looping and intensive query\\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\\neffectiveness of our method.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T13:43:51Z\"}"}
