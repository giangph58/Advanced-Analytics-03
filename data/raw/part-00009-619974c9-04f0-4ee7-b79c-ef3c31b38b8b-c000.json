{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07785v1\", \"title\": \"Towards Micro-Action Recognition with Limited Annotations: An\\n  Asynchronous Pseudo Labeling and Training Approach\", \"summary\": \"Micro-Action Recognition (MAR) aims to classify subtle human actions in\\nvideo. However, annotating MAR datasets is particularly challenging due to the\\nsubtlety of actions. To this end, we introduce the setting of Semi-Supervised\\nMAR (SSMAR), where only a part of samples are labeled. We first evaluate\\ntraditional Semi-Supervised Learning (SSL) methods to SSMAR and find that these\\nmethods tend to overfit on inaccurate pseudo-labels, leading to error\\naccumulation and degraded performance. This issue primarily arises from the\\ncommon practice of directly using the predictions of classifier as\\npseudo-labels to train the model. To solve this issue, we propose a novel\\nframework, called Asynchronous Pseudo Labeling and Training (APLT), which\\nexplicitly separates the pseudo-labeling process from model training.\\nSpecifically, we introduce a semi-supervised clustering method during the\\noffline pseudo-labeling phase to generate more accurate pseudo-labels.\\nMoreover, a self-adaptive thresholding strategy is proposed to dynamically\\nfilter noisy labels of different classes. We then build a memory-based\\nprototype classifier based on the filtered pseudo-labels, which is fixed and\\nused to guide the subsequent model training phase. By alternating the two\\npseudo-labeling and model training phases in an asynchronous manner, the model\\ncan not only be learned with more accurate pseudo-labels but also avoid the\\noverfitting issue. Experiments on three MAR datasets show that our APLT largely\\noutperforms state-of-the-art SSL methods. For instance, APLT improves accuracy\\nby 14.5\\\\% over FixMatch on the MA-12 dataset when using only 50\\\\% labeled data.\\nCode will be publicly available.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-10T14:22:15Z\"}"}
