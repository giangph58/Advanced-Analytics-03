{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20505v1\", \"title\": \"MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural\\n  Language for Activities of Daily Living\", \"summary\": \"Recent advances in Large Language Models (LLMs) have shown promising\\npotential for human activity recognition (HAR) using ambient sensors,\\nespecially through natural language reasoning and zero-shot learning. However,\\nexisting datasets such as CASAS, ARAS, and MARBLE were not originally designed\\nwith LLMs in mind and therefore lack the contextual richness, complexity, and\\nannotation granularity required to fully exploit LLM capabilities. In this\\npaper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with\\nnatural Language, comprising over 21 hours of multi-user sensor data collected\\nfrom 21 sessions in a smart-home environment. MuRAL is annotated with\\nfine-grained natural language descriptions, resident identities, and high-level\\nactivity labels, all situated in dynamic, realistic multi-resident settings. We\\nbenchmark MuRAL using state-of-the-art LLMs for three core tasks: subject\\nassignment, action description, and activity classification. Our results\\ndemonstrate that while LLMs can provide rich semantic interpretations of\\nambient data, current models still face challenges in handling multi-user\\nambiguity and under-specified sensor contexts. We release MuRAL to support\\nfuture research on LLM-powered, explainable, and socially aware activity\\nunderstanding in smart environments. For access to the dataset, please reach\\nout to us via the provided contact information. A direct link for dataset\\nretrieval will be made available at this location in due course.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-29T07:46:14Z\"}"}
