{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09904v1\", \"title\": \"LiteTracker: Leveraging Temporal Causality for Accurate Low-latency\\n  Tissue Tracking\", \"summary\": \"Tissue tracking plays a critical role in various surgical navigation and\\nextended reality (XR) applications. While current methods trained on large\\nsynthetic datasets achieve high tracking accuracy and generalize well to\\nendoscopic scenes, their runtime performances fail to meet the low-latency\\nrequirements necessary for real-time surgical applications. To address this\\nlimitation, we propose LiteTracker, a low-latency method for tissue tracking in\\nendoscopic video streams. LiteTracker builds on a state-of-the-art long-term\\npoint tracking method, and introduces a set of training-free runtime\\noptimizations. These optimizations enable online, frame-by-frame tracking by\\nleveraging a temporal memory buffer for efficient feature reuse and utilizing\\nprior motion for accurate track initialization. LiteTracker demonstrates\\nsignificant runtime improvements being around 7x faster than its predecessor\\nand 2x than the state-of-the-art. Beyond its primary focus on efficiency,\\nLiteTracker delivers high-accuracy tracking and occlusion prediction,\\nperforming competitively on both the STIR and SuPer datasets. We believe\\nLiteTracker is an important step toward low-latency tissue tracking for\\nreal-time surgical applications in the operating room.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T05:53:57Z\"}"}
