{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04152v1\", \"title\": \"Can Language Models Understand Social Behavior in Clinical\\n  Conversations?\", \"summary\": \"Effective communication between providers and their patients influences\\nhealth and care outcomes. The effectiveness of such conversations has been\\nlinked not only to the exchange of clinical information, but also to a range of\\ninterpersonal behaviors; commonly referred to as social signals, which are\\noften conveyed through non-verbal cues and shape the quality of the\\npatient-provider relationship. Recent advances in large language models (LLMs)\\nhave demonstrated an increasing ability to infer emotional and social behaviors\\neven when analyzing only textual information. As automation increases also in\\nclinical settings, such as for transcription of patient-provider conversations,\\nthere is growing potential for LLMs to automatically analyze and extract social\\nbehaviors from these interactions. To explore the foundational capabilities of\\nLLMs in tracking social signals in clinical dialogue, we designed task-specific\\nprompts and evaluated model performance across multiple architectures and\\nprompting styles using a highly imbalanced, annotated dataset spanning 20\\ndistinct social signals such as provider dominance, patient warmth, etc. We\\npresent the first system capable of tracking all these 20 coded signals, and\\nuncover patterns in LLM behavior. Further analysis of model configurations and\\nclinical context provides insights for enhancing LLM performance on social\\nsignal processing tasks in healthcare settings.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CY,cs.HC\", \"published\": \"2025-05-07T06:03:37Z\"}"}
