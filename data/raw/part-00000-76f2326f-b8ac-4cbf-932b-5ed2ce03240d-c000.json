{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14879v1\", \"title\": \"Impact of Latent Space Dimension on IoT Botnet Detection Performance:\\n  VAE-Encoder Versus ViT-Encoder\", \"summary\": \"The rapid evolution of Internet of Things (IoT) technology has led to a\\nsignificant increase in the number of IoT devices, applications, and services.\\nThis surge in IoT devices, along with their widespread presence, has made them\\na prime target for various cyber-attacks, particularly through IoT botnets. As\\na result, security has become a major concern within the IoT ecosystem. This\\nstudy focuses on investigating how the latent dimension impacts the performance\\nof different deep learning classifiers when trained on latent vector\\nrepresentations of the train dataset. The primary objective is to compare the\\noutcomes of these models when encoder components from two cutting-edge\\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\\n(VAE) are utilized to project the high dimensional train dataset to the learned\\nlow dimensional latent space. The encoder components are employed to project\\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\\nreduction for both datasets in terms of four performance metrics including\\naccuracy, precision, recall, and F1-score for all models which can be\\nattributed to absence of spatial patterns in the datasets the ViT model\\nattempts to learn and extract from image instances.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-21T06:15:07Z\"}"}
