{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09887v1\", \"title\": \"Enhanced Semantic Extraction and Guidance for UGC Image Super Resolution\", \"summary\": \"Due to the disparity between real-world degradations in user-generated\\ncontent(UGC) images and synthetic degradations, traditional super-resolution\\nmethods struggle to generalize effectively, necessitating a more robust\\napproach to model real-world distortions. In this paper, we propose a novel\\napproach to UGC image super-resolution by integrating semantic guidance into a\\ndiffusion framework. Our method addresses the inconsistency between\\ndegradations in wild and synthetic datasets by separately simulating the\\ndegradation processes on the LSDIR dataset and combining them with the official\\npaired training set. Furthermore, we enhance degradation removal and detail\\ngeneration by incorporating a pretrained semantic extraction model (SAM2) and\\nfine-tuning key hyperparameters for improved perceptual fidelity. Extensive\\nexperiments demonstrate the superiority of our approach against\\nstate-of-the-art methods. Additionally, the proposed model won second place in\\nthe CVPR NTIRE 2025 Short-form UGC Image Super-Resolution Challenge, further\\nvalidating its effectiveness. The code is available at\\nhttps://github.c10pom/Moonsofang/NTIRE-2025-SRlab.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T05:26:24Z\"}"}
