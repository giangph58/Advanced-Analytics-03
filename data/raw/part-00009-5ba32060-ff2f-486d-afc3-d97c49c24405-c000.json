{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00256v1\", \"title\": \"Policy Learning with $\\u03b1$-Expected Welfare\", \"summary\": \"This paper proposes an optimal policy that targets the average welfare of the\\nworst-off $\\\\alpha$-fraction of the post-treatment outcome distribution. We\\nrefer to this policy as the $\\\\alpha$-Expected Welfare Maximization\\n($\\\\alpha$-EWM) rule, where $\\\\alpha \\\\in (0,1]$ denotes the size of the\\nsubpopulation of interest. The $\\\\alpha$-EWM rule interpolates between the\\nexpected welfare ($\\\\alpha=1$) and the Rawlsian welfare ($\\\\alpha\\\\rightarrow 0$).\\nFor $\\\\alpha\\\\in (0,1)$, an $\\\\alpha$-EWM rule can be interpreted as a\\ndistributionally robust EWM rule that allows the target population to have a\\ndifferent distribution than the study population. Using the dual formulation of\\nour $\\\\alpha$-expected welfare function, we propose a debiased estimator for the\\noptimal policy and establish its asymptotic upper regret bounds. In addition,\\nwe develop asymptotically valid inference for the optimal welfare based on the\\nproposed debiased estimator. We examine the finite sample performance of the\\ndebiased estimator and inference via both real and synthetic data.\", \"main_category\": \"econ.EM\", \"categories\": \"econ.EM\", \"published\": \"2025-05-01T02:42:13Z\"}"}
