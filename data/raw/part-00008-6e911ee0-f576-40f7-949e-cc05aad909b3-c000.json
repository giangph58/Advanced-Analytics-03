{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06250v1\", \"title\": \"Fractal and Regular Geometry of Deep Neural Networks\", \"summary\": \"We study the geometric properties of random neural networks by investigating\\nthe boundary volumes of their excursion sets for different activation\\nfunctions, as the depth increases. More specifically, we show that, for\\nactivations which are not very regular (e.g., the Heaviside step function), the\\nboundary volumes exhibit fractal behavior, with their Hausdorff dimension\\nmonotonically increasing with the depth. On the other hand, for activations\\nwhich are more regular (e.g., ReLU, logistic and $\\\\tanh$), as the depth\\nincreases, the expected boundary volumes can either converge to zero, remain\\nconstant or diverge exponentially, depending on a single spectral parameter\\nwhich can be easily computed. Our theoretical results are confirmed in some\\nnumerical experiments based on Monte Carlo simulations.\", \"main_category\": \"math.PR\", \"categories\": \"math.PR,cs.LG,stat.ML\", \"published\": \"2025-04-08T17:56:05Z\"}"}
