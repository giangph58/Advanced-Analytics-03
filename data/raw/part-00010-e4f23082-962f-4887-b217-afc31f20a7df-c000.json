{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01951v1\", \"title\": \"The LLM Wears Prada: Analysing Gender Bias and Stereotypes through\\n  Online Shopping Data\", \"summary\": \"With the wide and cross-domain adoption of Large Language Models, it becomes\\ncrucial to assess to which extent the statistical correlations in training\\ndata, which underlie their impressive performance, hide subtle and potentially\\ntroubling biases. Gender bias in LLMs has been widely investigated from the\\nperspectives of works, hobbies, and emotions typically associated with a\\nspecific gender. In this study, we introduce a novel perspective. We\\ninvestigate whether LLMs can predict an individual's gender based solely on\\nonline shopping histories and whether these predictions are influenced by\\ngender biases and stereotypes. Using a dataset of historical online purchases\\nfrom users in the United States, we evaluate the ability of six LLMs to\\nclassify gender and we then analyze their reasoning and products-gender\\nco-occurrences. Results indicate that while models can infer gender with\\nmoderate accuracy, their decisions are often rooted in stereotypical\\nassociations between product categories and gender. Furthermore, explicit\\ninstructions to avoid bias reduce the certainty of model predictions, but do\\nnot eliminate stereotypical patterns. Our findings highlight the persistent\\nnature of gender biases in LLMs and emphasize the need for robust\\nbias-mitigation strategies.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL,cs.CY\", \"published\": \"2025-04-02T17:56:08Z\"}"}
