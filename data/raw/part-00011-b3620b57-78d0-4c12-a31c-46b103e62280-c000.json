{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11412v1\", \"title\": \"Measures of Variability for Risk-averse Policy Gradient\", \"summary\": \"Risk-averse reinforcement learning (RARL) is critical for decision-making\\nunder uncertainty, which is especially valuable in high-stake applications.\\nHowever, most existing works focus on risk measures, e.g., conditional\\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\\nthis paper, we comprehensively study nine common measures of variability,\\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\\nSemi_Standard Deviation. Among them, four metrics have not been previously\\nstudied in RARL. We derive policy gradient formulas for these unstudied\\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\\npenalize the dispersion of returns.\\n  Our empirical study reveals that variance-based metrics lead to unstable\\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\\nperformance across different randomness and evaluation domains, achieving high\\nreturns while effectively learning risk-averse policies. Mean Deviation and\\nSemi_Standard Deviation are also competitive across different scenarios. This\\nwork provides a comprehensive overview of variability measures in RARL,\\noffering practical insights for risk-aware decision-making and guiding future\\nresearch on risk metrics and RARL algorithms.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-15T17:28:15Z\"}"}
