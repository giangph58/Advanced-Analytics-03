{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11895v1\", \"title\": \"Search is All You Need for Few-shot Anomaly Detection\", \"summary\": \"Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging\\ntask in industrial inspection, where normal distribution modeling must be\\naccomplished with only a few normal images. While existing approaches typically\\nemploy multi-modal foundation models combining language and vision modalities\\nfor prompt-guided anomaly detection, these methods often demand sophisticated\\nprompt engineering and extensive manual tuning. In this paper, we demonstrate\\nthat a straightforward nearest-neighbor search framework can surpass\\nstate-of-the-art performance in both single-class and multi-class FSAD\\nscenarios. Our proposed method, VisionAD, consists of four simple yet essential\\ncomponents: (1) scalable vision foundation models that extract universal and\\ndiscriminative features; (2) dual augmentation strategies - support\\naugmentation to enhance feature matching adaptability and query augmentation to\\naddress the oversights of single-view prediction; (3) multi-layer feature\\nintegration that captures both low-frequency global context and high-frequency\\nlocal details with minimal computational overhead; and (4) a class-aware visual\\nmemory bank enabling efficient one-for-all multi-class detection. Extensive\\nevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate\\nVisionAD's exceptional performance. Using only 1 normal images as support, our\\nmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%\\nrespectively, outperforming current state-of-the-art approaches by significant\\nmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior\\nfew-shot capabilities of VisionAD make it particularly appealing for real-world\\napplications where samples are scarce or expensive to obtain. Code is available\\nat https://github.com/Qiqigeww/VisionAD.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T09:21:34Z\"}"}
