{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04994v1\", \"title\": \"Rethinking Invariance in In-context Learning\", \"summary\": \"In-Context Learning (ICL) has emerged as a pivotal capability of\\nauto-regressive large language models, yet it is hindered by a notable\\nsensitivity to the ordering of context examples regardless of their mutual\\nindependence. To address this issue, recent studies have introduced several\\nvariant algorithms of ICL that achieve permutation invariance. However, many of\\nthese do not exhibit comparable performance with the standard auto-regressive\\nICL algorithm. In this work, we identify two crucial elements in the design of\\nan invariant ICL algorithm: information non-leakage and context\\ninterdependence, which are not simultaneously achieved by any of the existing\\nmethods. These investigations lead us to the proposed Invariant ICL (InvICL), a\\nmethodology designed to achieve invariance in ICL while ensuring the two\\nproperties. Empirically, our findings reveal that InvICL surpasses previous\\nmodels, both invariant and non-invariant, in most benchmark datasets,\\nshowcasing superior generalization capabilities across varying input lengths.\\nCode is available at https://github.com/PKU-ML/InvICL.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-05-08T06:59:14Z\"}"}
