{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12187v1\", \"title\": \"What Do Large Language Models Know? Tacit Knowledge as a Potential\\n  Causal-Explanatory Structure\", \"summary\": \"It is sometimes assumed that Large Language Models (LLMs) know language, or\\nfor example that they know that Paris is the capital of France. But what -- if\\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\\ncertain architectural features of LLMs satisfy the constraints of semantic\\ndescription, syntactic structure, and causal systematicity. Thus, tacit\\nknowledge may serve as a conceptual framework for describing, explaining, and\\nintervening on LLMs and their behavior.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-04-16T15:42:33Z\"}"}
