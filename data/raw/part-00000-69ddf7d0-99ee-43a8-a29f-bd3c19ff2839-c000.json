{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03299v1\", \"title\": \"Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A\\n  Capabilities Encoding Approach\", \"summary\": \"Foundation models constitute a significant advancement in computer vision:\\nafter a single, albeit costly, training phase, they can address a wide array of\\ntasks. In the field of Earth observation, over 75 remote sensing vision\\nfoundation models have been developed in the past four years. However, none has\\nconsistently outperformed the others across all available downstream tasks. To\\nfacilitate their comparison, we propose a cost-effective method for predicting\\na model's performance on multiple downstream tasks without the need for\\nfine-tuning on each one. This method is based on what we call \\\"capabilities\\nencoding.\\\" The utility of this novel approach is twofold: we demonstrate its\\npotential to simplify the selection of a foundation model for a given new task,\\nand we employ it to offer a fresh perspective on the existing literature,\\nsuggesting avenues for future research. Codes are available at\\nhttps://github.com/pierreadorni/capabilities-encoding.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-05-06T08:29:18Z\"}"}
