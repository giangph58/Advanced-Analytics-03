{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03460v1\", \"title\": \"LogisticsVLN: Vision-Language Navigation For Low-Altitude Terminal\\n  Delivery Based on Agentic UAVs\", \"summary\": \"The growing demand for intelligent logistics, particularly fine-grained\\nterminal delivery, underscores the need for autonomous UAV (Unmanned Aerial\\nVehicle)-based delivery systems. However, most existing last-mile delivery\\nstudies rely on ground robots, while current UAV-based Vision-Language\\nNavigation (VLN) tasks primarily focus on coarse-grained, long-range goals,\\nmaking them unsuitable for precise terminal delivery. To bridge this gap, we\\npropose LogisticsVLN, a scalable aerial delivery system built on multimodal\\nlarge language models (MLLMs) for autonomous terminal delivery. LogisticsVLN\\nintegrates lightweight Large Language Models (LLMs) and Visual-Language Models\\n(VLMs) in a modular pipeline for request understanding, floor localization,\\nobject detection, and action-decision making. To support research and\\nevaluation in this new setting, we construct the Vision-Language Delivery (VLD)\\ndataset within the CARLA simulator. Experimental results on the VLD dataset\\nshowcase the feasibility of the LogisticsVLN system. In addition, we conduct\\nsubtask-level evaluations of each module of our system, offering valuable\\ninsights for improving the robustness and real-world deployment of foundation\\nmodel-based vision-language delivery systems.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-05-06T12:00:49Z\"}"}
