{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12966v1\", \"title\": \"Vision and Language Integration for Domain Generalization\", \"summary\": \"Domain generalization aims at training on source domains to uncover a\\ndomain-invariant feature space, allowing the model to perform robust\\ngeneralization ability on unknown target domains. However, due to domain gaps,\\nit is hard to find reliable common image feature space, and the reason for that\\nis the lack of suitable basic units for images. Different from image in vision\\nspace, language has comprehensive expression elements that can effectively\\nconvey semantics. Inspired by the semantic completeness of language and\\nintuitiveness of image, we propose VLCA, which combine language space and\\nvision space, and connect the multiple image domains by using semantic space as\\nthe bridge domain. Specifically, in language space, by taking advantage of the\\ncompleteness of language basic units, we tend to capture the semantic\\nrepresentation of the relations between categories through word vector\\ndistance. Then, in vision space, by taking advantage of the intuitiveness of\\nimage features, the common pattern of sample features with the same class is\\nexplored through low-rank approximation. In the end, the language\\nrepresentation is aligned with the vision representation through the multimodal\\nspace of text and image. Experiments demonstrate the effectiveness of the\\nproposed method.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-04-17T14:19:09Z\"}"}
