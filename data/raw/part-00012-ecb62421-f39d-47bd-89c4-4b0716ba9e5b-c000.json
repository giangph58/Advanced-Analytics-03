{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15650v1\", \"title\": \"AffordanceSAM: Segment Anything Once More in Affordance Grounding\", \"summary\": \"Improving the generalization ability of an affordance grounding model to\\nrecognize regions for unseen objects and affordance functions is crucial for\\nreal-world application. However, current models are still far away from such\\nstandards. To address this problem, we introduce AffordanceSAM, an effective\\napproach that extends SAM's generalization capacity to the domain of affordance\\ngrounding. For the purpose of thoroughly transferring SAM's robust performance\\nin segmentation to affordance, we initially propose an affordance-adaption\\nmodule in order to help modify SAM's segmentation output to be adapted to the\\nspecific functional regions required for affordance grounding. We concurrently\\nmake a coarse-to-fine training recipe to make SAM first be aware of affordance\\nobjects and actions coarsely, and then be able to generate affordance heatmaps\\nfinely. Both quantitative and qualitative experiments show the strong\\ngeneralization capacity of our AffordanceSAM, which not only surpasses previous\\nmethods under AGD20K benchmark but also shows evidence to handle the task with\\nnovel objects and affordance functions.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-22T07:16:56Z\"}"}
