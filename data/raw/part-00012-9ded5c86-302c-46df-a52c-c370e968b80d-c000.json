{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12898v1\", \"title\": \"Information Gain-Guided Causal Intervention for Autonomous Debiasing\\n  Large Language Models\", \"summary\": \"Despite significant progress, recent studies indicate that current large\\nlanguage models (LLMs) may still capture dataset biases and utilize them during\\ninference, leading to the poor generalizability of LLMs. However, due to the\\ndiversity of dataset biases and the insufficient nature of bias suppression\\nbased on in-context learning, the effectiveness of previous prior\\nknowledge-based debiasing methods and in-context learning based automatic\\ndebiasing methods is limited. To address these challenges, we explore the\\ncombination of causal mechanisms with information theory and propose an\\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\\nframework first utilizes an information gain-guided causal intervention method\\nto automatically and autonomously balance the distribution of\\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\\nshow that IGCIDB can effectively debias LLM to improve its generalizability\\nacross different tasks.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-17T12:39:25Z\"}"}
