{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10191v1\", \"title\": \"Localized Cultural Knowledge is Conserved and Controllable in Large\\n  Language Models\", \"summary\": \"Just as humans display language patterns influenced by their native tongue\\nwhen speaking new languages, LLMs often default to English-centric responses\\neven when generating in other languages. Nevertheless, we observe that local\\ncultural information persists within the models and can be readily activated\\nfor cultural customization. We first demonstrate that explicitly providing\\ncultural context in prompts significantly improves the models' ability to\\ngenerate culturally localized responses. We term the disparity in model\\nperformance with versus without explicit cultural context the explicit-implicit\\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\\nit may not naturally surface in multilingual interactions if cultural context\\nis not explicitly provided. Despite the explicit prompting benefit, however,\\nthe answers reduce in diversity and tend toward stereotypes. Second, we\\nidentify an explicit cultural customization vector, conserved across all\\nnon-English languages we explore, which enables LLMs to be steered from the\\nsynthetic English cultural world-model toward each non-English cultural world.\\nSteered responses retain the diversity of implicit prompting and reduce\\nstereotypes to dramatically improve the potential for customization. We discuss\\nthe implications of explicit cultural customization for understanding the\\nconservation of alternative cultural world models within LLMs, and their\\ncontrollable utility for translation, cultural customization, and the\\npossibility of making the explicit implicit through soft control for expanded\\nLLM function and appeal.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-14T12:53:58Z\"}"}
