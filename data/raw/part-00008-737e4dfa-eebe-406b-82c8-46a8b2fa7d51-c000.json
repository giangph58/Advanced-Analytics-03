{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13120v1\", \"title\": \"Probing and Inducing Combinational Creativity in Vision-Language Models\", \"summary\": \"The ability to combine existing concepts into novel ideas stands as a\\nfundamental hallmark of human intelligence. Recent advances in Vision-Language\\nModels (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their\\noutputs reflect combinational creativity--defined by M. A. Boden (1998) as\\nsynthesizing novel ideas through combining existing concepts--or sophisticated\\npattern matching of training data. Drawing inspiration from cognitive science,\\nwe investigate the combinational creativity of VLMs from the lens of concept\\nblending. We propose the Identification-Explanation-Implication (IEI)\\nframework, which decomposes creative processes into three levels: identifying\\ninput spaces, extracting shared attributes, and deriving novel semantic\\nimplications. To validate this framework, we curate CreativeMashup, a\\nhigh-quality dataset of 666 artist-generated visual mashups annotated according\\nto the IEI framework. Through extensive experiments, we demonstrate that in\\ncomprehension tasks, best VLMs have surpassed average human performance while\\nfalling short of expert-level understanding; in generation tasks, incorporating\\nour IEI framework into the generation pipeline significantly enhances the\\ncreative quality of VLMs outputs. Our findings establish both a theoretical\\nfoundation for evaluating artificial creativity and practical guidelines for\\nimproving creative generation in VLMs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL\", \"published\": \"2025-04-17T17:38:18Z\"}"}
