{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01921v1\", \"title\": \"Client Selection in Federated Learning with Data Heterogeneity and\\n  Network Latencies\", \"summary\": \"Federated learning (FL) is a distributed machine learning paradigm where\\nmultiple clients conduct local training based on their private data, then the\\nupdated models are sent to a central server for global aggregation. The\\npractical convergence of FL is challenged by multiple factors, with the primary\\nhurdle being the heterogeneity among clients. This heterogeneity manifests as\\ndata heterogeneity concerning local data distribution and latency heterogeneity\\nduring model transmission to the server. While prior research has introduced\\nvarious efficient client selection methods to alleviate the negative impacts of\\neither of these heterogeneities individually, efficient methods to handle\\nreal-world settings where both these heterogeneities exist simultaneously do\\nnot exist. In this paper, we propose two novel theoretically optimal client\\nselection schemes that can handle both these heterogeneities. Our methods\\ninvolve solving simple optimization problems every round obtained by minimizing\\nthe theoretical runtime to convergence. Empirical evaluations on 9 datasets\\nwith non-iid data distributions, 2 practical delay distributions, and\\nnon-convex neural network models demonstrate that our algorithms are at least\\ncompetitive to and at most 20 times better than best existing baselines.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-02T17:31:15Z\"}"}
