{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06003v1\", \"title\": \"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\\n  Gaussians\", \"summary\": \"The primary focus of most recent works on open-vocabulary neural fields is\\nextracting precise semantic features from the VLMs and then consolidating them\\nefficiently into a multi-view consistent 3D neural fields representation.\\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\\nwithout any further refinement. Moreover, several existing works improved\\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\\nworlds for precise semantic features with complete and precise boundaries. 2) A\\nlow dimensional contextual space to enforce 3D multi-view consistency while\\nimproving computational efficiency by fusing backprojected multi-view 2D\\nfeatures and follow by dimensional reduction directly on the fused 3D features\\ninstead of operating on each 2D view separately. Our econSG shows\\nstate-of-the-art performance on four benchmark datasets compared to the\\nexisting methods. Furthermore, we are also the most efficient training among\\nall the methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-08T13:12:31Z\"}"}
