{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12636v1\", \"title\": \"A0: An Affordance-Aware Hierarchical Model for General Robotic\\n  Manipulation\", \"summary\": \"Robotic manipulation faces critical challenges in understanding spatial\\naffordances--the \\\"where\\\" and \\\"how\\\" of object interactions--essential for\\ncomplex manipulation tasks like wiping a board or stacking objects. Existing\\nmethods, including modular-based and end-to-end approaches, often lack robust\\nspatial reasoning capabilities. Unlike recent point-based and flow-based\\naffordance methods that focus on dense spatial representations or trajectory\\nmodeling, we propose A0, a hierarchical affordance-aware diffusion model that\\ndecomposes manipulation tasks into high-level spatial affordance understanding\\nand low-level action execution. A0 leverages the Embodiment-Agnostic Affordance\\nRepresentation, which captures object-centric spatial affordances by predicting\\ncontact points and post-contact trajectories. A0 is pre-trained on 1 million\\ncontact points data and fine-tuned on annotated trajectories, enabling\\ngeneralization across platforms. Key components include Position Offset\\nAttention for motion-aware feature extraction and a Spatial Information\\nAggregation Layer for precise coordinate mapping. The model's output is\\nexecuted by the action execution module. Experiments on multiple robotic\\nsystems (Franka, Kinova, Realman, and Dobot) demonstrate A0's superior\\nperformance in complex tasks, showcasing its efficiency, flexibility, and\\nreal-world applicability.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-17T04:45:15Z\"}"}
