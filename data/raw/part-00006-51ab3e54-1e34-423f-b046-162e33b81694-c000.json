{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03490v1\", \"title\": \"A new membership inference attack that spots memorization in generative\\n  and predictive models: Loss-Based with Reference Model algorithm (LBRM)\", \"summary\": \"Generative models can unintentionally memorize training data, posing\\nsignificant privacy risks. This paper addresses the memorization phenomenon in\\ntime series imputation models, introducing the Loss-Based with Reference Model\\n(LBRM) algorithm. The LBRM method leverages a reference model to enhance the\\naccuracy of membership inference attacks, distinguishing between training and\\ntest data. Our contributions are twofold: first, we propose an innovative\\nmethod to effectively extract and identify memorized training data,\\nsignificantly improving detection accuracy. On average, without fine-tuning,\\nthe AUROC improved by approximately 40\\\\%. With fine-tuning, the AUROC increased\\nby approximately 60\\\\%. Second, we validate our approach through membership\\ninference attacks on two types of architectures designed for time series\\nimputation, demonstrating the robustness and versatility of the LBRM approach\\nin different contexts. These results highlight the significant enhancement in\\ndetection accuracy provided by the LBRM approach, addressing privacy risks in\\ntime series imputation models.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-05-06T12:47:24Z\"}"}
