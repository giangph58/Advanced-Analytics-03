{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11986v1\", \"title\": \"Language Models as Quasi-Crystalline Thought: Structure, Constraint, and\\n  Emergence in Generative Systems\", \"summary\": \"This essay proposes an analogy between large language models (LLMs) and\\nquasicrystals: systems that exhibit global coherence without periodic\\nrepetition and that are generated through local constraints. While LLMs are\\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\\nstructural perspective suggests that their most characteristic behavior is the\\nproduction of internally resonant linguistic patterns. Just as quasicrystals\\nforced a redefinition of order in physical systems, viewing LLMs as generators\\nof quasi-structured language opens new paths for evaluation and design:\\nprivileging propagation of constraint over token-level accuracy, and coherence\\nof form over fixed meaning. LLM outputs should be read not only for what they\\nsay, but for the patterns of constraint and coherence that organize them. This\\nshift reframes generative language as a space of emergent patterning: LLMs are\\nneither fully random nor strictly rule-based, but defined by a logic of\\nconstraint, resonance, and structural depth.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-16T11:27:47Z\"}"}
