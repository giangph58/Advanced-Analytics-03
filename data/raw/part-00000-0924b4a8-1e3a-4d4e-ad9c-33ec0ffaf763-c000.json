{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23765v1\", \"title\": \"STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World\\n  Understanding?\", \"summary\": \"The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution\\nfor Embodied AI and Autonomous Driving has become a prevailing trend. While\\nMLLMs have been extensively studied for visual semantic understanding tasks,\\ntheir ability to perform precise and quantitative spatial-temporal\\nunderstanding in real-world applications remains largely unexamined, leading to\\nuncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we\\nintroduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal\\nunderstanding through challenging tasks such as estimating and predicting the\\nappearance, pose, displacement, and motion of objects. Our benchmark\\nencompasses a wide range of robot and vehicle operations across desktop,\\nindoor, and outdoor scenarios. The extensive experiments reveals that the\\nstate-of-the-art MLLMs still struggle in real-world spatial-temporal\\nunderstanding, especially in tasks requiring precise distance estimation and\\nmotion analysis.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T06:30:35Z\"}"}
