{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16072v1\", \"title\": \"Describe Anything: Detailed Localized Image and Video Captioning\", \"summary\": \"Generating detailed and accurate descriptions for specific regions in images\\nand videos remains a fundamental challenge for vision-language models. We\\nintroduce the Describe Anything Model (DAM), a model designed for detailed\\nlocalized captioning (DLC). DAM preserves both local details and global context\\nthrough two key innovations: a focal prompt, which ensures high-resolution\\nencoding of targeted regions, and a localized vision backbone, which integrates\\nprecise localization with its broader context. To tackle the scarcity of\\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\\ndetailed multi-sentence localized image and video captioning.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-22T17:51:41Z\"}"}
