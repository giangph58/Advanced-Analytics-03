{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16774v1\", \"title\": \"Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors\\n  and Cross-Model Attention Mechanism\", \"summary\": \"The examination of chest X-ray images is a crucial component in detecting\\nvarious thoracic illnesses. This study introduces a new image description\\ngeneration model that integrates a Vision Transformer (ViT) encoder with\\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\\nhigh-quality visual features from chest X-rays, which are fused with text data\\nthrough cross-modal attention to improve the accuracy, context, and richness of\\nimage descriptions. The GPT-4 decoder transforms these fused features into\\naccurate and relevant captions. The model was tested on the National Institutes\\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\\nevaluation, assisting radiologists in more precise and efficient diagnosis.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-23T14:46:10Z\"}"}
