{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12012v1\", \"title\": \"Purposefully Induced Psychosis (PIP): Embracing Hallucination as\\n  Imagination in Large Language Models\", \"summary\": \"Hallucinations in Large Language Models (LLMs) are widely regarded as errors\\n- outputs that deviate from factual accuracy. However, in creative or\\nexploratory contexts, these \\\"mistakes\\\" may represent unexpected avenues for\\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\\nHerman Melville's Moby-Dick, where Pip's \\\"madness\\\" reveals profound insight, we\\nreframe hallucinations as a source of computational imagination rather than a\\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\\nsurreal outputs - hallucinations that are useful when factual accuracy is not\\nthe chief objective. Inspired by the consensual illusions of theater and stage\\nmagic, PIP situates these creative missteps in contexts where users willingly\\nsuspend disbelief, thereby transforming \\\"errors\\\" into catalysts for new ways of\\nthinking. We discuss potential applications, design principles for ensuring\\nuser consent, preliminary observations, and implications for broader AI ethics\\nand human-AI collaboration.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.HC\", \"published\": \"2025-04-16T12:13:02Z\"}"}
