{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19500v1\", \"title\": \"Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding\", \"summary\": \"Open-vocabulary 3D scene understanding is pivotal for enhancing physical\\nintelligence, as it enables embodied agents to interpret and interact\\ndynamically within real-world environments. This paper introduces MPEC, a novel\\nMasked Point-Entity Contrastive learning method for open-vocabulary 3D semantic\\nsegmentation that leverages both 3D entity-language alignment and point-entity\\nconsistency across different point cloud views to foster entity-specific\\nfeature representations. Our method improves semantic discrimination and\\nenhances the differentiation of unique instances, achieving state-of-the-art\\nresults on ScanNet for open-vocabulary 3D semantic segmentation and\\ndemonstrating superior zero-shot scene understanding capabilities. Extensive\\nfine-tuning experiments on 8 datasets, spanning from low-level perception to\\nhigh-level reasoning tasks, showcase the potential of learned 3D features,\\ndriving consistent performance gains across varied 3D scene understanding\\ntasks. Project website: https://mpec-3d.github.io/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL\", \"published\": \"2025-04-28T05:43:14Z\"}"}
