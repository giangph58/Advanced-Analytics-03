{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05037v1\", \"title\": \"Enhanced convergence rates of Adaptive Importance Sampling with\\n  recycling schemes via quasi-Monte Carlo methods\", \"summary\": \"This article investigates the integration of quasi-Monte Carlo (QMC) methods\\nusing the Adaptive Multiple Importance Sampling (AMIS). Traditional Importance\\nSampling (IS) often suffers from poor performance since it heavily relies on\\nthe choice of the proposal distributions. The AMIS and the Modified version of\\nAMIS (MAMIS) address this by iteratively refining proposal distributions and\\nreusing all past samples through a recycling strategy. We introduce the RQMC\\nmethods into the MAMIS, achieving higher convergence rates compared to the\\nMonte Carlo (MC) methods. Our main contributions include a detailed convergence\\nanalysis of the MAMIS estimator under randomized QMC (RQMC) sampling.\\nSpecifically, we establish the $L^q$ $(q \\\\geq 2)$ error bound for the\\nRQMC-based estimator using a smoothed projection method, which enables us to\\napply the H\\\\\\\"older's inequality in the error analysis of the RQMC-based MAMIS\\nestimator. As a result, we prove that the root mean square error of the\\nRQMC-based MAMIS estimator converges at a rate of\\n$\\\\mathcal{O}(\\\\bar{N}_T^{-1+\\\\epsilon})$, where $\\\\bar{N}_T$ is the average number\\nof samples used in each step over $T$ iterations, and $\\\\epsilon > 0$ is\\narbitrarily small. Numerical experiments validate the effectiveness of our\\nmethod, including mixtures of Gaussians, a banana-shaped model, and Bayesian\\nLogistic regression.\", \"main_category\": \"math.NA\", \"categories\": \"math.NA,cs.NA\", \"published\": \"2025-05-08T08:16:58Z\"}"}
