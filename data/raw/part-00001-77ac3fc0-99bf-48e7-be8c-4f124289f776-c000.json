{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10222v1\", \"title\": \"PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam\\n  Annealing Search\", \"summary\": \"Recent work increasingly focuses on improving the reasoning capabilities of\\nMultimodal Large Language Models (MLLMs). Among existing methods, Process\\nReward Models (PRMs) stand out for offering dense, step-wise supervision to\\nguide intermediate reasoning. However, how to effectively integrate PRMs into\\nsearch strategies remains an open question. In this paper, we introduce PRM-BAS\\n(PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided\\nreasoning that dynamically adjusts beam size -- starting with a broader search\\nspace and gradually narrowing it as contextual information accumulates, thereby\\nbalancing performance and efficiency. We further propose a unified framework\\nfor data construction and PRM training. Specifically, we construct the\\nPRM-BAS-300k dataset by selecting 300k questions from existing datasets and\\nperforming rollouts at each step to estimate the probability of reaching a\\ncorrect final answer. The PRM is then trained using a combination of value loss\\nfor absolute action quality and rank loss for relative action quality.\\nExtensive experiments on challenging multimodal reasoning benchmarks\\ndemonstrate that PRM-BAS significantly improves reasoning performance while\\nmaintaining low computational cost. Moreover, it generalizes well across\\ndifferent model scales and architectures, showcasing strong robustness and\\nplug-and-play capability.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM\", \"published\": \"2025-04-14T13:44:11Z\"}"}
