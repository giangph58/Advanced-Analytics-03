{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24382v1\", \"title\": \"Free360: Layered Gaussian Splatting for Unbounded 360-Degree View\\n  Synthesis from Extremely Sparse and Unposed Views\", \"summary\": \"Neural rendering has demonstrated remarkable success in high-quality 3D\\nneural reconstruction and novel view synthesis with dense input views and\\naccurate poses. However, applying it to extremely sparse, unposed views in\\nunbounded 360{\\\\deg} scenes remains a challenging problem. In this paper, we\\npropose a novel neural rendering framework to accomplish the unposed and\\nextremely sparse-view 3D reconstruction in unbounded 360{\\\\deg} scenes. To\\nresolve the spatial ambiguity inherent in unbounded scenes with sparse input\\nviews, we propose a layered Gaussian-based representation to effectively model\\nthe scene with distinct spatial layers. By employing a dense stereo\\nreconstruction model to recover coarse geometry, we introduce a layer-specific\\nbootstrap optimization to refine the noise and fill occluded regions in the\\nreconstruction. Furthermore, we propose an iterative fusion of reconstruction\\nand generation alongside an uncertainty-aware training approach to facilitate\\nmutual conditioning and enhancement between these two processes. Comprehensive\\nexperiments show that our approach outperforms existing state-of-the-art\\nmethods in terms of rendering quality and surface reconstruction accuracy.\\nProject page: https://zju3dv.github.io/free360/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T17:59:25Z\"}"}
