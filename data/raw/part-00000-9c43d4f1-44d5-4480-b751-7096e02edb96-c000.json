{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20520v1\", \"title\": \"PRISM: Projection-based Reward Integration for Scene-Aware\\n  Real-to-Sim-to-Real Transfer with Few Demonstrations\", \"summary\": \"Learning from few demonstrations to develop policies robust to variations in\\nrobot initial positions and object poses is a problem of significant practical\\ninterest in robotics. Compared to imitation learning, which often struggles to\\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\\nexplore to obtain robust behaviors. Training RL agents through direct\\ninteraction with the real world is often impractical and unsafe, while building\\nsimulation environments requires extensive manual effort, such as designing\\nscenes and crafting task-specific reward functions. To address these\\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\\nconstructs simulation environments based on expert demonstrations by\\nidentifying scene objects from images and retrieving their corresponding 3D\\nmodels from existing libraries. We introduce a projection-based reward model\\nfor RL policy training that is supervised by a vision-language model (VLM)\\nusing human-guided object projection relationships as prompts, with the policy\\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\\nthe construction of simulation environments and RL-based policy training,\\nultimately enabling the deployment of reliable robotic control policies in\\nreal-world scenarios.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI\", \"published\": \"2025-04-29T08:01:27Z\"}"}
