{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17524v1\", \"title\": \"ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot\\n  Learning for Color Image Inpainting\", \"summary\": \"Image inpainting is a technique used to restore missing or damaged regions of\\nan image. Traditional methods primarily utilize information from adjacent\\npixels for reconstructing missing areas, while they struggle to preserve\\ncomplex details and structures. Simultaneously, models based on deep learning\\nnecessitate substantial amounts of training data. To address this challenge, an\\nencoding strategy-inspired diffusion model with few-shot learning for color\\nimage inpainting is proposed in this paper. The main idea of this novel\\nencoding strategy is the deployment of a \\\"virtual mask\\\" to construct\\nhigh-dimensional objects through mutual perturbations between channels. This\\napproach enables the diffusion model to capture diverse image representations\\nand detailed features from limited training samples. Moreover, the encoding\\nstrategy leverages redundancy between channels, integrates with low-rank\\nmethods during iterative inpainting, and incorporates the diffusion model to\\nachieve accurate information output. Experimental results indicate that our\\nmethod exceeds current techniques in quantitative metrics, and the\\nreconstructed images quality has been improved in aspects of texture and\\nstructural integrity, leading to more precise and coherent results.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T13:08:36Z\"}"}
