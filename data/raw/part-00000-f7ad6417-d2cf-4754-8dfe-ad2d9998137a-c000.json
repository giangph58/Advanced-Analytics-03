{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23859v1\", \"title\": \"Evaluating small vision-language models as AI assistants for radio\\n  astronomical source analysis tasks\", \"summary\": \"The advent of next-generation radio telescopes is set to transform radio\\nastronomy by producing massive data volumes that challenge traditional\\nprocessing methods. Deep learning techniques have shown strong potential in\\nautomating radio analysis tasks, yet are often constrained by the limited\\navailability of large annotated datasets. Recent progress in self-supervised\\nlearning has led to foundational radio vision models, but adapting them for new\\ntasks typically requires coding expertise, limiting their accessibility to a\\nbroader astronomical community. Text-based AI interfaces offer a promising\\nalternative by enabling task-specific queries and example-driven learning. In\\nthis context, Large Language Models (LLMs), with their remarkable zero-shot\\ncapabilities, are increasingly used in scientific domains. However, deploying\\nlarge-scale models remains resource-intensive, and there is a growing demand\\nfor AI systems that can reason over both visual and textual data in\\nastronomical analysis. This study explores small-scale Vision-Language Models\\n(VLMs) as AI assistants for radio astronomy, combining LLM capabilities with\\nvision transformers. We fine-tuned the LLaVA VLM on a dataset of 59k radio\\nimages from multiple surveys, enriched with 38k image-caption pairs from the\\nliterature. The fine-tuned models show clear improvements over base models in\\nradio-specific tasks, achieving ~30% F1-score gains in extended source\\ndetection, but they underperform pure vision models and exhibit ~20% drop on\\ngeneral multimodal tasks. Inclusion of caption data and LoRA fine-tuning\\nenhances instruction-following and helps recover ~10% accuracy on standard\\nbenchmarks. This work lays the foundation for future advancements in radio\\nVLMs, highlighting their potential and limitations, such as the need for better\\nmultimodal alignment, higher-quality datasets, and mitigation of catastrophic\\nforgetting.\", \"main_category\": \"astro-ph.IM\", \"categories\": \"astro-ph.IM\", \"published\": \"2025-03-31T09:06:23Z\"}"}
