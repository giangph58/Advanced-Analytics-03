{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17366v1\", \"title\": \"LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from\\n  Live Streams\", \"summary\": \"Long-context understanding poses significant challenges in natural language\\nprocessing, particularly for real-world dialogues characterized by speech-based\\nelements, high redundancy, and uneven information density. Although large\\nlanguage models (LLMs) achieve impressive results on existing benchmarks, these\\ndatasets fail to reflect the complexities of such texts, limiting their\\napplicability to practical scenarios. To bridge this gap, we construct the\\nfirst spoken long-text dataset, derived from live streams, designed to reflect\\nthe redundancy-rich and conversational nature of real-world scenarios. We\\nconstruct tasks in three categories: retrieval-dependent, reasoning-dependent,\\nand hybrid. We then evaluate both popular LLMs and specialized methods to\\nassess their ability to understand long-contexts in these tasks. Our results\\nshow that current methods exhibit strong task-specific preferences and perform\\npoorly on highly redundant inputs, with no single method consistently\\noutperforming others. We propose a new baseline that better handles redundancy\\nin spoken text and achieves strong performance across tasks. Our findings\\nhighlight key limitations of current methods and suggest future directions for\\nimproving long-context understanding. Finally, our benchmark fills a gap in\\nevaluating long-context spoken language understanding and provides a practical\\nfoundation for developing real-world e-commerce systems. The code and benchmark\\nare available at https://github.com/Yarayx/livelongbench.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-24T08:27:48Z\"}"}
