{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11455v1\", \"title\": \"SimpleAR: Pushing the Frontier of Autoregressive Visual Generation\\n  through Pretraining, SFT, and RL\", \"summary\": \"This work presents SimpleAR, a vanilla autoregressive visual generation\\nframework without complex architecure modifications. Through careful\\nexploration of training and inference optimization, we demonstrate that: 1)\\nwith only 0.5B parameters, our model can generate 1024x1024 resolution images\\nwith high fidelity, and achieve competitive results on challenging\\ntext-to-image benchmarks, e.g., 0.59 on GenEval and 79.66 on DPG; 2) both\\nsupervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO)\\ntraining could lead to significant improvements on generation aesthectics and\\nprompt alignment; and 3) when optimized with inference acceleraton techniques\\nlike vLLM, the time for SimpleAR to generate an 1024x1024 image could be\\nreduced to around 14 seconds. By sharing these findings and open-sourcing the\\ncode, we hope to reveal the potential of autoregressive visual generation and\\nencourage more participation in this research field. Code is available at\\nhttps://github.com/wdrink/SimpleAR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T17:59:46Z\"}"}
