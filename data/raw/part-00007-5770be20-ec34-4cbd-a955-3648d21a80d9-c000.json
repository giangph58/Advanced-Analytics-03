{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14858v1\", \"title\": \"AlignRAG: An Adaptable Framework for Resolving Misalignments in\\n  Retrieval-Aware Reasoning of RAG\", \"summary\": \"Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\\nfor knowledge-grounded text generation. However, existing RAG pipelines often\\nfail to ensure that the reasoning trajectories align with the evidential\\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\\nmisalignment-the mismatch between a model's reasoning trajectory and the\\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\\ntest-time framework that mitigates reasoning misalignment through iterative\\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\\nrely on static training or post-hoc selection, AlignRAG actively refines\\nreasoning trajectories during inference by enforcing fine-grained alignment\\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\\nreasoning by: (1) constructing context-rich training corpora; (2) generating\\ncontrastive critiques from preference-aware reasoning trajectories; (3)\\ntraining a dedicated \\\\textit{Critic Language Model (CLM)} to identify reasoning\\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\\niteratively. Empirical results demonstrate that AlignRAG consistently\\noutperforms all baselines and could integrate as a plug-and-play module into\\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\\nstructured reasoning trajectory and establishing the test-time framework for\\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\\nadvancements for retrieval-aware generation.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL\", \"published\": \"2025-04-21T04:56:47Z\"}"}
