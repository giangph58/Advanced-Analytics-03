{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11833v1\", \"title\": \"Could Thinking Multilingually Empower LLM Reasoning?\", \"summary\": \"Previous work indicates that large language models exhibit a significant\\n\\\"English bias\\\", i.e. they often perform better when tasks are presented in\\nEnglish. Interestingly, we have observed that using certain other languages in\\nreasoning tasks can yield better performance than English. However, this\\nphenomenon remains under-explored. In this paper, we explore the upper bound of\\nharnessing multilingualism in reasoning tasks, suggesting that multilingual\\nreasoning promises significantly (by nearly 10 Acc@$k$ points) and robustly\\n(tolerance for variations in translation quality and language choice) higher\\nupper bounds than English-only reasoning. Besides analyzing the reason behind\\nthe upper bound and challenges in reaching it, we also find that common answer\\nselection methods cannot achieve this upper bound, due to their limitations and\\nbiases. These insights could pave the way for future research aimed at fully\\nharnessing the potential of multilingual reasoning in LLMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-16T07:45:10Z\"}"}
