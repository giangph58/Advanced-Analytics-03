{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10925v1\", \"title\": \"Transfer Learning for Temporal Link Prediction\", \"summary\": \"Link prediction on graphs has applications spanning from recommender systems\\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\\nlinks in a temporally evolving graph and adds additional complexity related to\\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\\nmodules alongside graph neural networks to learn both the temporal mechanisms\\nof incoming nodes and the evolving graph topology. However, memory modules only\\nstore information about nodes seen at train time, and hence such models cannot\\nbe directly transferred to entirely new graphs at test time and deployment. In\\nthis work, we study a new transfer learning task for temporal link prediction,\\nand develop transfer-effective methods for memory-laden models. Specifically,\\nmotivated by work showing the informativeness of structural signals for the TLP\\ntask, we augment a structural mapping module to the existing TLP model\\narchitectures, which learns a mapping from graph structural (topological)\\nfeatures to memory embeddings. Our work paves the way for a memory-free\\nfoundation model for TLP.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-15T07:12:00Z\"}"}
