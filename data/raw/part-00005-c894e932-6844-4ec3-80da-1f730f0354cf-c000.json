{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11116v1\", \"title\": \"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy\\n  Optimization for Continuous-Time Multi-Asset Portfolio\", \"summary\": \"Solving large-scale, continuous-time portfolio optimization problems\\ninvolving numerous assets and state-dependent dynamics has long been challenged\\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\\nmethods, while rigorous, typically become computationally intractable beyond a\\nsmall number of state variables (often limited to ~3-6 in prior numerical\\nstudies). To overcome this critical barrier, we introduce the\\n\\\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\\nleverages Pontryagin's Maximum Principle to directly guide neural network\\npolicies via backpropagation-through-time, naturally incorporating exogenous\\nstate processes without requiring dense state grids. Crucially, our\\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\\ncostate estimates derived from BPTT, converting them into near-optimal\\nclosed-form Pontryagin controls after only a short warm-up, significantly\\nreducing training overhead. This enables a breakthrough in scalability:\\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\\nwith dimensions previously considered far out of reach, optimizing portfolios\\nwith up to 50 assets and 10 state variables. The framework delivers\\nnear-optimal policies, offering a practical and powerful alternative for\\nhigh-dimensional continuous-time portfolio choice.\", \"main_category\": \"q-fin.PM\", \"categories\": \"q-fin.PM,q-fin.CP\", \"published\": \"2025-04-15T12:03:14Z\"}"}
