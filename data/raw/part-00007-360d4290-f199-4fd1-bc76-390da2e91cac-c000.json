{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10957v1\", \"title\": \"When is Task Vector Provably Effective for Model Editing? A\\n  Generalization Analysis of Nonlinear Transformers\", \"summary\": \"Task arithmetic refers to editing the pre-trained model by adding a weighted\\nsum of task vectors, each of which is the weight update from the pre-trained\\nmodel to fine-tuned models for certain tasks. This approach recently gained\\nattention as a computationally efficient inference method for model editing,\\ne.g., multi-task learning, forgetting, and out-of-domain generalization\\ncapabilities. However, the theoretical understanding of why task vectors can\\nexecute various conceptual operations remains limited, due to the highly\\nnon-convexity of training Transformer-based models. To the best of our\\nknowledge, this paper provides the first theoretical characterization of the\\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\\nconsider a conceptual learning setting, where each task is a binary\\nclassification problem based on a discriminative pattern. We theoretically\\nprove the effectiveness of task addition in simultaneously learning a set of\\nirrelevant or aligned tasks, as well as the success of task negation in\\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\\nthe proper selection of linear coefficients for task arithmetic to achieve\\nguaranteed generalization to out-of-domain tasks. All of our theoretical\\nresults hold for both dense-weight parameters and their low-rank\\napproximations. Although established in a conceptual setting, our theoretical\\nfindings were validated on a practical machine unlearning task using the large\\nlanguage model Phi-1.5 (1.3B).\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-15T08:04:39Z\"}"}
