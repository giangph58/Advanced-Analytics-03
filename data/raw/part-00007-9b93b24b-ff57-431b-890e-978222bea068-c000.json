{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15159v1\", \"title\": \"Acquire and then Adapt: Squeezing out Text-to-Image Model for Image\\n  Restoration\", \"summary\": \"Recently, pre-trained text-to-image (T2I) models have been extensively\\nadopted for real-world image restoration because of their powerful generative\\nprior. However, controlling these large models for image restoration usually\\nrequires a large number of high-quality images and immense computational\\nresources for training, which is costly and not privacy-friendly. In this\\npaper, we find that the well-trained large T2I model (i.e., Flux) is able to\\nproduce a variety of high-quality images aligned with real-world distributions,\\noffering an unlimited supply of training samples to mitigate the above issue.\\nSpecifically, we proposed a training data construction pipeline for image\\nrestoration, namely FluxGen, which includes unconditional image generation,\\nimage selection, and degraded image simulation. A novel light-weighted adapter\\n(FluxIR) with squeeze-and-excitation layers is also carefully designed to\\ncontrol the large Diffusion Transformer (DiT)-based T2I model so that\\nreasonable details can be restored. Experiments demonstrate that our proposed\\nmethod enables the Flux model to adapt effectively to real-world image\\nrestoration tasks, achieving superior scores and visual quality on both\\nsynthetic and real-world degradation datasets - at only about 8.5\\\\% of the\\ntraining cost compared to current approaches.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T15:05:22Z\"}"}
