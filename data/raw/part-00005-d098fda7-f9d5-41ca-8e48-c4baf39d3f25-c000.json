{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12796v1\", \"title\": \"A Survey on Cross-Modal Interaction Between Music and Multimodal Data\", \"summary\": \"Multimodal learning has driven innovation across various industries,\\nparticularly in the field of music. By enabling more intuitive interaction\\nexperiences and enhancing immersion, it not only lowers the entry barriers to\\nthe music but also increases its overall appeal. This survey aims to provide a\\ncomprehensive review of multimodal tasks related to music, outlining how music\\ncontributes to multimodal learning and offering insights for researchers\\nseeking to expand the boundaries of computational music. Unlike text and\\nimages, which are often semantically or visually intuitive, music primarily\\ninteracts with humans through auditory perception, making its data\\nrepresentation inherently less intuitive. Therefore, this paper first\\nintroduces the representations of music and provides an overview of music\\ndatasets. Subsequently, we categorize cross-modal interactions between music\\nand multimodal data into three types: music-driven cross-modal interactions,\\nmusic-oriented cross-modal interactions, and bidirectional music cross-modal\\ninteractions. For each category, we systematically trace the development of\\nrelevant sub-tasks, analyze existing limitations, and discuss emerging trends.\\nFurthermore, we provide a comprehensive summary of datasets and evaluation\\nmetrics used in multimodal tasks related to music, offering benchmark\\nreferences for future research. Finally, we discuss the current challenges in\\ncross-modal interactions involving music and propose potential directions for\\nfuture research.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM,cs.SD,eess.AS\", \"published\": \"2025-04-17T09:58:38Z\"}"}
