{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00422v1\", \"title\": \"Toward Automated Regulatory Decision-Making: Trustworthy Medical Device\\n  Risk Classification with Multimodal Transformers and Self-Training\", \"summary\": \"Accurate classification of medical device risk levels is essential for\\nregulatory oversight and clinical safety. We present a Transformer-based\\nmultimodal framework that integrates textual descriptions and visual\\ninformation to predict device regulatory classification. The model incorporates\\na cross-attention mechanism to capture intermodal dependencies and employs a\\nself-training strategy for improved generalization under limited supervision.\\nExperiments on a real-world regulatory dataset demonstrate that our approach\\nachieves up to 90.4% accuracy and 97.9% AUROC, significantly outperforming\\ntext-only (77.2%) and image-only (54.8%) baselines. Compared to standard\\nmultimodal fusion, the self-training mechanism improved SVM performance by 3.3\\npercentage points in accuracy (from 87.1% to 90.4%) and 1.4 points in macro-F1,\\nsuggesting that pseudo-labeling can effectively enhance generalization under\\nlimited supervision. Ablation studies further confirm the complementary\\nbenefits of both cross-modal attention and self-training.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CL\", \"published\": \"2025-05-01T09:41:41Z\"}"}
