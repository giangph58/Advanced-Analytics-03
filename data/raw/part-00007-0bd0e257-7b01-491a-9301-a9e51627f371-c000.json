{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09984v1\", \"title\": \"On Precomputation and Caching in Information Retrieval Experiments with\\n  Pipeline Architectures\", \"summary\": \"Modern information retrieval systems often rely on multiple components\\nexecuted in a pipeline. In a research setting, this can lead to substantial\\nredundant computations (e.g., retrieving the same query multiple times for\\nevaluating different downstream rerankers). To overcome this, researchers take\\ncached \\\"result\\\" files as inputs, which represent the output of another\\npipeline. However, these result files can be brittle and can cause a disconnect\\nbetween the conceptual design of the pipeline and its logical implementation.\\nTo overcome both the redundancy problem (when executing complete pipelines) and\\nthe disconnect problem (when relying on intermediate result files), we describe\\nour recent efforts to improve the caching capabilities in the open-source\\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\\ncaching of common pipeline prefixes when comparing systems and (2) explicit\\ncaching of operations through a new extension package, pyterrier-caching. These\\napproaches allow for the best of both worlds: pipelines can be fully expressed\\nend-to-end, while also avoiding redundant computations between pipelines.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-14T08:51:35Z\"}"}
