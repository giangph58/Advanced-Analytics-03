{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16423v1\", \"title\": \"Advancing Radar Hand Gesture Recognition: A Hybrid Spectrum Synthetic\\n  Framework Merging Simulation with Neural Networks\", \"summary\": \"Millimeter wave (mmWave) radar sensors play a vital role in hand gesture\\nrecognition (HGR) by detecting subtle motions while preserving user privacy.\\nHowever, the limited scale of radar datasets hinders the performance. Existing\\nsynthetic data generation methods fall short in two key areas. On the one hand,\\nmodeling-based approaches fail to accurately simulate the wave propagation and\\nreflection at the hand-gesture level, facing unique complexities such as\\ndiffraction and occlusion. On the other hand, generative model-based methods\\nare hard to converge while radar data is limited, lacking interpretability, and\\nsometimes fail to produce kinematically plausible results. To overcome these\\nlimitations, we propose a novel hybrid spectrum synthetic framework leveraging\\nvisual hand gesture data. It combines a cylinder mesh-based hand reflection\\nmodel with a small-scale neural network called RadarWeightNet, which focuses on\\nassigning weights to simulated signals. Our framework addresses two key\\nchallenges: achieving accurate simulation of complex hand geometry and bridging\\nthe simulation-to-real gap in a data-driven manner while preserving\\ninterpretability, which balances physical accuracy with machine learning\\nadaptability. We tested our framework under extreme scenarios where radar data\\nis scarce. The results demonstrate the effectiveness of our hybrid framework,\\nachieving up to 63% SSIM in synthetic performance and up to 30% improvement in\\nclassification performance in few-shot learning.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC\", \"published\": \"2025-04-23T05:15:43Z\"}"}
