{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20842v1\", \"title\": \"Language Model for Large-Text Transmission in Noisy Quantum\\n  Communications\", \"summary\": \"Quantum communication has the potential to revolutionize information\\nprocessing, providing unparalleled security and increased capacity compared to\\nits classical counterpart by using the principles of quantum mechanics.\\nHowever, the presence of noise remains a major barrier to realizing these\\nadvantages. While strategies like quantum error correction and mitigation have\\nbeen developed to address this challenge, they often come with substantial\\noverhead in physical qubits or sample complexity, limiting their practicality\\nfor large-scale information transfer. Here, we present an alternative approach:\\napplying machine learning frameworks from natural language processing to\\nenhance the performance of noisy quantum communications, focusing on superdense\\ncoding. By employing bidirectional encoder representations from transformers\\n(BERT), a model known for its capabilities in natural language processing, we\\ndemonstrate improvements in information transfer efficiency without resorting\\nto conventional error correction or mitigation techniques. These results mark a\\nstep toward the practical realization of a scalable and resilient quantum\\ninternet.\", \"main_category\": \"quant-ph\", \"categories\": \"quant-ph\", \"published\": \"2025-04-29T15:11:35Z\"}"}
