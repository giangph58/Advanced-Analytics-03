{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11092v1\", \"title\": \"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\\n  Inpainting\", \"summary\": \"Reconstructing 4D dynamic scenes from casually captured monocular videos is\\nvaluable but highly challenging, as each timestamp is observed from a single\\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\\nvideo synthesis by augmenting observation views - synthesizing multi-view\\nvideos from a monocular input. Unlike existing methods that either solely\\nleverage geometric priors for supervision or use generative priors while\\noverlooking geometry, we integrate both. This reformulates view augmentation as\\na video inpainting task, where observed views are warped into new viewpoints\\nbased on monocular depth priors. To achieve this, we train a video inpainting\\nmodel on unposed web videos with synthetically generated masks that mimic\\nwarping occlusions, ensuring spatially and temporally consistent completion of\\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\\nintroduce an iterative view augmentation strategy and a robust reconstruction\\nloss. Experiments demonstrate that our method effectively improves monocular 4D\\nscene reconstruction and completion.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T11:38:14Z\"}"}
