{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15099v1\", \"title\": \"Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training\\n  of GAN\", \"summary\": \"Up to now, the training processes of typical Generative Adversarial Networks\\n(GANs) are still particularly sensitive to data properties and hyperparameters,\\nwhich may lead to severe oscillations, difficulties in convergence, or even\\nfailures to converge, especially when the overall variances of the training\\nsets are large. These phenomena are often attributed to the training\\ncharacteristics of such networks. Aiming at the problem, this paper develops a\\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\\nemploys reinforcement learning in the training process of GANs to make training\\neasier. Specifically, this paper allows the training step size to be controlled\\nby an agent to improve training stability, and makes the training process more\\nintelligent with variable learning rates, making GANs less sensitive to step\\nsize. Experiments have been conducted on three benchmark datasets to verify the\\neffectiveness of the developed FSCO.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-21T13:41:09Z\"}"}
