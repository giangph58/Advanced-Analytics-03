{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10020v1\", \"title\": \"The Mirage of Performance Gains: Why Contrastive Decoding Fails to\\n  Address Multimodal Hallucination\", \"summary\": \"Contrastive decoding strategies are widely used to reduce hallucinations in\\nmultimodal large language models (MLLMs). These methods work by constructing\\ncontrastive samples to induce hallucinations and then suppressing them in the\\noutput distribution. However, this paper demonstrates that such approaches fail\\nto effectively mitigate the hallucination problem. The performance improvements\\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\\ncrude, unidirectional adjustments to the model's output distribution and (2)\\nthe adaptive plausibility constraint, which reduces the sampling strategy to\\ngreedy search. To further illustrate these issues, we introduce a series of\\nspurious improvement methods and evaluate their performance against contrastive\\ndecoding techniques. Experimental results reveal that the observed performance\\ngains in contrastive decoding are entirely unrelated to its intended goal of\\nmitigating hallucinations. Our findings challenge common assumptions about the\\neffectiveness of contrastive decoding strategies and pave the way for\\ndeveloping genuinely effective solutions to hallucinations in MLLMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.CV\", \"published\": \"2025-04-14T09:25:37Z\"}"}
