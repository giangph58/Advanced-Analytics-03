{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21309v1\", \"title\": \"An Evaluation of a Visual Question Answering Strategy for Zero-shot\\n  Facial Expression Recognition in Still Images\", \"summary\": \"Facial expression recognition (FER) is a key research area in computer vision\\nand human-computer interaction. Despite recent advances in deep learning,\\nchallenges persist, especially in generalizing to new scenarios. In fact,\\nzero-shot FER significantly reduces the performance of state-of-the-art FER\\nmodels. To address this problem, the community has recently started to explore\\nthe integration of knowledge from Large Language Models for visual tasks. In\\nthis work, we evaluate a broad collection of locally executed Visual Language\\nModels (VLMs), avoiding the lack of task-specific knowledge by adopting a\\nVisual Question Answering strategy. We compare the proposed pipeline with\\nstate-of-the-art FER models, both integrating and excluding VLMs, evaluating\\nwell-known FER benchmarks: AffectNet, FERPlus, and RAF-DB. The results show\\nexcellent performance for some VLMs in zero-shot FER scenarios, indicating the\\nneed for further exploration to improve FER generalization.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,I.2.10\", \"published\": \"2025-04-30T04:38:05Z\"}"}
