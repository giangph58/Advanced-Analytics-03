{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13123v1\", \"title\": \"Low-hallucination Synthetic Captions for Large-Scale Vision-Language\\n  Model Pre-training\", \"summary\": \"In recent years, the field of vision-language model pre-training has\\nexperienced rapid advancements, driven primarily by the continuous enhancement\\nof textual capabilities in large language models. However, existing training\\nparadigms for multimodal large language models heavily rely on high-quality\\nimage-text pairs. As models and data scales grow exponentially, the\\navailability of such meticulously curated data has become increasingly scarce\\nand saturated, thereby severely limiting further advancements in this domain.\\nThis study investigates scalable caption generation techniques for\\nvision-language model pre-training and demonstrates that large-scale\\nlow-hallucination synthetic captions can serve dual purposes: 1) acting as a\\nviable alternative to real-world data for pre-training paradigms and 2)\\nachieving superior performance enhancement when integrated into vision-language\\nmodels through empirical validation. This paper presents three key\\ncontributions: 1) a novel pipeline for generating high-quality,\\nlow-hallucination, and knowledge-rich synthetic captions. Our continuous DPO\\nmethodology yields remarkable results in reducing hallucinations. Specifically,\\nthe non-hallucination caption rate on a held-out test set increases from 48.2%\\nto 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals\\nthat our synthetic captions confer superior pre-training advantages over their\\ncounterparts. Across 35 vision language tasks, the model trained with our data\\nachieves a significant performance gain of at least 6.2% compared to alt-text\\npairs and other previous work. Meanwhile, it also offers considerable support\\nin the text-to-image domain. With our dataset, the FID score is reduced by 17.1\\non a real-world validation benchmark and 13.3 on the MSCOCO validation\\nbenchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and\\nknowledge-intensive synthetic caption dataset.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-17T17:40:06Z\"}"}
