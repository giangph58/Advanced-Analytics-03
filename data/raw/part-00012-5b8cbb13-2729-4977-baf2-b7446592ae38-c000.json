{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20781v1\", \"title\": \"Using LLMs in Generating Design Rationale for Software Architecture\\n  Decisions\", \"summary\": \"Design Rationale (DR) for software architecture decisions refers to the\\nreasoning underlying architectural choices, which provides valuable insights\\ninto the different phases of the architecting process throughout software\\ndevelopment. However, in practice, DR is often inadequately documented due to a\\nlack of motivation and effort from developers. With the recent advancements in\\nLarge Language Models (LLMs), their capabilities in text comprehension,\\nreasoning, and generation may enable the generation and recovery of DR for\\narchitecture decisions. In this study, we evaluated the performance of LLMs in\\ngenerating DR for architecture decisions. First, we collected 50 Stack Overflow\\n(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture\\ndecisions to construct a dataset of 100 architecture-related problems. Then, we\\nselected five LLMs to generate DR for the architecture decisions with three\\nprompting strategies, including zero-shot, chain of thought (CoT), and\\nLLM-based agents. With the DR provided by human experts as ground truth, the\\nPrecision of LLM-generated DR with the three prompting strategies ranges from\\n0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.\\nAdditionally, 64.45% to 69.42% of the arguments of DR not mentioned by human\\nexperts are also helpful, 4.12% to 4.87% of the arguments have uncertain\\ncorrectness, and 1.59% to 3.24% of the arguments are potentially misleading.\\nBased on the results, we further discussed the pros and cons of the three\\nprompting strategies and the strengths and limitations of the DR generated by\\nLLMs.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.AI\", \"published\": \"2025-04-29T14:00:18Z\"}"}
