{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02624v1\", \"title\": \"EmbodiedSense: Understanding Embodied Activities with Earphones\", \"summary\": \"In this paper, we propose EmbodiedSense, a sensing system based on commercial\\nearphones, which enables fine-grained activity logs using existing sensors. The\\nactivity logs record both user activities and the scenario in which the\\nactivities took place, benefiting detailed behavior understanding. By\\nunderstanding both the user and the environment, EmbodiedSense addresses three\\nmain challenges: the limited recognition capability caused by\\ninformation-hungry configurations (i.e., limited sensors available), the\\nineffective fusion to extract ambient information such as contextual scenarios,\\nand the interference from ambient noise. Specifically, EmbodiedSense consists\\nof a context-aware scenario recognition module and spatial-aware activity\\ndetection, which is further integrated with other attributes by expert\\nknowledge. We implement our system on commercial earphones equipped with\\nbinaural microphones and an Inertial Measurement Unit (IMU). By distinguishing\\nusage scenarios and identifying the source of sounds, EmbodiedSense enables\\nfine-grained activity logs in a zero-shot manner (evaluated with up to 41\\ncategories) and outperforms strong baselines like ImageBind-LLM by 38%\\nF1-score. Extensive evaluations demonstrate that EmbodiedSense is a promising\\nsolution for long-term and short-term activity logs and provides significant\\nbenefits in monitoring the wearer's daily life.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC\", \"published\": \"2025-04-03T14:21:35Z\"}"}
