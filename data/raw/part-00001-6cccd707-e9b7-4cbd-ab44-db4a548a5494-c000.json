{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05692v1\", \"title\": \"POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D\\n  Reconstruction\", \"summary\": \"3D reconstruction in dynamic scenes primarily relies on the combination of\\ngeometry estimation and matching modules where the latter task is pivotal for\\ndistinguishing dynamic regions which can help to mitigate the interference\\nintroduced by camera and object motion. Furthermore, the matching module\\nexplicitly models object motion, enabling the tracking of specific targets and\\nadvancing motion understanding in complex scenarios. Recently, the proposed\\nrepresentation of pointmap in DUSt3R suggests a potential solution to unify\\nboth geometry estimation and matching in 3D space, but it still struggles with\\nambiguous matching in dynamic regions, which may hamper further improvement. In\\nthis work, we present POMATO, a unified framework for dynamic 3D reconstruction\\nby marrying pointmap matching with temporal motion. Specifically, our method\\nfirst learns an explicit matching relationship by mapping RGB pixels from both\\ndynamic and static regions across different views to 3D pointmaps within a\\nunified coordinate system. Furthermore, we introduce a temporal motion module\\nfor dynamic motions that ensures scale consistency across different frames and\\nenhances performance in tasks requiring both precise geometry and reliable\\nmatching, most notably 3D point tracking. We show the effectiveness of the\\nproposed pointmap matching and temporal fusion paradigm by demonstrating the\\nremarkable performance across multiple downstream tasks, including video depth\\nestimation, 3D point tracking, and pose estimation. Code and models are\\npublicly available at https://github.com/wyddmw/POMATO.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-08T05:33:13Z\"}"}
