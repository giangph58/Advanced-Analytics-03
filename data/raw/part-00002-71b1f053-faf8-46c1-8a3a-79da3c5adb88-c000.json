{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03719v1\", \"title\": \"Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$\\n  Approach\", \"summary\": \"In this paper, we focus on a class of decentralized constraint-coupled\\noptimization problem: $\\\\min_{x_i \\\\in \\\\mathbb{R}^{d_i}, i \\\\in \\\\mathcal{I}; y \\\\in\\n\\\\mathbb{R}^p}$ $\\\\sum_{i=1}^n\\\\left(f_i(x_i) + g_i(x_i)\\\\right) + h(y) \\\\\\n\\\\text{s.t.} \\\\ \\\\sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected\\nnetwork of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private\\ninformation of agent $i \\\\in \\\\mathcal{I} = \\\\{1, \\\\cdots, n\\\\}$, while $h$ is\\npublic for all agents. Building on a novel dual$^2$ approach, we develop two\\naccelerated algorithms for solving this problem: the inexact Dual$^2$\\nAccelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$\\nAccelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A\\ncan guarantee asymptotic convergence under a milder condition on $h$ compared\\nto existing algorithms. Furthermore, linear convergence is established under\\nadditional assumptions. By employing specialized saddle-point subproblem\\nsolvers, iD2A and MiD2A attain significantly lower communication and\\ncomputational complexities than existing algorithms across various scenarios.\\nFinally, we conduct several numerical experiments to validate our theoretical\\nresults and to showcase the superior performance of iD2A and MiD2A in practice.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC,cs.SY,eess.SY\", \"published\": \"2025-05-06T17:46:49Z\"}"}
