{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00299v1\", \"title\": \"Intelligent Task Scheduling for Microservices via A3C-Based\\n  Reinforcement Learning\", \"summary\": \"To address the challenges of high resource dynamism and intensive task\\nconcurrency in microservice systems, this paper proposes an adaptive resource\\nscheduling method based on the A3C reinforcement learning algorithm. The\\nscheduling problem is modeled as a Markov Decision Process, where policy and\\nvalue networks are jointly optimized to enable fine-grained resource allocation\\nunder varying load conditions. The method incorporates an asynchronous\\nmulti-threaded learning mechanism, allowing multiple agents to perform parallel\\nsampling and synchronize updates to the global network parameters. This design\\nimproves both policy convergence efficiency and model stability. In the\\nexperimental section, a real-world dataset is used to construct a scheduling\\nscenario. The proposed method is compared with several typical approaches\\nacross multiple evaluation metrics, including task delay, scheduling success\\nrate, resource utilization, and convergence speed. The results show that the\\nproposed method delivers high scheduling performance and system stability in\\nmulti-task concurrent environments. It effectively alleviates the resource\\nallocation bottlenecks faced by traditional methods under heavy load,\\ndemonstrating its practical value for intelligent scheduling in microservice\\nsystems.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC,cs.LG\", \"published\": \"2025-05-01T04:42:48Z\"}"}
