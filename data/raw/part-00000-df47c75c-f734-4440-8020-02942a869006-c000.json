{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09927v1\", \"title\": \"Efficient Task-specific Conditional Diffusion Policies: Shortcut Model\\n  Acceleration and SO(3) Optimization\", \"summary\": \"Imitation learning, particularly Diffusion Policies based methods, has\\nrecently gained significant traction in embodied AI as a powerful approach to\\naction policy generation. These models efficiently generate action policies by\\nlearning to predict noise. However, conventional Diffusion Policy methods rely\\non iterative denoising, leading to inefficient inference and slow response\\ntimes, which hinder real-time robot control. To address these limitations, we\\npropose a Classifier-Free Shortcut Diffusion Policy (CF-SDP) that integrates\\nclassifier-free guidance with shortcut-based acceleration, enabling efficient\\ntask-specific action generation while significantly improving inference speed.\\nFurthermore, we extend diffusion modeling to the SO(3) manifold in shortcut\\nmodel, defining the forward and reverse processes in its tangent space with an\\nisotropic Gaussian distribution. This ensures stable and accurate rotational\\nestimation, enhancing the effectiveness of diffusion-based control. Our\\napproach achieves nearly 5x acceleration in diffusion inference compared to\\nDDIM-based Diffusion Policy while maintaining task performance. Evaluations\\nboth on the RoboTwin simulation platform and real-world scenarios across\\nvarious tasks demonstrate the superiority of our method.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-14T06:37:22Z\"}"}
