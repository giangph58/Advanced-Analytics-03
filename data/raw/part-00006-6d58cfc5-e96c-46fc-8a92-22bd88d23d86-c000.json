{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04600v1\", \"title\": \"Perpetuating Misogyny with Generative AI: How Model Personalization\\n  Normalizes Gendered Harm\", \"summary\": \"Open-source text-to-image (TTI) pipelines have become dominant in the\\nlandscape of AI-generated visual content, driven by technological advances that\\nenable users to personalize models through adapters tailored to specific tasks.\\nWhile personalization methods such as LoRA offer unprecedented creative\\nopportunities, they also facilitate harmful practices, including the generation\\nof non-consensual deepfakes and the amplification of misogynistic or\\nhypersexualized content. This study presents an exploratory sociotechnical\\nanalysis of CivitAI, the most active platform for sharing and developing\\nopen-source TTI models. Drawing on a dataset of more than 40 million\\nuser-generated images and over 230,000 models, we find a disproportionate rise\\nin not-safe-for-work (NSFW) content and a significant number of models intended\\nto mimic real individuals. We also observe a strong influence of internet\\nsubcultures on the tools and practices shaping model personalizations and\\nresulting visual media. In response to these findings, we contextualize the\\nemergence of exploitative visual media through feminist and constructivist\\nperspectives on technology, emphasizing how design choices and community\\ndynamics shape platform outcomes. Building on this analysis, we propose\\ninterventions aimed at mitigating downstream harm, including improved content\\nmoderation, rethinking tool design, and establishing clearer platform policies\\nto promote accountability and consent.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY\", \"published\": \"2025-05-07T17:43:52Z\"}"}
