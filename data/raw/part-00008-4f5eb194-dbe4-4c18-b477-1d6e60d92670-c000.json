{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12714v1\", \"title\": \"Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination\", \"summary\": \"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a\\ncooperative task, is a critical component of human-compatible AI. While prior\\nwork has focused on training agents to cooperate on a single task, these\\nspecialized models do not generalize to new tasks, even if they are highly\\nsimilar. Here, we study how reinforcement learning on a distribution of\\nenvironments with a single partner enables learning general cooperative skills\\nthat support ZSC with many new partners on many new problems. We introduce two\\nJax-based, procedural generators that create billions of solvable coordination\\nchallenges. We develop a new paradigm called Cross-Environment Cooperation\\n(CEC), and show that it outperforms competitive baselines quantitatively and\\nqualitatively when collaborating with real people. Our findings suggest that\\nlearning to collaborate across many unique scenarios encourages agents to\\ndevelop general norms, which prove effective for collaboration with different\\npartners. Together, our results suggest a new route toward designing generalist\\ncooperative agents capable of interacting with humans without requiring human\\ndata.\", \"main_category\": \"cs.MA\", \"categories\": \"cs.MA,cs.AI,cs.LG\", \"published\": \"2025-04-17T07:41:25Z\"}"}
