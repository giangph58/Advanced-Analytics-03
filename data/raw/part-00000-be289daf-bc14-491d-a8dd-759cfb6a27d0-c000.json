{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21411v1\", \"title\": \"Galvatron: An Automatic Distributed System for Efficient Foundation\\n  Model Training\", \"summary\": \"Galvatron is a distributed system for efficiently training large-scale\\nFoundation Models. It overcomes the complexities of selecting optimal\\nparallelism strategies by automatically identifying the most efficient hybrid\\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\\nparallelism, along with recomputation. The system's architecture includes a\\nprofiler for hardware and model analysis, a search engine for strategy\\noptimization using decision trees and dynamic programming, and a runtime for\\nexecuting these strategies efficiently. Benchmarking on various clusters\\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\\nThis open-source system offers user-friendly interfaces and comprehensive\\ndocumentation, making complex distributed training accessible and efficient.\\nThe source code of Galvatron is available at\\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC,cs.AI,cs.LG\", \"published\": \"2025-04-30T08:11:45Z\"}"}
