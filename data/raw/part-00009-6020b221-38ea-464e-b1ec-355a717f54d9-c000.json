{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04185v1\", \"title\": \"S3D: Sketch-Driven 3D Model Generation\", \"summary\": \"Generating high-quality 3D models from 2D sketches is a challenging task due\\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\\npresent S3D, a novel framework that converts simple hand-drawn sketches into\\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\\narchitecture to convert sketches into face segmentation masks, which are then\\nused to generate a 3D representation that can be rendered from novel views. To\\nensure robust consistency between the sketch domain and the 3D output, we\\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\\nfeatures with the initial encoder outputs of the 3D generation module,\\nsignificantly enhancing reconstruction fidelity. To further enhance the\\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\\nThis streamlined framework demonstrates the effectiveness of S3D in generating\\nhigh-quality 3D models from sketch inputs. The source code for this project is\\npublicly available at https://github.com/hailsong/S3D.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-05-07T07:34:37Z\"}"}
