{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15800v1\", \"title\": \"FinDER: Financial Dataset for Question Answering and Evaluating\\n  Retrieval-Augmented Generation\", \"summary\": \"In the fast-paced financial domain, accurate and up-to-date information is\\ncritical to addressing ever-evolving market conditions. Retrieving this\\ninformation correctly is essential in financial Question-Answering (QA), since\\nmany language models struggle with factual accuracy in this domain. We present\\nFinDER, an expert-generated dataset tailored for Retrieval-Augmented Generation\\n(RAG) in finance. Unlike existing QA datasets that provide predefined contexts\\nand rely on relatively clear and straightforward queries, FinDER focuses on\\nannotating search-relevant evidence by domain experts, offering 5,703\\nquery-evidence-answer triplets derived from real-world financial inquiries.\\nThese queries frequently include abbreviations, acronyms, and concise\\nexpressions, capturing the brevity and ambiguity common in the realistic search\\nbehavior of professionals. By challenging models to retrieve relevant\\ninformation from large corpora rather than relying on readily determined\\ncontexts, FinDER offers a more realistic benchmark for evaluating RAG systems.\\nWe further present a comprehensive evaluation of multiple state-of-the-art\\nretrieval models and Large Language Models, showcasing challenges derived from\\na realistic benchmark to drive future research on truthful and precise RAG in\\nthe financial domain.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-22T11:30:13Z\"}"}
