{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15241v1\", \"title\": \"MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning\", \"summary\": \"Large Language Models (LLMs) are susceptible to adversarial attacks such as\\njailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability\\nis exacerbated in multilingual setting, where multilingual safety-aligned data\\nare often limited. Thus, developing a guardrail capable of detecting and\\nfiltering unsafe content across diverse languages is critical for deploying\\nLLMs in real-world applications. In this work, we propose an approach to build\\na multilingual guardrail with reasoning. Our method consists of: (1) synthetic\\nmultilingual data generation incorporating culturally and linguistically\\nnuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group\\nRelative Policy Optimization (GRPO) framework that further improves\\nperformance. Experimental results demonstrate that our multilingual guardrail\\nconsistently outperforms recent baselines across both in-domain and\\nout-of-domain languages. The multilingual reasoning capability of our guardrail\\nenables it to generate multilingual explanations, which are particularly useful\\nfor understanding language-specific risks and ambiguities in multilingual\\ncontent moderation.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-21T17:15:06Z\"}"}
