{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19821v1\", \"title\": \"SILENT: A New Lens on Statistics in Software Timing Side Channels\", \"summary\": \"Cryptographic research takes software timing side channels seriously.\\nApproaches to mitigate them include constant-time coding and techniques to\\nenforce such practices. However, recent attacks like Meltdown [42], Spectre\\n[37], and Hertzbleed [70] have challenged our understanding of what it means\\nfor code to execute in constant time on modern CPUs. To ensure that assumptions\\non the underlying hardware are correct and to create a complete feedback loop,\\ndevelopers should also perform \\\\emph{timing measurements} as a final validation\\nstep to ensure the absence of exploitable side channels. Unfortunately, as\\nhighlighted by a recent study by Jancar et al. [30], developers often avoid\\nmeasurements due to the perceived unreliability of the statistical analysis and\\nits guarantees.\\n  In this work, we combat the view that statistical techniques only provide\\nweak guarantees by introducing a new algorithm for the analysis of timing\\nmeasurements with strong, formal statistical guarantees, giving developers a\\nreliable analysis tool. Specifically, our algorithm (1) is non-parametric,\\nmaking minimal assumptions about the underlying distribution and thus\\novercoming limitations of classical tests like the t-test, (2) handles unknown\\ndata dependencies in measurements, (3) can estimate in advance how many samples\\nare needed to detect a leak of a given size, and (4) allows the definition of a\\nnegligible leak threshold $\\\\Delta$, ensuring that acceptable non-exploitable\\nleaks do not trigger false positives, without compromising statistical\\nsoundness. We demonstrate the necessity, effectiveness, and benefits of our\\napproach on both synthetic benchmarks and real-world applications.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,stat.AP,stat.ME\", \"published\": \"2025-04-28T14:22:23Z\"}"}
