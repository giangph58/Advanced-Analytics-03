{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16899v1\", \"title\": \"Linear convergence of a one-cut conditional gradient method for total\\n  variation regularization\", \"summary\": \"We introduce a fully-corrective generalized conditional gradient method for\\nconvex minimization problems involving total variation regularization on\\nmultidimensional domains. It relies on alternating between updating an active\\nset of subsets of the spatial domain as well as of an iterate given by a conic\\ncombination of the associated characteristic functions. Different to previous\\napproaches in the same spirit, the computation of a new candidate set only\\nrequires the solution of one prescribed mean curvature problem instead of the\\nresolution of a fractional minimization task analogous to finding a generalized\\nCheeger set. After discretization, the former can be realized by a single run\\nof a graph cut algorithm leading to significant speedup in practice. We prove\\nthe global sublinear convergence of the resulting method, under mild\\nassumptions, and its asymptotic linear convergence in a more restrictive\\ntwo-dimensional setting which uses results of stability of surfaces of\\nprescribed curvature under perturbations of the curvature. Finally, we\\nnumerically demonstrate this convergence behavior in some model PDE-constrained\\nminimization problems.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC,cs.NA,math.NA\", \"published\": \"2025-04-23T17:27:06Z\"}"}
