{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00351v1\", \"title\": \"Integral Representations of Sobolev Spaces via ReLU$^k$ Activation\\n  Function and Optimal Error Estimates for Linearized Networks\", \"summary\": \"This paper presents two main theoretical results concerning shallow neural\\nnetworks with ReLU$^k$ activation functions. We establish a novel integral\\nrepresentation for Sobolev spaces, showing that every function in\\n$H^{\\\\frac{d+2k+1}{2}}(\\\\Omega)$ can be expressed as an $L^2$-weighted integral\\nof ReLU$^k$ ridge functions over the unit sphere. This result mirrors the known\\nrepresentation of Barron spaces and highlights a fundamental connection between\\nSobolev regularity and neural network representations. Moreover, we prove that\\nlinearized shallow networks -- constructed by fixed inner parameters and\\noptimizing only the linear coefficients -- achieve optimal approximation rates\\n$O(n^{-\\\\frac{1}{2}-\\\\frac{2k+1}{2d}})$ in Sobolev spaces.\", \"main_category\": \"math.NA\", \"categories\": \"math.NA,cs.NA\", \"published\": \"2025-05-01T06:50:41Z\"}"}
