{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20976v1\", \"title\": \"Real-Time Wayfinding Assistant for Blind and Low-Vision Users\", \"summary\": \"Navigating unfamiliar places continues to be one of the most persistent and\\nessential everyday obstacles for those who are blind or have limited vision\\n(BLV). Existing assistive technologies, such as GPS-based navigation systems,\\nAI-powered smart glasses, and sonar-equipped canes, often face limitations in\\nreal-time obstacle avoidance, precise localization, and adaptability to dynamic\\nsurroundings. To investigate potential solutions, we introduced PathFinder, a\\nnovel map-less navigation system that explores different models for\\nunderstanding 2D images, including Vision Language Models (VLMs), Large\\nLanguage Models (LLMs), and employs monocular depth estimation for free-path\\ndetection. Our approach integrates a Depth-First Search (DFS) algorithm on\\ndepth images to determine the longest obstacle-free path, ensuring optimal\\nroute selection while maintaining computational efficiency. We conducted\\ncomparative evaluations against existing AI-powered navigation methods and\\nperformed a usability study with BLV participants. The results demonstrate that\\nPathFinder achieves a favorable balance between accuracy, computational\\nefficiency, and real-time responsiveness. Notably, it reduces mean absolute\\nerror (MAE) and improves decision-making speed in outdoor navigation compared\\nto AI-based alternatives. Participant feedback emphasizes the system's\\nusability and effectiveness in outside situations, but also identifies issues\\nin complicated indoor locations and low-light conditions. Usability testing\\nrevealed that 73% of participants understood how to use the app in about a\\nminute, and 80% praised its balance of accuracy, quick response, and overall\\nconvenience.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC\", \"published\": \"2025-04-29T17:45:04Z\"}"}
