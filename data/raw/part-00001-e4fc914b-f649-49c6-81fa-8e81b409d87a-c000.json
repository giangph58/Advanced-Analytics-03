{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01928v1\", \"title\": \"Is the Reversal Curse a Binding Problem? Uncovering Limitations of\\n  Transformers from a Basic Generalization Failure\", \"summary\": \"Despite their impressive capabilities, LLMs exhibit a basic generalization\\nfailure known as the Reversal Curse, where they struggle to learn reversible\\nfactual associations. Understanding why this occurs could help identify\\nweaknesses in current models and advance their generalization and robustness.\\nIn this paper, we conjecture that the Reversal Curse in LLMs is a manifestation\\nof the long-standing binding problem in cognitive science, neuroscience and AI.\\nSpecifically, we identify two primary causes of the Reversal Curse stemming\\nfrom transformers' limitations in conceptual binding: the inconsistency and\\nentanglements of concept representations. We perform a series of experiments\\nthat support these conjectures. Our exploration leads to a model design based\\non JEPA (Joint-Embedding Predictive Architecture) that for the first time\\nbreaks the Reversal Curse without side-stepping it with specialized data\\naugmentation or non-causal masking, and moreover, generalization could be\\nfurther improved by incorporating special memory layers that support\\ndisentangled concept representations. We demonstrate that the skill of reversal\\nunlocks a new kind of memory integration that enables models to solve\\nlarge-scale arithmetic reasoning problems via parametric forward-chaining,\\noutperforming frontier LLMs based on non-parametric memory and prolonged\\nexplicit reasoning.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.LG\", \"published\": \"2025-04-02T17:38:03Z\"}"}
