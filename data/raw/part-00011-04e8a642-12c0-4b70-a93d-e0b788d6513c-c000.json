{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12039v1\", \"title\": \"RadMamba: Efficient Human Activity Recognition through Radar-based\\n  Micro-Doppler-Oriented Mamba State-Space Model\", \"summary\": \"Radar-based HAR has emerged as a promising alternative to conventional\\nmonitoring approaches, such as wearable devices and camera-based systems, due\\nto its unique privacy preservation and robustness advantages. However, existing\\nsolutions based on convolutional and recurrent neural networks, although\\neffective, are computationally demanding during deployment. This limits their\\napplicability in scenarios with constrained resources or those requiring\\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\\noffer improved modeling capabilities and have made efforts toward lightweight\\ndesigns. However, their computational complexity remains relatively high. To\\nleverage the strengths of transformer architectures while simultaneously\\nenhancing accuracy and reducing computational complexity, this paper introduces\\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\\nspecifically tailored for radar-based HAR. Across three diverse datasets,\\nRadMamba matches the top-performing previous model's 99.8% classification\\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\\nparameters. In scenarios with continuous sequences of actions evaluated on\\nDataset UoG2020, RadMamba surpasses other models with significantly higher\\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\\ncode is available at: https://github.com/lab-emi/AIRHAR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-16T12:54:11Z\"}"}
