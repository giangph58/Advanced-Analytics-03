{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20965v1\", \"title\": \"AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM\\n  Security\", \"summary\": \"We introduce AegisLLM, a cooperative multi-agent defense against adversarial\\nattacks and information leakage. In AegisLLM, a structured workflow of\\nautonomous agents - orchestrator, deflector, responder, and evaluator -\\ncollaborate to ensure safe and compliant LLM outputs, while self-improving over\\ntime through prompt optimization. We show that scaling agentic reasoning system\\nat test-time - both by incorporating additional agent roles and by leveraging\\nautomated prompt optimization (such as DSPy)- substantially enhances robustness\\nwithout compromising model utility. This test-time defense enables real-time\\nadaptability to evolving attacks, without requiring model retraining.\\nComprehensive evaluations across key threat scenarios, including unlearning and\\njailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning\\nbenchmark, AegisLLM achieves near-perfect unlearning with only 20 training\\nexamples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve\\n51% improvement compared to the base model on StrongReject, with false refusal\\nrates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our\\nresults highlight the advantages of adaptive, agentic reasoning over static\\ndefenses, establishing AegisLLM as a strong runtime alternative to traditional\\napproaches based on model modifications. Code is available at\\nhttps://github.com/zikuicai/aegisllm\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-29T17:36:05Z\"}"}
