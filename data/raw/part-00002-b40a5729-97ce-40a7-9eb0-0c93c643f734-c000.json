{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04251v1\", \"title\": \"Facilitating Trustworthy Human-Agent Collaboration in LLM-based\\n  Multi-Agent System oriented Software Engineering\", \"summary\": \"Multi-agent autonomous systems (MAS) are better at addressing challenges that\\nspans across multiple domains than singular autonomous agents. This holds true\\nwithin the field of software engineering (SE) as well. The state-of-the-art\\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\\nmajor challenges is the strategic allocation of tasks between humans and the\\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\\nframework is proposed in this work in progress article, along with\\nimplementation guidelines and an example implementation of the framework. The\\nproposed framework can facilitate efficient collaboration, ensure\\naccountability, and mitigate potential risks associated with LLM-driven\\nautomation while aligning with the Trustworthy AI guidelines. The future steps\\nfor this work delineating the planned empirical validation method are also\\npresented.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.AI,cs.MA\", \"published\": \"2025-05-07T08:55:15Z\"}"}
