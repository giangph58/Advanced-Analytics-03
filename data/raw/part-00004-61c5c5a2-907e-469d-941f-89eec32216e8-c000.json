{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12255v1\", \"title\": \"Human Aligned Compression for Robust Models\", \"summary\": \"Adversarial attacks on image models threaten system robustness by introducing\\nimperceptible perturbations that cause incorrect predictions. We investigate\\nhuman-aligned learned lossy compression as a defense mechanism, comparing two\\nlearned models (HiFiC and ELIC) against traditional JPEG across various quality\\nlevels. Our experiments on ImageNet subsets demonstrate that learned\\ncompression methods outperform JPEG, particularly for Vision Transformer\\narchitectures, by preserving semantically meaningful content while removing\\nadversarial noise. Even in white-box settings where attackers can access the\\ndefense, these methods maintain substantial effectiveness. We also show that\\nsequential compression--applying rounds of\\ncompression/decompression--significantly enhances defense efficacy while\\nmaintaining classification performance. Our findings reveal that human-aligned\\ncompression provides an effective, computationally efficient defense that\\nprotects the image features most relevant to human and machine understanding.\\nIt offers a practical approach to improving model robustness against\\nadversarial threats.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-16T17:05:58Z\"}"}
