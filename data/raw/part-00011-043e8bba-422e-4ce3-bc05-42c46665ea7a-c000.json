{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15199v1\", \"title\": \"Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's\\n  LLM-CLIP Framework for Image Captioning\", \"summary\": \"MILS (Multimodal Iterative LLM Solver) is a recently published framework that\\nclaims \\\"LLMs can see and hear without any training\\\" by leveraging an iterative,\\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\\napproach demonstrates good performance, our investigation reveals that this\\nsuccess comes at a hidden, substantial computational cost due to its expensive\\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\\nand GPT-4V achieve competitive results through a streamlined, single-pass\\napproach. We hypothesize that the significant overhead inherent in MILS's\\niterative process may undermine its practical benefits, thereby challenging the\\nnarrative that zero-shot performance can be attained without incurring heavy\\nresource demands. This work is the first to expose and quantify the trade-offs\\nbetween output quality and computational cost in MILS, providing critical\\ninsights for the design of more efficient multimodal models.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG,cs.PF\", \"published\": \"2025-04-21T16:16:19Z\"}"}
