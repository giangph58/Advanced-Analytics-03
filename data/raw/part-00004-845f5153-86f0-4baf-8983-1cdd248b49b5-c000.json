{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01596v1\", \"title\": \"DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and\\n  RGB Image\", \"summary\": \"Depth enhancement, which uses RGB images as guidance to convert raw signals\\nfrom dToF into high-precision, dense depth maps, is a critical task in computer\\nvision. Although existing super-resolution-based methods show promising results\\non public datasets, they often rely on idealized assumptions like accurate\\nregion correspondences and reliable dToF inputs, overlooking calibration errors\\nthat cause misalignment and anomaly signals inherent to dToF imaging, limiting\\nreal-world applicability. To address these challenges, we propose a novel\\ncompletion-based method, named DEPTHOR, featuring advances in both the training\\nstrategy and model architecture. First, we propose a method to simulate\\nreal-world dToF data from the accurate ground truth in synthetic datasets to\\nenable noise-robust training. Second, we design a novel network that\\nincorporates monocular depth estimation (MDE), leveraging global depth\\nrelationships and contextual information to improve prediction in challenging\\nregions. On the ZJU-L5 dataset, our training strategy significantly enhances\\ndepth completion models, achieving results comparable to depth super-resolution\\nmethods, while our model achieves state-of-the-art results, improving Rel and\\nRMSE by 27% and 18%, respectively. On a more challenging set of dToF samples we\\ncollected, our method outperforms SOTA methods on preliminary stereo-based GT,\\nimproving Rel and RMSE by 23% and 22%, respectively. Our Code is available at\\nhttps://github.com/ShadowBbBb/Depthor\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T11:02:21Z\"}"}
