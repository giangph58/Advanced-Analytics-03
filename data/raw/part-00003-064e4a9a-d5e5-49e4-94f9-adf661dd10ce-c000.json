{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05250v1\", \"title\": \"PEAKS: Selecting Key Training Examples Incrementally via Prediction\\n  Error Anchored by Kernel Similarity\", \"summary\": \"As deep learning continues to be driven by ever-larger datasets,\\nunderstanding which examples are most important for generalization has become a\\ncritical question. While progress in data selection continues, emerging\\napplications require studying this problem in dynamic contexts. To bridge this\\ngap, we pose the Incremental Data Selection (IDS) problem, where examples\\narrive as a continuous stream, and need to be selected without access to the\\nfull data source. In this setting, the learner must incrementally build a\\ntraining dataset of predefined size while simultaneously learning the\\nunderlying task. We find that in IDS, the impact of a new sample on the model\\nstate depends fundamentally on both its geometric relationship in the feature\\nspace and its prediction error. Leveraging this insight, we propose PEAKS\\n(Prediction Error Anchored by Kernel Similarity), an efficient data selection\\nmethod tailored for IDS. Our comprehensive evaluations demonstrate that PEAKS\\nconsistently outperforms existing selection strategies. Furthermore, PEAKS\\nyields increasingly better performance returns than random selection as\\ntraining data size grows on real-world datasets.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-07T16:42:09Z\"}"}
