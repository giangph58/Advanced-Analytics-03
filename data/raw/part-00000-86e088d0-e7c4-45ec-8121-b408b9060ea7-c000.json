{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24006v1\", \"title\": \"Comparing representations of long clinical texts for the task of patient\\n  note-identification\", \"summary\": \"In this paper, we address the challenge of patient-note identification, which\\ninvolves accurately matching an anonymized clinical note to its corresponding\\npatient, represented by a set of related notes. This task has broad\\napplications, including duplicate records detection and patient similarity\\nanalysis, which require robust patient-level representations. We explore\\nvarious embedding methods, including Hierarchical Attention Networks (HAN),\\nthree-level Hierarchical Transformer Networks (HTN), LongFormer, and advanced\\nBERT-based models, focusing on their ability to process mediumto-long clinical\\ntexts effectively. Additionally, we evaluate different pooling strategies\\n(mean, max, and mean_max) for aggregating wordlevel embeddings into\\npatient-level representations and we examine the impact of sliding windows on\\nmodel performance. Our results indicate that BERT-based embeddings outperform\\ntraditional and hierarchical models, particularly in processing lengthy\\nclinical notes and capturing nuanced patient representations. Among the pooling\\nstrategies, mean_max pooling consistently yields the best results, highlighting\\nits ability to capture critical features from clinical notes. Furthermore, the\\nreproduction of our results on both MIMIC dataset and Necker hospital data\\nwarehouse illustrates the generalizability of these approaches to real-world\\napplications, emphasizing the importance of both embedding methods and\\naggregation strategies in optimizing patient-note identification and enhancing\\npatient-level modeling.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-03-31T12:31:44Z\"}"}
