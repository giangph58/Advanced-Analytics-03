{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11397v1\", \"title\": \"MLPs and KANs for data-driven learning in physical problems: A\\n  performance comparison\", \"summary\": \"There is increasing interest in solving partial differential equations (PDEs)\\nby casting them as machine learning problems. Recently, there has been a spike\\nin exploring Kolmogorov-Arnold Networks (KANs) as an alternative to traditional\\nneural networks represented by Multi-Layer Perceptrons (MLPs). While showing\\npromise, their performance advantages in physics-based problems remain largely\\nunexplored. Several critical questions persist: Can KANs capture complex\\nphysical dynamics and under what conditions might they outperform traditional\\narchitectures? In this work, we present a comparative study of KANs and MLPs\\nfor learning physical systems governed by PDEs. We assess their performance\\nwhen applied in deep operator networks (DeepONet) and graph network-based\\nsimulators (GNS), and test them on physical problems that vary significantly in\\nscale and complexity. Drawing inspiration from the Kolmogorov Representation\\nTheorem, we examine the behavior of KANs and MLPs across shallow and deep\\nnetwork architectures. Our results reveal that although KANs do not\\nconsistently outperform MLPs when configured as deep neural networks, they\\ndemonstrate superior expressiveness in shallow network settings, significantly\\noutpacing MLPs in accuracy over our test cases. This suggests that KANs are a\\npromising choice, offering a balance of efficiency and accuracy in applications\\ninvolving physical systems.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,physics.comp-ph\", \"published\": \"2025-04-15T17:13:42Z\"}"}
