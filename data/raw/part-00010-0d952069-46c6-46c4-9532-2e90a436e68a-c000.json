{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15090v1\", \"title\": \"Federated Latent Factor Model for Bias-Aware Recommendation with\\n  Privacy-Preserving\", \"summary\": \"A recommender system (RS) aims to provide users with personalized item\\nrecommendations, enhancing their overall experience. Traditional RSs collect\\nand process all user data on a central server. However, this centralized\\napproach raises significant privacy concerns, as it increases the risk of data\\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\\nprivacy-sensitive users. To address these privacy challenges, federated\\nlearning has been integrated into RSs, ensuring that user data remains secure.\\nIn centralized RSs, the issue of rating bias is effectively addressed by\\njointly analyzing all users' raw interaction data. However, this becomes a\\nsignificant challenge in federated RSs, as raw data is no longer accessible due\\nto privacy-preserving constraints. To overcome this problem, we propose a\\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\\nexplicitly incorporated into every local model's loss function, allowing for\\nthe effective elimination of rating bias without compromising data privacy.\\nExtensive experiments conducted on three real-world datasets demonstrate that\\nFBALF achieves significantly higher recommendation accuracy compared to other\\nstate-of-the-art federated RSs.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-21T13:24:30Z\"}"}
