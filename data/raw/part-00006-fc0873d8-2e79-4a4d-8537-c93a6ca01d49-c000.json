{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10105v1\", \"title\": \"Global and Local Mamba Network for Multi-Modality Medical Image\\n  Super-Resolution\", \"summary\": \"Convolutional neural networks and Transformer have made significant\\nprogresses in multi-modality medical image super-resolution. However, these\\nmethods either have a fixed receptive field for local learning or significant\\ncomputational burdens for global learning, limiting the super-resolution\\nperformance. To solve this problem, State Space Models, notably Mamba, is\\nintroduced to efficiently model long-range dependencies in images with linear\\ncomputational complexity. Relying on the Mamba and the fact that low-resolution\\nimages rely on global information to compensate for missing details, while\\nhigh-resolution reference images need to provide more local details for\\naccurate super-resolution, we propose a global and local Mamba network\\n(GLMamba) for multi-modality medical image super-resolution. To be specific,\\nour GLMamba is a two-branch network equipped with a global Mamba branch and a\\nlocal Mamba branch. The global Mamba branch captures long-range relationships\\nin low-resolution inputs, and the local Mamba branch focuses more on\\nshort-range details in high-resolution reference images. We also use the deform\\nblock to adaptively extract features of both branches to enhance the\\nrepresentation ability. A modulator is designed to further enhance deformable\\nfeatures in both global and local Mamba blocks. To fully integrate the\\nreference image for low-resolution image super-resolution, we further develop a\\nmulti-modality feature fusion block to adaptively fuse features by considering\\nsimilarities, differences, and complementary aspects between modalities. In\\naddition, a contrastive edge loss (CELoss) is developed for sufficient\\nenhancement of edge textures and contrast in medical images.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T11:14:24Z\"}"}
