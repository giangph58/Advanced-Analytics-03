{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05995v1\", \"title\": \"NativQA Framework: Enabling LLMs with Native, Local, and Everyday\\n  Knowledge\", \"summary\": \"The rapid advancement of large language models (LLMs) has raised concerns\\nabout cultural bias, fairness, and their applicability in diverse linguistic\\nand underrepresented regional contexts. To enhance and benchmark the\\ncapabilities of LLMs, there is a need to develop large-scale resources focused\\non multilingual, local, and cultural contexts. In this study, we propose a\\nframework, NativQA, that can seamlessly construct large-scale, culturally and\\nregionally aligned QA datasets in native languages. The framework utilizes\\nuser-defined seed queries and leverages search engines to collect\\nlocation-specific, everyday information. It has been evaluated across 39\\nlocations in 24 countries and in 7 languages, ranging from extremely\\nlow-resource to high-resource languages, which resulted over 300K Question\\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\\nfurther fine-tuning. The framework has been made publicly available for the\\ncommunity (https://gitlab.com/nativqa/nativqa-framework).\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-08T13:01:51Z\"}"}
