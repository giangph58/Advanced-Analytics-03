{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05103v1\", \"title\": \"A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple\\n  Large Language Models Network\", \"summary\": \"Large Language Models (LLMs) have achieved remarkable success across a wide\\nrange of applications. However, individual LLMs often produce inconsistent,\\nbiased, or hallucinated outputs due to limitations in their training corpora\\nand model architectures. Recently, collaborative frameworks such as the\\nMulti-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to\\ninteract and jointly respond to user queries. Nevertheless, MultiLLMN\\narchitectures raise critical concerns regarding the reliability and security of\\nthe generated content, particularly in open environments where malicious or\\ncompromised LLMs may be present. Moreover, reliance on centralized coordination\\nundermines system efficiency and introduces single points of failure. In this\\npaper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted\\nByzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the\\nreliability, security, and efficiency of multi-LLM collaboration. In WBFT,\\nvoting weights are adaptively assigned to each LLM based on its response\\nquality and trustworthiness, incentivizing reliable behavior, and reducing the\\nimpact of malicious nodes. Extensive simulations demonstrate that WBFT\\nsignificantly improves both consensus security and efficiency compared to\\nclassical and modern consensus mechanisms, particularly under wireless network\\nconditions. Furthermore, our evaluations reveal that Trusted MultiLLMN\\nsupported by WBFT can deliver higher-quality and more credible responses than\\nboth single LLMs and conventional MultiLLMNs, thereby providing a promising\\npath toward building robust, decentralized AI collaboration networks.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.NI\", \"published\": \"2025-05-08T10:04:41Z\"}"}
