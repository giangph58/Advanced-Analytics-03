{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20658v1\", \"title\": \"TrueFake: A Real World Case Dataset of Last Generation Fake Images also\\n  Shared on Social Networks\", \"summary\": \"AI-generated synthetic media are increasingly used in real-world scenarios,\\noften with the purpose of spreading misinformation and propaganda through\\nsocial media platforms, where compression and other processing can degrade fake\\ndetection cues. Currently, many forensic tools fail to account for these\\nin-the-wild challenges. In this work, we introduce TrueFake, a large-scale\\nbenchmarking dataset of 600,000 images including top notch generative\\ntechniques and sharing via three different social networks. This dataset allows\\nfor rigorous evaluation of state-of-the-art fake image detectors under very\\nrealistic and challenging conditions. Through extensive experimentation, we\\nanalyze how social media sharing impacts detection performance, and identify\\ncurrent most effective detection and training strategies. Our findings\\nhighlight the need for evaluating forensic models in conditions that mirror\\nreal-world use.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM,cs.AI,cs.CV\", \"published\": \"2025-04-29T11:33:52Z\"}"}
