{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05089v1\", \"title\": \"Nonlinear Motion-Guided and Spatio-Temporal Aware Network for\\n  Unsupervised Event-Based Optical Flow\", \"summary\": \"Event cameras have the potential to capture continuous motion information\\nover time and space, making them well-suited for optical flow estimation.\\nHowever, most existing learning-based methods for event-based optical flow\\nadopt frame-based techniques, ignoring the spatio-temporal characteristics of\\nevents. Additionally, these methods assume linear motion between consecutive\\nevents within the loss time window, which increases optical flow errors in\\nlong-time sequences. In this work, we observe that rich spatio-temporal\\ninformation and accurate nonlinear motion between events are crucial for\\nevent-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel\\nunsupervised event-based optical flow network focusing on long-time sequences.\\nWe propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an\\nAdaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich\\nspatio-temporal information to learn spatio-temporal data associations.\\nMeanwhile, we propose a nonlinear motion compensation loss that utilizes the\\naccurate nonlinear motion between events to improve the unsupervised learning\\nof our network. Extensive experiments demonstrate the effectiveness and\\nsuperiority of our method. Remarkably, our method ranks first among\\nunsupervised learning methods on the MVSEC and DSEC-Flow datasets. Our project\\npage is available at https://wynelio.github.io/E-NMSTFlow.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T09:39:19Z\"}"}
