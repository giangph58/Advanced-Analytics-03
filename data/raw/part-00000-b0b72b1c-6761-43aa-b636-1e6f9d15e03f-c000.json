{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19838v1\", \"title\": \"LLM-Powered GUI Agents in Phone Automation: Surveying Progress and\\n  Prospects\", \"summary\": \"With the rapid rise of large language models (LLMs), phone automation has\\nundergone transformative changes. This paper systematically reviews LLM-driven\\nphone GUI agents, highlighting their evolution from script-based automation to\\nintelligent, adaptive systems. We first contextualize key challenges, (i)\\nlimited generality, (ii) high maintenance overhead, and (iii) weak intent\\ncomprehension, and show how LLMs address these issues through advanced language\\nunderstanding, multimodal perception, and robust decision-making. We then\\npropose a taxonomy covering fundamental agent frameworks (single-agent,\\nmulti-agent, plan-then-act), modeling approaches (prompt engineering,\\ntraining-based), and essential datasets and benchmarks. Furthermore, we detail\\ntask-specific architectures, supervised fine-tuning, and reinforcement learning\\nstrategies that bridge user intent and GUI operations. Finally, we discuss open\\nchallenges such as dataset diversity, on-device deployment efficiency,\\nuser-centric adaptation, and security concerns, offering forward-looking\\ninsights into this rapidly evolving field. By providing a structured overview\\nand identifying pressing research gaps, this paper serves as a definitive\\nreference for researchers and practitioners seeking to harness LLMs in\\ndesigning scalable, user-friendly phone GUI agents.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC\", \"published\": \"2025-04-28T14:39:25Z\"}"}
