{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12156v1\", \"title\": \"Predictive Multiplicity in Survival Models: A Method for Quantifying\\n  Model Uncertainty in Predictive Maintenance Applications\", \"summary\": \"In many applications, especially those involving prediction, models may yield\\nnear-optimal performance yet significantly disagree on individual-level\\noutcomes. This phenomenon, known as predictive multiplicity, has been formally\\ndefined in binary, probabilistic, and multi-target classification, and\\nundermines the reliability of predictive systems. However, its implications\\nremain unexplored in the context of survival analysis, which involves\\nestimating the time until a failure or similar event while properly handling\\ncensored data. We frame predictive multiplicity as a critical concern in\\nsurvival-based models and introduce formal measures -- ambiguity, discrepancy,\\nand obscurity -- to quantify it. This is particularly relevant for downstream\\ntasks such as maintenance scheduling, where precise individual risk estimates\\nare essential. Understanding and reporting predictive multiplicity helps build\\ntrust in models deployed in high-stakes environments. We apply our methodology\\nto benchmark datasets from predictive maintenance, extending the notion of\\nmultiplicity to survival models. Our findings show that ambiguity steadily\\nincreases, reaching up to 40-45% of observations; discrepancy is lower but\\nexhibits a similar trend; and obscurity remains mild and concentrated in a few\\nmodels. These results demonstrate that multiple accurate survival models may\\nyield conflicting estimations of failure risk and degradation progression for\\nthe same equipment. This highlights the need to explicitly measure and\\ncommunicate predictive multiplicity to ensure reliable decision-making in\\nprocess health management.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-16T15:04:00Z\"}"}
