{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15867v1\", \"title\": \"Inducing Vulnerable Code Generation in LLM Coding Assistants\", \"summary\": \"Due to insufficient domain knowledge, LLM coding assistants often reference\\nrelated solutions from the Internet to address programming problems. However,\\nincorporating external information into LLMs' code generation process\\nintroduces new security risks. In this paper, we reveal a real-world threat,\\nnamed HACKODE, where attackers exploit referenced external information to embed\\nattack sequences, causing LLMs to produce code with vulnerabilities such as\\nbuffer overflows and incomplete validations. We designed a prototype of the\\nattack, which generates effective attack sequences for potential diverse inputs\\nwith various user queries and prompt templates. Through the evaluation on two\\ngeneral LLMs and two code LLMs, we demonstrate that the attack is effective,\\nachieving an 84.29% success rate. Additionally, on a real-world application,\\nHACKODE achieves 75.92% ASR, demonstrating its real-world impact.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-22T13:09:20Z\"}"}
