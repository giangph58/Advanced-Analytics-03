{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21723v1\", \"title\": \"OccRobNet : Occlusion Robust Network for Accurate 3D Interacting\\n  Hand-Object Pose Estimation\", \"summary\": \"Occlusion is one of the challenging issues when estimating 3D hand pose. This\\nproblem becomes more prominent when hand interacts with an object or two hands\\nare involved. In the past works, much attention has not been given to these\\noccluded regions. But these regions contain important and beneficial\\ninformation that is vital for 3D hand pose estimation. Thus, in this paper, we\\npropose an occlusion robust and accurate method for the estimation of 3D\\nhand-object pose from the input RGB image. Our method includes first localising\\nthe hand joints using a CNN based model and then refining them by extracting\\ncontextual information. The self attention transformer then identifies the\\nspecific joints along with the hand identity. This helps the model to identify\\nthe hand belongingness of a particular joint which helps to detect the joint\\neven in the occluded region. Further, these joints with hand identity are then\\nused to estimate the pose using cross attention mechanism. Thus, by identifying\\nthe joints in the occluded region, the obtained network becomes robust to\\nocclusion. Hence, this network achieves state-of-the-art results when evaluated\\non the InterHand2.6M, HO3D and H$_2$O3D datasets.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.HC\", \"published\": \"2025-03-27T17:36:55Z\"}"}
