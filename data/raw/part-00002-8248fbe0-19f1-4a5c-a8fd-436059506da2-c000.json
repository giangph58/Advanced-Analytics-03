{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10322v1\", \"title\": \"Efficient Prompt Tuning for Hierarchical Ingredient Recognition\", \"summary\": \"Fine-grained ingredient recognition presents a significant challenge due to\\nthe diverse appearances of ingredients, resulting from different cutting and\\ncooking methods. While existing approaches have shown promising results, they\\nstill require extensive training costs and focus solely on fine-grained\\ningredient recognition. In this paper, we address these limitations by\\nintroducing an efficient prompt-tuning framework that adapts pretrained\\nvisual-language models (VLMs), such as CLIP, to the ingredient recognition task\\nwithout requiring full model finetuning. Additionally, we introduce three-level\\ningredient hierarchies to enhance both training performance and evaluation\\nrobustness. Specifically, we propose a hierarchical ingredient recognition\\ntask, designed to evaluate model performance across different hierarchical\\nlevels (e.g., chicken chunks, chicken, meat), capturing recognition\\ncapabilities from coarse- to fine-grained categories. Our method leverages\\nhierarchical labels, training prompt-tuned models with both fine-grained and\\ncorresponding coarse-grained labels. Experimental results on the VireoFood172\\ndataset demonstrate the effectiveness of prompt-tuning with hierarchical\\nlabels, achieving superior performance. Moreover, the hierarchical ingredient\\nrecognition task provides valuable insights into the model's ability to\\ngeneralize across different levels of ingredient granularity.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM\", \"published\": \"2025-04-14T15:30:49Z\"}"}
