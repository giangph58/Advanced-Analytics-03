{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04300v1\", \"title\": \"Sparsity is All You Need: Rethinking Biological Pathway-Informed\\n  Approaches in Deep Learning\", \"summary\": \"Biologically-informed neural networks typically leverage pathway annotations\\nto enhance performance in biomedical applications. We hypothesized that the\\nbenefits of pathway integration does not arise from its biological relevance,\\nbut rather from the sparsity it introduces. We conducted a comprehensive\\nanalysis of all relevant pathway-based neural network models for predictive\\ntasks, critically evaluating each study's contributions. From this review, we\\ncurated a subset of methods for which the source code was publicly available.\\nThe comparison of the biologically informed state-of-the-art deep learning\\nmodels and their randomized counterparts showed that models based on randomized\\ninformation performed equally well as biologically informed ones across\\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\\nthe randomized versions even outperformed their biologically informed\\ncounterparts. Moreover, pathway-informed models did not show any clear\\nadvantage in interpretability, as randomized models were still able to identify\\nrelevant disease biomarkers despite lacking explicit pathway information. Our\\nfindings suggest that pathway annotations may be too noisy or inadequately\\nexplored by current methods. Therefore, we propose a methodology that can be\\napplied to different domains and can serve as a robust benchmark for\\nsystematically comparing novel pathway-informed models against their randomized\\ncounterparts. This approach enables researchers to rigorously determine whether\\nobserved performance improvements can be attributed to biological insights.\", \"main_category\": \"q-bio.QM\", \"categories\": \"q-bio.QM,cs.AI,cs.LG\", \"published\": \"2025-05-07T10:14:31Z\"}"}
