{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14952v1\", \"title\": \"PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for\\n  PIV\", \"summary\": \"Deep learning algorithms have significantly reduced the computational time\\nand improved the spatial resolution of particle image velocimetry~(PIV).\\nHowever, the models trained on synthetic datasets might have a degraded\\nperformance on practical particle images due to domain gaps. As a result,\\nspecial residual patterns are often observed for the vector fields of deep\\nlearning-based estimators. To reduce the special noise step-by-step, we employ\\na denoising diffusion model~(FlowDiffuser) for PIV analysis. And the\\ndata-hungry iterative denoising diffusion model is trained via a transfer\\nlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)\\npre-training a FlowDiffuser model with multiple optical flow datasets of the\\ncomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the\\npre-trained model on synthetic PIV datasets. Note that the PIV images are\\nupsampled by a factor of two to resolve the small-scale turbulent flow\\nstructures. The visualized results indicate that our PIV-FlowDiffuser\\neffectively suppresses the noise patterns. Therefore, the denoising diffusion\\nmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV\\nbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits\\nenhanced generalization performance on unseen particle images due to transfer\\nlearning. Overall, this study highlights the transfer-learning-based denoising\\ndiffusion models for PIV. And a detailed implementation is recommended for\\ninterested readers in the repository\\nhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-21T08:22:58Z\"}"}
