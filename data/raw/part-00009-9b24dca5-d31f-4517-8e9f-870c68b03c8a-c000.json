{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03168v1\", \"title\": \"Approximation of Markov Chain Expectations and the Key Role of\\n  Stationary Distribution Convergence\", \"summary\": \"Consider a sequence $P_n$ of positive recurrent transition matrices or\\nkernels that approximate a limiting infinite state matrix or kernel\\n$P_{\\\\infty}$. Such approximations arise naturally when one truncates an\\ninfinite state Markov chain and replaces it with a finite state approximation.\\nIt also describes the situation in which $P_{\\\\infty}$ is a simplified limiting\\napproximation to $P_n$ when $n$ is large. In both settings, it is often\\nverified that the approximation $P_n$ has the characteristic that its\\nstationary distribution $\\\\pi_n$ converges to the stationary distribution\\n$\\\\pi_{\\\\infty}$ associated with the limit. In this paper, we show that when the\\nstate space is countably infinite, this stationary distribution convergence\\nimplies that $P_n^m$ can be approximated uniformly in $m$ by $P_{\\\\infty}^m$\\nwhen n is large. We show that this ability to approximate the marginal\\ndistributions at all time scales $m$ fails in continuous state space, but is\\nvalid when the convergence is in total variation or when we have weak\\nconvergence and the kernels are suitably Lipschitz. When the state space is\\ndiscrete (as in the truncation setting), we further show that stationary\\ndistribution convergence also implies that all the expectations that are\\ncomputable via first transition analysis (e.g. mean hitting times, expected\\ninfinite horizon discounted rewards) converge to those associated with the\\nlimit $P_{\\\\infty}$. Simply put, we show that once one has established\\nstationary distribution convergence, one immediately can infer convergence for\\na huge range of other expectations.\", \"main_category\": \"math.PR\", \"categories\": \"math.PR\", \"published\": \"2025-05-06T04:25:03Z\"}"}
