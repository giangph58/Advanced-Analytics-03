{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04231v1\", \"title\": \"Multi-Agent Reinforcement Learning-based Cooperative Autonomous Driving\\n  in Smart Intersections\", \"summary\": \"Unsignalized intersections pose significant safety and efficiency challenges\\ndue to complex traffic flows. This paper proposes a novel roadside unit\\n(RSU)-centric cooperative driving system leveraging global perception and\\nvehicle-to-infrastructure (V2I) communication. The core of the system is an\\nRSU-based decision-making module using a two-stage hybrid reinforcement\\nlearning (RL) framework. At first, policies are pre-trained offline using\\nconservative Q-learning (CQL) combined with behavior cloning (BC) on collected\\ndataset. Subsequently, these policies are fine-tuned in the simulation using\\nmulti-agent proximal policy optimization (MAPPO), aligned with a self-attention\\nmechanism to effectively solve inter-agent dependencies. RSUs perform real-time\\ninference based on the trained models to realize vehicle control via V2I\\ncommunications. Extensive experiments in CARLA environment demonstrate high\\neffectiveness of the proposed system, by: \\\\textit{(i)} achieving failure rates\\nbelow 0.03\\\\% in coordinating three connected and autonomous vehicles (CAVs)\\nthrough complex intersection scenarios, significantly outperforming the\\ntraditional Autoware control method, and \\\\textit{(ii)} exhibiting strong\\nrobustness across varying numbers of controlled agents and shows promising\\ngeneralization capabilities on other maps.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.MA,cs.SY,eess.SY\", \"published\": \"2025-05-07T08:27:52Z\"}"}
