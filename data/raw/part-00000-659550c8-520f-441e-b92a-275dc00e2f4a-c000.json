{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24057v1\", \"title\": \"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\\n  Micro-Expression Recognition\", \"summary\": \"Micro-expressions are typically regarded as unconscious manifestations of a\\nperson's genuine emotions. However, their short duration and subtle signals\\npose significant challenges for downstream recognition. We propose a multi-task\\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\\nmicro-expressions through self-supervised subtle motion magnification, while\\nthe sparse spatial selection Mamba architecture combines sparse activation with\\nthe advanced Visual Mamba model to model key motion regions and their valuable\\nrepresentations more effectively. Additionally, we employ evolutionary search\\nto optimize the magnification factor and the sparsity ratios of spatial\\nselection, followed by fine-tuning to improve performance further. Extensive\\nexperiments on two standard datasets demonstrate that the proposed AMMSM\\nachieves state-of-the-art (SOTA) accuracy and robustness.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T13:17:43Z\"}"}
