{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20042v1\", \"title\": \"CompleteMe: Reference-based Human Image Completion\", \"summary\": \"Recent methods for human image completion can reconstruct plausible body\\nshapes but often fail to preserve unique details, such as specific clothing\\npatterns or distinctive accessories, without explicit reference images. Even\\nstate-of-the-art reference-based inpainting approaches struggle to accurately\\ncapture and integrate fine-grained details from reference images. To address\\nthis limitation, we propose CompleteMe, a novel reference-based human image\\ncompletion framework. CompleteMe employs a dual U-Net architecture combined\\nwith a Region-focused Attention (RFA) Block, which explicitly guides the\\nmodel's attention toward relevant regions in reference images. This approach\\neffectively captures fine details and ensures accurate semantic correspondence,\\nsignificantly improving the fidelity and consistency of completed images.\\nAdditionally, we introduce a challenging benchmark specifically designed for\\nevaluating reference-based human image completion tasks. Extensive experiments\\ndemonstrate that our proposed method achieves superior visual quality and\\nsemantic consistency compared to existing techniques. Project page:\\nhttps://liagm.github.io/CompleteMe/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T17:59:56Z\"}"}
