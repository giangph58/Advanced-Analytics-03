{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10148v1\", \"title\": \"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for\\n  Multi-Instance Synthesis in Diffusion Transformers\", \"summary\": \"Text-to-image (T2I) generation models often struggle with multi-instance\\nsynthesis (MIS), where they must accurately depict multiple distinct instances\\nin a single image based on complex prompts detailing individual features.\\nTraditional MIS control methods for UNet architectures like SD v1.5/SDXL fail\\nto adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated\\nattention between image and text tokens rather than text-image cross-attention.\\nTo enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.\\nOur token-wise and layer-wise analysis of attention maps reveals a hierarchical\\nresponse structure: instance tokens dominate early layers, background tokens in\\nmiddle layers, and attribute tokens in later layers. Building on this\\nobservation, we propose a training-free approach for enhancing MIS in DiT-based\\nmodels with hierarchical and step-layer-wise attention specialty tuning (AST).\\nAST amplifies key regions while suppressing irrelevant areas in distinct\\nattention maps across layers and steps, guided by the hierarchical structure.\\nThis optimizes multimodal interactions by hierarchically decoupling the complex\\nprompts with instance-based sketches. We evaluate our approach using upgraded\\nsketch-based layouts for the T2I-CompBench and customized complex scenes. Both\\nquantitative and qualitative results confirm our method enhances complex layout\\ngeneration, ensuring precise instance placement and attribute representation in\\nMIS.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T11:59:58Z\"}"}
