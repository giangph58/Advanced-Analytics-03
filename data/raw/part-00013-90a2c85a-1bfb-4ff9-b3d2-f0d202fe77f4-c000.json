{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15777v1\", \"title\": \"Tina: Tiny Reasoning Models via LoRA\", \"summary\": \"How cost-effectively can strong reasoning abilities be achieved in language\\nmodels? Driven by this fundamental question, we present Tina, a family of tiny\\nreasoning models achieved with high cost-efficiency. Notably, Tina demonstrates\\nthat substantial reasoning performance can be developed using only minimal\\nresources, by applying parameter-efficient updates during reinforcement\\nlearning (RL), using low-rank adaptation (LoRA), to an already tiny 1.5B\\nparameter base model. This minimalist approach produces models that achieve\\nreasoning performance which is competitive with, and sometimes surpasses, SOTA\\nRL reasoning models built upon the same base model. Crucially, this is achieved\\nat a tiny fraction of the computational post-training cost employed by existing\\nSOTA models. In fact, the best Tina model achieves a >20\\\\% reasoning\\nperformance increase and 43.33\\\\% Pass@1 accuracy on AIME24, at only \\\\$9 USD\\npost-training and evaluation cost (i.e., an estimated 260x cost reduction). Our\\nwork reveals the surprising effectiveness of efficient RL reasoning via LoRA.\\nWe validate this across multiple open-source reasoning datasets and various\\nablation settings starting with a single, fixed set of hyperparameters.\\nFurthermore, we hypothesize that this effectiveness and efficiency stem from\\nLoRA rapidly adapting the model to the structural format of reasoning rewarded\\nby RL, while largely preserving the base model's underlying knowledge. In\\nservice of accessibility and open research, we fully open-source all code,\\ntraining logs, and model weights \\\\& checkpoints.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.LG\", \"published\": \"2025-04-22T10:38:00Z\"}"}
