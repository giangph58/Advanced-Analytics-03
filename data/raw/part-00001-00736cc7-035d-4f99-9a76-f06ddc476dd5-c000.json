{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05163v1\", \"title\": \"Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty\\n  Quantification with Gaussian Process Latent Variable Models\", \"summary\": \"Vision-Language Models (VLMs) learn joint representations by mapping images\\nand text into a shared latent space. However, recent research highlights that\\ndeterministic embeddings from standard VLMs often struggle to capture the\\nuncertainties arising from the ambiguities in visual and textual descriptions\\nand the multiple possible correspondences between images and texts. Existing\\napproaches tackle this by learning probabilistic embeddings during VLM\\ntraining, which demands large datasets and does not leverage the powerful\\nrepresentations already learned by large-scale VLMs like CLIP. In this paper,\\nwe propose GroVE, a post-hoc approach to obtaining probabilistic embeddings\\nfrom frozen VLMs. GroVE builds on Gaussian Process Latent Variable Model\\n(GPLVM) to learn a shared low-dimensional latent space where image and text\\ninputs are mapped to a unified representation, optimized through single-modal\\nembedding reconstruction and cross-modal alignment objectives. Once trained,\\nthe Gaussian Process model generates uncertainty-aware probabilistic\\nembeddings. Evaluation shows that GroVE achieves state-of-the-art uncertainty\\ncalibration across multiple downstream tasks, including cross-modal retrieval,\\nvisual question answering, and active learning.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-05-08T11:57:35Z\"}"}
