{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05196v1\", \"title\": \"Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based\\n  Retrieval-Augmented Recommender Systems\", \"summary\": \"We present a systematic study of provider-side data poisoning in\\nretrieval-augmented recommender systems (RAG-based). By modifying only a small\\nfraction of tokens within item descriptions -- for instance, adding emotional\\nkeywords or borrowing phrases from semantically related items -- an attacker\\ncan significantly promote or demote targeted items. We formalize these attacks\\nunder token-edit and semantic-similarity constraints, and we examine their\\neffectiveness in both promotion (long-tail items) and demotion (short-head\\nitems) scenarios. Our experiments on MovieLens, using two large language model\\n(LLM) retrieval modules, show that even subtle attacks shift final rankings and\\nitem exposures while eluding naive detection. The results underscore the\\nvulnerability of RAG-based pipelines to small-scale metadata rewrites and\\nemphasize the need for robust textual consistency checks and provenance\\ntracking to thwart stealthy provider-side poisoning.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-05-08T12:53:42Z\"}"}
