{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02828v1\", \"title\": \"Concept Lancet: Image Editing with Compositional Representation\\n  Transplant\", \"summary\": \"Diffusion models are widely used for image editing tasks. Existing editing\\nmethods often design a representation manipulation procedure by curating an\\nedit direction in the text embedding or score space. However, such a procedure\\nfaces a key challenge: overestimating the edit strength harms visual\\nconsistency while underestimating it fails the editing task. Notably, each\\nsource image may require a different editing strength, and it is costly to\\nsearch for an appropriate strength via trial-and-error. To address this\\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\\nframework for principled representation manipulation in diffusion-based image\\nediting. At inference time, we decompose the source input in the latent (text\\nembedding or diffusion score) space as a sparse linear combination of the\\nrepresentations of the collected visual concepts. This allows us to accurately\\nestimate the presence of concepts in each image, which informs the edit. Based\\non the editing task (replace/add/remove), we perform a customized concept\\ntransplant process to impose the corresponding editing direction. To\\nsufficiently model the concept space, we curate a conceptual representation\\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\\nvisual terms and phrases for the latent dictionary. Experiments on multiple\\ndiffusion-based image editing baselines show that methods equipped with CoLan\\nachieve state-of-the-art performance in editing effectiveness and consistency\\npreservation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL\", \"published\": \"2025-04-03T17:59:58Z\"}"}
