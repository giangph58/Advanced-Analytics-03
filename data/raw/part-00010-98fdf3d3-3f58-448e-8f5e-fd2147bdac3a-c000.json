{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03739v1\", \"title\": \"VITA-Audio: Fast Interleaved Cross-Modal Token Generation for Efficient\\n  Large Speech-Language Model\", \"summary\": \"With the growing requirement for natural human-computer interaction,\\nspeech-based systems receive increasing attention as speech is one of the most\\ncommon forms of daily communication. However, the existing speech models still\\nexperience high latency when generating the first audio token during streaming,\\nwhich poses a significant bottleneck for deployment. To address this issue, we\\npropose VITA-Audio, an end-to-end large speech model with fast audio-text token\\ngeneration. Specifically, we introduce a lightweight Multiple Cross-modal Token\\nPrediction (MCTP) module that efficiently generates multiple audio tokens\\nwithin a single model forward pass, which not only accelerates the inference\\nbut also significantly reduces the latency for generating the first audio in\\nstreaming scenarios. In addition, a four-stage progressive training strategy is\\nexplored to achieve model acceleration with minimal loss of speech quality. To\\nour knowledge, VITA-Audio is the first multi-modal large language model capable\\nof generating audio output during the first forward pass, enabling real-time\\nconversational capabilities with minimal latency. VITA-Audio is fully\\nreproducible and is trained on open-source data only. Experimental results\\ndemonstrate that our model achieves an inference speedup of 3~5x at the 7B\\nparameter scale, but also significantly outperforms open-source models of\\nsimilar model size on multiple benchmarks for automatic speech recognition\\n(ASR), text-to-speech (TTS), and spoken question answering (SQA) tasks.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-05-06T17:59:53Z\"}"}
