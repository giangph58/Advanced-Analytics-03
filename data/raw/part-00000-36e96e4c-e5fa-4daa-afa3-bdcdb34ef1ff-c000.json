{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10280v1\", \"title\": \"Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for\\n  Distance and Geometry Perception in Robotic Manipulation\", \"summary\": \"Camera-based tactile sensors provide robots with a high-performance tactile\\nsensing approach for environment perception and dexterous manipulation.\\nHowever, achieving comprehensive environmental perception still requires\\ncooperation with additional sensors, which makes the system bulky and limits\\nits adaptability to unstructured environments. In this work, we present a\\nvision-enhanced camera-based dual-modality sensor, which realizes full-scale\\ndistance sensing from 50 cm to -3 mm while simultaneously keeping\\nultra-high-resolution texture sensing and reconstruction capabilities. Unlike\\nconventional designs with fixed opaque gel layers, our sensor features a\\npartially transparent sliding window, enabling mechanical switching between\\ntactile and visual modes. For each sensing mode, a dynamic distance sensing\\nmodel and a contact geometry reconstruction model are proposed. Through\\nintegration with soft robotic fingers, we systematically evaluate the\\nperformance of each mode, as well as in their synergistic operation.\\nExperimental results show robust distance tracking across various speeds,\\nnanometer-scale roughness detection, and sub-millimeter 3D texture\\nreconstruction. The combination of both modalities improves the robot's\\nefficiency in executing grasping tasks. Furthermore, the embedded mechanical\\ntransmission in the sensor allows for fine-grained intra-hand adjustments and\\nprecise manipulation, unlocking new capabilities for soft robotic hands.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-14T14:49:09Z\"}"}
