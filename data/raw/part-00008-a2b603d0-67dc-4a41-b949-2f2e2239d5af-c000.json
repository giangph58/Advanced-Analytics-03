{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10092v1\", \"title\": \"Bayesian optimal experimental design with Wasserstein information\\n  criteria\", \"summary\": \"Bayesian optimal experimental design (OED) provides a principled framework\\nfor selecting the most informative observational settings in experiments. With\\nrapid advances in computational power, Bayesian OED has become increasingly\\nfeasible for inference problems involving large-scale simulations, attracting\\ngrowing interest in fields such as inverse problems. In this paper, we\\nintroduce a novel design criterion based on the expected Wasserstein-$p$\\ndistance between the prior and posterior distributions. Especially, for $p=2$,\\nthis criterion shares key parallels with the widely used expected information\\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\\nregression, a property which can be also leveraged for approximative schemes.\\nSecond, it can be interpreted as maximizing the information gain measured by\\nthe transport cost incurred when updating the prior to the posterior. Our main\\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\\nprovide a rigorous error analysis under perturbations of the prior or\\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\\nIn particular, these results yield error rates when empirical approximations of\\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\\ncriterion and demonstrate our approximation rates through simulations.\", \"main_category\": \"stat.ME\", \"categories\": \"stat.ME,cs.NA,math.NA,stat.CO\", \"published\": \"2025-04-14T10:56:42Z\"}"}
