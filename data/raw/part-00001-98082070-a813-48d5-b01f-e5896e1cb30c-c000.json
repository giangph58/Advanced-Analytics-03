{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21362v1\", \"title\": \"Enhancing New-item Fairness in Dynamic Recommender Systems\", \"summary\": \"New-items play a crucial role in recommender systems (RSs) for delivering\\nfresh and engaging user experiences. However, traditional methods struggle to\\neffectively recommend new-items due to their short exposure time and limited\\ninteraction records, especially in dynamic recommender systems (DRSs) where\\nnew-items get continuously introduced and users' preferences evolve over time.\\nThis leads to significant unfairness towards new-items, which could accumulate\\nover the successive model updates, ultimately compromising the stability of the\\nentire system. Therefore, we propose FairAgent, a reinforcement learning\\n(RL)-based new-item fairness enhancement framework specifically designed for\\nDRSs. It leverages knowledge distillation to extract collaborative signals from\\ntraditional models, retaining strong recommendation capabilities for old-items.\\nIn addition, FairAgent introduces a novel reward mechanism for recommendation\\ntailored to the characteristics of DRSs, which consists of three components: 1)\\na new-item exploration reward to promote the exposure of dynamically introduced\\nnew-items, 2) a fairness reward to adapt to users' personalized fairness\\nrequirements for new-items, and 3) an accuracy reward which leverages users'\\ndynamic feedback to enhance recommendation accuracy. Extensive experiments on\\nthree public datasets and backbone models demonstrate the superior performance\\nof FairAgent. The results present that FairAgent can effectively boost new-item\\nexposure, achieve personalized new-item fairness, while maintaining high\\nrecommendation accuracy.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-30T06:49:36Z\"}"}
