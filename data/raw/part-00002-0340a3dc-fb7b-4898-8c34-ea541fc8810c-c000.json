{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02730v1\", \"title\": \"HQViT: Hybrid Quantum Vision Transformer for Image Classification\", \"summary\": \"Transformer-based architectures have revolutionized the landscape of deep\\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\\nperformance on par with or even surpassing that of convolutional neural\\nnetworks. However, the quadratic computational complexity of its self-attention\\nmechanism poses challenges for classical computing, making model training with\\nhigh-dimensional input data, e.g., images, particularly expensive. To address\\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\\nleverages the principles of quantum computing to accelerate model training\\nwhile enhancing model performance. HQViT introduces whole-image processing with\\namplitude encoding to better preserve global image information without\\nadditional positional encoding. By leveraging quantum computation on the most\\ncritical steps and selectively handling other components in a classical way, we\\nlower the cost of quantum resources for HQViT. The qubit requirement is\\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\\ndevices. By offloading the computationally intensive attention coefficient\\nmatrix calculation to the quantum framework, HQViT reduces the classical\\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\\nmaximum improvement of up to $10.9\\\\%$ (on the MNIST 10-classification task)\\nover the state of the art. This work highlights the great potential to combine\\nquantum and classical computing to cope with complex image classification\\ntasks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-04-03T16:13:34Z\"}"}
