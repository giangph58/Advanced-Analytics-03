{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04317v1\", \"title\": \"Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play\\n  Reinforcement Learning\", \"summary\": \"In this paper, we tackle the problem of learning to play 3v3 multi-drone\\nvolleyball, a new embodied competitive task that requires both high-level\\nstrategic coordination and low-level agile control. The task is turn-based,\\nmulti-agent, and physically grounded, posing significant challenges due to its\\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\\n(HCSP), a hierarchical reinforcement learning framework that separates\\ncentralized high-level strategic decision-making from decentralized low-level\\nmotion control. We design a three-stage population-based training pipeline to\\nenable both strategy and skill to emerge from scratch without expert\\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\\nstrategy via self-play with fixed low-level controllers, and (III) joint\\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\\nperformance, outperforming non-hierarchical self-play and rule-based\\nhierarchical baselines with an average 82.9\\\\% win rate and a 71.5\\\\% win rate\\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\\nbehaviors such as role switching and coordinated formations, demonstrating the\\neffectiveness of our hierarchical design and training scheme.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-05-07T11:04:36Z\"}"}
