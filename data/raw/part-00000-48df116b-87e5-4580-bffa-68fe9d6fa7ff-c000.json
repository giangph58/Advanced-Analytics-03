{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20969v1\", \"title\": \"XPG-RL: Reinforcement Learning with Explainable Priority Guidance for\\n  Efficiency-Boosted Mechanical Search\", \"summary\": \"Mechanical search (MS) in cluttered environments remains a significant\\nchallenge for autonomous manipulators, requiring long-horizon planning and\\nrobust state estimation under occlusions and partial observability. In this\\nwork, we introduce XPG-RL, a reinforcement learning framework that enables\\nagents to efficiently perform MS tasks through explainable, priority-guided\\ndecision-making based on raw sensory inputs. XPG-RL integrates a task-driven\\naction prioritization mechanism with a learned context-aware switching strategy\\nthat dynamically selects from a discrete set of action primitives such as\\ntarget grasping, occlusion removal, and viewpoint adjustment. Within this\\nstrategy, a policy is optimized to output adaptive threshold values that govern\\nthe discrete selection among action primitives. The perception module fuses\\nRGB-D inputs with semantic and geometric features to produce a structured scene\\nrepresentation for downstream decision-making. Extensive experiments in both\\nsimulation and real-world settings demonstrate that XPG-RL consistently\\noutperforms baseline methods in task success rates and motion efficiency,\\nachieving up to 4.5$\\\\times$ higher efficiency in long-horizon tasks. These\\nresults underscore the benefits of integrating domain knowledge with learnable\\ndecision-making policies for robust and efficient robotic manipulation.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.LG\", \"published\": \"2025-04-29T17:37:45Z\"}"}
