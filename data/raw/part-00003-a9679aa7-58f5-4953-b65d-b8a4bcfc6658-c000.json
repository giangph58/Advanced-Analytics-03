{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04955v1\", \"title\": \"Chain-of-Thought Tokens are Computer Program Variables\", \"summary\": \"Chain-of-thoughts (CoT) requires large language models (LLMs) to generate\\nintermediate steps before reaching the final answer, and has been proven\\neffective to help LLMs solve complex reasoning tasks. However, the inner\\nmechanism of CoT still remains largely unclear. In this paper, we empirically\\nstudy the role of CoT tokens in LLMs on two compositional tasks: multi-digit\\nmultiplication and dynamic programming. While CoT is essential for solving\\nthese problems, we find that preserving only tokens that store intermediate\\nresults would achieve comparable performance. Furthermore, we observe that\\nstoring intermediate results in an alternative latent form will not affect\\nmodel performance. We also randomly intervene some values in CoT, and notice\\nthat subsequent CoT tokens and the final answer would change correspondingly.\\nThese findings suggest that CoT tokens may function like variables in computer\\nprograms but with potential drawbacks like unintended shortcuts and\\ncomputational complexity limits between tokens. The code and data are available\\nat https://github.com/solitaryzero/CoTs_are_Variables.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-05-08T05:32:36Z\"}"}
