{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05677v1\", \"title\": \"Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise\\n  Injection\", \"summary\": \"Neural network ensembles is a simple yet effective approach for enhancing\\ngeneralization capabilities. The most common method involves independently\\ntraining multiple neural networks initialized with different weights and then\\naveraging their predictions during inference. However, this approach increases\\ntraining time linearly with the number of ensemble members. To address this\\nissue, we propose the novel ``\\\\textbf{Noisy Deep Ensemble}'' method,\\nsignificantly reducing the training time required for neural network ensembles.\\nIn this method, a \\\\textit{parent model} is trained until convergence, and then\\nthe weights of the \\\\textit{parent model} are perturbed in various ways to\\nconstruct multiple \\\\textit{child models}. This perturbation of the\\n\\\\textit{parent model} weights facilitates the exploration of different local\\nminima while significantly reducing the training time for each ensemble member.\\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\\nachieving test accuracy comparable to standard ensembles. Code is available at\\n\\\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-08T04:36:39Z\"}"}
