{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12112v1\", \"title\": \"A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image\\n  Reconstruction\", \"summary\": \"Remote sensing imagery is essential for environmental monitoring,\\nagricultural management, and disaster response. However, data loss due to cloud\\ncover, sensor failures, or incomplete acquisition-especially in high-resolution\\nand high-frequency tasks-severely limits satellite imagery's effectiveness.\\nTraditional interpolation methods struggle with large missing areas and complex\\nstructures. Remote sensing imagery consists of multiple bands, each with\\ndistinct meanings, and ensuring consistency across bands is critical to avoid\\nanomalies in the combined images. This paper proposes SatelliteMaker, a\\ndiffusion-based method that reconstructs missing data across varying levels of\\ndata loss while maintaining spatial, spectral, and temporal consistency. We\\nalso propose Digital Elevation Model (DEM) as a conditioning input and use\\ntailored prompts to generate realistic images, making diffusion models\\napplicable to quantitative remote sensing tasks. Additionally, we propose a\\nVGG-Adapter module based on Distribution Loss, which reduces distribution\\ndiscrepancy and ensures style consistency. Extensive experiments show that\\nSatelliteMaker achieves state-of-the-art performance across multiple tasks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-16T14:19:57Z\"}"}
