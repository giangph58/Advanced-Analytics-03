{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17315v1\", \"title\": \"DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation\\n  System Leveraging Large Vision-Language Model\", \"summary\": \"This paper presents the technical solution proposed by Huawei Translation\\nService Center (HW-TSC) for the \\\"End-to-End Document Image Machine Translation\\nfor Complex Layouts\\\" competition at the 19th International Conference on\\nDocument Analysis and Recognition (DIMT25@ICDAR2025). Leveraging\\nstate-of-the-art open-source large vision-language model (LVLM), we introduce a\\ntraining framework that combines multi-task learning with perceptual\\nchain-of-thought to develop a comprehensive end-to-end document translation\\nsystem. During the inference phase, we apply minimum Bayesian decoding and\\npost-processing strategies to further enhance the system's translation\\ncapabilities. Our solution uniquely addresses both OCR-based and OCR-free\\ndocument image translation tasks within a unified framework. This paper\\nsystematically details the training methods, inference strategies, LVLM base\\nmodels, training data, experimental setups, and results, demonstrating an\\neffective approach to document image machine translation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-24T07:17:59Z\"}"}
