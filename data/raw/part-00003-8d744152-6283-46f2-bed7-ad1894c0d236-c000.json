{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07958v1\", \"title\": \"Detect Anything 3D in the Wild\", \"summary\": \"Despite the success of deep learning in close-set 3D object detection,\\nexisting approaches struggle with zero-shot generalization to novel objects and\\ncamera configurations. We introduce DetAny3D, a promptable 3D detection\\nfoundation model capable of detecting any novel object under arbitrary camera\\nconfigurations using only monocular inputs. Training a foundation model for 3D\\ndetection is fundamentally constrained by the limited availability of annotated\\n3D data, which motivates DetAny3D to leverage the rich prior knowledge embedded\\nin extensively pre-trained 2D foundation models to compensate for this\\nscarcity. To effectively transfer 2D knowledge to 3D, DetAny3D incorporates two\\ncore modules: the 2D Aggregator, which aligns features from different 2D\\nfoundation models, and the 3D Interpreter with Zero-Embedding Mapping, which\\nmitigates catastrophic forgetting in 2D-to-3D knowledge transfer. Experimental\\nresults validate the strong generalization of our DetAny3D, which not only\\nachieves state-of-the-art performance on unseen categories and novel camera\\nconfigurations, but also surpasses most competitors on in-domain data.DetAny3D\\nsheds light on the potential of the 3D foundation model for diverse\\napplications in real-world scenarios, e.g., rare object detection in autonomous\\ndriving, and demonstrates promise for further exploration of 3D-centric tasks\\nin open-world settings. More visualization results can be found at DetAny3D\\nproject page.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-10T17:59:22Z\"}"}
