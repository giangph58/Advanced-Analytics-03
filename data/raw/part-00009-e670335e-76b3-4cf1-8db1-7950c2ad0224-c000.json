{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16026v1\", \"title\": \"Trends in AI Supercomputers\", \"summary\": \"Frontier AI development relies on powerful AI supercomputers, yet analysis of\\nthese systems is limited. We create a dataset of 500 AI supercomputers from\\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\\nownership, and global distribution. We find that the computational performance\\nof AI supercomputers has doubled every nine months, while hardware acquisition\\ncost and power needs both doubled every year. The leading system in March 2025,\\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\\\$7B, and\\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\\nevolved from tools for science to industrial machines, companies rapidly\\nexpanded their share of total AI supercomputer performance, while the share of\\ngovernments and academia diminished. Globally, the United States accounts for\\nabout 75% of total performance in our dataset, with China in second place at\\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\\nachieve $2\\\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\\nhardware cost of \\\\$200 billion, and require 9 GW of power. Our analysis\\nprovides visibility into the AI supercomputer landscape, allowing policymakers\\nto assess key AI trends like resource needs, ownership, and national\\ncompetitiveness.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY,cs.AI\", \"published\": \"2025-04-22T16:44:34Z\"}"}
