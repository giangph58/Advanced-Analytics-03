{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10936v1\", \"title\": \"Can LLMs Leverage Observational Data? Towards Data-Driven Causal\\n  Discovery with LLMs\", \"summary\": \"Causal discovery traditionally relies on statistical methods applied to\\nobservational data, often requiring large datasets and assumptions about\\nunderlying causal structures. Recent advancements in Large Language Models\\n(LLMs) have introduced new possibilities for causal discovery by providing\\ndomain expert knowledge. However, it remains unclear whether LLMs can\\neffectively process observational data for causal discovery. In this work, we\\nexplore the potential of LLMs for data-driven causal discovery by integrating\\nobservational data for LLM-based reasoning. Specifically, we examine whether\\nLLMs can effectively utilize observational data through two prompting\\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\\nIn both approaches, we incorporate the observational data directly into the\\nprompt to assess LLMs' ability to infer causal relationships from such data.\\nExperiments on benchmark datasets show that incorporating observational data\\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\\npairwise and BFS LLM-based prompting, while outperforming traditional\\nstatistical causal discovery baseline by up to 0.52 points. Our findings\\nhighlight the potential and limitations of LLMs for data-driven causal\\ndiscovery, demonstrating their ability to move beyond textual metadata and\\neffectively interpret and utilize observational data for more informed causal\\nreasoning. Our studies lays the groundwork for future advancements toward fully\\nLLM-driven causal discovery.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-15T07:32:35Z\"}"}
