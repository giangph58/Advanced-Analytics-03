{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04843v1\", \"title\": \"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation\\n  for Sequential Recommendation\", \"summary\": \"Data augmentation has become a promising method of mitigating data sparsity\\nin sequential recommendation. Existing methods generate new yet effective data\\nduring model training to improve performance. However, deploying them requires\\nretraining, architecture modification, or introducing additional learnable\\nparameters. The above steps are time-consuming and costly for well-trained\\nmodels, especially when the model scale becomes large. In this work, we explore\\nthe test-time augmentation (TTA) for sequential recommendation, which augments\\nthe inputs during the model inference and then aggregates the model's\\npredictions for augmented data to improve final accuracy. It avoids significant\\ntime and cost overhead from loss calculation and backward propagation. We first\\nexperimentally disclose the potential of existing augmentation operators for\\nTTA and find that the Mask and Substitute consistently achieve better\\nperformance. Further analysis reveals that these two operators are effective\\nbecause they retain the original sequential pattern while adding appropriate\\nperturbations. Meanwhile, we argue that these two operators still face\\ntime-consuming item selection or interference information from mask tokens.\\nBased on the analysis and limitations, we present TNoise and TMask. The former\\ninjects uniform noise into the original representation, avoiding the\\ncomputational overhead of item selection. The latter blocks mask token from\\nparticipating in model calculations or directly removes interactions that\\nshould have been replaced with mask tokens. Comprehensive experiments\\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-07T08:56:16Z\"}"}
