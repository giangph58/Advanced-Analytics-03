{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11230v1\", \"title\": \"CAP-Net: A Unified Network for 6D Pose and Size Estimation of\\n  Categorical Articulated Parts from a Single RGB-D Image\", \"summary\": \"This paper tackles category-level pose estimation of articulated objects in\\nrobotic manipulation tasks and introduces a new benchmark dataset. While recent\\nmethods estimate part poses and sizes at the category level, they often rely on\\ngeometric cues and complex multi-stage pipelines that first segment parts from\\nthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimation\\nfor 6D poses. These approaches overlook dense semantic cues from RGB images,\\nleading to suboptimal accuracy, particularly for objects with small parts. To\\naddress these limitations, we propose a single-stage Network, CAP-Net, for\\nestimating the 6D poses and sizes of Categorical Articulated Parts. This method\\ncombines RGB-D features to generate instance segmentation and NPCS\\nrepresentations for each part in an end-to-end manner. CAP-Net uses a unified\\nnetwork to simultaneously predict point-wise class labels, centroid offsets,\\nand NPCS maps. A clustering algorithm then groups points of the same predicted\\nclass based on their estimated centroid distances to isolate each part.\\nFinally, the NPCS region of each part is aligned with the point cloud to\\nrecover its final pose and size. To bridge the sim-to-real domain gap, we\\nintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,\\nfeaturing photorealistic RGB images and depth noise simulated from real\\nsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that our\\nmethod significantly outperforms the state-of-the-art approach. Real-world\\ndeployments of our model in robotic tasks underscore its robustness and\\nexceptional sim-to-real transfer capabilities, confirming its substantial\\npractical utility. Our dataset, code and pre-trained models are available on\\nthe project page.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-04-15T14:30:26Z\"}"}
