{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19683v1\", \"title\": \"GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial\\n  Task Learning\", \"summary\": \"Most existing robot manipulation methods prioritize task learning by\\nenhancing perception through complex deep network architectures. However, they\\nface challenges in real-time collision-free planning. Hence, Robotic Attention\\nMamba (RAM) is designed for refined planning. Specifically, by integrating\\nMamba and parallel single-view attention, RAM aligns multi-view vision and\\ntask-related language features, ensuring efficient fine-grained task planning\\nwith linear complexity and robust real-time performance. Nevertheless, it has\\nthe potential for further improvement in high-precision grasping and\\nmanipulation. Thus, Grasp-Pretraining Augmentation (GPA) is devised, with a\\ngrasp pose feature extractor pretrained utilizing object grasp poses directly\\ninherited from whole-task demonstrations. Subsequently, the extracted grasp\\nfeatures are fused with the spatially aligned planning features from RAM\\nthrough attention-based Pre-trained Location Fusion, preserving high-resolution\\ngrasping cues overshadowed by an overemphasis on global planning. To summarize,\\nwe propose Grasp-Pretraining Augmented Robotic Attention Mamba (GPA-RAM),\\ndividing spatial task learning into RAM for planning skill learning and GPA for\\ngrasping skill learning. GPA-RAM demonstrates superior performance across three\\nrobot systems with distinct camera configurations in simulation and the real\\nworld. Compared with previous state-of-the-art methods, it improves the\\nabsolute success rate by 8.2% (from 79.3% to 87.5%) on the RLBench multi-task\\nbenchmark and 40\\\\% (from 16% to 56%), 12% (from 86% to 98%) on the ALOHA\\nbimanual manipulation tasks, while delivering notably faster inference.\\nFurthermore, experimental results demonstrate that both RAM and GPA enhance\\ntask learning, with GPA proving robust to different architectures of pretrained\\ngrasp pose feature extractors. The website is:\\nhttps://logssim.github.io/GPA\\\\_RAM\\\\_website/.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-28T11:20:51Z\"}"}
