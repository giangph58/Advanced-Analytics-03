{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21847v1\", \"title\": \"Differentiable Room Acoustic Rendering with Multi-View Vision Priors\", \"summary\": \"An immersive acoustic experience enabled by spatial audio is just as crucial\\nas the visual aspect in creating realistic virtual environments. However,\\nexisting methods for room impulse response estimation rely either on\\ndata-demanding learning-based models or computationally expensive physics-based\\nmodeling. In this work, we introduce Audio-Visual Differentiable Room Acoustic\\nRendering (AV-DAR), a framework that leverages visual cues extracted from\\nmulti-view images and acoustic beam tracing for physics-based room acoustic\\nrendering. Experiments across six real-world environments from two datasets\\ndemonstrate that our multimodal, physics-based approach is efficient,\\ninterpretable, and accurate, significantly outperforming a series of prior\\nmethods. Notably, on the Real Acoustic Field dataset, AV-DAR achieves\\ncomparable performance to models trained on 10 times more data while delivering\\nrelative gains ranging from 16.6% to 50.9% when trained at the same scale.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.SD\", \"published\": \"2025-04-30T17:55:29Z\"}"}
