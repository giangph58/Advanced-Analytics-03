{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19705v1\", \"title\": \"Guided Tensor Lifting\", \"summary\": \"Domain-specific languages (DSLs) for machine learning are revolutionizing the\\nspeed and efficiency of machine learning workloads as they enable users easy\\naccess to high-performance compiler optimizations and accelerators. However, to\\ntake advantage of these capabilities, a user must first translate their legacy\\ncode from the language it is currently written in, into the new DSL. The\\nprocess of automatically lifting code into these DSLs has been identified by\\nseveral recent works, which propose program synthesis as a solution. However,\\nsynthesis is expensive and struggles to scale without carefully designed and\\nhard-wired heuristics. In this paper, we present an approach for lifting that\\ncombines an enumerative synthesis approach with a Large Language Model used to\\nautomatically learn the domain-specific heuristics for program lifting, in the\\nform of a probabilistic grammar. Our approach outperforms the state-of-the-art\\ntools in this area, despite only using learned heuristics.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-28T12:00:10Z\"}"}
