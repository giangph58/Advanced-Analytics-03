{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17526v1\", \"title\": \"Cooperative Task Offloading through Asynchronous Deep Reinforcement\\n  Learning in Mobile Edge Computing for Future Networks\", \"summary\": \"Future networks (including 6G) are poised to accelerate the realisation of\\nInternet of Everything. However, it will result in a high demand for computing\\nresources to support new services. Mobile Edge Computing (MEC) is a promising\\nsolution, enabling to offload computation-intensive tasks to nearby edge\\nservers from the end-user devices, thereby reducing latency and energy\\nconsumption. However, relying solely on a single MEC server for task offloading\\ncan lead to uneven resource utilisation and suboptimal performance in complex\\nscenarios. Additionally, traditional task offloading strategies specialise in\\ncentralised policy decisions, which unavoidably entail extreme transmission\\nlatency and reach computational bottleneck. To fill the gaps, we propose a\\nlatency and energy efficient Cooperative Task Offloading framework with\\nTransformer-driven Prediction (CTO-TP), leveraging asynchronous multi-agent\\ndeep reinforcement learning to address these challenges. This approach fosters\\nedge-edge cooperation and decreases the synchronous waiting time by performing\\nasynchronous training, optimising task offloading, and resource allocation\\nacross distributed networks. The performance evaluation demonstrates that the\\nproposed CTO-TP algorithm reduces up to 80% overall system latency and 87%\\nenergy consumption compared to the baseline schemes.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-24T13:12:12Z\"}"}
