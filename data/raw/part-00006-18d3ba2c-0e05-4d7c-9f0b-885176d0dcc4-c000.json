{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19918v1\", \"title\": \"Enhancing Surgical Documentation through Multimodal Visual-Temporal\\n  Transformers and Generative AI\", \"summary\": \"The automatic summarization of surgical videos is essential for enhancing\\nprocedural documentation, supporting surgical training, and facilitating\\npost-operative analysis. This paper presents a novel method at the intersection\\nof artificial intelligence and medicine, aiming to develop machine learning\\nmodels with direct real-world applications in surgical contexts. We propose a\\nmulti-modal framework that leverages recent advancements in computer vision and\\nlarge language models to generate comprehensive video summaries. % The approach\\nis structured in three key stages. First, surgical videos are divided into\\nclips, and visual features are extracted at the frame level using visual\\ntransformers. This step focuses on detecting tools, tissues, organs, and\\nsurgical actions. Second, the extracted features are transformed into\\nframe-level captions via large language models. These are then combined with\\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\\nsummaries that reflect the broader context of each video segment. Finally, the\\nclip-level descriptions are aggregated into a full surgical report using a\\ndedicated LLM tailored for the summarization task. % We evaluate our method on\\nthe CholecT50 dataset, using instrument and action annotations from 50\\nlaparoscopic videos. The results show strong performance, achieving 96\\\\%\\nprecision in tool detection and a BERT score of 0.74 for temporal context\\nsummarization. This work contributes to the advancement of AI-assisted tools\\nfor surgical reporting, offering a step toward more intelligent and reliable\\nclinical documentation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-28T15:46:02Z\"}"}
