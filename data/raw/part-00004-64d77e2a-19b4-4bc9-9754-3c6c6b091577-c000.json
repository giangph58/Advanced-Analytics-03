{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15041v1\", \"title\": \"Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong\\n  Person Re-identification\", \"summary\": \"Lifelong Person Re-identification (LReID) suffers from a key challenge in\\npreserving old knowledge while adapting to new information. The existing\\nsolutions include rehearsal-based and rehearsal-free methods to address this\\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\\ncontinuously accumulating forgetting during the distillation process.\\nRehearsal-free methods insufficiently learn the distribution of each domain,\\nleading to forgetfulness over time. To solve these issues, we propose a novel\\nDistribution-aware Forgetting Compensation (DAFC) model that explores\\ncross-domain shared representation learning and domain-specific distribution\\nintegration without using old exemplars or knowledge distillation. We propose a\\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\\nprompt elements and guide the prompt model to learn fine-grained\\nrepresentations for each instance. This can enhance the differentiation of\\nidentity information and establish the foundation for domain distribution\\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\\nto capture each domain-specific distribution by a dedicated expert network and\\nadaptively consolidate them into a shared region in high-dimensional space. In\\nthis manner, DAI can consolidate and enhance cross-domain shared representation\\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\\ndiscrimination and cross-domain consistency alignment strategies to facilitate\\nmodel adaptive learning of new knowledge from the current domain and promote\\nknowledge consolidation learning between acquired domain-specific\\ndistributions, respectively. Experimental results show that our DAFC outperform\\nstate-of-the-art methods by at least 9.8\\\\%/6.6\\\\% and 6.4\\\\%/6.2\\\\% of average\\nmAP/R@1 on two training orders.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-21T11:53:43Z\"}"}
