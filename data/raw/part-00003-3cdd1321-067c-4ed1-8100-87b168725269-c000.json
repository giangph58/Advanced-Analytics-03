{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03399v1\", \"title\": \"Typical Machine Learning Datasets as Low-Depth Quantum Circuits\", \"summary\": \"Quantum machine learning (QML) is an emerging field that investigates the\\ncapabilities of quantum computers for learning tasks. While QML models can\\ntheoretically offer advantages such as exponential speed-ups, challenges in\\ndata loading and the ability to scale to relevant problem sizes have prevented\\ndemonstrations of such advantages on practical problems. In particular, the\\nencoding of arbitrary classical data into quantum states usually comes at a\\nhigh computational cost, either in terms of qubits or gate count. However,\\nreal-world data typically exhibits some inherent structure (such as image data)\\nwhich can be leveraged to load them with a much smaller cost on a quantum\\ncomputer. This work further develops an efficient algorithm for finding\\nlow-depth quantum circuits to load classical image data as quantum states. To\\nevaluate its effectiveness, we conduct systematic studies on the MNIST,\\nFashion-MNIST, CIFAR-10, and Imagenette datasets. The corresponding circuits\\nfor loading the full large-scale datasets are available publicly as PennyLane\\ndatasets and can be used by the community for their own benchmarks. We further\\nanalyze the performance of various quantum classifiers, such as quantum kernel\\nmethods, parameterized quantum circuits, and tensor-network classifiers, and we\\ncompare them to convolutional neural networks. In particular, we focus on the\\nperformance of the quantum classifiers as we introduce nonlinear functions of\\nthe input state, e.g., by letting the circuit parameters depend on the input\\nstate.\", \"main_category\": \"quant-ph\", \"categories\": \"quant-ph\", \"published\": \"2025-05-06T10:27:51Z\"}"}
