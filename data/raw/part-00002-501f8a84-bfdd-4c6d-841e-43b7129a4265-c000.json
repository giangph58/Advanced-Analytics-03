{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06075v1\", \"title\": \"Collaborative Prediction: Tractable Information Aggregation via\\n  Agreement\", \"summary\": \"We give efficient \\\"collaboration protocols\\\" through which two parties, who\\nobserve different features about the same instances, can interact to arrive at\\npredictions that are more accurate than either could have obtained on their\\nown. The parties only need to iteratively share and update their own label\\npredictions-without either party ever having to share the actual features that\\nthey observe. Our protocols are efficient reductions to the problem of learning\\non each party's feature space alone, and so can be used even in settings in\\nwhich each party's feature space is illegible to the other-which arises in\\nmodels of human/AI interaction and in multi-modal learning. The communication\\nrequirements of our protocols are independent of the dimensionality of the\\ndata. In an online adversarial setting we show how to give regret bounds on the\\npredictions that the parties arrive at with respect to a class of benchmark\\npolicies defined on the joint feature space of the two parties, despite the\\nfact that neither party has access to this joint feature space. We also give\\nsimpler algorithms for the same task in the batch setting in which we assume\\nthat there is a fixed but unknown data distribution. We generalize our\\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\\nwhere parties communicate only \\\"best response actions.\\\"\\n  Our theorems give a computationally and statistically tractable\\ngeneralization of past work on information aggregation amongst Bayesians who\\nshare a common and correct prior, as part of a literature studying \\\"agreement\\\"\\nin the style of Aumann's agreement theorem. Our results require no knowledge of\\n(or even the existence of) a prior distribution and are computationally\\nefficient. Nevertheless we show how to lift our theorems back to this classical\\nBayesian setting, and in doing so, give new information aggregation theorems\\nfor Bayesian agreement.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.DS,cs.GT\", \"published\": \"2025-04-08T14:12:42Z\"}"}
