{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13179v1\", \"title\": \"ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation\", \"summary\": \"Object 6D pose estimation is a critical challenge in robotics, particularly\\nfor manipulation tasks. While prior research combining visual and tactile\\n(visuotactile) information has shown promise, these approaches often struggle\\nwith generalization due to the limited availability of visuotactile data. In\\nthis paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation\\nframework. Our key innovation lies in leveraging a visual model as its backbone\\nand performing feasibility checking and test-time optimization based on\\nphysical constraints derived from tactile and proprioceptive observations.\\nSpecifically, we model the gripper-object interaction as a spring-mass system,\\nwhere tactile sensors induce attractive forces, and proprioception generates\\nrepulsive forces. We validate our framework through experiments on a real-world\\nrobot setup, demonstrating its effectiveness across representative visual\\nbackbones and manipulation scenarios, including grasping, object picking, and\\nbimanual handover. Compared to the visual models, our approach overcomes some\\ndrastic failure modes while tracking the in-hand object pose. In our\\nexperiments, our approach shows an average increase of 55% in AUC of ADD-S and\\n60% in ADD, along with an 80% lower position error compared to FoundationPose.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.CV\", \"published\": \"2025-04-17T17:59:56Z\"}"}
