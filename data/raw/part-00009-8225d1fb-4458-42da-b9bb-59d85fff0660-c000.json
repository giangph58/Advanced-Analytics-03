{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05269v1\", \"title\": \"A Two-Sample Test of Text Generation Similarity\", \"summary\": \"The surge in digitized text data requires reliable inferential methods on\\nobserved textual patterns. This article proposes a novel two-sample text test\\nfor comparing similarity between two groups of documents. The hypothesis is\\nwhether the probabilistic mapping generating the textual data is identical\\nacross two groups of documents. The proposed test aims to assess text\\nsimilarity by comparing the entropy of the documents. Entropy is estimated\\nusing neural network-based language models. The test statistic is derived from\\nan estimation-and-inference framework, where the entropy is first approximated\\nusing an estimation set, followed by inference on the remaining data set. We\\nshowed theoretically that under mild conditions, the test statistic\\nasymptotically follows a normal distribution. A multiple data-splitting\\nstrategy is proposed to enhance test power, which combines p-values into a\\nunified decision. Various simulation studies and a real data example\\ndemonstrated that the proposed two-sample text test maintains the nominal Type\\none error rate while offering greater power compared to existing methods. The\\nproposed method provides a novel solution to assert differences in document\\nclasses, particularly in fields where large-scale textual information is\\ncrucial.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG\", \"published\": \"2025-05-08T14:15:53Z\"}"}
