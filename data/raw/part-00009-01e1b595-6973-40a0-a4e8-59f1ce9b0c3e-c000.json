{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04934v1\", \"title\": \"Boosting Relational Deep Learning with Pretrained Tabular Models\", \"summary\": \"Relational databases, organized into tables connected by primary-foreign key\\nrelationships, are a common format for organizing data. Making predictions on\\nrelational data often involves transforming them into a flat tabular format\\nthrough table joins and feature engineering, which serve as input to tabular\\nmethods. However, designing features that fully capture complex relational\\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\\nalternative by inherently modeling these relationships, but their time overhead\\nduring inference limits their applicability for real-time scenarios. In this\\nwork, we aim to bridge this gap by leveraging existing feature engineering\\nefforts to enhance the efficiency of GNNs in relational databases.\\nSpecifically, we use GNNs to capture complex relationships within relational\\ndatabases, patterns that are difficult to featurize, while employing engineered\\nfeatures to encode temporal information, thereby avoiding the need to retain\\nthe entire historical graph and enabling the use of smaller, more efficient\\ngraphs. Our \\\\textsc{LightRDL} approach not only improves efficiency, but also\\noutperforms existing models. Experimental results on the RelBench benchmark\\ndemonstrate that our framework achieves up to $33\\\\%$ performance improvement\\nand a $526\\\\times$ inference speedup compared to GNNs, making it highly suitable\\nfor real-time inference.\", \"main_category\": \"cs.DB\", \"categories\": \"cs.DB,cs.AI,cs.LG\", \"published\": \"2025-04-07T11:19:04Z\"}"}
