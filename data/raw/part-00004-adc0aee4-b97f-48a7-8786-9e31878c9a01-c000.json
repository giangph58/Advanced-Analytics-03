{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21327v1\", \"title\": \"A Generalized Meta Federated Learning Framework with Theoretical\\n  Convergence Guarantees\", \"summary\": \"Meta federated learning (FL) is a personalized variant of FL, where multiple\\nagents collaborate on training an initial shared model without exchanging raw\\ndata samples. The initial model should be trained in a way that current or new\\nagents can easily adapt it to their local datasets after one or a few\\nfine-tuning steps, thus improving the model personalization. Conventional meta\\nFL approaches minimize the average loss of agents on the local models obtained\\nafter one step of fine-tuning. In practice, agents may need to apply several\\nfine-tuning steps to adapt the global model to their local data, especially\\nunder highly heterogeneous data distributions across agents. To this end, we\\npresent a generalized framework for the meta FL by minimizing the average loss\\nof agents on their local model after any arbitrary number $\\\\nu$ of fine-tuning\\nsteps. For this generalized framework, we present a variant of the well-known\\nfederated averaging (FedAvg) algorithm and conduct a comprehensive theoretical\\nconvergence analysis to characterize the convergence speed as well as behavior\\nof the meta loss functions in both the exact and approximated cases. Our\\nexperiments on real-world datasets demonstrate superior accuracy and faster\\nconvergence for the proposed scheme compared to conventional approaches.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-30T05:29:46Z\"}"}
