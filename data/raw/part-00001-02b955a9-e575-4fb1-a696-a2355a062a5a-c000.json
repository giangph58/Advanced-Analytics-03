{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13055v1\", \"title\": \"NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation\", \"summary\": \"Recent advances in reinforcement learning (RL) have strengthened the\\nreasoning capabilities of vision-language models (VLMs). However, enhancing\\npolicy exploration to more effectively scale test-time compute remains\\nunderexplored in VLMs. In addition, VLMs continue to struggle with imperfect\\nvisual perception, which in turn affects the subsequent reasoning process. To\\nthis end, we propose NoisyRollout, a simple yet effective RL approach that\\nmixes trajectories from both clean and moderately distorted images to introduce\\ntargeted diversity in visual perception and the resulting reasoning patterns.\\nWithout additional training cost, NoisyRollout enhances the exploration\\ncapabilities of VLMs by incorporating a vision-oriented inductive bias.\\nFurthermore, NoisyRollout employs a noise annealing schedule that gradually\\nreduces distortion strength over training, ensuring benefit from noisy signals\\nearly while maintaining training stability and scalability in later stages.\\nWith just 2.1K training samples, NoisyRollout achieves state-of-the-art\\nperformance among open-source RL-tuned models on 5 out-of-domain benchmarks\\nspanning both reasoning and perception tasks, while preserving comparable or\\neven better in-domain performance.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T16:10:13Z\"}"}
