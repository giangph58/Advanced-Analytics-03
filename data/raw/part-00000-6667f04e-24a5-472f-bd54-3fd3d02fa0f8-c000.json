{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15728v1\", \"title\": \"SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal\\n  Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems\", \"summary\": \"Domain-adaptive thermal object detection plays a key role in facilitating\\nvisible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered\\nimage pairs and minimizing reliance on large annotated IR datasets. However,\\ninherent limitations of IR images, such as the lack of color and texture cues,\\npose challenges for RGB-trained models, leading to increased false positives\\nand poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray\\ncolor Augmentation (SAGA), a novel strategy for mitigating color bias and\\nbridging the domain gap by extracting object-level features relevant to IR\\nimages. Additionally, to validate the proposed SAGA for drone imagery, we\\nintroduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse\\napplications. The dataset contains 5,612 images with 145,666 instances,\\ncaptured from diverse angles, altitudes, backgrounds, and times of day,\\noffering valuable opportunities for multimodal learning, domain adaptation for\\nobject detection and segmentation, and exploration of sensor-specific strengths\\nand weaknesses. IndraEye aims to enhance the development of more robust and\\naccurate aerial perception systems, especially in challenging environments.\\nExperimental results show that SAGA significantly improves RGB-to-IR adaptation\\nfor autonomous driving and IndraEye dataset, achieving consistent performance\\ngains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain\\nadaptation techniques. The dataset and codes are available at\\nhttps://github.com/airliisc/IndraEye.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-22T09:22:11Z\"}"}
