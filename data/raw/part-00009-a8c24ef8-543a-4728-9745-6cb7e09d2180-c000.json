{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09923v1\", \"title\": \"Guiding Reasoning in Small Language Models with LLM Assistance\", \"summary\": \"The limited reasoning capabilities of small language models (SLMs) cast doubt\\non their suitability for tasks demanding deep, multi-step logical deduction.\\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\\nwhich selectively augments SLM reasoning with targeted guidance from large\\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\\nemploys a score-based evaluation to identify uncertain reasoning steps and\\ninjects corrective LLM-generated reasoning only when necessary. By framing\\nstructured reasoning as an optimal policy search, our approach steers the\\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\\nexperiments on mathematical reasoning datasets demonstrate that targeted\\nexternal scaffolding significantly improves performance, paving the way for\\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\\nare currently unsolvable by SLMs alone.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-14T06:32:45Z\"}"}
