{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07096v1\", \"title\": \"OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training\\n  Tokens\", \"summary\": \"We present OLMoTrace, the first system that traces the outputs of language\\nmodels back to their full, multi-trillion-token training data in real time.\\nOLMoTrace finds and shows verbatim matches between segments of language model\\noutput and documents in the training text corpora. Powered by an extended\\nversion of infini-gram (Liu et al., 2024), our system returns tracing results\\nwithin a few seconds. OLMoTrace can help users understand the behavior of\\nlanguage models through the lens of their training data. We showcase how it can\\nbe used to explore fact checking, hallucination, and the creativity of language\\nmodels. OLMoTrace is publicly available and fully open-source.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-09T17:59:35Z\"}"}
