{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02458v1\", \"title\": \"Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation\", \"summary\": \"Recently, Large Language Model (LLM)-empowered recommender systems have\\nrevolutionized personalized recommendation frameworks and attracted extensive\\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\\nthe negative impact of such vulnerabilities, one potential solution is to\\nemploy collaborative signals based on item-item co-occurrence to purify the\\nmalicious collaborative knowledge from the user's historical interactions\\ninserted by attackers. On the other hand, due to the capabilities to expand\\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\\ntechniques provide unprecedented opportunities to enhance the robustness of\\nLLM-empowered recommender systems by introducing external collaborative\\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\\nretrieving external collaborative signals to purify the poisoned user profiles\\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\\nSpecifically, retrieval-augmented perturbation positioning is proposed to\\nidentify potential perturbations within the users' historical sequences by\\nretrieving external knowledge from collaborative item graphs. After that, we\\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\\nusing either deletion or replacement strategies and introduce a robust ensemble\\nrecommendation strategy to generate final robust predictions. Extensive\\nexperiments on three real-world datasets demonstrate the effectiveness of the\\nproposed RETURN.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.AI\", \"published\": \"2025-04-03T10:22:30Z\"}"}
