{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17685v1\", \"title\": \"Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve\\n  LLM-level Accuracy in Profile Matching Tasks\", \"summary\": \"This study explores the potential of small language model(SLM) ensembles to\\nachieve accuracy comparable to proprietary large language models (LLMs). We\\npropose Ensemble Bayesian Inference (EBI), a novel approach that applies\\nBayesian estimation to combine judgments from multiple SLMs, allowing them to\\nexceed the performance limitations of individual models. Our experiments on\\ndiverse tasks(aptitude assessments and consumer profile analysis in both\\nJapanese and English) demonstrate EBI's effectiveness. Notably, we analyze\\ncases where incorporating models with negative Lift values into ensembles\\nimproves overall performance, and we examine the method's efficacy across\\ndifferent languages. These findings suggest new possibilities for constructing\\nhigh-performance AI systems with limited computational resources and for\\neffectively utilizing models with individually lower performance. Building on\\nexisting research on LLM performance evaluation, ensemble methods, and\\nopen-source LLM utilization, we discuss the novelty and significance of our\\napproach.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-24T15:55:10Z\"}"}
