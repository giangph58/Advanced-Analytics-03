{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19754v1\", \"title\": \"Reconstructing Context: Evaluating Advanced Chunking Strategies for\\n  Retrieval-Augmented Generation\", \"summary\": \"Retrieval-augmented generation (RAG) has become a transformative approach for\\nenhancing large language models (LLMs) by grounding their outputs in external\\nknowledge sources. Yet, a critical question persists: how can vast volumes of\\nexternal knowledge be managed effectively within the input constraints of LLMs?\\nTraditional methods address this by chunking external documents into smaller,\\nfixed-size segments. While this approach alleviates input limitations, it often\\nfragments context, resulting in incomplete retrieval and diminished coherence\\nin generation. To overcome these shortcomings, two advanced techniques, late\\nchunking and contextual retrieval, have been introduced, both aiming to\\npreserve global context. Despite their potential, their comparative strengths\\nand limitations remain unclear. This study presents a rigorous analysis of late\\nchunking and contextual retrieval, evaluating their effectiveness and\\nefficiency in optimizing RAG systems. Our results indicate that contextual\\nretrieval preserves semantic coherence more effectively but requires greater\\ncomputational resources. In contrast, late chunking offers higher efficiency\\nbut tends to sacrifice relevance and completeness.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.AI,cs.CL\", \"published\": \"2025-04-28T12:52:05Z\"}"}
