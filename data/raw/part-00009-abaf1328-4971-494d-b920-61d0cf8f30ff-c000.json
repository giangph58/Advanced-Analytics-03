{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17314v1\", \"title\": \"Class-Conditional Distribution Balancing for Group Robust Classification\", \"summary\": \"Spurious correlations that lead models to correct predictions for the wrong\\nreasons pose a critical challenge for robust real-world generalization.\\nExisting research attributes this issue to group imbalance and addresses it by\\nmaximizing group-balanced or worst-group accuracy, which heavily relies on\\nexpensive bias annotations. A compromise approach involves predicting bias\\ninformation using extensively pretrained foundation models, which requires\\nlarge-scale data and becomes impractical for resource-limited rare domains. To\\naddress these challenges, we offer a novel perspective by reframing the\\nspurious correlations as imbalances or mismatches in class-conditional\\ndistributions, and propose a simple yet effective robust learning method that\\neliminates the need for both bias annotations and predictions. With the goal of\\nreducing the mutual information between spurious factors and label information,\\nour method leverages a sample reweighting strategy to achieve class-conditional\\ndistribution balancing, which automatically highlights minority groups and\\nclasses, effectively dismantling spurious correlations and producing a debiased\\ndata distribution for classification. Extensive experiments and analysis\\ndemonstrate that our approach consistently delivers state-of-the-art\\nperformance, rivaling methods that rely on bias supervision.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-24T07:15:53Z\"}"}
