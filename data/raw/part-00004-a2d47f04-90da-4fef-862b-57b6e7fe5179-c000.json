{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03561v1\", \"title\": \"Ergodic Generative Flows\", \"summary\": \"Generative Flow Networks (GFNs) were initially introduced on directed acyclic\\ngraphs to sample from an unnormalized distribution density. Recent works have\\nextended the theoretical framework for generative methods allowing more\\nflexibility and enhancing application range. However, many challenges remain in\\ntraining GFNs in continuous settings and for imitation learning (IL), including\\nintractability of flow-matching loss, limited tests of non-acyclic training,\\nand the need for a separate reward model in imitation learning. The present\\nwork proposes a family of generative flows called Ergodic Generative Flows\\n(EGFs) which are used to address the aforementioned issues. First, we leverage\\nergodicity to build simple generative flows with finitely many globally defined\\ntransformations (diffeomorphisms) with universality guarantees and tractable\\nflow-matching loss (FM loss). Second, we introduce a new loss involving\\ncross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It\\nis designed for IL training without a separate reward model. We evaluate\\nIL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using\\nthe KL-weakFM loss. Additionally, we conduct toy 2D reinforcement learning\\nexperiments with a target reward, using the FM loss.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,math.DG,math.DS\", \"published\": \"2025-05-06T14:13:21Z\"}"}
