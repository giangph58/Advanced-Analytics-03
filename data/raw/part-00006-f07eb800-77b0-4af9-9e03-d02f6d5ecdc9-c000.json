{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05130v1\", \"title\": \"CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language\\n  Models\", \"summary\": \"Large pre-trained Vision-Language Models (VLMs), such as Contrastive\\nLanguage-Image Pre-training (CLIP), have exhibited remarkable zero-shot\\nperformance across various image classification tasks. Fine-tuning these models\\non domain-specific datasets further enhances their effectiveness for downstream\\napplications. However, fine-tuning in cloud environments raises significant\\nconcerns regarding data security and privacy. Federated Learning (FL) offers a\\ndecentralized solution by enabling model training across local clients without\\ncentralizing sensitive data, but the high communication and computation costs\\nof transmitting full pre-trained models during training limit its scalability.\\nAdditionally, non-Independent and Identically Distributed (non-IID) data across\\nlocal clients can negatively impact model convergence and performance. To\\naddress these challenges, we propose CacheFL, a novel federated learning method\\nthat replaces traditional full model fine-tuning with lightweight cache model\\nfine-tuning. The cache model is initialized using a class-balanced dataset\\ngenerated by a generative pre-trained model, effectively mitigating the impact\\nof non-IID data. This cache model is then distributed to local clients for\\nfine-tuning, and the updated parameters from each client are aggregated on the\\nserver and redistributed. With the updated cache model, the classification\\nperformance of CLIP is improved after just a few epochs. By limiting the\\ntraining and communication to the cache model, CacheFL significantly reduces\\nresource demands while ensuring data privacy and security. Extensive\\nexperiments conducted on ImageNet and 10 additional datasets demonstrate that\\nCacheFL outperforms traditional approaches in terms of classification accuracy,\\nresource efficiency, and privacy preservation.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC\", \"published\": \"2025-05-08T11:07:35Z\"}"}
