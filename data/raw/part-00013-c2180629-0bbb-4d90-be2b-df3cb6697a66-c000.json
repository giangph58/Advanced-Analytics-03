{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12991v1\", \"title\": \"Chain-of-Thought Prompting for Out-of-Distribution Samples: A\\n  Latent-Variable Study\", \"summary\": \"Chain-of-Thought (CoT) prompting has emerged as a powerful technique to\\nimprove in-context learning (ICL) in large language models (LLMs) by breaking\\ncomplex reasoning into intermediate steps. However, the ability of CoT to\\ngeneralize under distribution shift remains poorly understood. In this work, we\\nextend a latent-variable framework for CoT prompting and study its behavior on\\ntwo prototypical out-of-distribution (OOD) scenarios: (i) the latent variables\\nfor CoT steps are permuted into novel combinations, and (ii) the latent\\nvariables uniformly scaled by a factor. Our experiments demonstrate that CoT\\ninference generalizes effectively to OOD samples whose latent variables closely\\nresemble those seen during training, but its performance degrades as this\\nsimilarity decreases. These findings provide foundational insights into the\\nstrengths and limitations of CoT prompting under OOD conditions and suggest\\ndirections for developing more resilient reasoning strategies in future LLMs.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-17T14:59:29Z\"}"}
