{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12805v1\", \"title\": \"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind\\n  Evaluation\", \"summary\": \"This study explored how large language models (LLMs) perform in two areas\\nrelated to art: writing critiques of artworks and reasoning about mental states\\n(Theory of Mind, or ToM) in art-related situations. For the critique generation\\npart, we built a system that combines Noel Carroll's evaluative framework with\\na broad selection of art criticism theories. The model was prompted to first\\nwrite a full-length critique and then shorter, more coherent versions using a\\nstep-by-step prompting process. These AI-generated critiques were then compared\\nwith those written by human experts in a Turing test-style evaluation. In many\\ncases, human subjects had difficulty telling which was which, and the results\\nsuggest that LLMs can produce critiques that are not only plausible in style\\nbut also rich in interpretation, as long as they are carefully guided. In the\\nsecond part, we introduced new simple ToM tasks based on situations involving\\ninterpretation, emotion, and moral tension, which can appear in the context of\\nart. These go beyond standard false-belief tests and allow for more complex,\\nsocially embedded forms of reasoning. We tested 41 recent LLMs and found that\\ntheir performance varied across tasks and models. In particular, tasks that\\ninvolved affective or ambiguous situations tended to reveal clearer\\ndifferences. Taken together, these results help clarify how LLMs respond to\\ncomplex interpretative challenges, revealing both their cognitive limitations\\nand potential. While our findings do not directly contradict the so-called\\nGenerative AI Paradox--the idea that LLMs can produce expert-like output\\nwithout genuine understanding--they suggest that, depending on how LLMs are\\ninstructed, such as through carefully designed prompts, these models may begin\\nto show behaviors that resemble understanding more closely than we might\\nassume.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CY,cs.HC\", \"published\": \"2025-04-17T10:10:25Z\"}"}
