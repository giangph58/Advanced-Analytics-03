{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20829v1\", \"title\": \"GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for\\n  Targeted Scene Confusion\", \"summary\": \"As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene\\nrepresentation and novel view synthesis, its rapid adoption in safety-critical\\ndomains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of\\npotential security vulnerabilities. This paper presents the first systematic\\nstudy of backdoor threats in 3DGS pipelines. We identify that adversaries may\\nimplant backdoor views to induce malicious scene confusion during inference,\\npotentially leading to environmental misperception in autonomous navigation or\\nspatial distortion in immersive environments. To uncover this risk, we propose\\nGuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap\\ninjects malicious views at specific attack viewpoints while preserving\\nhigh-quality rendering in non-target views, ensuring minimal detectability and\\nmaximizing potential harm. Specifically, the proposed method consists of a\\nthree-stage pipeline (attack, stabilization, and normal training) to implant\\nstealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing\\nattack efficacy and perceptual realism to expose security risks in 3D\\nrendering. Extensive experiments on both synthetic and real-world datasets\\ndemonstrate that GuassTrap can effectively embed imperceptible yet harmful\\nbackdoor views while maintaining high-quality rendering in normal views,\\nvalidating its robustness, adaptability, and practical applicability.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-29T14:52:14Z\"}"}
