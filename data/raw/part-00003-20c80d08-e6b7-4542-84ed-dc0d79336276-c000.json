{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00364v1\", \"title\": \"From GNNs to Trees: Multi-Granular Interpretability for Graph Neural\\n  Networks\", \"summary\": \"Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying\\nreasoning behind model predictions, attributing their decisions to specific\\nsubgraphs that are informative. However, existing subgraph-based interpretable\\nmethods suffer from an overemphasis on local structure, potentially overlooking\\nlong-range dependencies within the entire graphs. Although recent efforts that\\nrely on graph coarsening have proven beneficial for global interpretability,\\nthey inevitably reduce the graphs to a fixed granularity. Such an inflexible\\nway can only capture graph connectivity at a specific level, whereas real-world\\ngraph tasks often exhibit relationships at varying granularities (e.g.,\\nrelevant interactions in proteins span from functional groups, to amino acids,\\nand up to protein domains). In this paper, we introduce a novel Tree-like\\nInterpretable Framework (TIF) for graph classification, where plain GNNs are\\ntransformed into hierarchical trees, with each level featuring coarsened graphs\\nof different granularity as tree nodes. Specifically, TIF iteratively adopts a\\ngraph coarsening module to compress original graphs (i.e., root nodes of trees)\\ninto increasingly coarser ones (i.e., child nodes of trees), while preserving\\ndiversity among tree nodes within different branches through a dedicated graph\\nperturbation module. Finally, we propose an adaptive routing module to identify\\nthe most informative root-to-leaf paths, providing not only the final\\nprediction but also the multi-granular interpretability for the decision-making\\nprocess. Extensive experiments on the graph classification benchmarks with both\\nsynthetic and real-world datasets demonstrate the superiority of TIF in\\ninterpretability, while also delivering a competitive prediction performance\\nakin to the state-of-the-art counterparts.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-01T07:22:51Z\"}"}
