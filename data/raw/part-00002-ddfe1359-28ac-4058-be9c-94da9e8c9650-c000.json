{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20708v1\", \"title\": \"Beyond the Last Answer: Your Reasoning Trace Uncovers More than You\\n  Think\", \"summary\": \"Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\\nproblems. Standard evaluation practice involves generating a complete reasoning\\ntrace and assessing the correctness of the final answer presented at its\\nconclusion. In this paper, we challenge the reliance on the final answer by\\nposing the following two questions: Does the final answer reliably represent\\nthe model's optimal conclusion? Can alternative reasoning paths yield different\\nresults? To answer these questions, we analyze intermediate reasoning steps,\\ntermed subthoughts, and propose a method based on our findings. Our approach\\ninvolves segmenting a reasoning trace into sequential subthoughts based on\\nlinguistic cues. We start by prompting the model to generate continuations from\\nthe end-point of each intermediate subthought. We extract a potential answer\\nfrom every completed continuation originating from different subthoughts. We\\nfind that aggregating these answers by selecting the most frequent one (the\\nmode) often yields significantly higher accuracy compared to relying solely on\\nthe answer derived from the original complete trace. Analyzing the consistency\\namong the answers derived from different subthoughts reveals characteristics\\nthat correlate with the model's confidence and correctness, suggesting\\npotential for identifying less reliable answers. Our experiments across various\\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\\nshow consistent accuracy improvements, with gains reaching up to 13\\\\% and 10\\\\%\\nrespectively. Implementation is available at:\\nhttps://github.com/hammoudhasan/SubthoughtReasoner.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-04-29T12:39:07Z\"}"}
