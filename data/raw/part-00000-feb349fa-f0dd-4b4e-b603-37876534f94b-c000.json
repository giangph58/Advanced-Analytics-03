{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07894v1\", \"title\": \"DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows\", \"summary\": \"Many real-world applications of flow-based generative models desire a diverse\\nset of samples that cover multiple modes of the target distribution. However,\\nthe predominant approach for obtaining diverse sets is not sample-efficient, as\\nit involves independently obtaining many samples from the source distribution\\nand mapping them through the flow until the desired mode coverage is achieved.\\nAs an alternative to repeated sampling, we introduce DiverseFlow: a\\ntraining-free approach to improve the diversity of flow models. Our key idea is\\nto employ a determinantal point process to induce a coupling between the\\nsamples that drives diversity under a fixed sampling budget. In essence,\\nDiverseFlow allows exploration of more variations in a learned flow model with\\nfewer samples. We demonstrate the efficacy of our method for tasks where\\nsample-efficient diversity is desirable, such as text-guided image generation\\nwith polysemous words, inverse problems like large-hole inpainting, and\\nclass-conditional image synthesis.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-10T16:09:50Z\"}"}
