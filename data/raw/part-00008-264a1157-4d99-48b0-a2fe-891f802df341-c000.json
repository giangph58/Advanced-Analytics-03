{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20988v1\", \"title\": \"Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine\\n  Learning\", \"summary\": \"We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm\\nfor collaborative machine learning that combines the strengths of Federated\\nLearning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier\\ncommunication structure that avoids the single point of failure inherent in FL\\nand outperforms the state-of-the-art P2PL framework, Epidemic Learning Local\\n(ELL). At equal communication budgets (total edges), HSL achieves higher\\nperformance than ELL, while at significantly lower communication budgets, it\\ncan match ELL's performance. For instance, with only 400 edges, HSL reaches the\\nsame test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on\\nCIFAR-10, demonstrating its suitability for resource-constrained systems. HSL\\nalso achieves stronger consensus among nodes after mixing, resulting in\\nimproved performance with fewer training rounds. We substantiate these claims\\nthrough rigorous theoretical analyses and extensive experimental results,\\nshowcasing HSL's practicality for large-scale collaborative learning.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.DC\", \"published\": \"2025-04-29T17:56:55Z\"}"}
