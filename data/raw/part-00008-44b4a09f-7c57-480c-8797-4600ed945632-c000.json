{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10143v1\", \"title\": \"Negate or Embrace: On How Misalignment Shapes Multimodal Representation\\n  Learning\", \"summary\": \"Multimodal representation learning, exemplified by multimodal contrastive\\nlearning (MMCL) using image-text pairs, aims to learn powerful representations\\nby aligning cues across modalities. This approach relies on the core assumption\\nthat the exemplar image-text pairs constitute two representations of an\\nidentical concept. However, recent research has revealed that real-world\\ndatasets often exhibit misalignment. There are two distinct viewpoints on how\\nto address this issue: one suggests mitigating the misalignment, and the other\\nleveraging it. We seek here to reconcile these seemingly opposing perspectives,\\nand to provide a practical guide for practitioners. Using latent variable\\nmodels we thus formalize misalignment by introducing two specific mechanisms:\\nselection bias, where some semantic variables are missing, and perturbation\\nbias, where semantic variables are distorted -- both affecting latent variables\\nshared across modalities. Our theoretical analysis demonstrates that, under\\nmild assumptions, the representations learned by MMCL capture exactly the\\ninformation related to the subset of the semantic variables invariant to\\nselection and perturbation biases. This provides a unified perspective for\\nunderstanding misalignment. Based on this, we further offer actionable insights\\ninto how misalignment should inform the design of real-world ML systems. We\\nvalidate our theoretical findings through extensive empirical studies on both\\nsynthetic data and real image-text datasets, shedding light on the nuanced\\nimpact of misalignment on multimodal representation learning.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-14T11:54:19Z\"}"}
