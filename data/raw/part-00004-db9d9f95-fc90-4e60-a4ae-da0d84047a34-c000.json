{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16584v1\", \"title\": \"Case Study: Fine-tuning Small Language Models for Accurate and Private\\n  CWE Detection in Python Code\", \"summary\": \"Large Language Models (LLMs) have demonstrated significant capabilities in\\nunderstanding and analyzing code for security vulnerabilities, such as Common\\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\\nand substantial computational requirements pose challenges for analyzing\\nsensitive or proprietary codebases due to privacy concerns and inference costs.\\nThis work explores the potential of Small Language Models (SLMs) as a viable\\nalternative for accurate, on-premise vulnerability detection. We investigated\\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\\nPython code. To facilitate this, we developed a targeted dataset of 500\\nexamples using a semi-supervised approach involving LLM-driven synthetic data\\ngeneration coupled with meticulous human review. Initial tests confirmed that\\nthe base codegen-mono model completely failed to identify CWEs in our samples.\\nHowever, after applying instruction-following fine-tuning, the specialized SLM\\nachieved remarkable performance on our test set, yielding approximately 99%\\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\\nefficient tools for CWE detection, offering a practical and privacy-preserving\\nsolution for integrating advanced security analysis directly into development\\nworkflows.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.AI\", \"published\": \"2025-04-23T10:05:27Z\"}"}
