{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06994v1\", \"title\": \"RayFronts: Open-Set Semantic Ray Frontiers for Online Scene\\n  Understanding and Exploration\", \"summary\": \"Open-set semantic mapping is crucial for open-world robots. Current mapping\\napproaches either are limited by the depth range or only map beyond-range\\nentities in constrained settings, where overall they fail to combine\\nwithin-range and beyond-range observations. Furthermore, these methods make a\\ntrade-off between fine-grained semantics and efficiency. We introduce\\nRayFronts, a unified representation that enables both dense and beyond-range\\nefficient semantic mapping. RayFronts encodes task-agnostic open-set semantics\\nto both in-range voxels and beyond-range rays encoded at map boundaries,\\nempowering the robot to reduce search volumes significantly and make informed\\ndecisions both within & beyond sensory range, while running at 8.84 Hz on an\\nOrin AGX. Benchmarking the within-range semantics shows that RayFronts's\\nfine-grained image encoding provides 1.34x zero-shot 3D semantic segmentation\\nperformance while improving throughput by 16.5x. Traditionally, online mapping\\nperformance is entangled with other system components, complicating evaluation.\\nWe propose a planner-agnostic evaluation framework that captures the utility\\nfor online beyond-range search and exploration, and show RayFronts reduces\\nsearch volume 2.2x more efficiently than the closest online baselines.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.CV,cs.LG\", \"published\": \"2025-04-09T16:06:58Z\"}"}
