{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11809v1\", \"title\": \"Efficient and Adaptive Simultaneous Speech Translation with Fully\\n  Unidirectional Architecture\", \"summary\": \"Simultaneous speech translation (SimulST) produces translations incrementally\\nwhile processing partial speech input. Although large language models (LLMs)\\nhave showcased strong capabilities in offline translation tasks, applying them\\nto SimulST poses notable challenges. Existing LLM-based SimulST approaches\\neither incur significant computational overhead due to repeated encoding of\\nbidirectional speech encoder, or they depend on a fixed read/write policy,\\nlimiting the efficiency and performance. In this work, we introduce Efficient\\nand Adaptive Simultaneous Speech Translation (EASiST) with fully unidirectional\\narchitecture, including both speech encoder and LLM. EASiST includes a\\nmulti-latency data curation strategy to generate semantically aligned SimulST\\ntraining samples and redefines SimulST as an interleaved generation task with\\nexplicit read/write tokens. To facilitate adaptive inference, we incorporate a\\nlightweight policy head that dynamically predicts read/write actions.\\nAdditionally, we employ a multi-stage training strategy to align speech-text\\nmodalities and optimize both translation and policy behavior. Experiments on\\nthe MuST-C En$\\\\rightarrow$De and En$\\\\rightarrow$Es datasets demonstrate that\\nEASiST offers superior latency-quality trade-offs compared to several strong\\nbaselines.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-16T06:46:15Z\"}"}
