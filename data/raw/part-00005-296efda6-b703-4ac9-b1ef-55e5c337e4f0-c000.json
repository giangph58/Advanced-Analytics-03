{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05376v1\", \"title\": \"GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans\", \"summary\": \"We propose a novel method that reconstructs hair strands directly from\\ncolorless 3D scans by leveraging multi-modal hair orientation extraction. Hair\\nstrand reconstruction is a fundamental problem in computer vision and graphics\\nthat can be used for high-fidelity digital avatar synthesis, animation, and\\nAR/VR applications. However, accurately recovering hair strands from raw scan\\ndata remains challenging due to human hair's complex and fine-grained\\nstructure. Existing methods typically rely on RGB captures, which can be\\nsensitive to the environment and can be a challenging domain for extracting the\\norientation of guiding strands, especially in the case of challenging\\nhairstyles. To reconstruct the hair purely from the observed geometry, our\\nmethod finds sharp surface features directly on the scan and estimates strand\\norientation through a neural 2D line detector applied to the renderings of scan\\nshading. Additionally, we incorporate a diffusion prior trained on a diverse\\nset of synthetic hair scans, refined with an improved noise schedule, and\\nadapted to the reconstructed contents via a scan-specific text prompt. We\\ndemonstrate that this combination of supervision signals enables accurate\\nreconstruction of both simple and intricate hairstyles without relying on color\\ninformation. To facilitate further research, we introduce Strands400, the\\nlargest publicly available dataset of hair strands with detailed surface\\ngeometry extracted from real-world data, which contains reconstructed hair\\nstrands from the scans of 400 subjects.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T16:11:09Z\"}"}
