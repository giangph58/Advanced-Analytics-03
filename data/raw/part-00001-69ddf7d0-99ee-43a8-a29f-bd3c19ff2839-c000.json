{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03300v1\", \"title\": \"3D Can Be Explored In 2D: Pseudo-Label Generation for LiDAR Point Clouds\\n  Using Sensor-Intensity-Based 2D Semantic Segmentation\", \"summary\": \"Semantic segmentation of 3D LiDAR point clouds, essential for autonomous\\ndriving and infrastructure management, is best achieved by supervised learning,\\nwhich demands extensive annotated datasets and faces the problem of domain\\nshifts. We introduce a new 3D semantic segmentation pipeline that leverages\\naligned scenes and state-of-the-art 2D segmentation methods, avoiding the need\\nfor direct 3D annotation or reliance on additional modalities such as camera\\nimages at inference time. Our approach generates 2D views from LiDAR scans\\ncolored by sensor intensity and applies 2D semantic segmentation to these views\\nusing a camera-domain pretrained model. The segmented 2D outputs are then\\nback-projected onto the 3D points, with a simple voting-based estimator that\\nmerges the labels associated to each 3D point. Our main contribution is a\\nglobal pipeline for 3D semantic segmentation requiring no prior 3D annotation\\nand not other modality for inference, which can be used for pseudo-label\\ngeneration. We conduct a thorough ablation study and demonstrate the potential\\nof the generated pseudo-labels for the Unsupervised Domain Adaptation task.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T08:31:32Z\"}"}
