{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17360v1\", \"title\": \"PatientDx: Merging Large Language Models for Protecting Data-Privacy in\\n  Healthcare\", \"summary\": \"Fine-tuning of Large Language Models (LLMs) has become the default practice\\nfor improving model performance on a given task. However, performance\\nimprovement comes at the cost of training on vast amounts of annotated data\\nwhich could be sensitive leading to significant data privacy concerns. In\\nparticular, the healthcare domain is one of the most sensitive domains exposed\\nto data privacy issues. In this paper, we present PatientDx, a framework of\\nmodel merging that allows the design of effective LLMs for health-predictive\\ntasks without requiring fine-tuning nor adaptation on patient data. Our\\nproposal is based on recently proposed techniques known as merging of LLMs and\\naims to optimize a building block merging strategy. PatientDx uses a pivotal\\nmodel adapted to numerical reasoning and tunes hyperparameters on examples\\nbased on a performance metric but without training of the LLM on these data.\\nExperiments using the mortality tasks of the MIMIC-IV dataset show improvements\\nup to 7% in terms of AUROC when compared to initial models. Additionally, we\\nconfirm that when compared to fine-tuned models, our proposal is less prone to\\ndata leak problems without hurting performance. Finally, we qualitatively show\\nthe capabilities of our proposal through a case study. Our best model is\\npublicly available at https://huggingface.co/ Jgmorenof/mistral\\\\_merged\\\\_0\\\\_4.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-24T08:21:04Z\"}"}
