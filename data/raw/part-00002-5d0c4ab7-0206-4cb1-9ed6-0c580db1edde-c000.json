{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23897v1\", \"title\": \"Training-Free Text-Guided Image Editing with Visual Autoregressive Model\", \"summary\": \"Text-guided image editing is an essential task that enables users to modify\\nimages through natural language descriptions. Recent advances in diffusion\\nmodels and rectified flows have significantly improved editing quality,\\nprimarily relying on inversion techniques to extract structured noise from\\ninput images. However, inaccuracies in inversion can propagate errors, leading\\nto unintended modifications and compromising fidelity. Moreover, even with\\nperfect inversion, the entanglement between textual prompts and image features\\noften results in global changes when only local edits are intended. To address\\nthese challenges, we propose a novel text-guided image editing framework based\\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\\ninversion while ensuring precise and controlled modifications. Our method\\nintroduces a caching mechanism that stores token indices and probability\\ndistributions from the original image, capturing the relationship between the\\nsource prompt and the image. Using this cache, we design an adaptive\\nfine-grained masking strategy that dynamically identifies and constrains\\nmodifications to relevant regions, preventing unintended changes. A token\\nreassembling approach further refines the editing process, enhancing diversity,\\nfidelity, and control. Our framework operates in a training-free manner and\\nachieves high-fidelity editing with faster inference speeds, processing a 1K\\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\\nthat our method achieves performance comparable to, or even surpassing,\\nexisting diffusion- and rectified flow-based approaches in both quantitative\\nmetrics and visual quality. The code will be released.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-03-31T09:46:56Z\"}"}
