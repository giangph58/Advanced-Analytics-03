{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17395v1\", \"title\": \"SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object\\n  Counting\", \"summary\": \"Open-world object counting leverages the robust text-image alignment of\\npre-trained vision-language models (VLMs) to enable counting of arbitrary\\ncategories in images specified by textual queries. However, widely adopted\\nnaive fine-tuning strategies concentrate exclusively on text-image consistency\\nfor categories contained in training, which leads to limited generalizability\\nfor unseen categories. In this work, we propose a plug-and-play Semantic-Driven\\nVisual Prompt Tuning framework (SDVPT) that transfers knowledge from the\\ntraining set to unseen categories with minimal overhead in parameters and\\ninference time. First, we introduce a two-stage visual prompt learning strategy\\ncomposed of Category-Specific Prompt Initialization (CSPI) and Topology-Guided\\nPrompt Refinement (TGPR). The CSPI generates category-specific visual prompts,\\nand then TGPR distills latent structural patterns from the VLM's text encoder\\nto refine these prompts. During inference, we dynamically synthesize the visual\\nprompts for unseen categories based on the semantic correlation between unseen\\nand training categories, facilitating robust text-image alignment for unseen\\ncategories. Extensive experiments integrating SDVPT with all available\\nopen-world object counting models demonstrate its effectiveness and\\nadaptability across three widely used datasets: FSC-147, CARPK, and PUCPR+.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T09:31:08Z\"}"}
