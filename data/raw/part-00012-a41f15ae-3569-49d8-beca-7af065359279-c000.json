{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11289v1\", \"title\": \"UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion\\n  Transformer\", \"summary\": \"This report presents UniAnimate-DiT, an advanced project that leverages the\\ncutting-edge and powerful capabilities of the open-source Wan2.1 model for\\nconsistent human image animation. Specifically, to preserve the robust\\ngenerative capabilities of the original Wan2.1 model, we implement Low-Rank\\nAdaptation (LoRA) technique to fine-tune a minimal set of parameters,\\nsignificantly reducing training memory overhead. A lightweight pose encoder\\nconsisting of multiple stacked 3D convolutional layers is designed to encode\\nmotion information of driving poses. Furthermore, we adopt a simple\\nconcatenation operation to integrate the reference appearance into the model\\nand incorporate the pose information of the reference image for enhanced pose\\nalignment. Experimental results show that our approach achieves visually\\nappearing and temporally consistent high-fidelity animations. Trained on 480p\\n(832x480) videos, UniAnimate-DiT demonstrates strong generalization\\ncapabilities to seamlessly upscale to 720P (1280x720) during inference. The\\ntraining and inference code is publicly available at\\nhttps://github.com/ali-vilab/UniAnimate-DiT.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T15:29:11Z\"}"}
