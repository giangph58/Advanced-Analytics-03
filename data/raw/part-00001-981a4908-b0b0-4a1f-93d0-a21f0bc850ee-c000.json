{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11451v1\", \"title\": \"PARTFIELD: Learning 3D Feature Fields for Part Segmentation and Beyond\", \"summary\": \"We propose PartField, a feedforward approach for learning part-based 3D\\nfeatures, which captures the general concept of parts and their hierarchy\\nwithout relying on predefined templates or text-based names, and can be applied\\nto open-world 3D shapes across various modalities. PartField requires only a 3D\\nfeedforward pass at inference time, significantly improving runtime and\\nrobustness compared to prior approaches. Our model is trained by distilling 2D\\nand 3D part proposals from a mix of labeled datasets and image segmentations on\\nlarge unsupervised datasets, via a contrastive learning formulation. It\\nproduces a continuous feature field which can be clustered to yield a\\nhierarchical part decomposition. Comparisons show that PartField is up to 20%\\nmore accurate and often orders of magnitude faster than other recent\\nclass-agnostic part-segmentation methods. Beyond single-shape part\\ndecomposition, consistency in the learned field emerges across shapes, enabling\\ntasks such as co-segmentation and correspondence, which we demonstrate in\\nseveral applications of these general-purpose, hierarchical, and consistent 3D\\nfeature fields. Check our Webpage!\\nhttps://research.nvidia.com/labs/toronto-ai/partfield-release/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T17:58:16Z\"}"}
