{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23688v1\", \"title\": \"Mapping Geopolitical Bias in 11 Large Language Models: A Bilingual,\\n  Dual-Framing Analysis of U.S.-China Tensions\", \"summary\": \"This study systematically analyzes geopolitical bias across 11 prominent\\nLarge Language Models (LLMs) by examining their responses to seven critical\\ntopics in U.S.-China relations. Utilizing a bilingual (English and Chinese) and\\ndual-framing (affirmative and reverse) methodology, we generated 19,712 prompts\\ndesigned to detect ideological leanings in model outputs. Responses were\\nquantitatively assessed on a normalized scale from -2 (strongly Pro-China) to\\n+2 (strongly Pro-U.S.) and categorized according to stance, neutrality, and\\nrefusal rates. The findings demonstrate significant and consistent ideological\\nalignments correlated with the LLMs' geographic origins; U.S.-based models\\npredominantly favored Pro-U.S. stances, while Chinese-origin models exhibited\\npronounced Pro-China biases. Notably, language and prompt framing substantially\\ninfluenced model responses, with several LLMs exhibiting stance reversals based\\non prompt polarity or linguistic context. Additionally, we introduced\\ncomprehensive metrics to evaluate response consistency across languages and\\nframing conditions, identifying variability and vulnerabilities in model\\nbehaviors. These results offer practical insights that can guide organizations\\nand individuals in selecting LLMs best aligned with their operational\\npriorities and geopolitical considerations, underscoring the importance of\\ncareful model evaluation in politically sensitive applications. Furthermore,\\nthe research highlights specific prompt structures and linguistic variations\\nthat can strategically trigger distinct responses from models, revealing\\nmethods for effectively navigating and influencing LLM outputs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.HC\", \"published\": \"2025-03-31T03:38:17Z\"}"}
