{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00702v1\", \"title\": \"RayZer: A Self-supervised Large View Synthesis Model\", \"summary\": \"We present RayZer, a self-supervised multi-view 3D Vision model trained\\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\\nrepresentation, and synthesizes novel views. During training, RayZer relies\\nsolely on its self-predicted camera poses to render target views, eliminating\\nthe need for any ground-truth camera annotations and allowing RayZer to be\\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\\nattributed to two key factors. First, we design a self-supervised framework,\\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\\nand scene representations. Second, we design a transformer-based model in which\\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\\nsimultaneously. RayZer demonstrates comparable or even superior novel view\\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-01T17:59:34Z\"}"}
