{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04109v1\", \"title\": \"One2Any: One-Reference 6D Pose Estimation for Any Object\", \"summary\": \"6D object pose estimation remains challenging for many applications due to\\ndependencies on complete 3D models, multi-view images, or training limited to\\nspecific object categories. These requirements make generalization to novel\\nobjects difficult for which neither 3D models nor multi-view images may be\\navailable. To address this, we propose a novel method One2Any that estimates\\nthe relative 6-degrees of freedom (DOF) object pose using only a single\\nreference-single query RGB-D image, without prior knowledge of its 3D model,\\nmulti-view data, or category constraints. We treat object pose estimation as an\\nencoding-decoding process, first, we obtain a comprehensive Reference Object\\nPose Embedding (ROPE) that encodes an object shape, orientation, and texture\\nfrom a single reference view. Using this embedding, a U-Net-based pose decoding\\nmodule produces Reference Object Coordinate (ROC) for new views, enabling fast\\nand accurate pose estimation. This simple encoding-decoding framework allows\\nour model to be trained on any pair-wise pose data, enabling large-scale\\ntraining and demonstrating great scalability. Experiments on multiple benchmark\\ndatasets demonstrate that our model generalizes well to novel objects,\\nachieving state-of-the-art accuracy and robustness even rivaling methods that\\nrequire multi-view or CAD inputs, at a fraction of compute.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-07T03:54:59Z\"}"}
