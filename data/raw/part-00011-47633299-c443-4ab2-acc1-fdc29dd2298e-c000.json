{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13176v1\", \"title\": \"IMAGGarment-1: Fine-Grained Garment Generation for Controllable Fashion\\n  Design\", \"summary\": \"This paper presents IMAGGarment-1, a fine-grained garment generation (FGG)\\nframework that enables high-fidelity garment synthesis with precise control\\nover silhouette, color, and logo placement. Unlike existing methods that are\\nlimited to single-condition inputs, IMAGGarment-1 addresses the challenges of\\nmulti-conditional controllability in personalized fashion design and digital\\napparel applications. Specifically, IMAGGarment-1 employs a two-stage training\\nstrategy to separately model global appearance and local details, while\\nenabling unified and controllable generation through end-to-end inference. In\\nthe first stage, we propose a global appearance model that jointly encodes\\nsilhouette and color using a mixed attention module and a color adapter. In the\\nsecond stage, we present a local enhancement model with an adaptive\\nappearance-aware module to inject user-defined logos and spatial constraints,\\nenabling accurate placement and visual consistency. To support this task, we\\nrelease GarmentBench, a large-scale dataset comprising over 180K garment\\nsamples paired with multi-level design conditions, including sketches, color\\nreferences, logo placements, and textual prompts. Extensive experiments\\ndemonstrate that our method outperforms existing baselines, achieving superior\\nstructural stability, color fidelity, and local controllability performance.\\nThe code and model are available at https://github.com/muzishen/IMAGGarment-1.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T17:59:47Z\"}"}
