{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00263v1\", \"title\": \"EnronQA: Towards Personalized RAG over Private Documents\", \"summary\": \"Retrieval Augmented Generation (RAG) has become one of the most popular\\nmethods for bringing knowledge-intensive context to large language models (LLM)\\nbecause of its ability to bring local context at inference time without the\\ncost or data leakage risks associated with fine-tuning. A clear separation of\\nprivate information from the LLM training has made RAG the basis for many\\nenterprise LLM workloads as it allows the company to augment LLM's\\nunderstanding using customers' private documents. Despite its popularity for\\nprivate documents in enterprise deployments, current RAG benchmarks for\\nvalidating and optimizing RAG pipelines draw their corpora from public data\\nsuch as Wikipedia or generic web pages and offer little to no personal context.\\nSeeking to empower more personal and private RAG we release the EnronQA\\nbenchmark, a dataset of 103,638 emails with 528,304 question-answer pairs\\nacross 150 different user inboxes. EnronQA enables better benchmarking of RAG\\npipelines over private data and allows for experimentation on the introduction\\nof personalized retrieval settings over realistic data. Finally, we use EnronQA\\nto explore the tradeoff in memorization and retrieval when reasoning over\\nprivate documents.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.CL\", \"published\": \"2025-05-01T03:07:30Z\"}"}
