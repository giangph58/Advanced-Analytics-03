{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15100v1\", \"title\": \"Application of Sensitivity Analysis Methods for Studying Neural Network\\n  Models\", \"summary\": \"This study demonstrates the capabilities of several methods for analyzing the\\nsensitivity of neural networks to perturbations of the input data and\\ninterpreting their underlying mechanisms. The investigated approaches include\\nthe Sobol global sensitivity analysis, the local sensitivity method for input\\npixel perturbations and the activation maximization technique. As examples, in\\nthis study we consider a small feedforward neural network for analyzing an open\\ntabular dataset of clinical diabetes data, as well as two classical\\nconvolutional architectures, VGG-16 and ResNet-18, which are widely used in\\nimage processing and classification. Utilization of the global sensitivity\\nanalysis allows us to identify the leading input parameters of the chosen tiny\\nneural network and reduce their number without significant loss of the\\naccuracy. As far as global sensitivity analysis is not applicable to larger\\nmodels we try the local sensitivity analysis and activation maximization method\\nin application to the convolutional neural networks. These methods show\\ninteresting patterns for the convolutional models solving the image\\nclassification problem. All in all, we compare the results of the activation\\nmaximization method with popular Grad-CAM technique in the context of\\nultrasound data analysis.\", \"main_category\": \"math.NA\", \"categories\": \"math.NA,cs.LG,cs.NA\", \"published\": \"2025-04-21T13:41:20Z\"}"}
