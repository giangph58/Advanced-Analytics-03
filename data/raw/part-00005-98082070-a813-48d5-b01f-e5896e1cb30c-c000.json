{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21366v1\", \"title\": \"DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic\\n  Gating Fusion\", \"summary\": \"Current Audio-Visual Source Separation methods primarily adopt two design\\nstrategies. The first strategy involves fusing audio and visual features at the\\nbottleneck layer of the encoder, followed by processing the fused features\\nthrough the decoder. However, when there is a significant disparity between the\\ntwo modalities, this approach may lead to the loss of critical information. The\\nsecond strategy avoids direct fusion and instead relies on the decoder to\\nhandle the interaction between audio and visual features. Nonetheless, if the\\nencoder fails to integrate information across modalities adequately, the\\ndecoder may be unable to effectively capture the complex relationships between\\nthem. To address these issues, this paper proposes a dynamic fusion method\\nbased on a gating mechanism that dynamically adjusts the modality fusion\\ndegree. This approach mitigates the limitations of solely relying on the\\ndecoder and facilitates efficient collaboration between audio and visual\\nfeatures. Additionally, an audio attention module is introduced to enhance the\\nexpressive capacity of audio features, thereby further improving model\\nperformance. Experimental results demonstrate that our method achieves\\nsignificant performance improvements on two benchmark datasets, validating its\\neffectiveness and advantages in Audio-Visual Source Separation tasks.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.AI\", \"published\": \"2025-04-30T06:55:24Z\"}"}
