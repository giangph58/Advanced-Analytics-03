{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23925v1\", \"title\": \"CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral\\n  Subpixel-Level Semi-Dense Image Matching\", \"summary\": \"This prospective study proposes CoMatch, a novel semi-dense image matcher\\nwith dynamic covisibility awareness and bilateral subpixel accuracy. Firstly,\\nobserving that modeling context interaction over the entire coarse feature map\\nelicits highly redundant computation due to the neighboring representation\\nsimilarity of tokens, a covisibility-guided token condenser is introduced to\\nadaptively aggregate tokens in light of their covisibility scores that are\\ndynamically estimated, thereby ensuring computational efficiency while\\nimproving the representational capacity of aggregated tokens simultaneously.\\nSecondly, considering that feature interaction with massive non-covisible areas\\nis distracting, which may degrade feature distinctiveness, a\\ncovisibility-assisted attention mechanism is deployed to selectively suppress\\nirrelevant message broadcast from non-covisible reduced tokens, resulting in\\nrobust and compact attention to relevant rather than all ones. Thirdly, we find\\nthat at the fine-level stage, current methods adjust only the target view's\\nkeypoints to subpixel level, while those in the source view remain restricted\\nat the coarse level and thus not informative enough, detrimental to keypoint\\nlocation-sensitive usages. A simple yet potent fine correlation module is\\ndeveloped to refine the matching candidates in both source and target views to\\nsubpixel level, attaining attractive performance improvement. Thorough\\nexperimentation across an array of public benchmarks affirms CoMatch's\\npromising accuracy, efficiency, and generalizability.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T10:17:01Z\"}"}
