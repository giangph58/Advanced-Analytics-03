{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21314v1\", \"title\": \"Capturing Conditional Dependence via Auto-regressive Diffusion Models\", \"summary\": \"Diffusion models have demonstrated appealing performance in both image and\\nvideo generation. However, many works discover that they struggle to capture\\nimportant, high-level relationships that are present in the real world. For\\nexample, they fail to learn physical laws from data, and even fail to\\nunderstand that the objects in the world exist in a stable fashion. This is due\\nto the fact that important conditional dependence structures are not adequately\\ncaptured in the vanilla diffusion models. In this work, we initiate an in-depth\\nstudy on strengthening the diffusion model to capture the conditional\\ndependence structures in the data. In particular, we examine the efficacy of\\nthe auto-regressive (AR) diffusion models for such purpose and develop the\\nfirst theoretical results on the sampling error of AR diffusion models under\\n(possibly) the mildest data assumption. Our theoretical findings indicate that,\\ncompared with typical diffusion models, the AR variant produces samples with a\\nreduced gap in approximating the data conditional distribution. On the other\\nhand, the overall inference time of the AR-diffusion models is only moderately\\nlarger than that for the vanilla diffusion models, making them still practical\\nfor large scale applications. We also provide empirical results showing that\\nwhen there is clear conditional dependence structure in the data, the AR\\ndiffusion models captures such structure, whereas vanilla DDPM fails to do so.\\nOn the other hand, when there is no obvious conditional dependence across\\npatches of the data, AR diffusion does not outperform DDPM.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-30T04:57:12Z\"}"}
