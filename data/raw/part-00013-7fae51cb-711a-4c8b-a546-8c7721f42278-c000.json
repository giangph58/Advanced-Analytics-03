{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15674v1\", \"title\": \"TrojanDam: Detection-Free Backdoor Defense in Federated Learning through\\n  Proactive Model Robustification utilizing OOD Data\", \"summary\": \"Federated learning (FL) systems allow decentralized data-owning clients to\\njointly train a global model through uploading their locally trained updates to\\na centralized server. The property of decentralization enables adversaries to\\ncraft carefully designed backdoor updates to make the global model misclassify\\nonly when encountering adversary-chosen triggers. Existing defense mechanisms\\nmainly rely on post-training detection after receiving updates. These methods\\neither fail to identify updates which are deliberately fabricated statistically\\nclose to benign ones, or show inconsistent performance in different FL training\\nstages. The effect of unfiltered backdoor updates will accumulate in the global\\nmodel, and eventually become functional. Given the difficulty of ruling out\\nevery backdoor update, we propose a backdoor defense paradigm, which focuses on\\nproactive robustification on the global model against potential backdoor\\nattacks. We first reveal that the successful launching of backdoor attacks in\\nFL stems from the lack of conflict between malicious and benign updates on\\nredundant neurons of ML models. We proceed to prove the feasibility of\\nactivating redundant neurons utilizing out-of-distribution (OOD) samples in\\ncentralized settings, and migrating to FL settings to propose a novel backdoor\\ndefense mechanism, TrojanDam. The proposed mechanism has the FL server\\ncontinuously inject fresh OOD mappings into the global model to activate\\nredundant neurons, canceling the effect of backdoor updates during aggregation.\\nWe conduct systematic and extensive experiments to illustrate the superior\\nperformance of TrojanDam, over several SOTA backdoor defense methods across a\\nwide range of FL settings.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.LG\", \"published\": \"2025-04-22T07:56:51Z\"}"}
