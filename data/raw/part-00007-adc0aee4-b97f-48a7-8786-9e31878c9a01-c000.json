{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21330v1\", \"title\": \"Does the Prompt-based Large Language Model Recognize Students'\\n  Demographics and Introduce Bias in Essay Scoring?\", \"summary\": \"Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\\ndue to their ability to capture semantic meaning. Traditional fine-tuning\\napproaches required technical expertise, limiting accessibility for educators\\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\\nhave made AES more accessible, enabling educators to obtain machine-generated\\nscores using natural-language prompts (i.e., the prompt-based paradigm).\\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\\nparticularly against disadvantaged groups. It remains unclear whether such\\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\\ntools. Since such biases are believed to stem from the demographic information\\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\\npredict demographic attributes), this study explores the relationship between\\nthe model's predictive power of students' demographic attributes based on their\\nwritten works and its predictive bias in the scoring task in the prompt-based\\nparadigm. Using a publicly available dataset of over 25,000 students'\\nargumentative essays, we designed prompts to elicit demographic inferences\\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\\nautomated scoring. Then we conducted multivariate regression analysis to\\nexplore the impact of the model's ability to predict demographics on its\\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\\ninfer students' demographics, particularly their first-language backgrounds,\\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\\ncorrectly predicts students' first-language background than when it does not;\\nand (iii) scoring error for non-native English speakers increases when the LLM\\ncorrectly identifies them as non-native.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-30T05:36:28Z\"}"}
