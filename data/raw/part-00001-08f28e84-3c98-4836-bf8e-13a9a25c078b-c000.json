{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09960v1\", \"title\": \"Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness\\n  and Adaptive Temporal Modeling\", \"summary\": \"Event-based eye tracking has become a pivotal technology for augmented\\nreality and human-computer interaction. Yet, existing methods struggle with\\nreal-world challenges such as abrupt eye movements and environmental noise.\\nBuilding on the efficiency of the Lightweight Spatiotemporal Network-a causal\\narchitecture optimized for edge devices-we introduce two key advancements.\\nFirst, a robust data augmentation pipeline incorporating temporal shift,\\nspatial flip, and event deletion improves model resilience, reducing Euclidean\\ndistance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second,\\nwe propose KnightPupil, a hybrid architecture combining an EfficientNet-B3\\nbackbone for spatial feature extraction, a bidirectional GRU for contextual\\ntemporal modeling, and a Linear Time-Varying State-Space Module to adapt to\\nsparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, our\\nframework achieved 1.61 Euclidean distance on the private test set of the\\nEvent-based Eye Tracking Challenge at CVPR 2025, demonstrating its\\neffectiveness for practical deployment in AR/VR systems while providing a\\nfoundation for future innovations in neuromorphic vision.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T07:57:22Z\"}"}
