{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11427v1\", \"title\": \"NormalCrafter: Learning Temporally Consistent Normals from Video\\n  Diffusion Priors\", \"summary\": \"Surface normal estimation serves as a cornerstone for a spectrum of computer\\nvision applications. While numerous efforts have been devoted to static image\\nscenarios, ensuring temporal coherence in video-based normal estimation remains\\na formidable challenge. Instead of merely augmenting existing methods with\\ntemporal components, we present NormalCrafter to leverage the inherent temporal\\npriors of video diffusion models. To secure high-fidelity normal estimation\\nacross sequences, we propose Semantic Feature Regularization (SFR), which\\naligns diffusion features with semantic cues, encouraging the model to\\nconcentrate on the intrinsic semantics of the scene. Moreover, we introduce a\\ntwo-stage training protocol that leverages both latent and pixel space learning\\nto preserve spatial accuracy while maintaining long temporal context. Extensive\\nevaluations demonstrate the efficacy of our method, showcasing a superior\\nperformance in generating temporally consistent normal sequences with intricate\\ndetails from diverse videos.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T17:39:07Z\"}"}
