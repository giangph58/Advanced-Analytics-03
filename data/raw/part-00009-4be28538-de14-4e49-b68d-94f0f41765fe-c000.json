{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00382v1\", \"title\": \"Approximation to Deep Q-Network by Stochastic Delay Differential\\n  Equations\", \"summary\": \"Despite the significant breakthroughs that the Deep Q-Network (DQN) has\\nbrought to reinforcement learning, its theoretical analysis remains limited. In\\nthis paper, we construct a stochastic differential delay equation (SDDE) based\\non the DQN algorithm and estimate the Wasserstein-1 distance between them. We\\nprovide an upper bound for the distance and prove that the distance between the\\ntwo converges to zero as the step size approaches zero. This result allows us\\nto understand DQN's two key techniques, the experience replay and the target\\nnetwork, from the perspective of continuous systems. Specifically, the delay\\nterm in the equation, corresponding to the target network, contributes to the\\nstability of the system. Our approach leverages a refined Lindeberg principle\\nand an operator comparison to establish these results.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,math.PR\", \"published\": \"2025-05-01T08:19:24Z\"}"}
