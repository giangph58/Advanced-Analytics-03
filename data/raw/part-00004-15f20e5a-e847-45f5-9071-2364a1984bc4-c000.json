{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02792v1\", \"title\": \"Unified World Models: Coupling Video and Action Diffusion for\\n  Pretraining on Large Robotic Datasets\", \"summary\": \"Imitation learning has emerged as a promising approach towards building\\ngeneralist robots. However, scaling imitation learning for large robot\\nfoundation models remains challenging due to its reliance on high-quality\\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\\nrange of environments and diverse behaviors are readily available. This data\\nprovides a rich source of information about real-world dynamics and\\nagent-environment interactions. Leveraging this data directly for imitation\\nlearning, however, has proven difficult due to the lack of action annotation\\nrequired for most contemporary methods. In this work, we present Unified World\\nModels (UWM), a framework that allows for leveraging both video and action data\\nfor policy learning. Specifically, a UWM integrates an action diffusion process\\nand a video diffusion process within a unified transformer architecture, where\\nindependent diffusion timesteps govern each modality. We show that by simply\\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\\nand real-world experiments, we show that: (1) UWM enables effective pretraining\\non large-scale multitask robot datasets with both dynamics and action\\npredictions, resulting in more generalizable and robust policies than imitation\\nlearning, (2) UWM naturally facilitates learning from action-free video data\\nthrough independent control of modality-specific diffusion timesteps, further\\nimproving the performance of finetuned policies. Our results suggest that UWM\\noffers a promising step toward harnessing large, heterogeneous datasets for\\nscalable robot learning, and provides a simple unification between the often\\ndisparate paradigms of imitation learning and world modeling. Videos and code\\nare available at https://weirdlabuw.github.io/uwm/.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.LG\", \"published\": \"2025-04-03T17:38:59Z\"}"}
