{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06189v1\", \"title\": \"Accessible and Pedagogically-Grounded Explainability for Human-Robot\\n  Interaction: A Framework Based on UDL and Symbolic Interfaces\", \"summary\": \"This paper presents a novel framework for accessible and\\npedagogically-grounded robot explainability, designed to support human-robot\\ninteraction (HRI) with users who have diverse cognitive, communicative, or\\nlearning needs. We combine principles from Universal Design for Learning (UDL)\\nand Universal Design (UD) with symbolic communication strategies to facilitate\\nthe alignment of mental models between humans and robots. Our approach employs\\nAsterics Grid and ARASAAC pictograms as a multimodal, interpretable front-end,\\nintegrated with a lightweight HTTP-to-ROS 2 bridge that enables real-time\\ninteraction and explanation triggering. We emphasize that explainability is not\\na one-way function but a bidirectional process, where human understanding and\\nrobot transparency must co-evolve. We further argue that in educational or\\nassistive contexts, the role of a human mediator (e.g., a teacher) may be\\nessential to support shared understanding. We validate our framework with\\nexamples of multimodal explanation boards and discuss how it can be extended to\\ndifferent scenarios in education, assistive robotics, and inclusive AI.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.HC\", \"published\": \"2025-04-08T16:33:52Z\"}"}
