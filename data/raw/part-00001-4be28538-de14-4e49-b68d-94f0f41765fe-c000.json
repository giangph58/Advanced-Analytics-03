{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00374v1\", \"title\": \"Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise\\n  Separable Dilated Convolutional Network\", \"summary\": \"Deep neural networks have demonstrated highly competitive performance in\\nsuper-resolution (SR) for natural images by learning mappings from\\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\\nsuper-resolution remains an ill-posed problem due to the high spectral\\ndimensionality of the data and the scarcity of available training samples.\\nMoreover, existing methods often rely on large models with a high number of\\nparameters or require the fusion with panchromatic or RGB images, both of which\\nare often impractical in real-world scenarios. Inspired by the MobileNet\\narchitecture, we introduce a lightweight depthwise separable dilated\\nconvolutional network (DSDCN) to address the aforementioned challenges.\\nSpecifically, our model leverages multiple depthwise separable convolutions,\\nsimilar to the MobileNet architecture, and further incorporates a dilated\\nconvolution fusion block to make the model more flexible for the extraction of\\nboth spatial and spectral features. In addition, we propose a custom loss\\nfunction that combines mean squared error (MSE), an L2 norm\\nregularization-based constraint, and a spectral angle-based loss, ensuring the\\npreservation of both spectral and spatial details. The proposed model achieves\\nvery competitive performance on two publicly available hyperspectral datasets,\\nmaking it well-suited for hyperspectral image super-resolution tasks. The\\nsource codes are publicly available at:\\n\\\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-05-01T07:57:23Z\"}"}
