{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05180v1\", \"title\": \"OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world\\n  Prompt Tuning\", \"summary\": \"Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks\\nwith minimal training costs. In this direction, one typical paradigm evaluates\\nmodel performance separately on known classes (i.e., base domain) and unseen\\nclasses (i.e., new domain). However, real-world scenarios require models to\\nhandle inputs without prior domain knowledge. This practical challenge has\\nspurred the development of open-world prompt tuning, which demands a unified\\nevaluation of two stages: 1) detecting whether an input belongs to the base or\\nnew domain (P1), and 2) classifying the sample into its correct class (P2).\\nWhat's more, as domain distributions are generally unknown, a proper metric\\nshould be insensitive to varying base/new sample ratios (P3). However, we find\\nthat current metrics, including HM, overall accuracy, and AUROC, fail to\\nsatisfy these three properties simultaneously. To bridge this gap, we propose\\nOpenworldAUC, a unified metric that jointly assesses detection and\\nclassification through pairwise instance comparisons. To optimize OpenworldAUC\\neffectively, we introduce Gated Mixture-of-Prompts (GMoP), which employs\\ndomain-specific prompts and a gating mechanism to dynamically balance detection\\nand classification. Theoretical guarantees ensure generalization of GMoP under\\npractical conditions. Experiments on 15 benchmarks in open-world scenarios show\\nGMoP achieves SOTA performance on OpenworldAUC and other metrics. We release\\nthe code at https://github.com/huacong/OpenworldAUC\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-08T12:31:40Z\"}"}
