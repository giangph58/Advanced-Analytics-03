{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15876v1\", \"title\": \"Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement\\n  Learning for Strategic Confrontation\", \"summary\": \"In swarm robotics, confrontation scenarios, including strategic\\nconfrontations, require efficient decision-making that integrates discrete\\ncommands and continuous actions. Traditional task and motion planning methods\\nseparate decision-making into two layers, but their unidirectional structure\\nfails to capture the interdependence between these layers, limiting\\nadaptability in dynamic environments. Here, we propose a novel bidirectional\\napproach based on hierarchical reinforcement learning, enabling dynamic\\ninteraction between the layers. This method effectively maps commands to task\\nallocation and actions to path planning, while leveraging cross-training\\ntechniques to enhance learning across the hierarchical framework. Furthermore,\\nwe introduce a trajectory prediction model that bridges abstract task\\nrepresentations with actionable planning goals. In our experiments, it achieves\\nover 80\\\\% in confrontation win rate and under 0.01 seconds in decision time,\\noutperforming existing approaches. Demonstrations through large-scale tests and\\nreal-world robot experiments further emphasize the generalization capabilities\\nand practical applicability of our method.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI\", \"published\": \"2025-04-22T13:22:58Z\"}"}
