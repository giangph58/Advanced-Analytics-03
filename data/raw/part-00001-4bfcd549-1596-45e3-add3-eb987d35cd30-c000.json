{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21497v1\", \"title\": \"MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric\\n  Guidance\", \"summary\": \"In this paper, we propose a method for video face reenactment that integrates\\na 3D face parametric model into a latent diffusion framework, aiming to improve\\nshape consistency and motion control in existing video-based face generation\\napproaches. Our approach employs the FLAME (Faces Learned with an Articulated\\nModel and Expressions) model as the 3D face parametric representation,\\nproviding a unified framework for modeling face expressions and head pose. This\\nenables precise extraction of detailed face geometry and motion features from\\ndriving videos. Specifically, we enhance the latent diffusion model with rich\\n3D expression and detailed pose information by incorporating depth maps, normal\\nmaps, and rendering maps derived from FLAME sequences. A multi-layer face\\nmovements fusion module with integrated self-attention mechanisms is used to\\ncombine identity and motion latent features within the spatial domain. By\\nutilizing the 3D face parametric model as motion guidance, our method enables\\nparametric alignment of face identity between the reference image and the\\nmotion captured from the driving video. Experimental results on benchmark\\ndatasets show that our method excels at generating high-quality face animations\\nwith precise expression and head pose variation modeling. In addition, it\\ndemonstrates strong generalization performance on out-of-domain images. Code is\\npublicly available at https://github.com/weimengting/MagicPortrait.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T10:30:46Z\"}"}
