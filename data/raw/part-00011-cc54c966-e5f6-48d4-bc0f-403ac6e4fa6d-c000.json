{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17789v1\", \"title\": \"Token-Shuffle: Towards High-Resolution Image Generation with\\n  Autoregressive Models\", \"summary\": \"Autoregressive (AR) models, long dominant in language generation, are\\nincreasingly applied to image synthesis but are often considered less\\ncompetitive than Diffusion-based models. A primary limitation is the\\nsubstantial number of image tokens required for AR models, which constrains\\nboth training and inference efficiency, as well as image resolution. To address\\nthis, we present Token-Shuffle, a novel yet simple method that reduces the\\nnumber of image tokens in Transformer. Our key insight is the dimensional\\nredundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),\\nwhere low-dimensional visual codes from visual encoder are directly mapped to\\nhigh-dimensional language vocabularies. Leveraging this, we consider two key\\noperations: token-shuffle, which merges spatially local tokens along channel\\ndimension to decrease the input token number, and token-unshuffle, which\\nuntangles the inferred tokens after Transformer blocks to restore the spatial\\narrangement for output. Jointly training with textual prompts, our strategy\\nrequires no additional pretrained text-encoder and enables MLLMs to support\\nextremely high-resolution image synthesis in a unified next-token prediction\\nway while maintaining efficient training and inference. For the first time, we\\npush the boundary of AR text-to-image generation to a resolution of 2048x2048\\nwith gratifying generation performance. In GenAI-benchmark, our 2.7B model\\nachieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen\\nby 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human\\nevaluations also demonstrate our prominent image generation ability in terms of\\ntext-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle\\ncan serve as a foundational design for efficient high-resolution image\\ngeneration within MLLMs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T17:59:56Z\"}"}
