{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04935v1\", \"title\": \"RCCFormer: A Robust Crowd Counting Network Based on Transformer\", \"summary\": \"Crowd counting, which is a key computer vision task, has emerged as a\\nfundamental technology in crowd analysis and public safety management. However,\\nchallenges such as scale variations and complex backgrounds significantly\\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\\nspecifically designed for background suppression and scale awareness. The\\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\\nmeticulously integrates features extracted at diverse stages of the backbone\\narchitecture. It establishes a strong baseline capable of capturing intricate\\nand comprehensive feature representations, surpassing traditional baselines.\\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\\ncontextual information and local details through global self-attention and\\nlocal attention along with a learnable manner for efficient fusion. This\\nenhances the model's ability to focus on foreground regions while effectively\\nmitigating background noise interference. Additionally, we develop an Adaptive\\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\\nConvolution (IDConv) as its fundamental building block. This module dynamically\\nadapts to changes in head target shapes and scales, significantly improving the\\nnetwork's capability to accommodate large-scale variations. The effectiveness\\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\\nachieves excellent performance across all four datasets, showcasing\\nstate-of-the-art outcomes.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T11:19:05Z\"}"}
