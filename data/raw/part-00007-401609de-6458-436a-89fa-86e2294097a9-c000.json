{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10374v1\", \"title\": \"Ctrl-Z: Controlling AI Agents via Resampling\", \"summary\": \"Control evaluations measure whether monitoring and security protocols for AI\\nsystems prevent intentionally subversive AI models from causing harm. Our work\\npresents the first control evaluation performed in an agent environment. We\\nconstruct BashBench, a dataset of 257 challenging multi-step system\\nadministration tasks, and evaluate whether various safety measures can prevent\\nan adversarially constructed AI agent from covertly downloading and executing\\nmalicious code in this environment. This multi-step setting introduces new\\nattack and defense dynamics, which we investigate in order to design novel\\ncontrol protocols that prevent safety failures without hindering the ability of\\nnon-malicious agents to perform useful work. We introduce a class of control\\nprotocols called resample protocols that dynamically take additional samples of\\ncertain actions. We find these protocols significantly improve on existing\\ntechniques by selectively blocking the AI agent from executing suspicious code\\nand incriminating the agent by generating additional examples of dangerous\\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\\nbest protocol combines resampling with analysis of previous steps, reducing the\\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\\nnon-malicious agent.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-14T16:22:11Z\"}"}
