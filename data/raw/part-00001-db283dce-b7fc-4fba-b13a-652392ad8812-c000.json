{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04795v1\", \"title\": \"Embodied Perception for Test-time Grasping Detection Adaptation with\\n  Knowledge Infusion\", \"summary\": \"It has always been expected that a robot can be easily deployed to unknown\\nscenarios, accomplishing robotic grasping tasks without human intervention.\\nNevertheless, existing grasp detection approaches are typically off-body\\ntechniques and are realized by training various deep neural networks with\\nextensive annotated data support. {In this paper, we propose an embodied\\ntest-time adaptation framework for grasp detection that exploits the robot's\\nexploratory capabilities.} The framework aims to improve the generalization\\nperformance of grasping skills for robots in an unforeseen environment.\\nSpecifically, we introduce embodied assessment criteria based on the robot's\\nmanipulation capability to evaluate the quality of the grasp detection and\\nmaintain suitable samples. This process empowers the robots to actively explore\\nthe environment and continuously learn grasping skills, eliminating human\\nintervention. Besides, to improve the efficiency of robot exploration, we\\nconstruct a flexible knowledge base to provide context of initial optimal\\nviewpoints. Conditioned on the maintained samples, the grasp detection networks\\ncan be adapted in the test-time scene. When the robot confronts new objects, it\\nwill undergo the same adaptation procedure mentioned above to realize\\ncontinuous learning. Extensive experiments conducted on a real-world robot\\ndemonstrate the effectiveness and generalization of our proposed framework.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-07T07:39:15Z\"}"}
