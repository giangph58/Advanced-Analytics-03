{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17704v1\", \"title\": \"Safety in Large Reasoning Models: A Survey\", \"summary\": \"Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks\\nlike mathematics and coding, leveraging their advanced reasoning capabilities.\\nNevertheless, as these capabilities progress, significant concerns regarding\\ntheir vulnerabilities and safety have arisen, which can pose challenges to\\ntheir deployment and application in real-world settings. This paper presents a\\ncomprehensive survey of LRMs, meticulously exploring and summarizing the newly\\nemerged safety risks, attacks, and defense strategies. By organizing these\\nelements into a detailed taxonomy, this work aims to offer a clear and\\nstructured understanding of the current safety landscape of LRMs, facilitating\\nfuture research and development to enhance the security and reliability of\\nthese powerful models.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-24T16:11:01Z\"}"}
