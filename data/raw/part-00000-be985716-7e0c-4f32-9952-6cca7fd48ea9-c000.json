{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04397v1\", \"title\": \"Deep residual learning with product units\", \"summary\": \"We propose a deep product-unit residual neural network (PURe) that integrates\\nproduct units into residual blocks to improve the expressiveness and parameter\\nefficiency of deep convolutional networks. Unlike standard summation neurons,\\nproduct units enable multiplicative feature interactions, potentially offering\\na more powerful representation of complex patterns. PURe replaces conventional\\nconvolutional layers with 2D product units in the second layer of each residual\\nblock, eliminating nonlinear activation functions to preserve structural\\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\\nResNet152, while converging nearly five times faster and demonstrating strong\\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\\ncomparable to ResNet1001 but at less than half the model size. These results\\ndemonstrate that PURe achieves a favorable balance between accuracy,\\nefficiency, and robustness. Compared to traditional residual networks, PURe not\\nonly achieves competitive classification performance with faster convergence\\nand fewer parameters, but also demonstrates greater robustness to noise. Its\\neffectiveness across diverse datasets highlights the potential of\\nproduct-unit-based architectures for scalable and reliable deep learning in\\ncomputer vision.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-05-07T13:21:25Z\"}"}
