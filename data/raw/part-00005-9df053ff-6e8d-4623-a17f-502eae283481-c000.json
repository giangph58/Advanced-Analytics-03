{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03697v1\", \"title\": \"Fairness of Automatic Speech Recognition in Cleft Lip and Palate Speech\", \"summary\": \"Speech produced by individuals with cleft lip and palate (CLP) is often\\nhighly nasalized and breathy due to structural anomalies, causing shifts in\\nformant structure that affect automatic speech recognition (ASR) performance\\nand fairness. This study hypothesizes that publicly available ASR systems\\nexhibit reduced fairness for CLP speech and confirms this through experiments.\\nDespite formant disruptions, mild and moderate CLP speech retains some\\nspectro-temporal alignment with normal speech, motivating augmentation\\nstrategies to enhance fairness. The study systematically explores augmenting\\nCLP speech with normal speech across severity levels and evaluates its impact\\non ASR fairness. Three ASR models-GMM-HMM, Whisper, and XLS-R-were tested on\\nAIISH and NMCPC datasets. Results indicate that training with normal speech and\\ntesting on mixed data improves word error rate (WER). Notably, WER decreased\\nfrom $22.64\\\\%$ to $18.76\\\\%$ (GMM-HMM, AIISH) and $28.45\\\\%$ to $18.89\\\\%$\\n(Whisper, NMCPC). The superior performance of GMM-HMM on AIISH may be due to\\nits suitability for Kannada children's speech, a challenge for foundation\\nmodels like XLS-R and Whisper. To assess fairness, a fairness score was\\nintroduced, revealing improvements of $17.89\\\\%$ (AIISH) and $47.50\\\\%$ (NMCPC)\\nwith augmentation.\", \"main_category\": \"eess.AS\", \"categories\": \"eess.AS\", \"published\": \"2025-05-06T17:04:20Z\"}"}
