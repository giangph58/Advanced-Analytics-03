{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19578v1\", \"title\": \"LAMBench: A Benchmark for Large Atomic Models\", \"summary\": \"Large atomic models (LAMs) have undergone remarkable progress recently,\\nemerging as universal or fundamental representations of the potential energy\\nsurface defined by the first-principles calculations of atomic systems.\\nHowever, our understanding of the extent to which these models achieve true\\nuniversality, as well as their comparative performance across different models,\\nremains limited. This gap is largely due to the lack of comprehensive\\nbenchmarks capable of evaluating the effectiveness of LAMs as approximations to\\nthe universal potential energy surface. In this study, we introduce LAMBench, a\\nbenchmarking system designed to evaluate LAMs in terms of their\\ngeneralizability, adaptability, and applicability. These attributes are crucial\\nfor deploying LAMs as ready-to-use tools across a diverse array of scientific\\ndiscovery contexts. We benchmark eight state-of-the-art LAMs released prior to\\nApril 1, 2025, using LAMBench. Our findings reveal a significant gap between\\nthe current LAMs and the ideal universal potential energy surface. They also\\nhighlight the need for incorporating cross-domain training data, supporting\\nmulti-fidelity modeling, and ensuring the models' conservativeness and\\ndifferentiability. As a dynamic and extensible platform, LAMBench is intended\\nto continuously evolve, thereby facilitating the development of robust and\\ngeneralizable LAMs capable of significantly advancing scientific research. The\\nLAMBench code is open-sourced at https://github.com/deepmodeling/lambench, and\\nan interactive leaderboard is available at\\nhttps://www.aissquare.com/openlam?tab=Benchmark.\", \"main_category\": \"physics.comp-ph\", \"categories\": \"physics.comp-ph,cond-mat.mtrl-sci\", \"published\": \"2025-04-28T08:36:40Z\"}"}
