{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13078v1\", \"title\": \"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\\n  Try-Off\", \"summary\": \"Computer vision is transforming fashion through Virtual Try-On (VTON) and\\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\\ngarment using a target photo and a standardized garment image, while a more\\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\\nof another person wearing the garment. VTOFF, on the other hand, extracts\\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\\na diffusion-based VTOFF model. Built on a latent diffusion framework with\\nSigLIP image conditioning, it effectively captures garment properties like\\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-17T16:45:18Z\"}"}
