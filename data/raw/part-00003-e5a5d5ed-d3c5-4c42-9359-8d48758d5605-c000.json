{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14848v1\", \"title\": \"Object-Level Verbalized Confidence Calibration in Vision-Language Models\\n  via Semantic Perturbation\", \"summary\": \"Vision-language models (VLMs) excel in various multimodal tasks but\\nfrequently suffer from poor calibration, resulting in misalignment between\\ntheir verbalized confidence and response correctness. This miscalibration\\nundermines user trust, especially when models confidently provide incorrect or\\nfabricated information. In this work, we propose a novel Confidence Calibration\\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\\nverbalized confidence for VLMs in response to object-centric queries. We first\\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\\nregions to simulate visual uncertainty at different confidence levels,\\nestablishing an explicit mapping between visual ambiguity and confidence\\nlevels. We further enhance calibration through a two-stage training process\\ncombining supervised fine-tuning on the perturbed dataset with subsequent\\npreference optimization. Extensive experiments on popular benchmarks\\ndemonstrate that our method significantly improves the alignment between\\nverbalized confidence and response correctness while maintaining or enhancing\\noverall task performance. These results highlight the potential of semantic\\nperturbation as a practical tool for improving the reliability and\\ninterpretability of VLMs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-21T04:01:22Z\"}"}
