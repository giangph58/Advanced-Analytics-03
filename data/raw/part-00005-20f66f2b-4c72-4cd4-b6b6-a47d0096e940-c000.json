{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04732v1\", \"title\": \"Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with\\n  3D Object Detection\", \"summary\": \"3D semantic occupancy prediction aims to forecast detailed geometric and\\nsemantic information of the surrounding environment for autonomous vehicles\\n(AVs) using onboard surround-view cameras. Existing methods primarily focus on\\nintricate inner structure module designs to improve model performance, such as\\nefficient feature sampling and aggregation processes or intermediate feature\\nrepresentation formats. In this paper, we explore multitask learning by\\nintroducing an additional 3D supervision signal by incorporating an additional\\n3D object detection auxiliary branch. This extra 3D supervision signal enhances\\nthe model's overall performance by strengthening the capability of the\\nintermediate features to capture small dynamic objects in the scene, and these\\nsmall dynamic objects often include vulnerable road users, i.e. bicycles,\\nmotorcycles, and pedestrians, whose detection is crucial for ensuring driving\\nsafety in autonomous vehicles. Extensive experiments conducted on the nuScenes\\ndatasets, including challenging rainy and nighttime scenarios, showcase that\\nour approach attains state-of-the-art results, achieving an IoU score of 31.73%\\nand a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU).\\nThe code will be made available at:https://github.com/DanielMing123/Inverse++\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-04-07T05:08:22Z\"}"}
