{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20464v1\", \"title\": \"A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement\\n  Learning\", \"summary\": \"Graphical User Interface (GUI) agents, driven by Multi-modal Large Language\\nModels (MLLMs), have emerged as a promising paradigm for enabling intelligent\\ninteraction with digital systems. This paper provides a structured summary of\\nrecent advances in GUI agents, focusing on architectures enhanced by\\nReinforcement Learning (RL). We first formalize GUI agent tasks as Markov\\nDecision Processes and discuss typical execution environments and evaluation\\nmetrics. We then review the modular architecture of (M)LLM-based GUI agents,\\ncovering Perception, Planning, and Acting modules, and trace their evolution\\nthrough representative works. Furthermore, we categorize GUI agent training\\nmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and\\nRL-based approaches, highlighting the progression from simple prompt\\nengineering to dynamic policy learning via RL. Our summary illustrates how\\nrecent innovations in multimodal perception, decision reasoning, and adaptive\\naction generation have significantly improved the generalization and robustness\\nof GUI agents in complex real-world environments. We conclude by identifying\\nkey challenges and future directions for building more capable and reliable GUI\\nagents.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-29T06:55:15Z\"}"}
