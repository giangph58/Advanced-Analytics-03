{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10174v1\", \"title\": \"LLaVA-ReID: Selective Multi-image Questioner for Interactive Person\\n  Re-Identification\", \"summary\": \"Traditional text-based person ReID assumes that person descriptions from\\nwitnesses are complete and provided at once. However, in real-world scenarios,\\nsuch descriptions are often partial or vague. To address this limitation, we\\nintroduce a new task called interactive person re-identification (Inter-ReID).\\nInter-ReID is a dialogue-based retrieval task that iteratively refines initial\\ndescriptions through ongoing interactions with the witnesses. To facilitate the\\nstudy of this new task, we construct a dialogue dataset that incorporates\\nmultiple types of questions by decomposing fine-grained attributes of\\nindividuals. We further propose LLaVA-ReID, a question model that generates\\ntargeted questions based on visual and textual contexts to elicit additional\\ndetails about the target person. Leveraging a looking-forward strategy, we\\nprioritize the most informative questions as supervision during training.\\nExperimental results on both Inter-ReID and text-based ReID benchmarks\\ndemonstrate that LLaVA-ReID significantly outperforms baselines.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T12:26:31Z\"}"}
