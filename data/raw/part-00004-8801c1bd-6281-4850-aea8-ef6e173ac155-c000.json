{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12606v1\", \"title\": \"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for\\n  Robust Scene Graph Generation\", \"summary\": \"In this paper, we introduce a novel method named Robo-SGG, i.e.,\\nLayout-Oriented Normalization and Restitution for Robust Scene Graph\\nGeneration. Compared to the existing SGG setting, the robust scene graph\\ngeneration aims to perform inference on a diverse range of corrupted images,\\nwith the core challenge being the domain shift between the clean and corrupted\\nimages. Existing SGG methods suffer from degraded performance due to\\ncompromised visual features e.g., corruption interference or occlusions. To\\nobtain robust visual features, we exploit the layout information, which is\\ndomain-invariant, to enhance the efficacy of existing SGG methods on corrupted\\nimages. Specifically, we employ Instance Normalization(IN) to filter out the\\ndomain-specific feature and recover the unchangeable structural features, i.e.,\\nthe positional and semantic relationships among objects by the proposed\\nLayout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder\\n(LEE) that augments the existing object and predicate encoders within the SGG\\nframework, enriching the robust positional and semantic features of objects and\\npredicates. Note that our proposed Robo-SGG module is designed as a\\nplug-and-play component, which can be easily integrated into any baseline SGG\\nmodel. Extensive experiments demonstrate that by integrating the\\nstate-of-the-art method into our proposed Robo-SGG, we achieve relative\\nimprovements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet\\ntasks on the VG-C dataset, respectively, and achieve new state-of-the-art\\nperformance in corruption scene graph generation benchmark (VG-C and GQA-C). We\\nwill release our source code and model.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-17T03:09:22Z\"}"}
