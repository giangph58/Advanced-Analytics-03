{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00410v1\", \"title\": \"Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A\\n  Comparative Study of ML and Explainability Analysis\", \"summary\": \"The present research tackles the difficulty of predicting osteoporosis risk\\nvia machine learning (ML) approaches, emphasizing the use of explainable\\nartificial intelligence (XAI) to improve model transparency. Osteoporosis is a\\nsignificant public health concern, sometimes remaining untreated owing to its\\nasymptomatic characteristics, and early identification is essential to avert\\nfractures. The research assesses six machine learning classifiers: Random\\nForest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting\\nand utilizes a dataset based on clinical, demographic, and lifestyle variables.\\nThe models are refined using GridSearchCV to calibrate hyperparameters, with\\nthe objective of enhancing predictive efficacy. XGBoost had the greatest\\naccuracy (91%) among the evaluated models, surpassing others in precision\\n(0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI\\napproaches, such as SHAP, LIME, and Permutation Feature Importance, to\\nelucidate the decision-making process of the optimal model. The study indicates\\nthat age is the primary determinant in forecasting osteoporosis risk, followed\\nby hormonal alterations and familial history. These results corroborate\\nclinical knowledge and affirm the models' therapeutic significance. The\\nresearch underscores the significance of explainability in machine learning\\nmodels for healthcare applications, guaranteeing that physicians can rely on\\nthe system's predictions. The report ultimately proposes directions for further\\nresearch, such as validation across varied populations and the integration of\\nsupplementary biomarkers for enhanced predictive accuracy.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-01T09:05:02Z\"}"}
