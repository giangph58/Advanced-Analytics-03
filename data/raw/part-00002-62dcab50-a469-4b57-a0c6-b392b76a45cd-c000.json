{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12806v1\", \"title\": \"A Numerical Gradient Inversion Attack in Variational Quantum\\n  Neural-Networks\", \"summary\": \"The loss landscape of Variational Quantum Neural Networks (VQNNs) is\\ncharacterized by local minima that grow exponentially with increasing qubits.\\nBecause of this, it is more challenging to recover information from model\\ngradients during training compared to classical Neural Networks (NNs). In this\\npaper we present a numerical scheme that successfully reconstructs input\\ntraining, real-world, practical data from trainable VQNNs' gradients. Our\\nscheme is based on gradient inversion that works by combining gradients\\nestimation with the finite difference method and adaptive low-pass filtering.\\nThe scheme is further optimized with Kalman filter to obtain efficient\\nconvergence. Our experiments show that our algorithm can invert even\\nbatch-trained data, given the VQNN model is sufficiently over-parameterized.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CR\", \"published\": \"2025-04-17T10:12:38Z\"}"}
