{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23869v1\", \"title\": \"Communication-Efficient and Personalized Federated Foundation Model\\n  Fine-Tuning via Tri-Matrix Adaptation\", \"summary\": \"In federated learning, fine-tuning pre-trained foundation models poses\\nsignificant challenges, particularly regarding high communication cost and\\nsuboptimal model performance due to data heterogeneity between the clients. To\\naddress these issues, this paper introduces communication-efficient federated\\nLoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rank\\nadaptation approach with personalized model parameter aggregation. We first\\npresents a novel LoRA parameter factorization by introducing a small-size dense\\nmatrix, which can significantly reduce the communication cost and achieve\\ncomparable empirical performance than transferring the low-rank parameter\\nmatrix used by existing methods. Without violating data privacy, the server\\nconsiders the client similarity in both training dataset and model parameter\\nspace, and learns personalized weights for model aggregation. Our experiments\\non various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not only\\nsignificantly reduces communication overhead but also improves performance\\nunder not independently and identically distributed data conditions. In\\naddition, CE-LoRA improves data privacy protection, effectively mitigating\\ngradient-based data reconstruction attacks.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-03-31T09:18:42Z\"}"}
