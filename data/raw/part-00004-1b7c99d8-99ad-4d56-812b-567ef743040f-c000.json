{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11190v1\", \"title\": \"Enhancing multimodal analogical reasoning with Logic Augmented\\n  Generation\", \"summary\": \"Recent advances in Large Language Models have demonstrated their capabilities\\nacross a variety of tasks. However, automatically extracting implicit knowledge\\nfrom natural language remains a significant challenge, as machines lack active\\nexperience with the physical world. Given this scenario, semantic knowledge\\ngraphs can serve as conceptual spaces that guide the automated text generation\\nreasoning process to achieve more efficient and explainable results. In this\\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\\nexplicit representation of a text through a semantic knowledge graph and\\napplies it in combination with prompt heuristics to elicit implicit analogical\\nconnections. This method generates extended knowledge graph triples\\nrepresenting implicit meaning, enabling systems to reason on unlabeled\\nmultimodal data regardless of the domain. We validate our work through three\\nmetaphor detection and understanding tasks across four datasets, as they\\nrequire deep analogical reasoning capabilities. The results show that this\\nintegrated approach surpasses current baselines, performs better than humans in\\nunderstanding visual metaphors, and enables more explainable reasoning\\nprocesses, though still has inherent limitations in metaphor understanding,\\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\\nerror analysis, discussing issues with metaphorical annotations and current\\nevaluation methods.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL\", \"published\": \"2025-04-15T13:47:55Z\"}"}
