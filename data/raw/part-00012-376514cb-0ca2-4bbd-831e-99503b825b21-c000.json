{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15665v1\", \"title\": \"Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for\\n  Infrared Dim and Small Target Detection\", \"summary\": \"Infrared dim and small target detection presents a significant challenge due\\nto dynamic multi-frame scenarios and weak target signatures in the infrared\\nmodality. Traditional low-rank plus sparse models often fail to capture dynamic\\nbackgrounds and global spatial-temporal correlations, which results in\\nbackground leakage or target loss. In this paper, we propose a novel\\nmotion-enhanced nonlocal similarity implicit neural representation (INR)\\nframework to address these challenges. We first integrate motion estimation via\\noptical flow to capture subtle target movements, and propose multi-frame fusion\\nto enhance motion saliency. Second, we leverage nonlocal similarity to\\nconstruct patch tensors with strong low-rank properties, and propose an\\ninnovative tensor decomposition-based INR model to represent the nonlocal patch\\ntensor, effectively encoding both the nonlocal low-rankness and\\nspatial-temporal correlations of background through continuous neural\\nrepresentations. An alternating direction method of multipliers is developed\\nfor the nonlocal INR model, which enjoys theoretical fixed-point convergence.\\nExperimental results show that our approach robustly separates dim targets from\\ncomplex infrared backgrounds, outperforming state-of-the-art methods in\\ndetection accuracy and robustness.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-22T07:42:00Z\"}"}
