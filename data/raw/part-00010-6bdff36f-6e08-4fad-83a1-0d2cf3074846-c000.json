{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21681v1\", \"title\": \"Investigating the Effect of Parallel Data in the Cross-Lingual Transfer\\n  for Vision-Language Encoders\", \"summary\": \"Most pre-trained Vision-Language (VL) models and training data for the\\ndownstream tasks are only available in English. Therefore, multilingual VL\\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\\npre-trained model or transfer the text encoder using parallel data. We study\\nthe alternative approach: transferring an already trained encoder using\\nparallel data. We investigate the effect of parallel data: domain and the\\nnumber of languages, which were out of focus in previous work. Our results show\\nthat even machine-translated task data are the best on average, caption-like\\nauthentic parallel data outperformed it in some languages. Further, we show\\nthat most languages benefit from multilingual training.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-30T14:19:15Z\"}"}
