{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05155v1\", \"title\": \"FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data\\n  Preparation via Federated Learning\", \"summary\": \"Trajectory data, which capture the movement patterns of people and vehicles\\nover time and space, are crucial for applications like traffic optimization and\\nurban planning. However, issues such as noise and incompleteness often\\ncompromise data quality, leading to inaccurate trajectory analyses and limiting\\nthe potential of these applications. While Trajectory Data Preparation (TDP)\\ncan enhance data quality, existing methods suffer from two key limitations: (i)\\nthey do not address data privacy concerns, particularly in federated settings\\nwhere trajectory data sharing is prohibited, and (ii) they typically design\\ntask-specific models that lack generalizability across diverse TDP scenarios.\\nTo overcome these challenges, we propose FedTDP, a privacy-preserving and\\nunified framework that leverages the capabilities of Large Language Models\\n(LLMs) for TDP in federated environments. Specifically, we: (i) design a\\ntrajectory privacy autoencoder to secure data transmission and protect privacy,\\n(ii) introduce a trajectory knowledge enhancer to improve model learning of\\nTDP-related knowledge, enabling the development of TDP-oriented LLMs, and (iii)\\npropose federated parallel optimization to enhance training efficiency by\\nreducing data transmission and enabling parallel model training. Experiments on\\n6 real datasets and 10 mainstream TDP tasks demonstrate that FedTDP\\nconsistently outperforms 13 state-of-the-art baselines.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CR\", \"published\": \"2025-05-08T11:51:23Z\"}"}
