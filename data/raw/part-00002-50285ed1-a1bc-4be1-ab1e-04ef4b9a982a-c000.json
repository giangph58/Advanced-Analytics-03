{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11441v1\", \"title\": \"TADACap: Time-series Adaptive Domain-Aware Captioning\", \"summary\": \"While image captioning has gained significant attention, the potential of\\ncaptioning time-series images, prevalent in areas like finance and healthcare,\\nremains largely untapped. Existing time-series captioning methods typically\\noffer generic, domain-agnostic descriptions of time-series shapes and struggle\\nto adapt to new domains without substantial retraining. To address these\\nlimitations, we introduce TADACap, a retrieval-based framework to generate\\ndomain-aware captions for time-series images, capable of adapting to new\\ndomains without retraining. Building on TADACap, we propose a novel retrieval\\nstrategy that retrieves diverse image-caption pairs from a target domain\\ndatabase, namely TADACap-diverse. We benchmarked TADACap-diverse against\\nstate-of-the-art methods and ablation variants. TADACap-diverse demonstrates\\ncomparable semantic accuracy while requiring significantly less annotation\\neffort.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL\", \"published\": \"2025-04-15T17:54:59Z\"}"}
