{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21370v1\", \"title\": \"ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length\\n  for Efficient Reasoning\", \"summary\": \"Reasoning models such as OpenAI o3 and DeepSeek-R1 have demonstrated strong\\nperformance on reasoning-intensive tasks through extended Chain-of-Thought\\n(CoT) prompting. While longer reasoning traces can facilitate a more thorough\\nexploration of solution paths for complex problems, researchers have observed\\nthat these models often \\\"overthink\\\", leading to inefficient inference. In this\\npaper, we introduce ShorterBetter, a simple yet effective reinforcement\\nlearning methed that enables reasoning language models to discover their own\\noptimal CoT lengths without human intervention. By sampling multiple outputs\\nper problem and defining the Sample Optimal Length (SOL) as the shortest\\ncorrect response among all the outputs, our method dynamically guides the model\\ntoward optimal inference lengths. Applied to the DeepSeek-Distill-Qwen-1.5B\\nmodel, ShorterBetter achieves up to an 80% reduction in output length on both\\nin-domain and out-of-domain reasoning tasks while maintaining accuracy. Our\\nanalysis shows that overly long reasoning traces often reflect loss of\\nreasoning direction, and thus suggests that the extended CoT produced by\\nreasoning models is highly compressible.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-30T07:04:19Z\"}"}
