{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20387v1\", \"title\": \"DEER: Deep Runahead for Instruction Prefetching on Modern Mobile\\n  Workloads\", \"summary\": \"Mobile workloads incur heavy frontend stalls due to increasingly large code\\nfootprints as well as long repeat cycles. Existing instruction-prefetching\\ntechniques suffer from low coverage, poor timeliness, or high cost. We provide\\na SW/HW co-designed I-prefetcher; DEER uses profile analysis to extract\\nmetadata information that allow the hardware to prefetch the most likely future\\ninstruction cachelines, hundreds of instructions earlier. This profile analysis\\nskips over loops and recursions to go deeper into the future, and uses a\\nreturn-address stack on the hardware side to allow prefetch on the return-path\\nfrom large call-stacks. The produced metadata table is put in DRAM, pointed to\\nby an in-hardware register; the high depth of the lookahead allows to preload\\nthe metadata in time and thus nearly no on-chip metadata storage is needed.\\nGem5 evaluation on real-world modern mobile workloads shows up to 45% reduction\\nin L2 instruction-miss rate (19.6% on average), resulting in up to 8% speedup\\n(4.7% on average). These gains are up to 4X larger than full-hardware\\nrecord-and-replay prefetchers, while needing two orders of magnitude smaller\\non-chip storage.\", \"main_category\": \"cs.PF\", \"categories\": \"cs.PF,cs.AR\", \"published\": \"2025-04-29T03:15:17Z\"}"}
