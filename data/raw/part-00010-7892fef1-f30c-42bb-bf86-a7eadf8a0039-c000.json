{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01428v1\", \"title\": \"MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation\", \"summary\": \"Optical coherence tomography angiography (OCTA) shows its great importance in\\nimaging microvascular networks by providing accurate 3D imaging of blood\\nvessels, but it relies upon specialized sensors and expensive devices. For this\\nreason, previous works show the potential to translate the readily available 3D\\nOptical Coherence Tomography (OCT) images into 3D OCTA images. However,\\nexisting OCTA translation methods directly learn the mapping from the OCT\\ndomain to the OCTA domain in continuous and infinite space with guidance from\\nonly a single view, i.e., the OCTA project map, resulting in suboptimal\\nresults. To this end, we propose the multi-view Tri-alignment framework for OCT\\nto OCTA 3D image translation in discrete and finite space, named MuTri. In the\\nfirst stage, we pre-train two vector-quantized variational auto-encoder (VQ-\\nVAE) by reconstructing 3D OCT and 3D OCTA data, providing semantic prior for\\nsubsequent multi-view guidances. In the second stage, our multi-view\\ntri-alignment facilitates another VQVAE model to learn the mapping from the OCT\\ndomain to the OCTA domain in discrete and finite space. Specifically, a\\ncontrastive-inspired semantic alignment is proposed to maximize the mutual\\ninformation with the pre-trained models from OCT and OCTA views, to facilitate\\ncodebook learning. Meanwhile, a vessel structure alignment is proposed to\\nminimize the structure discrepancy with the pre-trained models from the OCTA\\nproject map view, benefiting from learning the detailed vessel structure\\ninformation. We also collect the first large-scale dataset, namely, OCTA2024,\\nwhich contains a pair of OCT and OCTA volumes from 846 subjects.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-02T07:28:09Z\"}"}
