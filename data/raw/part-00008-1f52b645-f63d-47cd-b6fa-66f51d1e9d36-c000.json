{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04416v1\", \"title\": \"OBLIVIATE: Robust and Practical Machine Unlearning for Large Language\\n  Models\", \"summary\": \"Large language models (LLMs) trained over extensive corpora risk memorizing\\nsensitive, copyrighted, or toxic content. To address this, we propose\\nOBLIVIATE, a robust unlearning framework that removes targeted data while\\npreserving model utility. The framework follows a structured process:\\nextracting target tokens, building retain sets, and fine-tuning with a tailored\\nloss function comprising three components -- masking, distillation, and world\\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\\ncompromising unlearning quality. We conduct experiments on multiple datasets,\\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\\nof metrics: forget quality (new document-level memorization score), model\\nutility, and fluency. Results demonstrate its effectiveness in resisting\\nmembership inference attacks, minimizing the impact on retained data, and\\nmaintaining robustness across diverse scenarios.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.CR,cs.LG\", \"published\": \"2025-05-07T13:51:42Z\"}"}
