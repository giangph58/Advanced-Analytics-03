{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14891v1\", \"title\": \"Retrieval Augmented Generation Evaluation in the Era of Large Language\\n  Models: A Comprehensive Survey\", \"summary\": \"Recent advancements in Retrieval-Augmented Generation (RAG) have\\nrevolutionized natural language processing by integrating Large Language Models\\n(LLMs) with external information retrieval, enabling accurate, up-to-date, and\\nverifiable text generation across diverse applications. However, evaluating RAG\\nsystems presents unique challenges due to their hybrid architecture that\\ncombines retrieval and generation components, as well as their dependence on\\ndynamic knowledge sources in the LLM era. In response, this paper provides a\\ncomprehensive survey of RAG evaluation methods and frameworks, systematically\\nreviewing traditional and emerging evaluation approaches, for system\\nperformance, factual accuracy, safety, and computational efficiency in the LLM\\nera. We also compile and categorize the RAG-specific datasets and evaluation\\nframeworks, conducting a meta-analysis of evaluation practices in high-impact\\nRAG research. To the best of our knowledge, this work represents the most\\ncomprehensive survey for RAG evaluation, bridging traditional and LLM-driven\\nmethods, and serves as a critical resource for advancing RAG development.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-21T06:39:47Z\"}"}
