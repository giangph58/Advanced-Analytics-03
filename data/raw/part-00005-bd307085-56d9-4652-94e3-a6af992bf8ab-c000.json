{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14933v1\", \"title\": \"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion\\n  Models\", \"summary\": \"In today's age of social media and marketing, copyright issues can be a major\\nroadblock to the free sharing of images. Generative AI models have made it\\npossible to create high-quality images, but concerns about copyright\\ninfringement are a hindrance to their abundant use. As these models use data\\nfrom training images to generate new ones, it is often a daunting task to\\nensure they do not violate intellectual property rights. Some AI models have\\neven been noted to directly copy copyrighted images, a problem often referred\\nto as source copying. Traditional copyright protection measures such as\\nwatermarks and metadata have also proven to be futile in this regard. To\\naddress this issue, we propose a novel two-step image generation model inspired\\nby the conditional diffusion model. The first step involves creating an image\\nsegmentation mask for some prompt-based generated images. This mask embodies\\nthe shape of the image. Thereafter, the diffusion model is asked to generate\\nthe image anew while avoiding the shape in question. This approach shows a\\ndecrease in structural similarity from the training image, i.e. we are able to\\navoid the source copying problem using this approach without expensive\\nretraining of the model or user-centered prompt generation techniques. This\\nmakes our approach the most computationally inexpensive approach to avoiding\\nboth copyright infringement and source copying for diffusion model-based image\\ngeneration.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T07:53:58Z\"}"}
