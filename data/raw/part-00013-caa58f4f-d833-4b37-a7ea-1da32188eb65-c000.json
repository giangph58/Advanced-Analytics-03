{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02606v1\", \"title\": \"Improving Counterfactual Truthfulness for Molecular Property Prediction\\n  through Uncertainty Quantification\", \"summary\": \"Explainable AI (xAI) interventions aim to improve interpretability for\\ncomplex black-box models, not only to improve user trust but also as a means to\\nextract scientific insights from high-performing predictive systems. In\\nmolecular property prediction, counterfactual explanations offer a way to\\nunderstand predictive behavior by highlighting which minimal perturbations in\\nthe input molecular structure cause the greatest deviation in the predicted\\nproperty. However, such explanations only allow for meaningful scientific\\ninsights if they reflect the distribution of the true underlying property -- a\\nfeature we define as counterfactual truthfulness. To increase this\\ntruthfulness, we propose the integration of uncertainty estimation techniques\\nto filter counterfactual candidates with high predicted uncertainty. Through\\ncomputational experiments with synthetic and real-world datasets, we\\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\\nand mean-variance estimation, can already substantially reduce the average\\nprediction error and increase counterfactual truthfulness, especially for\\nout-of-distribution settings. Our results highlight the importance and\\npotential impact of incorporating uncertainty estimation into explainability\\nmethods, especially considering the relatively high effectiveness of low-effort\\ninterventions like model ensembles.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-03T14:07:30Z\"}"}
