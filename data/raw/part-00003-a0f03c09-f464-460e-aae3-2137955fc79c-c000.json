{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15615v1\", \"title\": \"Dimension-Free Decision Calibration for Nonlinear Loss Functions\", \"summary\": \"When model predictions inform downstream decision making, a natural question\\nis under what conditions can the decision-makers simply respond to the\\npredictions as if they were the true outcomes. Calibration suffices to\\nguarantee that simple best-response to predictions is optimal. However,\\ncalibration for high-dimensional prediction outcome spaces requires exponential\\ncomputational and statistical complexity. The recent relaxation known as\\ndecision calibration ensures the optimality of the simple best-response rule\\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\\nHowever, known results on calibration and decision calibration crucially rely\\non linear loss functions for establishing best-response optimality. A natural\\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\\n$\\\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\\n$\\\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\\nexponentially large or infinite feature dimensions $m$. A key open problem is\\nwhether it is possible to achieve decision calibration with sample complexity\\nindependent of~$m$. We begin with a negative result: even verifying decision\\ncalibration under standard deterministic best response inherently requires\\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\\ninvestigate a smooth version of decision calibration in which decision-makers\\nfollow a smooth best-response. This smooth relaxation enables dimension-free\\ndecision calibration algorithms. We introduce algorithms that, given\\n$\\\\mathrm{poly}(|A|,1/\\\\epsilon)$ samples and any initial predictor~$p$, can\\nefficiently post-process it to satisfy decision calibration without worsening\\naccuracy. Our algorithms apply broadly to function classes that can be\\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\\nseparable RKHS.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-22T06:14:23Z\"}"}
