{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02302v1\", \"title\": \"Causal Self-supervised Pretrained Frontend with Predictive Code for\\n  Speech Separation\", \"summary\": \"Speech separation (SS) seeks to disentangle a multi-talker speech mixture\\ninto single-talker speech streams. Although SS can be generally achieved using\\noffline methods, such a processing paradigm is not suitable for real-time\\nstreaming applications. Causal separation models, which rely only on past and\\npresent information, offer a promising solution for real-time streaming.\\nHowever, these models typically suffer from notable performance degradation due\\nto the absence of future context. In this paper, we introduce a novel frontend\\nthat is designed to mitigate the mismatch between training and run-time\\ninference by implicitly incorporating future information into causal models\\nthrough predictive patterns. The pretrained frontend employs a transformer\\ndecoder network with a causal convolutional encoder as the backbone and is\\npretrained in a self-supervised manner with two innovative pretext tasks:\\nautoregressive hybrid prediction and contextual knowledge distillation. These\\ntasks enable the model to capture predictive patterns directly from mixtures in\\na self-supervised manner. The pretrained frontend subsequently serves as a\\nfeature extractor to generate high-quality predictive patterns. Comprehensive\\nevaluations on synthetic and real-world datasets validated the effectiveness of\\nthe proposed pretrained frontend.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.LG,eess.AS\", \"published\": \"2025-04-03T06:18:30Z\"}"}
