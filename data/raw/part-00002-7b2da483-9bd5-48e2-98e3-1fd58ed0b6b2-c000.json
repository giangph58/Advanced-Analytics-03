{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02654v1\", \"title\": \"SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based\\n  Reinforcement Learning\", \"summary\": \"We propose a learning architecture that allows symbolic control and guidance\\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\\nnovel modular approach that augments the existing Dueling Deep Q-Networks\\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\\nallow reinforcement learning agents to display behaviour consistent with\\nreasoning about the environment. Our experiment is an ablation study performed\\non the modules. It is conducted in a reinforcement learning environment of a\\n5x5 grid navigated by an agent that encounters various shapes, each associated\\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\\nbehaviour of the agent in this environment, while the modules facilitate shape\\nrecognition and reward prediction. We show that our architecture significantly\\nimproves learning, both in terms of performance and the precision of the agent.\\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\\nof combining neural and symbolic approaches in reinforcement learning.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.LO,cs.NE,I.2.6\", \"published\": \"2025-04-03T14:51:11Z\"}"}
