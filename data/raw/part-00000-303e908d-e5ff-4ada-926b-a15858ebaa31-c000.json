{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12914v1\", \"title\": \"In Which Areas of Technical AI Safety Could Geopolitical Rivals\\n  Cooperate?\", \"summary\": \"International cooperation is common in AI research, including between\\ngeopolitical rivals. While many experts advocate for greater international\\ncooperation on AI safety to address shared global risks, some view cooperation\\non AI with suspicion, arguing that it can pose unacceptable risks to national\\nsecurity. However, the extent to which cooperation on AI safety poses such\\nrisks, as well as provides benefits, depends on the specific area of\\ncooperation. In this paper, we consider technical factors that impact the risks\\nof international cooperation on AI safety research, focusing on the degree to\\nwhich such cooperation can advance dangerous capabilities, result in the\\nsharing of sensitive information, or provide opportunities for harm. We begin\\nby why nations historically cooperate on strategic technologies and analyse\\ncurrent US-China cooperation in AI as a case study. We further argue that\\nexisting frameworks for managing associated risks can be supplemented with\\nconsideration of key risks specific to cooperation on technical AI safety\\nresearch. Through our analysis, we find that research into AI verification\\nmechanisms and shared protocols may be suitable areas for such cooperation.\\nThrough this analysis we aim to help researchers and governments identify and\\nmitigate the risks of international cooperation on AI safety research, so that\\nthe benefits of cooperation can be fully realised.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY\", \"published\": \"2025-04-17T13:03:56Z\"}"}
