{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23679v1\", \"title\": \"The Devil is in the Distributions: Explicit Modeling of Scene Content is\\n  Key in Zero-Shot Video Captioning\", \"summary\": \"Zero-shot video captioning requires that a model generate high-quality\\ncaptions without human-annotated video-text pairs for training.\\nState-of-the-art approaches to the problem leverage CLIP to extract\\nvisual-relevant textual prompts to guide language models in generating\\ncaptions. These methods tend to focus on one key aspect of the scene and build\\na caption that ignores the rest of the visual input. To address this issue, and\\ngenerate more accurate and complete captions, we propose a novel progressive\\nmulti-granularity textual prompting strategy for zero-shot video captioning.\\nOur approach constructs three distinct memory banks, encompassing noun phrases,\\nscene graphs of noun phrases, and entire sentences. Moreover, we introduce a\\ncategory-aware retrieval mechanism that models the distribution of natural\\nlanguage surrounding the specific topics in question. Extensive experiments\\ndemonstrate the effectiveness of our method with 5.7%, 16.2%, and 3.4%\\nimprovements in terms of the main metric CIDEr on MSR-VTT, MSVD, and VATEX\\nbenchmarks compared to existing state-of-the-art.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T03:00:19Z\"}"}
