{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16855v1\", \"title\": \"Monte Carlo Planning with Large Language Model for Text-Based Game\\n  Agents\", \"summary\": \"Text-based games provide valuable environments for language-based autonomous\\nagents. However, planning-then-learning paradigms, such as those combining\\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\\ntime-consuming due to extensive iterations. Additionally, these algorithms\\nperform uncertainty-driven exploration but lack language understanding and\\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\\nthe language understanding and reasoning capabilities of Large Language Models\\n(LLMs) alongside the exploratory advantages of tree search algorithms.\\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\\nenabling them to learn from past experiences and dynamically adjust action\\nevaluations during planning. We conduct experiments on a series of text-based\\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\\nalgorithm significantly enhances performance across various games at the\\ninitial planning phase, outperforming strong contemporary methods that require\\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\\npaving the way for more efficient language-grounded planning in complex\\nenvironments.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-23T16:23:15Z\"}"}
