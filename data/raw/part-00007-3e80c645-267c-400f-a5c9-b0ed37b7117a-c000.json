{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09956v1\", \"title\": \"Semantic Depth Matters: Explaining Errors of Deep Vision Networks\\n  through Perceived Class Similarities\", \"summary\": \"Understanding deep neural network (DNN) behavior requires more than\\nevaluating classification accuracy alone; analyzing errors and their\\npredictability is equally crucial. Current evaluation methodologies lack\\ntransparency, particularly in explaining the underlying causes of network\\nmisclassifications. To address this, we introduce a novel framework that\\ninvestigates the relationship between the semantic hierarchy depth perceived by\\na network and its real-data misclassification patterns. Central to our\\nframework is the Similarity Depth (SD) metric, which quantifies the semantic\\nhierarchy depth perceived by a network along with a method of evaluation of how\\nclosely the network's errors align with its internally perceived similarity\\nstructure. We also propose a graph-based visualization of model semantic\\nrelationships and misperceptions. A key advantage of our approach is that\\nleveraging class templates -- representations derived from classifier layer\\nweights -- is applicable to already trained networks without requiring\\nadditional data or experiments. Our approach reveals that deep vision networks\\nencode specific semantic hierarchies and that high semantic depth improves the\\ncompliance between perceived class similarities and actual errors.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG,I.2.6\", \"published\": \"2025-04-14T07:44:34Z\"}"}
