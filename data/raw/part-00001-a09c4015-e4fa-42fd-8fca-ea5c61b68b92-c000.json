{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03179v1\", \"title\": \"Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for\\n  Cybersecurity\", \"summary\": \"This study investigates whether large language models (LLMs) can function as\\nintelligent collaborators to bridge expertise gaps in cybersecurity\\ndecision-making. We examine two representative tasks-phishing email detection\\nand intrusion detection-that differ in data modality, cognitive complexity, and\\nuser familiarity. Through a controlled mixed-methods user study, n = 58\\n(phishing, n = 34; intrusion, n = 24), we find that human-AI collaboration\\nimproves task performance,reducing false positives in phishing detection and\\nfalse negatives in intrusion detection. A learning effect is also observed when\\nparticipants transition from collaboration to independent work, suggesting that\\nLLMs can support long-term skill development. Our qualitative analysis shows\\nthat interaction dynamics-such as LLM definitiveness, explanation style, and\\ntone-influence user trust, prompting strategies, and decision revision. Users\\nengaged in more analytic questioning and showed greater reliance on LLM\\nfeedback in high-complexity settings. These results provide design guidance for\\nbuilding interpretable, adaptive, and trustworthy human-AI teaming systems, and\\ndemonstrate that LLMs can meaningfully support non-experts in reasoning through\\ncomplex cybersecurity problems.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-05-06T04:47:52Z\"}"}
