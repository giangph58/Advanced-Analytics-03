{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11434v1\", \"title\": \"Enhancing Out-of-Distribution Detection with Extended Logit\\n  Normalization\", \"summary\": \"Out-of-distribution (OOD) detection is essential for the safe deployment of\\nmachine learning models. Recent advances have explored improved classification\\nlosses and representation learning strategies to enhance OOD detection.\\nHowever, these methods are often tailored to specific post-hoc detection\\ntechniques, limiting their generalizability. In this work, we identify a\\ncritical issue in Logit Normalization (LogitNorm), which inhibits its\\neffectiveness in improving certain post-hoc OOD detection methods. To address\\nthis, we propose Extended Logit Normalization ($\\\\textbf{ELogitNorm}$), a novel\\nhyperparameter-free formulation that significantly benefits a wide range of\\npost-hoc detection methods. By incorporating feature distance-awareness to\\nLogitNorm, $\\\\textbf{ELogitNorm}$ shows more robust OOD separability and\\nin-distribution (ID) confidence calibration than its predecessor. Extensive\\nexperiments across standard benchmarks demonstrate that our approach\\noutperforms state-of-the-art training-time methods in OOD detection while\\nmaintaining strong ID classification accuracy.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T17:51:35Z\"}"}
