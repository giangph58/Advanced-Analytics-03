{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16682v1\", \"title\": \"Provable wavelet-based neural approximation\", \"summary\": \"In this paper, we develop a wavelet-based theoretical framework for analyzing\\nthe universal approximation capabilities of neural networks over a wide range\\nof activation functions. Leveraging wavelet frame theory on the spaces of\\nhomogeneous type, we derive sufficient conditions on activation functions to\\nensure that the associated neural network approximates any functions in the\\ngiven space, along with an error estimate. These sufficient conditions\\naccommodate a variety of smooth activation functions, including those that\\nexhibit oscillatory behavior. Furthermore, by considering the $L^2$-distance\\nbetween smooth and non-smooth activation functions, we establish a generalized\\napproximation result that is applicable to non-smooth activations, with the\\nerror explicitly controlled by this distance. This provides increased\\nflexibility in the design of network architectures.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,math.CA,stat.ML\", \"published\": \"2025-04-23T13:02:37Z\"}"}
