{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11999v1\", \"title\": \"A Complex-valued SAR Foundation Model Based on Physically Inspired\\n  Representation Learning\", \"summary\": \"Vision foundation models in remote sensing have been extensively studied due\\nto their superior generalization on various downstream tasks. Synthetic\\nAperture Radar (SAR) offers all-day, all-weather imaging capabilities,\\nproviding significant advantages for Earth observation. However, establishing a\\nfoundation model for SAR image interpretation inevitably encounters the\\nchallenges of insufficient information utilization and poor interpretability.\\nIn this paper, we propose a remote sensing foundation model based on\\ncomplex-valued SAR data, which simulates the polarimetric decomposition process\\nfor pre-training, i.e., characterizing pixel scattering intensity as a weighted\\ncombination of scattering bases and scattering coefficients, thereby endowing\\nthe foundation model with physical interpretability. Specifically, we construct\\na series of scattering queries, each representing an independent and meaningful\\nscattering basis, which interact with SAR features in the scattering query\\ndecoder and output the corresponding scattering coefficient. To guide the\\npre-training process, polarimetric decomposition loss and power\\nself-supervision loss are constructed. The former aligns the predicted\\ncoefficients with Yamaguchi coefficients, while the latter reconstructs power\\nfrom the predicted coefficients and compares it to the input image's power. The\\nperformance of our foundation model is validated on six typical downstream\\ntasks, achieving state-of-the-art results. Notably, the foundation model can\\nextract stable feature representations and exhibits strong generalization, even\\nin data-scarce conditions.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T11:51:34Z\"}"}
