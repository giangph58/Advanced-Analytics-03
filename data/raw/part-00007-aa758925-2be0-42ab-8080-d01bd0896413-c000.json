{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10231v1\", \"title\": \"A Model Zoo of Vision Transformers\", \"summary\": \"The availability of large, structured populations of neural networks - called\\n'model zoos' - has led to the development of a multitude of downstream tasks\\nranging from model analysis, to representation learning on model weights or\\ngenerative modeling of neural network parameters. However, existing model zoos\\nare limited in size and architecture and neglect the transformer, which is\\namong the currently most successful neural network architectures. We address\\nthis gap by introducing the first model zoo of vision transformers (ViT). To\\nbetter represent recent training approaches, we develop a new blueprint for\\nmodel zoo generation that encompasses both pre-training and fine-tuning steps,\\nand publish 250 unique models. They are carefully generated with a large span\\nof generating factors, and their diversity is validated using a thorough choice\\nof weight-space and behavioral metrics. To further motivate the utility of our\\nproposed dataset, we suggest multiple possible applications grounded in both\\nextensive exploratory experiments and a number of examples from the existing\\nliterature. By extending previous lines of similar work, our model zoo allows\\nresearchers to push their model population-based methods from the small model\\nregime to state-of-the-art architectures. We make our model zoo available at\\ngithub.com/ModelZoos/ViTModelZoo.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-14T13:52:26Z\"}"}
