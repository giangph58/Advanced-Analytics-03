{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07962v1\", \"title\": \"GLUS: Global-Local Reasoning Unified into A Single Large Language Model\\n  for Video Segmentation\", \"summary\": \"This paper proposes a novel framework utilizing multi-modal large language\\nmodels (MLLMs) for referring video object segmentation (RefVOS). Previous\\nMLLM-based methods commonly struggle with the dilemma between \\\"Ref\\\" and \\\"VOS\\\":\\nthey either specialize in understanding a few key frames (global reasoning) or\\ntracking objects on continuous frames (local reasoning), and rely on external\\nVOS or frame selectors to mitigate the other end of the challenge. However, our\\nframework GLUS shows that global and local consistency can be unified into a\\nsingle video segmentation MLLM: a set of sparse \\\"context frames\\\" provides\\nglobal information, while a stream of continuous \\\"query frames\\\" conducts local\\nobject tracking. This is further supported by jointly training the MLLM with a\\npre-trained VOS memory bank to simultaneously digest short-range and long-range\\ntemporal information. To improve the information efficiency within the limited\\ncontext window of MLLMs, we introduce object contrastive learning to\\ndistinguish hard false-positive objects and a self-refined framework to\\nidentify crucial frames and perform propagation. By collectively integrating\\nthese insights, our GLUS delivers a simple yet effective baseline, achieving\\nnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our\\nproject page is at https://glus-video.github.io/.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-10T17:59:55Z\"}"}
