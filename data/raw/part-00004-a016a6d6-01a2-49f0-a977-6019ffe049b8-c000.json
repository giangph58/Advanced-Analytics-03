{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12169v1\", \"title\": \"Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video\\n  Pipeline\", \"summary\": \"Low-light conditions pose significant challenges for both human and machine\\nannotation. This in turn has led to a lack of research into machine\\nunderstanding for low-light images and (in particular) videos. A common\\napproach is to apply annotations obtained from high quality datasets to\\nsynthetically created low light versions. In addition, these approaches are\\noften limited through the use of unrealistic noise models. In this paper, we\\npropose a new Degradation Estimation Network (DEN), which synthetically\\ngenerates realistic standard RGB (sRGB) noise without the requirement for\\ncamera metadata. This is achieved by estimating the parameters of\\nphysics-informed noise distributions, trained in a self-supervised manner. This\\nzero-shot approach allows our method to generate synthetic noisy content with a\\ndiverse range of realistic noise characteristics, unlike other methods which\\nfocus on recreating the noise characteristics of the training data. We evaluate\\nour proposed synthetic pipeline using various methods trained on its synthetic\\ndata for typical low-light tasks including synthetic noise replication, video\\nenhancement, and object detection, showing improvements of up to 24\\\\% KLD, 21\\\\%\\nLPIPS, and 62\\\\% AP$_{50-95}$, respectively.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,eess.IV\", \"published\": \"2025-04-16T15:19:11Z\"}"}
