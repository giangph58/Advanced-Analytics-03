{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14906v1\", \"title\": \"OmniAudio: Generating Spatial Audio from 360-Degree Video\", \"summary\": \"Traditional video-to-audio generation techniques primarily focus on\\nfield-of-view (FoV) video and non-spatial audio, often missing the spatial cues\\nnecessary for accurately representing sound sources in 3D environments. To\\naddress this limitation, we introduce a novel task, 360V2SA, to generate\\nspatial audio from 360-degree videos, specifically producing First-order\\nAmbisonics (FOA) audio - a standard format for representing 3D spatial audio\\nthat captures sound directionality and enables realistic 3D audio reproduction.\\nWe first create Sphere360, a novel dataset tailored for this task that is\\ncurated from real-world data. We also design an efficient semi-automated\\npipeline for collecting and cleaning paired video-audio data. To generate\\nspatial audio from 360-degree video, we propose a novel framework OmniAudio,\\nwhich leverages self-supervised pre-training using both spatial audio data (in\\nFOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a\\ndual-branch framework that utilizes both panoramic and FoV video inputs to\\ncapture comprehensive local and global information from 360-degree videos.\\nExperimental results demonstrate that OmniAudio achieves state-of-the-art\\nperformance across both objective and subjective metrics on Sphere360. Code and\\ndatasets will be released at https://github.com/liuhuadai/OmniAudio. The demo\\npage is available at https://OmniAudio-360V2SA.github.io.\", \"main_category\": \"eess.AS\", \"categories\": \"eess.AS,cs.CV,cs.SD\", \"published\": \"2025-04-21T07:21:28Z\"}"}
