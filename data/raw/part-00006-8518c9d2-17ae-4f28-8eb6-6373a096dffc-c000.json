{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03600v1\", \"title\": \"TailBench++: Flexible Multi-Client, Multi-Server Benchmarking for\\n  Latency-Critical Workloads\", \"summary\": \"Cloud systems have rapidly expanded worldwide in the last decade, shifting\\ncomputational tasks to cloud servers where clients submit their requests. Among\\ncloud workloads, latency-critical applications -- characterized by\\nhigh-percentile response times -- have gained special interest. These\\napplications are present in modern services, representing an important fraction\\nof cloud workloads. This work analyzes common cloud benchmarking suites and\\nidentifies TailBench as the most suitable to assess cloud performance with\\nlatency-critical workloads. Unfortunately, this suite presents key limitations,\\nespecially in multi-server scenarios or environments with variable client\\narrival patterns and fluctuating loads. To address these limitations, we\\npropose TailBench++, an enhanced benchmark suite that extends TailBench to\\nenable cloud evaluation studies to be performed in dynamic multi-client,\\nmulti-server environments. It allows reproducing experiments with varying\\nclient arrival times, dynamic query per second (QPS) fluctuations, and multiple\\nservers handling requests. Case studies show that TailBench++ enables more\\nrealistic evaluations by capturing a wider range of real-world scenarios.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC\", \"published\": \"2025-05-06T15:02:20Z\"}"}
