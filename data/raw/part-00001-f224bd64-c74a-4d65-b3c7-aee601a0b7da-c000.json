{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07677v1\", \"title\": \"Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal\\n  Localization\", \"summary\": \"Reliable localization is critical for robot navigation in complex indoor\\nenvironments. In this paper, we propose an uncertainty-aware localization\\nmethod that enhances the reliability of localization outputs without modifying\\nthe prediction model itself. This study introduces a percentile-based rejection\\nstrategy that filters out unreliable 3-DoF pose predictions based on aleatoric\\nand epistemic uncertainties the network estimates. We apply this approach to a\\nmulti-modal end-to-end localization that fuses RGB images and 2D LiDAR data,\\nand we evaluate it across three real-world datasets collected using a\\ncommercialized serving robot. Experimental results show that applying stricter\\nuncertainty thresholds consistently improves pose accuracy. Specifically, the\\nmean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean\\norientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70%\\nthresholds, respectively. Furthermore, the rejection strategy effectively\\nremoves extreme outliers, resulting in better alignment with ground truth\\ntrajectories. To the best of our knowledge, this is the first study to\\nquantitatively demonstrate the benefits of percentile-based uncertainty\\nrejection in multi-modal end-to-end localization tasks. Our approach provides a\\npractical means to enhance the reliability and accuracy of localization systems\\nin real-world deployments.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.CV\", \"published\": \"2025-04-10T12:07:24Z\"}"}
