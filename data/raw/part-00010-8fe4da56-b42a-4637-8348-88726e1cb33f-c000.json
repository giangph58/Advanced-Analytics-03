{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17414v1\", \"title\": \"3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models\", \"summary\": \"Video try-on replaces clothing in videos with target garments. Existing\\nmethods struggle to generate high-quality and temporally consistent results\\nwhen handling complex clothing patterns and diverse body poses. We present\\n3DV-TON, a novel diffusion-based framework for generating high-fidelity and\\ntemporally consistent video try-on results. Our approach employs generated\\nanimatable textured 3D meshes as explicit frame-level guidance, alleviating the\\nissue of models over-focusing on appearance fidelity at the expanse of motion\\ncoherence. This is achieved by enabling direct reference to consistent garment\\ntexture movements throughout video sequences. The proposed method features an\\nadaptive pipeline for generating dynamic 3D guidance: (1) selecting a keyframe\\nfor initial 2D image try-on, followed by (2) reconstructing and animating a\\ntextured 3D mesh synchronized with original video poses. We further introduce a\\nrobust rectangular masking strategy that successfully mitigates artifact\\npropagation caused by leaking clothing information during dynamic human and\\ngarment movements. To advance video try-on research, we introduce HR-VVT, a\\nhigh-resolution benchmark dataset containing 130 videos with diverse clothing\\ntypes and scenarios. Quantitative and qualitative results demonstrate our\\nsuperior performance over existing methods. The project page is at this link\\nhttps://2y7c3.github.io/3DV-TON/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-24T10:12:40Z\"}"}
