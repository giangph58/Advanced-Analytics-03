{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20041v1\", \"title\": \"Learning Streaming Video Representation via Multitask Training\", \"summary\": \"Understanding continuous video streams plays a fundamental role in real-time\\napplications including embodied AI and autonomous driving. Unlike offline video\\nunderstanding, streaming video understanding requires the ability to process\\nvideo streams frame by frame, preserve historical information, and make\\nlow-latency decisions.To address these challenges, our main contributions are\\nthree-fold. (i) We develop a novel streaming video backbone, termed as\\nStreamFormer, by incorporating causal temporal attention into a pre-trained\\nvision transformer. This enables efficient streaming video processing while\\nmaintaining image representation capability.(ii) To train StreamFormer, we\\npropose to unify diverse spatial-temporal video understanding tasks within a\\nmultitask visual-language alignment framework. Hence, StreamFormer learns\\nglobal semantics, temporal dynamics, and fine-grained spatial relationships\\nsimultaneously. (iii) We conduct extensive experiments on online action\\ndetection, online video instance segmentation, and video question answering.\\nStreamFormer achieves competitive results while maintaining efficiency,\\ndemonstrating its potential for real-time applications.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T17:59:54Z\"}"}
