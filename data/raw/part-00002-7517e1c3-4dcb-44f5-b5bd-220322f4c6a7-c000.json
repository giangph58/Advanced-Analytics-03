{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03374v1\", \"title\": \"Reducing Annotation Burden in Physical Activity Research Using\\n  Vision-Language Models\", \"summary\": \"Introduction: Data from wearable devices collected in free-living settings,\\nand labelled with physical activity behaviours compatible with health research,\\nare essential for both validating existing wearable-based measurement\\napproaches and developing novel machine learning approaches. One common way of\\nobtaining these labels relies on laborious annotation of sequences of images\\ncaptured by cameras worn by participants through the course of a day. Methods:\\nWe compare the performance of three vision language models and two\\ndiscriminative models on two free-living validation studies with 161 and 111\\nparticipants, collected in Oxfordshire, United Kingdom and Sichuan, China,\\nrespectively, using the Autographer (OMG Life, defunct) wearable camera.\\nResults: We found that the best open-source vision-language model (VLM) and\\nfine-tuned discriminative model (DM) achieved comparable performance when\\npredicting sedentary behaviour from single images on unseen participants in the\\nOxfordshire study; median F1-scores: VLM = 0.89 (0.84, 0.92), DM = 0.91 (0.86,\\n0.95). Performance declined for light (VLM = 0.60 (0.56,0.67), DM = 0.70 (0.63,\\n0.79)), and moderate-to-vigorous intensity physical activity (VLM = 0.66 (0.53,\\n0.85); DM = 0.72 (0.58, 0.84)). When applied to the external Sichuan study,\\nperformance fell across all intensity categories, with median Cohen's\\nkappa-scores falling from 0.54 (0.49, 0.64) to 0.26 (0.15, 0.37) for the VLM,\\nand from 0.67 (0.60, 0.74) to 0.19 (0.10, 0.30) for the DM. Conclusion: Freely\\navailable computer vision models could help annotate sedentary behaviour,\\ntypically the most prevalent activity of daily living, from wearable camera\\nimages within similar populations to seen data, reducing the annotation burden.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T09:49:45Z\"}"}
