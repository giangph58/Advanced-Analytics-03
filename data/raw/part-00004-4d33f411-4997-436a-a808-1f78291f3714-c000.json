{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11946v1\", \"title\": \"R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh\\n  Reconstruction with Diffusion Priors\", \"summary\": \"Mesh reconstruction from multi-view images is a fundamental problem in\\ncomputer vision, but its performance degrades significantly under sparse-view\\nconditions, especially in unseen regions where no ground-truth observations are\\navailable. While recent advances in diffusion models have demonstrated strong\\ncapabilities in synthesizing novel views from limited inputs, their outputs\\noften suffer from visual artifacts and lack 3D consistency, posing challenges\\nfor reliable mesh optimization. In this paper, we propose a novel framework\\nthat leverages diffusion models to enhance sparse-view mesh reconstruction in a\\nprincipled and reliable manner. To address the instability of diffusion\\noutputs, we propose a Consensus Diffusion Module that filters unreliable\\ngenerations via interquartile range (IQR) analysis and performs variance-aware\\nimage fusion to produce robust pseudo-supervision. Building on this, we design\\nan online reinforcement learning strategy based on the Upper Confidence Bound\\n(UCB) to adaptively select the most informative viewpoints for enhancement,\\nguided by diffusion loss. Finally, the fused images are used to jointly\\nsupervise a NeRF-based model alongside sparse-view ground truth, ensuring\\nconsistency across both geometry and appearance. Extensive experiments\\ndemonstrate that our method achieves significant improvements in both geometric\\nquality and rendering quality.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T10:23:59Z\"}"}
