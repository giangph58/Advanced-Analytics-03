{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04946v1\", \"title\": \"T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video\\n  Generation Models\", \"summary\": \"Thanks to recent advancements in scalable deep architectures and large-scale\\npretraining, text-to-video generation has achieved unprecedented capabilities\\nin producing high-fidelity, instruction-following content across a wide range\\nof styles, enabling applications in advertising, entertainment, and education.\\nHowever, these models' ability to render precise on-screen text, such as\\ncaptions or mathematical formulas, remains largely untested, posing significant\\nchallenges for applications requiring exact textual accuracy. In this work, we\\nintroduce T2VTextBench, the first human-evaluation benchmark dedicated to\\nevaluating on-screen text fidelity and temporal consistency in text-to-video\\nmodels. Our suite of prompts integrates complex text strings with dynamic scene\\nchanges, testing each model's ability to maintain detailed instructions across\\nframes. We evaluate ten state-of-the-art systems, ranging from open-source\\nsolutions to commercial offerings, and find that most struggle to generate\\nlegible, consistent text. These results highlight a critical gap in current\\nvideo generators and provide a clear direction for future research aimed at\\nenhancing textual manipulation in video synthesis.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL,cs.LG\", \"published\": \"2025-05-08T04:49:52Z\"}"}
