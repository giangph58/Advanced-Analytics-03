{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15236v1\", \"title\": \"Values in the Wild: Discovering and Analyzing Values in Real-World\\n  Language Model Interactions\", \"summary\": \"AI assistants can impart value judgments that shape people's decisions and\\nworldviews, yet little is known empirically about what values these systems\\nrely on in practice. To address this, we develop a bottom-up,\\nprivacy-preserving method to extract the values (normative considerations\\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\\nin hundreds of thousands of real-world interactions. We empirically discover\\nand taxonomize 3,307 AI values and study how they vary by context. We find that\\nClaude expresses many practical and epistemic values, and typically supports\\nprosocial human values while resisting values like \\\"moral nihilism\\\". While some\\nvalues appear consistently across contexts (e.g. \\\"transparency\\\"), many are more\\nspecialized and context-dependent, reflecting the diversity of human\\ninterlocutors and their varied contexts. For example, \\\"harm prevention\\\" emerges\\nwhen Claude resists users, \\\"historical accuracy\\\" when responding to queries\\nabout controversial events, \\\"healthy boundaries\\\" when asked for relationship\\nadvice, and \\\"human agency\\\" in technology ethics discussions. By providing the\\nfirst large-scale empirical mapping of AI values in deployment, our work\\ncreates a foundation for more grounded evaluation and design of values in AI\\nsystems.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.CY,cs.LG\", \"published\": \"2025-04-21T17:13:16Z\"}"}
