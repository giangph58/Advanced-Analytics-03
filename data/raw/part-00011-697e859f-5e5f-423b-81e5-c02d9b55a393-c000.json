{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16382v1\", \"title\": \"Fully Scalable MPC Algorithms for Euclidean k-Center\", \"summary\": \"The $k$-center problem is a fundamental optimization problem with numerous\\napplications in machine learning, data analysis, data mining, and communication\\nnetworks. The $k$-center problem has been extensively studied in the classical\\nsequential setting for several decades, and more recently there have been some\\nefforts in understanding the problem in parallel computing, on the Massively\\nParallel Computation (MPC) model. For now, we have a good understanding of\\n$k$-center in the case where each local MPC machine has sufficient local memory\\nto store some representatives from each cluster, that is, when one has\\n$\\\\Omega(k)$ local memory per machine. While this setting covers the case of\\nsmall values of $k$, for a large number of clusters these algorithms require\\nundesirably large local memory, making them poorly scalable. The case of large\\n$k$ has been considered only recently for the fully scalable low-local-memory\\nMPC model for the Euclidean instances of the $k$-center problem. However, the\\nearlier works have been considering only the constant dimensional Euclidean\\nspace, required a super-constant number of rounds, and produced only\\n$k(1+o(1))$ centers whose cost is a super-constant approximation of $k$-center.\\n  In this work, we significantly improve upon the earlier results for the\\n$k$-center problem for the fully scalable low-local-memory MPC model. In the\\nlow dimensional Euclidean case in $\\\\mathbb{R}^d$, we present the first\\nconstant-round fully scalable MPC algorithm for\\n$(2+\\\\varepsilon)$-approximation. We push the ratio further to $(1 +\\n\\\\varepsilon)$-approximation albeit using slightly more $(1 + \\\\varepsilon)k$\\ncenters. All these results naturally extends to slightly super-constant values\\nof $d$. In the high-dimensional regime, we provide the first fully scalable MPC\\nalgorithm that in a constant number of rounds achieves an $O(\\\\log n/ \\\\log \\\\log\\nn)$-approximation for $k$-center.\", \"main_category\": \"cs.DS\", \"categories\": \"cs.DS,cs.DC\", \"published\": \"2025-04-23T03:24:15Z\"}"}
