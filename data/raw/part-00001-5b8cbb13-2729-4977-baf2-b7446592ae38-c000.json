{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20770v1\", \"title\": \"JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular\\n  Generation\", \"summary\": \"The discovery of new molecules based on the original chemical molecule\\ndistributions is of great importance in medicine. The graph transformer, with\\nits advantages of high performance and scalability compared to traditional\\ngraph networks, has been widely explored in recent research for applications of\\ngraph structures. However, current transformer-based graph decoders struggle to\\neffectively utilize graph information, which limits their capacity to leverage\\nonly sequences of nodes rather than the complex topological structures of\\nmolecule graphs. This paper focuses on building a graph transformer-based\\nframework for molecular generation, which we call \\\\textbf{JTreeformer} as it\\ntransforms graph generation into junction tree generation. It combines GCN\\nparallel with multi-head attention as the encoder. It integrates a directed\\nacyclic GCN into a graph-based Transformer to serve as a decoder, which can\\niteratively synthesize the entire molecule by leveraging information from the\\npartially constructed molecular structure at each step. In addition, a\\ndiffusion model is inserted in the latent space generated by the encoder, to\\nenhance the efficiency and effectiveness of sampling further. The empirical\\nresults demonstrate that our novel framework outperforms existing molecule\\ngeneration methods, thus offering a promising tool to advance drug discovery\\n(https://anonymous.4open.science/r/JTreeformer-C74C).\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-29T13:51:07Z\"}"}
