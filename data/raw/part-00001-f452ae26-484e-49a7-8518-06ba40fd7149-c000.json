{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17791v1\", \"title\": \"LiDPM: Rethinking Point Diffusion for Lidar Scene Completion\", \"summary\": \"Training diffusion models that work directly on lidar points at the scale of\\noutdoor scenes is challenging due to the difficulty of generating fine-grained\\ndetails from white noise over a broad field of view. The latest works\\naddressing scene completion with diffusion models tackle this problem by\\nreformulating the original DDPM as a local diffusion process. It contrasts with\\nthe common practice of operating at the level of objects, where vanilla DDPMs\\nare currently used. In this work, we close the gap between these two lines of\\nwork. We identify approximations in the local diffusion formulation, show that\\nthey are not required to operate at the scene level, and that a vanilla DDPM\\nwith a well-chosen starting point is enough for completion. Finally, we\\ndemonstrate that our method, LiDPM, leads to better results in scene completion\\non SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-04-24T17:59:59Z\"}"}
