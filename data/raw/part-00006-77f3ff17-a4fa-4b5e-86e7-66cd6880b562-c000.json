{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16588v1\", \"title\": \"Data-Assimilated Model-Based Reinforcement Learning for Partially\\n  Observed Chaotic Flows\", \"summary\": \"The goal of many applications in energy and transport sectors is to control\\nturbulent flows. However, because of chaotic dynamics and high dimensionality,\\nthe control of turbulent flows is exceedingly difficult. Model-free\\nreinforcement learning (RL) methods can discover optimal control policies by\\ninteracting with the environment, but they require full state information,\\nwhich is often unavailable in experimental settings. We propose a\\ndata-assimilated model-based RL (DA-MBRL) framework for systems with partial\\nobservability and noisy measurements. Our framework employs a control-aware\\nEcho State Network for data-driven prediction of the dynamics, and integrates\\ndata assimilation with an Ensemble Kalman Filter for real-time state\\nestimation. An off-policy actor-critic algorithm is employed to learn optimal\\ncontrol strategies from state estimates. The framework is tested on the\\nKuramoto-Sivashinsky equation, demonstrating its effectiveness in stabilizing a\\nspatiotemporally chaotic flow from noisy and partial measurements.\", \"main_category\": \"eess.SY\", \"categories\": \"eess.SY,cs.LG,cs.SY,physics.flu-dyn\", \"published\": \"2025-04-23T10:12:53Z\"}"}
