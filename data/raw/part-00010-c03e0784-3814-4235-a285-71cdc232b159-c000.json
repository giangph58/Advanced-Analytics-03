{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04974v1\", \"title\": \"ReAlign: Bilingual Text-to-Motion Generation via Step-Aware\\n  Reward-Guided Alignment\", \"summary\": \"Bilingual text-to-motion generation, which synthesizes 3D human motions from\\nbilingual text inputs, holds immense potential for cross-linguistic\\napplications in gaming, film, and robotics. However, this task faces critical\\nchallenges: the absence of bilingual motion-language datasets and the\\nmisalignment between text and motion distributions in diffusion models, leading\\nto semantically inconsistent or low-quality motions. To address these\\nchallenges, we propose BiHumanML3D, a novel bilingual human motion dataset,\\nwhich establishes a crucial benchmark for bilingual text-to-motion generation\\nmodels. Furthermore, we propose a Bilingual Motion Diffusion model (BiMD),\\nwhich leverages cross-lingual aligned representations to capture semantics,\\nthereby achieving a unified bilingual model. Building upon this, we propose\\nReward-guided sampling Alignment (ReAlign) method, comprising a step-aware\\nreward model to assess alignment quality during sampling and a reward-guided\\nstrategy that directs the diffusion process toward an optimally aligned\\ndistribution. This reward model integrates step-aware tokens and combines a\\ntext-aligned module for semantic consistency and a motion-aligned module for\\nrealism, refining noisy motions at each timestep to balance probability density\\nand alignment. Experiments demonstrate that our approach significantly improves\\ntext-motion alignment and motion quality compared to existing state-of-the-art\\nmethods. Project page: https://wengwanjiang.github.io/ReAlign-page/.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T06:19:18Z\"}"}
