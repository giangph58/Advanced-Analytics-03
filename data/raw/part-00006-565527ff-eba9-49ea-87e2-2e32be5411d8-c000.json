{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20687v1\", \"title\": \"What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to\\n  Evaluate Generative Models\", \"summary\": \"Evaluating synthetic tabular data is challenging, since they can differ from\\nthe real data in so many ways. There exist numerous metrics of synthetic data\\nquality, ranging from statistical distances to predictive performance, often\\nproviding conflicting results. Moreover, they fail to explain or pinpoint the\\nspecific weaknesses in the synthetic data. To address this, we apply\\nexplainable AI (XAI) techniques to a binary detection classifier trained to\\ndistinguish real from synthetic data. While the classifier identifies\\ndistributional differences, XAI concepts such as feature importance and feature\\neffects, analyzed through methods like permutation feature importance, partial\\ndependence plots, Shapley values and counterfactual explanations, reveal why\\nsynthetic data are distinguishable, highlighting inconsistencies, unrealistic\\ndependencies, or missing patterns. This interpretability increases transparency\\nin synthetic data evaluation and provides deeper insights beyond conventional\\nmetrics, helping diagnose and improve synthetic data quality. We apply our\\napproach to two tabular datasets and generative models, showing that it\\nuncovers issues overlooked by standard evaluation techniques.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-29T12:10:52Z\"}"}
