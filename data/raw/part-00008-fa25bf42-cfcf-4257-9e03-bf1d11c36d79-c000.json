{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03368v1\", \"title\": \"Geospatial Mechanistic Interpretability of Large Language Models\", \"summary\": \"Large Language Models (LLMs) have demonstrated unprecedented capabilities\\nacross various natural language processing tasks. Their ability to process and\\ngenerate viable text and code has made them ubiquitous in many fields, while\\ntheir deployment as knowledge bases and \\\"reasoning\\\" tools remains an area of\\nongoing research. In geography, a growing body of literature has been focusing\\non evaluating LLMs' geographical knowledge and their ability to perform spatial\\nreasoning. However, very little is still known about the internal functioning\\nof these models, especially about how they process geographical information.\\n  In this chapter, we establish a novel framework for the study of geospatial\\nmechanistic interpretability - using spatial analysis to reverse engineer how\\nLLMs handle geographical information. Our aim is to advance our understanding\\nof the internal representations that these complex models generate while\\nprocessing geographical information - what one might call \\\"how LLMs think about\\ngeographic information\\\" if such phrasing was not an undue anthropomorphism.\\n  We first outline the use of probing in revealing internal structures within\\nLLMs. We then introduce the field of mechanistic interpretability, discussing\\nthe superposition hypothesis and the role of sparse autoencoders in\\ndisentangling polysemantic internal representations of LLMs into more\\ninterpretable, monosemantic features. In our experiments, we use spatial\\nautocorrelation to show how features obtained for placenames display spatial\\npatterns related to their geographic location and can thus be interpreted\\ngeospatially, providing insights into how these models process geographical\\ninformation. We conclude by discussing how our framework can help shape the\\nstudy and use of foundation models in geography.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-06T09:40:06Z\"}"}
