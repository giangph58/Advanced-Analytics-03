{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16397v1\", \"title\": \"Circinus: Efficient Query Planner for Compound ML Serving\", \"summary\": \"The rise of compound AI serving -- integrating multiple operators in a\\npipeline that may span edge and cloud tiers -- enables end-user applications\\nsuch as autonomous driving, generative AI-powered meeting companions, and\\nimmersive gaming. Achieving high service goodput -- i.e., meeting service level\\nobjectives (SLOs) for pipeline latency, accuracy, and costs -- requires\\neffective planning of operator placement, configuration, and resource\\nallocation across infrastructure tiers. However, the diverse SLO requirements,\\nvarying edge capabilities, and high query volumes create an enormous planning\\nsearch space, rendering current solutions fundamentally limited for real-time\\nserving and cost-efficient deployments.\\n  This paper presents Circinus, an SLO-aware query planner for large-scale\\ncompound AI workloads. Circinus novelly decomposes multi-query planning and\\nmulti-dimensional SLO objectives while preserving global decision quality. By\\nexploiting plan similarities within and across queries, it significantly\\nreduces search steps. It further improves per-step efficiency with a\\nprecision-aware plan profiler that incrementally profiles and strategically\\napplies early stopping based on imprecise estimates of plan performance. At\\nscale, Circinus selects query-plan combinations to maximize global SLO goodput.\\nEvaluations in real-world settings show that Circinus improves service goodput\\nby 3.2-5.0$\\\\times$, accelerates query planning by 4.2-5.8$\\\\times$, achieving\\nquery response in seconds, while reducing deployment costs by 3.2-4.0$\\\\times$\\nover state of the arts even in their intended single-tier deployments.\", \"main_category\": \"cs.DB\", \"categories\": \"cs.DB,cs.LG\", \"published\": \"2025-04-23T03:57:24Z\"}"}
