{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20741v1\", \"title\": \"In defence of post-hoc explanations in medical AI\", \"summary\": \"Since the early days of the Explainable AI movement, post-hoc explanations\\nhave been praised for their potential to improve user understanding, promote\\ntrust, and reduce patient safety risks in black box medical AI systems.\\nRecently, however, critics have argued that the benefits of post-hoc\\nexplanations are greatly exaggerated since they merely approximate, rather than\\nreplicate, the actual reasoning processes that black box systems take to arrive\\nat their outputs. In this article, we aim to defend the value of post-hoc\\nexplanations against this recent critique. We argue that even if post-hoc\\nexplanations do not replicate the exact reasoning processes of black box\\nsystems, they can still improve users' functional understanding of black box\\nsystems, increase the accuracy of clinician-AI teams, and assist clinicians in\\njustifying their AI-informed decisions. While post-hoc explanations are not a\\n\\\"silver bullet\\\" solution to the black box problem in medical AI, we conclude\\nthat they remain a useful strategy for addressing the black box problem in\\nmedical AI.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC,cs.AI,cs.CY,cs.LG\", \"published\": \"2025-04-29T13:24:21Z\"}"}
