{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01700v1\", \"title\": \"Reasoning LLMs for User-Aware Multimodal Conversational Agents\", \"summary\": \"Personalization in social robotics is critical for fostering effective\\nhuman-robot interactions, yet systems often face the cold start problem, where\\ninitial user preferences or characteristics are unavailable. This paper\\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\\nagent that addresses this challenge through dynamic user profiling and model\\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\\niteratively infer user preferences and vision-language models (VLMs) to\\ninitialize user profiles from multimodal inputs, enabling personalized\\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\\nGeneration (RAG) architecture, the system dynamically refines user\\nrepresentations within an inherent CoT process, ensuring contextually relevant\\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\\nunderscoring the impact of reasoning model size on performance. Human\\nevaluations further validate the framework's efficacy, particularly for elderly\\nusers, where tailored responses enhance engagement and trust. Ethical\\nconsiderations, including privacy preservation and bias mitigation, are\\nrigorously discussed and addressed to ensure responsible deployment.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC,cs.AI,cs.RO\", \"published\": \"2025-04-02T13:00:17Z\"}"}
