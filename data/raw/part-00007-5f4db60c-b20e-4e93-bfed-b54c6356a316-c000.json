{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13032v1\", \"title\": \"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\\n  Graphs for LLM-Based Task Planning\", \"summary\": \"Recent advancements in large language models (LLMs) have enabled their use as\\nagents for planning complex tasks. Existing methods typically rely on a\\nthought-action-observation (TAO) process to enhance LLM performance, but these\\napproaches are often constrained by the LLMs' limited knowledge of complex\\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\\nleveraging external databases to ground generation in retrieved information. In\\nthis paper, we identify two key challenges (enlargability and transferability)\\nin applying RAG to task planning. We propose InstructRAG, a novel solution\\nwithin a multi-agent meta-reinforcement learning framework, to address these\\nchallenges. InstructRAG includes a graph to organize past instruction paths\\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\\nimprove task generalization for transferability. The two agents are trained\\nend-to-end to optimize overall planning performance. Our experiments on four\\nwidely used task planning datasets demonstrate that InstructRAG significantly\\nenhances performance and adapts efficiently to new tasks, achieving up to a\\n19.2% improvement over the best existing approach.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.IR\", \"published\": \"2025-04-17T15:41:39Z\"}"}
