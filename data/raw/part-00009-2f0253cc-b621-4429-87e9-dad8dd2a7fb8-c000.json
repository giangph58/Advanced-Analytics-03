{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12137v1\", \"title\": \"Efficient Contrastive Decoding with Probabilistic Hallucination\\n  Detection - Mitigating Hallucinations in Large Vision Language Models -\", \"summary\": \"Despite recent advances in Large Vision Language Models (LVLMs), these models\\nstill suffer from generating hallucinatory responses that do not align with the\\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\\nContrastive Decoding (ECD), a simple method that leverages probabilistic\\nhallucination detection to shift the output distribution towards contextually\\naccurate answers at inference time. By contrasting token probabilities and\\nhallucination scores, ECD subtracts hallucinated concepts from the original\\ndistribution, effectively suppressing hallucinations. Notably, our proposed\\nmethod can be applied to any open-source LVLM and does not require additional\\nLVLM training. We evaluate our method on several benchmark datasets and across\\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\\nhallucinations, outperforming state-of-the-art methods with respect to\\nperformance on LVLM benchmarks and computation time.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL,cs.LG\", \"published\": \"2025-04-16T14:50:25Z\"}"}
