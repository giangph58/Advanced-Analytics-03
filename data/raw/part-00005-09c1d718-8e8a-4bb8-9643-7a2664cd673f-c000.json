{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07081v1\", \"title\": \"Self-Steering Language Models\", \"summary\": \"While test-time reasoning enables language models to tackle complex tasks,\\nsearching or planning in natural language can be slow, costly, and error-prone.\\nBut even when LMs struggle to emulate the precise reasoning steps needed to\\nsolve a problem, they often excel at describing its abstract structure--both\\nhow to verify solutions and how to search for them. This paper introduces\\nDisCIPL, a method for \\\"self-steering\\\" LMs where a Planner model generates a\\ntask-specific inference program that is executed by a population of Follower\\nmodels. Our approach equips LMs with the ability to write recursive search\\nprocedures that guide LM inference, enabling new forms of verifiable and\\nefficient reasoning. When instantiated with a small Follower (e.g.,\\nLlama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models,\\nincluding GPT-4o and o1, on challenging constrained generation tasks. In\\ndecoupling planning from execution, our work opens up a design space of\\nhighly-parallelized Monte Carlo inference strategies that outperform standard\\nbest-of-N sampling, require no finetuning, and can be implemented automatically\\nby existing LMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-09T17:54:22Z\"}"}
