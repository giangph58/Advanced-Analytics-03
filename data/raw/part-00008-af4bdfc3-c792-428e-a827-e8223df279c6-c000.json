{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17300v1\", \"title\": \"The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label\\n  Text Backdoors with Style Attributes\", \"summary\": \"Backdoor attacks on text classifiers can cause them to predict a predefined\\nlabel when a particular \\\"trigger\\\" is present. Prior attacks often rely on\\ntriggers that are ungrammatical or otherwise unusual, leading to conspicuous\\nattacks. As a result, human annotators, who play a critical role in curating\\ntraining data in practice, can easily detect and filter out these unnatural\\ntexts during manual inspection, reducing the risk of such attacks. We argue\\nthat a key criterion for a successful attack is for text with and without\\ntriggers to be indistinguishable to humans. However, prior work neither\\ndirectly nor comprehensively evaluated attack subtlety and invisibility with\\nhuman involvement. We bridge the gap by conducting thorough human evaluations\\nto assess attack subtlety. We also propose \\\\emph{AttrBkd}, consisting of three\\nrecipes for crafting subtle yet effective trigger attributes, such as\\nextracting fine-grained attributes from existing baseline backdoor attacks. Our\\nhuman evaluations find that AttrBkd with these baseline-derived attributes is\\noften more effective (higher attack success rate) and more subtle (fewer\\ninstances detected by humans) than the original baseline backdoor attacks,\\ndemonstrating that backdoor attacks can bypass detection by being inconspicuous\\nand appearing natural even upon close inspection, while still remaining\\neffective. Our human annotation also provides information not captured by\\nautomated metrics used in prior work, and demonstrates the misalignment of\\nthese metrics with human judgment.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-24T06:50:59Z\"}"}
