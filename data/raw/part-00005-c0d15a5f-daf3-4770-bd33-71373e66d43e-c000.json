{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21476v1\", \"title\": \"GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal\\n  Diffusion Transformers\", \"summary\": \"Garment sewing patterns are fundamental design elements that bridge the gap\\nbetween design concepts and practical manufacturing. The generative modeling of\\nsewing patterns is crucial for creating diversified garments. However, existing\\napproaches are limited either by reliance on a single input modality or by\\nsuboptimal generation efficiency. In this work, we present\\n\\\\textbf{\\\\textit{GarmentDiffusion}}, a new generative model capable of producing\\ncentimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text,\\nimage, and incomplete sewing pattern). Our method efficiently encodes 3D sewing\\npattern parameters into compact edge token representations, achieving a\\nsequence length that is $\\\\textbf{10}\\\\times$ shorter than that of the\\nautoregressive SewingGPT in DressCode. By employing a diffusion transformer, we\\nsimultaneously denoise all edge tokens along the temporal axis, while\\nmaintaining a constant number of denoising steps regardless of dataset-specific\\nedge and panel statistics. With all combination of designs of our model, the\\nsewing pattern generation speed is accelerated by $\\\\textbf{100}\\\\times$ compared\\nto SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well\\nas on the largest sewing pattern dataset, namely GarmentCodeData. The project\\nwebsite is available at https://shenfu-research.github.io/Garment-Diffusion/.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-30T09:56:59Z\"}"}
