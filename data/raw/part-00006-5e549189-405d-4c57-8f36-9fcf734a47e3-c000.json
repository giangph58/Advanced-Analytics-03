{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10018v1\", \"title\": \"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset\\n  and An Asymmetric RWKV Fusion Framework\", \"summary\": \"Existing pedestrian attribute recognition methods are generally developed\\nbased on RGB frame cameras. However, these approaches are constrained by the\\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\\nmotion blur, which hinder their performance. Furthermore, current attribute\\nrecognition primarily focuses on analyzing pedestrians' external appearance and\\nclothing, lacking an exploration of emotional dimensions. In this paper, we\\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\\nrecognition task by drawing inspiration from the advantages of event cameras in\\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\\nattributes related to both appearance and six human emotions, diverse scenes,\\nand various seasons. By retraining and evaluating mainstream PAR models on this\\ndataset, we establish a comprehensive benchmark and provide a solid foundation\\nfor future research in terms of data and algorithmic baselines. In addition, we\\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\\nmodule. Extensive experiments are conducted on our proposed dataset as well as\\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\\nstate-of-the-art results. The source code and dataset will be released on\\nhttps://github.com/Event-AHU/OpenPAR\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-14T09:22:16Z\"}"}
