{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11893v1\", \"title\": \"CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian\\n  Splatting\", \"summary\": \"Open-vocabulary 3D scene understanding is crucial for applications requiring\\nnatural language-driven spatial interpretation, such as robotics and augmented\\nreality. While 3D Gaussian Splatting (3DGS) offers a powerful representation\\nfor scene reconstruction, integrating it with open-vocabulary frameworks\\nreveals a key challenge: cross-view granularity inconsistency. This issue,\\nstemming from 2D segmentation methods like SAM, results in inconsistent object\\nsegmentations across views (e.g., a \\\"coffee set\\\" segmented as a single entity\\nin one view but as \\\"cup + coffee + spoon\\\" in another). Existing 3DGS-based\\nmethods often rely on isolated per-Gaussian feature learning, neglecting the\\nspatial context needed for cohesive object reasoning, leading to fragmented\\nrepresentations. We propose Context-Aware Gaussian Splatting (CAGS), a novel\\nframework that addresses this challenge by incorporating spatial context into\\n3DGS. CAGS constructs local graphs to propagate contextual features across\\nGaussians, reducing noise from inconsistent granularity, employs mask-centric\\ncontrastive learning to smooth SAM-derived features across views, and leverages\\na precomputation strategy to reduce computational cost by precomputing\\nneighborhood relationships, enabling efficient training in large-scale scenes.\\nBy integrating spatial context, CAGS significantly improves 3D instance\\nsegmentation and reduces fragmentation errors on datasets like LERF-OVS and\\nScanNet, enabling robust language-guided 3D scene understanding.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T09:20:03Z\"}"}
