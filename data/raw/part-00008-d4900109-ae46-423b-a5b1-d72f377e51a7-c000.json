{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11773v1\", \"title\": \"TacoDepth: Towards Efficient Radar-Camera Depth Estimation with\\n  One-stage Fusion\", \"summary\": \"Radar-Camera depth estimation aims to predict dense and accurate metric depth\\nby fusing input images and Radar data. Model efficiency is crucial for this\\ntask in pursuit of real-time processing on autonomous vehicles and robotic\\nplatforms. However, due to the sparsity of Radar returns, the prevailing\\nmethods adopt multi-stage frameworks with intermediate quasi-dense depth, which\\nare time-consuming and not robust. To address these challenges, we propose\\nTacoDepth, an efficient and accurate Radar-Camera depth estimation model with\\none-stage fusion. Specifically, the graph-based Radar structure extractor and\\nthe pyramid-based Radar fusion module are designed to capture and integrate the\\ngraph structures of Radar point clouds, delivering superior model efficiency\\nand robustness without relying on the intermediate depth results. Moreover,\\nTacoDepth can be flexible for different inference modes, providing a better\\nbalance of speed and accuracy. Extensive experiments are conducted to\\ndemonstrate the efficacy of our method. Compared with the previous\\nstate-of-the-art approach, TacoDepth improves depth accuracy and processing\\nspeed by 12.8% and 91.8%. Our work provides a new perspective on efficient\\nRadar-Camera depth estimation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T05:25:04Z\"}"}
