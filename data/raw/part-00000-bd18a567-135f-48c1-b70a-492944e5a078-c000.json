{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05956v1\", \"title\": \"Temporal Alignment-Free Video Matching for Few-shot Action Recognition\", \"summary\": \"Few-Shot Action Recognition (FSAR) aims to train a model with only a few\\nlabeled video instances. A key challenge in FSAR is handling divergent\\nnarrative trajectories for precise video matching. While the frame- and\\ntuple-level alignment approaches have been promising, their methods heavily\\nrely on pre-defined and length-dependent alignment units (e.g., frames or\\ntuples), which limits flexibility for actions of varying lengths and speeds. In\\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\\napproach, which eliminates the need for temporal units in action representation\\nand brute-force alignment during matching. Specifically, TEAM represents each\\nvideo with a fixed set of pattern tokens that capture globally discriminative\\nclues within the video instance regardless of action length or speed, ensuring\\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\\ncomparisons to measure similarity between videos, unlike existing methods that\\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\\nan adaptation process that identifies and removes common information across\\nclasses, establishing clear boundaries even between novel categories. Extensive\\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\\ngithub.com/leesb7426/TEAM.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-08T12:11:11Z\"}"}
