{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12718v1\", \"title\": \"TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole\\n  Slide Images of Histology\", \"summary\": \"Digital pathology, augmented by artificial intelligence (AI), holds\\nsignificant promise for improving the workflow of pathologists. However,\\nchallenges such as the labor-intensive annotation of whole slide images (WSIs),\\nhigh computational demands, and trust concerns arising from the absence of\\nuncertainty estimation in predictions hinder the practical application of\\ncurrent AI methodologies in histopathology. To address these issues, we present\\na novel trustful fully unsupervised multi-level segmentation methodology\\n(TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to\\nidentify the different tissue types within low-resolution training data. It\\nselects representative patches from each identified group based on an\\nuncertainty measure and then does unsupervised nuclei segmentation in their\\nrespective higher-resolution space without using any ML algorithms. Crucially,\\nthis solution integrates seamlessly into clinicians workflows, transforming the\\nexamination of a whole WSI into a review of concise, interpretable cross-level\\ninsights. This integration significantly enhances and accelerates the workflow\\nwhile ensuring transparency. We evaluated our approach using the UPENN-GBM\\ndataset, where the AE achieved a mean squared error (MSE) of 0.0016.\\nAdditionally, nucleus segmentation is assessed on the MoNuSeg dataset,\\noutperforming all unsupervised approaches with an F1 score of 77.46% and a\\nJaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in\\nadvancing the field of digital pathology.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.AI,cs.CV\", \"published\": \"2025-04-17T07:48:05Z\"}"}
