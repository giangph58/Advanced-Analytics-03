{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04192v1\", \"title\": \"VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video\\n  Instruction Tuning\", \"summary\": \"We present VideoPath-LLaVA, the first large multimodal model (LMM) in\\ncomputational pathology that integrates three distinct image scenarios, single\\npatch images, automatically keyframe-extracted clips, and manually segmented\\nvideo pathology images, to mimic the natural diagnostic process of\\npathologists. By generating detailed histological descriptions and culminating\\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\\nwith diagnostic reasoning.\\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\\neducational histopathology videos on YouTube. Although high-quality data is\\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\\nlimited in volume. To overcome this challenge, we transfer knowledge from\\nexisting single-image instruction datasets to train on weakly annotated,\\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\\noffers a promising foundation for future AI systems that support clinical\\ndecision-making through integrated visual and diagnostic reasoning. Our code,\\ndata, and model are publicly available at\\nhttps://github.com/trinhvg/VideoPath-LLaVA.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL\", \"published\": \"2025-05-07T07:41:19Z\"}"}
