{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10309v1\", \"title\": \"AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style\\n  Matching Text-to-Speech Synthesis\", \"summary\": \"With the advancement of speech synthesis technology, users have higher\\nexpectations for the naturalness and expressiveness of synthesized speech. But\\nprevious research ignores the importance of prompt selection. This study\\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\\nGeneration (RAG) technology, which can dynamically adjust the speech style\\naccording to the text content to achieve more natural and vivid communication\\neffects. We have constructed a speech style knowledge database containing\\nhigh-quality speech samples in various contexts and developed a style matching\\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\\nMoka, to match with samples in the knowledge database, selecting the most\\nappropriate speech style for synthesis. Furthermore, our empirical research\\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.AI\", \"published\": \"2025-04-14T15:18:59Z\"}"}
