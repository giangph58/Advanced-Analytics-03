{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15280v1\", \"title\": \"Seeing from Another Perspective: Evaluating Multi-View Understanding in\\n  MLLMs\", \"summary\": \"Multi-view understanding, the ability to reconcile visual information across\\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\\nadvances in high-level reasoning and planning, they frequently fall short when\\nconfronted with multi-view geometric consistency and cross-view correspondence.\\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\\ncarefully annotated multi-view question-answer pairs across 90 diverse\\nreal-world scenes. Our six tasks (counting, attribute identification, relative\\ndistance, relative direction, object manipulation, and camera pose estimation)\\nspecifically test model's geometric correspondence and the capacity to align\\ninformation consistently across views. Our extensive experiments, benchmark on\\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\\nGPT-4o against human evaluators reveals a substantial performance gap,\\nindicating that current MLLMs remain far from human-level proficiency. Through\\nin-depth analysis, we show that MLLMs are particularly underperforming under\\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\\nestablishing the coarse camera poses. These findings highlight the necessity of\\ndomain-specific refinements or modules that embed stronger multi-view\\nawareness. We believe that our All-Angles Bench offers valuable insights and\\ncontribute to bridging the gap between MLLMs and human-level multi-view\\nunderstanding. The project and benchmark are publicly available at\\nhttps://danielchyeh.github.io/All-Angles-Bench/.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL\", \"published\": \"2025-04-21T17:59:53Z\"}"}
