{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14847v1\", \"title\": \"Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph\\n  Reasoning\", \"summary\": \"Multi-modal data provides abundant and diverse object information, crucial\\nfor effective modal interactions in Re-Identification (ReID) tasks. However,\\nexisting approaches often overlook the quality variations in local features and\\nfail to fully leverage the complementary information across modalities,\\nparticularly in the case of low-quality features. In this paper, we propose to\\naddress this issue by leveraging a novel graph reasoning model, termed the\\nModality-aware Graph Reasoning Network (MGRNet). Specifically, we first\\nconstruct modality-aware graphs to enhance the extraction of fine-grained local\\ndetails by effectively capturing and modeling the relationships between\\npatches. Subsequently, the selective graph nodes swap operation is employed to\\nalleviate the adverse effects of low-quality local features by considering both\\nlocal and global information, enhancing the representation of discriminative\\ninformation. Finally, the swapped modality-aware graphs are fed into the\\nlocal-aware graph reasoning module, which propagates multi-modal information to\\nyield a reliable feature representation. Another advantage of the proposed\\ngraph reasoning approach is its ability to reconstruct missing modal\\ninformation by exploiting inherent structural relationships, thereby minimizing\\ndisparities between different modalities. Experimental results on four\\nbenchmarks (RGBNT201, Market1501-MM, RGBNT100, MSVR310) indicate that the\\nproposed method achieves state-of-the-art performance in multi-modal object\\nReID. The code for our method will be available upon acceptance.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T03:58:40Z\"}"}
