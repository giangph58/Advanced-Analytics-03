{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06084v1\", \"title\": \"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\\n  Egocentric Videos\", \"summary\": \"Large-scale egocentric video datasets capture diverse human activities across\\na wide range of scenarios, offering rich and detailed insights into how humans\\ninteract with objects, especially those that require fine-grained dexterous\\ncontrol. Such complex, dexterous skills with precise controls are crucial for\\nmany robotic manipulation tasks, yet are often insufficiently addressed by\\ntraditional data-driven approaches to robotic manipulation. To address this\\ngap, we leverage manipulation priors learned from large-scale egocentric video\\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\\nWe present MAPLE, a novel method for dexterous robotic manipulation that\\nexploits rich manipulation priors to enable efficient policy learning and\\nbetter performance on diverse, complex manipulation tasks. Specifically, we\\npredict hand-object contact points and detailed hand poses at the moment of\\nhand-object contact and use the learned features to train policies for\\ndownstream manipulation tasks. Experimental results demonstrate the\\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\\nnewly designed set of challenging simulation tasks, which require fine-grained\\nobject control and complex dexterous skills. The benefits of MAPLE are further\\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\\nsimultaneous evaluation across both simulation and real-world experiments has\\nremained underexplored in prior work.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.CV\", \"published\": \"2025-04-08T14:25:25Z\"}"}
