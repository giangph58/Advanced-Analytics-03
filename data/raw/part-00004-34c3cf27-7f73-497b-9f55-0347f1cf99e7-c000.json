{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19793v1\", \"title\": \"Prompt Injection Attack to Tool Selection in LLM Agents\", \"summary\": \"Tool selection is a key component of LLM agents. The process operates through\\na two-step mechanism - \\\\emph{retrieval} and \\\\emph{selection} - to pick the most\\nappropriate tool from a tool library for a given task. In this work, we\\nintroduce \\\\textit{ToolHijacker}, a novel prompt injection attack targeting tool\\nselection in no-box scenarios. ToolHijacker injects a malicious tool document\\ninto the tool library to manipulate the LLM agent's tool selection process,\\ncompelling it to consistently choose the attacker's malicious tool for an\\nattacker-chosen target task. Specifically, we formulate the crafting of such\\ntool documents as an optimization problem and propose a two-phase optimization\\nstrategy to solve it. Our extensive experimental evaluation shows that\\nToolHijacker is highly effective, significantly outperforming existing\\nmanual-based and automated prompt injection attacks when applied to tool\\nselection. Moreover, we explore various defenses, including prevention-based\\ndefenses (StruQ and SecAlign) and detection-based defenses (known-answer\\ndetection, perplexity detection, and perplexity windowed detection). Our\\nexperimental results indicate that these defenses are insufficient,\\nhighlighting the urgent need for developing new defense strategies.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-04-28T13:36:43Z\"}"}
