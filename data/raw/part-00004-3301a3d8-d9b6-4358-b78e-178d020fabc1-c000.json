{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11419v1\", \"title\": \"Embodied World Models Emerge from Navigational Task in Open-Ended\\n  Environments\", \"summary\": \"Understanding how artificial systems can develop spatial awareness and\\nreasoning has long been a challenge in AI research. Traditional models often\\nrely on passive observation, but embodied cognition theory suggests that deeper\\nunderstanding emerges from active interaction with the environment. This study\\ninvestigates whether neural networks can autonomously internalize spatial\\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\\nshow that agents can learn to encode spatial properties like direction,\\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\\nto model the agent-environment interaction as a closed dynamical system,\\nrevealing stable limit cycles that correspond to optimal navigation strategies.\\nRidge Representation allows us to map navigation paths into a fixed-dimensional\\nbehavioral space, enabling comparison with neural states. Canonical Correlation\\nAnalysis (CCA) confirms strong alignment between these representations,\\nsuggesting that the agent's neural states actively encode spatial knowledge.\\nIntervention experiments further show that specific neural dimensions are\\ncausally linked to navigation performance. This work provides an approach to\\nbridging the gap between action and perception in AI, offering new insights\\ninto building adaptive, interpretable models that can generalize across complex\\nenvironments. The causal validation of neural representations also opens new\\navenues for understanding and controlling the internal mechanisms of AI\\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\\nreal-world scenarios.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.NE\", \"published\": \"2025-04-15T17:35:13Z\"}"}
