{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12709v1\", \"title\": \"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\\n  Autonomous Driving\", \"summary\": \"The significant achievements of pre-trained models leveraging large volumes\\nof data in the field of NLP and 2D vision inspire us to explore the potential\\nof extensive data pre-training for 3D perception in autonomous driving. Toward\\nthis goal, this paper proposes to utilize massive unlabeled data from\\nheterogeneous datasets to pre-train 3D perception models. We introduce a\\nself-supervised pre-training framework that learns effective 3D representations\\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\\nadaptation strategy to reduce dataset bias. The approach significantly improves\\nmodel performance on downstream tasks such as 3D object detection, BEV\\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\\nperformance increase as the training data volume scales up, demonstrating the\\npotential of continually benefit 3D perception models for autonomous driving.\\nWe will release the source code to inspire further investigations in the\\ncommunity.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T07:26:11Z\"}"}
