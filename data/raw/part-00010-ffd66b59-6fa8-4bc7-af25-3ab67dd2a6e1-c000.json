{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06549v1\", \"title\": \"Societal Impacts Research Requires Benchmarks for Creative Composition\\n  Tasks\", \"summary\": \"Foundation models that are capable of automating cognitive tasks represent a\\npivotal technological shift, yet their societal implications remain unclear.\\nThese systems promise exciting advances, yet they also risk flooding our\\ninformation ecosystem with formulaic, homogeneous, and potentially misleading\\nsynthetic content. Developing benchmarks grounded in real use cases where these\\nrisks are most significant is therefore critical. Through a thematic analysis\\nusing 2 million language model user prompts, we identify creative composition\\ntasks as a prevalent usage category where users seek help with personal tasks\\nthat require everyday creativity. Our fine-grained analysis identifies\\nmismatches between current benchmarks and usage patterns among these tasks.\\nCrucially, we argue that the same use cases that currently lack thorough\\nevaluations can lead to negative downstream impacts. This position paper argues\\nthat benchmarks focused on creative composition tasks is a necessary step\\ntowards understanding the societal harms of AI-generated content. We call for\\ngreater transparency in usage patterns to inform the development of new\\nbenchmarks that can effectively measure both the progress and the impacts of\\nmodels with creative capabilities.\", \"main_category\": \"cs.CY\", \"categories\": \"cs.CY,cs.AI\", \"published\": \"2025-04-09T03:12:16Z\"}"}
