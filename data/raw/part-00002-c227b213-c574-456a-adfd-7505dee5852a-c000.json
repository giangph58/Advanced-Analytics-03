{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21263v1\", \"title\": \"Embracing Collaboration Over Competition: Condensing Multiple Prompts\\n  for Visual In-Context Learning\", \"summary\": \"Visual In-Context Learning (VICL) enables adaptively solving vision tasks by\\nleveraging pixel demonstrations, mimicking human-like task completion through\\nanalogy. Prompt selection is critical in VICL, but current methods assume the\\nexistence of a single \\\"ideal\\\" prompt in a pool of candidates, which in practice\\nmay not hold true. Multiple suitable prompts may exist, but individually they\\noften fall short, leading to difficulties in selection and the exclusion of\\nuseful context. To address this, we propose a new perspective: prompt\\ncondensation. Rather than relying on a single prompt, candidate prompts\\ncollaborate to efficiently integrate informative contexts without sacrificing\\nresolution. We devise Condenser, a lightweight external plugin that compresses\\nrelevant fine-grained context across multiple prompts. Optimized end-to-end\\nwith the backbone, Condenser ensures accurate integration of contextual cues.\\nExperiments demonstrate Condenser outperforms state-of-the-arts across\\nbenchmark tasks, showing superior context compression, scalability with more\\nprompts, and enhanced computational efficiency compared to ensemble methods,\\npositioning it as a highly competitive solution for VICL. Code is open-sourced\\nat https://github.com/gimpong/CVPR25-Condenser.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG,cs.MM\", \"published\": \"2025-04-30T02:43:03Z\"}"}
