{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11877v1\", \"title\": \"Benchmarking Mutual Information-based Loss Functions in Federated\\n  Learning\", \"summary\": \"Federated Learning (FL) has attracted considerable interest due to growing\\nprivacy concerns and regulations like the General Data Protection Regulation\\n(GDPR), which stresses the importance of privacy-preserving and fair machine\\nlearning approaches. In FL, model training takes place on decentralized data,\\nso as to allow clients to upload a locally trained model and receive a globally\\naggregated model without exposing sensitive information. However, challenges\\nrelated to fairness-such as biases, uneven performance among clients, and the\\n\\\"free rider\\\" issue complicates its adoption. In this paper, we examine the use\\nof Mutual Information (MI)-based loss functions to address these concerns. MI\\nhas proven to be a powerful method for measuring dependencies between variables\\nand optimizing deep learning models. By leveraging MI to extract essential\\nfeatures and minimize biases, we aim to improve both the fairness and\\neffectiveness of FL systems. Through extensive benchmarking, we assess the\\nimpact of MI-based losses in reducing disparities among clients while enhancing\\nthe overall performance of FL.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.DC\", \"published\": \"2025-04-16T08:58:44Z\"}"}
