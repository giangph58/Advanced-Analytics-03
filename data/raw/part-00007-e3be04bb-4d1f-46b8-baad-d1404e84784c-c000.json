{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10826v1\", \"title\": \"SteerMusic: Enhanced Musical Consistency for Zero-shot Text-Guided and\\n  Personalized Music Editing\", \"summary\": \"Music editing is an important step in music production, which has broad\\napplications, including game development and film production. Most existing\\nzero-shot text-guided methods rely on pretrained diffusion models by involving\\nforward-backward diffusion processes for editing. However, these methods often\\nstruggle to maintain the music content consistency. Additionally, text\\ninstructions alone usually fail to accurately describe the desired music. In\\nthis paper, we propose two music editing methods that enhance the consistency\\nbetween the original and edited music by leveraging score distillation. The\\nfirst method, SteerMusic, is a coarse-grained zero-shot editing approach using\\ndelta denoising score. The second method, SteerMusic+, enables fine-grained\\npersonalized music editing by manipulating a concept token that represents a\\nuser-defined musical style. SteerMusic+ allows for the editing of music into\\nany user-defined musical styles that cannot be achieved by the text\\ninstructions alone. Experimental results show that our methods outperform\\nexisting approaches in preserving both music content consistency and editing\\nfidelity. User studies further validate that our methods achieve superior music\\nediting quality. Audio examples are available on https://steermusic.pages.dev/.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.MM,eess.AS\", \"published\": \"2025-04-15T03:08:09Z\"}"}
