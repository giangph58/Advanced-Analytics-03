{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10400v1\", \"title\": \"Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone\", \"summary\": \"This work quantitatively evaluates the performance of event-based vision\\nsystems (EVS) against conventional RGB-based models for action prediction in\\ncollision avoidance on an FPGA accelerator. Our experiments demonstrate that\\nthe EVS model achieves a significantly higher effective frame rate (1 kHz) and\\nlower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the\\nRGB-based model, particularly when tested on out-of-distribution data. The EVS\\nmodel also exhibits superior robustness in selecting optimal evasion maneuvers.\\nIn particular, in distinguishing between movement and stationary states, it\\nachieves a 59 percentage point advantage in precision (78% vs. 19%) and a\\nsubstantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility\\nof the RGB model to overfitting. Further analysis in different combinations of\\nspatial classes confirms the consistent performance of the EVS model in both\\ntest data sets. Finally, we evaluated the system end-to-end and achieved a\\nlatency of approximately 2.14 ms, with event aggregation (1 ms) and inference\\non the processing unit (0.94 ms) accounting for the largest components. These\\nresults underscore the advantages of event-based vision for real-time collision\\navoidance and demonstrate its potential for deployment in resource-constrained\\nenvironments.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T16:51:10Z\"}"}
