{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10179v1\", \"title\": \"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance\", \"summary\": \"Multimodal Large Language Models (MLLMs) are set to transform how machines\\nprocess and generate human-like responses by integrating diverse modalities\\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\\nhinges on optimal prompt engineering. We present a comprehensive experimental\\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\\nand Integration. Our approach stratifies models by parameter count into Small\\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\\nin structured tasks such as code generation, achieving accuracies up to 96.88%\\nunder Few-Shot prompting, all models struggle with complex reasoning and\\nabstract understanding, often yielding accuracies below 60% and high\\nhallucination rates. Structured reasoning prompts frequently increased\\nhallucination up to 75% in small models and led to longer response times (over\\n20 seconds in Large MLLMs), while simpler prompting methods provided more\\nconcise and efficient outputs. No single prompting method uniformly optimises\\nall task types. Instead, adaptive strategies combining example-based guidance\\nwith selective structured reasoning are essential to enhance robustness,\\nefficiency, and factual accuracy. Our findings offer practical recommendations\\nfor prompt engineering and support more reliable deployment of MLLMs across\\napplications including AI-assisted coding, knowledge retrieval, and multimodal\\ncontent understanding.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL,cs.ET\", \"published\": \"2025-04-14T12:31:39Z\"}"}
