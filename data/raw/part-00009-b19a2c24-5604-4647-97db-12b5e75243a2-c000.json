{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03223v1\", \"title\": \"Lower Bounds for Greedy Teaching Set Constructions\", \"summary\": \"A fundamental open problem in learning theory is to characterize the\\nbest-case teaching dimension $\\\\operatorname{TS}_{\\\\min}$ of a concept class\\n$\\\\mathcal{C}$ with finite VC dimension $d$. Resolving this problem will, in\\nparticular, settle the conjectured upper bound on Recursive Teaching Dimension\\nposed by [Simon and Zilles; COLT 2015]. Prior work used a natural greedy\\nalgorithm to construct teaching sets recursively, thereby proving upper bounds\\non $\\\\operatorname{TS}_{\\\\min}$, with the best known bound being $O(d^2)$ [Hu,\\nWu, Li, and Wang; COLT 2017]. In each iteration, this greedy algorithm chooses\\nto add to the teaching set the $k$ labeled points that restrict the concept\\nclass the most. In this work, we prove lower bounds on the performance of this\\ngreedy approach for small $k$. Specifically, we show that for $k = 1$, the\\nalgorithm does not improve upon the halving-based bound of\\n$O(\\\\log(|\\\\mathcal{C}|))$. Furthermore, for $k = 2$, we complement the upper\\nbound of $O\\\\left(\\\\log(\\\\log(|\\\\mathcal{C}|))\\\\right)$ from [Moran, Shpilka,\\nWigderson, and Yuhudayoff; FOCS 2015] with a matching lower bound. Most\\nconsequentially, our lower bound extends up to $k \\\\le \\\\lceil c d \\\\rceil$ for\\nsmall constant $c>0$: suggesting that studying higher-order interactions may be\\nnecessary to resolve the conjecture that $\\\\operatorname{TS}_{\\\\min} = O(d)$.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.DS,cs.LG,math.CO\", \"published\": \"2025-05-06T06:30:01Z\"}"}
