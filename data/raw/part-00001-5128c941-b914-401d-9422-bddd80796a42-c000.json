{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05857v1\", \"title\": \"Towards an AI-Driven Video-Based American Sign Language Dictionary:\\n  Exploring Design and Usage Experience with Learners\", \"summary\": \"Searching for unfamiliar American Sign Language (ASL) signs is challenging\\nfor learners because, unlike spoken languages, they cannot type a text-based\\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\\nenabled the creation of video-based dictionaries, allowing users to submit a\\nvideo and receive a list of the closest matching signs. Previous HCI research\\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\\ndictionaries. Building on these studies, we incorporate their design\\nrecommendations and leverage state-of-the-art sign-recognition technology to\\ndevelop an automated video-based dictionary. We also present findings from an\\nobservational study with twelve novice ASL learners who used this dictionary\\nduring video-comprehension and question-answering tasks. Our results address\\nhuman-AI interaction challenges not covered in previous WoZ research, including\\nrecording and resubmitting signs, unpredictable outputs, system latency, and\\nprivacy concerns. These insights offer guidance for designing and deploying\\nvideo-based ASL dictionary systems.\", \"main_category\": \"cs.HC\", \"categories\": \"cs.HC,cs.AI\", \"published\": \"2025-04-08T09:35:46Z\"}"}
