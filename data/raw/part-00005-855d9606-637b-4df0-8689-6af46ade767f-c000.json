{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05141v1\", \"title\": \"EffOWT: Transfer Visual Language Models to Open-World Tracking\\n  Efficiently and Effectively\", \"summary\": \"Open-World Tracking (OWT) aims to track every object of any category, which\\nrequires the model to have strong generalization capabilities. Trackers can\\nimprove their generalization ability by leveraging Visual Language Models\\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\\nSpecifically, we build a small and independent learnable side network outside\\nthe VLM backbone. By freezing the backbone and only executing backpropagation\\non the side network, the model's efficiency requirements can be met. In\\naddition, EffOWT enhances the side network by proposing a hybrid structure of\\nTransformer and CNN to improve the model's performance in the OWT field.\\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\\ncategories, while only updating 1.3% of the parameters compared to full\\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\\nimprovement.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T14:47:58Z\"}"}
