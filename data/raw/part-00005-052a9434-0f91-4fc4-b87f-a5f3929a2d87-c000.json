{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21739v1\", \"title\": \"Bilateral Differentially Private Vertical Federated Boosted Decision\\n  Trees\", \"summary\": \"Federated learning is a distributed machine learning paradigm that enables\\ncollaborative training across multiple parties while ensuring data privacy.\\nGradient Boosting Decision Trees (GBDT), such as XGBoost, have gained\\npopularity due to their high performance and strong interpretability.\\nTherefore, there has been a growing interest in adapting XGBoost for use in\\nfederated settings via cryptographic techniques. However, it should be noted\\nthat these approaches may not always provide rigorous theoretical privacy\\nguarantees, and they often come with a high computational cost in terms of time\\nand space requirements. In this paper, we propose a variant of vertical\\nfederated XGBoost with bilateral differential privacy guarantee: MaskedXGBoost.\\nWe build well-calibrated noise to perturb the intermediate information to\\nprotect privacy. The noise is structured with part of its ingredients in the\\nnull space of the arithmetical operation for splitting score evaluation in\\nXGBoost, helping us achieve consistently better utility than other perturbation\\nmethods and relatively lower overhead than encryption-based techniques. We\\nprovide theoretical utility analysis and empirically verify privacy\\npreservation. Compared with other algorithms, our algorithm's superiority in\\nboth utility and efficiency has been validated on multiple datasets.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-04-30T15:37:44Z\"}"}
