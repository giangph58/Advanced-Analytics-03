{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16879v1\", \"title\": \"Learning Verifiable Control Policies Using Relaxed Verification\", \"summary\": \"To provide safety guarantees for learning-based control systems, recent work\\nhas developed formal verification methods to apply after training ends.\\nHowever, if the trained policy does not meet the specifications, or there is\\nconservatism in the verification algorithm, establishing these guarantees may\\nnot be possible. Instead, this work proposes to perform verification throughout\\ntraining to ultimately aim for policies whose properties can be evaluated\\nthroughout runtime with lightweight, relaxed verification algorithms. The\\napproach is to use differentiable reachability analysis and incorporate new\\ncomponents into the loss function. Numerical experiments on a quadrotor model\\nand unicycle model highlight the ability of this approach to lead to learned\\ncontrol policies that satisfy desired reach-avoid and invariance\\nspecifications.\", \"main_category\": \"eess.SY\", \"categories\": \"eess.SY,cs.LG,cs.SY\", \"published\": \"2025-04-23T16:54:35Z\"}"}
