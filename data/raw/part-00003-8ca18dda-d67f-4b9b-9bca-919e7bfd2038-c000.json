{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04621v1\", \"title\": \"Score Distillation Sampling for Audio: Source Separation, Synthesis, and\\n  Beyond\", \"summary\": \"We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\\nto text-conditioned audio diffusion models. While SDS was initially designed\\nfor text-to-3D generation using image diffusion, its core idea of distilling a\\npowerful generative prior into a separate parametric representation extends to\\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\\nbroad range of tasks without requiring specialized datasets. In particular, we\\ndemonstrate how Audio-SDS can guide physically informed impact sound\\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\\nsource separation. Our findings illustrate the versatility of\\ndistillation-based methods across modalities and establish a robust foundation\\nfor future work using generative priors in audio tasks.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.AI,cs.LG,cs.MM,eess.AS\", \"published\": \"2025-05-07T17:59:38Z\"}"}
