{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05098v1\", \"title\": \"X-Driver: Explainable Autonomous Driving with Vision-Language Models\", \"summary\": \"End-to-end autonomous driving has advanced significantly, offering benefits\\nsuch as system simplicity and stronger driving performance in both open-loop\\nand closed-loop settings than conventional pipelines. However, existing\\nframeworks still suffer from low success rates in closed-loop evaluations,\\nhighlighting their limitations in real-world deployment. In this paper, we\\nintroduce X-Driver, a unified multi-modal large language models(MLLMs)\\nframework designed for closed-loop autonomous driving, leveraging\\nChain-of-Thought(CoT) and autoregressive modeling to enhance perception and\\ndecision-making. We validate X-Driver across multiple autonomous driving tasks\\nusing public benchmarks in CARLA simulation environment, including\\nBench2Drive[6]. Our experimental results demonstrate superior closed-loop\\nperformance, surpassing the current state-of-the-art(SOTA) while improving the\\ninterpretability of driving decisions. These findings underscore the importance\\nof structured reasoning in end-to-end driving and establish X-Driver as a\\nstrong baseline for future research in closed-loop autonomous driving.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.CL,cs.CV,cs.ET\", \"published\": \"2025-05-08T09:52:55Z\"}"}
