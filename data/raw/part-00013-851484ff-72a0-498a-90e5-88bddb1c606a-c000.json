{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04175v1\", \"title\": \"DOTA: Deformable Optimized Transformer Architecture for End-to-End Text\\n  Recognition with Retrieval-Augmented Generation\", \"summary\": \"Text recognition in natural images remains a challenging yet essential task,\\nwith broad applications spanning computer vision and natural language\\nprocessing. This paper introduces a novel end-to-end framework that combines\\nResNet and Vision Transformer backbones with advanced methodologies, including\\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\\nFields (CRF). These innovations collectively enhance feature representation and\\nimprove Optical Character Recognition (OCR) performance. Specifically, the\\nframework substitutes standard convolution layers in the third and fourth\\nblocks with Deformable Convolutions, leverages adaptive dropout for\\nregularization, and incorporates CRF for more refined sequence modeling.\\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\\nof 77.77%. These results establish a new state-of-the-art for text recognition,\\ndemonstrating the robustness of the approach across diverse and challenging\\ndatasets.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-05-07T07:06:04Z\"}"}
