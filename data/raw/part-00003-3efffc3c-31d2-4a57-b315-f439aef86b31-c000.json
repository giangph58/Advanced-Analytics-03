{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10478v1\", \"title\": \"Weight Ensembling Improves Reasoning in Language Models\", \"summary\": \"We investigate a failure mode that arises during the training of reasoning\\nmodels, where the diversity of generations begins to collapse, leading to\\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\\nsimple intervention of interpolating the weights of the latest SFT checkpoint\\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\\nwith less data when tuned further by reinforcement learning. Finally, we find\\nthat WiSE-FT provides complementary performance gains that cannot be achieved\\nonly through diversity-inducing decoding strategies, like temperature scaling.\\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\\nreduce bias and variance simultaneously, while temperature scaling inherently\\ntrades-off between bias and variance.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-14T17:59:07Z\"}"}
