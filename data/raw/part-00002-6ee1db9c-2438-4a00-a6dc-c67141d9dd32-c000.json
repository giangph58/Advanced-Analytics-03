{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12167v1\", \"title\": \"RADLER: Radar Object Detection Leveraging Semantic 3D City Models and\\n  Self-Supervised Radar-Image Learning\", \"summary\": \"Semantic 3D city models are worldwide easy-accessible, providing accurate,\\nobject-oriented, and semantic-rich 3D priors. To date, their potential to\\nmitigate the noise impact on radar object detection remains under-explored. In\\nthis paper, we first introduce a unique dataset, RadarCity, comprising 54K\\nsynchronized radar-image pairs and semantic 3D city models. Moreover, we\\npropose a novel neural network, RADLER, leveraging the effectiveness of\\ncontrastive self-supervised learning (SSL) and semantic 3D city models to\\nenhance radar object detection of pedestrians, cyclists, and cars.\\nSpecifically, we first obtain the robust radar features via a SSL network in\\nthe radar-image pretext task. We then use a simple yet effective feature fusion\\nstrategy to incorporate semantic-depth features from semantic 3D city models.\\nHaving prior 3D information as guidance, RADLER obtains more fine-grained\\ndetails to enhance radar object detection. We extensively evaluate RADLER on\\nthe collected RadarCity dataset and demonstrate average improvements of 5.46%\\nin mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over\\nprevious radar object detection methods. We believe this work will foster\\nfurther research on semantic-guided and map-supported radar object detection.\\nOur project page is publicly available\\nathttps://gpp-communication.github.io/RADLER .\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-04-16T15:18:56Z\"}"}
