{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04915v1\", \"title\": \"Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question\\n  Answering via White-Box and Black-Box LLM Collaboration\", \"summary\": \"Retrieval-Augmented Generation (RAG) systems often struggle to handle\\nmulti-hop question-answering tasks accurately due to irrelevant context\\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\\na collaborative training framework that leverages mutual enhancement between a\\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\\nprovides feedback signals to improve the SLM's decomposition capability. We\\nobserve that Collab-RAG relies solely on supervision from an affordable\\nblack-box LLM without additional distillation from frontier LLMs, yet\\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.IR,cs.LG\", \"published\": \"2025-04-07T10:52:22Z\"}"}
