{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15629v1\", \"title\": \"CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation\\n  Correction\", \"summary\": \"Retrieval Augmented Generation (RAG) has emerged as a powerful application of\\nLarge Language Models (LLMs), revolutionizing information search and\\nconsumption. RAG systems combine traditional search capabilities with LLMs to\\ngenerate comprehensive answers to user queries, ideally with accurate\\ncitations. However, in our experience of developing a RAG product, LLMs often\\nstruggle with source attribution, aligning with other industry studies\\nreporting citation accuracy rates of only about 74% for popular generative\\nsearch engines. To address this, we present efficient post-processing\\nalgorithms to improve citation accuracy in LLM-generated responses, with\\nminimal impact on latency and cost. Our approaches cross-check generated\\ncitations against retrieved articles using methods including keyword + semantic\\nmatching, fine tuned model with BERTScore, and a lightweight LLM-based\\ntechnique. Our experimental results demonstrate a relative improvement of\\n15.46% in the overall accuracy metrics of our RAG system. This significant\\nenhancement potentially enables a shift from our current larger language model\\nto a relatively smaller model that is approximately 12x more cost-effective and\\n3x faster in inference time, while maintaining comparable performance. This\\nresearch contributes to enhancing the reliability and trustworthiness of\\nAI-generated content in information retrieval and summarization tasks which is\\ncritical to gain customer trust especially in commercial products.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.CL\", \"published\": \"2025-04-22T06:41:25Z\"}"}
