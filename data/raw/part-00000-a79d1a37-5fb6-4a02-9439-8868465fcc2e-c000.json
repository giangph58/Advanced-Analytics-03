{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11160v1\", \"title\": \"DMAGaze: Gaze Estimation Based on Feature Disentanglement and\\n  Multi-Scale Attention\", \"summary\": \"Gaze estimation, which predicts gaze direction, commonly faces the challenge\\nof interference from complex gaze-irrelevant information in face images. In\\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\\ninformation from facial images in three aspects: gaze-relevant global features\\n(disentangled from facial image), local eye features (extracted from cropped\\neye patch), and head pose estimation features, to improve overall performance.\\nFirstly, we design a new continuous mask-based Disentangler to accurately\\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\\nachieving the dual-branch disentanglement goal through separately\\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\\ncascaded attention module named Multi-Scale Global Local Attention Module\\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\\nfocuses on global and local information at multiple scales, further enhancing\\nthe information from the Disentangler. Finally, the global gaze-relevant\\nfeatures disentangled by the upper face branch, combined with head pose and\\nlocal eye features, are passed through the detection head for high-precision\\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\\nmainstream public datasets, achieving state-of-the-art performance.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-15T13:08:43Z\"}"}
