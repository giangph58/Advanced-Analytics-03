{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07524v1\", \"title\": \"DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy\\n  Prediction\", \"summary\": \"Monocular 3D occupancy prediction, aiming to predict the occupancy and\\nsemantics within interesting regions of 3D scenes from only 2D images, has\\ngarnered increasing attention recently for its vital role in 3D scene\\nunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from\\n2D images is ill-posed and resource-intensive. In this paper, we present\\n\\\\textbf{DGOcc}, a \\\\textbf{D}epth-aware \\\\textbf{G}lobal query-based network for\\nmonocular 3D \\\\textbf{Occ}upancy prediction. We first explore prior depth maps\\nto extract depth context features that provide explicit geometric information\\nfor the occupancy network. Then, in order to fully exploit the depth context\\nfeatures, we propose a Global Query-based (GQ) Module. The cooperation of\\nattention mechanisms and scale-aware operations facilitates the feature\\ninteraction between images and 3D voxels. Moreover, a Hierarchical Supervision\\nStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxel\\nfeatures to full resolution, which mitigates GPU memory utilization and time\\ncost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasets\\ndemonstrate that the proposed method achieves the best performance on monocular\\nsemantic occupancy prediction while reducing GPU and time overhead.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-10T07:44:55Z\"}"}
