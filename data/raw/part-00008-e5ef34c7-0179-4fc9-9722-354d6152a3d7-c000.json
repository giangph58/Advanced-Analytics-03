{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12749v1\", \"title\": \"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical\\n  Anomaly Detection\", \"summary\": \"Recent advances in industrial anomaly detection have highlighted the need for\\ndeeper logical anomaly analysis, where unexpected relationships among objects,\\ncounts, and spatial configurations must be identified and explained. Existing\\napproaches often rely on large-scale external reasoning modules or elaborate\\npipeline designs, hindering practical deployment and interpretability. To\\naddress these limitations, we introduce a new task, Reasoning Logical Anomaly\\nDetection (RLAD), which extends traditional anomaly detection by incorporating\\nlogical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny\\nmultimodal language model built on Qwen2.5-VL 3B. Our approach leverages a\\ntwo-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for\\nfine-grained visual understanding, followed by Group Relative Policy\\nOptimization (GRPO) to refine logical anomaly detection and enforce coherent,\\nhuman-readable reasoning. Crucially, reward signals are derived from both the\\ndetection accuracy and the structural quality of the outputs, obviating the\\nneed for building chain of thought (CoT) reasoning data. Experiments on the\\nMVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller,\\nmatches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further\\nexcels in producing concise and interpretable rationales. This unified design\\nreduces reliance on large models and complex pipelines, while offering\\ntransparent and interpretable insights into logical anomaly detection. Code and\\ndata will be released.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T08:41:23Z\"}"}
