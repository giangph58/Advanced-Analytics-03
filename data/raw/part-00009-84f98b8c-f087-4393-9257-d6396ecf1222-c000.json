{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13035v1\", \"title\": \"Prototypes are Balanced Units for Efficient and Effective Partially\\n  Relevant Video Retrieval\", \"summary\": \"In a retrieval system, simultaneously achieving search accuracy and\\nefficiency is inherently challenging. This challenge is particularly pronounced\\nin partially relevant video retrieval (PRVR), where incorporating more diverse\\ncontext representations at varying temporal scales for each video enhances\\naccuracy but increases computational and memory costs. To address this\\ndichotomy, we propose a prototypical PRVR framework that encodes diverse\\ncontexts within a video into a fixed number of prototypes. We then introduce\\nseveral strategies to enhance text association and video understanding within\\nthe prototypes, along with an orthogonal objective to ensure that the\\nprototypes capture a diverse range of content. To keep the prototypes\\nsearchable via text queries while accurately encoding video contexts, we\\nimplement cross- and uni-modal reconstruction tasks. The cross-modal\\nreconstruction task aligns the prototypes with textual features within a shared\\nspace, while the uni-modal reconstruction task preserves all video contexts\\nduring encoding. Additionally, we employ a video mixing technique to provide\\nweak guidance to further align prototypes and associated textual\\nrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, and\\nQVHighlights validate the effectiveness of our approach without sacrificing\\nefficiency.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-17T15:43:29Z\"}"}
