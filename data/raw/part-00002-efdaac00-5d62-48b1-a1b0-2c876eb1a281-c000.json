{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06134v1\", \"title\": \"SpikeStream: Accelerating Spiking Neural Network Inference on RISC-V\\n  Clusters with Sparse Computation Extensions\", \"summary\": \"Spiking Neural Network (SNN) inference has a clear potential for high energy\\nefficiency as computation is triggered by events. However, the inherent\\nsparsity of events poses challenges for conventional computing systems, driving\\nthe development of specialized neuromorphic processors, which come with high\\nsilicon area costs and lack the flexibility needed for running other\\ncomputational kernels, limiting widespread adoption. In this paper, we explore\\nthe low-level software design, parallelization, and acceleration of SNNs on\\ngeneral-purpose multicore clusters with a low-overhead RISC-V ISA extension for\\nstreaming sparse computations. We propose SpikeStream, an optimization\\ntechnique that maps weights accesses to affine and indirect register-mapped\\nmemory streams to enhance performance, utilization, and efficiency. Our results\\non the end-to-end Spiking-VGG11 model demonstrate a significant 4.39x speedup\\nand an increase in utilization from 9.28% to 52.3% compared to a non-streaming\\nparallel baseline. Additionally, we achieve an energy efficiency gain of 3.46x\\nover LSMCore and a performance gain of 2.38x over Loihi.\", \"main_category\": \"cs.AR\", \"categories\": \"cs.AR\", \"published\": \"2025-04-08T15:28:44Z\"}"}
