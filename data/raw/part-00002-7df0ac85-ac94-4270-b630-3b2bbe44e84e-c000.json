{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17356v1\", \"title\": \"Comprehend, Divide, and Conquer: Feature Subspace Exploration via\\n  Multi-Agent Hierarchical Reinforcement Learning\", \"summary\": \"Feature selection aims to preprocess the target dataset, find an optimal and\\nmost streamlined feature subset, and enhance the downstream machine learning\\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\\nlearning (RL)-based subspace exploration strategy provides a novel objective\\noptimization-directed perspective and promising performance. Nevertheless, even\\nwith improved performance, current reinforcement learning approaches face\\nchallenges similar to conventional methods when dealing with complex datasets.\\nThese challenges stem from the inefficient paradigm of using one agent per\\nfeature and the inherent complexities present in the datasets. This observation\\nmotivates us to investigate and address the above issue and propose a novel\\napproach, namely HRLFS. Our methodology initially employs a Large Language\\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\\nand semantic characteristics. Based on this information, features are\\nclustered, facilitating the construction of hierarchical agents for each\\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\\nscalability, and robustness of our approach. Compared to contemporary or the\\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\\nperformance with iterative feature subspace exploration while accelerating\\ntotal run time by reducing the number of agents involved.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.LG\", \"published\": \"2025-04-24T08:16:36Z\"}"}
