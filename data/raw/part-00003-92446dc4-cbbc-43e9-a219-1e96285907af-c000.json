{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13152v1\", \"title\": \"St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World\", \"summary\": \"Dynamic 3D reconstruction and point tracking in videos are typically treated\\nas separate tasks, despite their deep connection. We propose St4RTrack, a\\nfeed-forward framework that simultaneously reconstructs and tracks dynamic\\nvideo content in a world coordinate frame from RGB inputs. This is achieved by\\npredicting two appropriately defined pointmaps for a pair of frames captured at\\ndifferent moments. Specifically, we predict both pointmaps at the same moment,\\nin the same world, capturing both static and dynamic scene geometry while\\nmaintaining 3D correspondences. Chaining these predictions through the video\\nsequence with respect to a reference frame naturally computes long-range\\ncorrespondences, effectively combining 3D reconstruction with 3D tracking.\\nUnlike prior methods that rely heavily on 4D ground truth supervision, we\\nemploy a novel adaptation scheme based on a reprojection loss. We establish a\\nnew extensive benchmark for world-frame reconstruction and tracking,\\ndemonstrating the effectiveness and efficiency of our unified, data-driven\\nframework. Our code, model, and benchmark will be released.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T17:55:58Z\"}"}
