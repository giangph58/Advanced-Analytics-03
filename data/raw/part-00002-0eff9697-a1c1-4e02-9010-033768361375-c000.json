{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20896v1\", \"title\": \"LELANTE: LEveraging LLM for Automated ANdroid TEsting\", \"summary\": \"Given natural language test case description for an Android application,\\nexisting testing approaches require developers to manually write scripts using\\ntools such as Appium and Espresso to execute the corresponding test case. This\\nprocess is labor-intensive and demands significant effort to maintain as UI\\ninterfaces evolve throughout development. In this work, we introduce LELANTE, a\\nnovel framework that utilizes large language models (LLMs) to automate test\\ncase execution without requiring pre-written scripts. LELANTE interprets\\nnatural language test case descriptions, iteratively generate action plans, and\\nperform the actions directly on the Android screen using its GUI. LELANTE\\nemploys a screen refinement process to enhance LLM interpretability, constructs\\na structured prompt for LLMs, and implements an action generation mechanism\\nbased on chain-of-thought reasoning of LLMs. To further reduce computational\\ncost and enhance scalability, LELANTE utilizes model distillation using a\\nfoundational LLM. In experiments across 390 test cases spanning 10 popular\\nAndroid applications, LELANTE achieved a 73% test execution success rate. Our\\nresults demonstrate that LLMs can effectively bridge the gap between natural\\nlanguage test case description and automated execution, making mobile testing\\nmore scalable and adaptable.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-29T16:13:49Z\"}"}
