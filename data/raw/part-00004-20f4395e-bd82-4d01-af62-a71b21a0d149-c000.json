{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05031v1\", \"title\": \"LSRP: A Leader-Subordinate Retrieval Framework for Privacy-Preserving\\n  Cloud-Device Collaboration\", \"summary\": \"Cloud-device collaboration leverages on-cloud Large Language Models (LLMs)\\nfor handling public user queries and on-device Small Language Models (SLMs) for\\nprocessing private user data, collectively forming a powerful and\\nprivacy-preserving solution. However, existing approaches often fail to fully\\nleverage the scalable problem-solving capabilities of on-cloud LLMs while\\nunderutilizing the advantage of on-device SLMs in accessing and processing\\npersonalized data. This leads to two interconnected issues: 1) Limited\\nutilization of the problem-solving capabilities of on-cloud LLMs, which fail to\\nalign with personalized user-task needs, and 2) Inadequate integration of user\\ndata into on-device SLM responses, resulting in mismatches in contextual user\\ninformation.\\n  In this paper, we propose a Leader-Subordinate Retrieval framework for\\nPrivacy-preserving cloud-device collaboration (LSRP), a novel solution that\\nbridges these gaps by: 1) enhancing on-cloud LLM guidance to on-device SLM\\nthrough a dynamic selection of task-specific leader strategies named as\\nuser-to-user retrieval-augmented generation (U-U-RAG), and 2) integrating the\\ndata advantages of on-device SLMs through small model feedback Direct\\nPreference Optimization (SMFB-DPO) for aligning the on-cloud LLM with the\\non-device SLM. Experiments on two datasets demonstrate that LSRP consistently\\noutperforms state-of-the-art baselines, significantly improving question-answer\\nrelevance and personalization, while preserving user privacy through efficient\\non-device retrieval. Our code is available at:\\nhttps://github.com/Zhang-Yingyi/LSRP.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-05-08T08:06:34Z\"}"}
