{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07027v1\", \"title\": \"Using ML filters to help automated vulnerability repairs: when it helps\\n  and when it doesn't\", \"summary\": \"[Context:] The acceptance of candidate patches in automated program repair\\nhas been typically based on testing oracles. Testing requires typically a\\ncostly process of building the application while ML models can be used to\\nquickly classify patches, thus allowing more candidate patches to be generated\\nin a positive feedback loop. [Problem:] If the model predictions are unreliable\\n(as in vulnerability detection) they can hardly replace the more reliable\\noracles based on testing. [New Idea:] We propose to use an ML model as a\\npreliminary filter of candidate patches which is put in front of a traditional\\nfilter based on testing. [Preliminary Results:] We identify some theoretical\\nbounds on the precision and recall of the ML algorithm that makes such\\noperation meaningful in practice. With these bounds and the results published\\nin the literature, we calculate how fast some of state-of-the art vulnerability\\ndetectors must be to be more effective over a traditional AVR pipeline such as\\nAPR4Vuln based just on testing.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.CR,cs.LG\", \"published\": \"2025-04-09T16:39:09Z\"}"}
