{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21836v1\", \"title\": \"3D Stylization via Large Reconstruction Model\", \"summary\": \"With the growing success of text or image guided 3D generators, users demand\\nmore control over the generation process, appearance stylization being one of\\nthem. Given a reference image, this requires adapting the appearance of a\\ngenerated 3D asset to reflect the visual style of the reference while\\nmaintaining visual consistency from multiple viewpoints. To tackle this\\nproblem, we draw inspiration from the success of 2D stylization methods that\\nleverage the attention mechanisms in large image generation models to capture\\nand transfer visual style. In particular, we probe if large reconstruction\\nmodels, commonly used in the context of 3D generation, has a similar\\ncapability. We discover that the certain attention blocks in these models\\ncapture the appearance specific features. By injecting features from a visual\\nstyle image to such blocks, we develop a simple yet effective 3D appearance\\nstylization method. Our method does not require training or test time\\noptimization. Through both quantitative and qualitative evaluations, we\\ndemonstrate that our approach achieves superior results in terms of 3D\\nappearance stylization, significantly improving efficiency while maintaining\\nhigh-quality visual outcomes.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T17:46:32Z\"}"}
