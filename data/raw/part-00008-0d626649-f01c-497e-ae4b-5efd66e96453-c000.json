{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04146v1\", \"title\": \"Unmasking the Canvas: A Dynamic Benchmark for Image Generation\\n  Jailbreaking and LLM Content Safety\", \"summary\": \"Existing large language models (LLMs) are advancing rapidly and produce\\noutstanding results in image generation tasks, yet their content safety checks\\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\\nnatural prompts could lead to the generation of compromising images ranging\\nfrom realistic depictions of forged documents to manipulated images of public\\nfigures.\\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\\nOur methodology combines structured prompt engineering, multilingual\\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\\nstrategies, risk scoring, and automated tagging. All generations are stored\\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\\nover time with new data sources, prompt templates, and model behaviors.\\n  Warning: This paper includes visual examples of adversarial inputs designed\\nto test model safety. All outputs have been redacted to ensure responsible\\ndisclosure.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.CY\", \"published\": \"2025-05-07T05:54:04Z\"}"}
