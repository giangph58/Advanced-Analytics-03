{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21773v1\", \"title\": \"MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\\n  Knowledge Boundary Awareness\", \"summary\": \"With the widespread application of large language models (LLMs), the issue of\\ngenerating non-existing facts, known as hallucination, has garnered increasing\\nattention. Previous research in enhancing LLM confidence estimation mainly\\nfocuses on the single problem setting. However, LLM awareness of its internal\\nparameterized knowledge boundary under the more challenging multi-problem\\nsetting, which requires answering multiple problems accurately simultaneously,\\nremains underexplored. To bridge this gap, we introduce a novel method,\\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\\nthe learning of answer prediction and confidence estimation during fine-tuning\\non instruction data. Extensive experiments demonstrate that our method\\noutperforms baselines by up to 25% in average precision.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-30T16:17:53Z\"}"}
