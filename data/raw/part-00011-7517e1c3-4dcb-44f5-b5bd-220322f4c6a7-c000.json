{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03383v1\", \"title\": \"Attention-aggregated Attack for Boosting the Transferability of Facial\\n  Adversarial Examples\", \"summary\": \"Adversarial examples have revealed the vulnerability of deep learning models\\nand raised serious concerns about information security. The transfer-based\\nattack is a hot topic in black-box attacks that are practical to real-world\\nscenarios where the training datasets, parameters, and structure of the target\\nmodel are unknown to the attacker. However, few methods consider the\\nparticularity of class-specific deep models for fine-grained vision tasks, such\\nas face recognition (FR), giving rise to unsatisfactory attacking performance.\\nIn this work, we first investigate what in a face exactly contributes to the\\nembedding learning of FR models and find that both decisive and auxiliary\\nfacial features are specific to each FR model, which is quite different from\\nthe biological mechanism of human visual system. Accordingly we then propose a\\nnovel attack method named Attention-aggregated Attack (AAA) to enhance the\\ntransferability of adversarial examples against FR, which is inspired by the\\nattention divergence and aims to destroy the facial features that are critical\\nfor the decision-making of other FR models by imitating their attentions on the\\nclean face images. Extensive experiments conducted on various FR models\\nvalidate the superiority and robust effectiveness of the proposed method over\\nexisting methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T10:02:56Z\"}"}
