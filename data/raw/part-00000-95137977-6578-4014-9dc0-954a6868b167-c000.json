{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03201v1\", \"title\": \"Weighted Average Gradients for Feature Attribution\", \"summary\": \"In explainable AI, Integrated Gradients (IG) is a widely adopted technique\\nfor assessing the significance of feature attributes of the input on model\\noutputs by evaluating contributions from a baseline input to the current input.\\nThe choice of the baseline input significantly influences the resulting\\nexplanation. While the traditional Expected Gradients (EG) method assumes\\nbaselines can be uniformly sampled and averaged with equal weights, this study\\nargues that baselines should not be treated equivalently. We introduce Weighted\\nAverage Gradients (WG), a novel approach that unsupervisedly evaluates baseline\\nsuitability and incorporates a strategy for selecting effective baselines.\\nTheoretical analysis demonstrates that WG satisfies essential explanation\\nmethod criteria and offers greater stability than prior approaches.\\nExperimental results further confirm that WG outperforms EG across diverse\\nscenarios, achieving an improvement of 10-35\\\\% on main metrics. Moreover, by\\nevaluating baselines, our method can filter a subset of effective baselines for\\neach input to calculate explanations, maintaining high accuracy while reducing\\ncomputational cost. The code is available at:\\nhttps://github.com/Tamnt240904/weighted_baseline.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG\", \"published\": \"2025-05-06T05:36:47Z\"}"}
