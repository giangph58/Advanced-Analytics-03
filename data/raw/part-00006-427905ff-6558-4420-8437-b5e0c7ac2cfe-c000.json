{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04539v1\", \"title\": \"Qualitative Analysis of $\\u03c9$-Regular Objectives on Robust MDPs\", \"summary\": \"Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\\nconsider uncertainties in transition probabilities by defining a set of\\npossible transition functions. An objective is a set of runs (or infinite\\ntrajectories) of the RMDP, and the value for an objective is the maximal\\nprobability that the agent can guarantee against the adversarial environment.\\nWe consider (a) reachability objectives, where given a target set of states,\\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\\nwhich are a canonical representation for $\\\\omega$-regular objectives. The\\nqualitative analysis problem asks whether the objective can be ensured with\\nprobability 1.\\n  In this work, we study the qualitative problem for reachability and parity\\nobjectives on RMDPs without making any assumption over the structures of the\\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\\npresent efficient algorithms with oracle access to uncertainty sets that solve\\nqualitative problems of reachability and parity objectives. We then report\\nexperimental results demonstrating the effectiveness of our oracle-based\\napproach on classical RMDP examples from the literature scaling up to thousands\\nof states.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-05-07T16:15:40Z\"}"}
