{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16411v1\", \"title\": \"Out-of-the-Box Conditional Text Embeddings from Large Language Models\", \"summary\": \"Conditional text embedding is a proposed representation that captures the\\nshift in perspective on texts when conditioned on a specific aspect. Previous\\nmethods have relied on extensive training data for fine-tuning models, leading\\nto challenges in terms of labor and resource costs. We propose PonTE, a novel\\nunsupervised conditional text embedding method that leverages a causal large\\nlanguage model and a conditional prompt. Through experiments on conditional\\nsemantic text similarity and text clustering, we demonstrate that PonTE can\\ngenerate useful conditional text embeddings and achieve performance comparable\\nto supervised methods without fine-tuning. We also show the interpretability of\\ntext embeddings with PonTE by analyzing word generation following prompts and\\nembedding visualization.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-23T04:27:15Z\"}"}
