{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24354v1\", \"title\": \"ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent\\n  Diffusion\", \"summary\": \"Parameter generation has emerged as a novel paradigm for neural network\\ndevelopment, offering an alternative to traditional neural network training by\\nsynthesizing high-quality model weights directly. In the context of Low-Rank\\nAdaptation (LoRA) for evolving ($\\\\textit{i.e.}$, constantly updated) large\\nlanguage models (LLMs), this approach promises efficient adaptation without\\ncostly retraining. However, existing methods face critical limitations in\\nsimultaneously achieving scalability and controllability. In this paper, we\\nintroduce $\\\\texttt{ORAL}$, a novel $\\\\textbf{conditional recurrent diffusion}$\\nframework that addresses these challenges. $\\\\texttt{ORAL}$ incorporates a novel\\nconditioning mechanism that integrates model architecture and textual task\\nspecifications, enabling the generation of task-specific LoRA parameters that\\ncan seamlessly transfer across evolving foundation models. Our approach\\nsuccessfully scales to billions-of-parameter LLMs and maintains\\ncontrollability. Through extensive experiments across seven language tasks,\\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\\ndemonstrate that $\\\\texttt{ORAL}$ generates high-quality LoRA parameters that\\nachieve comparable or superior performance to vanilla trained counterparts.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CL,cs.CV\", \"published\": \"2025-03-31T17:34:59Z\"}"}
