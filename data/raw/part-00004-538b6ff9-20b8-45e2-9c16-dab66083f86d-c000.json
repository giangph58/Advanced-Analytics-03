{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02545v1\", \"title\": \"MAD: Makeup All-in-One with Cross-Domain Diffusion Model\", \"summary\": \"Existing makeup techniques often require designing multiple models to handle\\ndifferent inputs and align features across domains for different makeup tasks,\\ne.g., beauty filter, makeup transfer, and makeup removal, leading to increased\\ncomplexity. Another limitation is the absence of text-guided makeup try-on,\\nwhich is more user-friendly without needing reference images. In this study, we\\nmake the first attempt to use a single model for various makeup tasks.\\nSpecifically, we formulate different makeup tasks as cross-domain translations\\nand leverage a cross-domain diffusion model to accomplish all tasks. Unlike\\nexisting methods that rely on separate encoder-decoder configurations or\\ncycle-based mechanisms, we propose using different domain embeddings to\\nfacilitate domain control. This allows for seamless domain switching by merely\\nchanging embeddings with a single model, thereby reducing the reliance on\\nadditional modules for different tasks. Moreover, to support precise\\ntext-to-makeup applications, we introduce the MT-Text dataset by extending the\\nMT dataset with textual annotations, advancing the practicality of makeup\\ntechnologies.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T12:52:31Z\"}"}
