{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03532v1\", \"title\": \"Joint Generalized Cosine Similarity: A Novel Method for N-Modal Semantic\\n  Alignment Based on Contrastive Learning\", \"summary\": \"Alignment remains a crucial task in multi-modal deep learning, and\\ncontrastive learning has been widely applied in this field. However, when there\\nare more than two modalities, existing methods typically calculate pairwise\\nloss function and aggregate them into a composite loss function for the\\noptimization of model parameters. This limitation mainly stems from the\\ndrawbacks of traditional similarity measurement method (i.e. they can only\\ncalculate the similarity between two vectors). To address this issue, we\\npropose a novel similarity measurement method: the Joint Generalized Cosine\\nSimilarity (JGCS). Unlike traditional pairwise methods (e.g., dot product or\\ncosine similarity), JGCS centers around the angle derived from the Gram\\ndeterminant. To the best of our knowledge, this is the first similarity\\nmeasurement method capable of handling tasks involving an arbitrary number of\\nvectors. Based on this, we introduce the corresponding contrastive learning\\nloss function , GHA Loss, and the new inter-modal contrastive learning\\nparadigm. Additionally, comprehensive experiments conducted on the Derm7pt\\ndataset and simulated datasets demonstrate that our method achieves superior\\nperformance while exhibiting remarkable advantages such as noise robustness,\\ncomputational efficiency, and scalability. Finally, it is worth mentioning that\\nthe Joint Generalized Cosine Similarity proposed by us can not only be applied\\nin contrastive learning, but also be easily extended to other domains.\", \"main_category\": \"stat.AP\", \"categories\": \"stat.AP\", \"published\": \"2025-05-06T13:41:31Z\"}"}
