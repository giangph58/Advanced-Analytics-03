{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16922v1\", \"title\": \"Generalized Neighborhood Attention: Multi-dimensional Sparse Attention\\n  at the Speed of Light\", \"summary\": \"Many sparse attention mechanisms such as Neighborhood Attention have\\ntypically failed to consistently deliver speedup over the self attention\\nbaseline. This is largely due to the level of complexity in attention\\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\\nsame time, many state-of-the-art foundational models, particularly in computer\\nvision, are heavily bound by attention, and need reliable sparsity to escape\\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\\nattention mechanisms that focus on locality, and aim to develop a better\\nanalytical model of their performance improvements. We first introduce\\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\\nstrided sliding window, and blocked attention. We then consider possible design\\nchoices in implementing these approaches, and create a simulator that can\\nprovide much more realistic speedup upper bounds for any given setting.\\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\\npossible in many perfectly block-sparse cases, and achieves an effective\\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\\nspeedup on B200 without any fine-tuning. We will open source our simulator and\\nBlackwell kernels directly through the NATTEN project.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-23T17:49:53Z\"}"}
