{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14826v1\", \"title\": \"Distribution-aware Dataset Distillation for Efficient Image Restoration\", \"summary\": \"With the exponential increase in image data, training an image restoration\\nmodel is laborious. Dataset distillation is a potential solution to this\\nproblem, yet current distillation techniques are a blank canvas in the field of\\nimage restoration. To fill this gap, we propose the Distribution-aware Dataset\\nDistillation method (TripleD), a new framework that extends the principles of\\ndataset distillation to image restoration. Specifically, TripleD uses a\\npre-trained vision Transformer to extract features from images for complexity\\nevaluation, and the subset (the number of samples is much smaller than the\\noriginal training set) is selected based on complexity. The selected subset is\\nthen fed through a lightweight CNN that fine-tunes the image distribution to\\nalign with the distribution of the original dataset at the feature level. To\\nefficiently condense knowledge, the training is divided into two stages. Early\\nstages focus on simpler, low-complexity samples to build foundational\\nknowledge, while later stages select more complex and uncertain samples as the\\nmodel matures. Our method achieves promising performance on multiple image\\nrestoration tasks, including multi-task image restoration, all-in-one image\\nrestoration, and ultra-high-definition image restoration tasks. Note that we\\ncan train a state-of-the-art image restoration model on an\\nultra-high-definition (4K resolution) dataset using only one consumer-grade GPU\\nin less than 8 hours (500 savings in computing resources and immeasurable\\ntraining time).\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T03:00:18Z\"}"}
