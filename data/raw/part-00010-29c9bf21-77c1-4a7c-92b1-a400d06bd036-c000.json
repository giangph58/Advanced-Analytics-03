{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15259v1\", \"title\": \"Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset\\n  Generation\", \"summary\": \"Digital modeling and reconstruction of human faces serve various\\napplications. However, its availability is often hindered by the requirements\\nof data capturing devices, manual labor, and suitable actors. This situation\\nrestricts the diversity, expressiveness, and control over the resulting models.\\nThis work aims to demonstrate that a semantically controllable generative\\nnetwork can provide enhanced control over the digital face modeling process. To\\nenhance diversity beyond the limited human faces scanned in a controlled\\nsetting, we introduce a novel data generation pipeline that creates a\\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\\nnormalization module converts synthesized data from the diffusion model into\\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\\ndeveloped an efficient GAN-based generator. This generator accepts semantic\\nattributes as input, and generates geometry and albedo. It also allows\\ncontinuous post-editing of attributes in the latent space. Our asset refinement\\ncomponent subsequently creates physically-based facial assets. We introduce a\\ncomprehensive system designed for creating and editing high-quality face\\nassets. Our proposed model has undergone extensive experiment, comparison and\\nevaluation. We also integrate everything into a web-based interactive tool. We\\naim to make this tool publicly available with the release of the paper.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-21T17:38:50Z\"}"}
