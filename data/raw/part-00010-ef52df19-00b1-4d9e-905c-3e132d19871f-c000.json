{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20384v1\", \"title\": \"FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video\\n  Understanding\", \"summary\": \"Recent advancements in video understanding within visual large language\\nmodels (VLLMs) have led to notable progress. However, the complexity of video\\ndata and contextual processing limitations still hinder long-video\\ncomprehension. A common approach is video feature compression to reduce token\\ninput to large language models, yet many methods either fail to prioritize\\nessential features, leading to redundant inter-frame information, or introduce\\ncomputationally expensive modules.To address these issues, we propose\\nFiLA(Fine-grained Vision Language Model)-Video, a novel framework that\\nleverages a lightweight dynamic-weight multi-frame fusion strategy, which\\nadaptively integrates multiple frames into a single representation while\\npreserving key video information and reducing computational costs. To enhance\\nframe selection for fusion, we introduce a keyframe selection strategy,\\neffectively identifying informative frames from a larger pool for improved\\nsummarization. Additionally, we present a simple yet effective long-video\\ntraining data generation strategy, boosting model performance without extensive\\nmanual annotation. Experimental results demonstrate that FiLA-Video achieves\\nsuperior efficiency and accuracy in long-video comprehension compared to\\nexisting methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-29T03:09:46Z\"}"}
