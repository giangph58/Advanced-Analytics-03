{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10044v1\", \"title\": \"Aligning Anime Video Generation with Human Feedback\", \"summary\": \"Anime video generation faces significant challenges due to the scarcity of\\nanime data and unusual motion patterns, leading to issues such as motion\\ndistortion and flickering artifacts, which result in misalignment with human\\npreferences. Existing reward models, designed primarily for real-world videos,\\nfail to capture the unique appearance and consistency requirements of anime. In\\nthis work, we propose a pipeline to enhance anime video generation by\\nleveraging human feedback for better alignment. Specifically, we construct the\\nfirst multi-dimensional reward dataset for anime videos, comprising 30k\\nhuman-annotated samples that incorporating human preferences for both visual\\nappearance and visual consistency. Based on this, we develop AnimeReward, a\\npowerful reward model that employs specialized vision-language models for\\ndifferent evaluation dimensions to guide preference alignment. Furthermore, we\\nintroduce Gap-Aware Preference Optimization (GAPO), a novel training method\\nthat explicitly incorporates preference gaps into the optimization process,\\nenhancing alignment performance and efficiency. Extensive experiment results\\nshow that AnimeReward outperforms existing reward models, and the inclusion of\\nGAPO leads to superior alignment in both quantitative benchmarks and human\\nevaluations, demonstrating the effectiveness of our pipeline in enhancing anime\\nvideo quality. Our dataset and code will be publicly available.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T09:49:34Z\"}"}
