{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02612v1\", \"title\": \"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation\", \"summary\": \"Recent advances in text-to-image generative models have enabled numerous\\npractical applications, including subject-driven generation, which fine-tunes\\npretrained models to capture subject semantics from only a few examples. While\\ndiffusion-based models produce high-quality images, their extensive denoising\\nsteps result in significant computational overhead, limiting real-world\\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\\ntokens rather than spatially adjacent ones, offer significantly faster\\ninference suitable for practical deployment. In this paper, we propose the\\nfirst VAR-based approach for subject-driven generation. However, na\\\\\\\"{\\\\i}ve\\nfine-tuning VAR leads to computational overhead, language drift, and reduced\\ndiversity. To address these challenges, we introduce selective layer tuning to\\nreduce complexity and prior distillation to mitigate language drift.\\nAdditionally, we found that the early stages have a greater influence on the\\ngeneration of subject than the latter stages, which merely synthesize local\\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\\nprioritizes coarser resolutions for promoting the model to focus on the\\nsubject-relevant information instead of local details. Extensive experiments\\nvalidate that our method significantly outperforms diffusion-based baselines\\nacross various metrics and demonstrates its practical usage.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T14:12:55Z\"}"}
