{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20927v1\", \"title\": \"Exploiting inter-agent coupling information for efficient reinforcement\\n  learning of cooperative LQR\", \"summary\": \"Developing scalable and efficient reinforcement learning algorithms for\\ncooperative multi-agent control has received significant attention over the\\npast years. Existing literature has proposed inexact decompositions of local\\nQ-functions based on empirical information structures between the agents. In\\nthis paper, we exploit inter-agent coupling information and propose a\\nsystematic approach to exactly decompose the local Q-function of each agent. We\\ndevelop an approximate least square policy iteration algorithm based on the\\nproposed decomposition and identify two architectures to learn the local\\nQ-function for each agent. We establish that the worst-case sample complexity\\nof the decomposition is equal to the centralized case and derive necessary and\\nsufficient graphical conditions on the inter-agent couplings to achieve better\\nsample efficiency. We demonstrate the improved sample efficiency and\\ncomputational efficiency on numerical examples.\", \"main_category\": \"eess.SY\", \"categories\": \"eess.SY,cs.LG,cs.MA,cs.SY,math.OC\", \"published\": \"2025-04-29T16:42:13Z\"}"}
