{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15046v1\", \"title\": \"Text-to-Decision Agent: Learning Generalist Policies from Natural\\n  Language Supervision\", \"summary\": \"RL systems usually tackle generalization by inferring task beliefs from\\nhigh-quality samples or warmup explorations. The restricted form limits their\\ngenerality and usability since these supervision signals are expensive and even\\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\\nraw text about decision tasks is a promising alternative to leverage a much\\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\\n(T2DA), a simple and scalable framework that supervises generalist policy\\nlearning with natural language. We first introduce a generalized world model to\\nencode multi-task decision data into a dynamics-aware embedding space. Then,\\ninspired by CLIP, we predict which textual description goes with which decision\\nembedding, effectively bridging their semantic gap via contrastive\\nlanguage-decision pre-training and aligning the text embeddings to comprehend\\nthe environment dynamics. After training the text-conditioned generalist\\npolicy, the agent can directly realize zero-shot text-to-decision generation in\\nresponse to language instructions. Comprehensive experiments on MuJoCo and\\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\\ngeneralization and outperforms various types of baselines.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-21T12:00:20Z\"}"}
