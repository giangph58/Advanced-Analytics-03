{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12197v1\", \"title\": \"Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI\", \"summary\": \"Deep learning has provided considerable advancements for multimedia systems,\\nyet the interpretability of deep models remains a challenge. State-of-the-art\\npost-hoc explainability methods, such as GradCAM, provide visual interpretation\\nbased on heatmaps but lack conceptual clarity. Prototype-based approaches, like\\nProtoPNet and PIPNet, offer a more structured explanation but rely on fixed\\npatches, limiting their robustness and semantic consistency.\\n  To address these limitations, a part-prototypical concept mining network\\n(PCMNet) is proposed that dynamically learns interpretable prototypes from\\nmeaningful regions. PCMNet clusters prototypes into concept groups, creating\\nsemantically grounded explanations without requiring additional annotations.\\nThrough a joint process of unsupervised part discovery and concept activation\\nvector extraction, PCMNet effectively captures discriminative concepts and\\nmakes interpretable classification decisions.\\n  Our extensive experiments comparing PCMNet against state-of-the-art methods\\non multiple datasets show that it can provide a high level of interpretability,\\nstability, and robustness under clean and occluded scenarios.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T15:48:21Z\"}"}
