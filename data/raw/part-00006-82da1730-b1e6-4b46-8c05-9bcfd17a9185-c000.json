{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12737v1\", \"title\": \"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model\", \"summary\": \"Chinese-Vicuna is an open-source, resource-efficient language model designed\\nto bridge the gap in Chinese instruction-following capabilities by fine-tuning\\nMeta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting\\nlow-resource environments, it enables cost-effective deployment on consumer\\nGPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation\\nin fields like healthcare and law. By integrating hybrid datasets (BELLE and\\nGuanaco) and 4-bit quantization (QLoRA), the model achieves competitive\\nperformance in tasks such as translation, code generation, and domain-specific\\nQ\\\\&A. The project provides a comprehensive toolkit for model conversion, CPU\\ninference, and multi-turn dialogue interfaces, emphasizing accessibility for\\nresearchers and developers. Evaluations indicate competitive performance across\\nmedical tasks, multi-turn dialogue coherence, and real-time legal updates.\\nChinese-Vicuna's modular design, open-source ecosystem, and community-driven\\nenhancements position it as a versatile foundation for Chinese LLM\\napplications.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-17T08:27:02Z\"}"}
