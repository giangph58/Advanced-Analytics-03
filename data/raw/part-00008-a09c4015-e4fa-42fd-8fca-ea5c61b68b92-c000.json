{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03186v1\", \"title\": \"CoGenAV: Versatile Audio-Visual Representation Learning via\\n  Contrastive-Generative Synchronization\", \"summary\": \"The inherent synchronization between a speaker's lip movements, voice, and\\nthe underlying linguistic content offers a rich source of information for\\nimproving speech processing tasks, especially in challenging conditions where\\ntraditional audio-only systems falter. We introduce CoGenAV, a powerful and\\ndata-efficient model designed to learn versatile audio-visual representations\\napplicable across a wide range of speech and audio-visual tasks. CoGenAV is\\ntrained by optimizing a dual objective derived from natural audio-visual\\nsynchrony, contrastive feature alignment and generative text prediction, using\\nonly 223 hours of labeled data from the LRS2 dataset. This\\ncontrastive-generative synchronization strategy effectively captures\\nfundamental cross-modal correlations. We showcase the effectiveness and\\nversatility of the learned CoGenAV representations on multiple benchmarks. When\\nutilized for Audio-Visual Speech Recognition (AVSR) on LRS2, these\\nrepresentations contribute to achieving a state-of-the-art Word Error Rate\\n(WER) of 1.27. They also enable strong performance in Visual Speech Recognition\\n(VSR) with a WER of 22.0 on LRS2, and significantly improve performance in\\nnoisy environments by over 70%. Furthermore, CoGenAV representations benefit\\nspeech reconstruction tasks, boosting performance in Speech Enhancement and\\nSeparation, and achieve competitive results in audio-visual synchronization\\ntasks like Active Speaker Detection (ASD). Our model will be open-sourced to\\nfacilitate further development and collaboration within both academia and\\nindustry.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.CV,eess.AS\", \"published\": \"2025-05-06T05:07:11Z\"}"}
