{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19472v1\", \"title\": \"Conflicts in Texts: Data, Implications and Challenges\", \"summary\": \"As NLP models become increasingly integrated into real-world applications, it\\nbecomes clear that there is a need to address the fact that models often rely\\non and generate conflicting information. Conflicts could reflect the complexity\\nof situations, changes that need to be explained and dealt with, difficulties\\nin data annotation, and mistakes in generated outputs. In all cases,\\ndisregarding the conflicts in data could result in undesired behaviors of\\nmodels and undermine NLP models' reliability and trustworthiness. This survey\\ncategorizes these conflicts into three key areas: (1) natural texts on the web,\\nwhere factual inconsistencies, subjective biases, and multiple perspectives\\nintroduce contradictions; (2) human-annotated data, where annotator\\ndisagreements, mistakes, and societal biases impact model training; and (3)\\nmodel interactions, where hallucinations and knowledge conflicts emerge during\\ndeployment. While prior work has addressed some of these conflicts in\\nisolation, we unify them under the broader concept of conflicting information,\\nanalyze their implications, and discuss mitigation strategies. We highlight key\\nchallenges and future directions for developing conflict-aware NLP systems that\\ncan reason over and reconcile conflicting information more effectively.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-28T04:24:01Z\"}"}
