{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12883v1\", \"title\": \"Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?\", \"summary\": \"Implicit bias plays an important role in explaining how overparameterized\\nmodels generalize well. Explicit regularization like weight decay is often\\nemployed in addition to prevent overfitting. While both concepts have been\\nstudied separately, in practice, they often act in tandem. Understanding their\\ninterplay is key to controlling the shape and strength of implicit bias, as it\\ncan be modified by explicit regularization. To this end, we incorporate\\nexplicit regularization into the mirror flow framework and analyze its lasting\\neffects on the geometry of the training dynamics, covering three distinct\\neffects: positional bias, type of bias, and range shrinking. Our analytical\\napproach encompasses a broad class of problems, including sparse coding, matrix\\nsensing, single-layer attention, and LoRA, for which we demonstrate the utility\\nof our insights. To exploit the lasting effect of regularization and highlight\\nthe potential benefit of dynamic weight decay schedules, we propose to switch\\noff weight decay during training, which can improve generalization, as we\\ndemonstrate in experiments.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-17T12:17:51Z\"}"}
