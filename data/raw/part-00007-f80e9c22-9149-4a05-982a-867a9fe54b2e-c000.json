{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12923v1\", \"title\": \"Efficient Masked Image Compression with Position-Indexed Self-Attention\", \"summary\": \"In recent years, image compression for high-level vision tasks has attracted\\nconsiderable attention from researchers. Given that object information in\\nimages plays a far more crucial role in downstream tasks than background\\ninformation, some studies have proposed semantically structuring the bitstream\\nto selectively transmit and reconstruct only the information required by these\\ntasks. However, such methods structure the bitstream after encoding, meaning\\nthat the coding process still relies on the entire image, even though much of\\nthe encoded information will not be transmitted. This leads to redundant\\ncomputations. Traditional image compression methods require a two-dimensional\\nimage as input, and even if the unimportant regions of the image are set to\\nzero by applying a semantic mask, these regions still participate in subsequent\\ncomputations as part of the image. To address such limitations, we propose an\\nimage compression method based on a position-indexed self-attention mechanism\\nthat encodes and decodes only the visible parts of the masked image. Compared\\nto existing semantic-structured compression methods, our approach can\\nsignificantly reduce computational costs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T13:12:39Z\"}"}
