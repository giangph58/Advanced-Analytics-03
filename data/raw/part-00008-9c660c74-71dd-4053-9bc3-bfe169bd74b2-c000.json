{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15632v1\", \"title\": \"A Study On Mixup-inspired Augmentation Methods For Software\\n  Vulnerability Detection\", \"summary\": \"Various Deep Learning (DL) methods have recently been utilized to detect\\nsoftware vulnerabilities. Real-world software vulnerability datasets are rare\\nand hard to acquire as there's no simple metric for classifying vulnerability.\\nSuch datasets are heavily imbalanced, and none of the current datasets are\\nconsidered huge for DL models. To tackle these problems a recent work has tried\\nto augment the dataset using the source code and generate realistic\\nsingle-statement vulnerabilities which is not quite practical and requires\\nmanual checking of the generated vulnerabilities. In this regard, we aim to\\nexplore the augmentation of vulnerabilities at the representation level to help\\ncurrent models learn better which has never been done before to the best of our\\nknowledge. We implement and evaluate the 5 augmentation techniques that augment\\nthe embedding of the data and recently have been used for code search which is\\na completely different software engineering task. We also introduced a\\nconditioned version of those augmentation methods, which ensures the\\naugmentation does not change the vulnerable section of the vector\\nrepresentation. We show that such augmentation methods can be helpful and\\nincrease the f1-score by up to 9.67%, yet they cannot beat Random Oversampling\\nwhen balancing datasets which increases the f1-score by 10.82%!\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.CR,cs.LG\", \"published\": \"2025-04-22T06:47:39Z\"}"}
