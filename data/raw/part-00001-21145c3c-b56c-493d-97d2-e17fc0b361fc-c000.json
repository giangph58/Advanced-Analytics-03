{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13092v1\", \"title\": \"EventVAD: Training-Free Event-Aware Video Anomaly Detection\", \"summary\": \"Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos.\\nSupervised methods require an amount of in-domain training data and often\\nstruggle to generalize to unseen anomalies. In contrast, training-free methods\\nleverage the intrinsic world knowledge of large language models (LLMs) to\\ndetect anomalies but face challenges in localizing fine-grained visual\\ntransitions and diverse events. Therefore, we propose EventVAD, an event-aware\\nvideo anomaly detection framework that combines tailored dynamic graph\\narchitectures and multimodal LLMs through temporal-event reasoning.\\nSpecifically, EventVAD first employs dynamic spatiotemporal graph modeling with\\ntime-decay constraints to capture event-aware video features. Then, it performs\\nadaptive noise filtering and uses signal ratio thresholding to detect event\\nboundaries via unsupervised statistical features. The statistical boundary\\ndetection module reduces the complexity of processing long videos for MLLMs and\\nimproves their temporal reasoning through event consistency. Finally, it\\nutilizes a hierarchical prompting strategy to guide MLLMs in performing\\nreasoning before determining final decisions. We conducted extensive\\nexperiments on the UCF-Crime and XD-Violence datasets. The results demonstrate\\nthat EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free\\nsettings, outperforming strong baselines that use 7B or larger MLLMs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T16:59:04Z\"}"}
