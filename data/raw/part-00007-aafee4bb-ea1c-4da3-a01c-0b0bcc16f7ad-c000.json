{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11777v1\", \"title\": \"Bridging the Semantic Gaps: Improving Medical VQA Consistency with\\n  LLM-Augmented Question Sets\", \"summary\": \"Medical Visual Question Answering (MVQA) systems can interpret medical images\\nin response to natural language queries. However, linguistic variability in\\nquestion phrasing often undermines the consistency of these systems. To address\\nthis challenge, we propose a Semantically Equivalent Question Augmentation\\n(SEQA) framework, which leverages large language models (LLMs) to generate\\ndiverse yet semantically equivalent rephrasings of questions. Specifically,\\nthis approach enriches linguistic diversity while preserving semantic meaning.\\nWe further introduce an evaluation metric, Total Agreement Rate with\\nSemantically Equivalent Input and Correct Answer (TAR-SC), which assesses a\\nmodel's capability to generate consistent and correct responses to semantically\\nequivalent linguistic variations. In addition, we also propose three other\\ndiversity metrics - average number of QA items per image (ANQI), average number\\nof questions per image with the same answer (ANQA), and average number of\\nopen-ended questions per image with the same semantics (ANQS). Using the SEQA\\nframework, we augmented the benchmarked MVQA public datasets of SLAKE, VQA-RAD,\\nand PathVQA. As a result, all three datasets achieved significant improvements\\nby incorporating more semantically equivalent questions: ANQI increased by an\\naverage of 86.1, ANQA by 85.1, and ANQS by 46. Subsequent experiments evaluate\\nthree MVQA models (M2I2, MUMC, and BiomedGPT) under both zero-shot and\\nfine-tuning settings on the enhanced datasets. Experimental results in MVQA\\ndatasets show that fine-tuned models achieve an average accuracy improvement of\\n19.35%, while our proposed TAR-SC metric shows an average improvement of 11.\\n61%, indicating a substantial enhancement in model consistency.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-04-16T05:31:18Z\"}"}
