{"value":"{\"aid\": \"http://arxiv.org/abs/2504.09983v1\", \"title\": \"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\\n  Learning Training\", \"summary\": \"The increasing scale of deep learning models has led to the development of\\nvarious parallelization strategies for distributed training across\\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\\nFSDP partition the parameters of each layer across multiple GPUs and gather\\nthem through communication when needed. These methods rely on optimizations\\nsuch as prefetching, which initiates communication early to overlap it with\\ncomputation and reduce communication overhead, and unsharding, which retains as\\nmany parameters in their unsharded form as possible to reduce communication\\nvolume. Although the timing of prefetching should be adjusted in response to\\ndynamic memory usage during execution, these systems lack the flexibility to\\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\\nanticipate how memory usage will change after prefetching is applied, making it\\ndifficult to combine it effectively with other optimizations such as\\nunsharding. We present DeepCompile, which compiles user-defined models into\\ncomputation graphs and applies a sequence of profiling-guided optimization\\npasses for distributed training. Taking dynamic memory usage into account,\\nthese passes flexibly insert, reorder, or remove operations to improve\\ncommunication-computation overlap, reduce memory pressure, and coordinate\\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\\ntop of DeepCompile, along with three optimizations: proactive prefetching,\\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\\nusing offloading.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC\", \"published\": \"2025-04-14T08:51:23Z\"}"}
