{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16501v1\", \"title\": \"Dynamic Time-aware Continual User Representation Learning\", \"summary\": \"Traditional user modeling (UM) approaches have primarily focused on designing\\nmodels for a single specific task, but they face limitations in generalization\\nand adaptability across various tasks. Recognizing these challenges, recent\\nstudies have shifted towards continual learning (CL)-based universal user\\nrepresentation learning aiming to develop a single model capable of handling\\nmultiple tasks. Despite advancements, existing methods are in fact evaluated\\nunder an unrealistic scenario that does not consider the passage of time as\\ntasks progress, which overlooks newly emerged items that may change the item\\ndistribution of previous tasks. In this paper, we introduce a practical\\nevaluation scenario on which CL-based universal user representation learning\\napproaches should be evaluated, which takes into account the passage of time as\\ntasks progress. Then, we propose a novel framework Dynamic Time-aware continual\\nuser representation learner, named DITTO, designed to alleviate catastrophic\\nforgetting despite continuous shifts in item distribution, while also allowing\\nthe knowledge acquired from previous tasks to adapt to the current shifted item\\ndistribution. Through our extensive experiments, we demonstrate the superiority\\nof DITTO over state-of-the-art methods under a practical evaluation scenario.\\nOur source code is available at\\nhttps://github.com/seungyoon-Choi/DITTO_official.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-23T08:23:59Z\"}"}
