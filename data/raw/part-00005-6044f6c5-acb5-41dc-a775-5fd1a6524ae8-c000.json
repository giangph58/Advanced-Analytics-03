{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15281v1\", \"title\": \"StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on\\n  3D Gaussians\", \"summary\": \"3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction\\nbut struggles with stylized scenarios (e.g., cartoons, games) due to fragmented\\ntextures, semantic misalignment, and limited adaptability to abstract\\naesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer\\nthat integrates multi-modal style conditioning, multi-level semantic alignment,\\nand perceptual quality enhancement. Our key insights include: (1) optimizing\\nonly RGB attributes preserves geometric integrity during stylization; (2)\\ndisentangling low-, medium-, and high-level semantics is critical for coherent\\nstyle transfer; (3) scalability across isolated objects and complex scenes is\\nessential for practical deployment. StyleMe3D introduces four novel components:\\nDynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent\\nspace for semantic alignment; Contrastive Style Descriptor (CSD) for localized,\\ncontent-aware texture transfer; Simultaneously Optimized Scale (SOS) to\\ndecouple style details and structural coherence; and 3D Gaussian Quality\\nAssessment (3DG-QA), a differentiable aesthetic prior trained on human-rated\\ndata to suppress artifacts and enhance visual harmony. Evaluated on NeRF\\nsynthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D\\noutperforms state-of-the-art methods in preserving geometric details (e.g.,\\ncarvings on sculptures) and ensuring stylistic consistency across scenes (e.g.,\\ncoherent lighting in landscapes), while maintaining real-time rendering. This\\nwork bridges photorealistic 3D GS and artistic stylization, unlocking\\napplications in gaming, virtual worlds, and digital art.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T17:59:55Z\"}"}
