{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15080v1\", \"title\": \"Empowering AI to Generate Better AI Code: Guided Generation of Deep\\n  Learning Projects with LLMs\", \"summary\": \"While large language models (LLMs) have been widely applied to code\\ngeneration, they struggle with generating entire deep learning projects, which\\nare characterized by complex structures, longer functions, and stronger\\nreliance on domain knowledge than general-purpose code. An open-domain LLM\\noften lacks coherent contextual guidance and domain expertise for specific\\nprojects, making it challenging to produce complete code that fully meets user\\nrequirements.\\n  In this paper, we propose a novel planning-guided code generation method,\\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\\nstructured solution plan, offering global guidance for LLMs to generate the\\nproject. The generated plan is then leveraged to retrieve semantically\\nanalogous code samples and subsequently abstract a code template. To\\neffectively integrate these multiple retrieval-augmented techniques, a\\ncomparative learning mechanism is designed to generate the final code. We\\nvalidate the effectiveness of our approach on a dataset we build for deep\\nlearning code generation. Experimental results demonstrate that DLCodeGen\\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\\n3.6% in human evaluation metrics.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.AI\", \"published\": \"2025-04-21T13:09:25Z\"}"}
