{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05145v1\", \"title\": \"Understanding In-context Learning of Addition via Activation Subspaces\", \"summary\": \"To perform in-context learning, language models must extract signals from\\nindividual few-shot examples, aggregate these into a learned prediction rule,\\nand then apply this rule to new examples. How is this implemented in the\\nforward pass of modern transformer models? To study this, we consider a\\nstructured family of few-shot learning tasks for which the true prediction rule\\nis to add an integer $k$ to the input. We find that Llama-3-8B attains high\\naccuracy on this task for a range of $k$, and localize its few-shot ability to\\njust three attention heads via a novel optimization approach. We further show\\nthe extracted signals lie in a six-dimensional subspace, where four of the\\ndimensions track the unit digit and the other two dimensions track overall\\nmagnitude. We finally examine how these heads extract information from\\nindividual few-shot examples, identifying a self-correction mechanism in which\\nmistakes from earlier examples are suppressed by later examples. Our results\\ndemonstrate how tracking low-dimensional subspaces across a forward pass can\\nprovide insight into fine-grained computational structures.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CL\", \"published\": \"2025-05-08T11:32:46Z\"}"}
