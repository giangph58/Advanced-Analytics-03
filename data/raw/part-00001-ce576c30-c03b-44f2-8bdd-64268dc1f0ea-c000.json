{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20821v1\", \"title\": \"The When and How of Target Variable Transformations\", \"summary\": \"The machine learning pipeline typically involves the iterative process of (1)\\ncollecting the data, (2) preparing the data, (3) learning a model, and (4)\\nevaluating a model. Practitioners recognize the importance of the data\\npreparation phase in terms of its impact on the ability to learn accurate\\nmodels. In this regard, significant attention is often paid to manipulating the\\nfeature set (e.g., selection, transformations, dimensionality reduction). A\\npoint that is less well appreciated is that transformations on the target\\nvariable can also have a large impact on whether it is possible to learn a\\nsuitable model. These transformations may include accounting for\\nsubject-specific biases (e.g., in how someone uses a rating scale), contexts\\n(e.g., population size effects), and general trends (e.g., inflation). However,\\nthis point has received a much more cursory treatment in the existing\\nliterature. The goal of this paper is three-fold. First, we aim to highlight\\nthe importance of this problem by showing when transforming the target variable\\nhas been useful in practice. Second, we will provide a set of generic ``rules\\nof thumb'' that indicate situations when transforming the target variable may\\nbe needed. Third, we will discuss which transformations should be considered in\\na given situation.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-29T14:40:21Z\"}"}
