{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12959v1\", \"title\": \"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D\\n  Semantic Occupancy Prediction\", \"summary\": \"We present GDFusion, a temporal fusion method for vision-based 3D semantic\\noccupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects\\nof temporal fusion within the VisionOcc framework, focusing on both temporal\\ncues and fusion strategies. It systematically examines the entire VisionOcc\\npipeline, identifying three fundamental yet previously overlooked temporal\\ncues: scene-level consistency, motion calibration, and geometric\\ncomplementation. These cues capture diverse facets of temporal evolution and\\nmake distinct contributions across various modules in the VisionOcc framework.\\nTo effectively fuse temporal signals across heterogeneous representations, we\\npropose a novel fusion strategy by reinterpreting the formulation of vanilla\\nRNNs. This reinterpretation leverages gradient descent on features to unify the\\nintegration of diverse temporal information, seamlessly embedding the proposed\\ntemporal cues into the network. Extensive experiments on nuScenes demonstrate\\nthat GDFusion significantly outperforms established baselines. Notably, on\\nOcc3D benchmark, it achieves 1.4\\\\%-4.8\\\\% mIoU improvements and reduces memory\\nconsumption by 27\\\\%-72\\\\%.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T14:05:33Z\"}"}
