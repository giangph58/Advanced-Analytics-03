{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10283v1\", \"title\": \"$\\u03b1$-Flow: A Unified Framework for Continuous-State Discrete Flow\\n  Matching Models\", \"summary\": \"Recent efforts have extended the flow-matching framework to discrete\\ngenerative modeling. One strand of models directly works with the continuous\\nprobabilities instead of discrete tokens, which we colloquially refer to as\\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\\nsignificantly in their representations and geometric assumptions. This work\\npresents a unified framework for CS-DFM models, under which the existing\\nvariants can be understood as operating on different $\\\\alpha$-representations\\nof probabilities. Building upon the theory of information geometry, we\\nintroduce $\\\\alpha$-Flow, a family of CS-DFM models that adheres to the\\ncanonical $\\\\alpha$-geometry of the statistical manifold, and demonstrate its\\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\\nthat the flow matching loss for $\\\\alpha$-flow establishes a unified variational\\nbound for the discrete negative log-likelihood. We comprehensively evaluate\\ndifferent instantiations of $\\\\alpha$-flow on various discrete generation\\ndomains to demonstrate their effectiveness in discrete generative modeling,\\nincluding intermediate values whose geometries have never been explored before.\\n$\\\\alpha$-flow significantly outperforms its discrete-state counterpart in image\\nand protein sequence generation and better captures the entropy in language\\nmodeling.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-14T14:51:45Z\"}"}
