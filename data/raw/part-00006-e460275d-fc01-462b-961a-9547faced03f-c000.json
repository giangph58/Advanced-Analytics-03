{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06897v1\", \"title\": \"MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs\", \"summary\": \"This paper presents MedSegFactory, a versatile medical synthesis framework\\nthat generates high-quality paired medical images and segmentation masks across\\nmodalities and tasks. It aims to serve as an unlimited data repository,\\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\\nmedical images and the other generates corresponding segmentation masks. To\\nensure precise alignment between image-mask pairs, we introduce Joint\\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\\ncross-conditioning between streams. This bidirectional interaction allows both\\nrepresentations to guide each other's generation, enhancing consistency between\\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\\nimages and segmentation masks through user-defined prompts that specify the\\ntarget labels, imaging modalities, anatomical regions, and pathological\\nconditions, facilitating scalable and high-quality data generation. This new\\nparadigm of medical image synthesis enables seamless integration into diverse\\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\\nexperiments show that MedSegFactory generates data of superior quality and\\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\\nsegmentation tasks while addressing data scarcity and regulatory constraints.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-09T13:56:05Z\"}"}
