{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24253v1\", \"title\": \"Deep Learning-Based Data Fusion of 6G Sensing and Inertial Information\\n  for Target Positioning: Experimental Validation\", \"summary\": \"The sixth-generation (6G) cellular technology will be deployed with a key\\nfeature of Integrated Sensing and Communication (ISAC), allowing the cellular\\nnetwork to map the environment through radar sensing on top of providing\\ncommunication services. In this regard, the entire network can be considered as\\na sensor with a broader Field of View (FoV) of the environment, assisting in\\nboth the positioning of active and detection of passive targets. On the other\\nhand, the non-3GPP sensors available on the target can provide additional\\ninformation specific to the target that can be beneficially combined with ISAC\\nsensing information to enhance the overall achievable positioning accuracy. In\\nthis paper, we first study the performance of the ISAC system in terms of its\\nachievable accuracy in positioning the mobile target in an indoor scenario.\\nSecond, we study the performance gain achieved in the ISAC positioning accuracy\\nafter fusing the information from the target's non-3GPP sensors. To this end,\\nwe propose a novel data fusion solution based on the deep learning framework to\\nfuse the information from ISAC and non-3GPP sensors.\\n  We validate our proposed data fusion and positioning solution with a\\nreal-world ISAC Proof-of-Concept (PoC) as the wireless infrastructure, an\\nAutomated Guided Vehicle (AGV) as the target, and the Inertial Measurement Unit\\n(IMU) sensor on the target as the non-3GPP sensor. The experimental results\\nshow that our proposed solution achieves an average positioning error of\\n$3~\\\\textrm{cm}$, outperforming the considered baselines.\", \"main_category\": \"eess.SP\", \"categories\": \"eess.SP\", \"published\": \"2025-03-31T16:02:17Z\"}"}
