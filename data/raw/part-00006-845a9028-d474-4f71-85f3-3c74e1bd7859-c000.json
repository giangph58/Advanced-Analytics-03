{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07467v1\", \"title\": \"Defense against Prompt Injection Attacks via Mixture of Encodings\", \"summary\": \"Large Language Models (LLMs) have emerged as a dominant approach for a wide\\nrange of NLP tasks, with their access to external information further enhancing\\ntheir capabilities. However, this introduces new vulnerabilities, known as\\nprompt injection attacks, where external content embeds malicious instructions\\nthat manipulate the LLM's output. Recently, the Base64 defense has been\\nrecognized as one of the most effective methods for reducing success rate of\\nprompt injection attacks. Despite its efficacy, this method can degrade LLM\\nperformance on certain NLP tasks. To address this challenge, we propose a novel\\ndefense mechanism: mixture of encodings, which utilizes multiple character\\nencodings, including Base64. Extensive experimental results show that our\\nmethod achieves one of the lowest attack success rates under prompt injection\\nattacks, while maintaining high performance across all NLP tasks, outperforming\\nexisting character encoding-based defense methods. This underscores the\\neffectiveness of our mixture of encodings strategy for both safety and task\\nperformance metrics.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-10T05:35:21Z\"}"}
