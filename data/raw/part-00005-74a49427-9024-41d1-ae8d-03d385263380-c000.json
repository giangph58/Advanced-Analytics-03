{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16537v1\", \"title\": \"Transformers for Complex Query Answering over Knowledge Hypergraphs\", \"summary\": \"Complex Query Answering (CQA) has been extensively studied in recent years.\\nIn order to model data that is closer to real-world distribution, knowledge\\ngraphs with different modalities have been introduced. Triple KGs, as the\\nclassic KGs composed of entities and relations of arity 2, have limited\\nrepresentation of real-world facts. Real-world data is more sophisticated.\\nWhile hyper-relational graphs have been introduced, there are limitations in\\nrepresenting relationships of varying arity that contain entities with equal\\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\\nM-FB15k-HCQA. Each dataset contains various query types that include logical\\noperations such as projection, negation, conjunction, and disjunction. In order\\nto answer knowledge hypergraph (KHG) existential first-order queries, we\\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\\nprojection and a Logical Encoder for complex logical operations. Both encoders\\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\\nmethod over KHG and is able to generalize to out-of-distribution query types.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-23T09:07:21Z\"}"}
