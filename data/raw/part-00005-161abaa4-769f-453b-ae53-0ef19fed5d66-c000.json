{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17720v1\", \"title\": \"Multilingual Performance Biases of Large Language Models in Education\", \"summary\": \"Large language models (LLMs) are increasingly being adopted in educational\\nsettings. These applications expand beyond English, though current LLMs remain\\nprimarily English-centric. In this work, we ascertain if their use in education\\nsettings in non-English languages is warranted. We evaluated the performance of\\npopular LLMs on four educational tasks: identifying student misconceptions,\\nproviding targeted feedback, interactive tutoring, and grading translations in\\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\\nEnglish. We find that the performance on these tasks somewhat corresponds to\\nthe amount of language represented in training data, with lower-resource\\nlanguages having poorer task performance. Although the models perform\\nreasonably well in most languages, the frequent performance drop from English\\nis significant. Thus, we recommend that practitioners first verify that the LLM\\nworks well in the target language for their educational task before deployment.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-24T16:32:31Z\"}"}
