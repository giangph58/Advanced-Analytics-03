{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04979v1\", \"title\": \"Federated Deconfounding and Debiasing Learning for Out-of-Distribution\\n  Generalization\", \"summary\": \"Attribute bias in federated learning (FL) typically leads local models to\\noptimize inconsistently due to the learning of non-causal associations,\\nresulting degraded performance. Existing methods either use data augmentation\\nfor increasing sample diversity or knowledge distillation for learning\\ninvariant representations to address this problem. However, they lack a\\ncomprehensive analysis of the inference paths, and the interference from\\nconfounding factors limits their performance. To address these limitations, we\\npropose the \\\\underline{Fed}erated \\\\underline{D}econfounding and\\n\\\\underline{D}ebiasing \\\\underline{L}earning (FedDDL) method. It constructs a\\nstructured causal graph to analyze the model inference process, and performs\\nbackdoor adjustment to eliminate confounding paths. Specifically, we design an\\nintra-client deconfounding learning module for computer vision tasks to\\ndecouple background and objects, generating counterfactual samples that\\nestablish a connection between the background and any label, which stops the\\nmodel from using the background to infer the label. Moreover, we design an\\ninter-client debiasing learning module to construct causal prototypes to reduce\\nthe proportion of the background in prototype components. Notably, it bridges\\nthe gap between heterogeneous representations via causal prototypical\\nregularization. Extensive experiments on 2 benchmarking datasets demonstrate\\nthat \\\\methodname{} significantly enhances the model capability to focus on main\\nobjects in unseen data, leading to 4.5\\\\% higher Top-1 Accuracy on average over\\n9 state-of-the-art existing methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-08T06:32:59Z\"}"}
