{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02764v1\", \"title\": \"Scene Splatter: Momentum 3D Scene Generation from Single Image with\\n  Video Diffusion Model\", \"summary\": \"In this paper, we propose Scene Splatter, a momentum-based paradigm for video\\ndiffusion to generate generic scenes from single image. Existing methods, which\\nemploy video generation models to synthesize novel views, suffer from limited\\nvideo length and scene inconsistency, leading to artifacts and distortions\\nduring further reconstruction. To address this issue, we construct noisy\\nsamples from original features as momentum to enhance video details and\\nmaintain scene consistency. However, for latent features with the perception\\nfield that spans both known and unknown regions, such latent-level momentum\\nrestricts the generative ability of video diffusion in unknown regions.\\nTherefore, we further introduce the aforementioned consistent video as a\\npixel-level momentum to a directly generated video without momentum for better\\nrecovery of unseen regions. Our cascaded momentum enables video diffusion\\nmodels to generate both high-fidelity and consistent novel views. We further\\nfinetune the global Gaussian representations with enhanced frames and render\\nnew frames for momentum update in the next step. In this manner, we can\\niteratively recover a 3D scene, avoiding the limitation of video length.\\nExtensive experiments demonstrate the generalization capability and superior\\nperformance of our method in high-fidelity and consistent scene generation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-03T17:00:44Z\"}"}
