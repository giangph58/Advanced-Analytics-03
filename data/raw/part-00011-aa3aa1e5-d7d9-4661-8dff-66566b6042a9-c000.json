{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12088v1\", \"title\": \"AttentionDrop: A Novel Regularization Method for Transformer Models\", \"summary\": \"Transformer-based architectures achieve state-of-the-art performance across a\\nwide range of tasks in natural language processing, computer vision, and\\nspeech. However, their immense capacity often leads to overfitting, especially\\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\\nfamily of stochastic regularization techniques that operate directly on the\\nself-attention distributions. We introduces three variants: 1. Hard Attention\\nMasking: randomly zeroes out top-k attention logits per query to encourage\\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\\nGaussian convolution over attention logits to diffuse overly peaked\\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\\nstability under multiple independent AttentionDrop perturbations via a KL-based\\nconsistency loss.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-16T13:51:16Z\"}"}
