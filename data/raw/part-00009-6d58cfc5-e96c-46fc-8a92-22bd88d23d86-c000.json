{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04603v1\", \"title\": \"Likelihood-Free Adaptive Bayesian Inference via Nonparametric\\n  Distribution Matching\", \"summary\": \"When the likelihood is analytically unavailable and computationally\\nintractable, approximate Bayesian computation (ABC) has emerged as a widely\\nused methodology for approximate posterior inference; however, it suffers from\\nsevere computational inefficiency in high-dimensional settings or under diffuse\\npriors. To overcome these limitations, we propose Adaptive Bayesian Inference\\n(ABI), a framework that bypasses traditional data-space discrepancies and\\ninstead compares distributions directly in posterior space through\\nnonparametric distribution matching. By leveraging a novel Marginally-augmented\\nSliced Wasserstein (MSW) distance on posterior measures and exploiting its\\nquantile representation, ABI transforms the challenging problem of measuring\\ndivergence between posterior distributions into a tractable sequence of\\none-dimensional conditional quantile regression tasks. Moreover, we introduce a\\nnew adaptive rejection sampling scheme that iteratively refines the posterior\\napproximation by updating the proposal distribution via generative density\\nestimation. Theoretically, we establish parametric convergence rates for the\\ntrimmed MSW distance and prove that the ABI posterior converges to the true\\nposterior as the tolerance threshold vanishes. Through extensive empirical\\nevaluation, we demonstrate that ABI significantly outperforms data-based\\nWasserstein ABC, summary-based ABC, and state-of-the-art likelihood-free\\nsimulators, especially in high-dimensional or dependent observation regimes.\", \"main_category\": \"stat.ME\", \"categories\": \"stat.ME,cs.LG,stat.CO,stat.ML\", \"published\": \"2025-05-07T17:50:14Z\"}"}
