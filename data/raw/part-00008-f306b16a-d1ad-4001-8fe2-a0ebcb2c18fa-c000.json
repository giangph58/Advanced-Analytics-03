{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13146v1\", \"title\": \"Antidistillation Sampling\", \"summary\": \"Frontier models that generate extended reasoning traces inadvertently produce\\nrich token sequences that can facilitate model distillation. Recognizing this\\nvulnerability, model owners may seek sampling strategies that limit the\\neffectiveness of distillation without compromising model performance.\\n\\\\emph{Antidistillation sampling} provides exactly this capability. By\\nstrategically modifying a model's next-token probability distribution,\\nantidistillation sampling poisons reasoning traces, rendering them\\nsignificantly less effective for distillation while preserving the model's\\npractical utility. For further details, see https://antidistillation.com.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL\", \"published\": \"2025-04-17T17:54:14Z\"}"}
