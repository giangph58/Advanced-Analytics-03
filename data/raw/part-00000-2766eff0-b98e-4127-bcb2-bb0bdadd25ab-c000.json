{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12911v1\", \"title\": \"Benchmarking Multi-National Value Alignment for Large Language Models\", \"summary\": \"Do Large Language Models (LLMs) hold positions that conflict with your\\ncountry's values? Occasionally they do! However, existing works primarily focus\\non ethical reviews, failing to capture the diversity of national values, which\\nencompass broader policy, legal, and moral considerations. Furthermore, current\\nbenchmarks that rely on spectrum tests using manually designed questionnaires\\nare not easily scalable.\\n  To address these limitations, we introduce NaVAB, a comprehensive benchmark\\nto evaluate the alignment of LLMs with the values of five major nations: China,\\nthe United States, the United Kingdom, France, and Germany. NaVAB implements a\\nnational value extraction pipeline to efficiently construct value assessment\\ndatasets. Specifically, we propose a modeling procedure with instruction\\ntagging to process raw data sources, a screening process to filter\\nvalue-related topics and a generation process with a Conflict Reduction\\nmechanism to filter non-conflicting values.We conduct extensive experiments on\\nvarious LLMs across countries, and the results provide insights into assisting\\nin the identification of misaligned scenarios. Moreover, we demonstrate that\\nNaVAB can be combined with alignment techniques to effectively reduce value\\nconcerns by aligning LLMs' values with the target country.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-17T13:01:38Z\"}"}
