{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01459v1\", \"title\": \"Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning\", \"summary\": \"Reinforcement learning (RL) -- algorithms that teach artificial agents to\\ninteract with environments by maximising reward signals -- has achieved\\nsignificant success in recent years. These successes have been facilitated by\\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\\ngradients, proximal policy optimisation, trust region policy optimisation, and\\nsoft actor-critic) and specialised computational resources such as GPUs and\\nTPUs. One promising research direction involves introducing goals to allow\\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\\nlearning. These methods systematically decompose complex behaviours into\\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\\nlearn to run before we walk, or we learn arithmetic before calculus). However,\\nfully automating goal creation remains an open challenge. We present a novel\\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\\nlearning agents in continuous control and navigation tasks.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-02T08:15:16Z\"}"}
