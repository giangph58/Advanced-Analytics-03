{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10012v1\", \"title\": \"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting\", \"summary\": \"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\\nto model camera pose and radiance changes during exposure, reducing\\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\\nduring exposure, can effectively assist in modeling motion blur and improving\\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\\nGaussians from event streams and severely blurred images. This method jointly\\nlearns the parameters of these Gaussians while recovering camera motion\\ntrajectories during exposure time. Specifically, we first construct a blur loss\\nfunction by synthesizing multiple latent sharp images during the exposure time,\\nminimizing the difference between real and synthesized blurred images. Then we\\nuse event stream to supervise the light intensity changes between latent sharp\\nimages at any time within the exposure period, supplementing the light\\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\\nlatent sharp images at intermediate exposure times based on the event-based\\ndouble integral (EDI) prior, applying consistency constraints to enhance the\\ndetails and texture information of the reconstructed images. Extensive\\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\\nachieve high-quality 3D scene reconstruction under the condition of blurred\\nimages and event stream inputs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T09:17:00Z\"}"}
