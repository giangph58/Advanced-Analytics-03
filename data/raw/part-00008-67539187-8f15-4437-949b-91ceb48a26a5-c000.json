{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21294v1\", \"title\": \"Learning Multi-view Multi-class Anomaly Detection\", \"summary\": \"The latest trend in anomaly detection is to train a unified model instead of\\ntraining a separate model for each category. However, existing multi-class\\nanomaly detection (MCAD) models perform poorly in multi-view scenarios because\\nthey often fail to effectively model the relationships and complementary\\ninformation among different views. In this paper, we introduce a Multi-View\\nMulti-Class Anomaly Detection model (MVMCAD), which integrates information from\\nmultiple views to accurately identify anomalies. Specifically, we propose a\\nsemi-frozen encoder, where a pre-encoder prior enhancement mechanism is added\\nbefore the frozen encoder, enabling stable cross-view feature modeling and\\nefficient adaptation for improved anomaly detection. Furthermore, we propose an\\nAnomaly Amplification Module (AAM) that models global token interactions and\\nsuppresses normal regions to enhance anomaly signals, leading to improved\\ndetection performance in multi-view settings. Finally, we propose a\\nCross-Feature Loss that aligns shallow encoder features with deep decoder\\nfeatures and vice versa, enhancing the model's sensitivity to anomalies at\\ndifferent semantic levels under multi-view scenarios. Extensive experiments on\\nthe Real-IAD dataset for multi-view multi-class anomaly detection validate the\\neffectiveness of our approach, achieving state-of-the-art performance of\\n91.0/88.6/82.1 and 99.1/43.9/48.2/95.2 for image-level and the pixel-level,\\nrespectively.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T03:59:58Z\"}"}
