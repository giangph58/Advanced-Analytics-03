{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11992v1\", \"title\": \"Analysis of Pseudo-Labeling for Online Source-Free Universal Domain\\n  Adaptation\", \"summary\": \"A domain (distribution) shift between training and test data often hinders\\nthe real-world performance of deep neural networks, necessitating unsupervised\\ndomain adaptation (UDA) to bridge this gap. Online source-free UDA has emerged\\nas a solution for practical scenarios where access to source data is restricted\\nand target data is received as a continuous stream. However, the open-world\\nnature of many real-world applications additionally introduces category shifts\\nmeaning that the source and target label spaces may differ. Online source-free\\nuniversal domain adaptation (SF-UniDA) addresses this challenge. Existing\\nmethods mainly rely on self-training with pseudo-labels, yet the relationship\\nbetween pseudo-labeling and adaptation outcomes has not been studied yet. To\\nbridge this gap, we conduct a systematic analysis through controlled\\nexperiments with simulated pseudo-labeling, offering valuable insights into\\npseudo-labeling for online SF-UniDA. Our findings reveal a substantial gap\\nbetween the current state-of-the-art and the upper bound of adaptation achieved\\nwith perfect pseudo-labeling. Moreover, we show that a contrastive loss enables\\neffective adaptation even with moderate pseudo-label accuracy, while a\\ncross-entropy loss, though less robust to pseudo-label errors, achieves\\nsuperior results when pseudo-labeling approaches perfection. Lastly, our\\nfindings indicate that pseudo-label accuracy is in general more crucial than\\nquantity, suggesting that prioritizing fewer but high-confidence pseudo-labels\\nis beneficial. Overall, our study highlights the critical role of\\npseudo-labeling in (online) SF-UniDA and provides actionable insights to drive\\nfuture advancements in the field. Our code is available at\\nhttps://github.com/pascalschlachter/PLAnalysis.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-16T11:34:18Z\"}"}
