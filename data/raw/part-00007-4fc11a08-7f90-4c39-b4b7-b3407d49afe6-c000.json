{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10920v1\", \"title\": \"Towards Efficient Partially Relevant Video Retrieval with Active Moment\\n  Discovering\", \"summary\": \"Partially relevant video retrieval (PRVR) is a practical yet challenging task\\nin text-to-video retrieval, where videos are untrimmed and contain much\\nbackground content. The pursuit here is of both effective and efficient\\nsolutions to capture the partial correspondence between text queries and\\nuntrimmed videos. Existing PRVR methods, which typically focus on modeling\\nmulti-scale clip representations, however, suffer from content independence and\\ninformation redundancy, impairing retrieval performance. To overcome these\\nlimitations, we propose a simple yet effective approach with active moment\\ndiscovering (AMDNet). We are committed to discovering video moments that are\\nsemantically consistent with their queries. By using learnable span anchors to\\ncapture distinct moments and applying masked multi-moment attention to\\nemphasize salient moments while suppressing redundant backgrounds, we achieve\\nmore compact and informative video representations. To further enhance moment\\nmodeling, we introduce a moment diversity loss to encourage different moments\\nof distinct regions and a moment relevance loss to promote semantically\\nquery-relevant moments, which cooperate with a partially relevant retrieval\\nloss for end-to-end optimization. Extensive experiments on two large-scale\\nvideo datasets (\\\\ie, TVR and ActivityNet Captions) demonstrate the superiority\\nand efficiency of our AMDNet. In particular, AMDNet is about 15.5 times smaller\\n(\\\\#parameters) while 6.0 points higher (SumR) than the up-to-date method\\nGMMFormer on TVR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-15T07:00:18Z\"}"}
