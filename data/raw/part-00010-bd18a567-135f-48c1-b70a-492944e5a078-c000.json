{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05966v1\", \"title\": \"AVP-AP: Self-supervised Automatic View Positioning in 3D cardiac CT via\\n  Atlas Prompting\", \"summary\": \"Automatic view positioning is crucial for cardiac computed tomography (CT)\\nexaminations, including disease diagnosis and surgical planning. However, it is\\nhighly challenging due to individual variability and large 3D search space.\\nExisting work needs labor-intensive and time-consuming manual annotations to\\ntrain view-specific models, which are limited to predicting only a fixed set of\\nplanes. However, in real clinical scenarios, the challenge of positioning\\nsemantic 2D slices with any orientation into varying coordinate space in\\narbitrary 3D volume remains unsolved. We thus introduce a novel framework,\\nAVP-AP, the first to use Atlas Prompting for self-supervised Automatic View\\nPositioning in the 3D CT volume. Specifically, this paper first proposes an\\natlas prompting method, which generates a 3D canonical atlas and trains a\\nnetwork to map slices into their corresponding positions in the atlas space via\\na self-supervised manner. Then, guided by atlas prompts corresponding to the\\ngiven query images in a reference CT, we identify the coarse positions of\\nslices in the target CT volume using rigid transformation between the 3D atlas\\nand target CT volume, effectively reducing the search space. Finally, we refine\\nthe coarse positions by maximizing the similarity between the predicted slices\\nand the query images in the feature space of a given foundation model. Our\\nframework is flexible and efficient compared to other methods, outperforming\\nother methods by 19.8% average structural similarity (SSIM) in arbitrary view\\npositioning and achieving 9% SSIM in two-chamber view compared to four\\nradiologists. Meanwhile, experiments on a public dataset validate our\\nframework's generalizability.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-08T12:24:37Z\"}"}
