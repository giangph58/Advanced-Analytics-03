{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03554v1\", \"title\": \"Read My Ears! Horse Ear Movement Detection for Equine Affective State\\n  Assessment\", \"summary\": \"The Equine Facial Action Coding System (EquiFACS) enables the systematic\\nannotation of facial movements through distinct Action Units (AUs). It serves\\nas a crucial tool for assessing affective states in horses by identifying\\nsubtle facial expressions associated with discomfort. However, the field of\\nhorse affective state assessment is constrained by the scarcity of annotated\\ndata, as manually labelling facial AUs is both time-consuming and costly. To\\naddress this challenge, automated annotation systems are essential for\\nleveraging existing datasets and improving affective states detection tools. In\\nthis work, we study different methods for specific ear AU detection and\\nlocalization from horse videos. We leverage past works on deep learning-based\\nvideo feature extraction combined with recurrent neural networks for the video\\nclassification task, as well as a classic optical flow based approach. We\\nachieve 87.5% classification accuracy of ear movement presence on a public\\nhorse video dataset, demonstrating the potential of our approach. We discuss\\nfuture directions to develop these systems, with the aim of bridging the gap\\nbetween automated AU detection and practical applications in equine welfare and\\nveterinary diagnostics. Our code will be made publicly available at\\nhttps://github.com/jmalves5/read-my-ears.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T14:05:49Z\"}"}
