{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11009v1\", \"title\": \"MMC: Iterative Refinement of VLM Reasoning via MCTS-based Multimodal\\n  Critique\", \"summary\": \"Visual language models (VLMs) have demonstrated strong performance across\\ndiverse multimodal reasoning tasks but still face challenges such as\\nhallucinations, resulting in incorrect reasoning outcomes. Inspired by recent\\nresearch on external feedback mechanisms in large language models (LLMs), we\\npropose a multimodal actor-critic framework to enhance VLM reasoning\\ncapabilities. Specifically, the actor model generates step-by-step reasoning\\npaths based on image and text inputs, while the critic model evaluates these\\nreasoning paths and provides corrective feedback. The actor model iteratively\\nrefines its reasoning based on the feedback until the reasoning outcome is\\ndeemed satisfactory by the critic model. To reduce reliance on costly manual\\nannotations, we introduce an automated method for constructing multimodal\\ncritique datasets. By leveraging Monte Carlo Tree Search (MCTS), we\\nsystematically guide the actor model to explore diverse reasoning paths. To\\nobtain critique data for correcting erroneous reasoning steps, we prompt an\\nannotator model to compare pairs of reasoning paths diverging from a shared\\nancestor node - one leading to a correct conclusion and the other to an\\nincorrect one. This approach enables us to construct the MMC (MCTS-based\\nMultimodal Critique) dataset, upon which we further develop a comprehensive\\ntraining and inference pipeline. Extensive experiments conducted on several\\npublic benchmark datasets and mainstream VLMs demonstrate that our approach\\nsignificantly improves the performance of VLM on complex multimodal reasoning\\ntasks, underscoring its effectiveness and wide applicability.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM\", \"published\": \"2025-04-15T09:29:08Z\"}"}
