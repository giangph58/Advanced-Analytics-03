{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02799v1\", \"title\": \"Systematic Evaluation of Large Vision-Language Models for Surgical\\n  Artificial Intelligence\", \"summary\": \"Large Vision-Language Models offer a new paradigm for AI-driven image\\nunderstanding, enabling models to perform tasks without task-specific training.\\nThis flexibility holds particular promise across medicine, where\\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\\nintervention-focused domains--especially surgery, where decision-making is\\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\\ntimes outperforming supervised models when deployed outside their training\\nsetting. In-context learning, incorporating examples during testing, boosted\\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\\nsurgery, our findings offer insights into VLMs' potential for tackling complex\\nand dynamic scenarios in clinical and broader real-world applications.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-03T17:42:56Z\"}"}
