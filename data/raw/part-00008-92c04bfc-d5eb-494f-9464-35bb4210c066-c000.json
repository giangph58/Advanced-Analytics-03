{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04121v1\", \"title\": \"Vision Graph Prompting via Semantic Low-Rank Decomposition\", \"summary\": \"Vision GNN (ViG) demonstrates superior performance by representing images as\\ngraph structures, providing a more natural way to capture irregular semantic\\npatterns beyond traditional grid or sequence-based representations. To\\nefficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning\\ntechniques like visual prompting become increasingly essential. However,\\nexisting prompting methods are primarily designed for Transformer-based models,\\nneglecting the rich topological relationships among nodes and edges in\\ngraph-based representations, limiting their capacity to model complex\\nsemantics. In this paper, we propose Vision Graph Prompting (VGP), a novel\\nframework tailored for vision graph structures. Our core insight reveals that\\nsemantically connected components in the graph exhibit low-rank properties.\\nBuilding on this observation, we introduce a semantic low-rank prompting method\\nthat decomposes low-rank semantic features and integrates them with prompts on\\nvision graph topologies, capturing both global structural patterns and\\nfine-grained semantic dependencies. Extensive experiments demonstrate our\\nmethod significantly improves ViG's transfer performance on diverse downstream\\ntasks, achieving results comparable to full fine-tuning while maintaining\\nparameter efficiency. Our code is available at\\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-07T04:29:29Z\"}"}
