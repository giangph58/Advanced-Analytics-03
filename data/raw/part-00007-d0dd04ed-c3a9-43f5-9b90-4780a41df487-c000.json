{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07851v1\", \"title\": \"Independence Is Not an Issue in Neurosymbolic AI\", \"summary\": \"A popular approach to neurosymbolic AI is to take the output of the last\\nlayer of a neural network, e.g. a softmax activation, and pass it through a\\nsparse computation graph encoding certain logical constraints one wishes to\\nenforce. This induces a probability distribution over a set of random\\nvariables, which happen to be conditionally independent of each other in many\\ncommonly used neurosymbolic AI models. Such conditionally independent random\\nvariables have been deemed harmful as their presence has been observed to\\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\\ndeterministically prefer one of the valid solutions from the solution space\\nover the others. We provide evidence contesting this conclusion and show that\\nthe phenomenon of deterministic bias is an artifact of improperly applying\\nneurosymbolic AI.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-10T15:28:36Z\"}"}
