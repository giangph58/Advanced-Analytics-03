{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20532v1\", \"title\": \"TriniMark: A Robust Generative Speech Watermarking Method for\\n  Trinity-Level Attribution\", \"summary\": \"The emergence of diffusion models has facilitated the generation of speech\\nwith reinforced fidelity and naturalness. While deepfake detection technologies\\nhave manifested the ability to identify AI-generated content, their efficacy\\ndecreases as generative models become increasingly sophisticated. Furthermore,\\ncurrent research in the field has not adequately addressed the necessity for\\nrobust watermarking to safeguard the intellectual property rights associated\\nwith synthetic speech and generative models. To remedy this deficiency, we\\npropose a \\\\textbf{ro}bust generative \\\\textbf{s}peech wat\\\\textbf{e}rmarking\\nmethod (TriniMark) for authenticating the generated content and safeguarding\\nthe copyrights by enabling the traceability of the diffusion model. We first\\ndesign a structure-lightweight watermark encoder that embeds watermarks into\\nthe time-domain features of speech and reconstructs the waveform directly. A\\ntemporal-aware gated convolutional network is meticulously designed in the\\nwatermark decoder for bit-wise watermark recovery. Subsequently, the\\nwaveform-guided fine-tuning strategy is proposed for fine-tuning the diffusion\\nmodel, which leverages the transferability of watermarks and enables the\\ndiffusion model to incorporate watermark knowledge effectively. When an\\nattacker trains a surrogate model using the outputs of the target model, the\\nembedded watermark can still be learned by the surrogate model and correctly\\nextracted. Comparative experiments with state-of-the-art methods demonstrate\\nthe superior robustness of our method, particularly in countering compound\\nattacks.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM,cs.CR,cs.SD,eess.AS\", \"published\": \"2025-04-29T08:23:28Z\"}"}
