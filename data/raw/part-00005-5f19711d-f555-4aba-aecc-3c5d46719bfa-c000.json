{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12080v1\", \"title\": \"DC-SAM: In-Context Segment Anything in Images and Videos via Dual\\n  Consistency\", \"summary\": \"Given a single labeled example, in-context segmentation aims to segment\\ncorresponding objects. This setting, known as one-shot segmentation in few-shot\\nlearning, explores the segmentation model's generalization ability and has been\\napplied to various vision tasks, including scene understanding and image/video\\nediting. While recent Segment Anything Models have achieved state-of-the-art\\nresults in interactive segmentation, these approaches are not directly\\napplicable to in-context segmentation. In this work, we propose the Dual\\nConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2\\nfor in-context segmentation of both images and videos. Our key insights are to\\nenhance the features of the SAM's prompt encoder in segmentation by providing\\nhigh-quality visual prompts. When generating a mask prior, we fuse the SAM\\nfeatures to better align the prompt encoder. Then, we design a cycle-consistent\\ncross-attention on fused features and initial visual prompts. Next, a\\ndual-branch design is provided by using the discriminative positive and\\nnegative prompts in the prompt encoder. Furthermore, we design a simple\\nmask-tube training strategy to adopt our proposed dual consistency method into\\nthe mask tube. Although the proposed DC-SAM is primarily designed for images,\\nit can be seamlessly extended to the video domain with the support of SAM2.\\nGiven the absence of in-context segmentation in the video domain, we manually\\ncurate and construct the first benchmark from existing video segmentation\\ndatasets, named In-Context Video Object Segmentation (IC-VOS), to better assess\\nthe in-context capability of the model. Extensive experiments demonstrate that\\nour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on\\nPASCAL-5i, and a J&F score of 71.52 on the proposed IC-VOS benchmark. Our\\nsource code and benchmark are available at https://github.com/zaplm/DC-SAM.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T13:41:59Z\"}"}
