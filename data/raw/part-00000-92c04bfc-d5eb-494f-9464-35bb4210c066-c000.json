{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04113v1\", \"title\": \"Advancing Zero-shot Text-to-Speech Intelligibility across Diverse\\n  Domains via Preference Alignment\", \"summary\": \"Modern zero-shot text-to-speech (TTS) systems, despite using extensive\\npre-training, often struggle in challenging scenarios such as tongue twisters,\\nrepeated words, code-switching, and cross-lingual synthesis, leading to\\nintelligibility issues. To address these limitations, this paper leverages\\npreference alignment techniques, which enable targeted construction of\\nout-of-pretraining-distribution data to enhance performance. We introduce a new\\ndataset, named the Intelligibility Preference Speech Dataset (INTP), and extend\\nthe Direct Preference Optimization (DPO) framework to accommodate diverse TTS\\narchitectures. After INTP alignment, in addition to intelligibility, we observe\\noverall improvements including naturalness, similarity, and audio quality for\\nmultiple TTS models across diverse domains. Based on that, we also verify the\\nweak-to-strong generalization ability of INTP for more intelligible models such\\nas CosyVoice 2 and Ints. Moreover, we showcase the potential for further\\nimprovements through iterative alignment based on Ints. Audio samples are\\navailable at https://intalign.github.io/.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,eess.AS\", \"published\": \"2025-05-07T04:04:31Z\"}"}
