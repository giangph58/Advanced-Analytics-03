{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21507v1\", \"title\": \"Efficient Conversational Search via Topical Locality in Dense Retrieval\", \"summary\": \"Pre-trained language models have been widely exploited to learn dense\\nrepresentations of documents and queries for information retrieval. While\\nprevious efforts have primarily focused on improving effectiveness and user\\nsatisfaction, response time remains a critical bottleneck of conversational\\nsearch systems. To address this, we exploit the topical locality inherent in\\nconversational queries, i.e., the tendency of queries within a conversation to\\nfocus on related topics. By leveraging query embedding similarities, we\\ndynamically restrict the search space to semantically relevant document\\nclusters, reducing computational complexity without compromising retrieval\\nquality. We evaluate our approach on the TREC CAsT 2019 and 2020 datasets using\\nmultiple embedding models and vector indexes, achieving improvements in\\nprocessing speed of up to 10.4X with little loss in performance (4.4X without\\nany loss). Our results show that the proposed system effectively handles\\ncomplex, multiturn queries with high precision and efficiency, offering a\\npractical solution for real-time conversational search.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.HC,H.3\", \"published\": \"2025-04-30T10:56:34Z\"}"}
