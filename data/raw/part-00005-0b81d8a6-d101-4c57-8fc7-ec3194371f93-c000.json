{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07760v1\", \"title\": \"PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model\\n  Development\", \"summary\": \"Deep learning (DL), a pivotal technology in artificial intelligence, has\\nrecently gained substantial traction in the domain of dental auxiliary\\ndiagnosis. However, its application has predominantly been confined to imaging\\nmodalities such as panoramic radiographs and Cone Beam Computed Tomography,\\nwith limited focus on auxiliary analysis specifically targeting Periapical\\nRadiographs (PR). PR are the most extensively utilized imaging modality in\\nendodontics and periodontics due to their capability to capture detailed local\\nlesions at a low cost. Nevertheless, challenges such as resolution limitations\\nand artifacts complicate the annotation and recognition of PR, leading to a\\nscarcity of publicly available, large-scale, high-quality PR analysis datasets.\\nThis scarcity has somewhat impeded the advancement of DL applications in PR\\nanalysis. In this paper, we present PRAD-10K, a dataset for PR analysis.\\nPRAD-10K comprises 10,000 clinical periapical radiograph images, with\\npixel-level annotations provided by professional dentists for nine distinct\\nanatomical structures, lesions, and artificial restorations or medical devices,\\nWe also include classification labels for images with typical conditions or\\nlesions. Furthermore, we introduce a DL network named PRNet to establish\\nbenchmarks for PR segmentation tasks. Experimental results demonstrate that\\nPRNet surpasses previous state-of-the-art medical image segmentation models on\\nthe PRAD-10K dataset. The codes and dataset will be made publicly available.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-10T13:58:58Z\"}"}
