{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21577v1\", \"title\": \"Latent Feature-Guided Conditional Diffusion for High-Fidelity Generative\\n  Image Semantic Communication\", \"summary\": \"Semantic communication is proposed and expected to improve the efficiency and\\neffectiveness of massive data transmission over sixth generation (6G) networks.\\nHowever, existing deep learning-based joint source and channel coding\\n(DeepJSCC) image semantic communication scheme predominantly focuses on\\noptimizing pixel-level metrics, and neglects human perceptual requirements,\\nwhich results in degraded perceptual quality. To address this issue, we propose\\na latent representation-oriented image semantic communication (LRISC) system,\\nwhich transmits latent semantic features for image generation with semantic\\nconsistency, thereby ensuring the perceptual quality at the receiver. In\\nparticular, we first map the source image to latent features in a\\nhigh-dimensional semantic space via a neural network (NN)- based non-linear\\ntransformation. Subsequently, these features are encoded using a joint source\\nand channel coding (JSCC) scheme with adaptive coding length for efficient\\ntransmission over a wireless channel. At the receiver, a conditional diffusion\\nmodel is developed by using the received latent features as conditional\\nguidance to steer the reverse diffusion process, progressively reconstructing\\nhigh-fidelity images while preserving semantic consistency. Moreover, we\\nintroduce a channel signal-to-noise ratio (SNR) adaptation mechanism, allowing\\none model to work across various channel states. Experiments show that the\\nproposed method significantly outperforms existing methods, in terms of learned\\nperceptual image patch similarity (LPIPS) and robustness against channel noise,\\nwith an average LPIPS reduction of 43.3% compared to DeepJSCC, while\\nguaranteeing the semantic consistency.\", \"main_category\": \"cs.MM\", \"categories\": \"cs.MM\", \"published\": \"2025-04-30T12:30:57Z\"}"}
