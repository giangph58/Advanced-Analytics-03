{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20904v1\", \"title\": \"Dual Explanations via Subgraph Matching for Malware Detection\", \"summary\": \"Interpretable malware detection is crucial for understanding harmful\\nbehaviors and building trust in automated security systems. Traditional\\nexplainable methods for Graph Neural Networks (GNNs) often highlight important\\nregions within a graph but fail to associate them with known benign or\\nmalicious behavioral patterns. This limitation reduces their utility in\\nsecurity contexts, where alignment with verified prototypes is essential. In\\nthis work, we introduce a novel dual prototype-driven explainable framework\\nthat interprets GNN-based malware detection decisions. This dual explainable\\nframework integrates a base explainer (a state-of-the-art explainer) with a\\nnovel second-level explainer which is designed by subgraph matching technique,\\ncalled SubMatch explainer. The proposed explainer assigns interpretable scores\\nto nodes based on their association with matched subgraphs, offering a\\nfine-grained distinction between benign and malicious regions. This\\nprototype-guided scoring mechanism enables more interpretable, behavior-aligned\\nexplanations. Experimental results demonstrate that our method preserves high\\ndetection performance while significantly improving interpretability in malware\\nanalysis.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.LG\", \"published\": \"2025-04-29T16:20:28Z\"}"}
