{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17719v1\", \"title\": \"Evaluating Uncertainty in Deep Gaussian Processes\", \"summary\": \"Reliable uncertainty estimates are crucial in modern machine learning. Deep\\nGaussian Processes (DGPs) and Deep Sigma Point Processes (DSPPs) extend GPs\\nhierarchically, offering promising methods for uncertainty quantification\\ngrounded in Bayesian principles. However, their empirical calibration and\\nrobustness under distribution shift relative to baselines like Deep Ensembles\\nremain understudied. This work evaluates these models on regression (CASP\\ndataset) and classification (ESR dataset) tasks, assessing predictive\\nperformance (MAE, Accu- racy), calibration using Negative Log-Likelihood (NLL)\\nand Expected Calibration Error (ECE), alongside robustness under various\\nsynthetic feature-level distribution shifts. Results indicate DSPPs provide\\nstrong in-distribution calibration leveraging their sigma point approximations.\\nHowever, compared to Deep Ensembles, which demonstrated superior robustness in\\nboth per- formance and calibration under the tested shifts, the GP-based\\nmethods showed vulnerabilities, exhibiting particular sensitivity in the\\nobserved metrics. Our findings underscore ensembles as a robust baseline,\\nsuggesting that while deep GP methods offer good in-distribution calibration,\\ntheir practical robustness under distribution shift requires careful\\nevaluation. To facilitate reproducibility, we make our code available at\\nhttps://github.com/matthjs/xai-gp.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG\", \"published\": \"2025-04-24T16:31:55Z\"}"}
