{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03533v1\", \"title\": \"Small-Scale-Fading-Aware Resource Allocation in Wireless Federated\\n  Learning\", \"summary\": \"Judicious resource allocation can effectively enhance federated learning (FL)\\ntraining performance in wireless networks by addressing both system and\\nstatistical heterogeneity. However, existing strategies typically rely on block\\nfading assumptions, which overlooks rapid channel fluctuations within each\\nround of FL gradient uploading, leading to a degradation in FL training\\nperformance. Therefore, this paper proposes a small-scale-fading-aware resource\\nallocation strategy using a multi-agent reinforcement learning (MARL)\\nframework. Specifically, we establish a one-step convergence bound of the FL\\nalgorithm and formulate the resource allocation problem as a decentralized\\npartially observable Markov decision process (Dec-POMDP), which is subsequently\\nsolved using the QMIX algorithm. In our framework, each client serves as an\\nagent that dynamically determines spectrum and power allocations within each\\ncoherence time slot, based on local observations and a reward derived from the\\nconvergence analysis. The MARL setting reduces the dimensionality of the action\\nspace and facilitates decentralized decision-making, enhancing the scalability\\nand practicality of the solution. Experimental results demonstrate that our\\nQMIX-based resource allocation strategy significantly outperforms baseline\\nmethods across various degrees of statistical heterogeneity. Additionally,\\nablation studies validate the critical importance of incorporating small-scale\\nfading dynamics, highlighting its role in optimizing FL performance.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-06T13:41:59Z\"}"}
