{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17427v1\", \"title\": \"Beyond Whole Dialogue Modeling: Contextual Disentanglement for\\n  Conversational Recommendation\", \"summary\": \"Conversational recommender systems aim to provide personalized\\nrecommendations by analyzing and utilizing contextual information related to\\ndialogue. However, existing methods typically model the dialogue context as a\\nwhole, neglecting the inherent complexity and entanglement within the dialogue.\\nSpecifically, a dialogue comprises both focus information and background\\ninformation, which mutually influence each other. Current methods tend to model\\nthese two types of information mixedly, leading to misinterpretation of users'\\nactual needs, thereby lowering the accuracy of recommendations. To address this\\nissue, this paper proposes a novel model to introduce contextual\\ndisentanglement for improving conversational recommender systems, named\\nDisenCRS. The proposed model DisenCRS employs a dual disentanglement framework,\\nincluding self-supervised contrastive disentanglement and counterfactual\\ninference disentanglement, to effectively distinguish focus information and\\nbackground information from the dialogue context under unsupervised conditions.\\nMoreover, we design an adaptive prompt learning module to automatically select\\nthe most suitable prompt based on the specific dialogue context, fully\\nleveraging the power of large language models. Experimental results on two\\nwidely used public datasets demonstrate that DisenCRS significantly outperforms\\nexisting conversational recommendation models, achieving superior performance\\non both item recommendation and response generation tasks.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-24T10:33:26Z\"}"}
