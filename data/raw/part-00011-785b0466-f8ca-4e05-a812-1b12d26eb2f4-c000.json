{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11001v1\", \"title\": \"ReZero: Enhancing LLM search ability by trying one-more-time\", \"summary\": \"Retrieval-Augmented Generation (RAG) improves Large Language Model (LLM)\\nperformance on knowledge-intensive tasks but depends heavily on initial search\\nquery quality. Current methods, often using Reinforcement Learning (RL),\\ntypically focus on query formulation or reasoning over results, without\\nexplicitly encouraging persistence after a failed search. We introduce ReZero\\n(Retry-Zero), a novel RL framework that directly rewards the act of retrying a\\nsearch query following an initial unsuccessful attempt. This incentivizes the\\nLLM to explore alternative queries rather than prematurely halting. ReZero\\ndemonstrates significant improvement, achieving 46.88% accuracy compared to a\\n25% baseline. By rewarding persistence, ReZero enhances LLM robustness in\\ncomplex information-seeking scenarios where initial queries may prove\\ninsufficient.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-15T09:18:21Z\"}"}
