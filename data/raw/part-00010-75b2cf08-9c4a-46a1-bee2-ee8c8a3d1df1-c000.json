{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03469v1\", \"title\": \"Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting\\n  Efficient Reasoning in Large Language Models\", \"summary\": \"Recent advances in large language models have demonstrated that Supervised\\nFine-Tuning (SFT) with Chain-of-Thought (CoT) reasoning data distilled from\\nlarge reasoning models (e.g., DeepSeek R1) can effectively transfer reasoning\\ncapabilities to non-reasoning models. However, models fine-tuned with this\\napproach inherit the \\\"overthinking\\\" problem from teacher models, producing\\nverbose and redundant reasoning chains during inference. To address this\\nchallenge, we propose \\\\textbf{L}ong-\\\\textbf{S}hort Chain-of-Thought\\n\\\\textbf{Mixture} \\\\textbf{S}upervised \\\\textbf{F}ine-\\\\textbf{T}uning\\n(\\\\textbf{LS-Mixture SFT}), which combines long CoT reasoning dataset with their\\nshort counterparts obtained through structure-preserved rewriting. Our\\nexperiments demonstrate that models trained using the LS-Mixture SFT method,\\ncompared to those trained with direct SFT, achieved an average accuracy\\nimprovement of 2.3\\\\% across various benchmarks while substantially reducing\\nmodel response length by approximately 47.61\\\\%. This work offers an approach to\\nendow non-reasoning models with reasoning capabilities through supervised\\nfine-tuning while avoiding the inherent overthinking problems inherited from\\nteacher models, thereby enabling efficient reasoning in the fine-tuned models.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-05-06T12:18:11Z\"}"}
