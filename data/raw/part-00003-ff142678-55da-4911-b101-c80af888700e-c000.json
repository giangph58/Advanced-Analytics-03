{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15068v1\", \"title\": \"The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation\\n  with Large Language Models\", \"summary\": \"Large Language Models (LLMs) have significantly enhanced the capabilities of\\ninformation access systems, especially with retrieval-augmented generation\\n(RAG). Nevertheless, the evaluation of RAG systems remains a barrier to\\ncontinued progress, a challenge we tackle in this work by proposing an\\nautomatic evaluation framework that is validated against human annotations. We\\nbelieve that the nugget evaluation methodology provides a solid foundation for\\nevaluating RAG systems. This approach, originally developed for the TREC\\nQuestion Answering (QA) Track in 2003, evaluates systems based on atomic facts\\nthat should be present in good answers. Our efforts focus on \\\"refactoring\\\" this\\nmethodology, where we describe the AutoNuggetizer framework that specifically\\napplies LLMs to both automatically create nuggets and automatically assign\\nnuggets to system answers. In the context of the TREC 2024 RAG Track, we\\ncalibrate a fully automatic approach against strategies where nuggets are\\ncreated manually or semi-manually by human assessors and then assigned manually\\nto system answers. Based on results from a community-wide evaluation, we\\nobserve strong agreement at the run level between scores derived from fully\\nautomatic nugget evaluation and human-based variants. The agreement is stronger\\nwhen individual framework components such as nugget assignment are automated\\nindependently. This suggests that our evaluation framework provides tradeoffs\\nbetween effort and quality that can be used to guide the development of future\\nRAG systems. However, further research is necessary to refine our approach,\\nparticularly in establishing robust per-topic agreement to diagnose system\\nfailures effectively.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.CL\", \"published\": \"2025-04-21T12:55:06Z\"}"}
