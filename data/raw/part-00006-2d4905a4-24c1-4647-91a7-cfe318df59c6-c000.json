{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04502v1\", \"title\": \"Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video\\n  Face Detection and Recognition\", \"summary\": \"Video face detection and recognition in public places at the edge is required\\nin several applications, such as security reinforcement and contactless access\\nto authorized venues. This paper aims to maximize the simultaneous usage of\\nhardware engines available in edge GPUs nowadays by leveraging the concurrency\\nand pipelining of tasks required for face detection and recognition. This also\\nincludes the video decoding task, which is required in most face monitoring\\napplications as the video streams are usually carried via Gbps Ethernet\\nnetwork. This constitutes an improvement over previous works where the tasks\\nare usually allocated to a single engine due to the lack of a unified and\\nautomated framework that simultaneously explores all hardware engines. In\\naddition, previously, the input faces were usually embedded in still images or\\nwithin raw video streams that overlook the burst delay caused by the decoding\\nstage. The results on real-life video streams suggest that simultaneously using\\nall the hardware engines available in the recent NVIDIA edge Orin GPU, higher\\nthroughput, and a slight saving of power consumption of around 300 mW,\\naccounting for around 5%, have been achieved while satisfying the real-time\\nperformance constraint. The performance gets even higher by considering several\\nvideo streams simultaneously. Further performance improvement could have been\\nobtained if the number of shuffle layers that were created by the tensor RT\\nframework for the face recognition task was lower. Thus, the paper suggests\\nsome hardware improvements to the existing edge GPU processors to enhance their\\nperformance even higher.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AR,eess.IV\", \"published\": \"2025-05-07T15:22:17Z\"}"}
