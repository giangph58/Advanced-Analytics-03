{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23908v1\", \"title\": \"MAER-Nav: Bidirectional Motion Learning Through Mirror-Augmented\\n  Experience Replay for Robot Navigation\", \"summary\": \"Deep Reinforcement Learning (DRL) based navigation methods have demonstrated\\npromising results for mobile robots, but suffer from limited action flexibility\\nin confined spaces. Conventional DRL approaches predominantly learn\\nforward-motion policies, causing robots to become trapped in complex\\nenvironments where backward maneuvers are necessary for recovery. This paper\\npresents MAER-Nav (Mirror-Augmented Experience Replay for Robot Navigation), a\\nnovel framework that enables bidirectional motion learning without requiring\\nexplicit failure-driven hindsight experience replay or reward function\\nmodifications. Our approach integrates a mirror-augmented experience replay\\nmechanism with curriculum learning to generate synthetic backward navigation\\nexperiences from successful trajectories. Experimental results in both\\nsimulation and real-world environments demonstrate that MAER-Nav significantly\\noutperforms state-of-the-art methods while maintaining strong forward\\nnavigation capabilities. The framework effectively bridges the gap between the\\ncomprehensive action space utilization of traditional planning methods and the\\nenvironmental adaptability of learning-based approaches, enabling robust\\nnavigation in scenarios where conventional DRL methods consistently fail.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-03-31T09:58:28Z\"}"}
