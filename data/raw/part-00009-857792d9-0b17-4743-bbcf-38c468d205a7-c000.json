{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10158v1\", \"title\": \"COUNTS: Benchmarking Object Detectors and Multimodal Large Language\\n  Models under Distribution Shifts\", \"summary\": \"Current object detectors often suffer significant perfor-mance degradation in\\nreal-world applications when encountering distributional shifts. Consequently,\\nthe out-of-distribution (OOD) generalization capability of object detectors has\\ngarnered increasing attention from researchers. Despite this growing interest,\\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\\nbenchmark with fine-grained annotations tailored to assess the OOD\\ngeneralization on more intricate tasks like object detection and grounding. To\\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\\nto comprehensively evaluate the OOD generalization capabilities of object\\ndetectors by utilizing controlled distribution shifts between training and\\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\\ngrounding abilities in multimodal large language models (MLLMs). Our findings\\nreveal that, while large models and extensive pre-training data substantially\\nen hance performance in in-distribution (IID) scenarios, significant\\nlimitations and opportunities for improvement persist in OOD contexts for both\\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\\nCOUNTS facilitates advancements in the development and assessment of robust\\nobject detectors and MLLMs capable of maintaining high performance under\\ndistributional shifts.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-14T12:13:33Z\"}"}
