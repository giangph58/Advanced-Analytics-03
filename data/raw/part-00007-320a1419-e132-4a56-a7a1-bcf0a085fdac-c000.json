{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00591v1\", \"title\": \"Explainable AI in Spatial Analysis\", \"summary\": \"This chapter discusses the opportunities of eXplainable Artificial\\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\\nspatial analysis is to model spatial relationships and infer spatial processes\\nto generate knowledge from spatial data, which has been largely based on\\nspatial statistical methods. More recently, machine learning offers scalable\\nand flexible approaches that complement traditional methods and has been\\nincreasingly applied in spatial data science. Despite its advantages, machine\\nlearning is often criticized for being a black box, which limits our\\nunderstanding of model behavior and output. Recognizing this limitation, XAI\\nhas emerged as a pivotal field in AI that provides methods to explain the\\noutput of machine learning models to enhance transparency and understanding.\\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\\nreliability of results obtained from machine learning models. This chapter\\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\\napproaches, which is arguably the most popular XAI method, and their\\nintegration with spatial analysis. An empirical example of county-level voting\\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\\nof Shapley values and spatial analysis with a comparison to multi-scale\\ngeographically weighted regression. The chapter concludes with a discussion on\\nthe challenges and limitations of current XAI techniques and proposes new\\ndirections.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,econ.EM\", \"published\": \"2025-05-01T15:25:23Z\"}"}
