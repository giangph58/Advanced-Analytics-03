{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20452v1\", \"title\": \"Enhancing News Recommendation with Hierarchical LLM Prompting\", \"summary\": \"Personalized news recommendation systems often struggle to effectively\\ncapture the complexity of user preferences, as they rely heavily on shallow\\nrepresentations, such as article titles and abstracts. To address this problem,\\nwe introduce a novel method, namely PNR-LLM, for Large Language Models for\\nPersonalized News Recommendation. Specifically, PNR-LLM harnesses the\\ngeneration capabilities of LLMs to enrich news titles and abstracts, and\\nconsequently improves recommendation quality. PNR-LLM contains a novel module,\\nNews Enrichment via LLMs, which generates deeper semantic information and\\nrelevant entities from articles, transforming shallow contents into richer\\nrepresentations. We further propose an attention mechanism to aggregate\\nenriched semantic- and entity-level data, forming unified user and news\\nembeddings that reveal a more accurate user-news match. Extensive experiments\\non MIND datasets show that PNR-LLM outperforms state-of-the-art baselines.\\nMoreover, the proposed data enrichment module is model-agnostic, and we\\nempirically show that applying our proposed module to multiple existing models\\ncan further improve their performance, verifying the advantage of our design.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.AI\", \"published\": \"2025-04-29T06:02:16Z\"}"}
