{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06638v1\", \"title\": \"HGMamba: Enhancing 3D Human Pose Estimation with a HyperGCN-Mamba\\n  Network\", \"summary\": \"3D human pose lifting is a promising research area that leverages estimated\\nand ground-truth 2D human pose data for training. While existing approaches\\nprimarily aim to enhance the performance of estimated 2D poses, they often\\nstruggle when applied to ground-truth 2D pose data. We observe that achieving\\naccurate 3D pose reconstruction from ground-truth 2D poses requires precise\\nmodeling of local pose structures, alongside the ability to extract robust\\nglobal spatio-temporal features. To address these challenges, we propose a\\nnovel Hyper-GCN and Shuffle Mamba (HGMamba) block, which processes input data\\nthrough two parallel streams: Hyper-GCN and Shuffle-Mamba. The Hyper-GCN stream\\nmodels the human body structure as hypergraphs with varying levels of\\ngranularity to effectively capture local joint dependencies. Meanwhile, the\\nShuffle Mamba stream leverages a state space model to perform spatio-temporal\\nscanning across all joints, enabling the establishment of global dependencies.\\nBy adaptively fusing these two representations, HGMamba achieves strong global\\nfeature modeling while excelling at local structure modeling. We stack multiple\\nHGMamba blocks to create three variants of our model, allowing users to select\\nthe most suitable configuration based on the desired speed-accuracy trade-off.\\nExtensive evaluations on the Human3.6M and MPI-INF-3DHP benchmark datasets\\ndemonstrate the effectiveness of our approach. HGMamba-B achieves\\nstate-of-the-art results, with P1 errors of 38.65 mm and 14.33 mm on the\\nrespective datasets. Code and models are available:\\nhttps://github.com/HuCui2022/HGMamba\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T07:28:19Z\"}"}
