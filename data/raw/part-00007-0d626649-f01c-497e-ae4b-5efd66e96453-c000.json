{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04145v1\", \"title\": \"On submodularity of the expected information gain\", \"summary\": \"We consider finite-dimensional linear Gaussian Bayesian inverse problems with\\nuncorrelated sensor measurements. In this setting, it is known that the\\nexpected information gain (EIG), measured by the expected Kullback-Leibler\\ndivergence from the posterior to prior, is submodular. We present a simple\\nalternative proof of this fact tailored to a weighted inner product space\\nsetting arising from discretization of infinite-dimensional linear inverse\\nproblems governed by partial differential equations (PDEs).\", \"main_category\": \"math.OC\", \"categories\": \"math.OC\", \"published\": \"2025-05-07T05:52:02Z\"}"}
