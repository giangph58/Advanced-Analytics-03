{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07607v1\", \"title\": \"Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization\\n  with Linear Inequality Constraints\", \"summary\": \"We propose smoothed primal-dual algorithms for solving stochastic and smooth\\nnonconvex optimization problems with linear inequality constraints. Our\\nalgorithms are single-loop and only require a single stochastic gradient based\\non one sample at each iteration. A distinguishing feature of our algorithm is\\nthat it is based on an inexact gradient descent framework for the Moreau\\nenvelope, where the gradient of the Moreau envelope is estimated using one step\\nof a stochastic primal-dual augmented Lagrangian method. To handle inequality\\nconstraints and stochasticity, we combine the recently established global error\\nbounds in constrained optimization with a Moreau envelope-based analysis of\\nstochastic proximal algorithms. For obtaining $\\\\varepsilon$-stationary points,\\nwe establish the optimal $O(\\\\varepsilon^{-4})$ sample complexity guarantee for\\nour algorithms and provide extensions to stochastic linear constraints. We also\\nshow how to improve this complexity to $O(\\\\varepsilon^{-3})$ by using variance\\nreduction and the expected smoothness assumption. Unlike existing methods, the\\niterations of our algorithms are free of subproblems, large batch sizes or\\nincreasing penalty parameters and use dual variable updates to ensure\\nfeasibility.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC,cs.LG\", \"published\": \"2025-04-10T09:59:43Z\"}"}
