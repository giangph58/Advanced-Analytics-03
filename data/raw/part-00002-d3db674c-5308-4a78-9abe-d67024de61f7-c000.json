{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11277v1\", \"title\": \"From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning\\n  Method for LLMs\", \"summary\": \"Large language models (LLMs) exhibit excellent performance in natural\\nlanguage processing (NLP), but remain highly sensitive to the quality of input\\nqueries, especially when these queries contain misleading or inaccurate\\ninformation. Existing methods focus on correcting the output, but they often\\noverlook the potential of improving the ability of LLMs to detect and correct\\nmisleading content in the input itself. In this paper, we propose a novel\\nthree-stage fine-tuning method that enhances the ability of LLMs to detect and\\ncorrect misleading information in the input, further improving response\\naccuracy and reducing hallucinations. Specifically, the three stages include\\n(1) training LLMs to identify misleading information, (2) training LLMs to\\ncorrect the misleading information using built-in or external knowledge, and\\n(3) training LLMs to generate accurate answers based on the corrected queries.\\nTo evaluate our method, we conducted experiments on three datasets for the\\nhallucination detection task and the question answering (QA) task, as well as\\ntwo datasets containing misleading information that we constructed. The\\nexperimental results demonstrate that our method significantly improves the\\naccuracy and factuality of LLM responses, while also enhancing the ability to\\ndetect hallucinations and reducing the generation of hallucinations in the\\noutput, particularly when the query contains misleading information. We will\\npublicly release our code upon acceptance.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-15T15:16:45Z\"}"}
