{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15634v1\", \"title\": \"Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar\\n  Protein Folding Model with Attention-based layers\", \"summary\": \"Transformer-based architectures have recently propelled advances in sequence\\nmodeling across domains, but their application to the hydrophobic-hydrophilic\\n(H-P) model for protein folding remains relatively unexplored. In this work, we\\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\\n(Transformers) to address the 3D H-P protein folding problem. Our system\\nformulates folding decisions as a self-avoiding walk in a reinforced\\nenvironment, and employs a specialized reward function based on favorable\\nhydrophobic interactions. To improve performance, the method incorporates\\nvalidity check including symmetry-breaking constraints, dueling and double\\nQ-learning, and prioritized replay to focus learning on critical transitions.\\nExperimental evaluations on standard benchmark sequences demonstrate that our\\napproach achieves several known best solutions for shorter sequences, and\\nobtains near-optimal results for longer chains. This study underscores the\\npromise of attention-based reinforcement learning for protein folding, and\\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\\nlattice models.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-22T06:53:36Z\"}"}
