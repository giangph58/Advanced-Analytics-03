{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16871v1\", \"title\": \"Exploring How LLMs Capture and Represent Domain-Specific Knowledge\", \"summary\": \"We study whether Large Language Models (LLMs) inherently capture\\ndomain-specific nuances in natural language. Our experiments probe the domain\\nsensitivity of LLMs by examining their ability to distinguish queries from\\ndifferent domains using hidden states generated during the prefill phase. We\\nreveal latent domain-related trajectories that indicate the model's internal\\nrecognition of query domains. We also study the robustness of these domain\\nrepresentations to variations in prompt styles and sources. Our approach\\nleverages these representations for model selection, mapping the LLM that best\\nmatches the domain trace of the input query (i.e., the model with the highest\\nperformance on similar traces). Our findings show that LLMs can differentiate\\nqueries for related domains, and that the fine-tuned model is not always the\\nmost accurate. Unlike previous work, our interpretations apply to both closed\\nand open-ended generative tasks\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-23T16:46:06Z\"}"}
