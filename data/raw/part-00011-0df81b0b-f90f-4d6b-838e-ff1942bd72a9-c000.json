{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12913v1\", \"title\": \"MAIN: Mutual Alignment Is Necessary for instruction tuning\", \"summary\": \"Instruction tuning has enabled large language models (LLMs) to achieve\\nremarkable performance, but its success heavily depends on the availability of\\nlarge-scale, high-quality instruction-response pairs. However, current methods\\nfor scaling up data generation often overlook a crucial aspect: the alignment\\nbetween instructions and responses. We hypothesize that high-quality\\ninstruction-response pairs are not defined by the individual quality of each\\ncomponent, but by the extent of their alignment with each other. To address\\nthis, we propose a Mutual Alignment Framework (MAIN) that ensures coherence\\nbetween the instruction and response through mutual constraints. Experiments\\ndemonstrate that models such as LLaMA and Mistral, fine-tuned within this\\nframework, outperform traditional methods across multiple benchmarks. This\\napproach underscores the critical role of instruction-response alignment in\\nenabling scalable and high-quality instruction tuning for LLMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-17T13:02:44Z\"}"}
