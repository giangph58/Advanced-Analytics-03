{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19687v1\", \"title\": \"Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network\\n  for Low-Dose CT MAR\", \"summary\": \"Low-dose CT (LDCT) is capable of reducing X-ray radiation exposure, but it\\nwill potentially degrade image quality, even yields metal artifacts at the case\\nof metallic implants. For simultaneous LDCT reconstruction and metal artifact\\nreduction (LDMAR), existing deep learning-based efforts face two main\\nlimitations: i) the network design neglects multi-scale and within-scale\\ninformation; ii) training a distinct model for each dose necessitates\\nsignificant storage space for multiple doses. To fill these gaps, we propose a\\nprompt guiding multi-scale adaptive sparse representation-driven network,\\nabbreviated as PMSRNet, for LDMAR task. Specifically, we construct PMSRNet\\ninspired from multi-scale sparsifying frames, and it can simultaneously employ\\nwithin-scale characteristics and cross-scale complementarity owing to an\\nelaborated prompt guiding scale-adaptive threshold generator (PSATG) and a\\nbuilt multi-scale coefficient fusion module (MSFuM). The PSATG can adaptively\\ncapture multiple contextual information to generate more faithful thresholds,\\nachieved by fusing features from local, regional, and global levels.\\nFurthermore, we elaborate a model interpretable dual domain LDMAR framework\\ncalled PDuMSRNet, and train single model with a prompt guiding strategy for\\nmultiple dose levels. We build a prompt guiding module, whose input contains\\ndose level, metal mask and input instance, to provide various guiding\\ninformation, allowing a single model to accommodate various CT dose settings.\\nExtensive experiments at various dose levels demonstrate that the proposed\\nmethods outperform the state-of-the-art LDMAR methods.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T11:23:57Z\"}"}
