{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13054v1\", \"title\": \"Aspect-Based Summarization with Self-Aspect Retrieval Enhanced\\n  Generation\", \"summary\": \"Aspect-based summarization aims to generate summaries tailored to specific\\naspects, addressing the resource constraints and limited generalizability of\\ntraditional summarization approaches. Recently, large language models have\\nshown promise in this task without the need for training. However, they rely\\nexcessively on prompt engineering and face token limits and hallucination\\nchallenges, especially with in-context learning. To address these challenges,\\nin this paper, we propose a novel framework for aspect-based summarization:\\nSelf-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely\\non in-context learning, given an aspect, we employ an embedding-driven\\nretrieval mechanism to identify its relevant text segments. This approach\\nextracts the pertinent content while avoiding unnecessary details, thereby\\nmitigating the challenge of token limits. Moreover, our framework optimizes\\ntoken usage by deleting unrelated parts of the text and ensuring that the model\\ngenerates output strictly based on the given aspect. With extensive experiments\\non benchmark datasets, we demonstrate that our framework not only achieves\\nsuperior performance but also effectively mitigates the token limitation\\nproblem.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-17T16:09:57Z\"}"}
