{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12699v1\", \"title\": \"Unsupervised Cross-Domain 3D Human Pose Estimation via\\n  Pseudo-Label-Guided Global Transforms\", \"summary\": \"Existing 3D human pose estimation methods often suffer in performance, when\\napplied to cross-scenario inference, due to domain shifts in characteristics\\nsuch as camera viewpoint, position, posture, and body size. Among these\\nfactors, camera viewpoints and locations {have been shown} to contribute\\nsignificantly to the domain gap by influencing the global positions of human\\nposes. To address this, we propose a novel framework that explicitly conducts\\nglobal transformations between pose positions in the camera coordinate systems\\nof source and target domains. We start with a Pseudo-Label Generation Module\\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\\nposes. Then, a Global Transformation Module leverages a human-centered\\ncoordinate system as a novel bridging mechanism to seamlessly align the\\npositional orientations of poses across disparate domains, ensuring consistent\\nspatial referencing. To further enhance generalization, a Pose Augmentor is\\nincorporated to address variations in human posture and body size. This process\\nis iterative, allowing refined pseudo-labels to progressively improve guidance\\nfor domain adaptation. Our method is evaluated on various cross-dataset\\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\\noutperforms state-of-the-art approaches and even outperforms the target-trained\\nmodel.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T06:57:20Z\"}"}
