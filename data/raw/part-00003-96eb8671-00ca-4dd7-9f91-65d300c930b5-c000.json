{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00451v1\", \"title\": \"The iterated Dirichlet process and applications to Bayesian inference\", \"summary\": \"Consider an i.i.d. sequence of random variables, taking values in some space\\n$S$, whose underlying distribution is unknown. In problems of Bayesian\\ninference, one models this unknown distribution as a random measure, and the\\nlaw of this random measure is the prior. When $S = \\\\{0, 1\\\\}$, a commonly used\\nprior is the uniform distribution on $[0, 1]$, or more generally, the beta\\ndistribution. When $S$ is finite, the analogous choice is the Dirichlet\\ndistribution. For a general space $S$, we are led naturally to the Dirichlet\\nprocess (see [Ferguson, 1973]).\\n  Here, we consider an array of random variables, and in so doing are led to\\nwhat we call the iterated Dirichlet process (IDP). We define the IDP and then\\nshow how to compute the posterior distribution, given a finite set of\\nobservations, using the method of sequential imputation. Ordinarily, this\\nmethod requires the existence of certain joint density functions, which the IDP\\nlacks. We therefore present a new, more general proof of the validity of\\nsequential imputation, and show that the hypotheses of our proof are satisfied\\nby the IDP.\", \"main_category\": \"math.ST\", \"categories\": \"math.ST,math.PR,stat.TH\", \"published\": \"2025-05-01T10:53:49Z\"}"}
