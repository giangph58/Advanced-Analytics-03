{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02318v1\", \"title\": \"X-Capture: An Open-Source Portable Device for Multi-Sensory Learning\", \"summary\": \"Understanding objects through multiple sensory modalities is fundamental to\\nhuman perception, enabling cross-sensory integration and richer comprehension.\\nFor AI and robotic systems to replicate this ability, access to diverse,\\nhigh-quality multi-sensory data is critical. Existing datasets are often\\nlimited by their focus on controlled environments, simulated objects, or\\nrestricted modality pairings. We introduce X-Capture, an open-source, portable,\\nand cost-effective device for real-world multi-sensory data collection, capable\\nof capturing correlated RGBD images, tactile readings, and impact audio. With a\\nbuild cost under $1,000, X-Capture democratizes the creation of multi-sensory\\ndatasets, requiring only consumer-grade tools for assembly. Using X-Capture, we\\ncurate a sample dataset of 3,000 total points on 500 everyday objects from\\ndiverse, real-world environments, offering both richness and variety. Our\\nexperiments demonstrate the value of both the quantity and the sensory breadth\\nof our data for both pretraining and fine-tuning multi-modal representations\\nfor object-centric tasks such as cross-sensory retrieval and reconstruction.\\nX-Capture lays the groundwork for advancing human-like sensory representations\\nin AI, emphasizing scalability, accessibility, and real-world applicability.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-04-03T06:44:25Z\"}"}
