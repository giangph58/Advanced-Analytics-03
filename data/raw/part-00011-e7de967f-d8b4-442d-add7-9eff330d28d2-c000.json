{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04855v1\", \"title\": \"BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents\", \"summary\": \"Detecting biases in structured data is a complex and time-consuming task.\\nExisting automated techniques are limited in diversity of data types and\\nheavily reliant on human case-by-case handling, resulting in a lack of\\ngeneralizability. Currently, large language model (LLM)-based agents have made\\nsignificant progress in data science, but their ability to detect data biases\\nis still insufficiently explored. To address this gap, we introduce the first\\nend-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for\\nautomatic bias detection in structured data based on specific user\\nrequirements. It first develops a multi-stage plan to analyze user-specified\\nbias detection tasks and then implements it with a diverse and well-suited set\\nof tools. It delivers detailed results that include explanations and\\nvisualizations. To address the lack of a standardized framework for evaluating\\nthe capability of LLM agents to detect biases in data, we further propose a\\ncomprehensive benchmark that includes multiple evaluation metrics and a large\\nset of test cases. Extensive experiments demonstrate that our framework\\nachieves exceptional overall performance in structured data bias detection,\\nsetting a new milestone for fairer data applications.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-07T09:12:00Z\"}"}
