{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04717v1\", \"title\": \"Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large\\n  Language Models\", \"summary\": \"Recent advancements in large language models (LLMs) have revolutionized their\\nability to handle single-turn tasks, yet real-world applications demand\\nsophisticated multi-turn interactions. This survey provides a comprehensive\\nreview of recent advancements in evaluating and enhancing multi-turn\\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\\nfollowing in diverse domains such as math and coding to complex conversational\\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\\nsettings, we systematically examine the challenges of maintaining context,\\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\\norganizes current benchmarks and datasets into coherent categories that reflect\\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\\nreview a range of enhancement methodologies under multi-turn settings,\\nincluding model-centric strategies (contextual learning, supervised\\nfine-tuning, reinforcement learning, and new architectures), external\\nintegration approaches (memory-augmented, retrieval-based methods, and\\nknowledge graph), and agent-based techniques for collaborative interactions.\\nFinally, we discuss open challenges and propose future directions for research\\nto further advance the robustness and effectiveness of multi-turn interactions\\nin LLMs. Related resources and papers are available at\\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-07T04:00:08Z\"}"}
