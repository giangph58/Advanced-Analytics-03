{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04972v1\", \"title\": \"AI and Vision based Autonomous Navigation of Nano-Drones in\\n  Partially-Known Environments\", \"summary\": \"The miniaturisation of sensors and processors, the advancements in connected\\nedge intelligence, and the exponential interest in Artificial Intelligence are\\nboosting the affirmation of autonomous nano-size drones in the Internet of\\nRobotic Things ecosystem. However, achieving safe autonomous navigation and\\nhigh-level tasks such as exploration and surveillance with these tiny platforms\\nis extremely challenging due to their limited resources. This work focuses on\\nenabling the safe and autonomous flight of a pocket-size, 30-gram platform\\ncalled Crazyflie 2.1 in a partially known environment. We propose a novel\\nAI-aided, vision-based reactive planning method for obstacle avoidance under\\nthe ambit of Integrated Sensing, Computing and Communication paradigm. We deal\\nwith the constraints of the nano-drone by splitting the navigation task into\\ntwo parts: a deep learning-based object detector runs on the edge (external\\nhardware) while the planning algorithm is executed onboard. The results show\\nthe ability to command the drone at $\\\\sim8$ frames-per-second and a model\\nperformance reaching a COCO mean-average-precision of $60.8$. Field experiments\\ndemonstrate the feasibility of the solution with the drone flying at a top\\nspeed of $1$ m/s while steering away from an obstacle placed in an unknown\\nposition and reaching the target destination. The outcome highlights the\\ncompatibility of the communication delay and the model performance with the\\nrequirements of the real-time navigation task. We provide a feasible\\nalternative to a fully onboard implementation that can be extended to\\nautonomous exploration with nano-drones.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.CV,cs.LG,cs.NI\", \"published\": \"2025-05-08T06:16:36Z\"}"}
