{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12063v1\", \"title\": \"Optimizing Compound Retrieval Systems\", \"summary\": \"Modern retrieval systems do not rely on a single ranking model to construct\\ntheir rankings. Instead, they generally take a cascading approach where a\\nsequence of ranking models are applied in multiple re-ranking stages. Thereby,\\nthey balance the quality of the top-K ranking with computational costs by\\nlimiting the number of documents each model re-ranks. However, the cascading\\napproach is not the only way models can interact to form a retrieval system.\\n  We propose the concept of compound retrieval systems as a broader class of\\nretrieval systems that apply multiple prediction models. This encapsulates\\ncascading models but also allows other types of interactions than top-K\\nre-ranking. In particular, we enable interactions with large language models\\n(LLMs) which can provide relative relevance comparisons. We focus on the\\noptimization of compound retrieval system design which uniquely involves\\nlearning where to apply the component models and how to aggregate their\\npredictions into a final ranking. This work shows how our compound approach can\\ncombine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM\\nrelevance predictions, while optimizing a given ranking metric and efficiency\\ntarget. Our experimental results show optimized compound retrieval systems\\nprovide better trade-offs between effectiveness and efficiency than cascading\\napproaches, even when applied in a self-supervised manner.\\n  With the introduction of compound retrieval systems, we hope to inspire the\\ninformation retrieval field to more out-of-the-box thinking on how prediction\\nmodels can interact to form rankings.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR,cs.AI,cs.LG\", \"published\": \"2025-04-16T13:18:16Z\"}"}
