{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16601v1\", \"title\": \"Comparing Large Language Models and Traditional Machine Translation\\n  Tools for Translating Medical Consultation Summaries: A Pilot Study\", \"summary\": \"This study evaluates how well large language models (LLMs) and traditional\\nmachine translation (MT) tools translate medical consultation summaries from\\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\\nfriendly and clinician, focused texts using standard automated metrics. Results\\nshowed that traditional MT tools generally performed better, especially for\\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\\nChinese, when translating simpler summaries. Arabic translations improved with\\ncomplexity due to the language's morphology. Overall, while LLMs offer\\ncontextual flexibility, they remain inconsistent, and current evaluation\\nmetrics fail to capture clinical relevance. The study highlights the need for\\ndomain-specific training, improved evaluation methods, and human oversight in\\nmedical translation.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-23T10:31:33Z\"}"}
