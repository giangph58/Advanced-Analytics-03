{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07787v1\", \"title\": \"Fairness Mediator: Neutralize Stereotype Associations to Mitigate Bias\\n  in Large Language Models\", \"summary\": \"LLMs have demonstrated remarkable performance across diverse applications,\\nyet they inadvertently absorb spurious correlations from training data, leading\\nto stereotype associations between biased concepts and specific social groups.\\nThese associations perpetuate and even amplify harmful social biases, raising\\nsignificant fairness concerns. To mitigate such biases, prior studies have\\nattempted to project model embeddings into unbiased spaces during inference.\\nHowever, these approaches have shown limited effectiveness due to their weak\\nalignment with downstream social biases. Inspired by the observation that\\nconcept cognition in LLMs is primarily represented through a linear associative\\nmemory mechanism, where key-value mapping occurs in the MLP layers, we posited\\nthat biased concepts and social groups are similarly encoded as entity (key)\\nand information (value) pairs, which can be manipulated to promote fairer\\nassociations. To this end, we propose Fairness Mediator (FairMed), a bias\\nmitigation framework that neutralizes stereotype associations. Our framework\\ncomprises two main components: a stereotype association prober and an\\nadversarial debiasing neutralizer. The prober captures stereotype associations\\nencoded within MLP layer activations by employing prompts centered around\\nbiased concepts to detect the emission probabilities for social groups.\\nSubsequently, the adversarial debiasing neutralizer intervenes in MLP\\nactivations during inference to equalize the association probabilities among\\ndifferent social groups. Extensive experiments across nine protected attributes\\nshow that FairMed significantly outperforms SOTA methods in effectiveness.\\nCompared to the most effective baseline, FairMed presents competitive\\nefficiency by cutting mitigation overhead by hundreds of minutes. FairMed also\\nmaintains the LLM's language understanding capabilities without compromising\\noverall performance.\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE\", \"published\": \"2025-04-10T14:23:06Z\"}"}
