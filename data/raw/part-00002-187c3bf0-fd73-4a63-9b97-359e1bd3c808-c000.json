{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05189v1\", \"title\": \"Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language\\n  Models\", \"summary\": \"Prompt learning is one of the most effective paradigms for adapting\\npre-trained vision-language models (VLMs) to the biomedical image\\nclassification tasks in few shot scenarios. However, most of the current prompt\\nlearning methods only used the text prompts and ignored the particular\\nstructures (such as the complex anatomical structures and subtle pathological\\nfeatures) in the biomedical images. In this work, we propose Biomed-DPT, a\\nknowledge-enhanced dual modality prompt tuning technique. In designing the text\\nprompt, Biomed-DPT constructs a dual prompt including the template-driven\\nclinical prompts and the large language model (LLM)-driven domain-adapted\\nprompts, then extracts the clinical knowledge from the domain-adapted prompts\\nthrough the knowledge distillation technique. In designing the vision prompt,\\nBiomed-DPT introduces the zero vector as a soft prompt to leverage attention\\nre-weighting so that the focus on non-diagnostic regions and the recognition of\\nnon-critical pathological features are avoided. Biomed-DPT achieves an average\\nclassification accuracy of 66.14\\\\% across 11 biomedical image datasets covering\\n9 modalities and 10 organs, with performance reaching 78.06\\\\% in base classes\\nand 75.97\\\\% in novel classes, surpassing the Context Optimization (CoOp) method\\nby 6.20\\\\%, 3.78\\\\%, and 8.04\\\\%, respectively. Our code are available at\\n\\\\underline{https://github.com/Kanyooo/Biomed-DPT}.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-05-08T12:37:51Z\"}"}
