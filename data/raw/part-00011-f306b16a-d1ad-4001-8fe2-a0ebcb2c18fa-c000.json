{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13149v1\", \"title\": \"Long Range Navigator (LRN): Extending robot planning horizons beyond\\n  metric maps\", \"summary\": \"A robot navigating an outdoor environment with no prior knowledge of the\\nspace must rely on its local sensing to perceive its surroundings and plan.\\nThis can come in the form of a local metric map or local policy with some fixed\\nhorizon. Beyond that, there is a fog of unknown space marked with some fixed\\ncost. A limited planning horizon can often result in myopic decisions leading\\nthe robot off course or worse, into very difficult terrain. Ideally, we would\\nlike the robot to have full knowledge that can be orders of magnitude larger\\nthan a local cost map. In practice, this is intractable due to sparse sensing\\ninformation and often computationally expensive. In this work, we make a key\\nobservation that long-range navigation only necessitates identifying good\\nfrontier directions for planning instead of full map knowledge. To this end, we\\npropose Long Range Navigator (LRN), that learns an intermediate affordance\\nrepresentation mapping high-dimensional camera images to `affordable' frontiers\\nfor planning, and then optimizing for maximum alignment with the desired goal.\\nLRN notably is trained entirely on unlabeled ego-centric videos making it easy\\nto scale and adapt to new platforms. Through extensive off-road experiments on\\nSpot and a Big Vehicle, we find that augmenting existing navigation stacks with\\nLRN reduces human interventions at test-time and leads to faster decision\\nmaking indicating the relevance of LRN. https://personalrobotics.github.io/lrn\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-17T17:55:08Z\"}"}
