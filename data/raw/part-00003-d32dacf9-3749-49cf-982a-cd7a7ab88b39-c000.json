{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15052v1\", \"title\": \"Testing LLMs' Capabilities in Annotating Translations Based on an Error\\n  Typology Designed for LSP Translation: First Experiments with ChatGPT\", \"summary\": \"This study investigates the capabilities of large language models (LLMs),\\nspecifically ChatGPT, in annotating MT outputs based on an error typology. In\\ncontrast to previous work focusing mainly on general language, we explore\\nChatGPT's ability to identify and categorise errors in specialised\\ntranslations. By testing two different prompts and based on a customised error\\ntypology, we compare ChatGPT annotations with human expert evaluations of\\ntranslations produced by DeepL and ChatGPT itself. The results show that, for\\ntranslations generated by DeepL, recall and precision are quite high. However,\\nthe degree of accuracy in error categorisation depends on the prompt's specific\\nfeatures and its level of detail, ChatGPT performing very well with a detailed\\nprompt. When evaluating its own translations, ChatGPT achieves significantly\\npoorer results, revealing limitations with self-assessment. These results\\nhighlight both the potential and the limitations of LLMs for translation\\nevaluation, particularly in specialised domains. Our experiments pave the way\\nfor future research on open-source LLMs, which could produce annotations of\\ncomparable or even higher quality. In the future, we also aim to test the\\npractical effectiveness of this automated evaluation in the context of\\ntranslation training, particularly by optimising the process of human\\nevaluation by teachers and by exploring the impact of annotations by LLMs on\\nstudents' post-editing and translation learning.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,eess.AS\", \"published\": \"2025-04-21T12:21:37Z\"}"}
