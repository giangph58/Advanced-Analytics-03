{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03567v1\", \"title\": \"Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person\\n  Search in Full Images\", \"summary\": \"Text-based pedestrian search (TBPS) in full images aims to locate a target\\npedestrian in untrimmed images using natural language descriptions. However, in\\ncomplex scenes with multiple pedestrians, existing methods are limited by\\nuncertainties in detection and matching, leading to degraded performance. To\\naddress this, we propose UPD-TBPS, a novel framework comprising three modules:\\nMulti-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty\\nDecoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts\\nmulti-granularity queries to identify potential targets and assigns confidence\\nscores to reduce early-stage uncertainty. PUD leverages visual context\\ndecoupling and prototype mining to extract features of the target pedestrian\\ndescribed in the query. It separates and learns pedestrian prototype\\nrepresentations at both the coarse-grained cluster level and the fine-grained\\nindividual level, thereby reducing matching uncertainty. ReID evaluates\\ncandidates with varying confidence levels, improving detection and retrieval\\naccuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the\\neffectiveness of our framework.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-06T14:25:30Z\"}"}
