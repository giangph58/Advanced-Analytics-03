{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05169v1\", \"title\": \"Bandit Max-Min Fair Allocation\", \"summary\": \"In this paper, we study a new decision-making problem called the bandit\\nmax-min fair allocation (BMMFA) problem. The goal of this problem is to\\nmaximize the minimum utility among agents with additive valuations by\\nrepeatedly assigning indivisible goods to them. One key feature of this problem\\nis that each agent's valuation for each item can only be observed through the\\nsemi-bandit feedback, while existing work supposes that the item values are\\nprovided at the beginning of each round. Another key feature is that the\\nalgorithm's reward function is not additive with respect to rounds, unlike most\\nbandit-setting problems.\\n  Our first contribution is to propose an algorithm that has an asymptotic\\nregret bound of $O(m\\\\sqrt{T}\\\\ln T/n + m\\\\sqrt{T \\\\ln(mnT)})$, where $n$ is the\\nnumber of agents, $m$ is the number of items, and $T$ is the time horizon. This\\nis based on a novel combination of bandit techniques and a resource allocation\\nalgorithm studied in the literature on competitive analysis. Our second\\ncontribution is to provide the regret lower bound of $\\\\Omega(m\\\\sqrt{T}/n)$.\\nWhen $T$ is sufficiently larger than $n$, the gap between the upper and lower\\nbounds is a logarithmic factor of $T$.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-08T12:09:20Z\"}"}
