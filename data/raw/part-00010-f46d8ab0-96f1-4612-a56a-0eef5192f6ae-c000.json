{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11850v1\", \"title\": \"ACE: Attentional Concept Erasure in Diffusion Models\", \"summary\": \"Large text-to-image diffusion models have demonstrated remarkable image\\nsynthesis capabilities, but their indiscriminate training on Internet-scale\\ndata has led to learned concepts that enable harmful, copyrighted, or otherwise\\nundesirable content generation. We address the task of concept erasure in\\ndiffusion models, i.e., removing a specified concept from a pre-trained model\\nsuch that prompting the concept (or related synonyms) no longer yields its\\ndepiction, while preserving the model's ability to generate other content. We\\npropose a novel method, Attentional Concept Erasure (ACE), that integrates a\\nclosed-form attention manipulation with lightweight fine-tuning. Theoretically,\\nwe formulate concept erasure as aligning the model's conditional distribution\\non the target concept with a neutral distribution. Our approach identifies and\\nnullifies concept-specific latent directions in the cross-attention modules via\\na gated low-rank adaptation, followed by adversarially augmented fine-tuning to\\nensure thorough erasure of the concept and its synonyms. Empirically, we\\ndemonstrate on multiple benchmarks, including object classes, celebrity faces,\\nexplicit content, and artistic styles, that ACE achieves state-of-the-art\\nconcept removal efficacy and robustness. Compared to prior methods, ACE better\\nbalances generality (erasing concept and related terms) and specificity\\n(preserving unrelated content), scales to dozens of concepts, and is efficient,\\nrequiring only a few seconds of adaptation per concept. We will release our\\ncode to facilitate safer deployment of diffusion models.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-16T08:16:28Z\"}"}
