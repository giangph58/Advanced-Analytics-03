{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11268v1\", \"title\": \"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\\n  for Dense Multi-Task Learning\", \"summary\": \"Model merging is a flexible and computationally tractable approach to merge\\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\\non constrained multi-task settings where there is a one-to-one mapping between\\na sample and a task, overlooking the paradigm where multiple tasks may operate\\non the same sample, e.g., scene understanding. In this paper, we focus on the\\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\\nqualitatively differs from the single-input-single-output model merging\\nsettings studied in the literature due to the existence of task-specific\\ndecoders and diverse loss objectives. We identify that existing model merging\\nmethods lead to significant performance degradation, primarily due to\\nrepresentation misalignment between the merged encoder and task-specific\\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\\nre-align the feature representation after merging. Compared to joint\\nfine-tuning, our approach is computationally effective and flexible, and sheds\\nlight into identifying task relationships in an offline manner. Experiments on\\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\\narithmetic suffices to enable multi-task capabilities; however, the\\nrepresentations generated by the merged encoder has to be re-aligned with the\\ntask-specific heads; (2) the proposed architecture rivals traditional\\nmulti-task learning in performance but requires fewer samples and training\\nsteps by leveraging the existence of task-specific models.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-15T15:10:46Z\"}"}
