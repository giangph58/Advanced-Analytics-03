{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16727v1\", \"title\": \"V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental\\n  Visual Variations\", \"summary\": \"Large Vision Language Models (LVLMs) excel in various vision-language tasks.\\nYet, their robustness to visual variations in position, scale, orientation, and\\ncontext that objects in natural scenes inevitably exhibit due to changes in\\nviewpoint and environment remains largely underexplored. To bridge this gap, we\\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\\ndataset generation and principled metrics for thorough robustness assessment.\\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\\nto visual variations, in which even advanced models that excel at complex\\nvision-language tasks significantly underperform on simple tasks such as object\\nrecognition. Interestingly, these models exhibit a distinct visual position\\nbias that contradicts theories of effective receptive fields, and demonstrate a\\nhuman-like visual acuity threshold. To identify the source of these\\nvulnerabilities, we present a systematic framework for component-level\\nanalysis, featuring a novel visualization approach for aligned visual features.\\nResults show that these vulnerabilities stem from error accumulation in the\\npipeline architecture and inadequate multimodal alignment. Complementary\\nexperiments with synthetic data further demonstrate that these limitations are\\nfundamentally architectural deficiencies, scoring the need for architectural\\ninnovations in future LVLM designs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-23T14:01:32Z\"}"}
