{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04529v1\", \"title\": \"RAFT: Robust Augmentation of FeaTures for Image Segmentation\", \"summary\": \"Image segmentation is a powerful computer vision technique for scene\\nunderstanding. However, real-world deployment is stymied by the need for\\nhigh-quality, meticulously labeled datasets. Synthetic data provides\\nhigh-quality labels while reducing the need for manual data collection and\\nannotation. However, deep neural networks trained on synthetic data often face\\nthe Syn2Real problem, leading to poor performance in real-world deployments.\\n  To mitigate the aforementioned gap in image segmentation, we propose RAFT, a\\nnovel framework for adapting image segmentation models using minimal labeled\\nreal-world data through data and feature augmentations, as well as active\\nlearning. To validate RAFT, we perform experiments on the synthetic-to-real\\n\\\"SYNTHIA->Cityscapes\\\" and \\\"GTAV->Cityscapes\\\" benchmarks. We managed to surpass\\nthe previous state of the art, HALO. SYNTHIA->Cityscapes experiences an\\nimprovement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes\\nexperiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach\\non the real-to-real benchmark of \\\"Cityscapes->ACDC\\\", and again surpass HALO,\\nwith a gain in mIoU upon adaptation of 1.3%/73.2%. Finally, we examine the\\neffect of the allocated annotation budget and various components of RAFT upon\\nthe final transfer mIoU.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-05-07T16:02:46Z\"}"}
