{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19855v1\", \"title\": \"The Automation Advantage in AI Red Teaming\", \"summary\": \"This paper analyzes Large Language Model (LLM) security vulnerabilities based\\non data from Crucible, encompassing 214,271 attack attempts by 1,674 users\\nacross 30 LLM challenges. Our findings reveal automated approaches\\nsignificantly outperform manual techniques (69.5% vs 47.6% success rate),\\ndespite only 5.2% of users employing automation. We demonstrate that automated\\napproaches excel in systematic exploration and pattern matching challenges,\\nwhile manual approaches retain speed advantages in certain creative reasoning\\nscenarios, often solving problems 5x faster when successful. Challenge\\ncategories requiring systematic exploration are most effectively targeted\\nthrough automation, while intuitive challenges sometimes favor manual\\ntechniques for time-to-solve metrics. These results illuminate how algorithmic\\ntesting is transforming AI red-teaming practices, with implications for both\\noffensive security research and defensive measures. Our analysis suggests\\noptimal security testing combines human creativity for strategy development\\nwith programmatic execution for thorough exploration.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-04-28T14:48:00Z\"}"}
