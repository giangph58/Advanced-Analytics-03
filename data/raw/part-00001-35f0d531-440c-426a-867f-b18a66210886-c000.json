{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14988v1\", \"title\": \"Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A\\n  Comprehensive Evaluation\", \"summary\": \"Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\\nremarkable multimodal perception capabilities, garnering significant attention.\\nWhile numerous evaluation studies have emerged, assessing LVLMs both\\nholistically and on specialized tasks, fine-grained image tasks-fundamental to\\ncomputer vision-remain largely unexplored. To fill this gap, we introduce a\\ncomprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 3.49\\nmillion questions and 3.32 million images. Our evaluation systematically\\nexamines LVLMs from both human-oriented and machine-oriented perspectives,\\nfocusing on their semantic recognition and fine-grained feature representation\\ncapabilities. Through extensive experiments on eight representative LVLMs/VLMs,\\nwe uncover key findings regarding the influence of training paradigms, modality\\nalignment, perturbation susceptibility, and fine-grained category reasoning on\\ntask performance. This work provides critical insights into the limitations of\\ncurrent LVLMs and offers guidance for future data construction and model design\\nin the development of more advanced LVLMs. Our code is open-source and\\navailable at https://github.com/SEU-VIPGroup/FG-BMK.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-21T09:30:41Z\"}"}
