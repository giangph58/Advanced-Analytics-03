{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00350v1\", \"title\": \"Optimizing Deep Neural Networks using Safety-Guided Self Compression\", \"summary\": \"The deployment of deep neural networks on resource-constrained devices\\nnecessitates effective model com- pression strategies that judiciously balance\\nthe reduction of model size with the preservation of performance. This study\\nintroduces a novel safety-driven quantization framework that leverages\\npreservation sets to systematically prune and quantize neural network weights,\\nthereby optimizing model complexity without compromising accuracy. The proposed\\nmethodology is rigorously evaluated on both a convolutional neural network\\n(CNN) and an attention-based language model, demonstrating its applicability\\nacross diverse architectural paradigms. Experimental results reveal that our\\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\\noriginal unquantized models while maintaining 60% of the initial model size. In\\ncomparison to conventional quantization techniques, our approach not only\\naugments generalization by eliminating parameter noise and retaining essential\\nweights but also reduces variance, thereby ensuring the retention of critical\\nmodel features. These findings underscore the efficacy of safety-driven\\nquantization as a robust and reliable strategy for the efficient optimization\\nof deep learn- ing models. The implementation and comprehensive experimental\\nevaluations of our framework are publicly accessible at GitHub.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-05-01T06:50:30Z\"}"}
