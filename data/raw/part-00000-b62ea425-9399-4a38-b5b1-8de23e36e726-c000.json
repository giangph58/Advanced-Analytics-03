{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05408v1\", \"title\": \"Crosslingual Reasoning through Test-Time Scaling\", \"summary\": \"Reasoning capabilities of large language models are primarily studied for\\nEnglish, even when pretrained models are multilingual. In this work, we\\ninvestigate to what extent English reasoning finetuning with long\\nchain-of-thoughts (CoTs) can generalize across languages. First, we find that\\nscaling up inference compute for English-centric reasoning language models\\n(RLMs) improves multilingual mathematical reasoning across many languages\\nincluding low-resource languages, to an extent where they outperform models\\ntwice their size. Second, we reveal that while English-centric RLM's CoTs are\\nnaturally predominantly English, they consistently follow a quote-and-think\\npattern to reason about quoted non-English inputs. Third, we discover an\\neffective strategy to control the language of long CoT reasoning, and we\\nobserve that models reason better and more efficiently in high-resource\\nlanguages. Finally, we observe poor out-of-domain reasoning generalization, in\\nparticular from STEM to cultural commonsense knowledge, even for English.\\nOverall, we demonstrate the potentials, study the mechanisms and outline the\\nlimitations of crosslingual generalization of English reasoning test-time\\nscaling. We conclude that practitioners should let English-centric RLMs reason\\nin high-resource languages, while further work is needed to improve reasoning\\nin low-resource languages and out-of-domain contexts.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-05-08T16:50:06Z\"}"}
