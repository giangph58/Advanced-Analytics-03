{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14921v1\", \"title\": \"Fast Adversarial Training with Weak-to-Strong Spatial-Temporal\\n  Consistency in the Frequency Domain on Videos\", \"summary\": \"Adversarial Training (AT) has been shown to significantly enhance adversarial\\nrobustness via a min-max optimization approach. However, its effectiveness in\\nvideo recognition tasks is hampered by two main challenges. First, fast\\nadversarial training for video models remains largely unexplored, which\\nseverely impedes its practical applications. Specifically, most video\\nadversarial training methods are computationally costly, with long training\\ntimes and high expenses. Second, existing methods struggle with the trade-off\\nbetween clean accuracy and adversarial robustness. To address these challenges,\\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\\n(VFAT-WS), the first fast adversarial training method for video data.\\nSpecifically, VFAT-WS incorporates the following key designs: First, it\\nintegrates a straightforward yet effective temporal frequency augmentation\\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\\ndevises a weak-to-strong spatial-temporal consistency regularization, which\\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\\nLeveraging the consistency regularization, it steers the learning process from\\nsimple to complex augmentations. Both of them work together to achieve a better\\ntrade-off between clean accuracy and robustness. Extensive experiments on\\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\\nVFAT-WS achieves great improvements in adversarial robustness and corruption\\nrobustness, while accelerating training by nearly 490%.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-21T07:40:35Z\"}"}
