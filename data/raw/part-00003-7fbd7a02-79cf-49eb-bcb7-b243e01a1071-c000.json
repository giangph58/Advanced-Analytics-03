{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13077v1\", \"title\": \"Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts\\n  of Labeled Data\", \"summary\": \"This paper introduces a novel dual-region augmentation approach designed to\\nreduce reliance on large-scale labeled datasets while improving model\\nrobustness and adaptability across diverse computer vision tasks, including\\nsource-free domain adaptation (SFDA) and person re-identification (ReID). Our\\nmethod performs targeted data transformations by applying random noise\\nperturbations to foreground objects and spatially shuffling background patches.\\nThis effectively increases the diversity of the training data, improving model\\nrobustness and generalization. Evaluations on the PACS dataset for SFDA\\ndemonstrate that our augmentation strategy consistently outperforms existing\\nmethods, achieving significant accuracy improvements in both single-target and\\nmulti-target adaptation settings. By augmenting training data through\\nstructured transformations, our method enables model generalization across\\ndomains, providing a scalable solution for reducing reliance on manually\\nannotated datasets. Furthermore, experiments on Market-1501 and DukeMTMC-reID\\ndatasets validate the effectiveness of our approach for person ReID, surpassing\\ntraditional augmentation techniques.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-17T16:42:33Z\"}"}
