{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15113v1\", \"title\": \"Adaptive sieving with semismooth Newton proximal augmented Lagrangian\\n  algorithm for multi-task Lasso problems\", \"summary\": \"Multi-task learning enhances model generalization by jointly learning from\\nrelated tasks. This paper focuses on the $\\\\ell_{1,\\\\infty}$-norm constrained\\nmulti-task learning problem, which promotes a shared feature representation\\nwhile inducing sparsity in task-specific parameters. We propose an adaptive\\nsieving (AS) strategy to efficiently generate a solution path for multi-task\\nLasso problems. Each subproblem along the path is solved via an inexact\\nsemismooth Newton proximal augmented Lagrangian ({\\\\sc Ssnpal}) algorithm,\\nachieving an asymptotically superlinear convergence rate. By exploiting the\\nKarush-Kuhn-Tucker (KKT) conditions and the inherent sparsity of multi-task\\nLasso solutions, the {\\\\sc Ssnpal} algorithm solves a sequence of reduced\\nsubproblems with small dimensions. This approach enables our method to scale\\neffectively to large problems. Numerical experiments on synthetic and\\nreal-world datasets demonstrate the superior efficiency and robustness of our\\nalgorithm compared to state-of-the-art solvers.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC\", \"published\": \"2025-04-21T14:06:25Z\"}"}
