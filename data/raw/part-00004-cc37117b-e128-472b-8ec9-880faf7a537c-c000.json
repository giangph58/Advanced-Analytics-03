{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19979v1\", \"title\": \"Transfer Learning Under High-Dimensional Network Convolutional\\n  Regression Model\", \"summary\": \"Transfer learning enhances model performance by utilizing knowledge from\\nrelated domains, particularly when labeled data is scarce. While existing\\nresearch addresses transfer learning under various distribution shifts in\\nindependent settings, handling dependencies in networked data remains\\nchallenging. To address this challenge, we propose a high-dimensional transfer\\nlearning framework based on network convolutional regression (NCR), inspired by\\nthe success of graph convolutional networks (GCNs). The NCR model incorporates\\nrandom network structure by allowing each node's response to depend on its\\nfeatures and the aggregated features of its neighbors, capturing local\\ndependencies effectively. Our methodology includes a two-step transfer learning\\nalgorithm that addresses domain shift between source and target networks, along\\nwith a source detection mechanism to identify informative domains.\\nTheoretically, we analyze the lasso estimator in the context of a random graph\\nbased on the Erdos-Renyi model assumption, demonstrating that transfer learning\\nimproves convergence rates when informative sources are present. Empirical\\nevaluations, including simulations and a real-world application using Sina\\nWeibo data, demonstrate substantial improvements in prediction accuracy,\\nparticularly when labeled data in the target domain is limited.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ME\", \"published\": \"2025-04-28T16:52:28Z\"}"}
