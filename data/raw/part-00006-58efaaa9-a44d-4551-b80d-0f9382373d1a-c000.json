{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16636v1\", \"title\": \"Dual-Camera All-in-Focus Neural Radiance Fields\", \"summary\": \"We present the first framework capable of synthesizing the all-in-focus\\nneural radiance field (NeRF) from inputs without manual refocusing. Without\\nrefocusing, the camera will automatically focus on the fixed object for all\\nviews, and current NeRF methods typically using one camera fail due to the\\nconsistent defocus blur and a lack of sharp reference. To restore the\\nall-in-focus NeRF, we introduce the dual-camera from smartphones, where the\\nultra-wide camera has a wider depth-of-field (DoF) and the main camera\\npossesses a higher resolution. The dual camera pair saves the high-fidelity\\ndetails from the main camera and uses the ultra-wide camera's deep DoF as\\nreference for all-in-focus restoration. To this end, we first implement spatial\\nwarping and color matching to align the dual camera, followed by a\\ndefocus-aware fusion module with learnable defocus parameters to predict a\\ndefocus map and fuse the aligned camera pair. We also build a multi-view\\ndataset that includes image pairs of the main and ultra-wide cameras in a\\nsmartphone. Extensive experiments on this dataset verify that our solution,\\ntermed DC-NeRF, can produce high-quality all-in-focus novel views and compares\\nfavorably against strong baselines quantitatively and qualitatively. We further\\nshow DoF applications of DC-NeRF with adjustable blur intensity and focal\\nplane, including refocusing and split diopter.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-23T11:55:02Z\"}"}
