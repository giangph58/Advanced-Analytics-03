{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20923v1\", \"title\": \"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based\\n  Approach with Cross-Dataset Evaluation\", \"summary\": \"Audio deepfakes represent a growing threat to digital security and trust,\\nleveraging advanced generative models to produce synthetic speech that closely\\nmimics real human voices. Detecting such manipulations is especially\\nchallenging under open-world conditions, where spoofing methods encountered\\nduring testing may differ from those seen during training. In this work, we\\npropose an end-to-end deep learning framework for audio deepfake detection that\\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\\nconvolutional-recurrent architecture designed to capture both spectral and\\ntemporal features without handcrafted preprocessing. To enhance robustness, we\\nintroduce a training strategy that combines data from multiple domains and\\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\\ndemonstrate that incorporating codec-based manipulations and applying\\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\\nstretching) leads to significant generalization improvements under realistic\\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\\nhighlight the importance of diverse training data, tailored objective functions\\nand audio augmentations in building resilient and generalizable audio forgery\\ndetectors. Code and pretrained models are available at\\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.CV,eess.AS\", \"published\": \"2025-04-29T16:38:23Z\"}"}
