{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14866v1\", \"title\": \"GainSight: Application-Guided Profiling for Composing Heterogeneous\\n  On-Chip Memories in AI Hardware Accelerators\", \"summary\": \"As AI workloads drive soaring memory requirements, there is a need for\\nhigher-density on-chip memory for domain-specific accelerators that goes beyond\\nwhat current SRAM technology can provide. We motivate that algorithms and\\napplication behavior should guide the composition of heterogeneous on-chip\\nmemories. However, there has been little work in factoring dynamic application\\nprofiles into such design decisions. We present GainSight, a profiling\\nframework that analyzes fine-grained memory access patterns and computes data\\nlifetimes in domain-specific accelerators. By combining instrumentation and\\nsimulation across retargetable hardware backends, GainSight aligns\\nheterogeneous memory designs with workload-specific traffic and lifetime\\nmetrics. Case studies on MLPerf Inference and PolyBench workloads using NVIDIA\\nH100 GPUs and systolic arrays reveal key insights: (1) 40% of L1 and 18% of L2\\nGPU cache accesses, and 79% of systolic array scratchpad accesses across\\nprofiled workloads are short-lived and suitable for silicon-based gain cell RAM\\n(Si-GCRAM); (2) Si-GCRAM reduces active energy by 11-28% compared to SRAM; (3)\\nUp to 90% of GPU cache fetches are never reused, highlighting inefficiencies in\\nterms of cache pollution. These insights that GainSight provides can be used to\\nbetter understand the design spaces of both emerging on-chip memories and\\nsoftware algorithmic optimizations for the next generation of AI accelerators.\", \"main_category\": \"cs.AR\", \"categories\": \"cs.AR,cs.ET\", \"published\": \"2025-04-21T05:27:33Z\"}"}
