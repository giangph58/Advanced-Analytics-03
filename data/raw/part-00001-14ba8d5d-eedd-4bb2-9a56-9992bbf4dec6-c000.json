{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21387v1\", \"title\": \"Comparison of Different Deep Neural Network Models in the Cultural\\n  Heritage Domain\", \"summary\": \"The integration of computer vision and deep learning is an essential part of\\ndocumenting and preserving cultural heritage, as well as improving visitor\\nexperiences. In recent years, two deep learning paradigms have been established\\nin the field of computer vision: convolutional neural networks and transformer\\narchitectures. The present study aims to make a comparative analysis of some\\nrepresentatives of these two techniques of their ability to transfer knowledge\\nfrom generic dataset, such as ImageNet, to cultural heritage specific tasks.\\nThe results of testing examples of the architectures VGG, ResNet, DenseNet,\\nVisual Transformer, Swin Transformer, and PoolFormer, showed that DenseNet is\\nthe best in terms of efficiency-computability ratio.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T07:38:20Z\"}"}
