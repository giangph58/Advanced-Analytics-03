{"value":"{\"aid\": \"http://arxiv.org/abs/2504.12262v1\", \"title\": \"SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via\\n  Scalable Conditioned Neural Fields\", \"summary\": \"Spatiotemporal learning is challenging due to the intricate interplay between\\nspatial and temporal dependencies, the high dimensionality of the data, and\\nscalability constraints. These challenges are further amplified in scientific\\ndomains, where data is often irregularly distributed (e.g., missing values from\\nsensor failures) and high-volume (e.g., high-fidelity simulations), posing\\nadditional computational and modeling difficulties. In this paper, we present\\nSCENT, a novel framework for scalable and continuity-informed spatiotemporal\\nrepresentation learning. SCENT unifies interpolation, reconstruction, and\\nforecasting within a single architecture. Built on a transformer-based\\nencoder-processor-decoder backbone, SCENT introduces learnable queries to\\nenhance generalization and a query-wise cross-attention mechanism to\\neffectively capture multi-scale dependencies. To ensure scalability in both\\ndata size and model complexity, we incorporate a sparse attention mechanism,\\nenabling flexible output representations and efficient evaluation at arbitrary\\nresolutions. We validate SCENT through extensive simulations and real-world\\nexperiments, demonstrating state-of-the-art performance across multiple\\nchallenging tasks while achieving superior scalability.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-16T17:17:31Z\"}"}
