{"value":"{\"aid\": \"http://arxiv.org/abs/2504.17471v1\", \"title\": \"GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework\", \"summary\": \"Gossip Learning (GL) is a decentralized learning paradigm where users\\niteratively exchange and aggregate models with a small set of neighboring\\npeers. Recent GL approaches rely on dynamic communication graphs built and\\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\\ndynamics, GL can achieve fast convergence even over extremely sparse\\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\\nattack the RPS protocol to scale up model poisoning. We address this issue by\\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\\nleverages an estimate of Byzantine presence to set aggregation thresholds with\\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\\nof poisoned models and obtains these results in up to 9 times sparser graphs\\nthan dictated by current theory.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.DC\", \"published\": \"2025-04-24T12:03:15Z\"}"}
