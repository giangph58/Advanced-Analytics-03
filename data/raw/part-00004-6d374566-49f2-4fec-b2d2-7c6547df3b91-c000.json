{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06969v1\", \"title\": \"Towards LLMs Robustness to Changes in Prompt Format Styles\", \"summary\": \"Large language models (LLMs) have gained popularity in recent years for their\\nutility in various applications. However, they are sensitive to non-semantic\\nchanges in prompt formats, where small changes in the prompt format can lead to\\nsignificant performance fluctuations. In the literature, this problem is\\ncommonly referred to as prompt brittleness. Previous research on prompt\\nengineering has focused mainly on developing techniques for identifying the\\noptimal prompt for specific tasks. Some studies have also explored the issue of\\nprompt brittleness and proposed methods to quantify performance variations;\\nhowever, no simple solution has been found to address this challenge. We\\npropose Mixture of Formats (MOF), a simple and efficient technique for\\naddressing prompt brittleness in LLMs by diversifying the styles used in the\\nprompt few-shot examples. MOF was inspired by computer vision techniques that\\nutilize diverse style datasets to prevent models from associating specific\\nstyles with the target variable. Empirical results show that our proposed\\ntechnique reduces style-induced prompt brittleness in various LLMs while also\\nenhancing overall performance across prompt variations and different datasets.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-09T15:26:00Z\"}"}
