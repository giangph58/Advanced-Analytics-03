{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00675v1\", \"title\": \"Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future\\n  Directions\", \"summary\": \"Memory is a fundamental component of AI systems, underpinning large language\\nmodels (LLMs) based agents. While prior surveys have focused on memory\\napplications with LLMs, they often overlook the atomic operations that underlie\\nmemory dynamics. In this survey, we first categorize memory representations\\ninto parametric, contextual structured, and contextual unstructured and then\\nintroduce six fundamental memory operations: Consolidation, Updating, Indexing,\\nForgetting, Retrieval, and Compression. We systematically map these operations\\nto the most relevant research topics across long-term, long-context, parametric\\nmodification, and multi-source memory. By reframing memory systems through the\\nlens of atomic operations and representation types, this survey provides a\\nstructured and dynamic perspective on research, benchmark datasets, and tools\\nrelated to memory in AI, clarifying the functional interplay in LLMs based\\nagents while outlining promising directions for future research\\\\footnote{The\\npaper list, datasets, methods and tools are available at\\n\\\\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\\\_Memory\\\\_in\\\\_AI}.}.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-05-01T17:31:33Z\"}"}
