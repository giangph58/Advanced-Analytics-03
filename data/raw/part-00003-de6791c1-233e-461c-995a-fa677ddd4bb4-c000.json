{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10878v1\", \"title\": \"Large Language Model-Informed Feature Discovery Improves Prediction and\\n  Interpretation of Credibility Perceptions of Visual Content\", \"summary\": \"In today's visually dominated social media landscape, predicting the\\nperceived credibility of visual content and understanding what drives human\\njudgment are crucial for countering misinformation. However, these tasks are\\nchallenging due to the diversity and richness of visual features. We introduce\\na Large Language Model (LLM)-informed feature discovery framework that\\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\\nexplain its reasoning. We extract and quantify interpretable features using\\ntargeted prompts and integrate them into machine learning models to improve\\ncredibility predictions. We tested this approach on 4,191 visual social media\\nposts across eight topics in science, health, and politics, using credibility\\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\\nGPT-based predictions by 13 percent in R2, and revealed key features like\\ninformation concreteness and image format. We discuss the implications for\\nmisinformation mitigation, visual credibility, and the role of LLMs in social\\nscience.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-15T05:11:40Z\"}"}
