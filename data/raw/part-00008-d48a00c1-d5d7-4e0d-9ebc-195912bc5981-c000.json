{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06088v1\", \"title\": \"MCAT: Visual Query-Based Localization of Standard Anatomical Clips in\\n  Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer\", \"summary\": \"Accurate standard plane acquisition in fetal ultrasound (US) videos is\\ncrucial for fetal growth assessment, anomaly detection, and adherence to\\nclinical guidelines. However, manually selecting standard frames is\\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\\nmethods primarily rely on image-based approaches that capture standard frames\\nand then classify the input frames across different anatomies. This ignores the\\ndynamic nature of video acquisition and its interpretation. To address these\\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\\nvisual query-based video clip localization (VQ-VCL) method, to assist\\nsonographers by enabling them to capture a quick US sweep. By then providing a\\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\\ncontaining the standard frames for that anatomy, facilitating thorough\\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\\nefficiency and accuracy have significant potential implications for public\\nhealth, especially in low- and middle-income countries (LMICs), where it may\\nenhance prenatal care by streamlining standard plane acquisition, simplifying\\nUS-based screening, diagnosis and allowing sonographers to examine more\\npatients.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-08T14:29:15Z\"}"}
