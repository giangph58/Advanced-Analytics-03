{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03273v1\", \"title\": \"SepALM: Audio Language Models Are Error Correctors for Robust Speech\\n  Separation\", \"summary\": \"While contemporary speech separation technologies adeptly process lengthy\\nmixed audio waveforms, they are frequently challenged by the intricacies of\\nreal-world environments, including noisy and reverberant settings, which can\\nresult in artifacts or distortions in the separated speech. To overcome these\\nlimitations, we introduce SepALM, a pioneering approach that employs audio\\nlanguage models (ALMs) to rectify and re-synthesize speech within the text\\ndomain following preliminary separation. SepALM comprises four core components:\\na separator, a corrector, a synthesizer, and an aligner. By integrating an\\nALM-based end-to-end error correction mechanism, we mitigate the risk of error\\naccumulation and circumvent the optimization hurdles typically encountered in\\nconventional methods that amalgamate automatic speech recognition (ASR) with\\nlarge language models (LLMs). Additionally, we have developed Chain-of-Thought\\n(CoT) prompting and knowledge distillation techniques to facilitate the\\nreasoning and training processes of the ALM. Our experiments substantiate that\\nSepALM not only elevates the precision of speech separation but also markedly\\nbolsters adaptability in novel acoustic environments.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.CL,eess.AS\", \"published\": \"2025-05-06T08:04:37Z\"}"}
