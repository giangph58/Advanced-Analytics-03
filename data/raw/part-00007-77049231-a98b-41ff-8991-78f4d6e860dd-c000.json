{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19834v1\", \"title\": \"AnimateAnywhere: Rouse the Background in Human Image Animation\", \"summary\": \"Human image animation aims to generate human videos of given characters and\\nbackgrounds that adhere to the desired pose sequence. However, existing methods\\nfocus more on human actions while neglecting the generation of background,\\nwhich typically leads to static results or inharmonious movements. The\\ncommunity has explored camera pose-guided animation tasks, yet preparing the\\ncamera trajectory is impractical for most entertainment applications and\\nordinary users. As a remedy, we present an AnimateAnywhere framework, rousing\\nthe background in human image animation without requirements on camera\\ntrajectories. In particular, based on our key insight that the movement of the\\nhuman body often reflects the motion of the background, we introduce a\\nbackground motion learner (BML) to learn background motions from human pose\\nsequences. To encourage the model to learn more accurate cross-frame\\ncorrespondences, we further deploy an epipolar constraint on the 3D attention\\nmap. Specifically, the mask used to suppress geometrically unreasonable\\nattention is carefully constructed by combining an epipolar mask and the\\ncurrent 3D attention map. Extensive experiments demonstrate that our\\nAnimateAnywhere effectively learns the background motion from human pose\\nsequences, achieving state-of-the-art performance in generating human animation\\nresults with vivid and realistic backgrounds. The source code and model will be\\navailable at https://github.com/liuxiaoyu1104/AnimateAnywhere.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T14:35:01Z\"}"}
