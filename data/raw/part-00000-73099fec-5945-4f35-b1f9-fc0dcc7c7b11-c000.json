{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01647v1\", \"title\": \"FlowR: Flowing from Sparse to Dense 3D Reconstructions\", \"summary\": \"3D Gaussian splatting enables high-quality novel view synthesis (NVS) at\\nreal-time frame rates. However, its quality drops sharply as we depart from the\\ntraining views. Thus, dense captures are needed to match the high-quality\\nexpectations of some applications, e.g. Virtual Reality (VR). However, such\\ndense captures are very laborious and expensive to obtain. Existing works have\\nexplored using 2D generative models to alleviate this requirement by\\ndistillation or generating additional training views. These methods are often\\nconditioned only on a handful of reference input views and thus do not fully\\nexploit the available 3D information, leading to inconsistent generation\\nresults and reconstruction artifacts. To tackle this problem, we propose a\\nmulti-view, flow matching model that learns a flow to connect novel view\\nrenderings from possibly sparse reconstructions to renderings that we expect\\nfrom dense reconstructions. This enables augmenting scene captures with novel,\\ngenerated views to improve reconstruction quality. Our model is trained on a\\nnovel dataset of 3.6M image pairs and can process up to 45 views at 540x960\\nresolution (91K tokens) on one H100 GPU in a single forward pass. Our pipeline\\nconsistently improves NVS in sparse- and dense-view scenarios, leading to\\nhigher-quality reconstructions than prior works across multiple, widely-used\\nNVS benchmarks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T11:57:01Z\"}"}
