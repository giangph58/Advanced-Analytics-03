{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16027v1\", \"title\": \"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs\\n  DeepSeek-V3\", \"summary\": \"Determining the most effective Large Language Model for code smell detection\\npresents a complex challenge. This study introduces a structured methodology\\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\\ncode samples consistently annotated with known smells. The dataset spans four\\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\\nmetrics. Our analysis covers three levels of detail: overall performance,\\ncategory level performance, and individual code smell type performance.\\nAdditionally, we explore cost effectiveness by comparing the token based\\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\\nDeepSeek V3. The study also includes a cost analysis relative to traditional\\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\\nfor practitioners in selecting an efficient, cost effective solution for\\nautomated code smell detection\", \"main_category\": \"cs.SE\", \"categories\": \"cs.SE,cs.AI,cs.LG,cs.PL\", \"published\": \"2025-04-22T16:44:39Z\"}"}
