{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13175v1\", \"title\": \"Novel Demonstration Generation with Gaussian Splatting Enables Robust\\n  One-Shot Manipulation\", \"summary\": \"Visuomotor policies learned from teleoperated demonstrations face challenges\\nsuch as lengthy data collection, high costs, and limited data diversity.\\nExisting approaches address these issues by augmenting image observations in\\nRGB space or employing Real-to-Sim-to-Real pipelines based on physical\\nsimulators. However, the former is constrained to 2D data augmentation, while\\nthe latter suffers from imprecise physical simulation caused by inaccurate\\ngeometric reconstruction. This paper introduces RoboSplat, a novel method that\\ngenerates diverse, visually realistic demonstrations by directly manipulating\\n3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian\\nSplatting (3DGS), directly edit the reconstructed scene, and augment data\\nacross six types of generalization with five techniques: 3D Gaussian\\nreplacement for varying object types, scene appearance, and robot embodiments;\\nequivariant transformations for different object poses; visual attribute\\nediting for various lighting conditions; novel view synthesis for new camera\\nperspectives; and 3D content generation for diverse object types. Comprehensive\\nreal-world experiments demonstrate that RoboSplat significantly enhances the\\ngeneralization of visuomotor policies under diverse disturbances. Notably,\\nwhile policies trained on hundreds of real-world demonstrations with additional\\n2D data augmentation achieve an average success rate of 57.2%, RoboSplat\\nattains 87.8% in one-shot settings across six types of generalization in the\\nreal world.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-17T17:59:43Z\"}"}
