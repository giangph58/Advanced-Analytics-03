{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03565v1\", \"title\": \"Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and\\n  Low-Visibility Conditions\", \"summary\": \"Despite significant progress in autonomous navigation, a critical gap remains\\nin ensuring reliable localization in hazardous environments such as tunnels,\\nurban disaster zones, and underground structures. Tunnels present a uniquely\\ndifficult scenario: they are not only prone to GNSS signal loss, but also\\nprovide little features for visual localization due to their repetitive walls\\nand poor lighting. These conditions degrade conventional vision-based and\\nLiDAR-based systems, which rely on distinguishable environmental features. To\\naddress this, we propose a novel sensor fusion framework that integrates a\\nthermal camera with a LiDAR to enable robust localization in tunnels and other\\nperceptually degraded environments. The thermal camera provides resilience in\\nlow-light or smoke conditions, while the LiDAR delivers precise depth\\nperception and structural awareness. By combining these sensors, our framework\\nensures continuous and accurate localization across diverse and dynamic\\nenvironments. We use an Extended Kalman Filter (EKF) to fuse multi-sensor\\ninputs, and leverages visual odometry and SLAM (Simultaneous Localization and\\nMapping) techniques to process the sensor data, enabling robust motion\\nestimation and mapping even in GNSS-denied environments. This fusion of sensor\\nmodalities not only enhances system resilience but also provides a scalable\\nsolution for cyber-physical systems in connected and autonomous vehicles\\n(CAVs). To validate the framework, we conduct tests in a tunnel environment,\\nsimulating sensor degradation and visibility challenges. The results\\ndemonstrate that our method sustains accurate localization where standard\\napproaches deteriorate due to the tunnels featureless geometry. The frameworks\\nversatility makes it a promising solution for autonomous vehicles, inspection\\nrobots, and other cyber-physical systems operating in constrained, perceptually\\npoor environments.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.SY,eess.SY\", \"published\": \"2025-05-06T14:21:51Z\"}"}
