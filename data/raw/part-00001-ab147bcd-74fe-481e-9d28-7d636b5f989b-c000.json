{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19667v1\", \"title\": \"A Tripartite Perspective on GraphRAG\", \"summary\": \"Large Language Models (LLMs) have shown remarkable capabilities across\\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\\nlimitations include their tendency to hallucinate, lack of source traceability\\n(provenance), and challenges in timely knowledge updates. Combining language\\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\\nthese deficits. However, a major challenge lies in creating such a knowledge\\ngraph in the first place. Here, we propose a novel approach that combines LLMs\\nwith a tripartite knowledge graph representation, which is constructed by\\nconnecting complex, domain-specific objects via a curated ontology of\\ncorresponding, domain-specific concepts to relevant sections within chunks of\\ntext through a concept-anchored pre-analysis of source documents starting from\\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\\nimplements: i) a concept-specific, information-preserving pre-compression of\\ntextual chunks; ii) allows for the formation of a concept-specific relevance\\nestimation of embedding similarities grounded in statistics; and iii) avoids\\ncommon challenges w.r.t. continuous extendability, such as the need for entity\\nresolution and deduplication. By applying a transformation to the knowledge\\ngraph, we formulate LLM prompt creation as an unsupervised node classification\\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\\non a healthcare use case, involving multi-faceted analyses of patient anamneses\\ngiven a set of medical concepts as well as clinical literature. Experiments\\nindicate that it can optimize information density, coverage, and arrangement of\\nLLM prompts while reducing their lengths, which may lead to reduced costs and\\nmore consistent and reliable LLM outputs.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-28T10:43:35Z\"}"}
