{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04613v1\", \"title\": \"From Two Sample Testing to Singular Gaussian Discrimination\", \"summary\": \"We establish that testing for the equality of two probability measures on a\\ngeneral separable and compact metric space is equivalent to testing for the\\nsingularity between two corresponding Gaussian measures on a suitable\\nReproducing Kernel Hilbert Space. The corresponding Gaussians are defined via\\nthe notion of kernel mean and covariance embedding of a probability measure.\\nDiscerning two singular Gaussians is fundamentally simpler from an\\ninformation-theoretic perspective than non-parametric two-sample testing,\\nparticularly in high-dimensional settings. Our proof leverages the\\nFeldman-Hajek criterion for singularity/equivalence of Gaussians on Hilbert\\nspaces, and shows that discrepancies between distributions are heavily\\nmagnified through their corresponding Gaussian embeddings: at a population\\nlevel, distinct probability measures lead to essentially separated Gaussian\\nembeddings. This appears to be a new instance of the blessing of dimensionality\\nthat can be harnessed for the design of efficient inference tools in great\\ngenerality.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG,math.ST,stat.TH\", \"published\": \"2025-05-07T17:56:19Z\"}"}
