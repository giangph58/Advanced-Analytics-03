{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20769v1\", \"title\": \"Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in\\n  Large Language Models against Reference Corruption\", \"summary\": \"Chain-of-thought prompting has demonstrated great success in facilitating the\\nreasoning abilities of large language models. In this work, we explore how\\nthese enhanced reasoning abilities can be exploited to improve the robustness\\nof large language models in tasks that are not necessarily reasoning-focused.\\nIn particular, we show how a wide range of large language models exhibit\\nsignificantly improved robustness against reference corruption using a simple\\nmethod called chain-of-defensive-thought, where only a few exemplars with\\nstructured and defensive reasoning are provided as demonstrations. Empirically,\\nthe improvements can be astounding, especially given the simplicity and\\napplicability of the method. For example, in the Natural Questions task, the\\naccuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting\\nwhen 1 out of 10 references provided is corrupted with prompt injection\\nattacks. In contrast, GPT-4o using chain-of-defensive-thought prompting\\nmaintains an accuracy of 50%.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.LG\", \"published\": \"2025-04-29T13:50:05Z\"}"}
