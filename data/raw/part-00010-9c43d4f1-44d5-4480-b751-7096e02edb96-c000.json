{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20530v1\", \"title\": \"Beyond the Horizon: Decoupling UAVs Multi-View Action Recognition via\\n  Partial Order Transfer\", \"summary\": \"Action recognition in unmanned aerial vehicles (UAVs) poses unique challenges\\ndue to significant view variations along the vertical spatial axis. Unlike\\ntraditional ground-based settings, UAVs capture actions from a wide range of\\naltitudes, resulting in considerable appearance discrepancies. We introduce a\\nmulti-view formulation tailored to varying UAV altitudes and empirically\\nobserve a partial order among views, where recognition accuracy consistently\\ndecreases as the altitude increases. This motivates a novel approach that\\nexplicitly models the hierarchical structure of UAV views to improve\\nrecognition performance across altitudes. To this end, we propose the Partial\\nOrder Guided Multi-View Network (POG-MVNet), designed to address drastic view\\nvariations by effectively leveraging view-dependent information across\\ndifferent altitude levels. The framework comprises three key components: a View\\nPartition (VP) module, which uses the head-to-body ratio to group views by\\naltitude; an Order-aware Feature Decoupling (OFD) module, which disentangles\\naction-relevant and view-specific features under partial order guidance; and an\\nAction Partial Order Guide (APOG), which leverages the partial order to\\ntransfer informative knowledge from easier views to support learning in more\\nchallenging ones. We conduct experiments on Drone-Action, MOD20, and UAV\\ndatasets, demonstrating that POG-MVNet significantly outperforms competing\\nmethods. For example, POG-MVNet achieves a 4.7% improvement on Drone-Action\\ndataset and a 3.5% improvement on UAV dataset compared to state-of-the-art\\nmethods ASAT and FAR. The code for POG-MVNet will be made available soon.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-29T08:22:13Z\"}"}
