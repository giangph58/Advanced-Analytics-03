{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05741v1\", \"title\": \"DDT: Decoupled Diffusion Transformer\", \"summary\": \"Diffusion transformers have demonstrated remarkable generation quality,\\nalbeit requiring longer training iterations and numerous inference steps. In\\neach denoising step, diffusion transformers encode the noisy inputs to extract\\nthe lower-frequency semantic component and then decode the higher frequency\\nwith identical modules. This scheme creates an inherent optimization dilemma:\\nencoding low-frequency semantics necessitates reducing high-frequency\\ncomponents, creating tension between semantic encoding and high-frequency\\ndecoding. To resolve this challenge, we propose a new\\n\\\\textbf{\\\\color{ddt}D}ecoupled \\\\textbf{\\\\color{ddt}D}iffusion\\n\\\\textbf{\\\\color{ddt}T}ransformer~(\\\\textbf{\\\\color{ddt}DDT}), with a decoupled\\ndesign of a dedicated condition encoder for semantic extraction alongside a\\nspecialized velocity decoder. Our experiments reveal that a more substantial\\nencoder yields performance improvements as model size increases. For ImageNet\\n$256\\\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\\n{1.31 FID}~(nearly $4\\\\times$ faster training convergence compared to previous\\ndiffusion transformers). For ImageNet $512\\\\times512$, Our DDT-XL/2 achieves a\\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\\ndecoupled architecture enhances inference speed by enabling the sharing\\nself-condition between adjacent denoising steps. To minimize performance\\ndegradation, we propose a novel statistical dynamic programming approach to\\nidentify optimal sharing strategies.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-08T07:17:45Z\"}"}
