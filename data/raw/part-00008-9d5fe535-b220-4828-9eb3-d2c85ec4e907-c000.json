{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05649v1\", \"title\": \"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\\n  Cloud\", \"summary\": \"LiDAR-based 3D object detection is a fundamental task in the field of\\nautonomous driving. This paper explores the unique advantage of Frequency\\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\\nframe FMCW point cloud with radial velocity measurements, we expect that our\\nobject detector can detect the short-term future locations of objects using\\nonly the current frame sensor data and demonstrate a fast ability to respond to\\nintermediate danger. To achieve this, we extend the standard object detection\\ntask to a novel task named predictive object detection (POD), which aims to\\npredict the short-term future location and dimensions of objects based solely\\non current observations. Typically, a motion prediction task requires\\nhistorical sensor information to process the temporal contexts of each object,\\nwhile our detector's avoidance of multi-frame historical information enables a\\nmuch faster response time to potential dangers. The core advantage of FMCW\\nLiDAR lies in the radial velocity associated with every reflected point. We\\npropose a novel POD framework, the core idea of which is to generate a virtual\\nfuture point using a ray casting mechanism, create virtual two-frame point\\nclouds with the current and virtual future frames, and encode these two-frame\\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\\nfeatures: one decoded for standard current frame object detection and the other\\nfor future predictive object detection. Extensive experiments on our in-house\\ndataset demonstrate the state-of-the-art standard and predictive detection\\nperformance of the proposed POD framework.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-08T03:53:28Z\"}"}
