{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11183v1\", \"title\": \"Bias Beyond English: Evaluating Social Bias and Debiasing Methods in a\\n  Low-Resource Setting\", \"summary\": \"Social bias in language models can potentially exacerbate social\\ninequalities. Despite it having garnered wide attention, most research focuses\\non English data. In a low-resource scenario, the models often perform worse due\\nto insufficient training data. This study aims to leverage high-resource\\nlanguage corpora to evaluate bias and experiment with debiasing methods in\\nlow-resource languages. We evaluated the performance of recent multilingual\\nmodels in five languages: English (\\\\textsc{eng}), Chinese (\\\\textsc{zho}),\\nRussian (\\\\textsc{rus}), Indonesian (\\\\textsc{ind}) and Thai (\\\\textsc{tha}), and\\nanalyzed four bias dimensions: \\\\textit{gender}, \\\\textit{religion},\\n\\\\textit{nationality}, and \\\\textit{race-color}. By constructing multilingual\\nbias evaluation datasets, this study allows fair comparisons between models\\nacross languages. We have further investigated three debiasing\\nmethods-\\\\texttt{CDA}, \\\\texttt{Dropout}, \\\\texttt{SenDeb}-and demonstrated that\\ndebiasing methods from high-resource languages can be effectively transferred\\nto low-resource ones, providing actionable insights for fairness research in\\nmultilingual NLP.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-15T13:40:22Z\"}"}
