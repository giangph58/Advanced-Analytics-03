{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06778v1\", \"title\": \"Controllable Automatic Foley Artist\", \"summary\": \"Foley is a key element in video production, refers to the process of adding\\nan audio signal to a silent video while ensuring semantic and temporal\\nalignment. In recent years, the rise of personalized content creation and\\nadvancements in automatic video-to-audio models have increased the demand for\\ngreater user control in the process. One possible approach is to incorporate\\ntext to guide audio generation. While supported by existing methods, challenges\\nremain in ensuring compatibility between modalities, particularly when the text\\nintroduces additional information or contradicts the sounds naturally inferred\\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\\nArtist) a video-and-text-to-audio model that generates semantically and\\ntemporally aligned audio for a given video, guided by text input. CAFA is built\\nupon a text-to-audio model and integrates video information through a modality\\nadapter mechanism. By incorporating text, users can refine semantic details and\\nintroduce creative variations, guiding the audio synthesis beyond the expected\\nvideo contextual cues. Experiments show that besides its superior quality in\\nterms of semantic alignment and audio-visual synchronization the proposed\\nmethod enable high textual controllability as demonstrated in subjective and\\nobjective evaluations.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,eess.AS\", \"published\": \"2025-04-09T10:58:54Z\"}"}
