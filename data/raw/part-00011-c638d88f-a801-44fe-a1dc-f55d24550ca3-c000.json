{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02412v1\", \"title\": \"Bridging the Theoretical Gap in Randomized Smoothing\", \"summary\": \"Randomized smoothing has become a leading approach for certifying adversarial\\nrobustness in machine learning models. However, a persistent gap remains\\nbetween theoretical certified robustness and empirical robustness accuracy.\\nThis paper introduces a new framework that bridges this gap by leveraging\\nLipschitz continuity for certification and proposing a novel, less conservative\\nmethod for computing confidence intervals in randomized smoothing. Our approach\\ntightens the bounds of certified robustness, offering a more accurate\\nreflection of model robustness in practice. Through rigorous experimentation we\\nshow that our method improves the robust accuracy, compressing the gap between\\nempirical findings and previous theoretical results. We argue that\\ninvestigating local Lipschitz constants and designing ad-hoc confidence\\nintervals can further enhance the performance of randomized smoothing. These\\nresults pave the way for a deeper understanding of the relationship between\\nLipschitz continuity and certified robustness.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-03T09:05:49Z\"}"}
