{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06111v1\", \"title\": \"Leveraging Axis-Aligned Subspaces for High-Dimensional Bayesian\\n  Optimization with Group Testing\", \"summary\": \"Bayesian optimization (BO ) is an effective method for optimizing\\nexpensive-to-evaluate black-box functions. While high-dimensional problems can\\nbe particularly challenging, due to the multitude of parameter choices and the\\npotentially high number of data points required to fit the model, this\\nlimitation can be addressed if the problem satisfies simplifying assumptions.\\nAxis-aligned subspace approaches, where few dimensions have a significant\\nimpact on the objective, motivated several algorithms for high-dimensional BO .\\nHowever, the validity of this assumption is rarely verified, and the assumption\\nis rarely exploited to its full extent. We propose a group testing ( GT)\\napproach to identify active variables to facilitate efficient optimization in\\nthese domains. The proposed algorithm, Group Testing Bayesian Optimization\\n(GTBO), first runs a testing phase where groups of variables are systematically\\nselected and tested on whether they influence the objective, then terminates\\nonce active dimensions are identified. To that end, we extend the\\nwell-established GT theory to functions over continuous domains. In the second\\nphase, GTBO guides optimization by placing more importance on the active\\ndimensions. By leveraging the axis-aligned subspace assumption, GTBO\\noutperforms state-of-the-art methods on benchmarks satisfying the assumption of\\naxis-aligned subspaces, while offering improved interpretability.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,stat.ML\", \"published\": \"2025-04-08T15:00:15Z\"}"}
