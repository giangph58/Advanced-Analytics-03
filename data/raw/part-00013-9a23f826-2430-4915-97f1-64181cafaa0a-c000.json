{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03347v1\", \"title\": \"Variable projection framework for the reduced-rank matrix approximation\\n  problem by weighted least-squares\", \"summary\": \"In this monograph, we review and develop variable projection Gauss-Newton,\\nLevenberg-Marquardt and Newton methods for the Weighted Low-Rank Approximation\\n(WLRA) problem, which has now an increasing number of applications in many\\nscientific fields. Particular attention is drawn at the robustness, efficiency\\nand scalability of these variable projection second-order algorithms such that\\nthey can be used also on larger datasets now commonly found in many practical\\nproblems for which only first-order algorithms based on sequential repetitions\\nof local optimization (e.g., majorization, Expectation-Maximization or\\nalternating least-squares methods) or variations of gradient descent (e.g.,\\nconjugate, proximal or stochastic gradient descent methods), or hybrid\\nalgorithms from these two classes of methods, were only feasible due to their\\nlower cost and memory requirement per iteration. In parallel with this review\\nof variable projection algorithms, we develop new formulae for the Jacobian and\\nHessian matrices involved in these variable projection methods and demonstrate\\ntheir very specific properties such as the uniform rank deficiency of the\\nJacobian matrix or the rank deficiency of the Hessian matrix at the (local)\\nminimizers of the cost function associated with the WLRA problem. These\\nsystematic deficiencies must be taken into account in any practical\\nimplementations of the algorithms. These different properties and the very\\nparticular geometry of the WLRA problem have not been well appreciated in the\\npast and have been the main obstacles in the development of robust variable\\nprojection second-order algorithms for solving the WLRA problem. In addition,\\nwe demonstrate that the variable projection framework gives original insights\\non the solvability, the landscape and the non-smoothness of the WLRA problem.\\nIt also helps to describe the tight links between previously unrelated methods,\\nwhich have been proposed to solve it. Specifically, we illustrate the closed\\nlinks between the variable projection framework and Riemannian optimization on\\nthe Grassmann manifold for the WLRA problem. We expect that software's\\ndevelopers and practitioners in different fields such as computer vision,\\nsignal processing, recommender systems, machine learning, multivariate\\nstatistics and geophysical sciences will benefit from the results in this\\nmonograph in order to devise more robust and accurate algorithms to solve the\\nWLRA problem.\", \"main_category\": \"math.NA\", \"categories\": \"math.NA,cs.NA,math.OC\", \"published\": \"2025-05-06T09:14:30Z\"}"}
