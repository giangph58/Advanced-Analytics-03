{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21368v1\", \"title\": \"Revisiting Diffusion Autoencoder Training for Image Reconstruction\\n  Quality\", \"summary\": \"Diffusion autoencoders (DAEs) are typically formulated as a noise prediction\\nmodel and trained with a linear-$\\\\beta$ noise schedule that spends much of its\\nsampling steps at high noise levels. Because high noise levels are associated\\nwith recovering large-scale image structures and low noise levels with\\nrecovering details, this configuration can result in low-quality and blurry\\nimages. However, it should be possible to improve details while spending fewer\\nsteps recovering structures because the latent code should already contain\\nstructural information. Based on this insight, we propose a new DAE training\\nmethod that improves the quality of reconstructed images. We divide training\\ninto two phases. In the first phase, the DAE is trained as a vanilla\\nautoencoder by always setting the noise level to the highest, forcing the\\nencoder and decoder to populate the latent code with structural information. In\\nthe second phase, we incorporate a noise schedule that spends more time in the\\nlow-noise region, allowing the DAE to learn how to perfect the details. Our\\nmethod results in images that have accurate high-level structures and low-level\\ndetails while still preserving useful properties of the latent codes.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-30T07:00:33Z\"}"}
