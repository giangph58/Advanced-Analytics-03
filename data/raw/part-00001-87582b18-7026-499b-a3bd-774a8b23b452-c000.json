{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05833v1\", \"title\": \"AVENet: Disentangling Features by Approximating Average Features for\\n  Voice Conversion\", \"summary\": \"Voice conversion (VC) has made progress in feature disentanglement, but it is\\nstill difficult to balance timbre and content information. This paper evaluates\\nthe pre-trained model features commonly used in voice conversion, and proposes\\nan innovative method for disentangling speech feature representations.\\nSpecifically, we first propose an ideal content feature, referred to as the\\naverage feature, which is calculated by averaging the features within\\nframe-level aligned parallel speech (FAPS) data. For generating FAPS data, we\\nutilize a technique that involves freezing the duration predictor in a\\nText-to-Speech system and manipulating speaker embedding. To fit the average\\nfeature on traditional VC datasets, we then design the AVENet to take features\\nas input and generate closely matching average features. Experiments are\\nconducted on the performance of AVENet-extracted features within a VC system.\\nThe experimental results demonstrate its superiority over multiple current\\nspeech feature disentangling methods. These findings affirm the effectiveness\\nof our disentanglement approach.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD\", \"published\": \"2025-04-08T09:16:32Z\"}"}
