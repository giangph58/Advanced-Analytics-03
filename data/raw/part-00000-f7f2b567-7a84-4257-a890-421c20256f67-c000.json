{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11364v1\", \"title\": \"Teaching Large Language Models to Reason through Learning and Forgetting\", \"summary\": \"Leveraging inference-time search in large language models has proven\\neffective in further enhancing a trained model's capability to solve complex\\nmathematical and reasoning problems. However, this approach significantly\\nincreases computational costs and inference time, as the model must generate\\nand evaluate multiple candidate solutions to identify a viable reasoning path.\\nTo address this, we propose an effective approach that integrates search\\ncapabilities directly into the model by fine-tuning it using both successful\\n(learning) and failed reasoning paths (forgetting) derived from diverse search\\nmethods. While fine-tuning the model with these data might seem\\nstraightforward, we identify a critical issue: the model's search capability\\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\\ndegradation can be substantially mitigated by employing a smaller learning\\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\\nmathematical reasoning benchmarks show that our approach not only outperforms\\nboth standard fine-tuning and inference-time search baselines but also\\nsignificantly reduces inference time by 180$\\\\times$.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.CL\", \"published\": \"2025-04-15T16:30:02Z\"}"}
