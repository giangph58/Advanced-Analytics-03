{"value":"{\"aid\": \"http://arxiv.org/abs/2504.13059v1\", \"title\": \"RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins\", \"summary\": \"In the rapidly advancing field of robotics, dual-arm coordination and complex\\nobject manipulation are essential capabilities for developing advanced\\nautonomous systems. However, the scarcity of diverse, high-quality\\ndemonstration data and real-world-aligned evaluation benchmarks severely limits\\nsuch development. To address this, we introduce RoboTwin, a generative digital\\ntwin framework that uses 3D generative foundation models and large language\\nmodels to produce diverse expert datasets and provide a real-world-aligned\\nevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates\\nvaried digital twins of objects from single 2D images, generating realistic and\\ninteractive scenarios. It also introduces a spatial relation-aware code\\ngeneration framework that combines object annotations with large language\\nmodels to break down tasks, determine spatial constraints, and generate precise\\nrobotic movement code. Our framework offers a comprehensive benchmark with both\\nsimulated and real-world data, enabling standardized evaluation and better\\nalignment between simulated training and real-world performance. We validated\\nour approach using the open-source COBOT Magic Robot platform. Policies\\npre-trained on RoboTwin-generated data and fine-tuned with limited real-world\\nsamples demonstrate significant potential for enhancing dual-arm robotic\\nmanipulation systems by improving success rates by over 70% for single-arm\\ntasks and over 40% for dual-arm tasks compared to models trained solely on\\nreal-world data.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.CL\", \"published\": \"2025-04-17T16:14:24Z\"}"}
