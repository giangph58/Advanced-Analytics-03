{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03230v1\", \"title\": \"Joint Resource Management for Energy-efficient UAV-assisted SWIPT-MEC: A\\n  Deep Reinforcement Learning Approach\", \"summary\": \"The integration of simultaneous wireless information and power transfer\\n(SWIPT) technology in 6G Internet of Things (IoT) networks faces significant\\nchallenges in remote areas and disaster scenarios where ground infrastructure\\nis unavailable. This paper proposes a novel unmanned aerial vehicle\\n(UAV)-assisted mobile edge computing (MEC) system enhanced by directional\\nantennas to provide both computational resources and energy support for ground\\nIoT terminals. However, such systems require multiple trade-off policies to\\nbalance UAV energy consumption, terminal battery levels, and computational\\nresource allocation under various constraints, including limited UAV battery\\ncapacity, non-linear energy harvesting characteristics, and dynamic task\\narrivals. To address these challenges comprehensively, we formulate a\\nbi-objective optimization problem that simultaneously considers system energy\\nefficiency and terminal battery sustainability. We then reformulate this\\nnon-convex problem with a hybrid solution space as a Markov decision process\\n(MDP) and propose an improved soft actor-critic (SAC) algorithm with an action\\nsimplification mechanism to enhance its convergence and generalization\\ncapabilities. Simulation results have demonstrated that our proposed approach\\noutperforms various baselines in different scenarios, achieving efficient\\nenergy management while maintaining high computational performance.\\nFurthermore, our method shows strong generalization ability across different\\nscenarios, particularly in complex environments, validating the effectiveness\\nof our designed boundary penalty and charging reward mechanisms.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-05-06T06:46:19Z\"}"}
