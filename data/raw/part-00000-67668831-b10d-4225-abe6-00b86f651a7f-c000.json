{"value":"{\"aid\": \"http://arxiv.org/abs/2504.15580v1\", \"title\": \"On the Price of Differential Privacy for Hierarchical Clustering\", \"summary\": \"Hierarchical clustering is a fundamental unsupervised machine learning task\\nwith the aim of organizing data into a hierarchy of clusters. Many applications\\nof hierarchical clustering involve sensitive user information, therefore\\nmotivating recent studies on differentially private hierarchical clustering\\nunder the rigorous framework of Dasgupta's objective. However, it has been\\nshown that any privacy-preserving algorithm under edge-level differential\\nprivacy necessarily suffers a large error. To capture practical applications of\\nthis problem, we focus on the weight privacy model, where each edge of the\\ninput graph is at least unit weight. We present a novel algorithm in the weight\\nprivacy model that shows significantly better approximation than known\\nimpossibility results in the edge-level DP setting. In particular, our\\nalgorithm achieves $O(\\\\log^{1.5}n/\\\\varepsilon)$ multiplicative error for\\n$\\\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the\\ninput graph, and the cost is never worse than the optimal additive error in\\nexisting work. We complement our algorithm by showing if the unit-weight\\nconstraint does not apply, the lower bound for weight-level DP hierarchical\\nclustering is essentially the same as the edge-level DP, i.e.\\n$\\\\Omega(n^2/\\\\varepsilon)$ additive error. As a result, we also obtain a new\\nlower bound of $\\\\tilde{\\\\Omega}(1/\\\\varepsilon)$ additive error for balanced\\nsparsest cuts in the weight-level DP model, which may be of independent\\ninterest. Finally, we evaluate our algorithm on synthetic and real-world\\ndatasets. Our experimental results show that our algorithm performs well in\\nterms of extra cost and has good scalability to large graphs.\", \"main_category\": \"cs.DS\", \"categories\": \"cs.DS,cs.CR,cs.LG\", \"published\": \"2025-04-22T04:39:40Z\"}"}
