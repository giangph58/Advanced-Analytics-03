{"value":"{\"aid\": \"http://arxiv.org/abs/2505.04484v1\", \"title\": \"A Tutorial on Discriminative Clustering and Mutual Information\", \"summary\": \"To cluster data is to separate samples into distinctive groups that should\\nideally have some cohesive properties. Today, numerous clustering algorithms\\nexist, and their differences lie essentially in what can be perceived as\\n``cohesive properties''. Therefore, hypotheses on the nature of clusters must\\nbe set: they can be either generative or discriminative. As the last decade\\nwitnessed the impressive growth of deep clustering methods that involve neural\\nnetworks to handle high-dimensional data often in a discriminative manner; we\\nconcentrate mainly on the discriminative hypotheses. In this paper, our aim is\\nto provide an accessible historical perspective on the evolution of\\ndiscriminative clustering methods and notably how the nature of assumptions of\\nthe discriminative models changed over time: from decision boundaries to\\ninvariance critics. We notably highlight how mutual information has been a\\nhistorical cornerstone of the progress of (deep) discriminative clustering\\nmethods. We also show some known limitations of mutual information and how\\ndiscriminative clustering methods tried to circumvent those. We then discuss\\nthe challenges that discriminative clustering faces with respect to the\\nselection of the number of clusters. Finally, we showcase these techniques\\nusing the dedicated Python package, GemClus, that we have developed for\\ndiscriminative clustering.\", \"main_category\": \"stat.ML\", \"categories\": \"stat.ML,cs.LG,G.3\", \"published\": \"2025-05-07T14:54:36Z\"}"}
