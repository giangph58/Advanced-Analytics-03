{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10418v1\", \"title\": \"CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical\\n  Interview Dialogue Reconstruction and Evaluation\", \"summary\": \"Large language models (LLMs) hold great promise for assisting clinical\\ninterviews due to their fluent interactive capabilities and extensive medical\\nknowledge. However, the lack of high-quality interview dialogue data and widely\\naccepted evaluation methods has significantly impeded this process. So we\\npropose CliniChat, a framework that integrates multi-source knowledge to enable\\nLLMs to simulate real-world clinical interviews. It consists of two modules:\\nClini-Recon and Clini-Eval, each responsible for reconstructing and evaluating\\ninterview dialogues, respectively. By incorporating three sources of knowledge,\\nClini-Recon transforms clinical notes into systematic, professional, and\\nempathetic interview dialogues. Clini-Eval combines a comprehensive evaluation\\nmetric system with a two-phase automatic evaluation approach, enabling LLMs to\\nassess interview performance like experts. We contribute MedQA-Dialog, a\\nhigh-quality synthetic interview dialogue dataset, and CliniChatGLM, a model\\nspecialized for clinical interviews. Experimental results demonstrate that\\nCliniChatGLM's interview capabilities undergo a comprehensive upgrade,\\nparticularly in history-taking, achieving state-of-the-art performance.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-14T17:06:47Z\"}"}
