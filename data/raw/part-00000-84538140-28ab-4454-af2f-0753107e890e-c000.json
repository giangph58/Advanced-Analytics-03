{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21761v1\", \"title\": \"Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single\\n  Video\", \"summary\": \"This paper presents a unified approach to understanding dynamic scenes from\\ncasual videos. Large pretrained vision foundation models, such as\\nvision-language, video depth prediction, motion tracking, and segmentation\\nmodels, offer promising capabilities. However, training a single model for\\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\\nmulti-stage optimization framework that harnesses multiple pretrained models to\\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\\npose estimation, and dense 3D motion tracking. Our results show\\nstate-of-the-art performance in dynamic 4D modeling with superior visual\\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\\neffectiveness of repurposing visual foundation models for 4D understanding.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-03-27T17:57:32Z\"}"}
