{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06943v1\", \"title\": \"Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations,\\n  Architectural Components, and Cognitive Integration\", \"summary\": \"Agents powered by Large Language Models (LLMs) have recently demonstrated\\nimpressive capabilities in various tasks. Still, they face limitations in tasks\\nrequiring specific, structured knowledge, flexibility, or accountable\\ndecision-making. While agents are capable of perceiving their environments,\\nforming inferences, planning, and executing actions towards goals, they often\\nface issues such as hallucinations and lack of contextual memory across\\ninteractions. This paper explores how Case-Based Reasoning (CBR), a strategy\\nthat solves new problems by referencing past experiences, can be integrated\\ninto LLM agent frameworks. This integration allows LLMs to leverage explicit\\nknowledge, enhancing their effectiveness. We systematically review the\\ntheoretical foundations of these enhanced agents, identify critical framework\\ncomponents, and formulate a mathematical model for the CBR processes of case\\nretrieval, adaptation, and learning. We also evaluate CBR-enhanced agents\\nagainst other methods like Chain-of-Thought reasoning and standard\\nRetrieval-Augmented Generation, analyzing their relative strengths. Moreover,\\nwe explore how leveraging CBR's cognitive dimensions (including\\nself-reflection, introspection, and curiosity) via goal-driven autonomy\\nmechanisms can further enhance the LLM agent capabilities. Contributing to the\\nongoing research on neuro-symbolic hybrid systems, this work posits CBR as a\\nviable technique for enhancing the reasoning skills and cognitive aspects of\\nautonomous LLM agents.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.MA\", \"published\": \"2025-04-09T14:51:02Z\"}"}
