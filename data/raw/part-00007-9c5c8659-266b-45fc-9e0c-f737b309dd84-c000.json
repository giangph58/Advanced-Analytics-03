{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01588v1\", \"title\": \"Building Knowledge from Interactions: An LLM-Based Architecture for\\n  Adaptive Tutoring and Social Reasoning\", \"summary\": \"Integrating robotics into everyday scenarios like tutoring or physical\\ntraining requires robots capable of adaptive, socially engaging, and\\ngoal-oriented interactions. While Large Language Models show promise in\\nhuman-like communication, their standalone use is hindered by memory\\nconstraints and contextual incoherence. This work presents a multimodal,\\ncognitively inspired framework that enhances LLM-based autonomous\\ndecision-making in social and task-oriented Human-Robot Interaction.\\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\\nsocial conversation with task guidance and goal-driven motivation. To further\\nenhance autonomy and personalization, we introduce a memory system for\\nselecting, storing and retrieving experiences, facilitating generalized\\nreasoning based on knowledge built across different interactions. A preliminary\\nHRI user study and offline experiments with a synthetic dataset validate our\\napproach, demonstrating the system's ability to manage complex interactions,\\nautonomously drive training tasks, and build and retrieve contextual memories,\\nadvancing socially intelligent robotics.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI\", \"published\": \"2025-04-02T10:45:41Z\"}"}
