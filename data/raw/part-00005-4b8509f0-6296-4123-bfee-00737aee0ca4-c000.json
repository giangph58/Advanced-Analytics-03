{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19657v1\", \"title\": \"Neuronal correlations shape the scaling behavior of memory capacity and\\n  nonlinear computational capability of recurrent neural networks\", \"summary\": \"Reservoir computing is a powerful framework for real-time information\\nprocessing, characterized by its high computational ability and quick learning,\\nwith applications ranging from machine learning to biological systems. In this\\npaper, we demonstrate that the memory capacity of a reservoir recurrent neural\\nnetwork scales sublinearly with the number of readout neurons. To elucidate\\nthis phenomenon, we develop a theoretical framework for analytically deriving\\nmemory capacity, attributing the decaying growth of memory capacity to neuronal\\ncorrelations. In addition, numerical simulations reveal that once memory\\ncapacity becomes sublinear, increasing the number of readout neurons\\nsuccessively enables nonlinear processing at progressively higher polynomial\\norders. Furthermore, our theoretical framework suggests that neuronal\\ncorrelations govern not only memory capacity but also the sequential growth of\\nnonlinear computational capabilities. Our findings establish a foundation for\\ndesigning scalable and cost-effective reservoir computing, providing novel\\ninsights into the interplay among neuronal correlations, linear memory, and\\nnonlinear processing.\", \"main_category\": \"cond-mat.dis-nn\", \"categories\": \"cond-mat.dis-nn,cs.LG,q-bio.NC\", \"published\": \"2025-04-28T10:17:31Z\"}"}
