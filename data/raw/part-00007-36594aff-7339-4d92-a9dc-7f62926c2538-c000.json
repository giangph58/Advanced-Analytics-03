{"value":"{\"aid\": \"http://arxiv.org/abs/2505.00651v1\", \"title\": \"Open-Source LLM-Driven Federated Transformer for Predictive IoV\\n  Management\", \"summary\": \"The proliferation of connected vehicles within the Internet of Vehicles (IoV)\\necosystem presents critical challenges in ensuring scalable, real-time, and\\nprivacy-preserving traffic management. Existing centralized IoV solutions often\\nsuffer from high latency, limited scalability, and reliance on proprietary\\nArtificial Intelligence (AI) models, creating significant barriers to\\nwidespread deployment, particularly in dynamic and privacy-sensitive\\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\\nsystems remains underexplored, especially concerning prompt optimization and\\neffective utilization in federated contexts. To address these challenges, we\\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\\nintroduces a dynamic prompt optimization mechanism that iteratively refines\\ntextual prompts to enhance trajectory prediction. The architecture employs a\\ndual-layer federated learning paradigm, combining lightweight edge models for\\nreal-time inference with cloud-based LLMs to retain global intelligence. A\\nTransformer-driven synthetic data generator is incorporated to augment training\\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\\nwhile maintaining high performance on synthetic datasets. These results\\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\\nscalable IoV management, offering a promising alternative to proprietary\\nsolutions in smart mobility ecosystems.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.ET,cs.LG\", \"published\": \"2025-05-01T16:54:21Z\"}"}
