{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20013v1\", \"title\": \"LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case\\n  Study on Neural News Recommendation\", \"summary\": \"Online fake news moderation now faces a new challenge brought by the\\nmalicious use of large language models (LLMs) in fake news production. Though\\nexisting works have shown LLM-generated fake news is hard to detect from an\\nindividual aspect, it remains underexplored how its large-scale release will\\nimpact the news ecosystem. In this study, we develop a simulation pipeline and\\na dataset with ~56k generated news of diverse types to investigate the effects\\nof LLM-generated fake news within neural news recommendation systems. Our\\nfindings expose a truth decay phenomenon, where real news is gradually losing\\nits advantageous position in news ranking against fake news as LLM-generated\\nnews is involved in news recommendation. We further provide an explanation\\nabout why truth decay occurs from a familiarity perspective and show the\\npositive correlation between perplexity and news ranking. Finally, we discuss\\nthe threats of LLM-generated fake news and provide possible countermeasures. We\\nurge stakeholders to address this emerging challenge to preserve the integrity\\nof news ecosystems.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CY,cs.IR\", \"published\": \"2025-04-28T17:32:38Z\"}"}
