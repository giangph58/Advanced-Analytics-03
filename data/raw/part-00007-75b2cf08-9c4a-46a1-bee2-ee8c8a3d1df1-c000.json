{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03466v1\", \"title\": \"Design principles of deep translationally-symmetric neural quantum\\n  states for frustrated magnets\", \"summary\": \"Deep neural network quantum states have emerged as a leading method for\\nstudying the ground states of quantum magnets. Successful architectures exploit\\ntranslational symmetry, but the root of their effectiveness and differences\\nbetween architectures remain unclear. Here, we apply the ConvNext architecture,\\ndesigned to incorporate elements of transformers into convolutional networks,\\nto quantum many-body ground states. We find that it is remarkably similar to\\nthe factored vision transformer, which has been employed successfully for\\nseveral frustrated spin systems, allowing us to relate this architecture to\\nmore conventional convolutional networks. Through a series of numerical\\nexperiments we design the ConvNext to achieve greatest performance at lowest\\ncomputational cost, then apply this network to the Shastry-Sutherland and J1-J2\\nmodels, obtaining variational energies comparable to the state of the art,\\nproviding a blueprint for network design choices of translationally-symmetric\\narchitectures to tackle challenging ground-state problems in frustrated\\nmagnetism.\", \"main_category\": \"cond-mat.str-el\", \"categories\": \"cond-mat.str-el,cond-mat.dis-nn,quant-ph\", \"published\": \"2025-05-06T12:08:59Z\"}"}
