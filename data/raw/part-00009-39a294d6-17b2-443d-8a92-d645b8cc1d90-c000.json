{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16430v1\", \"title\": \"MAGIC: Near-Optimal Data Attribution for Deep Learning\", \"summary\": \"The goal of predictive data attribution is to estimate how adding or removing\\na given set of training datapoints will affect model predictions. In convex\\nsettings, this goal is straightforward (i.e., via the infinitesimal jackknife).\\nIn large-scale (non-convex) settings, however, existing methods are far less\\nsuccessful -- current methods' estimates often only weakly correlate with\\nground truth. In this work, we present a new data attribution method (MAGIC)\\nthat combines classical methods and recent advances in metadifferentiation to\\n(nearly) optimally estimate the effect of adding or removing training data on\\nmodel predictions.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CL,cs.CV,stat.ML\", \"published\": \"2025-04-23T05:32:37Z\"}"}
