{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10127v1\", \"title\": \"Breaking the Data Barrier -- Building GUI Agents Through Task\\n  Generalization\", \"summary\": \"Graphical User Interface (GUI) agents offer cross-platform solutions for\\nautomating complex digital tasks, with significant potential to transform\\nproductivity workflows. However, their performance is often constrained by the\\nscarcity of high-quality trajectory data. To address this limitation, we\\npropose training Vision Language Models (VLMs) on data-rich,\\nreasoning-intensive tasks during a dedicated mid-training stage, and then\\nexamine how incorporating these tasks facilitates generalization to GUI\\nplanning scenarios. Specifically, we explore a range of tasks with readily\\navailable instruction-tuning data, including GUI perception, multimodal\\nreasoning, and textual reasoning. Through extensive experiments across 11\\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\\neffective, yielding substantial improvements across most settings. For\\ninstance, multimodal mathematical reasoning enhances performance on\\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\\ngeneralization from text-based to visual domains; (2) Contrary to prior\\nassumptions, GUI perception data - previously considered closely aligned with\\nGUI agent tasks and widely utilized for training - has a comparatively limited\\nimpact on final performance; (3) Building on these insights, we identify the\\nmost effective mid-training tasks and curate optimized mixture datasets,\\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\\ntransfer for GUI agents and offers a practical approach to addressing data\\nscarcity challenges in this emerging field. The code, data and models will be\\navailable at https://github.com/hkust-nlp/GUIMid.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL,cs.CV\", \"published\": \"2025-04-14T11:35:02Z\"}"}
