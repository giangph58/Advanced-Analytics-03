{"value":"{\"aid\": \"http://arxiv.org/abs/2505.05406v1\", \"title\": \"Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than\\n  Humans?\", \"summary\": \"Framing in media critically shapes public perception by selectively\\nemphasizing some details while downplaying others. With the rise of large\\nlanguage models in automated news and content creation, there is growing\\nconcern that these systems may introduce or even amplify framing biases\\ncompared to human authors. In this paper, we explore how framing manifests in\\nboth out-of-the-box and fine-tuned LLM-generated news content. Our analysis\\nreveals that, particularly in politically and socially sensitive contexts, LLMs\\ntend to exhibit more pronounced framing than their human counterparts. In\\naddition, we observe significant variation in framing tendencies across\\ndifferent model architectures, with some models displaying notably higher\\nbiases. These findings point to the need for effective post-training mitigation\\nstrategies and tighter evaluation frameworks to ensure that automated news\\ncontent upholds the standards of balanced reporting.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-05-08T16:46:24Z\"}"}
