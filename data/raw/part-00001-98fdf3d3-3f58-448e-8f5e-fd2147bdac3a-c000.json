{"value":"{\"aid\": \"http://arxiv.org/abs/2505.03730v1\", \"title\": \"FlexiAct: Towards Flexible Action Control in Heterogeneous Scenarios\", \"summary\": \"Action customization involves generating videos where the subject performs\\nactions dictated by input control signals. Current methods use pose-guided or\\nglobal motion customization but are limited by strict constraints on spatial\\nstructure, such as layout, skeleton, and viewpoint consistency, reducing\\nadaptability across diverse subjects and scenarios. To overcome these\\nlimitations, we propose FlexiAct, which transfers actions from a reference\\nvideo to an arbitrary target image. Unlike existing methods, FlexiAct allows\\nfor variations in layout, viewpoint, and skeletal structure between the subject\\nof the reference video and the target image, while maintaining identity\\nconsistency. Achieving this requires precise action control, spatial structure\\nadaptation, and consistency preservation. To this end, we introduce RefAdapter,\\na lightweight image-conditioned adapter that excels in spatial adaptation and\\nconsistency preservation, surpassing existing methods in balancing appearance\\nconsistency and structural flexibility. Additionally, based on our\\nobservations, the denoising process exhibits varying levels of attention to\\nmotion (low frequency) and appearance details (high frequency) at different\\ntimesteps. So we propose FAE (Frequency-aware Action Extraction), which, unlike\\nexisting methods that rely on separate spatial-temporal architectures, directly\\nachieves action extraction during the denoising process. Experiments\\ndemonstrate that our method effectively transfers actions to subjects with\\ndiverse layouts, skeletons, and viewpoints. We release our code and model\\nweights to support further research at\\nhttps://shiyi-zh0408.github.io/projectpages/FlexiAct/\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.MM\", \"published\": \"2025-05-06T17:58:02Z\"}"}
