{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24311v1\", \"title\": \"Selective Inference in Graphical Models via Maximum Likelihood\", \"summary\": \"The graphical lasso is a widely used algorithm for fitting undirected\\nGaussian graphical models. However, for inference on functionals of edge values\\nin the learned graph, standard tools lack formal statistical guarantees, such\\nas control of the type I error rate. In this paper, we introduce a selective\\ninference method for asymptotically valid inference after graphical lasso\\nselection with added randomization. We obtain a selective likelihood,\\nconditional on the event of selection, through a change of variable on the\\nknown density of the randomization variables. Our method enables interval\\nestimation and hypothesis testing for a wide range of functionals of edge\\nvalues in the learned graph using the conditional maximum likelihood estimate.\\nOur numerical studies show that introducing a small amount of randomization:\\n(i) greatly increases power and yields substantially shorter intervals compared\\nto other conditional inference methods, including data splitting; (ii) ensures\\nintervals of bounded length in high-dimensional settings where data splitting\\nis infeasible due to insufficient samples for inference; (iii) enables\\ninference for a wide range of inferential targets in the learned graph,\\nincluding measures of node influence and connectivity between nodes.\", \"main_category\": \"stat.ME\", \"categories\": \"stat.ME,stat.AP,stat.CO\", \"published\": \"2025-03-31T16:57:04Z\"}"}
