{"value":"{\"aid\": \"http://arxiv.org/abs/2504.14871v1\", \"title\": \"Natural Fingerprints of Large Language Models\", \"summary\": \"Large language models (LLMs) often exhibit biases -- systematic deviations\\nfrom expected norms -- in their outputs. These range from overt issues, such as\\nunfair responses, to subtler patterns that can reveal which model produced\\nthem. We investigate the factors that give rise to identifiable characteristics\\nin LLMs. Since LLMs model training data distribution, it is reasonable that\\ndifferences in training data naturally lead to the characteristics. However,\\nour findings reveal that even when LLMs are trained on the exact same data, it\\nis still possible to distinguish the source model based on its generated text.\\nWe refer to these unintended, distinctive characteristics as natural\\nfingerprints. By systematically controlling training conditions, we show that\\nthe natural fingerprints can emerge from subtle differences in the training\\nprocess, such as parameter sizes, optimization settings, and even random seeds.\\nWe believe that understanding natural fingerprints offers new insights into the\\norigins of unintended bias and ways for improving control over LLM behavior.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-21T05:48:52Z\"}"}
