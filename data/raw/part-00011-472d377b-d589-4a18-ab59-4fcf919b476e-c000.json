{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16581v1\", \"title\": \"Revisiting Regret Benchmarks in Online Non-Stochastic Control\", \"summary\": \"In the online non-stochastic control problem, an agent sequentially selects\\ncontrol inputs for a linear dynamical system when facing unknown and\\nadversarially selected convex costs and disturbances. A common metric for\\nevaluating control policies in this setting is policy regret, defined relative\\nto the best-in-hindsight linear feedback controller. However, for general\\nconvex costs, this benchmark may be less meaningful since linear controllers\\ncan be highly suboptimal. To address this, we introduce an alternative, more\\nsuitable benchmark--the performance of the best fixed input. We show that this\\nbenchmark can be viewed as a natural extension of the standard benchmark used\\nin online convex optimization and propose a novel online control algorithm that\\nachieves sublinear regret with respect to this new benchmark. We also discuss\\nthe connections between our method and the original one proposed by Agarwal et\\nal. in their seminal work introducing the online non-stochastic control\\nproblem, and compare the performance of both approaches through numerical\\nsimulations.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC,cs.SY,eess.SY\", \"published\": \"2025-04-23T10:01:34Z\"}"}
