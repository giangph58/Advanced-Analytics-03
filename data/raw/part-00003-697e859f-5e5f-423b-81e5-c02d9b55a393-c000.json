{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16080v1\", \"title\": \"From Reflection to Perfection: Scaling Inference-Time Optimization for\\n  Text-to-Image Diffusion Models via Reflection Tuning\", \"summary\": \"Recent text-to-image diffusion models achieve impressive visual quality\\nthrough extensive scaling of training data and model parameters, yet they often\\nstruggle with complex scenes and fine-grained details. Inspired by the\\nself-reflection capabilities emergent in large language models, we propose\\nReflectionFlow, an inference-time framework enabling diffusion models to\\niteratively reflect upon and refine their outputs. ReflectionFlow introduces\\nthree complementary inference-time scaling axes: (1) noise-level scaling to\\noptimize latent initialization; (2) prompt-level scaling for precise semantic\\nguidance; and most notably, (3) reflection-level scaling, which explicitly\\nprovides actionable reflections to iteratively assess and correct previous\\ngenerations. To facilitate reflection-level scaling, we construct GenRef, a\\nlarge-scale dataset comprising 1 million triplets, each containing a\\nreflection, a flawed image, and an enhanced image. Leveraging this dataset, we\\nefficiently perform reflection tuning on state-of-the-art diffusion\\ntransformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified\\nframework. Experimental results show that ReflectionFlow significantly\\noutperforms naive noise-level scaling methods, offering a scalable and\\ncompute-efficient solution toward higher-quality image synthesis on challenging\\ntasks.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-22T17:58:07Z\"}"}
