{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20414v1\", \"title\": \"Enhancing Leakage Attacks on Searchable Symmetric Encryption Using\\n  LLM-Based Synthetic Data Generation\", \"summary\": \"Searchable Symmetric Encryption (SSE) enables efficient search capabilities\\nover encrypted data, allowing users to maintain privacy while utilizing cloud\\nstorage. However, SSE schemes are vulnerable to leakage attacks that exploit\\naccess patterns, search frequency, and volume information. Existing studies\\nfrequently assume that adversaries possess a substantial fraction of the\\nencrypted dataset to mount effective inference attacks, implying there is a\\ndatabase leakage of such documents, thus, an assumption that may not hold in\\nreal-world scenarios. In this work, we investigate the feasibility of enhancing\\nleakage attacks under a more realistic threat model in which adversaries have\\naccess to minimal leaked data. We propose a novel approach that leverages large\\nlanguage models (LLMs), specifically GPT-4 variants, to generate synthetic\\ndocuments that statistically and semantically resemble the real-world dataset\\nof Enron emails. Using the email corpus as a case study, we evaluate the\\neffectiveness of synthetic data generated via random sampling and hierarchical\\nclustering methods on the performance of the SAP (Search Access Pattern)\\nkeyword inference attack restricted to token volumes only. Our results\\ndemonstrate that, while the choice of LLM has limited effect, increasing\\ndataset size and employing clustering-based generation significantly improve\\nattack accuracy, achieving comparable performance to attacks using larger\\namounts of real data. We highlight the growing relevance of LLMs in adversarial\\ncontexts.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR\", \"published\": \"2025-04-29T04:23:10Z\"}"}
