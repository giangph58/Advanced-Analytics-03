{"value":"{\"aid\": \"http://arxiv.org/abs/2504.10001v1\", \"title\": \"GaussVideoDreamer: 3D Scene Generation with Video Diffusion and\\n  Inconsistency-Aware Gaussian Splatting\", \"summary\": \"Single-image 3D scene reconstruction presents significant challenges due to\\nits inherently ill-posed nature and limited input constraints. Recent advances\\nhave explored two promising directions: multiview generative models that train\\non 3D consistent datasets but struggle with out-of-distribution generalization,\\nand 3D scene inpainting and completion frameworks that suffer from cross-view\\ninconsistency and suboptimal error handling, as they depend exclusively on\\ndepth data or 3D smoothness, which ultimately degrades output quality and\\ncomputational performance. Building upon these approaches, we present\\nGaussVideoDreamer, which advances generative multimedia approaches by bridging\\nthe gap between image, video, and 3D generation, integrating their strengths\\nthrough two key innovations: (1) A progressive video inpainting strategy that\\nharnesses temporal coherence for improved multiview consistency and faster\\nconvergence. (2) A 3D Gaussian Splatting consistency mask to guide the video\\ndiffusion with 3D consistent multiview evidence. Our pipeline combines three\\ncore components: a geometry-aware initialization protocol, Inconsistency-Aware\\nGaussian Splatting, and a progressive video inpainting strategy. Experimental\\nresults demonstrate that our approach achieves 32% higher LLaVA-IQA scores and\\nat least 2x speedup compared to existing methods while maintaining robust\\nperformance across diverse scenes.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-14T09:04:01Z\"}"}
