{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16760v1\", \"title\": \"Lightweight Latent Verifiers for Efficient Meta-Generation Strategies\", \"summary\": \"Verifiers are auxiliary models that assess the correctness of outputs\\ngenerated by base large language models (LLMs). They play a crucial role in\\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\\nverifiers are LLMs themselves, often as large (or larger) than the base model\\nthey support, making them computationally expensive. In this work, we introduce\\na novel lightweight verification approach, LiLaVe, which reliably extracts\\ncorrectness signals from the hidden states of the base LLM. A key advantage of\\nLiLaVe is its ability to operate with only a small fraction of the\\ncomputational budget required by traditional LLM-based verifiers. To\\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\\nLiLaVe-based approaches, like conditional self-correction or conditional\\nmajority voting, that significantly improve both accuracy and efficiency in\\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\\nextracting latent information from the hidden states of LLMs, and opens the\\ndoor to scalable and resource-efficient solutions for reasoning-intensive\\napplications.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-23T14:33:20Z\"}"}
