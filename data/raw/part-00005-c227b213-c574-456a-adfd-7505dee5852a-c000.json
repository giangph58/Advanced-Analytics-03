{"value":"{\"aid\": \"http://arxiv.org/abs/2504.21266v1\", \"title\": \"CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine\\n  Text-Co-Guided Latent Diffusion\", \"summary\": \"In action recognition tasks, feature diversity is essential for enhancing\\nmodel generalization and performance. Existing methods typically promote\\nfeature diversity by expanding the training data in the sample space, which\\noften leads to inefficiencies and semantic inconsistencies. To overcome these\\nproblems, we propose a novel Coarse-fine text co-guidance Diffusion model\\n(CoCoDiff). CoCoDiff generates diverse yet semantically consistent features in\\nthe latent space by leveraging diffusion and multi-granularity textual\\nguidance. Specifically, our approach feeds spatio-temporal features extracted\\nfrom skeleton sequences into a latent diffusion model to generate diverse\\naction representations. Meanwhile, we introduce a coarse-fine text co-guided\\nstrategy that leverages textual information from large language models (LLMs)\\nto ensure semantic consistency between the generated features and the original\\ninputs. It is noted that CoCoDiff operates as a plug-and-play auxiliary module\\nduring training, incurring no additional inference cost. Extensive experiments\\ndemonstrate that CoCoDiff achieves SOTA performance on skeleton-based action\\nrecognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and\\nKinetics-Skeleton.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-30T02:50:24Z\"}"}
