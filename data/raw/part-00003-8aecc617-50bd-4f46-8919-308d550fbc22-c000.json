{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16595v1\", \"title\": \"HERB: Human-augmented Efficient Reinforcement learning for Bin-packing\", \"summary\": \"Packing objects efficiently is a fundamental problem in logistics, warehouse\\nautomation, and robotics. While traditional packing solutions focus on\\ngeometric optimization, packing irregular, 3D objects presents significant\\nchallenges due to variations in shape and stability. Reinforcement\\nLearning~(RL) has gained popularity in robotic packing tasks, but training\\npurely from simulation can be inefficient and computationally expensive. In\\nthis work, we propose HERB, a human-augmented RL framework for packing\\nirregular objects. We first leverage human demonstrations to learn the best\\nsequence of objects to pack, incorporating latent factors such as space\\noptimization, stability, and object relationships that are difficult to model\\nexplicitly. Next, we train a placement algorithm that uses visual information\\nto determine the optimal object positioning inside a packing container. Our\\napproach is validated through extensive performance evaluations, analyzing both\\npacking efficiency and latency. Finally, we demonstrate the real-world\\nfeasibility of our method on a robotic system. Experimental results show that\\nour method outperforms geometric and purely RL-based approaches by leveraging\\nhuman intuition, improving both packing robustness and adaptability. This work\\nhighlights the potential of combining human expertise-driven RL to tackle\\ncomplex real-world packing challenges in robotic systems.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.LG\", \"published\": \"2025-04-23T10:24:36Z\"}"}
