{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20887v1\", \"title\": \"Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation\", \"summary\": \"When optimising for conditional value at risk (CVaR) using policy gradients\\n(PG), current methods rely on discarding a large proportion of trajectories,\\nresulting in poor sample efficiency. We propose a reformulation of the CVaR\\noptimisation problem by capping the total return of trajectories used in\\ntraining, rather than simply discarding them, and show that this is equivalent\\nto the original problem if the cap is set appropriately. We show, with\\nempirical results in an number of environments, that this reformulation of the\\nproblem results in consistently improved performance compared to baselines.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-29T16:04:16Z\"}"}
