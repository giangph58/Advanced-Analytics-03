{"value":"{\"aid\": \"http://arxiv.org/abs/2504.20518v1\", \"title\": \"Dynamic Attention Analysis for Backdoor Detection in Text-to-Image\\n  Diffusion Models\", \"summary\": \"Recent studies have revealed that text-to-image diffusion models are\\nvulnerable to backdoor attacks, where attackers implant stealthy textual\\ntriggers to manipulate model outputs. Previous backdoor detection methods\\nprimarily focus on the static features of backdoor samples. However, a vital\\nproperty of diffusion models is their inherent dynamism. This study introduces\\na novel backdoor detection perspective named Dynamic Attention Analysis (DAA),\\nshowing that these dynamic characteristics serve as better indicators for\\nbackdoor detection. Specifically, by examining the dynamic evolution of\\ncross-attention maps, we observe that backdoor samples exhibit distinct feature\\nevolution patterns at the $<$EOS$>$ token compared to benign samples. To\\nquantify these dynamic anomalies, we first introduce DAA-I, which treats the\\ntokens' attention maps as spatially independent and measures dynamic feature\\nusing the Frobenius norm. Furthermore, to better capture the interactions\\nbetween attention maps and refine the feature, we propose a dynamical\\nsystem-based approach, referred to as DAA-S. This model formulates the spatial\\ncorrelations among attention maps using a graph-based state equation and we\\ntheoretically analyze the global asymptotic stability of this method. Extensive\\nexperiments across five representative backdoor attack scenarios demonstrate\\nthat our approach significantly surpasses existing detection methods, achieving\\nan average F1 Score of 79.49% and an AUC of 87.67%. The code is available at\\nhttps://github.com/Robin-WZQ/DAA.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-29T07:59:35Z\"}"}
