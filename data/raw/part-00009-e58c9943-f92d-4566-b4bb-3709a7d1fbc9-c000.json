{"value":"{\"aid\": \"http://arxiv.org/abs/2504.11385v1\", \"title\": \"GLL-type Nonmonotone Descent Methods Revisited under\\n  Kurdyka-\\u0141ojasiewicz Property\", \"summary\": \"The purpose of this paper is to extend the full convergence results of the\\nclassic GLL-type (Grippo-Lampariello-Lucidi) nonmonotone methods to nonconvex\\nand nonsmooth optimization. We propose a novel iterative framework for the\\nminimization of a proper and lower semicontinuous function $\\\\Phi$. The\\nframework consists of the GLL-type nonmonotone decrease condition for a\\nsequence, a relative error condition for its augmented sequence with respect to\\na Kurdyka-{\\\\L}ojasiewicz (KL) function $\\\\Theta$, and a relative gap condition\\nfor the partial maximum objective value sequence. The last condition is shown\\nto be a product of the prox-regularity of $\\\\Phi$ on the set of cluster points,\\nand to hold automatically under a mild condition on the objective value\\nsequence. We prove that for any sequence and its bounded augmented sequence\\ntogether falling within the framework, the sequence itself is convergent.\\nFurthermore, when $\\\\Theta$ is a KL function of exponent $\\\\theta\\\\in(0, 1)$, the\\nconvergence admits a linear rate if $\\\\theta\\\\in(0, 1/2]$ and a sublinear rate if\\n$\\\\theta\\\\in(1/2, 1)$. As applications, we prove, for the first time, that the\\ntwo existing algorithms, namely the nonmonotone proximal gradient (NPG) method\\nwith majorization and NPG with extrapolation both enjoy the full convergence of\\nthe iterate sequences for nonconvex and nonsmooth KL composite optimization\\nproblems.\", \"main_category\": \"math.OC\", \"categories\": \"math.OC\", \"published\": \"2025-04-15T16:54:25Z\"}"}
