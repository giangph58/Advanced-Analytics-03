{"value":"{\"aid\": \"http://arxiv.org/abs/2504.19970v1\", \"title\": \"Shopformer: Transformer-Based Framework for Detecting Shoplifting via\\n  Human Pose\", \"summary\": \"Shoplifting remains a costly issue for the retail sector, but traditional\\nsurveillance systems, which are mostly based on human monitoring, are still\\nlargely ineffective, with only about 2% of shoplifters being arrested. Existing\\nAI-based approaches rely on pixel-level video analysis which raises privacy\\nconcerns, is sensitive to environmental variations, and demands significant\\ncomputational resources. To address these limitations, we introduce Shopformer,\\na novel transformer-based model that detects shoplifting by analyzing pose\\nsequences rather than raw video. We propose a custom tokenization strategy that\\nconverts pose sequences into compact embeddings for efficient transformer\\nprocessing. To the best of our knowledge, this is the first pose-sequence-based\\ntransformer model for shoplifting detection. Evaluated on real-world pose data,\\nour method outperforms state-of-the-art anomaly detection models, offering a\\nprivacy-preserving, and scalable solution for real-time retail surveillance.\\nThe code base for this work is available at\\nhttps://github.com/TeCSAR-UNCC/Shopformer.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-28T16:43:01Z\"}"}
