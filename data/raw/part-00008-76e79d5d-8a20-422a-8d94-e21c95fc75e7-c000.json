{"value":"{\"aid\": \"http://arxiv.org/abs/2504.16640v1\", \"title\": \"SSLR: A Semi-Supervised Learning Method for Isolated Sign Language\\n  Recognition\", \"summary\": \"Sign language is the primary communication language for people with disabling\\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\\ngestures and translate them into spoken language. One of the main challenges in\\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\\npseudo-label method to annotate unlabeled samples. The sign gestures are\\nrepresented using pose information that encodes the signer's skeletal joint\\npoints. This information is used as input for the Transformer backbone model\\nutilized in the proposed approach. To demonstrate the learning capabilities of\\nSSL across various labeled data sizes, several experiments were conducted using\\ndifferent percentages of labeled data with varying numbers of classes. The\\nperformance of the SSL approach was compared with a fully supervised\\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\\nmodel outperformed the supervised learning-based model with less labeled data\\nin many cases.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-23T11:59:52Z\"}"}
