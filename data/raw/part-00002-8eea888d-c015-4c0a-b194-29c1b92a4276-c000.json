{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04740v1\", \"title\": \"Enhancing Compositional Reasoning in Vision-Language Models with\\n  Synthetic Preference Data\", \"summary\": \"Compositionality, or correctly recognizing scenes as compositions of atomic\\nvisual concepts, remains difficult for multimodal large language models\\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\\ndistinguishing compositions like \\\"dog chasing cat\\\" vs \\\"cat chasing dog\\\". While\\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\\nsignificant progress, they are still far from a human's performance. We show\\nthat compositional reasoning in these models can be improved by elucidating\\nsuch concepts via data, where a model is trained to prefer the correct caption\\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\\nan approach for preference tuning open-weight MLLMs on synthetic preference\\ndata generated in a fully automated manner from existing image-caption data.\\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\\ncapabilities which we can see through significant improvements across multiple\\nvision language compositionality benchmarks, as well as smaller but significant\\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\\nto date), while improving by ~1% on more general visual question answering\\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\\ndataset is available at https://github.com/samarth4149/SCRAMBLe.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T05:35:34Z\"}"}
