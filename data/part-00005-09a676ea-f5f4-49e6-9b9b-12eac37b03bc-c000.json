{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06606v1\", \"title\": \"Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program\", \"summary\": \"Recent advancements in reward signal usage for Large Language Models (LLMs)\\nare remarkable. However, significant challenges exist when transitioning reward\\nsignal to the multimodal domain, including labor-intensive annotations,\\nover-reliance on one-step rewards, and inadequate evaluation. To address these\\nissues, we propose SVIP, a novel approach to train a step-level\\nmulti-dimensional Chain-of-Thought~(CoT) reward model automatically. It\\ngenerates code for solving visual tasks and transforms the analysis of code\\nblocks into the evaluation of CoT step as training samples. Then, we train\\nSVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The\\nadvantages of SVIP-Reward are evident throughout the entire process of MLLM. We\\nalso introduce a benchmark for CoT reward model training and testing.\\nExperimental results demonstrate that SVIP-Reward improves MLLM performance\\nacross training and inference-time scaling, yielding better results on\\nbenchmarks while reducing hallucinations and enhancing reasoning ability.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T06:09:40Z\"}"}
