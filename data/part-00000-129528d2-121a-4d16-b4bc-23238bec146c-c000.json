{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24157v1\", \"title\": \"LLM4FS: Leveraging Large Language Models for Feature Selection and How\\n  to Improve It\", \"summary\": \"Recent advances in large language models (LLMs) have provided new\\nopportunities for decision-making, particularly in the task of automated\\nfeature selection. In this paper, we first comprehensively evaluate LLM-based\\nfeature selection methods, covering the state-of-the-art DeepSeek-R1,\\nGPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called\\nLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,\\ninput data samples into LLMs, and directly call traditional data-driven\\ntechniques such as random forest and forward sequential selection. Notably, our\\nanalysis reveals that the hybrid strategy leverages the contextual\\nunderstanding of LLMs and the high statistical reliability of traditional\\ndata-driven methods to achieve excellent feature selection performance, even\\nsurpassing LLMs and traditional data-driven methods. Finally, we point out the\\nlimitations of its application in decision-making.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-03-31T14:40:31Z\"}"}
