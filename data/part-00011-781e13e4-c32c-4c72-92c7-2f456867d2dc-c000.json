{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05245v1\", \"title\": \"Embedded Federated Feature Selection with Dynamic Sparse Training:\\n  Balancing Accuracy-Cost Tradeoffs\", \"summary\": \"Federated Learning (FL) enables multiple resource-constrained edge devices\\nwith varying levels of heterogeneity to collaboratively train a global model.\\nHowever, devices with limited capacity can create bottlenecks and slow down\\nmodel convergence. One effective approach to addressing this issue is to use an\\nefficient feature selection method, which reduces overall resource demands by\\nminimizing communication and computation costs, thereby mitigating the impact\\nof struggling nodes. Existing federated feature selection (FFS) methods are\\neither considered as a separate step from FL or rely on a third party. These\\napproaches increase computation and communication overhead, making them\\nimpractical for real-world high-dimensional datasets. To address this, we\\npresent \\\\textit{Dynamic Sparse Federated Feature Selection} (DSFFS), the first\\ninnovative embedded FFS that is efficient in both communication and\\ncomputation. In the proposed method, feature selection occurs simultaneously\\nwith model training. During training, input-layer neurons, their connections,\\nand hidden-layer connections are dynamically pruned and regrown, eliminating\\nuninformative features. This process enhances computational efficiency on\\ndevices, improves network communication efficiency, and boosts global model\\nperformance. Several experiments are conducted on nine real-world datasets of\\nvarying dimensionality from diverse domains, including biology, image, speech,\\nand text. The results under a realistic non-iid data distribution setting show\\nthat our approach achieves a better trade-off between accuracy, computation,\\nand communication costs by selecting more informative features compared to\\nother state-of-the-art FFS methods.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-07T16:33:05Z\"}"}
