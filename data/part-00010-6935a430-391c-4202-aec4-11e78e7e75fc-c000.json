{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06636v1\", \"title\": \"BBQRec: Behavior-Bind Quantization for Multi-Modal Sequential\\n  Recommendation\", \"summary\": \"Multi-modal sequential recommendation systems leverage auxiliary signals\\n(e.g., text, images) to alleviate data sparsity in user-item interactions.\\nWhile recent methods exploit large language models to encode modalities into\\ndiscrete semantic IDs for autoregressive prediction, we identify two critical\\nlimitations: (1) Existing approaches adopt fragmented quantization, where\\nmodalities are independently mapped to semantic spaces misaligned with\\nbehavioral objectives, and (2) Over-reliance on semantic IDs disrupts\\ninter-modal semantic coherence, thereby weakening the expressive power of\\nmulti-modal representations for modeling diverse user preferences.\\n  To address these challenges, we propose a Behavior-Bind multi-modal\\nQuantization for Sequential Recommendation (BBQRec for short) featuring\\ndual-aligned quantization and semantics-aware sequence modeling. First, our\\nbehavior-semantic alignment module disentangles modality-agnostic behavioral\\npatterns from noisy modality-specific features through contrastive codebook\\nlearning, ensuring semantic IDs are inherently tied to recommendation tasks.\\nSecond, we design a discretized similarity reweighting mechanism that\\ndynamically adjusts self-attention scores using quantized semantic\\nrelationships, preserving multi-modal synergies while avoiding invasive\\nmodifications to the sequence modeling architecture. Extensive evaluations\\nacross four real-world benchmarks demonstrate BBQRec's superiority over the\\nstate-of-the-art baselines.\", \"main_category\": \"cs.IR\", \"categories\": \"cs.IR\", \"published\": \"2025-04-09T07:19:48Z\"}"}
