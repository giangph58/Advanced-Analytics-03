{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04749v1\", \"title\": \"Vision Transformers with Autoencoders and Explainable AI for Cancer\\n  Patient Risk Stratification Using Whole Slide Imaging\", \"summary\": \"Cancer remains one of the leading causes of mortality worldwide,\\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\\nbecome an integral part of clinical workflows with advancements in digital\\npathology. While various studies have utilized WSIs, their extracted features\\nmay not fully capture the most relevant pathological information, and their\\nlack of interpretability limits clinical adoption.\\n  In this paper, we propose PATH-X, a framework that integrates Vision\\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\\nto enhance model explainability for patient stratification and risk prediction\\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\\nselected from each WSI, and numerical feature embeddings are extracted using\\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\\nsurvival analysis is applied to evaluate stratification into two and three risk\\ngroups. SHAP is used to identify key contributing features, which are mapped\\nonto histopathological slices to provide spatial context.\\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\\nsufficient number of WSIs enabled robust stratification. However, performance\\nin lung cancer was limited due to data availability, emphasizing the need for\\nlarger datasets to enhance model reliability and clinical applicability.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV,cs.LG\", \"published\": \"2025-04-07T05:48:42Z\"}"}
