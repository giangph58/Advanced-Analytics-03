{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04765v1\", \"title\": \"Multi-Agent Deep Reinforcement Learning for Multiple Anesthetics\\n  Collaborative Control\", \"summary\": \"Automated control of personalized multiple anesthetics in clinical Total\\nIntravenous Anesthesia (TIVA) is crucial yet challenging. Current systems,\\nincluding target-controlled infusion (TCI) and closed-loop systems, either rely\\non relatively static pharmacokinetic/pharmacodynamic (PK/PD) models or focus on\\nsingle anesthetic control, limiting personalization and collaborative control.\\nTo address these issues, we propose a novel framework, Value Decomposition\\nMulti-Agent Deep Reinforcement Learning (VD-MADRL). VD-MADRL optimizes the\\ncollaboration between two anesthetics propofol (Agent I) and remifentanil\\n(Agent II). And It uses a Markov Game (MG) to identify optimal actions among\\nheterogeneous agents. We employ various value function decomposition methods to\\nresolve the credit allocation problem and enhance collaborative control. We\\nalso introduce a multivariate environment model based on random forest (RF) for\\nanesthesia state simulation. Additionally, a data resampling and alignment\\ntechnique ensures synchronized trajectory data. Our experiments on general and\\nthoracic surgery datasets show that VD-MADRL performs better than human\\nexperience. It improves dose precision and keeps anesthesia states stable,\\nproviding great clinical value.\", \"main_category\": \"eess.SY\", \"categories\": \"eess.SY,cs.SY\", \"published\": \"2025-04-07T06:36:24Z\"}"}
