{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07091v1\", \"title\": \"AssistanceZero: Scalably Solving Assistance Games\", \"summary\": \"Assistance games are a promising alternative to reinforcement learning from\\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\\nmodeling the interaction between assistant and user as a two-player game where\\nthe assistant cannot observe their shared goal. Despite their potential,\\nassistance games have only been explored in simple settings. Scaling them to\\nmore complex environments is difficult because it requires both solving\\nintractable decision-making problems under uncertainty and accurately modeling\\nhuman users' behavior. We present the first scalable approach to solving\\nassistance games and apply it to a new, challenging Minecraft-based assistance\\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\\nAlphaZero with a neural network that predicts human actions and rewards,\\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\\nmodel-free RL algorithms and imitation learning in the Minecraft-based\\nassistance game. In a human study, our AssistanceZero-trained assistant\\nsignificantly reduces the number of actions participants take to complete\\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\\ntractable framework for training effective AI assistants in complex\\nenvironments. Our code and models are available at\\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.LG\", \"published\": \"2025-04-09T17:59:03Z\"}"}
