{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06721v1\", \"title\": \"Learning global control of underactuated systems with Model-Based\\n  Reinforcement Learning\", \"summary\": \"This short paper describes our proposed solution for the third edition of the\\n\\\"AI Olympics with RealAIGym\\\" competition, held at ICRA 2025. We employed\\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\\nalgorithm recognized for its exceptional data efficiency across various\\nlow-dimensional robotic tasks, including cart-pole, ball \\\\& plate, and Furuta\\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\\ndata, enabling policy refinement through simulation rather than direct system\\ndata optimization. This approach has proven highly effective in physical\\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\\nNotably, MC-PILCO has previously won the first two editions of this\\ncompetition, demonstrating its robustness in both simulated and real-world\\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\\na global policy for the pendubot and acrobot systems.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.AI,cs.LG\", \"published\": \"2025-04-09T09:20:37Z\"}"}
