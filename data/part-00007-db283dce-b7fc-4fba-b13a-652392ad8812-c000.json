{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04801v1\", \"title\": \"OrderChain: A General Prompting Paradigm to Improve Ordinal\\n  Understanding Ability of MLLM\", \"summary\": \"Despite the remarkable progress of multimodal large language models (MLLMs),\\nthey continue to face challenges in achieving competitive performance on\\nordinal regression (OR; a.k.a. ordinal classification). To address this issue,\\nthis paper presents OrderChain, a novel and general prompting paradigm that\\nimproves the ordinal understanding ability of MLLMs by specificity and\\ncommonality modeling. Specifically, our OrderChain consists of a set of\\ntask-aware prompts to facilitate the specificity modeling of diverse OR tasks\\nand a new range optimization Chain-of-Thought (RO-CoT), which learns a\\ncommonality way of thinking about OR tasks by uniformly decomposing them into\\nmultiple small-range optimization subtasks. Further, we propose a category\\nrecursive division (CRD) method to generate instruction candidate category\\nprompts to support RO-CoT automatic optimization. Comprehensive experiments\\nshow that a Large Language and Vision Assistant (LLaVA) model with our\\nOrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g.,\\nfrom 47.5% to 93.2% accuracy on the Adience dataset for age estimation, and\\nfrom 30.0% to 85.7% accuracy on the Diabetic Retinopathy dataset. Notably,\\nLLaVA with our OrderChain also remarkably outperforms state-of-the-art methods\\nby 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best\\nknowledge, our OrderChain is the first work that augments MLLMs for OR tasks,\\nand the effectiveness is witnessed across a spectrum of OR datasets.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T07:53:44Z\"}"}
