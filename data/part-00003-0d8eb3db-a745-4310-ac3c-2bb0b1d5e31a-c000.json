{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24053v1\", \"title\": \"ReaLM: Reliable and Efficient Large Language Model Inference with\\n  Statistical Algorithm-Based Fault Tolerance\", \"summary\": \"The demand for efficient large language model (LLM) inference has propelled\\nthe development of dedicated accelerators. As accelerators are vulnerable to\\nhardware faults due to aging, variation, etc, existing accelerator designs\\noften reserve a large voltage margin or leverage algorithm-based fault\\ntolerance (ABFT) techniques to ensure LLM inference correctness. However,\\nprevious methods often overlook the inherent fault tolerance of LLMs, leading\\nto high computation and energy overhead. To enable reliable yet efficient LLM\\ninference, in this paper, we propose a novel algorithm/circuit co-design\\nframework, dubbed ReaLM. For the first time, we systematically characterize the\\nfault tolerance of LLMs by performing a large-scale error injection study of\\nrepresentative LLMs and natural language understanding tasks. Then, we propose\\na statistical ABFT algorithm that fully leverages the error robustness to\\nminimize error recovery as much as possible. We also customize the error\\ndetection circuits to enable a low-cost online collection of error statistics.\\nExtensive experiments show that with only 1.42% circuit area and 1.79% power\\noverhead, our ReaLM can reduce perplexity degradation from 18.54 to 0.29.\\nCompared to existing methods, ReaLM consistently reduces recovery costs across\\ndifferent operating voltages and improves energy efficiency by up to 35.83%\\nwithout compromising LLM performance. Our error injection code is available at\\nhttps://github.com/2000012835xt/ReaLM-DAC.\", \"main_category\": \"cs.AR\", \"categories\": \"cs.AR\", \"published\": \"2025-03-31T13:15:03Z\"}"}
