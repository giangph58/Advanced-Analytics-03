{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07793v1\", \"title\": \"Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling\\n  Representations\", \"summary\": \"Out-of-distribution (OOD) detection is critical for ensuring the reliability\\nof deep learning systems, particularly in safety-critical applications.\\nLikelihood-based deep generative models have historically faced criticism for\\ntheir unsatisfactory performance in OOD detection, often assigning higher\\nlikelihood to OOD data than in-distribution samples when applied to image data.\\nIn this work, we demonstrate that likelihood is not inherently flawed. Rather,\\nseveral properties in the images space prohibit likelihood as a valid detection\\nscore. Given a sufficiently good likelihood estimator, specifically using the\\nprobability flow formulation of a diffusion model, we show that\\nlikelihood-based methods can still perform on par with state-of-the-art methods\\nwhen applied in the representation space of pre-trained encoders. The code of\\nour work can be found at\\n$\\\\href{https://github.com/limchaos/Likelihood-OOD.git}{\\\\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-10T14:30:41Z\"}"}
