{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04780v1\", \"title\": \"Bottom-Up Scattering Information Perception Network for SAR target\\n  recognition\", \"summary\": \"Deep learning methods based synthetic aperture radar (SAR) image target\\nrecognition tasks have been widely studied currently. The existing deep methods\\nare insufficient to perceive and mine the scattering information of SAR images,\\nresulting in performance bottlenecks and poor robustness of the algorithms. To\\nthis end, this paper proposes a novel bottom-up scattering information\\nperception network for more interpretable target recognition by constructing\\nthe proprietary interpretation network for SAR images. Firstly, the localized\\nscattering perceptron is proposed to replace the backbone feature extractor\\nbased on CNN networks to deeply mine the underlying scattering information of\\nthe target. Then, an unsupervised scattering part feature extraction model is\\nproposed to robustly characterize the target scattering part information and\\nprovide fine-grained target representation. Finally, by aggregating the\\nknowledge of target parts to form the complete target description, the\\ninterpretability and discriminative ability of the model is improved. We\\nperform experiments on the FAST-Vehicle dataset and the SAR-ACD dataset to\\nvalidate the performance of the proposed method.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T07:15:08Z\"}"}
