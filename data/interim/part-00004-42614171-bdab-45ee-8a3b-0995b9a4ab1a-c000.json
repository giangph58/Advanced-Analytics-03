{"aid":"http://arxiv.org/abs/2503.21658v1","title":"Numerical Analysis of the Stability of Iron Dust Bunsen Flames","summary":"This article presents numerical simulations of the response of an iron dust\nBunsen flame to particle seeding changes. A validated numerical model is used\nto study the impact of particle seeding fluctuations on flame stability.\nSimulations are conducted for the Bunsen setup in the right-side up and up-side\ndown configuration. No significant differences in flame response are identified\nin flame stability between the right-side up and up-side down configurations.\nWe find that the Bunsen flame is surprisingly robust to abrupt changes in\nparticle loading. The sudden change in particle loading does not excite any\nintrinsic instabilities in the flame. Based on our results, the iron dust\nflames are robust to imposed fluctuations. We hypothesize that this is due to\nthe lack of a feedback mechanism between the burned temperature and the heat\nrelease rate. This mechanism is present in conventional, chemistry-driven,\ngaseous flames. However, such a mechanism is absent in iron dust flames because\nthe combustion of individual iron particles is limited by oxygen diffusion,\nwhich is insensitive to temperature.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-27T16:22:50Z"}
{"aid":"http://arxiv.org/abs/2503.21669v1","title":"Proton-Driven Plasma Wakefield Acceleration for Future HEP Colliders","summary":"We discuss the main elements of a collider facility based on proton-driven\nplasma wakefield acceleration. We show that very competitive luminosities could\nbe reached for high energy $e^+e^-$ colliders. A first set of parameters was\ndeveloped for a Higgs Factory indicating that such a scheme is indeed\npotentially feasible. There are clearly many challenges to the development of\nthis scheme, including novel RF acceleration modules and high precision and\nstrong magnets for the proton driver. Challenges in the plasma acceleration\nstage include the ability to accelerate positrons while maintaining necessary\nemittance and the energy transfer efficiency from the driver to the witness.\nSince many exciting applications would become available from our approach, its\ndevelopment should be pursued.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.plasm-ph","published":"2025-03-27T16:36:33Z"}
{"aid":"http://arxiv.org/abs/2503.21671v1","title":"A Bespoke Design Approach to Low-Power Printed Microprocessors for\n  Machine Learning Applications","summary":"Printed electronics have gained significant traction in recent years,\npresenting a viable path to integrating computing into everyday items, from\ndisposable products to low-cost healthcare. However, the adoption of computing\nin these domains is hindered by strict area and power constraints, limiting the\neffectiveness of general-purpose microprocessors. This paper proposes a bespoke\nmicroprocessor design approach to address these challenges, by tailoring the\ndesign to specific applications and eliminating unnecessary logic. Targeting\nmachine learning applications, we further optimize core operations by\nintegrating a SIMD MAC unit supporting 4 precision configurations that boost\nthe efficiency of microprocessors. Our evaluation across 6 ML models and the\nlarge-scale Zero-Riscy core, shows that our methodology can achieve\nimprovements of 22.2%, 23.6%, and 33.79% in area, power, and speed,\nrespectively, without compromising accuracy. Against state-of-the-art printed\nprocessors, our approach can still offer significant speedups, but along with\nsome accuracy degradation. This work explores how such trade-offs can enable\nlow-power printed microprocessors for diverse ML applications.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-27T16:37:18Z"}
{"aid":"http://arxiv.org/abs/2503.21678v1","title":"Orderings on measures induced by higher-order monotone functions","summary":"The main aim of this paper is to study the functional inequality\n\\begin{equation*} \\int_{[0,1]}f\\bigl((1-t)x+ty\\bigr)d\\mu(t)\\geq 0, \\qquad\nx,y\\in I \\mbox{ with } x<y, \\end{equation*} for a continuous unknown function\n$f:I\\to{\\mathbb R}$, where $I$ is a nonempty open real interval and $\\mu$ is a\nsigned and bounded Borel measure on $[0,1]$. We derive necessary as well as\nsufficient conditions for its validity in terms of higher-order monotonicity\nproperties of $f$.\n  Using the results so obtained we can derive sufficient conditions under which\nthe inequality $${\\mathbb E} f(X)\\leq {\\mathbb E} f(Y)$$ is satisfied by all\nfunctions which are simultaneously: $k_1$-increasing (or decreasing),\n$k_2$-increasing (or decreasing), \\dots , $k_l$-increasing (or decreasing) for\ngiven nonnegative integers $k_1,\\dots,k_l.$ This extends several well-known\nresults on stochastic ordering.\n  A necessary condition for the $(n,n+1,\\dots,m)$-increasing ordering is also\npresented.","main_category":"math.CA","categories":"math.CA","published":"2025-03-27T16:48:37Z"}
{"aid":"http://arxiv.org/abs/2503.21718v1","title":"Outlier dimensions favor frequent tokens in language model","summary":"We study last-layer outlier dimensions, i.e.dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.7","published":"2025-03-27T17:30:50Z"}
{"aid":"http://arxiv.org/abs/2503.21720v1","title":"Collab: Controlled Decoding using Mixture of Agents for LLM Alignment","summary":"Alignment of Large Language models (LLMs) is crucial for safe and trustworthy\ndeployment in applications. Reinforcement learning from human feedback (RLHF)\nhas emerged as an effective technique to align LLMs to human preferences and\nbroader utilities, but it requires updating billions of model parameters, which\nis computationally expensive. Controlled Decoding, by contrast, provides a\nmechanism for aligning a model at inference time without retraining. However,\nsingle-agent decoding approaches often struggle to adapt to diverse tasks due\nto the complexity and variability inherent in these tasks. To strengthen the\ntest-time performance w.r.t the target task, we propose a mixture of\nagent-based decoding strategies leveraging the existing off-the-shelf aligned\nLLM policies. Treating each prior policy as an agent in the spirit of mixture\nof agent collaboration, we develop a decoding method that allows for\ninference-time alignment through a token-level selection strategy among\nmultiple agents. For each token, the most suitable LLM is dynamically chosen\nfrom a pool of models based on a long-term utility metric. This\npolicy-switching mechanism ensures optimal model selection at each step,\nenabling efficient collaboration and alignment among LLMs during decoding.\nTheoretical analysis of our proposed algorithm establishes optimal performance\nwith respect to the target task represented via a target reward for the given\noff-the-shelf models. We conduct comprehensive empirical evaluations with\nopen-source aligned models on diverse tasks and preferences, which demonstrates\nthe merits of this approach over single-agent decoding baselines. Notably,\nCollab surpasses the current SoTA decoding strategy, achieving an improvement\nof up to 1.56x in average reward and 71.89% in GPT-4 based win-tie rate.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:34:25Z"}
{"aid":"http://arxiv.org/abs/2503.21737v1","title":"High-intensity Voronoi percolation on manifolds","summary":"We study Voronoi percolation on a large class of $d$-dimensional Riemannian\nmanifolds, which includes hyperbolic space $\\mathbb{H}^d$ for $d\\geq 2$. We\nprove that as the intensity $\\lambda$ of the underlying Poisson point process\ntends to infinity, both critical parameters $p_c(M,\\lambda)$ and\n$p_u(M,\\lambda)$ converge to the Euclidean critical parameter\n$p_c(\\mathbb{R}^d)$. This extends a recent result of Hansen & M\\\"uller in the\nspecial case $M=\\mathbb{H}^2$ to a general class of manifolds of arbitrary\ndimension. A crucial step in our proof, which may be of independent interest,\nis to show that if $M$ is simply connected and one-ended, then embedded graphs\ninduced by a general class of tessellations on $M$ have connected minimal\ncutsets. In particular, this result applies to $\\varepsilon$-nets, allowing us\nto implement a \"fine-graining\" argument. We also develop an annealed way of\nexploring the Voronoi cells that we use to characterize the uniqueness phase.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:49:50Z"}
{"aid":"http://arxiv.org/abs/2503.21738v1","title":"Galaxy Morphologies at Cosmic Noon with JWST : A Foundation for\n  Exploring Gas Transport with Bars and Spiral Arms","summary":"How radial flows shape galaxy structure and evolution remains an open\nquestion. Internal drivers of such flows, such as bars and spiral arms, known\nto mediate gas flows in the local Universe, are now observable at high redshift\nthanks to JWST's unobscured view. We investigate the morphology of massive\nstar-forming galaxies at 0.8 < z < 1.3 and 2.0 < z < 2.5, epochs marking the\npeak and decline of cosmic star formation, both well-covered by kinematic\nsurveys. Using JWST/NIRCam imaging, we visually classify 1,451 galaxies,\nidentify non-axisymmetric features, count the number of spiral arms, analyze\nnon-parametric morphological indicators and study the dynamical support of the\nsample covered by kinematics (10% of the sample) as measured via v/{\\sigma}.\nDisk galaxies dominate the sample (82%), with 48% exhibiting spiral structure\nand 11% hosting bars. Both fractions decline with redshift, consistent with\nprevious studies. The proportion of two- and three-armed spirals remains\nlargely unchanged across redshift, with roughly two-thirds showing two arms and\none-third showing three arms in both bins. Notably, we find a higher incidence\nof three-armed spirals than reported in the local Universe, suggesting a mild\nevolution in spiral arm multiplicity. Non-parametric morphological metrics\nstrongly correlate with stellar mass but show no significant redshift\nevolution. Finally, kinematic analysis reveals a strong correlation between\ndisk morphology and rotational support, with most disks exhibiting v/{\\sigma} >\n3 and median values of v/{\\sigma} > 7 for spirals and v/{\\sigma} > 5 for barred\ngalaxies. This study establishes a population-wide framework for linking galaxy\nmorphology and dynamics at cosmic noon, providing a key reference for future\nstudies on the role of detailed structural features in galaxy evolution.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:50:32Z"}
{"aid":"http://arxiv.org/abs/2503.21743v1","title":"Three-Dimensional Stacking as a Line Intensity Mapping Statistic","summary":"Line-intensity mapping (LIM) is a growing technique that measures the\nintegrated spectral-line emission from unresolved galaxies over a\nthree-dimensional region of the Universe. Although LIM experiments ultimately\naim to provide powerful cosmological constraints via auto-correlation, many LIM\nexperiments are also designed to take advantage of overlapping galaxy surveys,\nenabling joint analyses of the two datasets. We introduce a flexible simulation\npipeline that can generate mock galaxy surveys and mock LIM data simultaneously\nfor the same population of simulated galaxies. Using this pipeline, we explore\na simple joint analysis technique: three-dimensional co-addition (stacking) of\nLIM data on the positions of galaxies from a traditional galaxy catalogue. We\ntest how the output of this technique reacts to changes in experimental design\nof both the LIM experiment and the galaxy survey, its sensitivity to various\nastrophysical parameters, and its susceptibility to common systematic errors.\nWe find that an ideal catalogue for a stacking analysis targets as many\nhigh-mass dark matter halos as possible. We also find that the signal in a LIM\nstacking analysis originates almost entirely from the large-scale clustering of\nhalos around the catalogue objects, rather than the catalogue objects\nthemselves. While stacking is a sensitive and conceptually simple way to\nachieve a LIM detection, thus providing a valuable way to validate a LIM\nauto-correlation detection, it will likely require a full cross-correlation to\nachieve further characterization of the galaxy tracers involved, as the\ncosmological and astrophysical parameters we explore here have degenerate\neffects on the stack.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-03-27T17:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21745v1","title":"3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models","summary":"3D generation is experiencing rapid advancements, while the development of 3D\nevaluation has not kept pace. How to keep automatic evaluation equitably\naligned with human perception has become a well-recognized challenge. Recent\nadvances in the field of language and image generation have explored human\npreferences and showcased respectable fitting ability. However, the 3D domain\nstill lacks such a comprehensive preference dataset over generative models. To\nmitigate this absence, we develop 3DGen-Arena, an integrated platform in a\nbattle manner. Then, we carefully design diverse text and image prompts and\nleverage the arena platform to gather human preferences from both public users\nand expert annotators, resulting in a large-scale multi-dimension human\npreference dataset 3DGen-Bench. Using this dataset, we further train a\nCLIP-based scoring model, 3DGen-Score, and a MLLM-based automatic evaluator,\n3DGen-Eval. These two models innovatively unify the quality evaluation of\ntext-to-3D and image-to-3D generation, and jointly form our automated\nevaluation system with their respective strengths. Extensive experiments\ndemonstrate the efficacy of our scoring model in predicting human preferences,\nexhibiting a superior correlation with human ranks compared to existing\nmetrics. We believe that our 3DGen-Bench dataset and automated evaluation\nsystem will foster a more equitable evaluation in the field of 3D generation,\nfurther promoting the development of 3D generative models and their downstream\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.21760v1","title":"MemInsight: Autonomous Memory Augmentation for LLM Agents","summary":"Large language model (LLM) agents have evolved to intelligently process\ninformation, make decisions, and interact with users or tools. A key capability\nis the integration of long-term memory capabilities, enabling these agents to\ndraw upon historical interactions and knowledge. However, the growing memory\nsize and need for semantic structuring pose significant challenges. In this\nwork, we propose an autonomous memory augmentation approach, MemInsight, to\nenhance semantic data representation and retrieval mechanisms. By leveraging\nautonomous augmentation to historical interactions, LLM agents are shown to\ndeliver more accurate and contextualized responses. We empirically validate the\nefficacy of our proposed approach in three task scenarios; conversational\nrecommendation, question answering and event summarization. On the LLM-REDIAL\ndataset, MemInsight boosts persuasiveness of recommendations by up to 14%.\nMoreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval.\nOur empirical results show the potential of MemInsight to enhance the\ncontextual performance of LLM agents across multiple tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-27T17:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.23685v1","title":"An In-Situ Spatial-Temporal Sequence Detector for Neuromorphic Vision\n  Sensor Empowered by High Density Vertical NAND Storage","summary":"Neuromorphic vision sensors require efficient real-time pattern recognition,\nyet conventional architectures struggle with energy and latency constraints.\nHere, we present a novel in-situ spatiotemporal sequence detector that\nleverages vertical NAND storage to achieve massively parallel pattern\ndetection. By encoding each cell with two single-transistor-based multi-level\ncell (MLC) memory elements, such as ferroelectric field-effect transistors\n(FeFETs), and mapping a pixel's temporal sequence onto consecutive word lines\n(WLs), we enable direct temporal pattern detection within NAND strings. Each\nNAND string serves as a dedicated reference for a single pixel, while different\nblocks store patterns for distinct pixels, allowing large-scale\nspatial-temporal pattern recognition via simple direct bit-line (BL) sensing, a\nwell-established operation in vertical NAND storage. We experimentally validate\nour approach at both the cell and array levels, demonstrating that vertical\nNAND-based detector achieves more than six orders of magnitude improvement in\nenergy efficiency and more than three orders of magnitude reduction in latency\ncompared to conventional CPU-based methods. These findings establish vertical\nNAND storage as a scalable and energy-efficient solution for next-generation\nneuromorphic vision processing.","main_category":"cs.ET","categories":"cs.ET","published":"2025-03-31T03:34:29Z"}
{"aid":"http://arxiv.org/abs/2503.23687v1","title":"MKA: Leveraging Cross-Lingual Consensus for Model Abstention","summary":"Reliability of LLMs is questionable even as they get better at more tasks. A\nwider adoption of LLMs is contingent on whether they are usably factual. And if\nthey are not, on whether they can properly calibrate their confidence in their\nresponses. This work focuses on utilizing the multilingual knowledge of an LLM\nto inform its decision to abstain or answer when prompted. We develop a\nmultilingual pipeline to calibrate the model's confidence and let it abstain\nwhen uncertain. We run several multilingual models through the pipeline to\nprofile them across different languages. We find that the performance of the\npipeline varies by model and language, but that in general they benefit from\nit. This is evidenced by the accuracy improvement of $71.2\\%$ for Bengali over\na baseline performance without the pipeline. Even a high-resource language like\nEnglish sees a $15.5\\%$ improvement. These results hint at possible further\nimprovements.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-31T03:38:12Z"}
{"aid":"http://arxiv.org/abs/2503.23705v1","title":"Steering Large Agent Populations using Mean-Field Schrodinger Bridges\n  with Gaussian Mixture Models","summary":"The Mean-Field Schrodinger Bridge (MFSB) problem is an optimization problem\naiming to find the minimum effort control policy to drive a McKean-Vlassov\nstochastic differential equation from one probability measure to another. In\nthe context of multiagent control, the objective is to control the\nconfiguration of a swarm of identical, interacting cooperative agents, as\ncaptured by the time-varying probability measure of their state. Available\nmethods for solving this problem for distributions with continuous support rely\neither on spatial discretizations of the problem's domain or on approximating\noptimal solutions using neural networks trained through stochastic optimization\nschemes. For agents following Linear Time-Varying dynamics, and for Gaussian\nMixture Model boundary distributions, we propose a highly efficient\nparameterization to approximate the solutions of the corresponding MFSB in\nclosed form, without any learning steps. Our proposed approach consists of a\nmixture of elementary policies, each solving a Gaussian-to-Gaussian Covariance\nSteering problem from the components of the initial to the components of the\nterminal mixture. Leveraging the semidefinite formulation of the Covariance\nSteering problem, our proposed solver can handle probabilistic hard constraints\non the system's state, while maintaining numerical tractability. We illustrate\nour approach on a variety of numerical examples.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-03-31T04:01:04Z"}
{"aid":"http://arxiv.org/abs/2503.23707v1","title":"From Geometry to Culture: An Iterative VLM Layout Framework for Placing\n  Objects in Complex 3D Scene Contexts","summary":"3D layout tasks have traditionally concentrated on geometric constraints, but\nmany practical applications demand richer contextual understanding that spans\nsocial interactions, cultural traditions, and usage conventions. Existing\nmethods often rely on rule-based heuristics or narrowly trained learning\nmodels, making them difficult to generalize and frequently prone to orientation\nerrors that break realism. To address these challenges, we define four\nescalating context levels, ranging from straightforward physical placement to\ncomplex cultural requirements such as religious customs and advanced social\nnorms. We then propose a Vision-Language Model-based pipeline that inserts\nminimal visual cues for orientation guidance and employs iterative feedback to\npinpoint, diagnose, and correct unnatural placements in an automated fashion.\nEach adjustment is revisited through the system's verification process until it\nachieves a coherent result, thereby eliminating the need for extensive user\noversight or manual parameter tuning. Our experiments across these four context\nlevels reveal marked improvements in rotation accuracy, distance control, and\noverall layout plausibility compared with native VLM. By reducing the\ndependence on pre-programmed constraints or prohibitively large training sets,\nour method enables fully automated scene composition for both everyday\nscenarios and specialized cultural tasks, moving toward a universally adaptable\nframework for 3D arrangement.","main_category":"cs.GR","categories":"cs.GR","published":"2025-03-31T04:09:00Z"}
{"aid":"http://arxiv.org/abs/2503.23725v1","title":"Exploring Temporal Dynamics in Event-based Eye Tracker","summary":"Eye-tracking is a vital technology for human-computer interaction, especially\nin wearable devices such as AR, VR, and XR. The realization of high-speed and\nhigh-precision eye-tracking using frame-based image sensors is constrained by\ntheir limited temporal resolution, which impairs the accurate capture of rapid\nocular dynamics, such as saccades and blinks. Event cameras, inspired by\nbiological vision systems, are capable of perceiving eye movements with\nextremely low power consumption and ultra-high temporal resolution. This makes\nthem a promising solution for achieving high-speed, high-precision tracking\nwith rich temporal dynamics. In this paper, we propose TDTracker, an effective\neye-tracking framework that captures rapid eye movements by thoroughly modeling\ntemporal dynamics from both implicit and explicit perspectives. TDTracker\nutilizes 3D convolutional neural networks to capture implicit short-term\ntemporal dynamics and employs a cascaded structure consisting of a\nFrequency-aware Module, GRU, and Mamba to extract explicit long-term temporal\ndynamics. Ultimately, a prediction heatmap is used for eye coordinate\nregression. Experimental results demonstrate that TDTracker achieves\nstate-of-the-art (SOTA) performance on the synthetic SEET dataset and secured\nThird place in the CVPR event-based eye-tracking challenge 2025. Our code is\navailable at https://github.com/rhwxmx/TDTracker.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.23730v1","title":"KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large\n  Vision-Language Models in the Korean Language","summary":"The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-03-31T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2503.23731v1","title":"Investigation of intelligent barbell squat coaching system based on\n  computer vision and machine learning","summary":"Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV","published":"2025-03-31T05:08:52Z"}
{"aid":"http://arxiv.org/abs/2503.23740v1","title":"LANID: LLM-assisted New Intent Discovery","summary":"Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T05:34:32Z"}
{"aid":"http://arxiv.org/abs/2503.23742v1","title":"On the Steady-State Distributionally Robust Kalman Filter","summary":"State estimation in the presence of uncertain or data-driven noise\ndistributions remains a critical challenge in control and robotics. Although\nthe Kalman filter is the most popular choice, its performance degrades\nsignificantly when distributional mismatches occur, potentially leading to\ninstability or divergence. To address this limitation, we introduce a novel\nsteady-state distributionally robust (DR) Kalman filter that leverages\nWasserstein ambiguity sets to explicitly account for uncertainties in both\nprocess and measurement noise distributions. Our filter achieves computational\nefficiency by requiring merely the offline solution of a single convex\nsemidefinite program, which yields a constant DR Kalman gain for robust state\nestimation under distributional mismatches. Additionally, we derive explicit\ntheoretical conditions on the ambiguity set radius that ensure the asymptotic\nconvergence of the time-varying DR Kalman filter to the proposed steady-state\nsolution. Numerical simulations demonstrate that our approach outperforms\nexisting baseline filters in terms of robustness and accuracy across both\nGaussian and non-Gaussian uncertainty scenarios, highlighting its significant\npotential for real-world control and estimation applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T05:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.23743v1","title":"DUNE Software and Computing Research and Development","summary":"The international collaboration designing and constructing the Deep\nUnderground Neutrino Experiment (DUNE) at the Long-Baseline Neutrino Facility\n(LBNF) has developed a two-phase strategy toward the implementation of this\nleading-edge, large-scale science project. The ambitious physics program of\nPhase I and Phase II of DUNE is dependent upon deployment and utilization of\nsignificant computing resources, and successful research and development of\nsoftware (both infrastructure and algorithmic) in order to achieve these\nscientific goals. This submission discusses the computing resources\nprojections, infrastructure support, and software development needed for DUNE\nduring the coming decades as an input to the European Strategy for Particle\nPhysics Update for 2026. The DUNE collaboration is submitting four main\ncontributions to the 2026 Update of the European Strategy for Particle Physics\nprocess. This submission to the 'Computing' stream focuses on DUNE software and\ncomputing. Additional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and European contributions to Fermilab accelerator\nupgrades and facilities for the DUNE experiment, are also being submitted to\nother streams.","main_category":"physics.data-an","categories":"physics.data-an,hep-ex,physics.ins-det","published":"2025-03-31T05:47:08Z"}
{"aid":"http://arxiv.org/abs/2503.23754v1","title":"On doubly commuting operators in $C_{1, r}$ class and quantum annulus","summary":"For $ 0 < r < 1 $, let $ \\mathbb{A}_r = \\{ z \\in \\mathbb{C} : r < |z| < 1 \\}\n$ be the annulus with boundary $ \\partial \\overline{\\mathbb{A}}_r = \\mathbb{T}\n\\cup r\\mathbb{T} $, where $ \\mathbb{T} $ is the unit circle in the complex\nplane $\\mathbb C$. We study the class of operators \\[ C_{1,r} = \\{ T : T \\text{\nis invertible and } \\|T\\|, \\|rT^{-1}\\| \\leq 1 \\}, \\] introduced by Bello and\nYakubovich. Any operator $T$ for which the closed annulus\n$\\overline{\\mathbb{A}}_r$ is a spectral set is in $C_{1,r}$. The class $C_{1,\nr}$ is closely related to the \\textit{quantum annulus} which is given by \\[\nQA_r = \\{ T : T \\text{ is invertible and } \\|rT\\|, \\|rT^{-1}\\| \\leq 1 \\}. \\]\nMcCullough and Pascoe proved that an operator in $ QA_r $ admits a dilation to\nan operator $ S $ satisfying $(r^{-2} + r^2)I - S^*S - S^{-1}S^{-*} = 0$. An\nanalogous dilation result holds for operators in $ C_{1,r}$ class. We extend\nthese dilation results to doubly commuting tuples of operators in quantum\nannulus as well as in $C_{1,r}$ class. We also provide characterizations and\ndecomposition results for such tuples.","main_category":"math.FA","categories":"math.FA","published":"2025-03-31T06:07:12Z"}
{"aid":"http://arxiv.org/abs/2503.23769v1","title":"Acceleration Theorem for Low-Dimensional Electron Systems with\n  Off-Diagonal Effective Mass Components","summary":"The motion of electrons under homogeneously applied electric fields in\nlow-dimensional systems with non-zero off-diagonal effective mass (ODEM) is\nstudied. The equation describing the time evolution of a probability\ncoefficient of finding an electron in a subband is derived using the\nKrieger-Iafrate theory in the effective mass approximation. It is shown that an\nelectron can change subbands during free flight due to the ODEM-induced\ninter-subband transitions. By introducing an effective dispersion defined as a\nweighted average of the subband dispersions, it is also shown that the initial\nacceleration of an electron effectively follows the bulk dispersion relation.\nThe results obtained suggest that the transport properties of the quantized\nsystems when many subbands are occupied in the weak confinement limit approach\nthe values one would find without considering the quantization.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mes-hall","published":"2025-03-31T06:40:52Z"}
{"aid":"http://arxiv.org/abs/2503.23772v1","title":"TransVFC: A Transformable Video Feature Compression Framework for\n  Machines","summary":"Nowadays, more and more video transmissions primarily aim at downstream\nmachine vision tasks rather than humans. While widely deployed Human Visual\nSystem (HVS) oriented video coding standards like H.265/HEVC and H.264/AVC are\nefficient, they are not the optimal approaches for Video Coding for Machines\n(VCM) scenarios, leading to unnecessary bitrate expenditure. The academic and\ntechnical exploration within the VCM domain has led to the development of\nseveral strategies, and yet, conspicuous limitations remain in their\nadaptability for multi-task scenarios. To address the challenge, we propose a\nTransformable Video Feature Compression (TransVFC) framework. It offers a\ncompress-then-transfer solution and includes a video feature codec and Feature\nSpace Transform (FST) modules. In particular, the temporal redundancy of video\nfeatures is squeezed by the codec through the scheme-based inter-prediction\nmodule. Then, the codec implements perception-guided conditional coding to\nminimize spatial redundancy and help the reconstructed features align with\ndownstream machine perception.After that, the reconstructed features are\ntransferred to new feature spaces for diverse downstream tasks by FST modules.\nTo accommodate a new downstream task, it only requires training one lightweight\nFST module, avoiding retraining and redeploying the upstream codec and\ndownstream task networks. Experiments show that TransVFC achieves high\nrate-task performance for diverse tasks of different granularities. We expect\nour work can provide valuable insights for video feature compression in\nmulti-task scenarios. The codes are at https://github.com/Ws-Syx/TransVFC.","main_category":"eess.IV","categories":"eess.IV","published":"2025-03-31T06:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.23788v1","title":"Detection of an extraterrestrial technical civilisation on the\n  extrasolar planet GJ 1132b","summary":"We report the detection of whisky in the atmosphere of the extrasolar\nsuper-Earth planet GJ 1132b from transmission spectroscopic data. It is seen\nboth in atmospheric absorption as well as in chromospheric emission, the latter\nprobably due to the intense heating of the co-rotating planet's day-side\nsurface. This detection cannot be explained using natural sources of alcohol,\nimplying that there must be a technically advanced civilisation -- possibly\noriginating from the neighboring habitable planet GJ 1132c -- that is engaged\nin massive distilling operations accompanied by high levels of industrial\npollution. The reason for the necessarily vast scale of production is either to\nproduce rocket fuel for an interplanetary economy or, more likely, for an\nunusually high level of personal consumption. The latter hypothesis suggests a\nnovel explanation for the Fermi Paradox (the lack of indirect or direct contact\nwith extraterrestrials): a technically versed civilisation would be incapable\nof achieving the higher technical levels necessary for the development of a\ndetectable radio signature -- much less interstellar travel -- at the suggested\nrates of consumption.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.soc-ph","published":"2025-03-31T07:03:23Z"}
{"aid":"http://arxiv.org/abs/2503.23789v1","title":"Reviewing the fundamentals and best practices to characterize\n  microplastics using state-of-the-art quantum-cascade laser\n  reflectance-absorbance spectroscopy","summary":"Microplastic pollution studies depend on reliable identification of the\nsuspicious particles. Out of the various analytical techniques available to\ncharacterize them, infrared transflectance using a tuneable mid-IR quantum\ncascade laser is a high-throughput state-of-the-art imaging option,\nspecifically Agilent QCL-LDIR (Quantum Cascade Laser Direct Infrared imaging).\nIts conceptual grounds are reviewed, instrumental developments are discussed,\nalong with a review of applications and best practices to overcome\nobstacles/difficulties in routine measurements, namely: the spectral range, the\nvariation of some peak intensities with the particles size, effects of the size\nof the particles, processing speed, and avoiding the use of measurement\naliquots. Objective procedures to avoid too many false positives when\nidentifying spectra and to distinguish fibers and fragments are given. These\npractices open a path to QCL-LDIR measurement standardization and potential use\nfor microplastics monitoring, as requested by many governmental bodies in\ncharge of setting environmental protection rules.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:04:13Z"}
{"aid":"http://arxiv.org/abs/2503.23793v1","title":"Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables","summary":"Recently, deep learning-based pan-sharpening algorithms have achieved notable\nadvancements over traditional methods. However, many deep learning-based\napproaches incur substantial computational overhead during inference,\nespecially with high-resolution images. This excessive computational demand\nlimits the applicability of these methods in real-world scenarios, particularly\nin the absence of dedicated computing devices such as GPUs and TPUs. To address\nthese challenges, we propose Pan-LUT, a novel learnable look-up table (LUT)\nframework for pan-sharpening that strikes a balance between performance and\ncomputational efficiency for high-resolution remote sensing images. To finely\ncontrol the spectral transformation, we devise the PAN-guided look-up table\n(PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained\nspatial details and adaptively learn local contexts, we introduce the spatial\ndetails look-up table (SDLUT) and adaptive aggregation look-up table (AALUT).\nOur proposed method contains fewer than 300K parameters and processes a 8K\nresolution image in under 1 ms using a single NVIDIA GeForce RTX 2080 Ti GPU,\ndemonstrating significantly faster performance compared to other methods.\nExperiments reveal that Pan-LUT efficiently processes large remote sensing\nimages in a lightweight manner, bridging the gap to real-world applications.\nFurthermore, our model surpasses SOTA methods in full-resolution scenes under\nreal-world conditions, highlighting its effectiveness and efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:13:59Z"}
{"aid":"http://arxiv.org/abs/2503.23809v1","title":"Nuclear clustering process in heavy-ion collisions : experimental\n  constraints on the low-temperature region of the QCD phase diagram","summary":"In this article, we study the production of Hydrogen and Helium isotopes in\nheavy-ion collisions in the incident energy range between 80 and 150\nMeV/nucleon. We compare their inclusive multiplicities emitted in the\ntransverse plane of the reaction with the predictions given by the thermal\nmodel. As a first step, we validate the choice of this approach to describe the\nexperimental measurements. We also show that the transient states have to be\nexplicitly taken into account for a good statistical description of the\nexperimental multiplicities. From the thermodynamical parameter values obtained\nwe complete the existing database built with the use of thermal-statistical\nmodels to reproduce particle production in the (ultra-)relativistic-energy\nmeasurements. We then proposed a new constraint on the so-called freeze-out\nregion in the temperature (T) versus baryonic chemical potential (muB) phase\ndiagram of the quantum chromodynamics. These new results indicate that there is\na common framework to describe the hadron production and nuclear clustering\nprocesses in heavy-ion collisions.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-03-31T07:43:48Z"}
{"aid":"http://arxiv.org/abs/2503.23810v1","title":"Adaptive Attention-Based Model for 5G Radio-based Outdoor Localization","summary":"Radio-based localization in dynamic environments, such as urban and vehicular\nsettings, requires systems that can efficiently adapt to varying signal\nconditions and environmental changes. Factors such as multipath interference\nand obstructions introduce different levels of complexity that affect the\naccuracy of the localization. Although generalized models offer broad\napplicability, they often struggle to capture the nuances of specific\nenvironments, leading to suboptimal performance in real-world deployments. In\ncontrast, specialized models can be tailored to particular conditions, enabling\nmore precise localization by effectively handling domain-specific variations\nand noise patterns. However, deploying multiple specialized models requires an\nefficient mechanism to select the most appropriate one for a given scenario. In\nthis work, we develop an adaptive localization framework that combines shallow\nattention-based models with a router/switching mechanism based on a\nsingle-layer perceptron (SLP). This enables seamless transitions between\nspecialized localization models optimized for different conditions, balancing\naccuracy, computational efficiency, and robustness to environmental variations.\nWe design three low-complex localization models tailored for distinct\nscenarios, optimized for reduced computational complexity, test time, and model\nsize. The router dynamically selects the most suitable model based on real-time\ninput characteristics. The proposed framework is validated using real-world\nvehicle localization data collected from a massive MIMO base station (BS),\ndemonstrating its ability to seamlessly adapt to diverse deployment conditions\nwhile maintaining high localization accuracy.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-03-31T07:44:14Z"}
{"aid":"http://arxiv.org/abs/2503.23816v1","title":"Two-electron edge states in a double SSH-chain of quantum dots","summary":"We study an interacting two-body model with adjustable spin tunneling in the\ncontext of the double SSH chains for a quantum dot system. We discovered that\nvarying interaction strengths and spin tunneling significantly influence the\nproperties of correlated edge states in the energy spectrum obtained through\nexact diagonalization. We observe that stronger interactions lead to longer\ndecay lengths of these states. Conversely, the decay length decreases as the\ndifference in intracell or intercell tunneling increases. Importantly, the\ndecay length is strongly correlated with the dynamical behavior of two\nparticles; specifically, an increase in decay length corresponds to a decrease\nin motion frequency. This conclusion is supported by the observation of the\nexpectation value of coordinate operators of the particles.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T07:50:06Z"}
{"aid":"http://arxiv.org/abs/2503.23825v1","title":"Calibration requirements for Epoch of Reionization 21-cm signal\n  observations -- IV. Bias and variance with time and frequency correlated\n  residual gains","summary":"Observation of multifrequency angular power spectrum of the redshifted 21-cm\nbrightness temperature fluctuation from the neutral hydrogen holds the key to\nunderstand the structure formation and its evolution during the reionization\nand post-reionization era. A major challenge in observing the neutral hydrogen\narises from presence of strong foreground signals in the frequency range of\ninterest. Mitigating the direct effect of foregrounds are being addressed\nthrough various techniques in literature. An additional second order effect\narises, in presence of foreground, with limited accuracy in time and frequency\ndependent gain calibrations. This manifests as the residual gain and bandpass\nerror in the observed data, introduces bias and increases uncertainty in the\nestimates of multifrequency angular power spectrum. In this work, we present an\nanalytic method to estimate the bias and excess uncertainty in the estimates of\nmultifrequency angular power spectrum in presence of residual gain and bandpass\nerrors. We use this framework to estimate the effect of these errors for\ndetection of redshifted 21-cm emission from a redshift of $\\sim 8$ with the\nupcoming SKA1-Low. Due to the high baseline density at the required range of\nangular multipoles, the SKA1-Low is found to be a tuned instrument for the\nredshifted 21-cm signal detection. We find that, there are scenario with\nresidual gain and bandpass errors where there can be significant bias in these\nestimates. Certain foreground mitigation strategies, is expected to reduce a\npart of the bias. The detailed study of different aspects of gain and bandpass\nerrors and their relative effects are discussed. We find, with assumed models\nof gain and bandpass errors, signal detection is possible at this redshift with\n$128$ hours of observations. However, to achieve this one needs to have better\ncalibration accuracy than present day interferometers.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-03-31T08:19:59Z"}
{"aid":"http://arxiv.org/abs/2503.23826v1","title":"Determinization of Min-Plus Weighted Automata is Decidable","summary":"We show that the determinization problem for min-plus (tropical) weighted\nautomata is decidable, thus resolving this long-standing open problem. In doing\nso, we develop a new toolbox for analyzing and reasoning about the\nrun-structure of nondeterministic automata.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-31T08:21:09Z"}
{"aid":"http://arxiv.org/abs/2503.23829v1","title":"Expanding RL with Verifiable Rewards Across Diverse Domains","summary":"Reinforcement learning (RL) with verifiable rewards (RLVR) has shown\npromising results in mathematical reasoning and coding tasks where\nwell-structured reference answers are available. However, its applicability to\nbroader domains remains underexplored. In this work, we study the extension of\nRLVR to more diverse domains such as medicine, chemistry, psychology, and\neconomics. We observe high agreement in binary judgments across different large\nlanguage models (LLMs) when objective reference answers exist, which challenges\nthe necessity of large-scale annotation for training domain-specific reward\nmodels. To address the limitations of binary rewards when handling unstructured\nreference answers, we further incorporate model-based soft scoring into RLVR to\nimprove its flexibility. Our experiments show that a distilled generative\nreward model can serve as an effective cross-domain verifier, providing\nreliable reward signals for RL without requiring domain-specific annotations.\nBy fine-tuning a base 7B model using various RL algorithms against our reward\nmodel, we obtain policies that outperform state-of-the-art open-source aligned\nLLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a large\nmargin, across domains in free-form answer settings. This also strengthens\nRLVR's robustness and scalability, highlighting its potential for real-world\napplications with noisy or weak labels.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T08:22:49Z"}
{"aid":"http://arxiv.org/abs/2503.23842v1","title":"Toward the detection of spin-vortex-induced loop currents in a single\n  bilayer Bi$_2$Sr$_2$CaCu$_2$O$_{8+}$ thin film and their possible use\n  as qubits: Model calculations for three nano-island architecture","summary":"A theory for cuprate superconductivity predicts the existence of nano-sized\nloop currents called, ``spin-vortex-induced loop currents (SVILCs)''. In this\nwok, we first calculate magnetic fields produced by them in a single bilayer\nBi$_2$Sr$_2$CaCu$_2$O$_{8+\\delta}$ (Bi-2212) thin film for the purpose of\ndetecting the SVILCs. The estimated magnitude of the magnetic field at the\npoint 10$a$ ($a$ is the lattice constant of the CuO$_2$ plane) above the\nsurface could be in the order of 100mT; thus, they may be detectable by\ncurrently available detection methods. Next, we investigate the use of them as\nqubits (the ``SVILC qubits'') in an architecture composed of three nano-islands\nof the thin film; and consider the use of the detection of the magnetic field\ngenerated by the SVILCs as the qubit readout. We show there are a number of\nenergy levels suitable for qubit states that can be manipulated by external\ncurrent feeding, and the magnetic field generated by the SVILCs is large enough\nto be used for the readout.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T08:44:36Z"}
{"aid":"http://arxiv.org/abs/2503.23844v1","title":"FlexiMo: A Flexible Remote Sensing Foundation Model","summary":"The rapid expansion of multi-source satellite imagery drives innovation in\nEarth observation, opening unprecedented opportunities for Remote Sensing\nFoundation Models to harness diverse data. However, many existing models remain\nconstrained by fixed spatial resolutions and patch sizes, limiting their\nability to fully exploit the heterogeneous spatial characteristics inherent in\nsatellite imagery. To address these challenges, we propose FlexiMo, a flexible\nremote sensing foundation model that endows the pre-trained model with the\nflexibility to adapt to arbitrary spatial resolutions. Central to FlexiMo is a\nspatial resolution-aware module that employs a parameter-free alignment\nembedding mechanism to dynamically recalibrate patch embeddings based on the\ninput image's resolution and dimensions. This design not only preserves\ncritical token characteristics and ensures multi-scale feature fidelity but\nalso enables efficient feature extraction without requiring modifications to\nthe underlying network architecture. In addition, FlexiMo incorporates a\nlightweight channel adaptation module that leverages prior spectral information\nfrom sensors. This mechanism allows the model to process images with varying\nnumbers of channels while maintaining the data's intrinsic physical properties.\nExtensive experiments on diverse multimodal, multi-resolution, and multi-scale\ndatasets demonstrate that FlexiMo significantly enhances model generalization\nand robustness. In particular, our method achieves outstanding performance\nacross a range of downstream tasks, including scene classification, land cover\nclassification, urban building segmentation, and cloud detection. By enabling\nparameter-efficient and physically consistent adaptation, FlexiMo paves the way\nfor more adaptable and effective foundation models in real-world remote sensing\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T08:46:05Z"}
{"aid":"http://arxiv.org/abs/2503.23859v1","title":"Evaluating small vision-language models as AI assistants for radio\n  astronomical source analysis tasks","summary":"The advent of next-generation radio telescopes is set to transform radio\nastronomy by producing massive data volumes that challenge traditional\nprocessing methods. Deep learning techniques have shown strong potential in\nautomating radio analysis tasks, yet are often constrained by the limited\navailability of large annotated datasets. Recent progress in self-supervised\nlearning has led to foundational radio vision models, but adapting them for new\ntasks typically requires coding expertise, limiting their accessibility to a\nbroader astronomical community. Text-based AI interfaces offer a promising\nalternative by enabling task-specific queries and example-driven learning. In\nthis context, Large Language Models (LLMs), with their remarkable zero-shot\ncapabilities, are increasingly used in scientific domains. However, deploying\nlarge-scale models remains resource-intensive, and there is a growing demand\nfor AI systems that can reason over both visual and textual data in\nastronomical analysis. This study explores small-scale Vision-Language Models\n(VLMs) as AI assistants for radio astronomy, combining LLM capabilities with\nvision transformers. We fine-tuned the LLaVA VLM on a dataset of 59k radio\nimages from multiple surveys, enriched with 38k image-caption pairs from the\nliterature. The fine-tuned models show clear improvements over base models in\nradio-specific tasks, achieving ~30% F1-score gains in extended source\ndetection, but they underperform pure vision models and exhibit ~20% drop on\ngeneral multimodal tasks. Inclusion of caption data and LoRA fine-tuning\nenhances instruction-following and helps recover ~10% accuracy on standard\nbenchmarks. This work lays the foundation for future advancements in radio\nVLMs, highlighting their potential and limitations, such as the need for better\nmultimodal alignment, higher-quality datasets, and mitigation of catastrophic\nforgetting.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T09:06:23Z"}
{"aid":"http://arxiv.org/abs/2503.23865v1","title":"$L^p$-solvability of boundary value problems for the Laplacian in\n  locally flat unbounded domains","summary":"We establish the solvability of the $L^p$-Dirichlet and\n$L^{p^\\prime}$-Neumann problems for the Laplacian for $p\\in\n(\\frac{n}{n-1}-\\varepsilon,\\frac{2n}{n-1}]$ for some $\\varepsilon>0$ in\n$2$-sided chord-arc domains with unbounded boundary that is sufficiently flat\nat large scales and outward unit normal vector whose oscillation fails to be\nsmall only at finitely many dyadic boundary balls.","main_category":"math.AP","categories":"math.AP,math.CA,math.FA","published":"2025-03-31T09:15:23Z"}
{"aid":"http://arxiv.org/abs/2503.23870v1","title":"A SAT-centered XAI method for Deep Learning based Video Understanding","summary":"This paper introduces a novel formal SAT-based explanation model for deep\nlearning in video understanding. The proposed method integrates SAT solving\ntechniques with the principles of formal explainable AI to address the\nlimitations of existing XAI techniques in this domain. By encoding deep\nlearning models and video data into a logical framework and formulating\nexplanation queries as satisfiability problems, the method aims to generate\nlogic-based explanations with formal guarantees. The paper details the\nconceptual framework, the process of encoding deep learning models and video\ndata, the formulation of \"Why?\" and \"Why not?\" questions, and a novel\narchitecture integrating a SAT solver with a deep learning video understanding\nmodel. While challenges related to computational complexity and the\nrepresentational power of propositional logic remain, the proposed approach\noffers a promising direction for enhancing the explainability of deep learning\nin the complex and critical domain of video understanding.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T09:20:06Z"}
{"aid":"http://arxiv.org/abs/2503.23880v1","title":"Can a ferroelectric diode be a selector-less, universal, non-volatile\n  memory?","summary":"Recent advances in silicon foundry-process compatible ferroelectric (FE) thin\nfilms have reinvigorated interest in FE-based non-volatile memory (NVM)\ndevices. Ferroelectric diodes (FeDs) are two-terminal NVM devices exhibiting\nrectifying current-voltage hysteretic characteristics that enable\nself-selecting designs critical for high-density memory. We examine progress in\nFeDs based on CMOS-compatible HZO, AlScN, and emerging van der Waals\nferroelectrics. While FeDs demonstrate promising ON/OFF ratios and\nrectification capabilities, they face persistent challenges including limited\nwrite-cycling endurance, elevated operating voltages, and insufficient read\ncurrents. We provide materials-focused strategies to enhance reliability and\nperformance of FeDs for energy-efficient electronic memory applications, with\nemphasis on their unique self-rectifying capabilities that eliminate the need\nfor selector elements in crossbar arrays for compute in memory applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:29:57Z"}
{"aid":"http://arxiv.org/abs/2503.23889v1","title":"Robust Predictive Routing for Internet of Vehicles Leveraging Both V2I\n  and V2V Links","summary":"With the developments of the Internet of Vehicles (IoV) from 4G to 5G,\nvehicle-to-infrastructure (V2I) communications are becoming attractive for\nvehicle users (VUEs) to obtain diverse cloud service through base stations\n(BSs). To tackle V2I link deterioration caused by blockage and out-of-coverage\ncases, multi-hop V2X routing with both vehicle-to-vehicle (V2V) and V2I links\nneeds to be investigated. However, traditional routing reacts to statistical or\nreal-time information, which may suffer link degradation during path switchover\nin fast-changing vehicular networks. Predictive routing protocols take timely\nactions by forecasting link connectivity, but they fail to satisfy specific QoS\nrequirements. Low robustness to link failures is also incurred without\nconsidering imperfect prediction. To build continual paths between VUEs and BSs\nfor QoS provision of cloud service, a robust predictive routing framework\n(ROPE) is proposed with three major components: 1) an early warning scheme\ndetects V2I link deterioration in advance via predicting vehicle mobility and\nlink signal strength to facilitate seamless path switchover; 2) a virtual\nrouting mechanism finds top3 paths that have the highest path strength and\nsatisfy the connectivity and hop count constraints based on the prediction\nresults to fulfill QoS requirements of cloud service; 3) a path verification\nprotocol checks availability and quality of the top3 paths shortly before\nswitchover and activates one qualified path for switchover to ensure routing\nrobustness. We implement ROPE in a simulation framework incorporating\nreal-world urban maps, microscopic traffic generation, geometry-based channel\nmodeling, and offline data analysis as well as online inference. Extensive\nsimulations demonstrate the superiority of ROPE over direct V2I communications\nand a connectivity-based predictive routing protocol under various scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T09:41:16Z"}
{"aid":"http://arxiv.org/abs/2503.23901v1","title":"Existence of periodic solution of a non-autonomous allelopathic\n  phytoplankton model with fear effect","summary":"In this paper, we consider a non-autonomous allelopathic phytoplankton\ncompetition ODE model, incorporating the influence of fear effects observed in\nnatural biological phenomena. Based on Mawhin's coincidence degree theory some\nsufficient conditions for existence of periodic solutions are obtained. We\nvalidate our findings through an illustrative example and numerical\nsimulations, showing that constant coefficients lead to steady-state dynamics,\nwhile periodic variations induce oscillatory behavior.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T09:50:32Z"}
{"aid":"http://arxiv.org/abs/2503.23902v1","title":"First-Principle Investigation On Chromium Decorated Graphene-based\n  Systems for Hydrogen Storage","summary":"Sorbent materials like Cr decorated 2D materials are explored among its\nstorage options. 2D material like graphene has been used as it has a high\nsurface to volume ratio. A comparative study is done with Cr adsorbed in\ndefect-free and single vacancy defect graphene systems. Ab-initio calculations\nare performed with and without Van der Waals interaction to check the hydrogen\nstorage efficiency. Efficiency is determined by calculating the binding energy\nof the system. The preferred range for binding energy for reversible hydrogen\nstorage, as determined by the Department of Energy, US, is between 0.2-0.6 eV.\nThis work also visualizes the thermal stability spectrum of the efficient\nmaterials at 300 K using molecular dynamics calculations, predicting their\nstability at room temperature.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:51:56Z"}
{"aid":"http://arxiv.org/abs/2503.23910v1","title":"Droplet breakup morphologies and the resultant size distribution in an\n  opposed-flow airstream at different Weber numbers","summary":"The present study investigates the morphology and breakup dynamics of a\nfreely falling drop in a vertical airstream using shadowgraphy and in-line\nholography. The in-line holography provides the temporal evolution of the\nvolumetric size distribution of child droplets formed during various\nfragmentation processes at different Weber numbers (We). The droplet undergoes\ndifferent fragmentation processes at significantly lower Weber numbers in\nopposed-flow configurations compared to cross-flow configurations. Our findings\nreveal distinct fragmentation modes, namely bag, bag-stamen, and dual-bag\nbreakup, observed at We=9.38, 16.9, and 18.9, respectively. At We = 9.38, the\ncombined effects of bag rupture, rim breakup, and node fragmentation generate\nchild droplets of varying sizes, driven by the interplay of the\nRayleigh-Plateau and Rayleigh-Taylor instabilities. At We = 16.9, the\ninteraction of aerodynamic and shear forces leads to bag-stamen fragmentation,\ncharacterized by forming a stamen-like structure along with the bag. Both bag\nand bag-stamen breakups result in tri-modal size distributions. However, at We\n= 16.9, fewer tiny droplets are produced compared to the bag breakup observed\nat lower Weber numbers. In contrast, at We = 18.9, a dual-bag breakup occurs,\nwhere both bags inflate and burst simultaneously. This process generates tiny\nchild droplets in the early stages, while larger child droplets form later due\nto the fragmentation of the rim and nodes, resulting in a bi-modal size\ndistribution. We have performed a theoretical analysis using a two-parameter\ngamma distribution, which satisfactorily predicts the size distributions\nobserved experimentally at different Weber numbers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T10:02:22Z"}
{"aid":"http://arxiv.org/abs/2503.23911v1","title":"FineCausal: A Causal-Based Framework for Interpretable Fine-Grained\n  Action Quality Assessment","summary":"Action quality assessment (AQA) is critical for evaluating athletic\nperformance, informing training strategies, and ensuring safety in competitive\nsports. However, existing deep learning approaches often operate as black boxes\nand are vulnerable to spurious correlations, limiting both their reliability\nand interpretability. In this paper, we introduce FineCausal, a novel\ncausal-based framework that achieves state-of-the-art performance on the\nFineDiving-HM dataset. Our approach leverages a Graph Attention Network-based\ncausal intervention module to disentangle human-centric foreground cues from\nbackground confounders, and incorporates a temporal causal attention module to\ncapture fine-grained temporal dependencies across action stages. This\ndual-module strategy enables FineCausal to generate detailed spatio-temporal\nrepresentations that not only achieve state-of-the-art scoring performance but\nalso provide transparent, interpretable feedback on which features drive the\nassessment. Despite its strong performance, FineCausal requires extensive\nexpert knowledge to define causal structures and depends on high-quality\nannotations, challenges that we discuss and address as future research\ndirections. Code is available at https://github.com/Harrison21/FineCausal.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:02:29Z"}
{"aid":"http://arxiv.org/abs/2503.23912v1","title":"Certified Approximate Reachability (CARe): Formal Error Bounds on Deep\n  Learning of Reachable Sets","summary":"Recent approaches to leveraging deep learning for computing reachable sets of\ncontinuous-time dynamical systems have gained popularity over traditional\nlevel-set methods, as they overcome the curse of dimensionality. However, as\nwith level-set methods, considerable care needs to be taken in limiting\napproximation errors, particularly since no guarantees are provided during\ntraining on the accuracy of the learned reachable set. To address this\nlimitation, we introduce an epsilon-approximate Hamilton-Jacobi Partial\nDifferential Equation (HJ-PDE), which establishes a relationship between\ntraining loss and accuracy of the true reachable set. To formally certify this\napproximation, we leverage Satisfiability Modulo Theories (SMT) solvers to\nbound the residual error of the HJ-based loss function across the domain of\ninterest. Leveraging Counter Example Guided Inductive Synthesis (CEGIS), we\nclose the loop around learning and verification, by fine-tuning the neural\nnetwork on counterexamples found by the SMT solver, thus improving the accuracy\nof the learned reachable set. To the best of our knowledge, Certified\nApproximate Reachability (CARe) is the first approach to provide soundness\nguarantees on learned reachable sets of continuous dynamical systems.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,math.OC","published":"2025-03-31T10:02:57Z"}
{"aid":"http://arxiv.org/abs/2503.23914v1","title":"Scenarios for the Deployment of Automated Vehicles in Europe","summary":"The deployment of Automated Vehicles (AVs) is expected to address road\ntransport externalities (e.g., safety, traffic, environmental impact, etc.).\nFor this reason, a legal framework for their large-scale market introduction\nand deployment is currently being developed in the European Union. Despite the\nfirst steps towards road transport automation, the timeline for full automation\nand its potential economic benefits remains uncertain. The aim of this paper is\ntwofold. First, it presents a methodological framework to determine deployment\npathways of the five different levels of automation in EU27+UK to 2050 under\nthree scenarios (i.e., slow, medium baseline and fast) focusing on passenger\nvehicles. Second, it proposes an assessment of the economic impact of AVs\nthrough the calculation of the value-added. The method to define assumptions\nand uptake trajectories involves a comprehensive literature review, expert\ninterviews, and a model to forecast the new registrations of different levels\nof automation. In this way, the interviews provided insights that complemented\nthe literature and informed the design of assumptions and deployment\ntrajectories. The added-value assessment shows additional economic activity due\nto the introduction of automated technologies in all uptake scenarios.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T10:06:27Z"}
{"aid":"http://arxiv.org/abs/2503.23918v1","title":"Hint of $r\\simeq 0.01$ after DESI DR2 ?","summary":"In the report by BICEP and Keck collaborations, the tensor-to-scalar ratio is\n$r_{0.05}<0.036$ (95\\% C.L.) and $ <1.3\\sigma$ non-zero (with pre-DESI BAO\ndata). However, recent datasets have significantly shifted the bestfit values\nof relevant $\\Lambda$CDM cosmological parameters, and thus possibly alter the\namplitude of lensing B-mode spectrum, which would affect the search for $r$.\nHere, the joint analysis of Planck and BICEP/Keck data with DESI DR2 reveals\nthat the lower bound of $r_{0.05}$ is $2.0\\sigma$ and $2.1\\sigma$ non-zero for\nPantheonPlus and DES-Y5, respectively, and the bestfit $r$ is $r_{0.05}\\simeq\n0.01$. The results are consistent with those with DESI DR1, but slightly\nstrengthened. There might be still systematic uncertainties in B-mode\nmeasurements due to the foreground contamination, however, our work is to not\nsay what about the value of $r$, but emphasize that the detection for $r$ is\nmodel-dependent and depends potentially on our insight into the dark universe,\nhighlighting the important role of cosmological surveys in comprehending our\nvery early universe.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-03-31T10:08:04Z"}
{"aid":"http://arxiv.org/abs/2503.23945v1","title":"DiffuSE: Cross-Layer Design Space Exploration of DNN Accelerator via\n  Diffusion-Driven Optimization","summary":"The proliferation of deep learning accelerators calls for efficient and\ncost-effective hardware design solutions, where parameterized modular hardware\ngenerator and electronic design automation (EDA) tools play crucial roles in\nimproving productivity and final Quality-of-Results (QoR). To strike a good\nbalance across multiple QoR of interest (e.g., performance, power, and area),\nthe designers need to navigate a vast design space, encompassing tunable\nparameters for both hardware generator and EDA synthesis tools. However, the\nsignificant time for EDA tool invocations and complex interplay among numerous\ndesign parameters make this task extremely challenging, even for experienced\ndesigners. To address these challenges, we introduce DiffuSE, a\ndiffusion-driven design space exploration framework for cross-layer\noptimization of DNN accelerators. DiffuSE leverages conditional diffusion\nmodels to capture the inverse, one-to-many mapping from QoR objectives to\nparameter combinations, allowing for targeted exploration within promising\nregions of the design space. By carefully selecting the conditioning QoR\nvalues, the framework facilitates an effective trade-off among multiple QoR\nmetrics in a sample-efficient manner. Experimental results under 7nm technology\ndemonstrate the superiority of the proposed framework compared to previous\narts.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T10:50:00Z"}
{"aid":"http://arxiv.org/abs/2503.23950v1","title":"Plasmons in N-layer systems","summary":"In multilayer structures, the coupling between layers gives rise to unique\nplasmon modes, but analytic solutions are typically available only for bilayers\ndue to the increasing complexity as the number of layers increases. We\ninvestigate plasmons in multilayer structures, including the effects of\ninterlayer tunneling. By introducing the Coulomb eigenvector basis for\nmultilayer systems, which can be solved exactly using Kac-Murdock-Szeg\\H{o}\nToeplitz matrices, we analytically derive the long-wavelength plasmon\ndispersions both with and without interlayer tunneling. In the $N$-layer\nsystems, we find that, in the absence of interlayer tunneling, the out-of-phase\nacoustic or charge neutral plasmon modes with linear dispersions\n($\\omega_\\alpha\\propto q/\\sqrt{{1-\\cos{\\left(\\frac{\\alpha-1}{N}\\pi\\right)}}}$\nfor $\\alpha = 2, 3, \\cdots, N$) exist, while the in-phase classical plasmon\nmode exhibits its conventional dispersion ($\\omega_1\\propto \\sqrt{q}$). When\ninterlayer tunneling is present, the out-of-phase modes develop plasmon gaps\nthat are governed by specific interband transitions, whereas the classical mode\nremains unaffected. These findings have broad applicability to general\ncoupled-layer structures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T11:02:44Z"}
{"aid":"http://arxiv.org/abs/2503.23969v1","title":"Electronic structure of UGe$_2$ at ambient pressure: comparison with\n  X-ray photoemission spectra","summary":"Based on experimental crystallographic data, electronic structure of UGe$_2$\nhave been calculated and compared with our results of X-ray photoelectron\nspectroscopy (XPS) measurements. We employed two different advanced full\npotential (FP) methods: FP-local-orbital (FPLO) and FP-linear augmented plane\nwaves (Wien2k) codes for non-magnetic and ferromagnetic states. Starting from\nthe local spin-density approximation (LSDA) or generalised gradient\napproximation (GGA), we verified either the orbital polarisation (OP)\ncorrection or the GGA+U approach for the U 5f-electrons, changing\nCoulomb-repulsion energies U in the range 0-4 eV. Satisfying agreement was\nachieved between experimental and our calculated magnetic moments using\nab-initio LSDA+OP and non-ab-initio GGA+U approaches, the latter for realistic\nU values of 2-3 eV. We proved by the LSDA+OP approach an existence of the Fermi\nsurface nesting vector along the a axis, possibly responsible for the triplet\nsuperconducting pairing. The calculated data reveal predominantly an itinerant\nU 5f-electron character of bands near the Fermi level, EF, with only small\ncontributions from the U 6d and Ge 4p states. The experimental XPS spectrum of\nvalence bands (VB) also contains the sharp main 5f-electron peak at EF, a wide\nhump (around -2 eV), and broad small peaks at higher energies. In the\ncalculated XPS spectrum, the width of the main 5f-electron peak varies between\n0.8 and 1.4 eV, depending on a method used in computations, but the hump\nremains unresolved. A newly observed asymmetric 1-eV satellite in the\nexperimental 4f-core XPS spectrum together with known 3-eV and 7-eV satellites\nsuggest dual behaviour of U-5f-electrons in UGe$_2$, the feature is inferred\nalso from the VB studies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el,physics.comp-ph","published":"2025-03-31T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2503.23980v1","title":"SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point\n  Clouds with Cross-Scene Adaptability and 4D Consistency","summary":"We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDAR\npoint clouds with cross-scene adaptability and 4D consistency. Unlike recent\napproaches that rely on camera distillation, SALT operates directly on raw\nLiDAR data, automatically generating pre-segmentation results. To achieve this,\nwe propose a novel zero-shot learning paradigm, termed data alignment, which\ntransforms LiDAR data into pseudo-images by aligning with the training\ndistribution of vision foundation models. Additionally, we design a\n4D-consistent prompting strategy and 4D non-maximum suppression module to\nenhance SAM2, ensuring high-quality, temporally consistent presegmentation.\nSALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI and\nachieves nearly 40-50% of human annotator performance on our newly collected\nlow-resolution LiDAR data and on combined data from three LiDAR types,\nsignificantly boosting annotation efficiency. We anticipate that SALT's\nopen-sourcing will catalyze substantial expansion of current LiDAR datasets and\nlay the groundwork for the future development of LiDAR foundation models. Code\nis available at https://github.com/Cavendish518/SALT.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T11:46:55Z"}
{"aid":"http://arxiv.org/abs/2503.23983v1","title":"Quantum-computing within a bosonic context: Assessing finite basis\n  effects on prototypical vibrational Hamiltonian spectra","summary":"Quantum computing has recently been emerging in theoretical chemistry as a\nrealistic avenue meant to offer computational speedup to challenging\neigenproblems in the context of strongly-correlated molecular systems or\nextended materials. Most studies so far have been devoted to the quantum\ntreatment of electronic structure and only a few were directed to the quantum\ntreatment of vibrational structure, which at the moment remains not devoid of\nunknowns. In particular, we address here a formal problem that arises when\nsimulating a vibrational model under harmonic second quantization, whereby the\ndisruption of the closure relation (resolution of the identity) -- which occurs\nwhen truncating the infinite bosonic basis set -- may have some serious effects\nas regards the correct evaluation of Hamiltonian matrix elements. This relates\nintimately to the normal ordering of products of ladder operators. In addition,\nwe discuss the relevance of choosing an adequate primitive basis set within the\npresent context with respect to its variational convergence properties. Such\nfundamental, yet consequential, aspects are illustrated numerically in the\npresent work on a one-dimensional anharmonic Hamiltonian model corresponding to\na double-well potential showing strong tunneling, of interest both for\nvibrational spectroscopy and chemical reactivity.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T11:52:04Z"}
{"aid":"http://arxiv.org/abs/2503.23984v1","title":"Two-wheel-driven Electric Superbike Powertrain Optimization","summary":"In this paper, we propose an optimization framework for the powertrain design\nof a two-wheel-driven electric superbike, minimizing energy consumption.\nSpecifically, we jointly optimize the force distribution between the wheels\nwith the gear ratio, and rear motor and battery sizing while explicitly\nconsidering vehicle dynamics and performance constraints. First, we present an\nenergy consumption model of the vehicle, including a scalable model of the\nelectric machine based on data from the industry, accounting for iron, copper,\nand mechanical losses. Then, we analyze the propulsive blending strategy to\ndistribute the required power to the wheels while considering adherence limits.\nFinally, we demonstrate the effectiveness of our approach by analyzing the\ndesign of a superbike, based on regulatory driving cycles and a custom\nhigh-performance circuit by comparing the force distribution approaches. The\nresults underline the significance of joint optimization of powertrain\ncomponents and propulsive bias, achieving a reduction of up to 22.36% in energy\nconsumption for the Sport high-performance driving cycle.","main_category":"eess.SY","categories":"eess.SY,cs.SY,J.6","published":"2025-03-31T11:54:50Z"}
{"aid":"http://arxiv.org/abs/2503.23988v1","title":"Deep Learning Model Deployment in Multiple Cloud Providers: an\n  Exploratory Study Using Low Computing Power Environments","summary":"The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.PF","published":"2025-03-31T11:58:37Z"}
{"aid":"http://arxiv.org/abs/2503.24004v1","title":"Multivariate Species Sampling Models","summary":"Species sampling processes have long served as the framework for studying\nrandom discrete distributions. However, their statistical applicability is\nlimited when partial exchangeability is assumed as probabilistic invariance for\nthe observables. Despite numerous discrete models for partially exchangeable\nobservations, a unifying framework is currently missing, leaving many questions\nabout the induced learning mechanisms unanswered in this setting. To fill this\ngap, we consider the natural extension of species sampling models to a\nmultivariate framework, obtaining a general class of models characterized by\ntheir partially exchangeable partition probability function. A notable\nsubclass, named regular multivariate species sampling models, exists among\nthese models. In the subclass, dependence across processes is accurately\ncaptured by the correlation among them: a correlation of one equals full\nexchangeability and a null correlation corresponds to independence. Regular\nmultivariate species sampling models encompass discrete processes for partial\nexchangeable data used in Bayesian models, thereby highlighting their core\ndistributional properties and providing a means for developing new models.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-03-31T12:30:54Z"}
{"aid":"http://arxiv.org/abs/2503.24005v1","title":"Attraction of a jerk","summary":"Jerk plays a pivotal role in the thrilling experience of many amusemement\npark rides. In addition to exploring the physical aspect of jerks, we tackle\nthe empirical observation of an attractive force between passengers in the\npopular attraction, the spinning teacups. By modeling the complex system of\nrotating platforms, we show that pseudotorques induced by changing acceleration\nlead to jerky movements and an attractive interaction among riders. Our\nnumerical analysis confirms the empirical observations, highlighting the\nconnection between attraction and jerks.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.pop-ph","published":"2025-03-31T12:30:57Z"}
{"aid":"http://arxiv.org/abs/2503.24007v1","title":"CITRAS: Covariate-Informed Transformer for Time Series Forecasting","summary":"Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:32:23Z"}
{"aid":"http://arxiv.org/abs/2503.24031v1","title":"An ANN-Enhanced Approach for Flatness-Based Constrained Control of\n  Nonlinear Systems","summary":"Neural networks have proven practical for a synergistic combination of\nadvanced control techniques. This work analyzes the implementation of rectified\nlinear unit neural networks to achieve constrained control in differentially\nflat systems. Specifically, the class of flat systems enjoys the benefit of\nfeedback linearizability, i.e., the systems can be linearized by means of a\nproper variable transformation. However, the price for linearizing the dynamics\nis that the constraint descriptions are distorted geometrically. Our results\nshow that, by using neural networks, these constraints can be represented as a\nunion of polytopes, enabling the use of mixed-integer programming tools to\nguarantee constraint satisfaction. We further analyze the integration of the\ncharacterization into efficient settings such as control Lyapunov\nfunction-based and model predictive control (MPC). Interestingly, this\ndescription also allows us to explicitly compute the solution of the MPC\nproblem for the nonlinear system. Several examples are provided to illustrate\nthe effectiveness of our framework.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-03-31T12:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.24035v1","title":"Using directed acyclic graphs to determine whether multiple imputation\n  or subsample multiple imputation estimates of an exposure-outcome association\n  are unbiased","summary":"Background: Missing data is a pervasive problem in epidemiology, with\ncomplete records analyses (CRA) or multiple imputation (MI) the most common\nmethods to deal with incomplete data. MI is valid when incomplete variables are\nindependent of response indicators, conditional on complete variables -\nhowever, this can be hard to assess with multiple incomplete variables.\nPrevious literature has shown that MI may be valid in subsamples of the data,\neven if not necessarily valid in the full dataset. Current guidance on how to\ndecide whether MI is appropriate is lacking.\n  Methods: We develop an algorithm that is sufficient to indicate when MI will\nestimate an exposure-outcome coefficient without bias and show how to implement\nthis using directed acyclic graphs (DAGs). We extend the algorithm to\ninvestigate whether MI applied to a subsample of the data, in which some\nvariables and complete and the remaining are imputed, will be unbiased for the\nsame estimand. We demonstrate the algorithm by applying it to several simple\nexamples and a more complex real-life example.\n  Conclusions: Multiple incomplete variables are common in practice. Assessing\nthe plausibility of each of CRA and MI estimating an exposure-outcome\nassociation without bias is crucial in analysing and interpreting results. Our\nalgorithm provides researchers with the tools to decide whether (and how) to\nuse MI in practice. Further work could focus on the likely size and direction\nof biases, and the impact of different missing data patterns.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T13:00:18Z"}
{"aid":"http://arxiv.org/abs/2503.24036v1","title":"Automated Discovery of Tactic Libraries for Interactive Theorem Proving","summary":"Enabling more concise and modular proofs is essential for advancing formal\nreasoning using interactive theorem provers (ITPs). Since many ITPs, such as\nRocq and Lean, use tactic-style proofs, learning higher-level custom tactics is\ncrucial for proof modularity and automation. This paper presents a novel\napproach to tactic discovery, which leverages Tactic Dependence Graphs (TDGs)\nto identify reusable proof strategies across multiple proofs. TDGs capture\nlogical dependencies between tactic applications while abstracting away\nirrelevant syntactic details, allowing for both the discovery of new tactics\nand the refactoring of existing proofs into more modular forms. We have\nimplemented this technique in a tool called TacMiner and compare it against an\nanti-unification-based approach Peano to tactic discovery. Our evaluation\ndemonstrates that TacMiner can learn 3x as many tactics as Peano and reduces\nthe size of proofs by 26% across all benchmarks. Furthermore, our evaluation\ndemonstrates the benefits of learning custom tactics for proof automation,\nallowing a state-of-the-art proof automation tool to achieve a relative\nincrease of 172% in terms of success rate.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T13:00:29Z"}
{"aid":"http://arxiv.org/abs/2503.24050v1","title":"A Deep Learning Framework for the Electronic Structure of Water: Towards\n  a Universal Model","summary":"Accurately modeling the electronic structure of water across scales, from\nindividual molecules to bulk liquid, remains a grand challenge. Traditional\ncomputational methods face a critical trade-off between computational cost and\nefficiency.We present an enhanced machine-learning Deep Kohn-Sham (DeePKS)\nmethod for improved electronic structure, DeePKS-ES, that overcomes this\ndilemma. By incorporating the Hamiltonian matrix and their eigenvalues and\neigenvectors into the loss function, we establish a universal model for water\nsystems, which can reproduce high-level hybrid functional (HSE06) electronic\nproperties from inexpensive generalized gradient approximation (PBE)\ncalculations. Validated across molecular clusters and liquid-phase simulations,\nour approach reliably predicts key electronic structure properties such as band\ngaps and density of states, as well as total energy and atomic forces. This\nwork bridges quantum-mechanical precision with scalable computation, offering\ntransformative opportunities for modeling aqueous systems in catalysis, climate\nscience, and energy storage.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atm-clus,physics.comp-ph","published":"2025-03-31T13:13:47Z"}
{"aid":"http://arxiv.org/abs/2503.24052v1","title":"Accelerated Airfoil Design Using Neural Network Approaches","summary":"In this paper, prediction of airfoil shape from targeted pressure\ndistribution (suction and pressure sides) and vice versa is demonstrated using\nboth Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs)\ntechniques. The dataset is generated for 1600 airfoil shapes, with simulations\ncarried out at Reynolds numbers (Re) ranging from 10,000 and 90,00,000 and\nangles of attack (AoA) ranging from 0 to 15 degrees, ensuring the dataset\ncaptured diverse aerodynamic conditions. Five different CNN and DNN models are\ndeveloped depending on the input/output parameters. Results demonstrate that\nthe refined models exhibit improved efficiency, with the DNN model achieving a\nmulti-fold reduction in training time compared to the CNN model for complex\ndatasets consisting of varying airfoil, Re, and AoA. The predicted airfoil\nshapes/pressure distribution closely match the targeted values, validating the\neffectiveness of deep learning frameworks. However, the performance of CNN\nmodels is found to be better compared to DNN models. Lastly, a flying wing\naircraft model of wingspan >10 m is considered for the prediction of pressure\ndistribution along the chordwise. The proposed CNN and DNN models show\npromising results. This research underscores the potential of deep learning\nmodels accelerating aerodynamic optimization and advancing the design of\nhigh-performance airfoils.","main_category":"cs.LG","categories":"cs.LG,math-ph,math.MP,physics.app-ph,physics.flu-dyn,physics.space-ph","published":"2025-03-31T13:14:14Z"}
{"aid":"http://arxiv.org/abs/2503.24054v1","title":"Infinite matrix associated to sequences","summary":"In this paper, we study the Euler-Seidel matrices with coefficients and\ndetermine the associated Riordan matrix to a given matrix, if it does exist.\nComputation of the generating fonction of the final sequence is established by\nthe associated Riordan matrix. Applications are given.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:15:17Z"}
{"aid":"http://arxiv.org/abs/2503.24092v1","title":"New universal operator approximation theorem for encoder-decoder\n  architectures (Preprint)","summary":"Motivated by the rapidly growing field of mathematics for operator\napproximation with neural networks, we present a novel universal operator\napproximation theorem for a broad class of encoder-decoder architectures. In\nthis study, we focus on approximating continuous operators in\n$\\mathcal{C}(\\mathcal{X}, \\mathcal{Y})$, where $\\mathcal{X}$ and $\\mathcal{Y}$\nare infinite-dimensional normed or metric spaces, and we consider uniform\nconvergence on compact subsets of $\\mathcal{X}$. Unlike standard results in the\noperator learning literature, we investigate the case where the approximating\noperator sequence can be chosen independently of the compact sets. Taking a\ntopological perspective, we analyze different types of operator approximation\nand show that compact-set-independent approximation is a strictly stronger\nproperty in most relevant operator learning frameworks. To establish our\nresults, we introduce a new approximation property tailored to encoder-decoder\narchitectures, which enables us to prove a universal operator approximation\ntheorem ensuring uniform convergence on every compact subset. This result\nunifies and extends existing universal operator approximation theorems for\nvarious encoder-decoder architectures, including classical DeepONets,\nBasisONets, special cases of MIONets, architectures based on frames and other\nrelated approaches.","main_category":"math.FA","categories":"math.FA,cs.LG,math.GN","published":"2025-03-31T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2503.24093v1","title":"Active Reconfigurable Intelligent Surfaces: Circuit Modeling and\n  Reflection Amplification Optimization","summary":"Reconfigurable Intelligent Surfaces (RISs) constitute a promising emerging\ntechnology that enables wireless systems to control the propagation environment\nto enhance diverse communication objectives. To mitigate double-fading\nattenuation in RIS-aided links, the paradigm of active metamaterials capable of\namplifying their incident wave has emerged. In this paper, capitalizing on the\ninherent negative-resistance region of tunnel diodes, we propose their\nintegration into each RIS unit element to enable RISs with reflection\namplification entirely in the analog domain. We derive novel realistic\nphase-amplitude relationships and power constraints specific to this model,\naddressing gaps in the existing literature where amplitude limits are often\nchosen arbitrarily. This characterization of our active RIS unit elements is\nincorporated into two novel optimization frameworks targeting the spectral\nefficiency maximization of RIS-assisted Multiple-Input-Multiple-Output (MIMO)\nsystems, which are solved via an one-step approach and an iterative Alternating\nOptimization (AO) method. The former approach is used to initialize the AO\nframework, enhancing both its performance and convergence. Our numerical\ninvestigations emphasize the importance of accurately modeling phase-amplitude\ndependencies, and provide key insights into the impact of RIS-induced noise as\nwell as the trade-off between available power and the number of active\nelements.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T13:44:03Z"}
{"aid":"http://arxiv.org/abs/2503.24117v1","title":"Organizations, teams, and job mobility: A social microdynamics approach","summary":"The internal structures of large organizations determine much of what occurs\ninside including the way in which tasks are performed, the workers that perform\nthem, and the mobility of those workers within the organization. However,\nregarding this latter process, most of the theoretical and modeling approaches\nused to understand organizational worker mobility are highly stylized, using\nidealizations such as structureless organizations, indistinguishable workers,\nand a lack of social bonding of the workers. In this article, aided by a decade\nof precise, temporally resolved data of a large US government organization, we\nintroduce a new model to describe organizations as composites of teams within\nwhich individuals perform specific tasks and where social connections develop.\nBy tracking the personnel composition of organizational teams, we find that\nworkers that change jobs are highly influenced by preferring to reunite with\npast co-workers. In this organization, 34\\% of all moves lead to worker\nreunions, a percentage well-above expectation. We find that the greater the\ntime workers spend together or the smaller the team they share both increase\ntheir likelihood to reunite, supporting the notion of increased familiarity and\ntrust behind such reunions and the dominant role of social capital in the\nevolution of large organizations.","main_category":"cs.CE","categories":"cs.CE","published":"2025-03-31T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2503.24121v1","title":"IMPACT: A Generic Semantic Loss for Multimodal Medical Image\n  Registration","summary":"Image registration is fundamental in medical imaging, enabling precise\nalignment of anatomical structures for diagnosis, treatment planning,\nimage-guided treatment or longitudinal monitoring. This work introduces IMPACT\n(Image Metric with Pretrained model-Agnostic Comparison for Transmodality\nregistration), a generic semantic similarity metric designed for seamless\nintegration into diverse image registration frameworks (such as Elastix and\nVoxelmorph). It compares deep learning-based features extracted from medical\nimages without requiring task-specific training, ensuring broad applicability\nacross various modalities. By leveraging the features of the large-scale\npretrained TotalSegmentator models and the ability to integrate Segment\nAnything Model (SAM) and other large-scale segmentation networks, this approach\noffers significant advantages. It provides robust, scalable, and efficient\nsolutions for multimodal image registration. The IMPACT loss was evaluated on\nfive challenging registration tasks involving thoracic CT/CBCT, and pelvic\nMR/CT datasets. Quantitative metrics, such as Target Registration Error and\nDice Similarity Coefficient, demonstrated significant improvements in\nanatomical alignment compared to baseline methods. Qualitative analyses further\nconfirmed the increased robustness of the proposed metric in the face of noise,\nartifacts, and modality variations. IMPACT's versatility and efficiency make it\na valuable tool for advancing registration performance in clinical and research\napplications, addressing critical challenges in multimodal medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:08:21Z"}
{"aid":"http://arxiv.org/abs/2503.24122v1","title":"Position-Momenta Uncertainties in Classical Systems","summary":"We design a thermal bath that preserves the conservation of a system's\nangular momentum or allows it to fluctuate around a specified nonzero mean\nwhile maintaining a Boltzmann distribution of energy in the steady state.We\ndemonstrate that classical particles immersed in such baths exhibit\nposition-momentum uncertainties with a strictly positive lower bound\nproportional to the absolute value of the mean angular momentum. The\nproportionality constant, $c$, is dimensionless and independent of the system's\nparameters. Remarkably, while $c$ is universally bounded by unity, it attains\nthe exact value $c=1/2$ for particles in central potentials.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-03-31T14:08:41Z"}
{"aid":"http://arxiv.org/abs/2503.24138v1","title":"AI-Assisted Colonoscopy: Polyp Detection and Segmentation using\n  Foundation Models","summary":"In colonoscopy, 80% of the missed polyps could be detected with the help of\nDeep Learning models. In the search for algorithms capable of addressing this\nchallenge, foundation models emerge as promising candidates. Their zero-shot or\nfew-shot learning capabilities, facilitate generalization to new data or tasks\nwithout extensive fine-tuning. A concept that is particularly advantageous in\nthe medical imaging domain, where large annotated datasets for traditional\ntraining are scarce. In this context, a comprehensive evaluation of foundation\nmodels for polyp segmentation was conducted, assessing both detection and\ndelimitation. For the study, three different colonoscopy datasets have been\nemployed to compare the performance of five different foundation models,\nDINOv2, YOLO-World, GroundingDINO, SAM and MedSAM, against two benchmark\nnetworks, YOLOv8 and Mask R-CNN. Results show that the success of foundation\nmodels in polyp characterization is highly dependent on domain specialization.\nFor optimal performance in medical applications, domain-specific models are\nessential, and generic models require fine-tuning to achieve effective results.\nThrough this specialization, foundation models demonstrated superior\nperformance compared to state-of-the-art detection and segmentation models,\nwith some models even excelling in zero-shot evaluation; outperforming\nfine-tuned models on unseen data.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-03-31T14:20:53Z"}
{"aid":"http://arxiv.org/abs/2503.24155v1","title":"The Belle II Experiment at SuperKEKB -- Input to the European Particle\n  Physics Strategy","summary":"Belle II is an intensity-frontier experiment at the SuperKEKB collider in\nTsukuba, Japan. Over the coming decades, it will record the decays of billions\nof bottom mesons, charm hadrons, and tau leptons produced in 10 GeV\nelectron-positron collisions. The experiment's low-background environment and\nprecisely known kinematics enable high-precision measurements of hundreds of\nStandard Model (SM) parameters while probing for new particles at mass scales\nfar beyond the direct reach of high-energy colliders. We project Belle II's\nsensitivity for key measurements - where it will be uniquely positioned or\nworld-leading - over datasets ranging from 1 to 50 ab${}^{-1}$. By exploring\npreviously uncharted regions of non-SM parameter space with high precision,\nBelle II will either reveal new physics or set stringent constraints, guiding\nfuture experimental and theoretical efforts. Additionally, we outline near-term\nupgrades to the Belle II detector and SuperKEKB accelerator, which will enhance\nsensitivity in searches for new physics beyond the SM across flavor, tau,\nelectroweak, and dark sector physics. These improvements will ensure that Belle\nII remains both complementary to and competitive with the LHC and other\nexperiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-03-31T14:39:29Z"}
{"aid":"http://arxiv.org/abs/2503.24160v1","title":"A Comparative Study of Scanpath Models in Graph-Based Visualization","summary":"Information Visualization (InfoVis) systems utilize visual representations to\nenhance data interpretation. Understanding how visual attention is allocated is\nessential for optimizing interface design. However, collecting Eye-tracking\n(ET) data presents challenges related to cost, privacy, and scalability.\nComputational models provide alternatives for predicting gaze patterns, thereby\nadvancing InfoVis research. In our study, we conducted an ET experiment with 40\nparticipants who analyzed graphs while responding to questions of varying\ncomplexity within the context of digital forensics. We compared human scanpaths\nwith synthetic ones generated by models such as DeepGaze, UMSS, and Gazeformer.\nOur research evaluates the accuracy of these models and examines how question\ncomplexity and number of nodes influence performance. This work contributes to\nthe development of predictive modeling in visual analytics, offering insights\nthat can enhance the design and effectiveness of InfoVis systems.","main_category":"cs.HC","categories":"cs.HC,cs.CV","published":"2025-03-31T14:43:42Z"}
{"aid":"http://arxiv.org/abs/2503.24173v1","title":"Worldvolume fermion as baryon with homogeneous instantons in holographic\n  $\\mathrm{QCD}_{3}$","summary":"We investigate holographically the effective theory of the worldvolume\nfermion on the flavor branes in the D3/D7 model with homogeneously smeared\nD(-1)-branes. As a top-down approach in gauge-gravity duality, the D(-1)-branes\nare instantons and violate the CP symmetry in the dual theory. The background\ngeometry of this model contains black brane (deconfined geometry) and bubble\nD3-brane solutions (confined geometry), all with a non-zero Romand-Romand zero\nform as axion. The dual theories to the backgrounds are respectively the Super\nYang-Mills theory at finite temperature and three-dimensional confining\nYang-Mills theory, all with a Chern-Simons term induced by instantons. In the\nconfined geometry, we introduce a baryon vertex as a D5-brane wrapped on\n$S^{5}$, then identify the fermionic flux on the D7-brane as a baryonic\noperator. Afterwards, we study the spectrum and the holographic correlation\nfunction of the flavored fermion on the D7-branes. Remarkably, the fermionic\nspectrum is in agreement with the dispersion curves obtained from the confined\ncorrelation function, and the mass ratio of the lowest baryon and meson in our\nmodel is close to the associated experimental data. Moreover, the effective\ninteraction terms of the holographic baryon and meson are derived and all the\ncoupling constants take order of $N_{c}^{1/2}$ agreeing with the evaluation\nfrom the large N field theory. In the deconfined geometry, the holographic\ncorrelation function is also evaluated numerically while the fermion on\nD7-brane is identified to plasmino instead of baryon. The dispersion curves\nfrom the deconfined correlation function basically covers the results from the\nhard thermal loop approximation and may imply the instanton-induced interaction\nwith spin. Overall, this work constructs a holographic theory about baryonic\nfermion and mesonic boson with instantons or CP violation.","main_category":"hep-th","categories":"hep-th,hep-ph,nucl-th","published":"2025-03-31T14:51:40Z"}
{"aid":"http://arxiv.org/abs/2503.24174v1","title":"Low-energy electron microscopy as a tool for analysis of self-assembled\n  molecular layers on surfaces","summary":"Low-energy electron microscopy (LEEM) is a surface science method that works\nprimarily in the UHV environment. It provides information complementary to the\nother established techniques: it extends the limited view of scanning probe\nmicroscopies from nanometers to micrometers and measurement time down to tens\nof milliseconds, enabling to visualize the changes during sample treatment,\ne.g., annealing, deposition, and gas or light exposure. From the point of\nstructural analysis, it allows the measurement of diffraction patterns from an\narea of diameter below 200 nm and imaging of phase distribution on the surfaces\neither through dark-filed imaging or LEEM-I(V) fingerprinting. The advanced\nmodes provide local angle-resolved photoelectron spectra and surface potential\ndistribution. In this review, we aim to describe the utilization of LEEM to\nstudy self-assembled molecular structures on solid surfaces. We present the\nLEEM instrumentation and analysis of measured data in a tutorial way to provide\nthe necessary background knowledge to enter the field. In the second part, we\nsummarize the knowledge obtained by LEEM for several selected systems, which\npoints to the strength of LEEM in understanding the self-assembled molecular\nsystems and its synergy with other surface science techniques.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T14:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.24176v1","title":"Tunable macroscopic defect patterns induced by a low-frequency AC\n  electric field in ferroelectric nematic liquid crystals","summary":"Regulation of topological structures and pattern formation is attracting wide\ninterest in the field of condensed matter. Liquid crystals (LCs) represent soft\nmatter with a remarkable combination of fluidity and anisotropic properties.\nTopological defects may appear in confined LCs under external stimuli. Recently\ndiscovered ferroelectric nematics (NF) opened exceptional opportunities in\ntechnologies owing to high permittivity and polarisation. Polar properties of\nNF supply more variability to topological structures. In this research, we\npresent tunable 2D topological defect arrays in NF compound, induced by an\nalternating (AC) electric field in simple sandwich cells without\npre-patterning. The observed arrays of defects form pseudo-square lattices,\nwhich character and periodicity depend on the frequency of the applied field\nand partially on the cell thickness. The observed effect is explained to occur\ndue to the competition between elastic and electrical forces. The proposed\nsystem can be useful to create reconfigurable spatially periodic polarisation\nstructures.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T14:53:41Z"}
{"aid":"http://arxiv.org/abs/2503.24225v1","title":"Compressible N-phase fluid mixture models","summary":"Fluid mixture models are essential for describing a wide range of physical\nphenomena, including wave dynamics and spinodal decomposition. However, there\nis a lack of consensus in the modeling of compressible mixtures, with limited\nconnections between different classes of models. On the one hand, existing\ncompressible two-phase flow models accurately describe wave dynamics, but do\nnot incorporate phase separation mechanisms. On the other hand, phase-field\ntechnology in fluid dynamics consists of models incorporating spinodal\ndecomposition, however, a general phase-field theory for compressible mixtures\nremains largely undeveloped.\n  In this paper, we take an initial step toward bridging the gap between\ncompressible two-phase flow models and phase-field models by developing a\ntheory for compressible, isothermal N-phase mixtures. Our theory establishes a\nsystem of reduced complexity by formulating N mass balance laws alongside a\nsingle momentum balance law, thereby naturally extending the Navier-Stokes\nKorteweg model to N-phases and providing the Navier-Stokes\nCahn-Hilliard/Allen-Cahn model for compressible mixtures. Key aspects of the\nframework include its grounding in continuum mixture theory and its\npreservation of thermodynamic consistency despite its reduced complexity.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.AP,math.MP","published":"2025-03-31T15:38:49Z"}
{"aid":"http://arxiv.org/abs/2503.24231v1","title":"Distinct parallel electrostatic collisionless shocks in hot-cold\n  ablative mixing plasmas","summary":"Hot-cold ablative mixing plasmas are ubiquitous in astrophysical and\nlaboratory systems, where a cold/dense plasma is roughly in pressure balance\nwith a hot/dilute plasma. Examples include the plasma thermal quench during\nmajor disruptions in tokamaks, interaction between a central hot-spot and the\nsolid liner in an inertial confinement fusion (ICF) capsule, and the formation\nof large-scale structures in galaxy clusters. In such systems, a parallel\nelectrostatic collisionless shock forms and plays a critical role in both the\nthermal collapse of the hot plasma and the ablative mixing of cold ions. The\nformation and dynamics of such shocks are investigated by employing\none-dimensional VPIC simulations and theoretical analyses, revealing key\ndifferences from the well-studied collisionless shocks where an over-pressured,\nhigh-density plasma expands into a rarefied background. Notably, the shock\nformation has a weak dependence on the plasma pressure, provided that the\ndensity ratio between the cold and hot plasmas is large. Instead, the shock is\nprimarily governed by the plasma temperatures on both sides. The collisionless\nelectron thermal conduction flux in both upstream and downstream regions\nfollows the free-streaming limit itself, but its spatial gradient exhibits\nconvective scaling, ensuring the same characteristic length scale of the\nelectron temperature and density evolution.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-03-31T15:44:34Z"}
{"aid":"http://arxiv.org/abs/2503.24233v1","title":"Input from the SND@LHC collaboration to the 2026 Update to the European\n  Strategy for Particle Physics","summary":"By observing collider neutrino interactions of different flavours, the\nSND@LHC and Faser experiments have shown that the LHC can make interesting\ncontributions to neutrino physics. This document summarizes why the SND@LHC\nCollaboration intends to continue taking data at the High Luminosity LHC\n(HL-LHC). The upgraded detector will instrument the regions of both the\nneutrino vertex and the magnetized calorimeter with silicon microstrips. The\nuse of this technology will allow us to continue the physics program of the\ncurrent SND@LHC detector with higher statistics. It will also offer new\npossibilities. For instance, the magnetization of the hadron calorimeter will\nenable the separation between neutrinos and antineutrinos. This could lead to\nthe first direct observation of tau antineutrinos. The use of ultrafast timing\nlayers will enable triggers to be sent to ATLAS, potentially allowing the\nidentification of the charm quark pair that produced the neutrino interacting\nin the detector. Such tagging of the neutrino source would fulfill Pontecorvo\noriginal proposal of a tagged neutrino beam. The experiment will perform unique\nmeasurements with high energy neutrinos and will also provide a means to\nmeasure gluon parton distribution functions in a previously unexplored domain\n(Bjorkenx <10^-5). Furthermore, the technological advancements of the upgrade\nand the experience that will be gained in the areas of operation and data\nanalysis will play a crucial role in the design of the neutrino detector for\nthe SHiP experiment.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T15:45:38Z"}
{"aid":"http://arxiv.org/abs/2503.24243v1","title":"Music Information Retrieval on Representative Mexican Folk Vocal\n  Melodies Through MIDI Feature Extraction","summary":"This study analyzes representative Mexican folk vocal melodies using MIDI\nfeature extraction, examining ambitus, pitch-class entropy, and interval\ndistribution. It also explores the relationship between these features and song\npopularity, as measured by Spotify plays. The study employs MATLAB and the MIDI\nToolbox for extracting musical features and performing statistical analysis.\nThe findings reveal a significant variation in ambitus, with values ranging\nfrom 8 to 27 semitones, indicating a diverse compositional style and vocal\ndemand across the genre. The analysis of pitch-class entropy showcases a broad\nspectrum of melodic complexity, with Armando Manzanero's `Somos Novios'\ndisplaying the highest entropy, suggesting varied and complex melodic\nstructures, while traditional pieces like `La Bamba' exhibit lower entropy,\nindicating simpler, more repetitive patterns. The interval distribution\npredominantly features prime intervals (P1), major and minor seconds (M2, m2),\npointing to a compositional preference for close, contiguous intervals that\ncontribute to the melodies' accessibility and appeal. Statistical analysis do\nnot establish a significant correlation between the ambitus or entropy and the\nnumber of Spotify plays.","main_category":"cs.SD","categories":"cs.SD,cs.IR","published":"2025-03-31T15:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.24253v1","title":"Deep Learning-Based Data Fusion of 6G Sensing and Inertial Information\n  for Target Positioning: Experimental Validation","summary":"The sixth-generation (6G) cellular technology will be deployed with a key\nfeature of Integrated Sensing and Communication (ISAC), allowing the cellular\nnetwork to map the environment through radar sensing on top of providing\ncommunication services. In this regard, the entire network can be considered as\na sensor with a broader Field of View (FoV) of the environment, assisting in\nboth the positioning of active and detection of passive targets. On the other\nhand, the non-3GPP sensors available on the target can provide additional\ninformation specific to the target that can be beneficially combined with ISAC\nsensing information to enhance the overall achievable positioning accuracy. In\nthis paper, we first study the performance of the ISAC system in terms of its\nachievable accuracy in positioning the mobile target in an indoor scenario.\nSecond, we study the performance gain achieved in the ISAC positioning accuracy\nafter fusing the information from the target's non-3GPP sensors. To this end,\nwe propose a novel data fusion solution based on the deep learning framework to\nfuse the information from ISAC and non-3GPP sensors.\n  We validate our proposed data fusion and positioning solution with a\nreal-world ISAC Proof-of-Concept (PoC) as the wireless infrastructure, an\nAutomated Guided Vehicle (AGV) as the target, and the Inertial Measurement Unit\n(IMU) sensor on the target as the non-3GPP sensor. The experimental results\nshow that our proposed solution achieves an average positioning error of\n$3~\\textrm{cm}$, outperforming the considered baselines.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T16:02:17Z"}
{"aid":"http://arxiv.org/abs/2503.24254v1","title":"PromoPlot: Covering open-access fees by filling wasted space in corner\n  plots","summary":"In an effort to reduce drain on grant funds and decrease unused space in\npublications, we have developed a Python package for inserting advertisements\ninto the space left empty by corner plots. This novel technique can allow\nauthors to reduce or eliminate publication charges for journals such as MNRAS\nand ApJ. In order to offset publication costs entirely, we recommend that\nauthors include anywhere from 200-700 corner plots per paper, with the exact\nnumber depending on the journal used. Finally, we discuss other opportunities\nto generate ad revenue through publications.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T16:02:37Z"}
{"aid":"http://arxiv.org/abs/2503.24256v1","title":"Ranked percolation model for the caking time of amorphous molecular\n  powders","summary":"When amorphous molecular powders are exposed to high humidity levels or\ntemperatures, the particle viscosity increases due to plasticization, promoting\nthe formation of sinter bridges between pairs of particles in contact. Over\ntime, these bridges facilitate particle agglomeration, eventually leading to\nthe formation of a macroscopic cake that alters the mechanical properties and\naffects product quality. In this work, we model the caking process of amorphous\npowders subjected to a temperature shock as a bond percolation problem and\ninvestigate how particle bed heterogeneities influence the percolation\nthreshold and, consequently, the expected caking times. Our findings indicate\nthat a slight dispersion in particle size lowers the percolation threshold\ncompared to a monodisperse bed or random percolation in polydisperse systems.\nFurthermore, we show that the expected caking time exhibits a non-monotonic\nbehavior with the size dispersion, initially decreasing for low dispersion\nvalues and increasing for higher values. These results provide insights into\nthe role of the particle size distribution on the caking dynamics of amorphous\nmolecular powders","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-03-31T16:03:56Z"}
{"aid":"http://arxiv.org/abs/2503.24260v1","title":"MaintainCoder: Maintainable Code Generation Under Dynamic Requirements","summary":"Modern code generation has made significant strides in functional correctness\nand execution efficiency. However, these systems often overlook a critical\ndimension in real-world software development: maintainability. To handle\ndynamic requirements with minimal rework, we propose MaintainCoder as a\npioneering solution. It integrates Waterfall model, design patterns, and\nmulti-agent collaboration to systematically enhance cohesion, reduce coupling,\nand improve adaptability. We also introduce MaintainBench, a benchmark\ncomprising requirement changes and corresponding dynamic metrics on\nmaintainance effort. Experiments demonstrate that existing code generation\nmethods struggle to meet maintainability standards when requirements evolve. In\ncontrast, MaintainCoder improves maintainability metrics by 14-30% with even\nhigher correctness, i.e. pass@k. Our work not only provides the foundation of\nmaintainable code generation, but also highlights the need for more holistic\ncode quality research. Resources:\nhttps://github.com/IAAR-Shanghai/MaintainCoder.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24262v1","title":"New Statistical Framework for Extreme Error Probability in High-Stakes\n  Domains for Reliable Machine Learning","summary":"Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ME,stat.ML","published":"2025-03-31T16:08:11Z"}
{"aid":"http://arxiv.org/abs/2503.24272v1","title":"Learning Velocity and Acceleration: Self-Supervised Motion Consistency\n  for Pedestrian Trajectory Prediction","summary":"Understanding human motion is crucial for accurate pedestrian trajectory\nprediction. Conventional methods typically rely on supervised learning, where\nground-truth labels are directly optimized against predicted trajectories. This\namplifies the limitations caused by long-tailed data distributions, making it\ndifficult for the model to capture abnormal behaviors. In this work, we propose\na self-supervised pedestrian trajectory prediction framework that explicitly\nmodels position, velocity, and acceleration. We leverage velocity and\nacceleration information to enhance position prediction through feature\ninjection and a self-supervised motion consistency mechanism. Our model\nhierarchically injects velocity features into the position stream. Acceleration\nfeatures are injected into the velocity stream. This enables the model to\npredict position, velocity, and acceleration jointly. From the predicted\nposition, we compute corresponding pseudo velocity and acceleration, allowing\nthe model to learn from data-generated pseudo labels and thus achieve\nself-supervised learning. We further design a motion consistency evaluation\nstrategy grounded in physical principles; it selects the most reasonable\npredicted motion trend by comparing it with historical dynamics and uses this\ntrend to guide and constrain trajectory generation. We conduct experiments on\nthe ETH-UCY and Stanford Drone datasets, demonstrating that our method achieves\nstate-of-the-art performance on both datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T16:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24288v1","title":"Magnetic Confinement of a Bubble of Supercooled $^3$He-A","summary":"We have designed and constructed a magnet surrounding a cylindrical volume of\nsuperfluid helium-3 to isolate a region of metastable, supercooled A-phase,\nentirely surrounded by bulk A-phase - isolating the 'bubble' from rough\nsurfaces that can trigger the transition to the stable B-phase. We outline the\ndesign of the experimental cell and magnet, and show that the performance of\nthe magnet is consistent with simulations, including the capability to\nproducing the high field gradient required for generating a bubble. Future\nplans include the investigation of possible intrinsic mechanisms underpinning\nthe A-B transition, with potential implications for early-universe cosmological\nphase transitions.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-03-31T16:35:56Z"}
{"aid":"http://arxiv.org/abs/2503.24296v1","title":"Fair Dynamic Spectrum Access via Fully Decentralized Multi-Agent\n  Reinforcement Learning","summary":"We consider a decentralized wireless network with several source-destination\npairs sharing a limited number of orthogonal frequency bands. Sources learn to\nadapt their transmissions (specifically, their band selection strategy) over\ntime, in a decentralized manner, without sharing information with each other.\nSources can only observe the outcome of their own transmissions (i.e., success\nor collision), having no prior knowledge of the network size or of the\ntransmission strategy of other sources. The goal of each source is to maximize\ntheir own throughput while striving for network-wide fairness. We propose a\nnovel fully decentralized Reinforcement Learning (RL)-based solution that\nachieves fairness without coordination. The proposed Fair Share RL (FSRL)\nsolution combines: (i) state augmentation with a semi-adaptive time reference;\n(ii) an architecture that leverages risk control and time difference\nlikelihood; and (iii) a fairness-driven reward structure. We evaluate FSRL in\nmore than 50 network settings with different number of agents, different\namounts of available spectrum, in the presence of jammers, and in an ad-hoc\nsetting. Simulation results suggest that, when we compare FSRL with a common\nbaseline RL algorithm from the literature, FSRL can be up to 89.0% fairer (as\nmeasured by Jain's fairness index) in stringent settings with several sources\nand a single frequency band, and 48.1% fairer on average.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T16:42:11Z"}
{"aid":"http://arxiv.org/abs/2503.24301v1","title":"QUADRO: A Hybrid Quantum Optimization Framework for Drone Delivery","summary":"Quantum computing holds transformative potential for optimizing large-scale\ndrone fleet operations, yet its near-term limitations necessitate hybrid\napproaches blending classical and quantum techniques. This work introduces\nQuantum Unmanned Aerial Delivery Routing Optimization (QUADRO), a novel hybrid\nframework addressing the Energy-Constrained Capacitated Unmanned Aerial Vehicle\nRouting Problem and the Unmanned Aerial Vehicle Scheduling Problem. By\nformulating these challenges as Quadratic Unconstrained Binary Optimization\nproblems, QUADRO leverages the Quantum Approximate Optimization Algorithm for\nrouting and scheduling, enhanced by classical heuristics and post-processing.\nWe minimize total transit time in routing, considering payload and battery\nconstraints, and optimize makespan scheduling across various drone fleets.\nEvaluated on adapted Augerat benchmarks (16-51 nodes), QUADRO competes against\nclassical and prior hybrid methods, achieving scalable solutions with fewer\nthan one hundred qubits. The proposed results underscore the viability of\nhybrid quantum-classical strategies for real-world drone logistics, paving the\nway for quantum-enhanced optimization in the Noisy Intermediate Scale Quantum\nera.","main_category":"cs.ET","categories":"cs.ET","published":"2025-03-31T16:44:42Z"}
{"aid":"http://arxiv.org/abs/2503.24311v1","title":"Selective Inference in Graphical Models via Maximum Likelihood","summary":"The graphical lasso is a widely used algorithm for fitting undirected\nGaussian graphical models. However, for inference on functionals of edge values\nin the learned graph, standard tools lack formal statistical guarantees, such\nas control of the type I error rate. In this paper, we introduce a selective\ninference method for asymptotically valid inference after graphical lasso\nselection with added randomization. We obtain a selective likelihood,\nconditional on the event of selection, through a change of variable on the\nknown density of the randomization variables. Our method enables interval\nestimation and hypothesis testing for a wide range of functionals of edge\nvalues in the learned graph using the conditional maximum likelihood estimate.\nOur numerical studies show that introducing a small amount of randomization:\n(i) greatly increases power and yields substantially shorter intervals compared\nto other conditional inference methods, including data splitting; (ii) ensures\nintervals of bounded length in high-dimensional settings where data splitting\nis infeasible due to insufficient samples for inference; (iii) enables\ninference for a wide range of inferential targets in the learned graph,\nincluding measures of node influence and connectivity between nodes.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-03-31T16:57:04Z"}
{"aid":"http://arxiv.org/abs/2503.24315v1","title":"Multiscale Insights of Domain Unfolding in Fibrin Mechanical Response","summary":"Fibrinogen, the monomeric unit of fibrin, the main constituent of blood clot,\nhas a very complex structure. The fibrinogen builds the fibrin fiber and\nnetwork through the half-staggered packing via knob-hole interaction and the\n$\\alpha$C crosslinkers. Due to its rich structure, the elastic behavior also\nshows a unique nature of very high stretchability and multiple regimes in\nstress-strain behaviour, which is not yet fully understood. We develop an\nUnfolding-incorporated Coarse-Grained Polymer (UCGP) model for fibrinogen to\nstudy the effect of domain unfolding on the mechanical behavior of fibrin fiber\nand network. Our model captures the stretching behavior of fibrinogen as\nobserved in AFM and all-atom simulations. We further extend our model to fibrin\nfiber to study the effect of molecular unfolding at the fiber and network\nlevel. We anticipate that our model will be able to account for the nonlinear\nmechanical behavior of crosslinked fibrin gel. It is possibly the first model\nof this sort to consider the precise, controllable knowledge of the effects of\ndomain unfolding in crosslinked proteins. This model can also be used to model\nsystems that have sacrificial bonds.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-03-31T17:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24340v1","title":"Faster Rates for No-Regret Learning in General Games via Cautious\n  Optimism","summary":"We establish the first uncoupled learning algorithm that attains $O(n \\log^2\nd \\log T)$ per-player regret in multi-player general-sum games, where $n$ is\nthe number of players, $d$ is the number of actions available to each player,\nand $T$ is the number of repetitions of the game. Our results exponentially\nimprove the dependence on $d$ compared to the $O(n\\, d \\log T)$ regret\nattainable by Log-Regularized Lifted Optimistic FTRL [Far+22c], and also reduce\nthe dependence on the number of iterations $T$ from $\\log^4 T$ to $\\log T$\ncompared to Optimistic Hedge, the previously well-studied algorithm with $O(n\n\\log d \\log^4 T)$ regret [DFG21]. Our algorithm is obtained by combining the\nclassic Optimistic Multiplicative Weights Update (OMWU) with an adaptive,\nnon-monotonic learning rate that paces the learning process of the players,\nmaking them more cautious when their regret becomes too negative.","main_category":"cs.GT","categories":"cs.GT,cs.LG,math.OC","published":"2025-03-31T17:25:33Z"}
{"aid":"http://arxiv.org/abs/2503.24358v1","title":"SQuat: Subspace-orthogonal KV Cache Quantization","summary":"The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.IT,math.IT","published":"2025-03-31T17:37:32Z"}
{"aid":"http://arxiv.org/abs/2503.24368v1","title":"Adapting Vision Foundation Models for Real-time Ultrasound Image\n  Segmentation","summary":"We propose a novel approach that adapts hierarchical vision foundation models\nfor real-time ultrasound image segmentation. Existing ultrasound segmentation\nmethods often struggle with adaptability to new tasks, relying on costly manual\nannotations, while real-time approaches generally fail to match\nstate-of-the-art performance. To overcome these limitations, we introduce an\nadaptive framework that leverages the vision foundation model Hiera to extract\nmulti-scale features, interleaved with DINOv2 representations to enhance visual\nexpressiveness. These enriched features are then decoded to produce precise and\nrobust segmentation. We conduct extensive evaluations on six public datasets\nand one in-house dataset, covering both cardiac and thyroid ultrasound\nsegmentation. Experiments show that our approach outperforms state-of-the-art\nmethods across multiple datasets and excels with limited supervision,\nsurpassing nnUNet by over 20\\% on average in the 1\\% and 10\\% data settings.\nOur method achieves $\\sim$77 FPS inference speed with TensorRT on a single GPU,\nenabling real-time clinical applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:47:42Z"}
{"aid":"http://arxiv.org/abs/2503.24378v1","title":"ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning","summary":"The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T17:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01323v1","title":"The optimal strong convergence rates of the truncated EM and logarithmic\n  truncated EM methods for multi-dimensional nonlinear stochastic differential\n  equations","summary":"The truncated Euler--Maruyama (EM) method, developed by Mao (2015), is used\nto solve multi-dimensional nonlinear stochastic differential equations (SDEs).\nHowever, its convergence rate is suboptimal due to an unnecessary infinitesimal\nfactor. The primary goal of this paper is to demonstrate the optimal\nconvergence of the truncated EM method without infinitesimal factors. Besides,\nthe logarithmic truncated EM method has not been studied in multi-dimensional\ncases, which is the other goal of this paper. We will show the optimal strong\nconvergence order of the positivity-preserving logarithmic truncated EM method\nfor solving multi-dimensional SDEs with positive solutions. Numerical examples\nare given to support our theoretical conclusions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T03:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.01350v1","title":"Intuitive Human-Drone Collaborative Navigation in Unknown Environments\n  through Mixed Reality","summary":"Considering the widespread integration of aerial robots in inspection, search\nand rescue, and monitoring tasks, there is a growing demand to design intuitive\nhuman-drone interfaces. These aim to streamline and enhance the user\ninteraction and collaboration process during drone navigation, ultimately\nexpediting mission success and accommodating users' inputs. In this paper, we\npresent a novel human-drone mixed reality interface that aims to (a) increase\nhuman-drone spatial awareness by sharing relevant spatial information and\nrepresentations between the human equipped with a Head Mounted Display (HMD)\nand the robot and (b) enable safer and intuitive human-drone interactive and\ncollaborative navigation in unknown environments beyond the simple command and\ncontrol or teleoperation paradigm. We validate our framework through extensive\nuser studies and experiments in a simulated post-disaster scenarios, comparing\nits performance against a traditional First-Person View (FPV) control systems.\nFurthermore, multiple tests on several users underscore the advantages of the\nproposed solution, which offers intuitive and natural interaction with the\nsystem. This demonstrates the solution's ability to assist humans during a\ndrone navigation mission, ensuring its safe and effective execution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T04:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.01368v1","title":"Proton cumulants from hydrodynamics in light of new STAR data","summary":"New measurements of proton number cumulants from the Beam Energy Scan Phase\nII (BES-II) program at RHIC by the STAR Collaboration provide unprecedented\nprecision and insights into the properties of strongly interacting matter. This\nreport discusses the measurements in the context of predictions from\nhydrodynamics, emphasizing the enhanced sensitivity of factorial cumulants and\ntheir implications for the search for the QCD critical point. The experimental\ndata shows enhancement of second-order factorial cumulants and suppression of\nthird-order factorial cumulants relative to the non-critical baseline at $7.7 <\n\\sqrt{s_{\\rm NN}} \\lesssim 10$ GeV. We discuss implications of this observation\nfor the possible location of the critical point in the QCD phase diagram and\nopportunities for future measurements of acceptance dependence of factorial\ncumulants.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-02T05:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01375v1","title":"Simultaneous Pre-compensation for Bandwidth Limitation and Fiber\n  Dispersion in Cost-Sensitive IM/DD Transmission Systems","summary":"We propose a pre-compensation scheme for bandwidth limitation and fiber\ndispersion (pre-BL-EDC) based on the modified Gerchberg-Saxton (GS) algorithm.\nExperimental results demonstrate 1.0/1.0/2.0 dB gains compared to modified GS\npre-EDC for 20/28/32 Gbit/s bandwidth-limited systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T05:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.01387v1","title":"Derived McKay correspondence for real reflection groups of rank three","summary":"We describe the derived McKay correspondence for real reflection groups of\nrank $3$ in terms of a maximal resolution of the logarithmic pair consisting of\nthe quotient variety and the discriminant divisor with coefficient\n$\\frac{1}{2}$. As an application, we verify a conjecture by Polishchuk and Van\nden Bergh on the existence of a certain semiorthgonal decomposition of the\nequivariant derived category into the derived categories of affine spaces for\nany real reflection group of rank $3$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T05:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01389v1","title":"De Novo Molecular Design Enabled by Direct Preference Optimization and\n  Curriculum Learning","summary":"De novo molecular design has extensive applications in drug discovery and\nmaterials science. The vast chemical space renders direct molecular searches\ncomputationally prohibitive, while traditional experimental screening is both\ntime- and labor-intensive. Efficient molecular generation and screening methods\nare therefore essential for accelerating drug discovery and reducing costs.\nAlthough reinforcement learning (RL) has been applied to optimize molecular\nproperties via reward mechanisms, its practical utility is limited by issues in\ntraining efficiency, convergence, and stability. To address these challenges,\nwe adopt Direct Preference Optimization (DPO) from NLP, which uses molecular\nscore-based sample pairs to maximize the likelihood difference between high-\nand low-quality molecules, effectively guiding the model toward better\ncompounds. Moreover, integrating curriculum learning further boosts training\nefficiency and accelerates convergence. A systematic evaluation of the proposed\nmethod on the GuacaMol Benchmark yielded excellent scores. For instance, the\nmethod achieved a score of 0.883 on the Perindopril MPO task, representing a\n6\\% improvement over competing models. And subsequent target protein binding\nexperiments confirmed its practical efficacy. These results demonstrate the\nstrong potential of DPO for molecular design tasks and highlight its\neffectiveness as a robust and efficient solution for data-driven drug\ndiscovery.","main_category":"cs.LG","categories":"cs.LG,physics.chem-ph,q-bio.BM","published":"2025-04-02T06:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.01392v1","title":"Spatial-Filter-Bank-Based Neural Method for Multichannel Speech\n  Enhancement","summary":"The performance of deep learning-based multi-channel speech enhancement\nmethods often deteriorates when the geometric parameters of the microphone\narray change. Traditional approaches to mitigate this issue typically involve\ntraining on multiple microphone arrays, which can be costly. To address this\nchallenge, we focus on uniform circular arrays and propose the use of a spatial\nfilter bank to extract features that are approximately invariant to geometric\nparameters. These features are then processed by a two-stage conformer-based\nmodel (TSCBM) to enhance speech quality. Experimental results demonstrate that\nour proposed method can be trained on a fixed microphone array while\nmaintaining effective performance across uniform circular arrays with unseen\ngeometric configurations during applications.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-02T06:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.01396v1","title":"All Patches Matter, More Patches Better: Enhance AI-Generated Image\n  Detection via Panoptic Patch Learning","summary":"The exponential growth of AI-generated images (AIGIs) underscores the urgent\nneed for robust and generalizable detection methods. In this paper, we\nestablish two key principles for AIGI detection through systematic analysis:\n\\textbf{(1) All Patches Matter:} Unlike conventional image classification where\ndiscriminative features concentrate on object-centric regions, each patch in\nAIGIs inherently contains synthetic artifacts due to the uniform generation\nprocess, suggesting that every patch serves as an important artifact source for\ndetection. \\textbf{(2) More Patches Better}: Leveraging distributed artifacts\nacross more patches improves detection robustness by capturing complementary\nforensic evidence and reducing over-reliance on specific patches, thereby\nenhancing robustness and generalization. However, our counterfactual analysis\nreveals an undesirable phenomenon: naively trained detectors often exhibit a\n\\textbf{Few-Patch Bias}, discriminating between real and synthetic images based\non minority patches. We identify \\textbf{Lazy Learner} as the root cause:\ndetectors preferentially learn conspicuous artifacts in limited patches while\nneglecting broader artifact distributions. To address this bias, we propose the\n\\textbf{P}anoptic \\textbf{P}atch \\textbf{L}earning (PPL) framework, involving:\n(1) Random Patch Replacement that randomly substitutes synthetic patches with\nreal counterparts to compel models to identify artifacts in underutilized\nregions, encouraging the broader use of more patches; (2) Patch-wise\nContrastive Learning that enforces consistent discriminative capability across\nall patches, ensuring uniform utilization of all patches. Extensive experiments\nacross two different settings on several benchmarks verify the effectiveness of\nour approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T06:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.01413v1","title":"Quantum light sources with configurable lifetime leveraging parity-time\n  symmetry","summary":"Quantum light sources with configurable photon lifetimes are essential for\nlarge-scale quantum circuits, enabling applications in programmable quantum\ncomputing, various quantum key distribution protocols, and quantum tomography\ntechniques. However, the fundamental trade-off between efficiency and photon\nlifetime imposes significant challenges on the design of high-performance large\nconfigurable lifetime quantum light sources. Here, we report on such chip-scale\nquantum light sources by harnessing the unique feature of parity-time (PT)\nsymmetry. The core design centers on employing PT-symmetric coupling between\ntwo microresonators of distinct circumferences, enabling broad-range and\nselective tuning of intracavity photon density of states. By controlling the\nalignment between resonators, we achieved a 38-fold photon lifetime tuning\nrange (4 ~ 158 ps), with the shortest lifetimes near the exceptional points of\nthe PT-symmetric systems. The device generates energy-time entangled photon\npairs with 87.1 +- 1.1% interference visibility and a heralded second-order\nautocorrelation of g_h^((2) ) (0)= 0.069 +- 0.001. Our work highlights the\npotential of PT symmetry for advanced quantum applications, including\nhigh-speed communication and programmable quantum computing, quantum coherent\ntomography, and beyond.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-02T07:04:31Z"}
{"aid":"http://arxiv.org/abs/2504.01421v1","title":"Interacting $p$-form gauge theories: New developments","summary":"Gauge $p$-forms in diverse dimensions are ubiquitous in supergravity and\nstring theory. This work reviews novel covariant formulations designed to\ngenerate arbitrary interacting duality-invariant or chiral (self-dual) $p$-form\ntheories in $d = 2p + 2$ space-time dimensions. For odd $p$, such theories\npossess $\\mathsf{U}(1)$ duality invariance and include the Born-Infeld and\nModMax theories. For even $p$, they describe a self-interacting chiral $p$-form\nwith its gauge-invariant field strength obeying a nonlinear self-duality\ncondition. We provide a complete description of $T\\bar T$-like deformations of\n$\\mathsf{U}(1)$ duality-invariant models for nonlinear electrodynamics in four\ndimensions and their six-dimensional counterparts -- interacting chiral\ntwo-form field theories. We also elaborate on consistent flows in the spaces of\nduality-invariant or chiral (self-dual) $p$-form theories beyond six\ndimensions.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T07:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.01427v1","title":"Observational diversity of bright long-lived Type II supernovae","summary":"In various types of supernovae (SNe), strong interaction between the SN\nejecta and circumstellar material (CSM) has been reported. This raises\nquestions on their progenitors and mass-loss processes shortly before the\nexplosion. Recently, the bright long-lived Type~II SN 2021irp was proposed to\nbe a standard Type II SN interacting with disk-like CSM. The observational\nproperties suggest that the progenitor was a massive star in a binary system\nand underwent a mass-ejection process due to the binary interaction just before\nthe explosion. Here, we study the diversity of the observational properties of\nbright long-lived Type II (21irp-like) SNe. We analyse the diversity of their\nCSM properties, in order to understand their progenitors and mass-loss\nmechanisms and their relations with the other types of interacting SNe. We\nperformed photometry, spectroscopy, and/or polarimetry for four 21irp-like SNe.\nBased on these observations as well as published data of SN~2021irp itself and\nwell-observed bright and long-lived type II SNe including SNe~2010jl, 2015da\nand 2017hcc, we discuss their CSM characteristics. This sample of SNe shows\nluminous and long-lived photometric evolution, with some variations in the\nphotometric evolution (from $\\sim-17$ to $\\sim-20$ absolute mag in the $r$/$o$\nband even at $\\sim 200$ days after the explosion). They show photospheric\nspectra characterized mainly by Balmer lines for several hundreds of days, with\nsome variations in the shapes of the lines. They show high polarization with\nslight variations in the polarization degrees with rapid declines with time\n(from $\\sim3-6$ \\% before the peak to $\\sim1$ \\% at $\\sim200$ days after the\npeak). The observational properties are consistent with the\ndisk-CSM-interaction scenario, i.e., typical Type~II SNe interacting with\ndisk-like CSM.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-02T07:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.01429v1","title":"Refining Interactions: Enhancing Anisotropy in Graph Neural Networks\n  with Language Semantics","summary":"The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.01450v1","title":"CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language\n  Models","summary":"Language models often struggle with cross-mode knowledge retrieval -- the\nability to access knowledge learned in one format (mode) when queried in\nanother. We demonstrate that models trained on multiple data sources (e.g.,\nWikipedia and TinyStories) exhibit significantly reduced accuracy when\nretrieving knowledge in a format different from its original training mode.\nThis paper quantitatively investigates this phenomenon through a controlled\nstudy of random token sequence memorization across different modes. We first\nexplore dataset rewriting as a solution, revealing that effective cross-mode\nretrieval requires prohibitively extensive rewriting efforts that follow a\nsigmoid-like relationship. As an alternative, we propose CASCADE, a novel\npretraining algorithm that uses cascading datasets with varying sequence\nlengths to capture knowledge at different scales. Our experiments demonstrate\nthat CASCADE outperforms dataset rewriting approaches, even when compressed\ninto a single model with a unified loss function. This work provides both\nqualitative evidence of cross-mode retrieval limitations and a practical\nsolution to enhance language models' ability to access knowledge independently\nof its presentational format.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-02T08:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.01459v1","title":"Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning","summary":"Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T08:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.01462v1","title":"Characterization of the chaotic phase in the tilted Bose-Hubbard model","summary":"The chaotic phase of the tilted Bose-Hubbard model is identified as a\nfunction of energy, tilt strength and particle interaction, from the eigenstate\nstructure and the statistical features of the energy spectrum. Our analysis\nreveals that the chaotic phase of the bare Bose-Hubbard Hamiltonian can\nactually be enhanced by the presence of a moderate tilt. We further unveil the\ndevelopment and scaling of the chaotic regime from the perspective of a\nhomogeneous density configuration typically used in cold atom experiments,\nproviding a valuable phase diagram for future theoretical and experimental\nstudies of this system.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas","published":"2025-04-02T08:18:33Z"}
{"aid":"http://arxiv.org/abs/2504.01464v1","title":"A Prefixed Patch Time Series Transformer for Two-Point Boundary Value\n  Problems in Three-Body Problems","summary":"Two-point boundary value problems for cislunar trajectories present\nsignificant challenges in circler restricted three body problem, making\ntraditional analytical methods like Lambert's problem inapplicable. This study\nproposes a novel approach using a prefixed patch time series Transformer model\nthat automates the solution of two-point boundary value problems from lunar\nflyby to arbitrary terminal conditions. Using prefix tokens of terminal\nconditions in our deep generative model enables solving boundary value problems\nin three-body dynamics. The training dataset consists of trajectories obtained\nthrough forward propagation rather than solving boundary value problems\ndirectly. The model demonstrates potential practical utility for preliminary\ntrajectory design in cislunar mission scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01466v1","title":"Mesh Mamba: A Unified State Space Model for Saliency Prediction in\n  Non-Textured and Textured Meshes","summary":"Mesh saliency enhances the adaptability of 3D vision by identifying and\nemphasizing regions that naturally attract visual attention. To investigate the\ninteraction between geometric structure and texture in shaping visual\nattention, we establish a comprehensive mesh saliency dataset, which is the\nfirst to systematically capture the differences in saliency distribution under\nboth textured and non-textured visual conditions. Furthermore, we introduce\nmesh Mamba, a unified saliency prediction model based on a state space model\n(SSM), designed to adapt across various mesh types. Mesh Mamba effectively\nanalyzes the geometric structure of the mesh while seamlessly incorporating\ntexture features into the topological framework, ensuring coherence throughout\nappearance-enhanced modeling. More importantly, by subgraph embedding and a\nbidirectional SSM, the model enables global context modeling for both local\ngeometry and texture, preserving the topological structure and improving the\nunderstanding of visual details and structural complexity. Through extensive\ntheoretical and empirical validation, our model not only improves performance\nacross various mesh types but also demonstrates high scalability and\nversatility, particularly through cross validations of various visual features.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.01468v1","title":"HH-PIM: Dynamic Optimization of Power and Performance with\n  Heterogeneous-Hybrid PIM for Edge AI Devices","summary":"Processing-in-Memory (PIM) architectures offer promising solutions for\nefficiently handling AI applications in energy-constrained edge environments.\nWhile traditional PIM designs enhance performance and energy efficiency by\nreducing data movement between memory and processing units, they are limited in\nedge devices due to continuous power demands and the storage requirements of\nlarge neural network weights in SRAM and DRAM. Hybrid PIM architectures,\nincorporating non-volatile memories like MRAM and ReRAM, mitigate these\nlimitations but struggle with a mismatch between fixed computing resources and\ndynamically changing inference workloads. To address these challenges, this\nstudy introduces a Heterogeneous-Hybrid PIM (HH-PIM) architecture, comprising\nhigh-performance MRAM-SRAM PIM modules and low-power MRAM-SRAM PIM modules. We\nfurther propose a data placement optimization algorithm that dynamically\nallocates data based on computational demand, maximizing energy efficiency.\nFPGA prototyping and power simulations with processors featuring HH-PIM and\nother PIM types demonstrate that the proposed HH-PIM achieves up to $60.43$\npercent average energy savings over conventional PIMs while meeting application\nlatency requirements. These results confirm the suitability of HH-PIM for\nadaptive, energy-efficient AI processing in edge devices.","main_category":"cs.AR","categories":"cs.AR,cs.AI","published":"2025-04-02T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.01472v1","title":"ANNEXE: Unified Analyzing, Answering, and Pixel Grounding for Egocentric\n  Interaction","summary":"Egocentric interaction perception is one of the essential branches in\ninvestigating human-environment interaction, which lays the basis for\ndeveloping next-generation intelligent systems. However, existing egocentric\ninteraction understanding methods cannot yield coherent textual and pixel-level\nresponses simultaneously according to user queries, which lacks flexibility for\nvarying downstream application requirements. To comprehend egocentric\ninteractions exhaustively, this paper presents a novel task named Egocentric\nInteraction Reasoning and pixel Grounding (Ego-IRG). Taking an egocentric image\nwith the query as input, Ego-IRG is the first task that aims to resolve the\ninteractions through three crucial steps: analyzing, answering, and pixel\ngrounding, which results in fluent textual and fine-grained pixel-level\nresponses. Another challenge is that existing datasets cannot meet the\nconditions for the Ego-IRG task. To address this limitation, this paper creates\nthe Ego-IRGBench dataset based on extensive manual efforts, which includes over\n20k egocentric images with 1.6 million queries and corresponding multimodal\nresponses about interactions. Moreover, we design a unified ANNEXE model to\ngenerate text- and pixel-level outputs utilizing multimodal large language\nmodels, which enables a comprehensive interpretation of egocentric\ninteractions. The experiments on the Ego-IRGBench exhibit the effectiveness of\nour ANNEXE model compared with other works.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:35Z"}
{"aid":"http://arxiv.org/abs/2504.01491v1","title":"How to Define the Quality of Data? A Feature-Based Literature Survey","summary":"The digital transformation of our society is a constant challenge, as data is\ngenerated in almost every digital interaction. To use data effectively, it must\nbe of high quality. This raises the question: what exactly is data quality? A\nsystematic literature review of the existing literature shows that data quality\nis a multifaceted concept, characterized by a number of quality dimensions.\nHowever, the definitions of data quality vary widely. We used feature-oriented\ndomain analysis to specify a taxonomy of data quality definitions and to\nclassify the existing definitions. This allows us to identify research gaps and\nfuture topics.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.01516v1","title":"An addendum on the Mathieu Conjecture for $SU(N)$, $Sp(N)$ and $G_2$","summary":"In this paper, we sharpen results obtained by the author in 2023. The new\nresults reduce the Mathieu Conjecture on $SU(N)$ (formulated for all compact\nconnected Lie groups by O. Mathieu in 1997) to a conjecture involving only\nfunctions on $\\mathbb{R}^n\\times (S^1)^m$ with $n,m$ non-negative integers\ninstead of involving functions on $\\mathbb{R}^n\\times (S^1\\setminus\\{1\\})^m$.\nThe proofs rely on a more recent work of the author (2024) and a specific $KAK$\ndecomposition. Finally, with these results we can also improve the results on\nthe groups $Sp(N)$ and $G_2$ in the latter paper, since they relied on the\nconstruction introduced in the 2023 paper.","main_category":"math.GR","categories":"math.GR","published":"2025-04-02T09:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.01522v1","title":"Redefining technology for indigenous languages","summary":"In this paper, we offer an overview of indigenous languages, identifying the\ncauses of their devaluation and the need for legislation on language rights. We\nreview the technologies used to revitalize these languages, finding that when\nthey come from outside, they often have the opposite effect to what they seek;\nhowever, when developed from within communities, they become powerful\ninstruments of expression. We propose that the inclusion of Indigenous\nknowledge in large language models (LLMs) will enrich the technological\nlandscape, but must be done in a participatory environment that encourages the\nexchange of knowledge.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-02T09:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.01524v1","title":"On the limitations for causal inference in Cox models with time-varying\n  treatment","summary":"When using the Cox model to analyze the effect of a time-varying treatment on\na survival outcome, treatment is commonly included, using only the current\nlevel as a time-dependent covariate. Such a model does not necessarily assume\nthat past treatment is not associated with the outcome (the Markov property),\nsince it is possible to model the hazard conditional on only the current\ntreatment value. However, modeling the hazard conditional on the full treatment\nhistory is required in order to interpret the results causally, and such a full\nmodel assumes the Markov property when only including current treatment. This\nis, for example, common in marginal structural Cox models. We demonstrate that\nrelying on the Markov property is problematic, since it only holds in\nunrealistic settings or if the treatment has no causal effect. This is the case\neven if there are no confounders and the true causal effect of treatment really\nonly depends on its current level. Further, we provide an example of a scenario\nwhere the Markov property is not fulfilled, but the Cox model that includes\nonly current treatment as a covariate is correctly specified. Transforming the\nresult to the survival scale does not give the true intervention-specific\nsurvival probabilities, showcasing that it is unclear how to make causal\nstatements from such models.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T09:10:48Z"}
{"aid":"http://arxiv.org/abs/2504.01528v1","title":"Analytical and Numerical Linear Analyses of Convection Revisited","summary":"We conduct linear analyses of convection in domains larger than the\ntemperature scale height. We employ both analytical and numerical methods in\nthese analyses. In the case excluding all dissipation, the typical time scale\nof convection is determined by the free fall time over the temperature scale\nheight. We quantitatively show the condition for the Boussinesq and\nWentzel-Kramers-Brillouin (WKB) approximations to be applicable. We provide a\nreassessment of the critical Rayleigh number, a key indicator of convection,\nand show that WKB approximation tends to underestimate the critical Rayleigh\nnumber, particularly when the temperature scale height is comparable to or\nsmaller than the domain height. We show clear explanation why both thermal\nconduction and viscosity are required for stabilizing negative entropy gradient\nmedium.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T09:13:31Z"}
{"aid":"http://arxiv.org/abs/2504.01529v1","title":"Improvement of fully-implicit two-phase pore-network models by employing\n  generalized flux functions with additional throat variables","summary":"In fully-implicit two-phase pore-network models, developing a well-converged\nscheme remains a major challenge, primarily due to the discontinuities in the\nphase conductivities. This paper addresses these numerical issues by proposing\na generalized flux function that establishes a continuous flux expression for\ntwo-phase flows by introducing an additional throat variable $\\Theta$. Two\napproaches for expressing this additional throat variable are introduced: the\nfirst applies regularization strategies, while the second constructs an\nadditional residual constraint equation. It is shown that this approach\nsignificantly improves accuracy and ensures the temporal convergence, as\ndemonstrated through various numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MP","published":"2025-04-02T09:14:42Z"}
{"aid":"http://arxiv.org/abs/2504.01530v1","title":"Predicting passenger injury distributions under uncertainty variables\n  using Gaussian process modeling with GHBMC","summary":"This work presents a Gaussian Process (GP) modeling method to predict\nstatistical characteristics of injury kinematics responses using Human Body\nModels (HBM) more accurately and efficiently. We validate the GHBMC model\nagainst a 50\\%tile male Post-Mortem Human Surrogate (PMHS) test. Using this\nvalidated model, we create various postured models and generate injury\nprediction data across different postures and personalized D-ring heights\nthrough parametric crash simulations. We then train the GP using this\nsimulation data, implementing a novel adaptive sampling approach to improve\naccuracy. The trained GP model demonstrates robustness by achieving target\nprediction accuracy at points with high uncertainty. The proposed method\nperforms continuous injury prediction for various crash scenarios using just 27\ncomputationally expensive simulation runs. This method can be effectively\napplied to designing highly reliable occupant restraint systems across diverse\ncrash conditions.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-02T09:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.01540v1","title":"From Smr-re-brd to Subwords: Training LLMs on Danish, One\n  Morpheme at a Time","summary":"The best performing transformer-based language models use subword\ntokenization techniques, such as Byte-Pair-Encoding (BPE). However, these\napproaches often overlook linguistic principles, such as morphological\nsegmentation, which we believe is fundamental for understanding\nlanguage-specific word structure. In this study, we leverage an annotated\nDanish morphological dataset to train a semisupervised model for morphological\nsegmentation, enabling the development of tokenizers optimized for Danish\nmorphology. We evaluate four distinct tokenizers, including two custom\nmorphological tokenizers, by analyzing their performance in morphologically\nsegmenting Danish words. Additionally, we train two generative transformer\nmodels, \\textit{CerebrasGPT-111M} and \\textit{LLaMA-3.2 1B}, using these\ntokenizers and evaluate their downstream performance. Our findings reveal that\nour custom-developed tokenizers substantially enhance morphological\nsegmentation, achieving an F1 score of 58.84, compared to 39.28 achieved by a\nDanish BPE tokenizer. In downstream tasks, models trained with our\nmorphological tokenizers outperform those using BPE tokenizers across different\nevaluation metrics. These results highlight that incorporating Danish\nmorphological segmentation strategies into tokenizers leads to improved\nperformance in generative transformer models on Danish language","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.01554v1","title":"8-DoFs Cable Driven Parallel Robots for Bimanual Teleportation","summary":"Teleoperation plays a critical role in intuitive robot control and imitation\nlearning, particularly for complex tasks involving mobile manipulators with\nredundant degrees of freedom (DoFs). However, most existing master controllers\nare limited to 6-DoF spatial control and basic gripper control, making them\ninsufficient for controlling high-DoF robots and restricting the operator to a\nsmall workspace. In this work, we present a novel, low-cost, high-DoF master\ncontroller based on Cable-Driven Parallel Robots (CDPRs), designed to overcome\nthese limitations. The system decouples translation and orientation control,\nfollowing a scalable 3 + 3 + n DoF structure: 3 DoFs for large-range\ntranslation using a CDPR, 3 DoFs for orientation using a gimbal mechanism, and\nn additional DoFs for gripper and redundant joint control. Its lightweight\ncable-driven design enables a large and adaptable workspace while minimizing\nactuator load. The end-effector remains stable without requiring continuous\nhigh-torque input, unlike most serial robot arms. We developed the first\ndual-arm CDPR-based master controller using cost-effective actuators and a\nsimple mechanical structure. In demonstrations, the system successfully\ncontrolled an 8-DoF robotic arm with a 2-DoF pan-tilt camera, performing tasks\nsuch as pick-and-place, knot tying, object sorting, and tape application. The\nresults show precise, versatile, and practical high-DoF teleoperation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T09:54:16Z"}
{"aid":"http://arxiv.org/abs/2504.01557v1","title":"FastER: Fast On-Demand Entity Resolution in Property Graphs","summary":"Entity resolution (ER) is the problem of identifying and linking database\nrecords that refer to the same real-world entity. Traditional ER methods use\nbatch processing, which becomes impractical with growing data volumes due to\nhigh computational costs and lack of real-time capabilities. In many\napplications, users need to resolve entities for only a small portion of their\ndata, making full data processing unnecessary -- a scenario known as\n\"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework\nfor property graphs. Our approach uses graph differential dependencies (GDDs)\nas a knowledge encoding language to design effective filtering mechanisms that\nleverage both structural and attribute semantics of graphs. We construct a\nblocking graph from filtered subgraphs to reduce the number of candidate entity\npairs requiring comparison. Additionally, FastER incorporates Progressive\nProfile Scheduling (PPS), allowing the system to incrementally produce results\nthroughout the resolution process. Extensive evaluations on multiple benchmark\ndatasets demonstrate that FastER significantly outperforms state-of-the-art ER\nmethods in computational efficiency and real-time processing for on-demand\ntasks while ensuring reliability. We make FastER publicly available at:\nhttps://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.01562v1","title":"Asymptotic analysis of the finite predictor for the fractional Gaussian\n  noise","summary":"The goal of this paper is to propose a new approach to asymptotic analysis of\nthe finite predictor for stationary sequences. It produces the exact\nasymptotics of the relative prediction error and the partial correlation\ncoefficients. The assumptions are analytic in nature and applicable to\nprocesses with long range dependence. The ARIMA type process driven by the\nfractional Gaussian noise (fGn), which previously remained elusive, serves as\nour study case.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-02T10:03:53Z"}
{"aid":"http://arxiv.org/abs/2504.01568v1","title":"Ab-initio investigation of transition metal dichalcogenides for the\n  hydrogenation of carbon dioxide to methanol","summary":"We computationally investigate the catalytic potential of MoSe$_2$, WS$_2$,\nand WSe$_2$ nanoribbons and nanosheets for the partial hydrogenation of CO$_2$\nto methanol by comparing their electronic, adsorption, and defect properties to\nMoS$_2$, a known thermo-catalyst. We identify Se-deficient MoSe$_2$ (followed\nby WSe$_2$) nanosheets to be favorable for selective methanol formation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.01602v1","title":"Comment Staytime Prediction with LLM-enhanced Comment Understanding","summary":"In modern online streaming platforms, the comments section plays a critical\nrole in enhancing the overall user experience. Understanding user behavior\nwithin the comments section is essential for comprehensive user interest\nmodeling. A key factor of user engagement is staytime, which refers to the\namount of time that users browse and post comments. Existing watchtime\nprediction methods struggle to adapt to staytime prediction, overlooking\ninteractions with individual comments and their interrelation. In this paper,\nwe present a micro-video recommendation dataset with video comments (named as\nKuaiComt) which is collected from Kuaishou platform. correspondingly, we\npropose a practical framework for comment staytime prediction with LLM-enhanced\nComment Understanding (LCU). Our framework leverages the strong text\ncomprehension capabilities of large language models (LLMs) to understand\ntextual information of comments, while also incorporating fine-grained comment\nranking signals as auxiliary tasks. The framework is two-staged: first, the LLM\nis fine-tuned using domain-specific tasks to bridge the video and the comments;\nsecond, we incorporate the LLM outputs into the prediction model and design two\ncomment ranking auxiliary tasks to better understand user preference. Extensive\noffline experiments demonstrate the effectiveness of our framework, showing\nsignificant improvements on the task of comment staytime prediction.\nAdditionally, online A/B testing further validates the practical benefits on\nindustrial scenario. Our dataset KuaiComt\n(https://github.com/lyingCS/KuaiComt.github.io) and code for LCU\n(https://github.com/lyingCS/LCU) are fully released.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T11:09:18Z"}
{"aid":"http://arxiv.org/abs/2504.01627v1","title":"Horizon Scans can be accelerated using novel information retrieval and\n  artificial intelligence tools","summary":"Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-02T11:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.01640v1","title":"Controlling photo-excited electron-spin by light-polarization in\n  ultrafast-pumped altermagnets","summary":"Altermagnets (AMs) constitute a novel class of spin-compensated materials in\nwhich the symmetry connecting opposite-spin sublattices involves a spatial\nrotation. Here, we uncover a set of unique non-linear, light-driven properties\nthat set AMs apart from traditional ferro- and antiferromagnets. We demonstrate\ntheoretically that the polarization of an electromagnetic pulse that\nphoto-excites electrons and holes in an AM, controls the spin orientation of\nthese non-equilibrium charge carriers. For a d-wave AM model and a prototype\nmaterial, we show that very large post-pump spin polarizations may be attained\nby exploiting resonances. We show that this protocol also allows, in an AM, to\ndirectly probe the spin splitting of the electronic states in energy and\nmomentum space. Thus, it can be used to identify and characterize altermagnetic\nmaterials via ultrafast pump-probe Kerr/Faraday spectroscopy or spin- and\ntime-resolved ARPES. This opens up the possibility of devising ultrafast\noptical switches of non-equilibrium spin-polarization, finely tunable by\nadjusting the pump-pulse characteristics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.01649v1","title":"Modeling the Siege of Syracuse: Resources, strategy, and collapse","summary":"The Siege of Syracuse ($214-212$ BC) was a decisive event in the Second Punic\nWar, leading to the city's fall to Rome despite its formidable defenses,\nincluding the war machines devised by Archimedes. In this work, we propose a\nmathematical model to describe the dynamics of the siege, incorporating the\ndepletion of resources, the decline of Syracuse's population, and the\npersistence of the Roman army. Our analysis reveals the existence of a critical\nthreshold $\\lambda_{c}$, which determines the outcome of the siege. This\nthreshold marks a phase transition: if the effectiveness of Syracuse's\ndefenses, represented by $\\lambda$, had exceeded $\\lambda_{c}$, the city could\nhave withstood the Roman assault. However, since history records Syracuse's\nfall, we conclude that $\\lambda < \\lambda_{c}$. This result provides a\nquantitative framework to understand the inevitability of the city's conquest\nand demonstrates how mathematical modeling can offer new insights into\nhistorical military conflicts. We also explore different scenarios and assess\nthe impact of key factors such as siege duration, supply constraints, and\ndefensive capabilities. The results provide insight into how strategic elements\ninfluenced the eventual fall of Syracuse and demonstrate the applicability of\nmathematical modeling in historical military analysis.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T11:59:21Z"}
{"aid":"http://arxiv.org/abs/2504.01665v1","title":"On products of sets of natural density one","summary":"In a previous work, Bettin, Koukoulopoulos, and Sanna prove that if two sets\nof natural numbers $A$ and $B$ have natural density $1$, then their product set\n$A \\cdot B := \\{ab : a \\in A, b \\in B\\}$ also has natural density $1$. They\nalso provide an effective rate and pose the question of determining the optimal\nrate. We make progress on this question by constructing a set $A$ of density 1\nsuch that $A\\cdot A$ has a ''large'' complement.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T12:15:22Z"}
{"aid":"http://arxiv.org/abs/2504.01685v1","title":"Augmenting chemical databases for atomistic machine learning by sampling\n  conformational space","summary":"Machine learning (ML) has become a standard tool for the exploration of\nchemical space. Much of the performance of such models depends on the chosen\ndatabase for a given task. Here, this aspect is investigated for \"chemical\ntasks\" including the prediction of hybridization, oxidation, substituent\neffects, and aromaticity, starting from an initial \"restricted\" database (iRD).\nChoosing molecules for augmenting this iRD, including increasing numbers of\nconformations generated at different temperatures, and retraining the models\ncan improve predictions of the models on the selected \"tasks\". Addition of a\nsmall percentage of conformers (1 % ) obtained at 300 K improves the\nperformance in almost all cases. On the other hand, and in line with previous\nstudies, redundancy and highly deformed structures in the augmentation set\ncompromise prediction quality. Energy and bond distributions were evaluated by\nmeans of Kullback-Leibler ($D_{\\rm KL}$) and Jensen-Shannon ($D_{\\rm JS}$)\ndivergence and Wasserstein distance ($W_{1}$). The findings of this work\nprovide a baseline for the rational augmentation of chemical databases or the\ncreation of synthetic databases.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.data-an","published":"2025-04-02T12:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01697v1","title":"Single-atom-at-a-time adsorption studies of $^{211}$Bi and its precursor\n  $^{211}$Pb on SiO$_{2}$ surfaces","summary":"In preparation of gas-phase chemical experiments with moscovium (Mc, element\n115), we studied the chemical behavior of the short-lived bismuth radioisotope\n$^{211}$Bi in helium, argon, and oxygen atmosphere. Internal chromatograms were\nrecorded as a function of various parameters including carrier gas type and\nflow rate, thus characterizing the novel miniCOMPACT detector array. This aids\nto optimize the conditions for experiments with superheavy elements. The\nbismuth progeny of $^{219}$Rn deposited on the SiO$_{2}$ surface of the\nminiCOMPACT via diffusion-controlled deposition. Bismuth showed the expected\nhigh reactivity towards the SiO$_{2}$ surface of the miniCOMPACT. Experiments\nin argon and oxygen atmosphere showed no measurable differences in the\ndeposition distribution of the activity. The intermediate 36-min $^{211}$Pb is\na member of the $^{227}$Ac decay chain, feeding the studied bismuth isotope,\nwas taken into account. To extract thermodynamical data from the results,\nnamely the lower limit of the value of the adsorption enthalpy of Bi on\nSiO$_{2}$, we performed Monte Carlo simulations, adapted to account for the\nprecursor effect, and compared the experimental results to their output.\nSimulations were also performed for bismuths heavier homologue, moscovium,\nusing a theoretically predicted value for the adsorption enthalpy of this\nelement on SiO$_{2}$. These suggest moscovium to adsorb in the first part of\nthe miniCOMPACT detection array, in line with recent observations.","main_category":"nucl-ex","categories":"nucl-ex,physics.ins-det","published":"2025-04-02T12:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.01703v1","title":"Computable Bounds on the Solution to Poisson's Equation for General\n  Harris Chains","summary":"Poisson's equation is fundamental to the study of Markov chains, and arises\nin connection with martingale representations and central limit theorems for\nadditive functionals, perturbation theory for stationary distributions, and\naverage reward Markov decision process problems. In this paper, we develop a\nnew probabilistic representation for the solution of Poisson's equation, and\nuse Lyapunov functions to bound this solution representation explicitly. In\ncontrast to most prior work on this problem, our bounds are computable. Our\ncontribution is closely connected to recent work of Herve and Ledoux (2025), in\nwhich they focus their study on a special class of Harris chains satisfying a\nparticular small set condition. However, our theory covers general Harris\nchains, and often provides a tighter bound. In addition to the new bound and\nrepresentation, we also develop a computable uniform bound on marginal\nexpectations for Harris chains, and a computable bound on the potential kernel\nrepresentation of the solution to Poisson's equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-02T13:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.01705v1","title":"Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via\n  Selective Pruning","summary":"The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.MA","published":"2025-04-02T13:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.01713v1","title":"A two-player voting game in Euclidean space","summary":"Given a finite set $S$ of points in $\\mathbb{R}^d$, which we regard as the\nlocations of voters on a $d$-dimensional political `spectrum', two candidates\n(Alice and Bob) select one point in $\\mathbb{R}^d$ each, in an attempt to get\nas many votes as possible. Alice goes first and Bob goes second, and then each\nvoter simply votes for the candidate closer to them in terms of Euclidean\ndistance. If a voter's distance from the two candidates is the same, they vote\nfor nobody. We give a geometric characterization of the sets $S$ for which each\ncandidate wins, assuming that Alice wins if they get an equal number of votes.\nWe also show that, if not all the voters lie on a single line, then, whenever\nAlice has a winning strategy, there is a unique winning point for her. We also\nprovide an algorithm which decides whether Alice has a winning point, and\ndetermines the location of that point, both in finite (in fact polynomial)\ntime.","main_category":"math.CO","categories":"math.CO,math.OC","published":"2025-04-02T13:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.01716v1","title":"Studies of Hadronic Showers in SND@LHC","summary":"The SND@LHC experiment was built for observing neutrinos arising from LHC pp\ncollisions. The detector consists of two sections: a target instrumented with\nSciFi modules and a hadronic calorimeter/muon detector. Energetic $\\nu$N\ncollisions in the target produce hadronic showers. Reconstruction of the shower\ntotal energy requires an estimate of the fractions deposited in both the target\nand the calorimeter. In order to calibrate the SND@LHC response, a replica of\nthe detector was exposed to hadron beams with 100 to 300 GeV in the CERN SPS H8\ntest beam line in Summer 2023. This report describes the methods developed to\ntag the presence of a shower, to locate the shower origin in the target, and to\ncombine the target SciFi and the calorimeter signals so to measure the shower\ntotal energy.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-02T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.01717v1","title":"Construction of MDS Euclidean Self-Dual Codes via Multiple Subsets","summary":"MDS self-dual codes have good algebraic structure, and their parameters are\ncompletely determined by the code length. In recent years, the construction of\nMDS Euclidean self-dual codes with new lengths has become an important issue in\ncoding theory. In this paper, we are committed to constructing new MDS\nEuclidean self-dual codes via generalized Reed-Solomon (GRS) codes and their\nextended (EGRS) codes. The main effort of our constructions is to find suitable\nsubsets of finite fields as the evaluation sets, ensuring that the\ncorresponding (extended) GRS codes are Euclidean self-dual. Firstly, we present\na method for selecting evaluation sets from multiple intersecting subsets and\nprovide a theorem to guarantee that the chosen evaluation sets meet the desired\ncriteria. Secondly, based on this theorem, we construct six new classes of MDS\nEuclidean self-dual codes using the norm function, as well as the union of\nthree multiplicity subgroups and their cosets respectively. Finally, in our\nconstructions, the proportion of possible MDS Euclidean self-dual codes exceeds\n85\\%, which is much higher than previously reported results.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T13:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.01723v1","title":"Analytical Framework of Orbital Angular Momentum Beam in Misaligned\n  Detection","summary":"This work provides an analytical framework to model the detected orbital\nangular momentum (OAM) spectrum of an optical beam in the presence of tilt and\nlateral displacement in the impinging beam. We show how both tilt and\ndisplacement cause OAM sidebands following the same function, with both having\ntheir characteristic adimensional parameter related to the size and wavelength\nof the beam. We see how an increase in topological charge on the beam causes\nwider detected OAM distribution. Finally, we show how, in the case of both tilt\nand lateral displacement, we can tune the amount of OAM mode in the original\nmode by having a perpendicular direction for the tilt and off-axis\ndisplacement, causing the misalignment errors to interfere destructively.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.01724v1","title":"DreamActor-M1: Holistic, Expressive and Robust Human Image Animation\n  with Hybrid Guidance","summary":"While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.01725v1","title":"Brillouin-enhanced four-wave mixing with optical chiral states","summary":"Brillouin-enhanced four-wave mixing - also known as Brillouin dynamic\ngratings - is an important nonlinear effect in photonics that couples four\nlight waves by travelling acoustic waves. The effect has received a lot of\nattention in the last few decades, especially for applications in fiber\nsensing, signal processing and optical delay lines. Here, we report\nBrillouin-enhanced four-wave mixing with optical chiral states (i.e. circular\npolarization and vortex states) in twisted photonic crystal fiber, by\nleveraging the topology-selective Brillouin effect. Phase-matching has the\nconsequence that the travelling acoustic gratings created by\ncircularly-polarized vortex pump and Stokes in the stimulated Brillouin\nscattering can be used to modulate a frequency-shifted probe, where the\npump/Stokes and probe have different circular polarization or topological\ncharges. We demonstrate cross-frequency selective information transfer and show\nthat the information is transferred only when pump and probe have opposite\ncircular polarization.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:31:57Z"}
{"aid":"http://arxiv.org/abs/2504.01739v1","title":"Understanding Cross-Model Perceptual Invariances Through Ensemble\n  Metamers","summary":"Understanding the perceptual invariances of artificial neural networks is\nessential for improving explainability and aligning models with human vision.\nMetamers - stimuli that are physically distinct yet produce identical neural\nactivations - serve as a valuable tool for investigating these invariances. We\nintroduce a novel approach to metamer generation by leveraging ensembles of\nartificial neural networks, capturing shared representational subspaces across\ndiverse architectures, including convolutional neural networks and vision\ntransformers. To characterize the properties of the generated metamers, we\nemploy a suite of image-based metrics that assess factors such as semantic\nfidelity and naturalness. Our findings show that convolutional neural networks\ngenerate more recognizable and human-like metamers, while vision transformers\nproduce realistic but less transferable metamers, highlighting the impact of\narchitectural biases on representational invariances.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.01771v1","title":"Enhancing Interpretability in Generative AI Through Search-Based Data\n  Influence Analysis","summary":"Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-02T14:29:37Z"}
{"aid":"http://arxiv.org/abs/2504.01774v1","title":"Memory-efficient Low-latency Remote Photoplethysmography through\n  Temporal-Spatial State Space Duality","summary":"Remote photoplethysmography (rPPG), enabling non-contact physiological\nmonitoring through facial light reflection analysis, faces critical\ncomputational bottlenecks as deep learning introduces performance gains at the\ncost of prohibitive resource demands. This paper proposes ME-rPPG, a\nmemory-efficient algorithm built on temporal-spatial state space duality, which\nresolves the trilemma of model scalability, cross-dataset generalization, and\nreal-time constraints. Leveraging a transferable state space, ME-rPPG\nefficiently captures subtle periodic variations across facial frames while\nmaintaining minimal computational overhead, enabling training on extended video\nsequences and supporting low-latency inference. Achieving cross-dataset MAEs of\n5.38 (MMPD), 0.70 (VitalVideo), and 0.25 (PURE), ME-rPPG outperforms all\nbaselines with improvements ranging from 21.3% to 60.2%. Our solution enables\nreal-time inference with only 3.6 MB memory usage and 9.46 ms latency --\nsurpassing existing methods by 19.5%-49.7% accuracy and 43.2% user satisfaction\ngains in real-world deployments. The code and demos are released for\nreproducibility on https://github.com/Health-HCI-Group/ME-rPPG-demo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:34:04Z"}
{"aid":"http://arxiv.org/abs/2504.01810v1","title":"Parametrized scissors congruence $K$-theory of manifolds and cobordism\n  categories","summary":"We construct a parametrized version of scissors congruence $K$-theory of\nmanifolds, which in particular gives a topologized version of the scissors\ncongruence $K$-theory of oriented manifolds, and we describe this spectrum as\nmediating between the cobordism category and usual algebraic $K$-theory of\nspaces. We show that on $\\pi_0$, the scissors congruence $K$-theory of oriented\nmanifolds agrees with a version of the cobordism category where we allow free\nboundaries.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-04-02T15:16:00Z"}
{"aid":"http://arxiv.org/abs/2504.01822v1","title":"Track and Trace: Automatically Uncovering Cross-chain Transactions in\n  the Multi-blockchain Ecosystems","summary":"Cross-chain technology enables seamless asset transfer and message-passing\nwithin decentralized finance (DeFi) ecosystems, facilitating multi-chain\ncoexistence in the current blockchain environment. However, this development\nalso raises security concerns, as malicious actors exploit cross-chain asset\nflows to conceal the provenance and destination of assets, thereby facilitating\nillegal activities such as money laundering. Consequently, the need for\ncross-chain transaction traceability has become increasingly urgent. Prior\nresearch on transaction traceability has predominantly focused on single-chain\nand centralized finance (CeFi) cross-chain scenarios, overlooking DeFispecific\nconsiderations. This paper proposes ABCTRACER, an automated, bi-directional\ncross-chain transaction tracing tool, specifically designed for DeFi\necosystems. By harnessing transaction event log mining and named entity\nrecognition techniques, ABCTRACER automatically extracts explicit cross-chain\ncues. These cues are then combined with information retrieval techniques to\nencode implicit cues. ABCTRACER facilitates the autonomous learning of latent\nassociated information and achieves bidirectional, generalized cross-chain\ntransaction tracing. Our experiments on 12 mainstream cross-chain bridges\ndemonstrate that ABCTRACER attains 91.75% bi-directional traceability (F1\nmetrics) with self-adaptive capability. Furthermore, we apply ABCTRACER to\nreal-world cross-chain attack transactions and money laundering traceability,\nthereby bolstering the traceability and blockchain ecological security of DeFi\nbridging applications.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-02T15:28:25Z"}
{"aid":"http://arxiv.org/abs/2504.01826v1","title":"The properties of general Fourier partial sums of functions $f \\in C_L$","summary":"In this paper, we investigated the Fourier partial sums with respect to\ngeneral orthonormal systems when the function $f$ belongs to some\ndifferentiable class of functions","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T15:33:13Z"}
{"aid":"http://arxiv.org/abs/2504.01828v1","title":"Acoustic modes in M67 cluster stars trace deepening convective envelopes","summary":"Acoustic oscillations in stars are sensitive to stellar interiors. Frequency\ndifferences between overtone modes -- large separations -- probe stellar\ndensity, while differences between low-degree modes -- small separations --\nprobe the sound speed gradient in the energy-generating core of main sequence\nSun-like stars, and hence their ages. At later phases of stellar evolution,\ncharacterised by inert cores, small separations are believed to lose much of\ntheir power to probe deep interiors and simply become proportional to large\nseparations. Here, we present clear evidence of a rapidly evolving convective\nzone as stars evolve from the subgiant phase into red giants. By measuring\nacoustic oscillations in 27 stars from the open cluster M67, we observe\ndeviations of proportionality between small and large separations, which are\ncaused by the influence of the bottom of the convective envelope. These\ndeviations become apparent as the convective envelope penetrates deep into the\nstar during subgiant and red giant evolution, eventually entering an ultra-deep\nregime that leads to the red giant branch luminosity bump. The tight sequence\nof cluster stars, free of large spreads in ages and fundamental properties, is\nessential for revealing the connection between the observed small separations\nand the chemical discontinuities occurring at the bottom of the convective\nenvelope. We use this sequence to show that combining large and small\nseparations can improve estimations of the masses and ages of field stars well\nafter the main sequence.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-02T15:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.01839v1","title":"A Randomized Zeroth-Order Hierarchical Framework for Heterogeneous\n  Federated Learning","summary":"Heterogeneity in federated learning (FL) is a critical and challenging aspect\nthat significantly impacts model performance and convergence. In this paper, we\npropose a novel framework by formulating heterogeneous FL as a hierarchical\noptimization problem. This new framework captures both local and global\ntraining process through a bilevel formulation and is capable of the following:\n(i) addressing client heterogeneity through a personalized learning framework;\n(ii) capturing pre-training process on server's side; (iii) updating global\nmodel through nonstandard aggregation; (iv) allowing for nonidentical local\nsteps; and (v) capturing clients' local constraints. We design and analyze an\nimplicit zeroth-order FL method (ZO-HFL), provided with nonasymptotic\nconvergence guarantees for both the server-agent and the individual\nclient-agents, and asymptotic guarantees for both the server-agent and\nclient-agents in an almost sure sense. Notably, our method does not rely on\nstandard assumptions in heterogeneous FL, such as the bounded gradient\ndissimilarity condition. We implement our method on image classification tasks\nand compare with other methods under different heterogeneous settings.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-02T15:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.01880v1","title":"Partition function zeros of quantum many-body systems","summary":"We present a method for calculating the Yang-Lee partition function zeros of\na translationally invariant model of lattice fermions, exemplified by the\nHubbard model. The method rests on a theorem involving the single electron\nself-energy $\\Sigma_\\sigma(k, i \\omega_n)$ in the imaginary time Matsubara\nformulation. The theorem maps the Yang-Lee zeros to a set of wavevector and\nspin labeled virtual energies $\\xi_{k \\sigma}$. These, thermodynamically\nderived virtual energies, are solutions of equations involving the self-energy\nat corresponding $k\\sigma$'s. Examples of the method in simplified situations\nare provided.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-02T16:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.01888v1","title":"A novel gesture interaction control method for rehabilitation lower\n  extremity exoskeleton","summary":"With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.HC","published":"2025-04-02T16:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.01891v1","title":"Multi-stream Physics Hybrid Networks for solving Navier-Stokes equations","summary":"Understanding and solving fluid dynamics equations efficiently remains a\nfundamental challenge in computational physics. Traditional numerical solvers\nand physics-informed neural networks struggle to capture the full range of\nfrequency components in partial differential equation solutions, limiting their\naccuracy and efficiency. Here, we propose the Multi-stream Physics Hybrid\nNetwork, a novel neural architecture that integrates quantum and classical\nlayers in parallel to improve the accuracy of solving fluid dynamics equations,\nnamely Kovasznay flow problem. This approach decomposes the solution into\nseparate frequency components, each predicted by independent Parallel Hybrid\nNetworks, simplifying the training process and enhancing performance. We\nevaluated the proposed model against a comparable classical neural network, the\nMulti-stream Physics Classical Network, in both data-driven and physics-driven\nscenarios. Our results show that the Multi-stream Physics Hybrid Network\nachieves a reduction in root mean square error by 36% for velocity components\nand 41% for pressure prediction compared to the classical model, while using\n24% fewer trainable parameters. These findings highlight the potential of\nhybrid quantum-classical architectures for advancing computational fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,quant-ph","published":"2025-04-02T16:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.01898v1","title":"Analysis of an Idealized Stochastic Polyak Method and its Application to\n  Black-Box Model Distillation","summary":"We provide a general convergence theorem of an idealized stochastic Polyak\nstep size called SPS$^*$. Besides convexity, we only assume a local expected\ngradient bound, that includes locally smooth and locally Lipschitz losses as\nspecial cases. We refer to SPS$^*$ as idealized because it requires access to\nthe loss for every training batch evaluated at a solution. It is also ideal, in\nthat it achieves the optimal lower bound for globally Lipschitz function, and\nis the first Polyak step size to have an $O(1/\\sqrt{t})$ anytime convergence in\nthe smooth setting. We show how to combine SPS$^*$ with momentum to achieve the\nsame favorable rates for the last iterate. We conclude with several experiments\nto validate our theory, and a more practical setting showing how we can distill\na teacher GPT-2 model into a smaller student model without any hyperparameter\ntuning.","main_category":"cs.LG","categories":"cs.LG,G.1.6","published":"2025-04-02T16:57:39Z"}
{"aid":"http://arxiv.org/abs/2504.01903v1","title":"STAR-1: Safer Alignment of Reasoning LLMs with 1K Data","summary":"This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.01912v1","title":"Open cluster age calibration from colour-magnitude morphological indices\n  using Gaia DR3 data","summary":"Star clusters are crucial for understanding how stars evolve. Their\ncolour-magnitude diagrams show the effects of stellar evolution of\napproximately coeval objects with the same chemical composition. Furthermore,\nthe determination of their astrophysical parameters (age, distance, colour\nexcess and metallicity) together with their spatial distribution provides\ninformation about the structure and the evolution of the Galaxy itself. Using\ndata from the \\textit{Gaia} DR3 and 2MASS catalogues, we develop methodologies\nfor characterizing open clusters. Precise membership lists, mean astrometric\nparameters and radii are obtained. Using photometric data from both data\nsources, we carried out new age calibrations that rely on morphological indices\nbased on colour ($\\Delta BR$) and magnitude ($\\Delta G$) differences between\nthe red clump and the turnoff for a sample of 34 open clusters with ages\ncovering the interval $8.3 < \\log[t({\\rm yr})] < 9.9$. A set of age calibration\nfunctions based on \\textit{Gaia} morphological age indices are determined for\nthe first time. We demonstrate their accuracy, obtaining a mean residual of\n0.06 dex in $\\log[t(yr)]$. Our results also show that stellar evolution models\ntend to predict the difference $\\Delta G$. However, they typically overestimate\nthe difference $\\Delta BR$ for objects younger than $\\log[t({\\rm yr})] = 8.8$.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-02T17:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.01919v1","title":"Bridging the Linguistic Divide: A Survey on Leveraging Large Language\n  Models for Machine Translation","summary":"The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.01921v1","title":"Client Selection in Federated Learning with Data Heterogeneity and\n  Network Latencies","summary":"Federated learning (FL) is a distributed machine learning paradigm where\nmultiple clients conduct local training based on their private data, then the\nupdated models are sent to a central server for global aggregation. The\npractical convergence of FL is challenged by multiple factors, with the primary\nhurdle being the heterogeneity among clients. This heterogeneity manifests as\ndata heterogeneity concerning local data distribution and latency heterogeneity\nduring model transmission to the server. While prior research has introduced\nvarious efficient client selection methods to alleviate the negative impacts of\neither of these heterogeneities individually, efficient methods to handle\nreal-world settings where both these heterogeneities exist simultaneously do\nnot exist. In this paper, we propose two novel theoretically optimal client\nselection schemes that can handle both these heterogeneities. Our methods\ninvolve solving simple optimization problems every round obtained by minimizing\nthe theoretical runtime to convergence. Empirical evaluations on 9 datasets\nwith non-iid data distributions, 2 practical delay distributions, and\nnon-convex neural network models demonstrate that our algorithms are at least\ncompetitive to and at most 20 times better than best existing baselines.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-02T17:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.01928v1","title":"Is the Reversal Curse a Binding Problem? Uncovering Limitations of\n  Transformers from a Basic Generalization Failure","summary":"Despite their impressive capabilities, LLMs exhibit a basic generalization\nfailure known as the Reversal Curse, where they struggle to learn reversible\nfactual associations. Understanding why this occurs could help identify\nweaknesses in current models and advance their generalization and robustness.\nIn this paper, we conjecture that the Reversal Curse in LLMs is a manifestation\nof the long-standing binding problem in cognitive science, neuroscience and AI.\nSpecifically, we identify two primary causes of the Reversal Curse stemming\nfrom transformers' limitations in conceptual binding: the inconsistency and\nentanglements of concept representations. We perform a series of experiments\nthat support these conjectures. Our exploration leads to a model design based\non JEPA (Joint-Embedding Predictive Architecture) that for the first time\nbreaks the Reversal Curse without side-stepping it with specialized data\naugmentation or non-causal masking, and moreover, generalization could be\nfurther improved by incorporating special memory layers that support\ndisentangled concept representations. We demonstrate that the skill of reversal\nunlocks a new kind of memory integration that enables models to solve\nlarge-scale arithmetic reasoning problems via parametric forward-chaining,\noutperforming frontier LLMs based on non-parametric memory and prolonged\nexplicit reasoning.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-02T17:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.01934v1","title":"ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and\n  Diffusion Refinement","summary":"We present ILLUME+ that leverages dual visual tokenization and a diffusion\ndecoder to improve both deep semantic understanding and high-fidelity image\ngeneration. Existing unified models have struggled to simultaneously handle the\nthree fundamental capabilities in a unified model: understanding, generation,\nand editing. Models like Chameleon and EMU3 utilize VQGAN for image\ndiscretization, due to the lack of deep semantic interaction, they lag behind\nspecialist models like LLaVA in visual understanding tasks. To mitigate this,\nLaViT and ILLUME employ semantic encoders for tokenization, but they struggle\nwith image editing due to poor texture preservation. Meanwhile, Janus series\ndecouples the input and output image representation, limiting their abilities\nto seamlessly handle interleaved image-text understanding and generation. In\ncontrast, ILLUME+ introduces a unified dual visual tokenizer, DualViTok, which\npreserves both fine-grained textures and text-aligned semantics while enabling\na coarse-to-fine image representation strategy for multimodal understanding and\ngeneration. Additionally, we employ a diffusion model as the image detokenizer\nfor enhanced generation quality and efficient super-resolution. ILLUME+ follows\na continuous-input, discrete-output scheme within the unified MLLM and adopts a\nprogressive training procedure that supports dynamic resolution across the\nvision tokenizer, MLLM, and diffusion decoder. This design allows for flexible\nand efficient context-aware image editing and generation across diverse tasks.\nILLUME+ (3B) exhibits competitive performance against existing unified MLLMs\nand specialized models across multimodal understanding, generation, and editing\nbenchmarks. With its strong performance, ILLUME+ provides a scalable and\nversatile foundation for future multimodal applications. Project Page:\nhttps://illume-unified-mllm.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.01939v1","title":"Laboratory evaluation of a wearable instrumented headband for rotational\n  head kinematics measurement","summary":"Mild traumatic brain injuries (mTBI) are a highly prevalent condition with\nheterogeneous outcomes between individuals. A key factor governing brain tissue\ndeformation and the risk of mTBI is the rotational kinematics of the head.\nInstrumented mouthguards are a widely accepted method for measuring rotational\nhead motions, owing to their robust sensor-skull coupling. However, wearing\nmouthguards is not feasible in all situations, especially for long-term data\ncollection. Therefore, alternative wearable devices are needed. In this study,\nwe present an improved design and data processing scheme for an instrumented\nheadband. Our instrumented headband utilizes an array of inertial measurement\nunits (IMUs) and a new data-processing scheme based on continuous wavelet\ntransforms to address sources of error in the IMU measurements. The headband\nperformance was evaluated in the laboratory on an anthropomorphic test device,\nwhich was impacted with a soccer ball to replicate soccer heading. When\ncomparing the measured peak rotational velocities (PRV) and peak rotational\naccelerations (PRA) between the reference sensors and the headband for impacts\nto the front of the head, the correlation coefficients (r) were 0.80 and 0.63,\nand the normalized root mean square error (NRMSE) values were 0.20 and 0.28,\nrespectively. However, when considering all impact locations, r dropped to 0.42\nand 0.34 and NRMSE increased to 0.5 and 0.41 for PRV and PRA, respectively.\nThis new instrumented headband improves upon previous headband designs in\nreconstructing the rotational head kinematics resulting from frontal soccer\nball impacts, providing a potential alternative to instrumented mouthguards.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T17:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.02212v1","title":"Decidabilities of local unitary equivalence for entanglement witnesses\n  and states","summary":"The problem of determining whether two states are equivalent by local unitary\n(LU) operations is important for quantum information processing. In this paper\nwe propose an alternative perspective to study this problem by comparing the\ndecidabilities of LU equivalence (also known as LU decidabilities for short)\nbetween entanglement witnesses and states. We introduce a relation between sets\nof Hermitian operators in terms of the LU decidability. Then we compare the LU\ndecidability for the set of entanglement witness to those decidabilities for\nseveral sets of states, and establish a hierarchy on LU decidabilities for\nthese sets. Moreover, we realize that the simultaneous LU (SLU) equivalence\nbetween tuples of mutually orthogonal projectors is crucial to LU equivalent\noperators. We reveal by examples that for two tuples of projectors, the partial\nSLU equivalence cannot ensure the overall SLU equivalence. Generally, we\npresent a necessary and sufficient condition such that two tuples of states are\nSLU equivalent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T02:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.02237v1","title":"Super diffusive length dependent thermal conductivity in one-dimensional\n  materials with structural defects: longitudinal to transverse phonon\n  scattering leads to $\\propto L^{1/3}$ law","summary":"Structural defects in one-dimensional heat conductors couple longitudinal\n(stretching) and transverse (bending) vibrations. This coupling results in the\nscattering of longitudinal phonons to transverse phonons and backwards. We show\nthat the decay rate of longitudinal phonons due to this scattering scales with\ntheir frequencies as $\\omega^{3/2}$ within the long wavelength limit ($\\omega\n\\rightarrow 0$), which is more efficient scattering compared to the\ntraditionally considered Rayleigh scattering within the longitudinal band\n($\\omega^2$). This scattering results in temperature independent thermal\nconductivity depending on the size as $\\kappa \\propto L^{1/3}$ for sufficiently\nlong materials. This predicted length dependence is observed in nanowires,\nthough the temperature dependence is seen there possibly because of deviations\nfrom pure one-dimensional behavior. The significant effect of interaction of\nlongitudinal phonons with transverse phonons is consistent with the earlier\nobservations of a substantial suppression of thermal energy transport by kinks,\nobviously leading to such interaction, though anharmonic interaction can also\nbe significant.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.dis-nn","published":"2025-04-03T03:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.02246v1","title":"C*: Unifying Programming and Verification in C","summary":"Ensuring the correct functionality of systems software, given its\nsafety-critical and low-level nature, is a primary focus in formal verification\nresearch and applications. Despite advances in verification tooling,\nconventional programmers are rarely involved in the verification of their own\ncode, resulting in higher development and maintenance costs for verified\nsoftware. A key barrier to programmer participation in verification practices\nis the disconnect of environments and paradigms between programming and\nverification practices, which limits accessibility and real-time verification.\n  We introduce C*, a proof-integrated language design for C programming. C*\nextends C with verification capabilities, powered by a symbolic execution\nengine and an LCF-style proof kernel. It enables real-time verification by\nallowing programmers to embed proof-code blocks alongside implementation code,\nfacilitating interactive updates to the current proof state. Its expressive and\nextensible proof support allows users to build reusable libraries of logical\ndefinitions, theorems, and programmable proof automation. Crucially, C* unifies\nimplementation and proof code development by using C as the common language.\n  We implemented a prototype of C* and evaluated it on a representative\nbenchmark of small C programs and a challenging real-world case study: the\nattach function of pKVM's buddy allocator. Our results demonstrate that C*\nsupports the verification of a broad subset of C programming idioms and\neffectively handles complex reasoning tasks in real-world scenarios.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-03T03:22:22Z"}
{"aid":"http://arxiv.org/abs/2504.02252v1","title":"Adapting World Models with Latent-State Dynamics Residuals","summary":"Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-03T03:41:30Z"}
{"aid":"http://arxiv.org/abs/2504.02261v1","title":"WonderTurbo: Generating Interactive 3D World in 0.72 Seconds","summary":"Interactive 3D generation is gaining momentum and capturing extensive\nattention for its potential to create immersive virtual experiences. However, a\ncritical challenge in current 3D generation technologies lies in achieving\nreal-time interactivity. To address this issue, we introduce WonderTurbo, the\nfirst real-time interactive 3D scene generation framework capable of generating\nnovel perspectives of 3D scenes within 0.72 seconds. Specifically, WonderTurbo\naccelerates both geometric and appearance modeling in 3D scene generation. In\nterms of geometry, we propose StepSplat, an innovative method that constructs\nefficient 3D geometric representations through dynamic updates, each taking\nonly 0.26 seconds. Additionally, we design QuickDepth, a lightweight depth\ncompletion module that provides consistent depth input for StepSplat, further\nenhancing geometric accuracy. For appearance modeling, we develop FastPaint, a\n2-steps diffusion model tailored for instant inpainting, which focuses on\nmaintaining spatial appearance consistency. Experimental results demonstrate\nthat WonderTurbo achieves a remarkable 15X speedup compared to baseline\nmethods, while preserving excellent spatial consistency and delivering\nhigh-quality output.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T04:10:47Z"}
{"aid":"http://arxiv.org/abs/2504.02263v1","title":"MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated\n  Expert Parallelism","summary":"Mixture-of-Experts (MoE) showcases tremendous potential to scale large\nlanguage models (LLMs) with enhanced performance and reduced computational\ncomplexity. However, its sparsely activated architecture shifts feed-forward\nnetworks (FFNs) from being compute-intensive to memory-intensive during\ninference, leading to substantially lower GPU utilization and increased\noperational costs. We present MegaScale-Infer, an efficient and cost-effective\nsystem for serving large-scale MoE models. MegaScale-Infer disaggregates\nattention and FFN modules within each model layer, enabling independent\nscaling, tailored parallelism strategies, and heterogeneous deployment for both\nmodules. To fully exploit disaggregation in the presence of MoE's sparsity,\nMegaScale-Infer introduces ping-pong pipeline parallelism, which partitions a\nrequest batch into micro-batches and shuttles them between attention and FFNs\nfor inference. Combined with distinct model parallelism for each module,\nMegaScale-Infer effectively hides communication overhead and maximizes GPU\nutilization. To adapt to disaggregated attention and FFN modules and minimize\ndata transmission overhead (e.g., token dispatch), MegaScale-Infer provides a\nhigh-performance M2N communication library that eliminates unnecessary\nGPU-to-CPU data copies, group initialization overhead, and GPU synchronization.\nExperimental results indicate that MegaScale-Infer achieves up to 1.90x higher\nper-GPU throughput than state-of-the-art solutions.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-03T04:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.02288v1","title":"FEASE: Shallow AutoEncoding Recommender with Cold Start Handling via\n  Side Features","summary":"User and item cold starts present significant challenges in industrial\napplications of recommendation systems. Supplementing user-item interaction\ndata with metadata is a common solution-but often at the cost of introducing\nadditional biases. In this work, we introduce an augmented EASE model, i.e.\nFEASE, that seamlessly integrates both user and item side information to\naddress these cold start issues. Our straightforward, autoencoder-based method\nproduces a closed-form solution that leverages rich content signals for cold\nitems while refining user representations in data-sparse environments.\nImportantly, our method strikes a balance by effectively recommending cold\nstart items and handling cold start users without incurring extra bias, and it\nmaintains strong performance in warm settings. Experimental results demonstrate\nimproved recommendation accuracy and robustness compared to previous\ncollaborative filtering approaches. Moreover, our model serves as a strong\nbaseline for future comparative studies.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-03T05:27:55Z"}
{"aid":"http://arxiv.org/abs/2504.02293v1","title":"State-of-the-Art Translation of Text-to-Gloss using mBART : A case study\n  of Bangla","summary":"Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language\n(BdSL) remains a understudied domain. Specifically, there are no works on\nBangla text-to-gloss translation task. To address this gap, we begin by\naddressing the dataset problem. We take inspiration from grammatical rule based\ngloss generation used in Germany and American sign langauage (ASL) and adapt it\nfor BdSL. We also leverage LLM to generate synthetic data and use\nback-translation, text generation for data augmentation. With dataset prepared,\nwe started experimentation. We fine-tuned pretrained mBART-50 and\nmBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a\nnovel seq-to-seq model with multi-head attention. We observe significant high\nperformance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual\nmodel from Facebook. We then explored why we observe such high performance with\nmBART. We soon notice an interesting property of mBART -- it was trained on\nshuffled and masked text data. And as we know, gloss form has shuffling\nproperty. So we hypothesize that mBART is inherently good at text-to-gloss\ntasks. To find support against this hypothesis, we trained mBART-50 on\nPHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50\nfinetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,\nfar outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =\n55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on\nthe results, this study proposes a new paradigm for text-to-gloss task using\nmBART models. Additionally, our results show that BdSL text-to-gloss task can\ngreatly benefit from rule-based synthetic dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T05:47:51Z"}
{"aid":"http://arxiv.org/abs/2504.02295v1","title":"Dynamical Mordell-Lang problem for automorphisms of surfaces in positive\n  characteristic","summary":"We solve the dynamical Mordell-Lang problem in positive characteristic for\nautomorphisms of projective surfaces.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-03T05:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.02301v1","title":"Synchronization in bus systems with partially overlapping routes","summary":"In an increasingly interconnected world, understanding congestion-related\nphenomena in transportation and their underlying mechanisms is crucial for\nimproving efficiency. As the transportation system becomes denser, different\nmodes of transportation have more opportunities to interact with each other,\ngiving rise to emergent dynamics that simple models cannot explain. In this\nstudy, we investigate the synchronized motion of indirectly coupled\ntransportation modes. We develop a numerical simulation model on a\none-dimensional periodic lattice, where each point represents a bus station. In\nthis system, two types of buses operate: multiple local buses with\nnon-overlapping routes, each serving a specific zone, and a single global bus\nthat partially overlaps with the routes of the local buses. We perform\nnumerical simulations to examine how close the arrival times of these buses are\nto each other -- that is, how synchronized their motions are. When the number\nof zones is two, three, or five, robust synchronization occurs not only between\nthe global bus and the local buses, but also among the local buses themselves.\nIn contrast, no synchronization is found for other numbers of zones. We\ndeveloped a mathematical model using self-consistent equations and found that\ntwo distinct arrival patterns at the terminals must be considered. A stability\nanalysis reveals which pattern is ultimately realized in the simulations. Our\nresults show that transportation modes can exhibit coherent motion even when\nsharing only partial or no direct route overlaps. This outcome highlights that\nemergent behavior depends not only on local interactions but is also strongly\nshaped by the system's overall structural configuration.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-03T06:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.02304v1","title":"Measurement of LLM's Philosophies of Human Nature","summary":"The widespread application of artificial intelligence (AI) in various tasks,\nalong with frequent reports of conflicts or violations involving AI, has\nsparked societal concerns about interactions with AI systems. Based on\nWrightsman's Philosophies of Human Nature Scale (PHNS), a scale empirically\nvalidated over decades to effectively assess individuals' attitudes toward\nhuman nature, we design the standardized psychological scale specifically\ntargeting large language models (LLM), named the Machine-based Philosophies of\nHuman Nature Scale (M-PHNS). By evaluating LLMs' attitudes toward human nature\nacross six dimensions, we reveal that current LLMs exhibit a systemic lack of\ntrust in humans, and there is a significant negative correlation between the\nmodel's intelligence level and its trust in humans. Furthermore, we propose a\nmental loop learning framework, which enables LLM to continuously optimize its\nvalue system during virtual interactions by constructing moral scenarios,\nthereby improving its attitude toward human nature. Experiments demonstrate\nthat mental loop learning significantly enhances their trust in humans compared\nto persona or instruction prompts. This finding highlights the potential of\nhuman-based psychological assessments for LLM, which can not only diagnose\ncognitive biases but also provide a potential solution for ethical learning in\nartificial intelligence. We release the M-PHNS evaluation code and data at\nhttps://github.com/kodenii/M-PHNS.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.02310v1","title":"Improving Harmful Text Detection with Joint Retrieval and External\n  Knowledge","summary":"Harmful text detection has become a crucial task in the development and\ndeployment of large language models, especially as AI-generated content\ncontinues to expand across digital platforms. This study proposes a joint\nretrieval framework that integrates pre-trained language models with knowledge\ngraphs to improve the accuracy and robustness of harmful text detection.\nExperimental results demonstrate that the joint retrieval approach\nsignificantly outperforms single-model baselines, particularly in low-resource\ntraining scenarios and multilingual environments. The proposed method\neffectively captures nuanced harmful content by leveraging external contextual\ninformation, addressing the limitations of traditional detection models. Future\nresearch should focus on optimizing computational efficiency, enhancing model\ninterpretability, and expanding multimodal detection capabilities to better\ntackle evolving harmful content patterns. This work contributes to the\nadvancement of AI safety, ensuring more trustworthy and reliable content\nmoderation systems.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:37:55Z"}
{"aid":"http://arxiv.org/abs/2504.02324v1","title":"Dynamic Assortment Selection and Pricing with Censored Preference\n  Feedback","summary":"In this study, we investigate the problem of dynamic multi-product selection\nand pricing by introducing a novel framework based on a \\textit{censored\nmultinomial logit} (C-MNL) choice model. In this model, sellers present a set\nof products with prices, and buyers filter out products priced above their\nvaluation, purchasing at most one product from the remaining options based on\ntheir preferences. The goal is to maximize seller revenue by dynamically\nadjusting product offerings and prices, while learning both product valuations\nand buyer preferences through purchase feedback. To achieve this, we propose a\nLower Confidence Bound (LCB) pricing strategy. By combining this pricing\nstrategy with either an Upper Confidence Bound (UCB) or Thompson Sampling (TS)\nproduct selection approach, our algorithms achieve regret bounds of\n$\\tilde{O}(d^{\\frac{3}{2}}\\sqrt{T/\\kappa})$ and\n$\\tilde{O}(d^{2}\\sqrt{T/\\kappa})$, respectively. Finally, we validate the\nperformance of our methods through simulations, demonstrating their\neffectiveness.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T06:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02342v1","title":"On the twin-width of near-regular graphs","summary":"Twin-width is a recently introduced graph parameter based on the repeated\ncontraction of near-twins. It has shown remarkable utility in algorithmic and\nstructural graph theory, as well as in finite model theory -- particularly\nsince first-order model checking is fixed-parameter tractable when a witness\ncertifying small twin-width is provided. However, the behavior of twin-width in\nspecific graph classes, particularly cubic graphs, remains poorly understood.\nWhile cubic graphs are known to have unbounded twin-width, no explicit cubic\ngraph of twin-width greater than 4 is known.\n  This paper explores this phenomenon in regular and near-regular graph\nclasses. We show that extremal graphs of bounded degree and high twin-width are\nasymmetric, partly explaining their elusiveness. Additionally, we establish\nbounds for circulant and d-degenerate graphs, and examine strongly regular\ngraphs, which exhibit similar behavior to cubic graphs. Our results include\ndetermining the twin-width of Johnson graphs over 2-sets, and cyclic Latin\nsquare graphs.","main_category":"math.CO","categories":"math.CO,cs.DS","published":"2025-04-03T07:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.02344v1","title":"Boosting End-to-End Database Isolation Checking via Mini-Transactions\n  (Extended Version)","summary":"Transactional isolation guarantees are crucial for database correctness.\nHowever, recent studies have uncovered numerous isolation bugs in production\ndatabases. The common black-box approach to isolation checking stresses\ndatabases with large, concurrent, randomized transaction workloads and verifies\nwhether the resulting execution histories satisfy specified isolation levels.\nFor strong isolation levels such as strict serializability, serializability,\nand snapshot isolation, this approach often incurs significant end-to-end\nchecking overhead during both history generation and verification.\n  We address these inefficiencies through the novel design of Mini-Transactions\n(MTs). MTs are compact, short transactions that execute much faster than\ngeneral workloads, reducing overhead during history generation by minimizing\ndatabase blocking and transaction retries. By leveraging MTs' read-modify-write\npattern, we develop highly efficient algorithms to verify strong isolation\nlevels in linear or quadratic time. Despite their simplicity, MTs are\nsemantically rich and effectively capture common isolation anomalies described\nin the literature.\n  We implement our verification algorithms and an MT workload generator in a\ntool called MTC. Experimental results show that MTC outperforms\nstate-of-the-art tools in both history generation and verification. Moreover,\nMTC can detect bugs across various isolation levels in production databases\nwhile maintaining the effectiveness of randomized testing with general\nworkloads, making it a cost-effective solution for black-box isolation\nchecking.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-03T07:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.02353v1","title":"Interval Graphs are Reconstructible","summary":"A graph is reconstructible if it is determined up to isomorphism by the\nmultiset of its proper induced subgraphs. The reconstruction conjecture\npostulates that every graph of order at least 3 is reconstructible. We show\nthat interval graphs with at least three vertices are reconstructible. For this\npurpose we develop a technique to handle separations in the context of\nreconstruction. This resolves a major roadblock to using graph structure theory\nin the context of reconstruction. To apply our novel technique, we also develop\na resilient combinatorial structure theory for interval graphs. A consequence\nof our result is that interval graphs can be reconstructed in polynomial time.","main_category":"math.CO","categories":"math.CO,cs.DM,cs.DS","published":"2025-04-03T07:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.02379v1","title":"The Spear and the Ring: Emergent Structures in Magnetic Colloidal\n  Suspensions","summary":"We study from a mathematical point of view the nanoparticle model of a\nmagnetic colloid, presented by G. Klughertz. Our objective is to obtain\nproperties of stable stationary structures that arise in the long-time limit\nfor the magnetic nanoparticles dynamics following this model. In this article,\nwe present a detailed study of two specific structures using techniques from\nthe calculus of variations. The first, called the spear, consists of a chain of\naligned particles interacting via a Lennard-Jones potential. We establish\nexistence and uniqueness results, derive bounds on the distances between\nneighboring particles, and provide a sharp asymptotic description as the number\nof particles tends to infinity. The second structure, the ring, features\nparticles uniformly distributed along a circle. We prove its existence and\nuniqueness and derive an explicit formula for its radius.","main_category":"math-ph","categories":"math-ph,math.MP,math.OC","published":"2025-04-03T08:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.02383v1","title":"Reinforcement Learning for Solving the Pricing Problem in Column\n  Generation: Applications to Vehicle Routing","summary":"In this paper, we address the problem of Column Generation (CG) using\nReinforcement Learning (RL). Specifically, we use a RL model based on the\nattention-mechanism architecture to find the columns with most negative reduced\ncost in the Pricing Problem (PP). Unlike previous Machine Learning (ML)\napplications for CG, our model deploys an end-to-end mechanism as it\nindependently solves the pricing problem without the help of any heuristic. We\nconsider a variant of Vehicle Routing Problem (VRP) as a case study for our\nmethod. Through a set of experiments where our method is compared against a\nDynamic Programming (DP)-based heuristic for solving the PP, we show that our\nmethod solves the linear relaxation up to a reasonable objective gap within 9%\nin significantly shorter running times, up to over 300 times faster for\ninstances with 100 customers.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T08:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.02386v1","title":"VoiceCraft-Dub: Automated Video Dubbing with Neural Codec Language\n  Models","summary":"We present VoiceCraft-Dub, a novel approach for automated video dubbing that\nsynthesizes high-quality speech from text and facial cues. This task has broad\napplications in filmmaking, multimedia creation, and assisting voice-impaired\nindividuals. Building on the success of Neural Codec Language Models (NCLMs)\nfor speech synthesis, our method extends their capabilities by incorporating\nvideo features, ensuring that synthesized speech is time-synchronized and\nexpressively aligned with facial movements while preserving natural prosody. To\ninject visual cues, we design adapters to align facial features with the NCLM\ntoken space and introduce audio-visual fusion layers to merge audio-visual\ninformation within the NCLM framework. Additionally, we curate CelebV-Dub, a\nnew dataset of expressive, real-world videos specifically designed for\nautomated video dubbing. Extensive experiments show that our model achieves\nhigh-quality, intelligible, and natural speech synthesis with accurate lip\nsynchronization, outperforming existing methods in human perception and\nperforming favorably in objective evaluations. We also adapt VoiceCraft-Dub for\nthe video-to-speech task, demonstrating its versatility for various\napplications.","main_category":"cs.CV","categories":"cs.CV,eess.AS","published":"2025-04-03T08:24:47Z"}
{"aid":"http://arxiv.org/abs/2504.02395v1","title":"The quasi-semantic competence of LLMs: a case study on the part-whole\n  relation","summary":"Understanding the extent and depth of the semantic competence of \\emph{Large\nLanguage Models} (LLMs) is at the center of the current scientific agenda in\nArtificial Intelligence (AI) and Computational Linguistics (CL). We contribute\nto this endeavor by investigating their knowledge of the \\emph{part-whole}\nrelation, a.k.a. \\emph{meronymy}, which plays a crucial role in lexical\norganization, but it is significantly understudied. We used data from\nConceptNet relations \\citep{speer2016conceptnet} and human-generated semantic\nfeature norms \\citep{McRae:2005} to explore the abilities of LLMs to deal with\n\\textit{part-whole} relations. We employed several methods based on three\nlevels of analysis: i.) \\textbf{behavioral} testing via prompting, where we\ndirectly queried the models on their knowledge of meronymy, ii.) sentence\n\\textbf{probability} scoring, where we tested models' abilities to discriminate\ncorrect (real) and incorrect (asymmetric counterfactual) \\textit{part-whole}\nrelations, and iii.) \\textbf{concept representation} analysis in vector space,\nwhere we proved the linear organization of the \\textit{part-whole} concept in\nthe embedding and unembedding spaces. These analyses present a complex picture\nthat reveals that the LLMs' knowledge of this relation is only partial. They\nhave just a ``\\emph{quasi}-semantic'' competence and still fall short of\ncapturing deep inferential properties.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.02399v1","title":"Bayesian eco-evolutionary game dynamics","summary":"The symbiotic relationship between the frameworks of classical game theory\nand evolutionary game theory is well-established. However, evolutionary game\ntheorists have mostly tapped into the classical game of complete information\nwhere players are completely informed of all other players' payoffs. Of late,\nthere is a surge of interest in eco-evolutionary interactions where the\nenvironment's state is changed by the players' actions which, in turn, are\ninfluenced by the changing environment. However, in real life, the information\nabout the true environmental state must pass through some noisy channel (like\nusually imperfect sensory apparatus of the players) before it is perceived by\nthe players: The players naturally are prone to sometimes perceive the true\nstate erroneously. Given the uncertain perceived environment, the players may\nadopt bet-hedging kind of strategies in which they play different actions in\ndifferent perceptions. In a population of such ill-informed players, a player\nwould be confused about the information state of her opponent, and an\nincomplete information situation akin to a Bayesian game surfaces. In short, we\ncontemplate possibility of natural emergence of symbiotic relationship between\nthe frameworks of Bayesian games and eco-evolutionary games when the players\nare equipped with inefficient sensory apparatus. Herein, we illustrate this\nconnection using a setup of infinitely large, well-mixed population of players\nequipped with two actions for exploiting a resource (the environment) at two\ndifferent rates so that the resource state evolves accordingly. The state of\nthe resource impacts every player's decision of playing particular action. We\ninvestigate continuous state environment in the presence of a Gaussian noisy\nchannel. Employing the formalism of replicator dynamics, we find that noisy\ninformation can be effective in preventing resource from going extinct.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.TH,nlin.CD,physics.bio-ph","published":"2025-04-03T08:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.02406v1","title":"Lifecycle Management of Trustworthy AI Models in 6G Networks: The REASON\n  Approach","summary":"Artificial Intelligence (AI) is expected to play a key role in 6G networks\nincluding optimising system management, operation, and evolution. This requires\nsystematic lifecycle management of AI models, ensuring their impact on services\nand stakeholders is continuously monitored. While current 6G initiatives\nintroduce AI, they often fall short in addressing end-to-end intelligence and\ncrucial aspects like trust, transparency, privacy, and verifiability.\nTrustworthy AI is vital, especially for critical infrastructures like 6G. This\npaper introduces the REASON approach for holistically addressing AI's native\nintegration and trustworthiness in future 6G networks. The approach comprises\nAI Orchestration (AIO) for model lifecycle management, Cognition (COG) for\nperformance evaluation and explanation, and AI Monitoring (AIM) for tracking\nand feedback. Digital Twin (DT) technology is leveraged to facilitate real-time\nmonitoring and scenario testing, which are essential for AIO, COG, and AIM. We\ndemonstrate this approach through an AI-enabled xAPP use case, leveraging a DT\nplatform to validate, explain, and deploy trustworthy AI models.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-03T08:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.02414v1","title":"Effective field theory of Plasmas in Podolsky corrected Photonic field","summary":"A theory for abelian plasma permeated by photons has been developed\nconsidering QED (quantum electrodynamics) generalized in Podolsky\nelectrodynamics framework for consideration of higher order terms in\nelectromagnetic theory. The theory traces out photonic degrees of freedom in\nplasma and accounts for plasma dynamics mediated by photons by calculated\neffective Hamiltonian. New modes of propagation have been predicted along with\nsuppression of fields and collective behaviour. Non-Markovian behaviour is also\ndiscovered for plasma states and interactions in finite plasma system. This\nfinds applicability in solid-state plasma, plasma confinement of magnetic and\ninertial nature, and laser-plasma interaction when theory is reduced to local\ninteractions.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T09:10:19Z"}
{"aid":"http://arxiv.org/abs/2504.02432v1","title":"Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection","summary":"Robust low-rank approximation under row-wise adversarial corruption can be\nachieved with a single pass, randomized procedure that detects and removes\noutlier rows by thresholding their projected norms. We propose a scalable,\nnon-iterative algorithm that efficiently recovers the underlying low-rank\nstructure in the presence of row-wise adversarial corruption. By first\ncompressing the data with a Johnson Lindenstrauss projection, our approach\npreserves the geometry of clean rows while dramatically reducing\ndimensionality. Robust statistical techniques based on the median and median\nabsolute deviation then enable precise identification and removal of outlier\nrows with abnormally high norms. The subsequent rank-k approximation achieves\nnear-optimal error bounds with a one pass procedure that scales linearly with\nthe number of observations. Empirical results confirm that combining random\nsketches with robust statistics yields efficient, accurate decompositions even\nin the presence of large fractions of corrupted rows.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-03T09:43:27Z"}
{"aid":"http://arxiv.org/abs/2504.02444v1","title":"Isospectral oscillators as a resource for quantum information processing","summary":"We address quantum systems isospectral to the harmonic oscillator, as those\nfound within the framework of supersymmetric quantum mechanics, as potential\nresources for continuous variable quantum information. These deformed\noscillator potentials share the equally spaced energy levels of the shifted\nharmonic oscillator but differ significantly in that they are non-harmonic.\nConsequently, their ground states and thermal equilibrium states are no longer\nGaussian and exhibit non-classical properties. We quantify their\nnon-Gaussianity and evaluate their non-classicality using various measures,\nincluding quadrature squeezing, photon number squeezing, Wigner function\nnegativity, and quadrature coherence scale. Additionally, we employ quantum\nestimation theory to identify optimal measurement strategies and establish\nultimate precision bounds for inferring the deformation parameter. Our findings\nprove that quantum systems isospectral to the harmonic oscillator may represent\npromising platforms for quantum information with continuous variables. In turn,\nnon-Gaussian and non-classical stationary states may be obtained and these\nfeatures persist at non-zero temperature.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T10:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.02450v1","title":"CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles","summary":"To address the current challenges of low intelligence and simplistic vehicle\nbehavior modeling in autonomous driving simulation scenarios, this paper\nproposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles\n(CHARMS). The model can reason about the behavior of other vehicles like a\nhuman driver and respond with different decision-making styles, thereby\nimproving the intelligence and diversity of the surrounding vehicles in the\ndriving scenario. By introducing the Level-k behavioral game theory, the paper\nmodels the decision-making process of human drivers and employs deep\nreinforcement learning to train the models with diverse decision styles,\nsimulating different reasoning approaches and behavioral characteristics.\nBuilding on the Poisson cognitive hierarchy theory, this paper also presents a\nnovel driving scenario generation method. The method controls the proportion of\nvehicles with different driving styles in the scenario using Poisson and\nbinomial distributions, thus generating controllable and diverse driving\nenvironments. Experimental results demonstrate that CHARMS not only exhibits\nsuperior decision-making capabilities as ego vehicles, but also generates more\ncomplex and diverse driving scenarios as surrounding vehicles. We will release\ncode for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T10:15:19Z"}
{"aid":"http://arxiv.org/abs/2504.02457v1","title":"Size and shape of the trans-Neptunian object (470316) 2007 OC10:\n  Comparison with thermal data","summary":"The shapes of only 12 trans-Neptunian objects have been directly measured,\noffering crucial insights into their internal structure. These properties are\nstrongly connected to the processes that shaped the early Solar System, and\nprovide important clues about its evolution.\n  The aim of the present work is to characterise the size, shape, geometric\nalbedo, and beaming parameter of the TNO (470316) 2007 OC10 . We compared these\nvalues to the effective diameter and geometric albedo obtained from thermal\ndata by the TNOs are Cool survey. We also combined occultation and thermal data\nto constrain the size of a putative unresolved satellite.\n  We predicted an occultation of the star Gaia DR3 2727866328215869952 by 2007\nOC10 on 2022 August 22. Four stations detected the occultation. We implemented\nan elliptical shape model for the projection of 2007 OC10. Following a Bayesian\napproach, we obtained the posterior probability density in the model parameter\nspace using a Markov chain Monte Carlo method.\n  The elliptical limb of 2007 OC10 has semi-axes of $ 215^{+10}_{-7} \\times 141\n^{+24}_{-23}$ km, and thus the projected axis ratio is $b/a =\n0.58^{+0.16}_{-0.16}$. The area-equivalent diameter is $330^{+56}_{-55}$,km.\nFrom our own absolute magnitude value of $H_V = 5.40 \\pm 0.02$, the geometric\nalbedo is $p_V = 11.2 ^{+2.1}_{-5.0}$ %. Combining the occultation results with\nthermal data, we constrain the beaming parameter to $\\eta =\n1.42^{+0.75}_{-0.58}$. Occultation data reveal that the star is double. The\nsecondary star has a position angle with respect to the primary of\n$56^{+3}_{-17}$ degrees, has an angular separation of $57^{+4}_{-11}$ mas, and\nis $1.18^{+0.07}_{-0.07}$ magnitudes fainter than the primary.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T10:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.02459v1","title":"A Physics-Informed Meta-Learning Framework for the Continuous Solution\n  of Parametric PDEs on Arbitrary Geometries","summary":"In this work, we introduce implicit Finite Operator Learning (iFOL) for the\ncontinuous and parametric solution of partial differential equations (PDEs) on\narbitrary geometries. We propose a physics-informed encoder-decoder network to\nestablish the mapping between continuous parameter and solution spaces. The\ndecoder constructs the parametric solution field by leveraging an implicit\nneural field network conditioned on a latent or feature code. Instance-specific\ncodes are derived through a PDE encoding process based on the second-order\nmeta-learning technique. In training and inference, a physics-informed loss\nfunction is minimized during the PDE encoding and decoding. iFOL expresses the\nloss function in an energy or weighted residual form and evaluates it using\ndiscrete residuals derived from standard numerical PDE methods. This approach\nresults in the backpropagation of discrete residuals during both training and\ninference.\n  iFOL features several key properties: (1) its unique loss formulation\neliminates the need for the conventional encode-process-decode pipeline\npreviously used in operator learning with conditional neural fields for PDEs;\n(2) it not only provides accurate parametric and continuous fields but also\ndelivers solution-to-parameter gradients without requiring additional loss\nterms or sensitivity analysis; (3) it can effectively capture sharp\ndiscontinuities in the solution; and (4) it removes constraints on the geometry\nand mesh, making it applicable to arbitrary geometries and spatial sampling\n(zero-shot super-resolution capability). We critically assess these features\nand analyze the network's ability to generalize to unseen samples across both\nstationary and transient PDEs. The overall performance of the proposed method\nis promising, demonstrating its applicability to a range of challenging\nproblems in computational mechanics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T10:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.02464v1","title":"CornerPoint3D: Look at the Nearest Corner Instead of the Center","summary":"3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T10:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.02465v1","title":"RASP: Revisiting 3D Anamorphic Art for Shadow-Guided Packing of\n  Irregular Objects","summary":"Recent advancements in learning-based methods have opened new avenues for\nexploring and interpreting art forms, such as shadow art, origami, and sketch\nart, through computational models. One notable visual art form is 3D Anamorphic\nArt in which an ensemble of arbitrarily shaped 3D objects creates a realistic\nand meaningful expression when observed from a particular viewpoint and loses\nits coherence over the other viewpoints. In this work, we build on insights\nfrom 3D Anamorphic Art to perform 3D object arrangement. We introduce RASP, a\ndifferentiable-rendering-based framework to arrange arbitrarily shaped 3D\nobjects within a bounded volume via shadow (or silhouette)-guided optimization\nwith an aim of minimal inter-object spacing and near-maximal occupancy.\nFurthermore, we propose a novel SDF-based formulation to handle inter-object\nintersection and container extrusion. We demonstrate that RASP can be extended\nto part assembly alongside object packing considering 3D objects to be \"parts\"\nof another 3D object. Finally, we present artistic illustrations of multi-view\nanamorphic art, achieving meaningful expressions from multiple viewpoints\nwithin a single ensemble.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T10:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.02483v1","title":"Robust direction-dependent gain-calibration of beam-modelling errors far\n  from the target field","summary":"Many astronomical questions require deep, wide-field observations at low\nradio frequencies. Phased arrays like LOFAR and SKA-low are designed for this,\nbut have inherently unstable element gains, leading to time, frequency and\ndirection-dependent gain errors. Precise direction-dependent calibration of\nobservations is therefore key to reaching the highest possible dynamic range.\nMany tools for direction-dependent calibration utilise sky and beam models to\ninfer gains. However, these calibration tools struggle with precision\ncalibration for relatively bright (e.g. A-team) sources far from the beam\ncentre. Therefore, the point-spread-function of these sources can potentially\nobscure a faint signal of interest. We show that, and why, the assumption of a\nsmooth gain solution per station fails for realistic radio interferometers, and\nhow this affects gain-calibration results. Subsequently, we introduce an\nimprovement for smooth spectral gain constraints for direction-dependent\ngain-calibration algorithms, in which the level of regularisation is weighted\nby the expected station response to the sky model. We test this method using\ndirection-dependent calibration method DDECal and physically-motivated beam\nmodelling errors for LOFAR-HBA stations. The new method outperforms the\nstandard method for various calibration settings near nulls in the beam, and\nmatches the standard inverse-variance-weighted method's performance for the\nremainder of the data. The proposed method is especially effective for short\nbaselines, both in visibility and image space. Improved direction-dependent\ngain-calibration is critical for future high-precision SKA-low observations,\nwhere higher sensitivity, increased antenna beam complexity, and mutual\ncoupling call for better off-axis source subtraction, which may not be achieved\nthrough improved beam models alone.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-04-03T11:07:25Z"}
{"aid":"http://arxiv.org/abs/2504.02484v1","title":"Bochner-Riesz commutators on Mtivier groups: boundedness and\n  compactness","summary":"In this paper, we prove the boundedness and compactness properties of\nBochner-Riesz commutator associated to the sub-Laplacians on M\\'etivier groups.\nWe show that the smoothness parameter can be expressed in terms of the\ntopological dimension rather than the homogeneous dimension of the M\\'etivier\ngroups.","main_category":"math.CA","categories":"math.CA","published":"2025-04-03T11:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.02500v1","title":"An Overview of Josephson Junctions Based QPUs","summary":"Quantum processing units (QPUs) based on superconducting Josephson junctions\npromise significant advances in quantum computing. However, they face critical\nchallenges. Decoherence, scalability limitations, and error correction overhead\nhinder practical, fault-tolerant implementations. This paper investigates these\nissues by exploring both fundamental quantum phenomena and practical\nengineering challenges. We analyze key quantum mechanical principles such as\nsuperposition, entanglement, and decoherence that govern the behavior of\nsuperconducting qubits. We also discuss quantum tunneling, Cooper pair\nformation, and the operational mechanics of Josephson junctions in detail.\nAdditionally, we present a comparative analysis with alternative architectures,\nincluding ion trap and photonic systems. This comparison highlights the unique\nadvantages and trade-offs of Josephson junction-based QPUs. Our findings\nemphasize the critical role of material innovations and optimized control\ntechniques. These advances are essential for mitigating noise and decoherence\nand for realizing robust, scalable quantum computing.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cs.ET,quant-ph","published":"2025-04-03T11:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.02508v1","title":"APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian\n  Based Reconstruction for Vision Transformers","summary":"Vision Transformers (ViTs) have become one of the most commonly used\nbackbones for vision tasks. Despite their remarkable performance, they often\nsuffer significant accuracy drops when quantized for practical deployment,\nparticularly by post-training quantization (PTQ) under ultra-low bits.\nRecently, reconstruction-based PTQ methods have shown promising performance in\nquantizing Convolutional Neural Networks (CNNs). However, they fail when\napplied to ViTs, primarily due to the inaccurate estimation of output\nimportance and the substantial accuracy degradation in quantizing post-GELU\nactivations. To address these issues, we propose \\textbf{APHQ-ViT}, a novel PTQ\napproach based on importance estimation with Average Perturbation Hessian\n(APH). Specifically, we first thoroughly analyze the current approximation\napproaches with Hessian loss, and propose an improved average perturbation\nHessian loss. To deal with the quantization of the post-GELU activations, we\ndesign an MLP Reconstruction (MR) method by replacing the GELU function in MLP\nwith ReLU and reconstructing it by the APH loss on a small unlabeled\ncalibration set. Extensive experiments demonstrate that APHQ-ViT using linear\nquantizers outperforms existing PTQ methods by substantial margins in 3-bit and\n4-bit across different vision tasks. The source code is available at\nhttps://github.com/GoatWu/APHQ-ViT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T11:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.02510v1","title":"A complimentary impedance spectroscopy biosensing method with graphene","summary":"We present a method where a bioactive functional layer on an electrically\nconductive thin film with high sheet resistance can be effectively used for\ncomplementary electrochemical impedance spectroscopy biosensing. The functional\nlayer's properties, such as double-layer capacitance and charge-transfer\nresistance, influence the complex impedance of the thin film in direct contact\nwith the layer. These measurements can be performed using a simple\nlow-frequency setup with a lock-in amplifier. When graphene is used as the\nresistive thin film, the signal may also include contributions from graphene's\nquantum capacitance, which is sensitive to charge transfer to and from the\ngraphene. Unlike in traditional graphene biosensors, changes in electrolyte\nproperties over time, such as those caused by the dissolution of ambient gases,\ndo not significantly affect AC measurements. This technique supports biosensor\nminiaturization, ensures stable operation, and provides reliable biomarker\ndetection with a high signal-to-noise ratio.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph,physics.bio-ph","published":"2025-04-03T11:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.02513v1","title":"Adaptive Bivariate Quarklet Tree Approximation via Anisotropic Tensor\n  Quarklets","summary":"This paper deals with near-best approximation of a given bivariate function\nusing elements of quarkonial tensor frames. For that purpose we apply\nanisotropic tensor products of the univariate B-spline quarklets introduced\naround 2017 by Dahlke, Keding and Raasch. We introduce the concept of bivariate\nquarklet trees and develop an adaptive algorithm which allows for generalized\nhp-approximation of a given bivariate function by selected frame elements. It\nis proved that this algorithm is near-best, which means that as long as some\nstandard conditions concerning local errors are fulfilled it provides an\napproximation with an error close to that one of the best possible quarklet\ntree approximation. For this algorithm the complexity is investigated.\nMoreover, we use our techniques to approximate a bivariate test function with\ninverse-exponential rates of convergence. It can be expected that the results\npresented in this paper serve as important building block for the design of\nadaptive wavelet-hp-methods for solving PDEs in the bivariate setting with very\ngood convergence properties.","main_category":"math.NA","categories":"math.NA,cs.NA,math.FA","published":"2025-04-03T11:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.02524v1","title":"SelfMedHPM: Self Pre-training With Hard Patches Mining Masked\n  Autoencoders For Medical Image Segmentation","summary":"In recent years, deep learning methods such as convolutional neural network\n(CNN) and transformers have made significant progress in CT multi-organ\nsegmentation. However, CT multi-organ segmentation methods based on masked\nimage modeling (MIM) are very limited. There are already methods using MAE for\nCT multi-organ segmentation task, we believe that the existing methods do not\nidentify the most difficult areas to reconstruct. To this end, we propose a MIM\nself-training framework with hard patches mining masked autoencoders for CT\nmulti-organ segmentation tasks (selfMedHPM). The method performs ViT\nself-pretraining on the training set of the target data and introduces an\nauxiliary loss predictor, which first predicts the patch loss and determines\nthe location of the next mask. SelfMedHPM implementation is better than various\ncompetitive methods in abdominal CT multi-organ segmentation and body CT\nmulti-organ segmentation. We have validated the performance of our method on\nthe Multi Atlas Labeling Beyond The Cranial Vault (BTCV) dataset for abdomen\nmult-organ segmentation and the SinoMed Whole Body (SMWB) dataset for body\nmulti-organ segmentation tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:28:21Z"}
{"aid":"http://arxiv.org/abs/2504.02542v1","title":"Audio-visual Controlled Video Diffusion with Masked Selective State\n  Spaces Modeling for Natural Talking Head Generation","summary":"Talking head synthesis is vital for virtual avatars and human-computer\ninteraction. However, most existing methods are typically limited to accepting\ncontrol from a single primary modality, restricting their practical utility. To\nthis end, we introduce \\textbf{ACTalker}, an end-to-end video diffusion\nframework that supports both multi-signals control and single-signal control\nfor talking head video generation. For multiple control, we design a parallel\nmamba structure with multiple branches, each utilizing a separate driving\nsignal to control specific facial regions. A gate mechanism is applied across\nall branches, providing flexible control over video generation. To ensure\nnatural coordination of the controlled video both temporally and spatially, we\nemploy the mamba structure, which enables driving signals to manipulate feature\ntokens across both dimensions in each branch. Additionally, we introduce a\nmask-drop strategy that allows each driving signal to independently control its\ncorresponding facial region within the mamba structure, preventing control\nconflicts. Experimental results demonstrate that our method produces\nnatural-looking facial videos driven by diverse signals and that the mamba\nlayer seamlessly integrates multiple driving modalities without conflict.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.02547v1","title":"A smooth multi-group Gaussian Mixture Model for cellwise robust\n  covariance estimation","summary":"Are data groups which are pre-defined by expert opinions or medical diagnoses\ncorresponding to groups based on statistical modeling? For which reason might\nobservations be inconsistent? This contribution intends to answer both\nquestions by proposing a novel multi-group Gaussian mixture model that accounts\nfor the given group context while allowing high flexibility. This is achieved\nby assuming that the observations of a particular group originate not from a\nsingle distribution but from a Gaussian mixture of all group distributions.\nMoreover, the model provides robustness against cellwise outliers, thus against\natypical data cells of the observations. The objective function can be\nformulated as a likelihood problem and optimized efficiently. We also derive\nthe theoretical breakdown point of the estimators, an innovative result in this\ncontext to quantify the degree of robustness to cellwise outliers. Simulations\ndemonstrate the excellent performance and the advantages to alternative models\nand estimators. Applications from different areas illustrate the strength of\nthe method, particularly in investigating observations which are on the overlap\nof different groups.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T12:54:21Z"}
{"aid":"http://arxiv.org/abs/2504.02556v1","title":"Superconductivity in the Medium-Entropy/High-Entropy Re-based Alloys\n  with a Non-Centrosymmetric $$-Mn Lattice","summary":"Medium or high-entropy alloys (MEAs-HEAs) and rhenium-based compounds with a\nnon-centrosymmetric (NC) structure have received a lot of attention for\noffering a fertile soil in search for unconventional superconductivity. Here,\nfive previously unreported NC Re-based MEA-HEA superconductors with an\n$\\alpha$-Mn lattice are successfully synthesized, with their superconducting\ntransition temperatures (Tcs) ranging from 4 to 5 K. An increase in the\nsuperconducting transition temperature (Tc) can be achieved by modulating the\nvalence electron count (VEC) through compositional adjustments. Magnetization\nmeasurements confirm that all the synthesized Re-based MEA-HEAs are bulk\ntype-II superconductors. Specific heat analysis reveals that the\nsuperconducting state of these HEAs can be well described by a single-gap\ns-wave model. Our results show that the Kadowaki-Woods ratio of these\n$\\alpha$-Mn MEA/HEA superconductors are close to the typical value of heavy\nfermion compounds, suggesting the existence of strong electronic correlation.\nThese findings provide promising material platforms to study the role of high\ndisorder in the origin of superconductivity in the NC MEAs-HEAs.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-03T13:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.02559v1","title":"Leveraging LLM For Synchronizing Information Across Multilingual Tables","summary":"The vast amount of online information today poses challenges for non-English\nspeakers, as much of it is concentrated in high-resource languages such as\nEnglish and French. Wikipedia reflects this imbalance, with content in\nlow-resource languages frequently outdated or incomplete. Recent research has\nsought to improve cross-language synchronization of Wikipedia tables using\nrule-based methods. These approaches can be effective, but they struggle with\ncomplexity and generalization. This paper explores large language models (LLMs)\nfor multilingual information synchronization, using zero-shot prompting as a\nscalable solution. We introduce the Information Updation dataset, simulating\nthe real-world process of updating outdated Wikipedia tables, and evaluate LLM\nperformance. Our findings reveal that single-prompt approaches often produce\nsuboptimal results, prompting us to introduce a task decomposition strategy\nthat enhances coherence and accuracy. Our proposed method outperforms existing\nbaselines, particularly in Information Updation (1.79%) and Information\nAddition (20.58%), highlighting the model strength in dynamically updating and\nenriching data across architectures","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.02572v1","title":"Language Models reach higher Agreement than Humans in Historical\n  Interpretation","summary":"This paper compares historical annotations by humans and Large Language\nModels. The findings reveal that both exhibit some cultural bias, but Large\nLanguage Models achieve a higher consensus on the interpretation of historical\nfacts from short texts. While humans tend to disagree on the basis of their\npersonal biases, Large Models disagree when they skip information or produce\nhallucinations. These findings have significant implications for digital\nhumanities, enabling large-scale annotation and quantitative analysis of\nhistorical data. This offers new educational and research opportunities to\nexplore historical interpretations from different Language Models, fostering\ncritical thinking about bias.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.02620v1","title":"Efficient Model Editing with Task-Localized Sparse Fine-tuning","summary":"Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CV","published":"2025-04-03T14:20:06Z"}
{"aid":"http://arxiv.org/abs/2504.02629v1","title":"An efficient and energy-stable IMEX splitting scheme for dispersed\n  multiphase flows","summary":"Volume-averaged Navier--Stokes equations are used in various applications to\nmodel systems with two or more interpenetrating phases. Each fluid obeys its\nown momentum and mass equations, and the phases are typically coupled via drag\nforces and a shared pressure. Monolithic solvers can therefore be very\nexpensive and difficult to implement. On the other hand, designing robust\nsplitting schemes requires making both pressure and drag forces explicit\nwithout sacrificing temporal stability. In this context, we derive a new\nfirst-order pressure-correction method based on the incompressibility of the\nmean velocity field, combined with an explicit treatment of the drag forces.\nFurthermore, the convective terms are linearised using extrapolated velocities,\nwhile the viscous terms are treated semi-implicitly. This gives us an\nimplicit-explicit (IMEX) method that is very robust not only due to its\nunconditional energy stability, but also because it does not require any type\nof fixed-point iterations. Each time step involves only linear, scalar\ntransport equations and a single Poisson problem as building blocks, thereby\noffering both efficiency and simplicity. We rigorously prove temporal stability\nwithout any time-step size restrictions, and the theory is confirmed through\ntwo-phase numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T14:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.02630v1","title":"Grammar-based Ordinary Differential Equation Discovery","summary":"The understanding and modeling of complex physical phenomena through\ndynamical systems has historically driven scientific progress, as it provides\nthe tools for predicting the behavior of different systems under diverse\nconditions through time. The discovery of dynamical systems has been\nindispensable in engineering, as it allows for the analysis and prediction of\ncomplex behaviors for computational modeling, diagnostics, prognostics, and\ncontrol of engineered systems. Joining recent efforts that harness the power of\nsymbolic regression in this domain, we propose a novel framework for the\nend-to-end discovery of ordinary differential equations (ODEs), termed\nGrammar-based ODE Discovery Engine (GODE). The proposed methodology combines\nformal grammars with dimensionality reduction and stochastic search for\nefficiently navigating high-dimensional combinatorial spaces. Grammars allow us\nto seed domain knowledge and structure for both constraining, as well as,\nexploring the space of candidate expressions. GODE proves to be more sample-\nand parameter-efficient than state-of-the-art transformer-based models and to\ndiscover more accurate and parsimonious ODE expressions than both genetic\nprogramming- and other grammar-based methods for more complex inference tasks,\nsuch as the discovery of structural dynamics. Thus, we introduce a tool that\ncould play a catalytic role in dynamics discovery tasks, including modeling,\nsystem identification, and monitoring tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CE,cs.SC","published":"2025-04-03T14:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.02675v1","title":"Cybersickness Assessment Framework(TestBed): Towards a Standardization\n  of Experiments","summary":"Investigating cybersickness (CS) in virtual reality (VR) often requires\nsignificant resources to create the VR environment and manage other\nexperiment-related aspects. Additionally, slight differences in VR content\nacross studies can lead to conflicting results. To address these challenges, we\npropose a standardized assessment framework to facilitate cybersickness\nresearch. The main goal is to enable consistent and comparable CS-related\nexperiments. By establishing this common foundation, researchers can better\nevaluate and compare the impact of various factors on cybersickness. We provide\na comprehensive explanation of the conceptual designs, detail the technical\nimplementation, and offer instructions for using the proposed framework.\nLastly, we conclude by discussing the limitations and potential avenues for\nfuture development.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:15:10Z"}
{"aid":"http://arxiv.org/abs/2504.02683v1","title":"Probing patchy reionisation with JWST: IGM opacity constraints from the\n  Lyman-$$ forest of galaxies in legacy extragalactic fields","summary":"We present the first characterization of the Gunn-Peterson trough in\nhigh-redshift galaxies using public JWST NIRSpec spectroscopy. This enables us\nto derive the first galaxy-based IGM opacity measurements at the end of\nreionisation. Using galaxy spectra has several advantages over quasar spectra:\nit enables measurements of the IGM opacity in any extragalactic field over a\ncontinuous redshift range $4\\lesssim z\\lesssim 7$, as well as measurements of\nthe intrinsic Lyman-$\\beta$ opacity. Our novel constraints are in good\nagreement with state-of-the-art ground-based quasar Lyman-$\\alpha$ forest\nobservations, and will become competitive as the number of JWST $z>5$ galaxy\nspectra rapidly increases. We also provide the first constraints on the\nuncontaminated Lyman-$\\beta$ opacity at $5<z<6$. Finally, we demonstrate the\npower of JWST to connect the ionisation state of the IGM to the sources of\nreionisation in a single extragalactic field. We show that a previously\nreported galaxy overdensity and an excess of Lyman-$\\alpha$ emitters detected\nwith JWST in GOODS-South at $z=5.8-5.9$ coincides with an anomalously low IGM\nopacity to Lyman-$\\alpha$ at this redshift. The local photo-ionisation rate\nexcess can be fully accounted for by the cumulative ionising output of\n$M_{\\rm{UV}}\\lesssim -10$ galaxies in the overdensity, provided they have\n$\\log_{10}\\langle \\xi_{\\rm{ion}} f_{\\rm{esc}} / \\ [\\rm{erg}^{-1}\\rm{Hz}]\\rangle\n= 24.7$ (or equivalently $\\log_{10}\\xi_{\\rm{ion}} / \\\n[\\rm{erg}^{-1}\\rm{Hz}]=25.4$ and $f_{\\rm{esc}}=20\\%$). Overall, this\nbreakthrough offers a new way to connect the galaxy large-scale structure to\nthe state of the IGM, potentially enabling us to precisely identify the sources\nof reionisation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-03T15:24:01Z"}
{"aid":"http://arxiv.org/abs/2504.02691v1","title":"Hong-Ou-Mandel interference of more than 10 indistinguishable atoms","summary":"When two indistinguishable bosons interfere at a beam splitter, they both\nexit through the same output port. This foundational quantum-mechanical\nphenomenon, known as the Hong-Ou-Mandel (HOM) effect, has become a cornerstone\nin the field of quantum information. It also extends to many indistinguishable\nparticles, resulting in complex interference patterns. However, despite of its\nfundamental and applied interest, the many-particle effect has only been\nobserved in notoriously lossy photonic systems, but a realization with atomic\nsystems has remained elusive until now. Here, we demonstrate HOM interference\nwith up to 12 indistinguishable neutral atoms in a system with negligible loss.\nOur single-particle counting clearly reveals parity oscillations, a bunching\nenvelope and genuine multi-partite entanglement, defining features of the\nmulti-particle HOM effect. Our technique offers the potential for scaling to\nmuch larger numbers, presenting promising applications in quantum information\nwith indistinguishable particles and Heisenberg-limited atom interferometry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.02698v1","title":"SCMPPI: Supervised Contrastive Multimodal Framework for Predicting\n  Protein-Protein Interactions","summary":"Protein-Protein Interaction (PPI) prediction is a key task in uncovering\ncellular functional networks and disease mechanisms. However, traditional\nexperimental methods are time-consuming and costly, and existing computational\nmodels face challenges in cross-modal feature fusion, robustness, and\nfalse-negative suppression. In this paper, we propose a novel supervised\ncontrastive multimodal framework, SCMPPI, for PPI prediction. By integrating\nprotein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology\ninformation (Node2Vec graph embedding), and combining an improved supervised\ncontrastive learning strategy, SCMPPI significantly enhances PPI prediction\nperformance. For the PPI task, SCMPPI introduces a negative sample filtering\nmechanism and modifies the contrastive loss function, effectively optimizing\nmultimodal features. Experiments on eight benchmark datasets, including yeast,\nhuman, and H.pylori, show that SCMPPI outperforms existing state-of-the-art\nmethods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)\nand AUC (99.62%), and demonstrates strong generalization in cross-species\nprediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been\nsuccessfully applied to CD9 networks, the Wnt pathway, and cancer-specific\nnetworks, providing a reliable tool for disease target discovery. This\nframework also offers a new paradigm for multimodal biological information\nfusion and contrastive learning in collaborative optimization for various\ncombined predictions.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-04-03T15:34:02Z"}
{"aid":"http://arxiv.org/abs/2504.02702v1","title":"Background-Enhanced Axion Force by Axion Dark Matter","summary":"We investigate the influence of axion dark matter as a background on the\nspin-independent axion forces between nucleons. Notably, we find that the\npotential for axion forces scales from $1/r^3$ in a vacuum-only context to\n$1/r$ when the background effect is considered. Also, the magnitude of the\naxion force is substantially amplified in proportion to the number density of\naxion DM particles. These enhancements significantly improve the constraints on\nthe axion decay constant by several orders of magnitude, across a broad range\nof axion masses, based on the fifth-force experiments such as the Casimir-less\nand torsion balance tests. This suggests that such experiments are more\neffective than previously understood in detecting axions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T15:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02707v1","title":"Symplectic techniques for stochastic differential equations on reductive\n  Lie groups with applications to Langevin diffusions","summary":"We show how Langevin diffusions can be interpreted in the context of\nstochastic Hamiltonian systems with structure-preserving noise and dissipation\non reductive Lie groups. Reductive Lie groups provide the setting in which the\nLie group structure is compatible with Riemannian structures, via the existence\nof bi-invariant metrics. This structure allows for the explicit construction of\nRiemannian Brownian motion via symplectic techniques, which permits the study\nof Langevin diffusions with noise in the position coordinate as well as\nLangevin diffusions with noise in both momentum and position.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T15:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.02726v1","title":"Constraining hot and cold nuclear matter properties from heavy-ion\n  collisions and deep-inelastic scattering","summary":"We perform a global analysis of deep-inelastic $e+p$ scattering data from\nHERA and transverse energy distributions in $p+p$ and $p+\\Pb$ collisions,\nalongside charged hadron multiplicities in $\\Pb+\\Pb$ collisions at\n$\\sqrt{s_{\\mathrm{NN}}} = 5.02\\;\\mathrm{TeV}$ from ALICE. Using a\nsaturation-based initial state model grounded in high-energy QCD, we determine\nthe early-time non-equilibrium shear viscosity to entropy density ratio\n$\\eta/s$ of the quark-gluon plasma. Our results provide new insights into the\nearly-time transport properties of nuclear matter under extreme conditions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-03T16:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.02729v1","title":"Vortex Flows in the Solar Atmosphere: Detection and Heating Mechanisms\n  in 3D MHD Numerical Simulations","summary":"Vortex flows are structures associated with the rotation of the plasma and/or\nthe magnetic field that are present throughout the solar atmosphere. In recent\nyears, their study has become increasingly important, as they are present on a\nwide variety of temporal and spatial scales and can connect several layers of\nthe solar atmosphere. In this work, we focused on the detection and analysis of\nthese structures in an automatic way. We use realistic 3D MHD numerical\nsimulations obtained with the Mancha3D code at different magnetic field\nconfigurations and spatial resolutions. The vortex detection has been performed\nusing the novel SWIRL code. We have been able to determine multiple structures\nassociated with small and large scale vortices that extend in height in our\nsimulations. We performed a statistical analysis of these structures,\nquantifying their number and typical sizes, as well as their temperature and\nheating profiles, confirming their importance in the energy transport.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T16:12:11Z"}
{"aid":"http://arxiv.org/abs/2504.02731v1","title":"How Election Shocks Move Markets: Evidence from Sectoral Stock Prices","summary":"This paper examines the effects of U.S. presidential election cycles on\nsectoral stock markets. Using a high-frequency identification approach, I\nconstruct a novel \"election shock'' series, which captures exogenous surprises\nin election probabilities. Aside from election outcomes, the largest shocks are\nassociated with events that are orthogonal to innovations in the macroeconomy,\ne.g., scandals and debates. These shocks have immediate effects on asset prices\nin sectors that are differentially impacted by the policy platforms of the two\nmajor U.S. political parties. In particular, shocks favoring Republican\n(Democratic) candidates increase (decrease) the asset prices in the energy and\ndefense sectors, while decreasing (increasing) prices in the clean energy\nsector. These effects persist overtime.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-03T16:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.02752v1","title":"Anomalous vortex Hall effect in a ferromagnet/superconductor\n  heterostructure","summary":"The coexistence of superconductivity and ferromagnetism is a fascinating and\ncomplex phenomenon in condensed matter physics, as these two states are\ntypically mutually exclusive due to their competing spin configurations.\nHowever, the interplay between these two orders through the proximity effect\nhas been a subject of intense research as it opens up possibilities for novel\ntechnological applications. Here, we report the coexistence of\nsuperconductivity and ferromagnetism in superconducting\n{\\delta}-TaN/ferromagnetic CoFeB heterostructures grown by facing-target\nsputtering. Superconducting states are comprehensively investigated, with\nevidence of strong correlation between the superconducting and ferromagnetic\norder parameters. In particular, we observed an anomalous Hall signal without\nthe presence of the magnetic field in the mixed state of the superconducting\ntransition near the critical temperature. Systematic characterizations of the\nHall resistance under varying temperatures and magnetic fields attribute this\nbehavior to the vortex Hall effect (VHE), whereby superconducting vortices in\nthe mixed state undergo transverse motions near the critical temperature.\nUnlike previously reported VHEs in conventional type-II superconductors, the\nanomalous VHE in TaN is induced by the stray field in the underlying CoFeB\nlayers. The concurrency of strong spin-orbit coupling, the superconductivity in\nthe TaN layer, and the highly spin-polarized ferromagnetic ordering in the\nCoFeB layer offers new insights into proximity-induced vortex dynamics and the\ndesign of novel superconducting spintronic devices.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-03T16:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.02759v1","title":"Production of protons, deuterons and tritons in argon-nucleus\n  interactions at 3.2 AGeV","summary":"Results of the BM@N experiment at the Nuclotron/NICA complex on the\nproduction of protons, deuterons and tritons in interactions of an argon beam\nof 3.2 AGeV with fixed targets of C, Al, Cu, Sn and Pb are presented.\nTransverse mass spectra, rapidity distributions and multiplicities of protons,\ndeuterons and tritons are measured. The results are treated within a\ncoalescence approach and compared with predictions of theoretical models and\nwith other measurements","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T16:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.02767v1","title":"How Deep Do Large Language Models Internalize Scientific Literature and\n  Citation Practices?","summary":"The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.","main_category":"cs.DL","categories":"cs.DL,cs.AI,cs.LG,cs.SI","published":"2025-04-03T17:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.02772v1","title":"Interpreting gravitational fields of Topologically Massive Gravity using\n  geodesic deviation","summary":"We study relative motion of nearby test particles in Topologically Massive\nGravity (TMG) in three spacetime dimensions, using the equation of geodesic\ndeviation. We show that, in a suitable reference frame, the influence of any\ngravitational field can be decomposed into transverse, longitudinal, and\nNewtonian components, which are directly related to the Cotton scalars of the\nNewman-Penrose-type. In particular, we prove that Cotton type N spacetimes\nexhibit a purely transverse gravitational effect on test particles, and can\nthus be reasonably interpreted as specific gravitational waves with a single\npolarization mode in TMG. The influence of the cosmological constant manifests\nitself as an isotropic effect. We also discuss the physical interpretation of\nspacetimes of specific algebraic types, as well as the influence of various\nmatter fields, namely pure radiation, perfect fluid, and electromagnetic field.\nAs an example, we provide an explicit analysis of TN-waves and pp-waves in\nthree-dimensional TMG.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:08:37Z"}
{"aid":"http://arxiv.org/abs/2504.02787v1","title":"A 3D view of dwarf galaxies with Gaia and VLT/FLAMES II. The Sextans\n  dwarf spheroidal","summary":"The Sextans dwarf spheroidal galaxy has been challenging to study in a\ncomprehensive way as it is highly extended on the sky, with an uncertain but\nlarge tidal radius of between 80-160 arcminutes (or 3-4kpc), and an extremely\nlow central surface brightness of SigmaV = 26.2 mag/arcsec2. Here we present a\nnew homogeneous survey of 41 VLT/FLAMES multi-fibre spectroscopic pointings\nthat contain 2108 individual spectra, and combined with Gaia DR3 photometry and\nastrometry we present v-los measurements for 333 individual Red Giant Branch\nstars that are consistent with membership in the Sextans dwarf spheroidal\ngalaxy. In addition, we provide the metallicity, [Fe/H], determined from the\ntwo strongest CaII triplet lines, for 312 of these stars. We look again at the\nglobal characteristics of Sextans, deriving a mean line-of-sight velocity of\n<v-los> = +227.1km/s and a mean metallicity of <[Fe/H]> = -2.37. The\nmetallicity distribution is clearly double peaked, with the highest peak at\n[Fe/H]= -2.81 and another broader peak at [Fe/H]= -2.09. Thus it appears that\nSextans hosts two populations and the superposition leads to a radial variation\nin the mean metallicity, with the more metal rich population being centrally\nconcentrated. In addition there is an intriguing group of 9 probable members in\nthe outer region of Sextans at higher [Fe/H] than the mean in this region. If\nthis group could be confirmed as members they would eliminate the metallicity\ngradient. We also look again at the Colour-Magnitude Diagram of the resolved\nstellar population in Sextans. We also look again at the relation between\nSextans and the intriguingly nearby globular cluster, Pal3. The global\nproperties of Sextans have not changed significantly compared to previous\nstudies, but they are now more precise, and the sample of known members in the\nouter regions is now more complete.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T17:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.02789v1","title":"A Framework for Robust Cognitive Evaluation of LLMs","summary":"Emergent cognitive abilities in large language models (LLMs) have been widely\nobserved, but their nature and underlying mechanisms remain poorly understood.\nA growing body of research draws on cognitive science to investigate LLM\ncognition, but standard methodologies and experimen-tal pipelines have not yet\nbeen established. To address this gap we develop CognitivEval, a framework for\nsystematically evaluating the artificial cognitive capabilities of LLMs, with a\nparticular emphasis on robustness in response collection. The key features of\nCognitivEval include: (i) automatic prompt permutations, and (ii) testing that\ngathers both generations and model probability estimates. Our experiments\ndemonstrate that these features lead to more robust experimental outcomes.\nUsing CognitivEval, we replicate five classic experiments in cognitive science,\nillustrating the framework's generalizability across various experimental tasks\nand obtaining a cognitive profile of several state of the art LLMs.\nCognitivEval will be released publicly to foster broader collaboration within\nthe cognitive science community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T17:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.02797v1","title":"Spline-based Transformers","summary":"We introduce Spline-based Transformers, a novel class of Transformer models\nthat eliminate the need for positional encoding. Inspired by workflows using\nsplines in computer animation, our Spline-based Transformers embed an input\nsequence of elements as a smooth trajectory in latent space. Overcoming\ndrawbacks of positional encoding such as sequence length extrapolation,\nSpline-based Transformers also provide a novel way for users to interact with\ntransformer latent spaces by directly manipulating the latent control points to\ncreate new latent trajectories and sequences. We demonstrate the superior\nperformance of our approach in comparison to conventional positional encoding\non a variety of datasets, ranging from synthetic 2D to large-scale real-world\ndatasets of images, 3D shapes, and animations.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T17:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.02806v1","title":"Vertex-Based Localization of Turn's Theorem","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. Tur\\'{a}n's theorem states that in a simple\n$K_{r+1}$ free graph, $m \\leq \\frac{n^2(r-1)}{2r}$. In this paper, we\ngeneralize this result as follows: For each $v \\in V(G)$, let $c(v)$ be the\norder of the largest clique that contains $v$. We show that \\[ m \\leq\n\\frac{n}{2}\\sum_{v\\in V(G)}\\frac{c(v)-1}{c(v)}\\] Furthermore, we characterize\nthe class of extremal graphs that attain equality in this bound.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T17:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.02807v1","title":"MegaMath: Pushing the Limits of Open Math Corpora","summary":"Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T17:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.02822v1","title":"Do Two AI Scientists Agree?","summary":"When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T17:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.04721v1","title":"Bridging the Gap between Continuous and Informative Discrete\n  Representations by Random Product Quantization","summary":"Self-supervised learning has become a core technique in speech processing,\nbut the high dimensionality of its representations makes discretization\nessential for improving efficiency. However, existing discretization methods\nstill suffer from significant information loss, resulting in a notable\nperformance gap compared to continuous representations. To overcome these\nlimitations, we propose two quantization-based discretization methods: Product\nQuantization (PQ) and Random Product Quantization (RPQ). PQ partitions the\noriginal feature space into multiple subspaces and independently quantizes each\nsub-vector, producing a fused set of discrete units that retain diverse\ninformation from different subspaces, thus mitigating the loss associated with\nsingle-cluster quantization. RPQ further enhances representation diversity by\nrandomly sampling a fixed proportion of feature dimensions multiple times to\nconstruct sub-vectors, thereby better capturing the variability in the data\ndistribution. Theoretical analysis shows that RPQ reduces the correlation\ncoefficient rho (where 0 <= rho <= 1) between sub-quantizers. Its quantization\nerror is lower-bounded by the product of rho and epsilon-kms, where epsilon-kms\ndenotes the quantization error of a single K-means quantizer. Experimental\nresults on a combined dataset built from LibriSpeech and ML-SUPERB show that PQ\nand RPQ outperform standard K-means discretization, achieving relative\nimprovements of 21.8 percent and 20.0 percent in WER on LibriSpeech, and 24.1\npercent and 19.6 percent in CER on ML-SUPERB, respectively. Moreover, their\nperformance is competitive with, and in some cases even surpasses, that of\ncontinuous SSL representations.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-07T04:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.04724v1","title":"Three-dimensional abruptly autofocusing by counter-propagating Airy\n  pulses with radial Airy beam profile","summary":"We report the experimental observation of a three-dimensional abruptly\nautofocusing effect by synthesizing a radially distributed Airy beam with two\ncounter-propagating Airy pulses in time. As the wave packet propagates in a\ndispersive medium, the radially distributed Airy beam converges inward to the\ncenter point. Two Airy pulses counter-propagate toward each other to merge to\nform a high peak power pulse. As the result, the high intensity emerges\nabruptly as the wave packet achieves three-dimensional focusing. This\nautofocusing effect is believed to have potential applications such as material\nmodification, plasma physics, nanoparticle manipulations, etc.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T04:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.04745v1","title":"Can LLMs Interpret and Leverage Structured Linguistic Representations? A\n  Case Study with AMRs","summary":"This paper evaluates the ability of Large Language Models (LLMs) to leverage\ncontextual information in the form of structured linguistic representations.\nSpecifically, we examine the impact of encoding both short and long contexts\nusing Abstract Meaning Representation (AMR) structures across a diverse set of\nlanguage tasks. We perform our analysis using 8-bit quantized and\ninstruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our\nresults indicate that, for tasks involving short contexts, augmenting the\nprompt with the AMR of the original language context often degrades the\nperformance of the underlying LLM. However, for tasks that involve long\ncontexts, such as dialogue summarization in the SAMSum dataset, this\nenhancement improves LLM performance, for example, by increasing the zero-shot\ncosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is\nmore evident in the newer and larger LLMs, but does not extend to the older or\nsmaller ones. In addition, we observe that LLMs can effectively reconstruct the\noriginal text from a linearized AMR, achieving a cosine similarity of 81.3% in\nthe best-case scenario.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T05:38:40Z"}
{"aid":"http://arxiv.org/abs/2504.04752v1","title":"Investigating Popularity Bias Amplification in Recommender Systems\n  Employed in the Entertainment Domain","summary":"Recommender systems have become an integral part of our daily online\nexperience by analyzing past user behavior to suggest relevant content in\nentertainment domains such as music, movies, and books. Today, they are among\nthe most widely used applications of AI and machine learning. Consequently,\nregulations and guidelines for trustworthy AI, such as the European AI Act,\nwhich addresses issues like bias and fairness, are highly relevant to the\ndesign, development, and evaluation of recommender systems. One particularly\nimportant type of bias in this context is popularity bias, which results in the\nunfair underrepresentation of less popular content in recommendation lists.\nThis work summarizes our research on investigating the amplification of\npopularity bias in recommender systems within the entertainment sector.\nAnalyzing datasets from three entertainment domains, music, movies, and anime,\nwe demonstrate that an item's recommendation frequency is positively correlated\nwith its popularity. As a result, user groups with little interest in popular\ncontent receive less accurate recommendations compared to those who prefer\nwidely popular items. Furthermore, we aim to better understand the connection\nbetween recommendation accuracy, calibration quality of algorithms, and\npopularity bias amplification.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T05:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.04763v1","title":"Broad-band noises in GX 339-4 during the 2021 outburst observed with\n  Insight-HXMT and NICER","summary":"Rapid X-ray variability of GX 339$-$4 including the low-frequency\nquasi-periodic oscillations (LFQPOs) and broad-band noises have been observed\nwith the Hard X-ray Modulation Telescope (\\textit{Insight}-HXMT) and Neutron\nstar Interior Composition Explorer (\\textit {NICER}) during the 2021 outburst.\nHere we present a systematic study of the evolution and energy dependence\nproperties of such broad-band noises (BBN). The outburst from February to March\nof 2021 can be divided into three stages: the low hard state (LHS), the hard\nintermediate state (HIMS) and soft intermediate state (SIMS). In the PDSs of\nthe LHS and HIMS, the broad-band noises are well fitted with three Lorentzian\ncomponents: a low-frequency component $L_1$, a middle-frequency component $L_2$\nand a high-frequency component $L_3$. The increasing trend of the\ncharacteristic frequencies for $L_1$ and $L_2$ and the relation between the QPO\nfrequency and characteristic BBN frequency are reported. We found that the\nenergies corresponding to the peaks and shapes of the rms spectra for three BBN\ncomponents are different. The comparison among three BBN components indicates\nthat energy-dominant bands of these BBN components are distinct. Our results\ncan be explained with the truncated disc/hot flow model with a large variable\ndisc and a small hot inner flow. A possible description of the accretion\nstructure and its evolution from the LHS to the SIMS is proposed. Further\nresearch is still required to probe such accretion structure in GX 339--4.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.04777v1","title":"Dispersion in Rotating Electron-Positron-Ion Quantum Plasma","summary":"Quantum plasmas in astrophysical environments are abundant due to extreme\nelectric, magnetic, and gravitational fields. These plasmas can be most clearly\nobserved in neutron stars, white dwarfs, brown dwarfs, red dwarfs, accretion\ndisks of black holes, pulsars, quasars, and more. This paper examines the\npropagation of electromagnetic waves in a three-component e-p-i quantum plasma\nwithin a rotating frame, considering the particles' spin, Fermi pressure, and\nquantum Bohm potential. Additionally, effects unique to this specific\nenvironment, such as rotation and gravity, are included. The dispersion of\nelectrons, ions, and positrons has been obtained separately, and their coupling\nhas been analyzed to understand the collective behavior. It has been noted that\nthe quantum effects of Fermi pressure and Bohm potential significantly\ninfluence particle dynamics.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T07:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.04781v1","title":"OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on\n  Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance","summary":"Comprehending occluded objects are not well studied in existing large-scale\nvisual-language multi-modal models. Current state-of-the-art multi-modal large\nmodels struggles to provide satisfactory results in understanding occluded\nobjects through universal visual encoders and supervised learning strategies.\nTherefore, we propose OCC-MLLM-CoT-Alpha, a multi-modal large vision language\nframework that integrates 3D-aware supervision and Chain-of-Thoughts guidance.\nParticularly, (1) we build a multi-modal large vision-language model framework\nwhich is consisted of a large multi-modal vision-language model and a 3D\nreconstruction expert model. (2) the corresponding multi-modal\nChain-of-Thoughts is learned through a combination of supervised and\nreinforcement training strategies, allowing the multi-modal vision-language\nmodel to enhance the recognition ability with learned multi-modal\nchain-of-thoughts guidance. (3) A large-scale multi-modal chain-of-thoughts\nreasoning dataset, consisting of $110k$ samples of occluded objects held in\nhand, is built. In the evaluation, the proposed methods demonstrate decision\nscore improvement of 15.75%,15.30%,16.98%,14.62%, and 4.42%,3.63%,6.94%,10.70%\nfor two settings of a variety of state-of-the-art models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:15:26Z"}
{"aid":"http://arxiv.org/abs/2504.04782v1","title":"I only read it for the plot! Maturity Ratings Affect Fanfiction Style\n  and Community Engagement","summary":"We consider the textual profiles of different fanfiction maturity ratings,\nhow they vary across fan groups, and how this relates to reader engagement\nmetrics. Previous studies have shown that fanfiction writing is motivated by a\ncombination of admiration for and frustration with the fan object. These\nfindings emerge when looking at fanfiction as a whole, as well as when it is\ndivided into subgroups, also called fandoms. However, maturity ratings are used\nto indicate the intended audience of the fanfiction, as well as whether the\nstory includes mature themes and explicit scenes. Since these ratings can be\nused to filter readers and writers, they can also be seen as a proxy for\ndifferent reader/writer motivations and desires. We find that explicit\nfanfiction in particular has a distinct textual profile when compared to other\nmaturity ratings. These findings thus nuance our understanding of reader/writer\nmotivations in fanfiction communities, and also highlights the influence of the\ncommunity norms and fan behavior more generally on these cultural products.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T07:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.04785v1","title":"Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors","summary":"Efficiently leveraging of the capabilities of contemporary large language\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\nis expensive and often impractical. Existing training-free methods, including\nmanually or automated designed workflows, typically demand substantial human\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\nlanguage models to design and optimize workflows for harnessing stronger\nmodels. W4S formulates workflow design as a multi-turn markov decision process\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\nto train a weak meta-agent. Through iterative interaction with the environment,\nthe meta-agent learns to design increasingly effective workflows without manual\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\nNotably, W4S exhibits strong generalization capabilities across both seen and\nunseen tasks, offering an efficient, high-performing alternative to directly\nfine-tuning strong models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T07:27:31Z"}
{"aid":"http://arxiv.org/abs/2504.04844v1","title":"Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM","summary":"Simultaneous localization and mapping (SLAM) technology now has\nphotorealistic mapping capabilities thanks to the real-time high-fidelity\nrendering capability of 3D Gaussian splatting (3DGS). However, due to the\nstatic representation of scenes, current 3DGS-based SLAM encounters issues with\npose drift and failure to reconstruct accurate maps in dynamic environments. To\naddress this problem, we present D4DGS-SLAM, the first SLAM method based on\n4DGS map representation for dynamic environments. By incorporating the temporal\ndimension into scene representation, D4DGS-SLAM enables high-quality\nreconstruction of dynamic scenes. Utilizing the dynamics-aware InfoModule, we\ncan obtain the dynamics, visibility, and reliability of scene points, and\nfilter stable static points for tracking accordingly. When optimizing Gaussian\npoints, we apply different isotropic regularization terms to Gaussians with\nvarying dynamic characteristics. Experimental results on real-world dynamic\nscene datasets demonstrate that our method outperforms state-of-the-art\napproaches in both camera pose tracking and map quality.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T08:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.04859v1","title":"Block BDDC/FETI-DP Preconditioners for Three-Field mixed finite element\n  Discretizations of Biot's consolidation model","summary":"In this paper, we construct and analyze a block dual-primal preconditioner\nfor Biot's consolidation model approximated by three-field mixed finite\nelements based on a displacement, pressure, and total pressure formulation. The\ndomain is decomposed into nonoverlapping subdomains, and the continuity of the\ndisplacement component across the subdomain interface is enforced by\nintroducing a Lagrange multiplier. After eliminating all displacement variables\nand the independent subdomain interior components of pressure and total\npressure, the problem is reduced to a symmetric positive definite linear system\nfor the subdomain interface pressure, total pressure, and the Lagrange\nmultiplier. This reduced system is solved by a preconditioned conjugate\ngradient method, with a block dual-primal preconditioner using a Balancing\nDomain Decomposition by Constraints (BDDC) preconditioner for both the\ninterface total pressure block and the interface pressure blocks, as well as a\nFinite Element Tearing and Interconnecting-Dual Primal (FETI-DP) preconditioner\nfor the Lagrange multiplier block. By analyzing the conditioning of the\npreconditioned subsystem associated with the interface pressure and total\npressure components, we obtain a condition number bound of the preconditioned\nsystem, which is scalable in the number of subdomains, poly-logarithmic in the\nratio of subdomain and mesh sizes, and robust with respect to the parameters of\nthe model. Extensive numerical experiments confirm the theoretical result of\nthe proposed algorithm.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T09:17:37Z"}
{"aid":"http://arxiv.org/abs/2504.04864v1","title":"Statistical parametric simulation studies based on real data","summary":"Simulation studies are indispensable for evaluating and comparing statistical\nmethods. The most common simulation approach is parametric simulation, where\nthe data-generating mechanism (DGM) corresponds to a predefined parametric\nmodel from which observations are drawn. Many statistical simulation studies\naim to provide practical recommendations on a method's suitability for a given\napplication; however, parametric simulations in particular are frequently\ncriticized for being too simplistic and not reflecting reality. To overcome\nthis drawback, it is generally considered a sensible approach to employ real\ndata for constructing the parametric DGMs. However, while the concept of\nreal-data-based parametric DGMs is widely recognized, the specific ways in\nwhich DGM components are inferred from real data vary, and their implications\nmay not always be well understood. Additionally, researchers often rely on a\nlimited selection of real datasets, with the rationale for their selection\noften unclear. This paper addresses these issues by formally discussing how\ncomponents of parametric DGMs can be inferred from real data and how dataset\nselection can be performed more systematically. By doing so, we aim to support\nresearchers in conducting simulation studies with a lower risk of\novergeneralization and misinterpretation. We illustrate the construction of\nparametric DGMs based on a systematically selected set of real datasets using\ntwo examples: one on ordinal outcomes in randomized controlled trials and one\non differential gene expression analysis.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:19:28Z"}
{"aid":"http://arxiv.org/abs/2504.04868v1","title":"On Scenario Formalisms for Automated Driving","summary":"The concept of scenario and its many qualifications -- specifically logical\nand abstract scenarios -- have emerged as a foundational element in\nsafeguarding automated driving systems. However, the original linguistic\ndefinitions of the different scenario qualifications were often applied\nambiguously, leading to a divergence between scenario description languages\nproposed or standardized in practice and their terminological foundation. This\nresulted in confusion about the unique features as well as strengths and\nweaknesses of logical and abstract scenarios. To alleviate this, we give clear\nlinguistic definitions for the scenario qualifications concrete, logical, and\nabstract scenario and propose generic, unifying formalisms using curves,\nmappings to sets of curves, and temporal logics, respectively. We demonstrate\nthat these formalisms allow pinpointing strengths and weaknesses precisely by\ncomparing expressiveness, specification complexity, sampling, and monitoring of\nlogical and abstract scenarios. Our work hence enables the practitioner to\ncomprehend the different scenario qualifications and identify a suitable\nformalism.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T09:23:46Z"}
{"aid":"http://arxiv.org/abs/2504.04869v1","title":"Content-Aware Transformer for All-in-one Image Restoration","summary":"Image restoration has witnessed significant advancements with the development\nof deep learning models. Although Transformer architectures have progressed\nconsiderably in recent years, challenges remain, particularly the limited\nreceptive field in window-based self-attention. In this work, we propose\nDSwinIR, a Deformable Sliding window Transformer for Image Restoration. DSwinIR\nintroduces a novel deformable sliding window self-attention that adaptively\nadjusts receptive fields based on image content, enabling the attention\nmechanism to focus on important regions and enhance feature extraction aligned\nwith salient features. Additionally, we introduce a central ensemble pattern to\nreduce the inclusion of irrelevant content within attention windows. In this\nway, the proposed DSwinIR model integrates the deformable sliding window\nTransformer and central ensemble pattern to amplify the strengths of both CNNs\nand Transformers while mitigating their limitations. Extensive experiments on\nvarious image restoration tasks demonstrate that DSwinIR achieves\nstate-of-the-art performance. For example, in image deraining, compared to\nDRSformer on the SPA dataset, DSwinIR achieves a 0.66 dB PSNR improvement. In\nall-in-one image restoration, compared to PromptIR, DSwinIR achieves over a\n0.66 dB and 1.04 dB improvement on three-task and five-task settings,\nrespectively. Pretrained models and code are available at our project\nhttps://github.com/Aitical/DSwinIR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T09:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.04895v1","title":"Asymmetric 4.77 Three-Way Unequal Filtering Power Divider/Combiner for\n  Communication Systems Application","summary":"This study presents a novel three-way unequal filtering power\ndivider/combiner, addressing challenges in unequal power distribution while\nincorporating filtering functions in communication systems. Wilkinson power\ndivider (WPD) is the traditional power division approach using\nquarter-wavelength transmission lines [1]. This type of power divider is\npopularly used in communication systems due to its good electrical isolation\nand simple structure. The problem with WPD is that its operation requires the\nuse of an externally connected bandpass filter (BPF) to achieve filtering\nfunctionality. This leads to increased footprint and increased loss\ncoefficients in a system. In contrast to the traditional design approach\ninvolving a BPF, a matching transmission line, and a Wilkinson power divider as\nseparate components, the proposed integrated filtering power divider (FPD)\nconsolidates all three components into a single device, leading to lower\nfootprint and lower loss coefficient in a system. Circuit modelling and\nelectromagnetic (EM) simulations were conducted to ensure alignment between\ntheoretical and practical results. The design demonstrates effective unequal\npower division at the three output ports while maintaining very good filtering\nperformance. Results show a return loss better than 15 dB and a minimum\ninsertion loss of 1.2 dB. The overall size of the device is 32.2 x 50.0 mm.\nThis paper contributes to advancements in power divider design by addressing\nunequal power division challenges and integrating filtering functions. The\nfindings offer a foundation for future developments in advanced power\ndivider/combiner systems, with insights into potential challenges and areas for\nfurther improvements.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-04-07T10:06:59Z"}
{"aid":"http://arxiv.org/abs/2504.04901v1","title":"Design of a compact low loss 2-way millimetre wave power divider for\n  future communication","summary":"In this paper, a rectangular-shaped power divider has been presented\noperating at 27.9 GHz. The power divider has achieved acceptable results for\nimportant parameters such as S11, S12, S21, and S22. The substrate employed for\nthe power divider is Roger 3003 which has a thickness of 1.6 mm. This power\ndivider provides a reflection coefficient of -12.2 dB and an insertion loss of\n3.1 dB at 28 GHz. This ka-band T-junction power divider covers 68% of the\nbandwidth. Dimensions of the ka-band T-junction power divider are 50x80 mm. Due\nto its dimensions and bandwidth this power divider is more suitable for\nmillimetre wave applications like RADAR, beamforming, and 5G applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-04-07T10:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.04905v1","title":"Null geodesics around a magnetized Kiselev black hole","summary":"A new magnetically charged Kiselev black hole solution is used to study the\nnull geodesics in this spacetime. We derive the equations of motion for the\nnull geodesics and analyze their properties, including the gravitational\nlensing effect. The 3D and equatorial plane orbits are discussed, with\nparticular attention given to the effect of quintessence. The deviations from\nthe Ernst black hole provide insights into the potential observational\nconsequences of dark energy in strong gravitational fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T10:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.04924v1","title":"Inter-event Interval Microscopy for Event Cameras","summary":"Event cameras, an innovative bio-inspired sensor, differ from traditional\ncameras by sensing changes in intensity rather than directly perceiving\nintensity and recording these variations as a continuous stream of \"events\".\nThe intensity reconstruction from these sparse events has long been a\nchallenging problem. Previous approaches mainly focused on transforming\nmotion-induced events into videos or achieving intensity imaging for static\nscenes by integrating modulation devices at the event camera acquisition end.\nIn this paper, for the first time, we achieve event-to-intensity conversion\nusing a static event camera for both static and dynamic scenes in fluorescence\nmicroscopy. Unlike conventional methods that primarily rely on event\nintegration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the\ntime interval between consecutive events at each pixel. With a fixed threshold\nin the event camera, the time interval can precisely represent the intensity.\nAt the hardware level, the proposed IEIM integrates a pulse light modulation\ndevice within a microscope equipped with an event camera, termed Pulse\nModulation-based Event-driven Fluorescence Microscopy.mAdditionally, we have\ncollected IEIMat dataset under various scenes including high dynamic range and\nhigh-speed scenarios. Experimental results on the IEIMat dataset demonstrate\nthat the proposed IEIM achieves superior spatial and temporal resolution, as\nwell as a higher dynamic range, with lower bandwidth compared to other methods.\nThe code and the IEIMat dataset will be made publicly available.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T11:05:13Z"}
{"aid":"http://arxiv.org/abs/2504.04960v1","title":"Sign-changing multi-peak standing waves of the NLSE with a point\n  interaction","summary":"Consider the following semilinear problem with a point interaction in\n$\\mathbb{R}^N$: \\[- \\Delta_\\alpha u + \\omega u = u |u|^{p - 2},\\] where $N \\in\n\\{2, 3\\}$; $\\omega > 0$; $- \\Delta_\\alpha$ denotes the Hamiltonian of point\ninteraction with inverse $s$-wave scattering length $- (4 \\pi \\alpha)^{- 1}$\nand we want to solve for $u \\colon \\mathbb{R}^N \\to \\mathbb{R}$. By means of\nLyapunov--Schmidt reduction, we prove that this problem has sign-changing\nmulti-peak solutions when either (1) $N = 2$, $\\alpha \\in \\mathbb{R}$, $p_* < p\n\\leq 3$ and $\\omega$ is sufficiently large or (2) $N = 3$, $0 < \\alpha <\n\\infty$, $p_* < p < 3$ and $\\omega$ is sufficiently small, where $2.45 < p_* :=\n\\frac{9 + \\sqrt{113}}{8} < 2.46$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T11:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.04963v1","title":"Constraint Multi-class Positive and Unlabeled Learning for Distantly\n  Supervised Named Entity Recognition","summary":"Distantly supervised named entity recognition (DS-NER) has been proposed to\nexploit the automatically labeled training data by external knowledge bases\ninstead of human annotations. However, it tends to suffer from a high false\nnegative rate due to the inherent incompleteness. To address this issue, we\npresent a novel approach called \\textbf{C}onstraint \\textbf{M}ulti-class\n\\textbf{P}ositive and \\textbf{U}nlabeled Learning (CMPU), which introduces a\nconstraint factor on the risk estimator of multiple positive classes. It\nsuggests that the constraint non-negative risk estimator is more robust against\noverfitting than previous PU learning methods with limited positive data. Solid\ntheoretical analysis on CMPU is provided to prove the validity of our approach.\nExtensive experiments on two benchmark datasets that were labeled using diverse\nexternal knowledge sources serve to demonstrate the superior performance of\nCMPU in comparison to existing DS-NER methods.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T11:51:41Z"}
{"aid":"http://arxiv.org/abs/2504.04993v1","title":"Duality invariance of Faltings heights, Hodge line bundles and global\n  periods","summary":"We prove that an abelian variety and its dual over a global field have the\nsame Faltings height and, more precisely, have isomorphic Hodge line bundles,\nincluding their natural metrized bundle structures. More carefully treating\nreal places, we also show that these abelian varieties have the same real and\nglobal periods that appear in the Birch-Swinnerton-Dyer conjecture.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-07T12:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.05006v1","title":"Enhancing Smart Contract Vulnerability Detection in DApps Leveraging\n  Fine-Tuned LLM","summary":"Decentralized applications (DApps) face significant security risks due to\nvulnerabilities in smart contracts, with traditional detection methods\nstruggling to address emerging and machine-unauditable flaws. This paper\nproposes a novel approach leveraging fine-tuned Large Language Models (LLMs) to\nenhance smart contract vulnerability detection. We introduce a comprehensive\ndataset of 215 real-world DApp projects (4,998 contracts), including\nhard-to-detect logical errors like token price manipulation, addressing the\nlimitations of existing simplified benchmarks. By fine-tuning LLMs (Llama3-8B\nand Qwen2-7B) with Full-Parameter Fine-Tuning (FFT) and Low-Rank Adaptation\n(LoRA), our method achieves superior performance, attaining an F1-score of 0.83\nwith FFT and data augmentation via Random Over Sampling (ROS). Comparative\nexperiments demonstrate significant improvements over prompt-based LLMs and\nstate-of-the-art tools. Notably, the approach excels in detecting\nnon-machine-auditable vulnerabilities, achieving 0.97 precision and 0.68 recall\nfor price manipulation flaws. The results underscore the effectiveness of\ndomain-specific LLM fine-tuning and data augmentation in addressing real-world\nDApp security challenges, offering a robust solution for blockchain ecosystem\nprotection.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T12:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.05016v1","title":"Radio frequency single electron transmission spectroscopy of a\n  semiconductor Si/SiGe quantum dot","summary":"Rapid single shot spin readout is a key ingredient for fault tolerant quantum\ncomputing with spin qubits. An RF-SET (radio-frequency single electron\ntransistor) is predominantly used as its the readout timescale is far shorter\nthan the spin decoherence time. In this work, we experimentally demonstrate a\ntransmission-based RF-SET using a multi-module semiconductor-superconductor\nassembly. A monolithically integrated SET placed next to a double quantum dot\nin a Si/SiGe heterostructure is wire-bonded to a superconducting niobium\ninductor forming the impedance-transforming network. Compared to RF\nreflectometry, the proposed set-up is experimentally simpler without the need\nfor directional couplers. Read-out performance is benchmarked by the\nsignal-to-noise (SNR) of a dot-reservoir transition (DRT) and an interdot\ncharge transition (ICT) in the double quantum dot near the SET as a function of\nRF power and integration time. The minimum integration time for unitary SNR is\nfound to be 100 ns for ICT and 300 ns for DRT. The obtained minimum integration\ntimes are comparable to the state of the art in conventional RF reflectometry\nset-ups. Furthermore, we study the turn-on properties of the RF-SET to\ninvestigate capacitive shifts and RF losses. Understanding these effects are\ncrucial for further optimisations of the impedance transforming network as well\nas the device design to assist RF read-out. This new RF read-out scheme also\nshows promise for multiplexing spin-qubit readout and further studies on rapid\ncharge dynamics in quantum dots.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.app-ph","published":"2025-04-07T12:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.05027v1","title":"Indistinguishability of unbounded components in the occupied and vacant\n  sets of Boolean models on symmetric spaces","summary":"We study Boolean models on Riemannian symmetric spaces driven by homogeneous\ninsertion- or deletion-tolerant point processes. We prove that in both the set\ncovered by the balls (the occupied set) and its complement (the vacant set),\none cannot distinguish unbounded components from each other by any isometry\ninvariant component property. This implies the uniqueness monotonicity for the\noccupied and vacant sets of Poisson-Boolean models and an equivalence of\nnon-uniqueness to the decay of connectivity for both sets. These results are\ncontinuum analogues of those by Lyons and Schramm arXiv:math/9811170. However,\nunlike the proof of the indistinguishability in arXiv:math/9811170, our proof\ndoes not rely on transience of unbounded components. We also prove the\nexistence of a percolation phase transition for independent Poisson-Boolean\nmodel on unbounded connected components of both occupied and vacant sets and\nshow transience of a random walk on the occupied set. Apart from some technical\ndifferences, we treat the occupied and the vacant sets of Boolean models within\na single framework.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T12:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.05031v1","title":"Analog phase-sensitive time-reversal of optically-carried radiofrequency\n  signals","summary":"Achieving low-latency time-reversal of broadband radiofrequency signals is\ncrucial for reliable communications in dynamic, uncontrolled environments.\nHowever, existing approaches are either digitally assisted -- making broadband\nextension challenging -- or limited to amplitude modulation. In this work, we\nreport the very first experimental realization of a fully analog,\nphase-preserving time-reversal architecture for optically-carried\nradiofrequency signals. The method exploits the exceptional coherence\nproperties of rare-earth ion-doped materials, and leverages the\nwell-established photon echo mechanism, widely used in quantum technologies.\nWhile our demonstration is conducted with a modest bandwidth, we identify the\nfundamental cause of this limitation and propose solutions for future\nscalability.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph,quant-ph","published":"2025-04-07T12:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.05034v1","title":"Dominating Hyperplane Regularization for Variable Selection in\n  Multivariate Count Regression","summary":"Identifying relevant factors that influence the multinomial counts in\ncompositional data is difficult in high dimensional settings due to the complex\nassociations and overdispersion. Multivariate count models such as the\nDirichlet-multinomial (DM), negative multinomial, and generalized DM\naccommodate overdispersion but are difficult to optimize due to their\nnon-concave likelihood functions. Further, for the class of regression models\nthat associate covariates to the multivariate count outcomes, variable\nselection becomes necessary as the number of potentially relevant factors\nbecomes large. The sparse group lasso (SGL) is a natural choice for\nregularizing these models. Motivated by understanding the associations between\nwater quality and benthic macroinvertebrate compositions in Canada's Athabasca\noil sands region, we develop dominating hyperplane regularization (DHR), a\nnovel method for optimizing regularized regression models with the SGL penalty.\nUnder the majorization-minimization framework, we show that applying DHR to a\nSGL penalty gives rise to a surrogate function that can be expressed as a\nweighted ridge penalty. Consequently, we prove that for multivariate count\nregression models with the SGL penalty, the optimization leads to an\niteratively reweighted Poisson ridge regression. We demonstrate stable\noptimization and high performance of our algorithm through simulation and real\nworld application to benthic macroinvertebrate compositions.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-07T12:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05036v1","title":"Hybrid Nitsche for distributed computing","summary":"We extend the distributed finite element method of [1], built upon model\norder reduction, to arbitrary polynomial degree using a hybrid Nitsche scheme.\nThis new method considerably simplifies the transformation of the finite\nelement system to the reduced basis for large problems. We prove that the error\nof the reduced Nitsche solution converges optimally with respect to the\napproximation order of the finite element spaces and linearly with respect to\nthe dimension reduction parameter $\\epsilon$. Numerical tests with nontrivial\ntetrahedral meshes using second-degree polynomial bases support the theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05054v1","title":"Small-mass solutions in a two-dimensional logarithmic\n  chemotaxis-Navier-Stokes system with indirect nutrient consumption","summary":"This paper is concerned with the singular chemotaxis-fluid system with\nindirect nutrient consumption: $\n  n_{t}+u\\cdot\\nabla n=\\Delta n-\\nabla\\cdot(n S(x,n,v)\\cdot \\nabla v);\\\n  v_{t}+u\\cdot\\nabla v=\\Delta v-vw;\\\n  w_{t}+u\\cdot\\nabla w=\\Delta w-w+n;\\\n  u_t+(u\\cdot\\nabla) u=\\Delta u-\\nabla P+n\\nabla\\Phi;\\ \\nabla\\cdot u=0\\ $\n  in a smooth bounded domain $\\Omega\\subset\\mathbb{R}^2$\n  under no-flux/Neumann/Neumann/Dirichlet boundary conditions, where $\\Phi\\in\nW^{2,\\infty}(\\Omega)$, and $S: \\overline{\\Omega}\\times [0,\\infty) \\times\n(0,\\infty)\\rightarrow\\mathbb{R}^{2\\times 2}$ is a suitably smooth function that\nsatisfies $|S(x,n,v)|\\leq S_0(v) /v $ for all $(x,n,v) \\in \\Omega\\times\n(0,\\infty)^2$ with some nondecreasing $S_0: (0,\\infty)\\rightarrow(0,\\infty)$.\n  For all reasonably regular initial data with a smallness assumption merely\ninvolving the quantity $\\int_\\Omega n_0$,\n  it is shown that the problem possesses a globally bounded classical solution,\nwhich, inter alia, exponentially stabilizes\n  toward the spatially homogeneous state $(\n\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0,\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0)$\nwith respect to the norm in $L^\\infty(\\Omega)$.\n  This rigorously confirms that, at least in the two-dimensional setting, in\ncomparison to the direct mechanism of nutrient consumption, an indirect\nmechanism can induce much more regularity of solutions to the chemotaxis--fluid\nsystem even with a singular tensor-valued sensitivity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.05061v1","title":"Topology of circular orbits of charged particles in black holes with\n  multiple horizons","summary":"The study of the topological properties of circular orbits is opening up new\nperspectives for exploring the spacetime structure around black holes. In this\nwork, we investigate how the charged properties of particles affect the\ntopological characteristics of circular orbits for charged test particles in\nasymptotically flat, AdS, and dS black holes. Our findings demonstrate that the\ncharged properties not only influence the topological properties of timelike\ncircular orbits but also impact those of null circular orbits. Additionally, we\nexplore scenarios involving multiple horizons and find that for a multi-horizon\nblack hole, if a circular orbit can exist between two neighboring horizons,\nthere will always be both a null circular orbit and a timelike circular orbit.\nWhether these orbits are stable or unstable depends on the potential function.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T13:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.05064v1","title":"Wild generalised truncation of infinite matroids","summary":"For ${n \\in \\mathbb{N}}$, the $n$-truncation of a matroid $M$ of rank at\nleast $n$ is the matroid whose bases are the $n$-element independent sets of\n$M$. One can extend this definition to negative integers by letting the\n$(-n)$-truncation be the matroid whose bases are all the sets that can be\nobtained by deleting $n$ elements of a base of $M$. If $M$ has infinite rank,\nthen for distinct ${m,n \\in \\mathbb{Z}}$ the $m$-truncation and the\n$n$-truncation are distinct matroids.\n  Inspired by the work of Bowler and Geschke on infinite uniform matroids, we\nprovide a natural definition of generalised truncations that encompasses the\nnotions mentioned above. We call a generalised truncation wild if it is not an\n$n$-truncation for any ${n \\in \\mathbb{Z}}$ and we prove that, under Martin's\nAxiom, any finitary matroid of infinite rank and size of less than continuum\nadmits ${2^{2^{\\aleph_0}}}$ wild generalised truncations.","main_category":"math.CO","categories":"math.CO,math.LO","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05083v1","title":"X-ray variability of VHE detected FSRQs: A comparative study","summary":"Flat Spectrum Radio Quasars (FSRQs) are weak sources of very high energy\n(VHE; E>100 GeV) emission, despite exhibiting strong MeV-GeV emissions that\ndominate their radiative output. To date, only ten FSRQs have been detected at\nVHEs, primarily during bright optical phases. In this study, we perform a\ndetailed and systematic, temporal, and spectral analysis of the nine\nVHE-detected FSRQs, using the Swift X-ray Telescope (XRT) data. Our findings\nshow no correlation between VHE activity and the X-ray flux or spectral state\nof the sources. However, investigation of spectral properties with X-ray\nbrightness shows anti-correlation between flux and spectral index. The X-ray,\ngenerally with a different spectral shape lies at the farther end of the\noptical-UV synchrotron spectrum which typically shows a declining power-law\nspectrum, and thus, the X-ray spectrum is generally explained by Synchrotron\nSelf-Compton (SSC) process. However, if optical-UV synchrotron emission extends\ninto the X-ray band, it can soften the X-ray spectrum. While most sources in\nour sample exhibit rising X-ray SEDs, indicative of non-synchrotron origins or\nminimal synchrotron contributions, many display softer or flat X-ray spectra,\nmainly during low X-ray flux states (e.g., 4C +21.35, 3C 279, TON 0599, PKS\n1441+25, and PKS 0346-27) suggesting potential synchrotron contributions. These\nsynchrotron continuations influence the gamma-ray spectrum, implying extension\ninto the VHE range for inverse Compton (IC) scattering in the Thomson\nscattering limit. If the extended component corresponds to an underlying\nlow-level emission, these FSRQs could represent potential candidates for\npersistent VHE activity.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T13:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.05091v1","title":"Morse Index Theorem for Sturm-Liouville Operators on the Real Line","summary":"The classical Morse index theorem establishes a fundamental connection\nbetween the Morse index-the number of negative eigenvalues that characterize\nkey spectral properties of linear self-adjoint differential operators-and the\ncount of corresponding conjugate points. In this paper, we extend these\nfoundational results to the Sturm-Liouville operator on $\\mathbb{R}$. In\nparticular, for autonomous Lagrangian systems, we employ a geometric argument\nto derive a lower bound for the Morse index. As concrete applications, we\nestablish a criterion for detecting instability in traveling waves within\ngradient reaction-diffusion systems.","main_category":"math.DS","categories":"math.DS","published":"2025-04-07T14:00:13Z"}
{"aid":"http://arxiv.org/abs/2504.05111v1","title":"Theory of quantum-enhanced interferometry with general Markovian light\n  sources","summary":"Quantum optical systems comprising quantum emitters interacting with\nengineered optical modes generate non-classical states of light that can be\nused as resource states for quantum-enhanced interferometry. However, outside\nof well-controlled systems producing either single-mode states (e.g. Fock\nstates or squeezed states) or highly symmetric multi-mode states (e.g.\nsuperradiant states), their potential for quantum advantage remains\nuncharacterized. In this work, we develop a framework to analyze quantum\nenhanced interferometry with general Markovian quantum light sources. First, we\nshow how to compute the quantum Fisher Information (QFI) of the photons emitted\nby a source efficiently by just tracking its internal dynamics and without\nexplicitly computing the state of the emitted photons. We then use this\nrelationship to elucidate the connection between the level structure and\nspectrum of the source to a potential quantum advantage in interferometry.\nFinally, we analyze optimal measurement protocols that can be used to achieve\nthis quantum advantage with experimentally available optical elements. In\nparticular, we show that tunable optical elements with Kerr non-linearity can\nalways be harnessed to implement the optimal measurement for any given source.\nSimultaneously, we also outline general conditions under which linear optics\nand photodetection is enough to implement the optimal measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T14:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.05143v1","title":"Taming Double-Spending in Offline Payments with Reputation-Weighted Loan\n  Networks","summary":"Blockchain solutions typically assume a synchronous network to ensure\nconsistency and achieve consensus. In contrast, offline transaction systems aim\nto enable users to agree on and execute transactions without assuming bounded\ncommunication delays when interacting with the blockchain. Most existing\noffline payment schemes depend on trusted hardware wallets that are assumed to\nbe secure and tamper-proof. While this work introduces Overdraft, a novel\noffline payment system that shifts the reliance from hardware to users\nthemselves. Overdraft allows potential payment receivers to assess the\nlikelihood of being paid, allowing them to accept transactions with confidence\nor deny them. Overdraft achieves this by maintaining a loan network that is\nweighted by online reputation. This loan network contains time-limited\nagreements where users pledge to cover another user's payment if necessary. For\nexample, when a payer lacks sufficient funds at the moment of commitment.\nOffline users rely on the last known view of the loan network -- which they had\naccess to when last online -- to determine whether to participate in an offline\ntransaction. This view is used to estimate the probability of eventual payment,\npossibly using multiple loans. Once online again, users commit their\ntransactions to the blockchain with any conflicts being resolved\ndeterministically. Overdraft incorporates incentives for users and is designed\nto be resilient against Sybil attacks. As a proof of concept, we implemented\nOverdraft as an Ethereum Solidity smart contract and deployed it on the Sepolia\ntestnet to evaluate its performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T14:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.05156v1","title":"Blending Queries and Conversations: Understanding Tactics, Trust,\n  Verification, and System Choice in Web Search and Chat Interactions","summary":"This paper presents a user study (N=22) where participants used an interface\ncombining Web Search and a Generative AI-Chat feature to solve health-related\ninformation tasks. We study how people behaved with the interface, why they\nbehaved in certain ways, and what the outcomes of these behaviours were. A\nthink-aloud protocol captured their thought processes during searches. Our\nfindings suggest that GenAI is neither a search panacea nor a major regression\ncompared to standard Web Search interfaces. Qualitative and quantitative\nanalyses identified 78 tactics across five categories and provided insight into\nhow and why different interface features were used. We find evidence that\npre-task confidence and trust both influenced which interface feature was used.\nIn both systems, but particularly when using the chat feature, trust was often\nmisplaced in favour of ease-of-use and seemingly perfect answers, leading to\nincreased confidence post-search despite having incorrect results. We discuss\nwhat our findings mean in the context of our defined research questions and\noutline several open questions for future research.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-07T14:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.05180v1","title":"BRIDGES: Bridging Graph Modality and Large Language Models within EDA\n  Tasks","summary":"While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05184v1","title":"MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised\n  Prototypical Contrastive Loss for Coronary DSA Image Segmentation","summary":"The accurate segmentation of coronary Digital Subtraction Angiography (DSA)\nimages is essential for diagnosing and treating coronary artery diseases.\nDespite advances in deep learning-based segmentation, challenges such as low\ncontrast, noise, overlapping structures, high intra-class variance, and class\nimbalance limit precise vessel delineation. To overcome these limitations, we\npropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecture\nfor coronary DSA image segmentation. The framework combined Multi-Scale Dilated\nBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),\nwhich not only enhances multi-scale feature extraction but also preserve\nfine-grained details, and improve contextual understanding. Furthermore, we\npropose a new Supervised Prototypical Contrastive Loss (SPCL), which combines\nsupervised and prototypical contrastive learning to minimize class imbalance\nand high intra-class variance by focusing on hard-to-classified background\nsamples. Experiments carried out on a private coronary DSA dataset demonstrate\nthat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dice\ncoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced Average\nSurface Distance (ASD) and Average Contour Distance (ACD). The developed\nframework provides clinicians with precise vessel segmentation, enabling\naccurate identification of coronary stenosis and supporting informed diagnostic\nand therapeutic decisions. The code will be released at the following GitHub\nprofile link https://github.com/rayanmerghani/MSA-UNet3plus.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:35:30Z"}
{"aid":"http://arxiv.org/abs/2504.05186v1","title":"Training state-of-the-art pathology foundation models with orders of\n  magnitude less data","summary":"The field of computational pathology has recently seen rapid advances driven\nby the development of modern vision foundation models (FMs), typically trained\non vast collections of pathology images. Recent studies demonstrate that\nincreasing the training data set and model size and integrating domain-specific\nimage processing techniques can significantly enhance the model's performance\non downstream tasks. Building on these insights, our work incorporates several\nrecent modifications to the standard DINOv2 framework from the literature to\noptimize the training of pathology FMs. We also apply a post-training procedure\nfor fine-tuning models on higher-resolution images to further enrich the\ninformation encoded in the embeddings. We present three novel pathology FMs\ntrained on up to two orders of magnitude fewer WSIs than those used to train\nother state-of-the-art FMs while demonstrating a comparable or superior\nperformance on downstream tasks. Even the model trained on TCGA alone (12k\nWSIs) outperforms most existing FMs and, on average, matches Virchow2, the\nsecond-best FM published to date. This suggests that there still remains a\nsignificant potential for further improving the models and algorithms used to\ntrain pathology FMs to take full advantage of the vast data collections.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T15:38:12Z"}
{"aid":"http://arxiv.org/abs/2504.05188v1","title":"Breakdown of Bulk-Radiation Correspondence in Radiative Photonic\n  Lattices","summary":"The topological characteristics of energy bands in crystalline systems are\nencapsulated in the Berry curvature of the bulk Bloch states. In photonic\ncrystal slabs, far-field emission from guided resonances naturally provides a\nnon-invasive way to probe the embedded wavefunctions, raising the question of\nhow the information carried by escaping photons relates to the band topology.\nWe develop a non-Hermitian model to describe the guided and leaky modes of\nphotonic crystal slabs with long-range couplings and non-local responses.\nWithin this framework, radiation Berry curvature is defined from the far-field\npolarization and compared to the conventional bulk Berry curvature of the\ncrystal Bloch modes. We investigate this bulk-radiation correspondence in the\nvicinity of the $\\Gamma$-point of the square lattice and the $K$-point of the\nhoneycomb lattice. The results show that the comparability between the bulk\ntopology and the radiation topology is not universal; the validity is\ncontingent upon the specific bulk Bloch states. Notably, the correspondence\ncompletely breaks down surrounding the far-field singularities, while it can\nhold in smooth regions under special symmetry conditions, e.g., rotational\nsymmetry. Besides, net Berry curvature concentration is captured at the valleys\nof the non-local honeycomb lattice, facilitating further exploration on\ngeneralized topological phases in photonic lattices beyond the regimes with\nlocalized couplings and Hermiticity.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-07T15:40:02Z"}
{"aid":"http://arxiv.org/abs/2504.05216v1","title":"Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood\n  Modeling","summary":"Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-07T16:03:59Z"}
{"aid":"http://arxiv.org/abs/2504.05229v1","title":"FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in\n  Explainable Automatic Fact-Checking","summary":"The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T16:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.05245v1","title":"Embedded Federated Feature Selection with Dynamic Sparse Training:\n  Balancing Accuracy-Cost Tradeoffs","summary":"Federated Learning (FL) enables multiple resource-constrained edge devices\nwith varying levels of heterogeneity to collaboratively train a global model.\nHowever, devices with limited capacity can create bottlenecks and slow down\nmodel convergence. One effective approach to addressing this issue is to use an\nefficient feature selection method, which reduces overall resource demands by\nminimizing communication and computation costs, thereby mitigating the impact\nof struggling nodes. Existing federated feature selection (FFS) methods are\neither considered as a separate step from FL or rely on a third party. These\napproaches increase computation and communication overhead, making them\nimpractical for real-world high-dimensional datasets. To address this, we\npresent \\textit{Dynamic Sparse Federated Feature Selection} (DSFFS), the first\ninnovative embedded FFS that is efficient in both communication and\ncomputation. In the proposed method, feature selection occurs simultaneously\nwith model training. During training, input-layer neurons, their connections,\nand hidden-layer connections are dynamically pruned and regrown, eliminating\nuninformative features. This process enhances computational efficiency on\ndevices, improves network communication efficiency, and boosts global model\nperformance. Several experiments are conducted on nine real-world datasets of\nvarying dimensionality from diverse domains, including biology, image, speech,\nand text. The results under a realistic non-iid data distribution setting show\nthat our approach achieves a better trade-off between accuracy, computation,\nand communication costs by selecting more informative features compared to\nother state-of-the-art FFS methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T16:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.05251v1","title":"Rationalizing dynamic choices","summary":"An analyst observes an agent take a sequence of actions. The analyst does not\nhave access to the agent's information and ponders whether the observed actions\ncould be justified through a rational Bayesian model with a known utility\nfunction. We show that the observed actions cannot be justified if and only if\nthere is a single deviation argument that leaves the agent better off,\nregardless of the information. The result is then extended to allow for\ndistributions over possible action sequences. Four applications are presented:\nmonotonicity of rationalization with risk aversion, a potential rejection of\nthe Bayesian model with observable data, feasible outcomes in dynamic\ninformation design, and partial identification of preferences without\nassumptions on information.","main_category":"econ.TH","categories":"econ.TH,econ.EM","published":"2025-04-07T16:43:26Z"}
{"aid":"http://arxiv.org/abs/2504.05252v1","title":"Topological Hall effect in ferromagnetic Weyl semimetal Mn$_5$Ge$_3$\n  originating in competing dipolar interaction and magnetocrystalline\n  anisotropy","summary":"We report the anomalous and topological Hall effect of the ferromagnetic Weyl\nsemimetal Mn$_5$Ge$_3$. We observe a significant anisotropic anomalous Hall\neffect (AHE) due to nonzero Berry curvature in the momentum space, such that\nthe anomalous Hall conductivity (AHC) is 965 S/cm for the $xy$-plane and 233\nS/cm for the $zx$-plane of the single crystal. The band structure calculations\npredict several Weyl and nodal points span across the momentum space, gapped\nout under the spin-orbit coupling effect, leading to significant $k$-space\nBerry curvature and large AHC. Experimentally, we also demonstrate a sizeable\ntopological Hall effect that is originated by the non-coplanar chiral spin\nstructure due to the competition between the out-of-plane uniaxial\nmagnetocrystalline anisotropy and the dipole-dipole interaction between two Mn\nsublattices. This study hints at the importance of dipole-dipole interactions\nin producing the skyrmion lattice in Mn$_5$Ge$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T16:44:26Z"}
{"aid":"http://arxiv.org/abs/2504.05291v1","title":"Using Physiological Measures, Gaze, and Facial Expressions to Model\n  Human Trust in a Robot Partner","summary":"With robots becoming increasingly prevalent in various domains, it has become\ncrucial to equip them with tools to achieve greater fluency in interactions\nwith humans. One of the promising areas for further exploration lies in human\ntrust. A real-time, objective model of human trust could be used to maximize\nproductivity, preserve safety, and mitigate failure. In this work, we attempt\nto use physiological measures, gaze, and facial expressions to model human\ntrust in a robot partner. We are the first to design an in-person, human-robot\nsupervisory interaction study to create a dedicated trust dataset. Using this\ndataset, we train machine learning algorithms to identify the objective\nmeasures that are most indicative of trust in a robot partner, advancing trust\nprediction in human-robot interactions. Our findings indicate that a\ncombination of sensor modalities (blood volume pulse, electrodermal activity,\nskin temperature, and gaze) can enhance the accuracy of detecting human trust\nin a robot partner. Furthermore, the Extra Trees, Random Forest, and Decision\nTrees classifiers exhibit consistently better performance in measuring the\nperson's trust in the robot partner. These results lay the groundwork for\nconstructing a real-time trust model for human-robot interaction, which could\nfoster more efficient interactions between humans and robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.05293v1","title":"A BLE and UWB Beacon-Assist Framework for Multiuser Augmented Reality\n  Synchronization Across Multiple Devices in Shared Environments","summary":"The challenge to synchronize augmented reality (AR) across sessions/devices\nhas been solved by relying solely on vision-feature mapping, which is\nsuboptimal in scaling workable space and flaws under visual changes in\nsurroundings. This study implemented AR synchronization solutions utilizing\nlocation beacon technology, namely Bluetooth Low Energy (BLE) and\nUltra-Wideband (UWB), to discourse scalability issues and inconsistencies in\nthe existing AR system. The framework is bifurcated into two approaches:\nBLE-assist and UWB-assist AR synchronization. The BLE-assist method utilizes\niBeacon technology for room context recognition, integrating with Apple's ARKit\nARWorldMap and Google's ARCore Cloud Anchors. The UWB-assist solution employs\nprecise beacon ranging capabilities fusion with the device's azimuth to\nestablish fixed spatial reference in AR across sessions/devices. Comparative\nevaluations show that the UWB-assist approach outperforms the BLE-assist\napproach in reliability across environmental variations, as it always\nsuccessfully resolves virtual anchors with a near-constant latency average at\n25 seconds, regardless of the physical setting changes. Conversely, the\nBLE-assist implementation tends to be more accurate in resolving virtual\nanchors with a mean of 0.02 metres in position error and within 0.03 radian in\norientation error. In the UWB-assist approach, computed fixed spatial\nreferences have an average disparity of 0.04 metres and 0.11 radians in pose.\nThe UWB-assist approach is ideal for scenarios requiring consistently\nsuccessful localization with acceptable accuracy. In contrast, the BLE-assist\napproach is more suitable when demanding finer precision in virtual anchor\nposes with the performance tradeoffs when the surroundings are altered, such as\nfor destinated short-lived AR sessions.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-07T17:47:49Z"}
{"aid":"http://arxiv.org/abs/2504.05295v1","title":"Dion: A Communication-Efficient Optimizer for Large Models","summary":"Training large AI models efficiently requires distributing computation across\nmultiple accelerators, but this often incurs significant communication overhead\n-- especially during gradient synchronization. We introduce Dion, a\ncommunication-efficient optimizer that retains the synchronous semantics of\nstandard distributed training (e.g., DDP, FSDP) while substantially reducing\nI/O costs. Unlike conventional optimizers that synchronize full gradient\nmatrices, Dion leverages orthonormalized updates with device-local momentum\nbuffers, eliminating the need for full gradient exchange. It further supports\nan efficient sharding strategy that avoids reconstructing large matrices during\ntraining.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.OC","published":"2025-04-07T17:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.05626v1","title":"Remarks on the locality of generalized global symmetries","summary":"We examine generalized global symmetries as a kind of compactly supported\ncohomology, and so are led to revisit questions about the locality of quantum\nfield theory, following Segal. Physics naturally suggests a generalization of\nfactorization algebras, aimed at capturing nonperturbative information, and we\nexplain how higher group symmetries offer examples of this generalization,\nproviding an extension of the nonabelian Poincar\\'e duality of Salvatore and\nLurie. Finally, we explore how continuous generalized symmetries and anomalies\ncan be cast in this framework.","main_category":"math-ph","categories":"math-ph,hep-th,math.AT,math.MP","published":"2025-04-08T03:02:00Z"}
{"aid":"http://arxiv.org/abs/2504.05647v1","title":"Phase transitions of the Erds-Gyrfs function","summary":"Given positive integers $p,q$. For any integer $k\\ge2$, an edge coloring of\nthe complete $k$-graph $K_n^{(k)}$ is said to be a $(p,q)$-coloring if every\ncopy of $K_p^{(k)}$ receives at least $q$ colors. The Erd\\H{o}s-Gy\\'{a}rf\\'{a}s\nfunction $f_k(n,p,q)$ is the minimum number of colors that are needed for\n$K_n^{(k)}$ to have a $(p,q)$-coloring.\n  Conlon, Fox, Lee and Sudakov (\\emph{IMRN, 2015}) conjectured that for any\npositive integers $p, k$ and $i$ with $k\\ge3$ and $1\\le i<k$,\n$f_k(n,p,{{p-i}\\choose{k-i}})=(\\log_{(i-1)}n)^{o(1)}$, where $\\log_{(i)}n$ is\nan iterated $i$-fold logarithm in $n$. It has been verified to be true for\n$k=3, p=4, i=1$ by Conlon et. al (\\emph{IMRN, 2015}), for $k=3, p=5, i=2$ by\nMubayi (\\emph{JGT, 2016}), and for all $k\\ge 4, p=k+1,i=1$ by B. Janzer and O.\nJanzer (\\emph{JCTB, 2024}). In this paper, we give new constructions and show\nthat this conjecture holds for infinitely many new cases, i.e., it holds for\nall $k\\ge4$, $p=k+2$ and $i=k-1$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T03:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.05673v1","title":"VC-LLM: Automated Advertisement Video Creation from Raw Footage using\n  Multi-modal LLMs","summary":"As short videos have risen in popularity, the role of video content in\nadvertising has become increasingly significant. Typically, advertisers record\na large amount of raw footage about the product and then create numerous\ndifferent short-form advertisement videos based on this raw footage. Creating\nsuch videos mainly involves editing raw footage and writing advertisement\nscripts, which requires a certain level of creative ability. It is usually\nchallenging to create many different video contents for the same product, and\nmanual efficiency is often low. In this paper, we present VC-LLM, a framework\npowered by Large Language Models for the automatic creation of high-quality\nshort-form advertisement videos. Our approach leverages high-resolution spatial\ninput and low-resolution temporal input to represent video clips more\neffectively, capturing both fine-grained visual details and broader temporal\ndynamics. In addition, during training, we incorporate supplementary\ninformation generated by rewriting the ground truth text, ensuring that all key\noutput information can be directly traced back to the input, thereby reducing\nmodel hallucinations. We also designed a benchmark to evaluate the quality of\nthe created videos. Experiments show that VC-LLM based on GPT-4o can produce\nvideos comparable to those created by humans. Furthermore, we collected\nnumerous high-quality short advertisement videos to create a pre-training\ndataset and manually cleaned a portion of the data to construct a high-quality\nfine-tuning dataset. Experiments indicate that, on the benchmark, the VC-LLM\nbased on fine-tuned LLM can produce videos with superior narrative logic\ncompared to those created by the VC-LLM based on GPT-4o.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:35:23Z"}
{"aid":"http://arxiv.org/abs/2504.05684v1","title":"TARO: Timestep-Adaptive Representation Alignment with Onset-Aware\n  Conditioning for Synchronized Video-to-Audio Synthesis","summary":"This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-04-08T04:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.05690v1","title":"STAGE: Stemmed Accompaniment Generation through Prefix-Based\n  Conditioning","summary":"Recent advances in generative models have made it possible to create\nhigh-quality, coherent music, with some systems delivering production-level\noutput.Yet, most existing models focus solely on generating music from scratch,\nlimiting their usefulness for musicians who want to integrate such models into\na human, iterative composition workflow.In this paper we introduce STAGE, our\nSTemmed Accompaniment GEneration model, fine-tuned from the state-of-the-art\nMusicGen to generate single-stem instrumental accompaniments conditioned on a\ngiven mixture. Inspired by instruction-tuning methods for language models, we\nextend the transformer's embedding matrix with a context token, enabling the\nmodel to attend to a musical context through prefix-based conditioning.Compared\nto the baselines, STAGE yields accompaniments that exhibit stronger coherence\nwith the input mixture, higher audio quality, and closer alignment with textual\nprompts.Moreover, by conditioning on a metronome-like track, our framework\nnaturally supports tempo-constrained generation, achieving state-of-the-art\nalignment with the target rhythmic structure--all without requiring any\nadditional tempo-specific module.As a result, STAGE offers a practical,\nversatile tool for interactive music creation that can be readily adopted by\nmusicians in real-world workflows.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T05:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.05699v1","title":"Spacetime Models for Cosmology","summary":"I revisit Roberto Torretti's \"Spacetime Models for the World\" [SHPMP 31\n(2):171-186 (2000)] in the light of more recent work in (philosophy of)\ncosmology. I discuss the motivations for FLRW spacetimes as a natural starting\npoint for inquiry, and I suggest contemporary cosmologists can avoid the\nrationalism that Torretti attributes to Einstein's early work in relativistic\ncosmology. I then discuss the senses in which FLRW models are idealized, and I\nshow how those idealizations (and partial de-idealizations) have contributed to\nour understanding of the universe.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc","published":"2025-04-08T05:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.05715v1","title":"On the evidence of a dark matter density spike around the primary black\n  hole in OJ 287","summary":"The central engine of blazar OJ~287 is arguably the most notable supermassive\nblack hole (SMBH) binary candidate that emits nano-Hertz (nHz) gravitational\nwaves. This inference is mainly due to our ability to predict and successfully\nmonitor certain quasi-periodic doubly peaked high brightness flares with a\nperiod of $\\sim$12 years from this blazer. The use of post-Newtonian accurate\nSMBH binary orbital description that includes the effects of higher order GW\nemission turned out to be a crucial ingredient for accurately predicting the\nepochs of such Bremsstrahlung flares in our SMBH binary central engine\ndescription for OJ~287. It was very recently argued that one should include the\neffects of dynamical friction, induced by certain dark matter density spikes\naround the primary SMBH, to explain the {\\it observed} decay of SMBH binary\norbit in OJ~287. Invoking binary pulsar timing-based arguments, measurements,\nand OJ~287's orbital description, we show that observationally relevant SMBH\nbinary orbital dynamics in OJ~287 are insensitive to dark matter-induced\ndynamical friction effects. This implies that we could only provide an upper\nbound on the spike index parameter rather than obtaining an observationally\nderived value, as argued by \\cite{Chan2024}.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,gr-qc","published":"2025-04-08T06:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.05717v1","title":"Rainbow gravity effects on Klein-Gordon particles in a quantized\n  nonuniform external magnetic field in the Bonnor-Melvin domain walls\n  background","summary":"We investigate the effect of rainbow gravity on Klein-Gordon (KG) bosons in a\nquantized nonuniform magnetic field in the background of Bonnor-Melvin (BM)\nspacetime with a cosmological constant. In the process, we show that the BM\nspacetime introduces domain walls (i.e., infinitely impenetrable hard walls) at\n\\(r = 0\\) and \\(r = \\pi/\\sqrt{2\\Lambda}\\), as a consequence of the effective\ngravitational potential field generated by such a magnetized BM spacetime. As a\nresult, the motion of KG particles/antiparticles is restricted indefinitely\nwithin the range \\(r \\in [0, \\pi/\\sqrt{2\\Lambda}]\\), and the particles and\nantiparticles cannot be found elsewhere. Next, we provide a conditionally exact\nsolution in the form of the general Heun function \\(H_G(a, q, \\alpha, \\beta,\n\\gamma, \\delta, z)\\). Within the BM domain walls and under the condition of\nexact solvability, we study the effects of rainbow gravity on KG bosonic fields\nin a quantized nonuniform external magnetic field in the BM spacetime\nbackground. We use three pairs of rainbow functions: \\( f(u) = (1 -\n\\tilde{\\beta} |E|)^{-1}, \\, h(u) = 1 \\); and \\( f(u) = 1, \\, h(u) = \\sqrt{1 -\n\\tilde{\\beta} |E|^\\upsilon} \\), with \\(\\upsilon = 1,2\\), where \\(u = |E| /\nE_p\\), \\(\\tilde{\\beta} = \\beta / E_p\\), and \\(\\beta\\) is the rainbow parameter.\nWe find that such pairs of rainbow functions, \\((f(u), h(u))\\), fully comply\nwith the theory of rainbow gravity, ensuring that \\(E_p\\) is the maximum\npossible energy for particles and antiparticles alike. Moreover, we show that\nthe corresponding bosonic states form magnetized, rotating vortices, as\nintriguing consequences of such a magnetized BM spacetime background.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-08T06:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.05735v1","title":"Anomalous Maxwell-Garnett theory for photonic time crystals","summary":"Maxwell-Garnett theory, dating back to James Clerk Maxwell-Garnett's\nfoundational work in 1904, provides a simple yet powerful framework to describe\nthe inhomogeneous structure as an effective homogeneous medium, which\nsignificantly reduces the overall complexity of analysis, calculation, and\ndesign. As such, the Maxwell-Garnett theory enables many practical applications\nin diverse realms, ranging from photonics, acoustics, mechanics,\nthermodynamics, to material science. It has long been thought that the\nMaxwell-Garnett theory of light in impedance-mismatched periodic structures is\nvalid only within the long-wavelength limit, necessitating either the temporal\nor spatial period of light to be much larger than that of structures. Here, we\nbreak this long-held belief by revealing an anomalous Maxwell-Garnett theory\nfor impedance-mismatched photonic time crystals beyond this long-wavelength\nlimit. The key to this anomaly lies in the Fabry-Perot resonance. We discover\nthat under the Fabry-P\\'erot resonance, the impedance-mismatched photonic time\ncrystal could be essentially equivalent to a homogeneous temporal slab\nsimultaneously at specific discrete wavelengths, despite the temporal period of\nthese light being comparable to or even much smaller than that of photonic time\ncrystals.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T07:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.05747v1","title":"SEA-LION: Southeast Asian Languages in One Network","summary":"Recently, Large Language Models (LLMs) have dominated much of the artificial\nintelligence scene with their ability to process and generate natural\nlanguages. However, the majority of LLM research and development remains\nEnglish-centric, leaving low-resource languages such as those in the Southeast\nAsian (SEA) region under-represented. To address this representation gap, we\nintroduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge\nmultilingual LLMs designed for SEA languages. The SEA-LION family of LLMs\nsupports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese,\nMalay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages\nlarge-scale multilingual continued pre-training with a comprehensive\npost-training regime involving multiple stages of instruction fine-tuning,\nalignment, and model merging. Evaluation results on multilingual benchmarks\nindicate that our models achieve state-of-the-art performance across LLMs\nsupporting SEA languages. We open-source the models to benefit the wider SEA\ncommunity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.05781v1","title":"Building Proactive and Instant-Reactive Safety Designs to Address\n  Harassment in Social Virtual Reality","summary":"Social Virtual Reality (VR) games offer immersive socialization experiences\nbut pose significant challenges of harassment. Common solutions, such as\nreporting and moderation, address harassment after it happens but fail to\nprevent or stop harassment in the moment. In this study, we explore and design\nproactive and instant-reactive safety designs to mitigate harassment in social\nVR. Proactive designs prevent harassment from occurring, while instant-reactive\ndesigns minimize harm during incidents. We explore three directions for design:\nuser-initiated personal bubbles, clarifying social norms, and encouraging\nbystander intervention. Through an iterative process, we first conducted a\nformative interview study to determine design goals for making these features\neffective, fit user needs, and robust to manipulation. We then implemented\nPuffer, an integrated safety system that includes a suite of proactive and\ninstant-reactive features, as a social VR prototype. From an evaluation using\nsimulated scenarios with participants, we find evidence that Puffer can help\nprotect players during emergencies, foster prosocial norms, and create more\npositive social interactions. We conclude by discussing how system safety\nfeatures can be designed to complement existing proactive and instant-reactive\nstrategies, particularly for people with marginalized identities.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-08T08:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.05782v1","title":"MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in\n  Multimodal Large Language Models","summary":"Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:06:53Z"}
{"aid":"http://arxiv.org/abs/2504.05789v1","title":"Leveraging Synthetic Adult Datasets for Unsupervised Infant Pose\n  Estimation","summary":"Human pose estimation is a critical tool across a variety of healthcare\napplications. Despite significant progress in pose estimation algorithms\ntargeting adults, such developments for infants remain limited. Existing\nalgorithms for infant pose estimation, despite achieving commendable\nperformance, depend on fully supervised approaches that require large amounts\nof labeled data. These algorithms also struggle with poor generalizability\nunder distribution shifts. To address these challenges, we introduce SHIFT:\nLeveraging SyntHetic Adult Datasets for Unsupervised InFanT Pose Estimation,\nwhich leverages the pseudo-labeling-based Mean-Teacher framework to compensate\nfor the lack of labeled data and addresses distribution shifts by enforcing\nconsistency between the student and the teacher pseudo-labels. Additionally, to\npenalize implausible predictions obtained from the mean-teacher framework, we\nincorporate an infant manifold pose prior. To enhance SHIFT's self-occlusion\nperception ability, we propose a novel visibility consistency module for\nimproved alignment of the predicted poses with the original image. Extensive\nexperiments on multiple benchmarks show that SHIFT significantly outperforms\nexisting state-of-the-art unsupervised domain adaptation (UDA) pose estimation\nmethods by 5% and supervised infant pose estimation methods by a margin of 16%.\nThe project page is available at: https://sarosijbose.github.io/SHIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.05808v1","title":"Fast Sphericity and Roundness approximation in 2D and 3D using Local\n  Thickness","summary":"Sphericity and roundness are fundamental measures used for assessing object\nuniformity in 2D and 3D images. However, using their strict definition makes\ncomputation costly. As both 2D and 3D microscopy imaging datasets grow larger,\nthere is an increased demand for efficient algorithms that can quantify\nmultiple objects in large volumes. We propose a novel approach for extracting\nsphericity and roundness based on the output of a local thickness algorithm.\nFor sphericity, we simplify the surface area computation by modeling objects as\nspheroids/ellipses of varying lengths and widths of mean local thickness. For\nroundness, we avoid a complex corner curvature determination process by\napproximating it with local thickness values on the contour/surface of the\nobject. The resulting methods provide an accurate representation of the exact\nmeasures while being significantly faster than their existing implementations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.05810v1","title":"PaMi-VDPO: Mitigating Video Hallucinations by Prompt-Aware\n  Multi-Instance Video Preference Learning","summary":"Direct Preference Optimization (DPO) helps reduce hallucinations in Video\nMultimodal Large Language Models (VLLMs), but its reliance on offline\npreference data limits adaptability and fails to capture true video-response\nmisalignment. We propose Video Direct Preference Optimization (VDPO), an online\npreference learning framework that eliminates the need for preference\nannotation by leveraging video augmentations to generate rejected samples while\nkeeping responses fixed. However, selecting effective augmentations is\nnon-trivial, as some clips may be semantically identical to the original under\nspecific prompts, leading to false rejections and disrupting alignment. To\naddress this, we introduce Prompt-aware Multi-instance Learning VDPO\n(PaMi-VDPO), which selects augmentations based on prompt context. Instead of a\nsingle rejection, we construct a candidate set of augmented clips and apply a\nclose-to-far selection strategy, initially ensuring all clips are semantically\nrelevant while then prioritizing the most prompt-aware distinct clip. This\nallows the model to better capture meaningful visual differences, mitigating\nhallucinations, while avoiding false rejections, and improving alignment.\nPaMi-VDPOseamlessly integrates into existing VLLMs without additional\nparameters, GPT-4/human supervision. With only 10k SFT data, it improves the\nbase model by 5.3% on VideoHallucer, surpassing GPT-4o, while maintaining\nstable performance on general video benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.05826v1","title":"Work statistics and thermal phase transitions","summary":"The investigation of nonequilibrium thermodynamics in quantum many-body\nsystems underscores the importance of quantum work, which differs from its\nclassical counterpart due to its statistical nature. Recent studies have shown\nthat quantum work can serve as an effective indicator of quantum phase\ntransitions in systems subjected to sudden quenches. However, the potential of\nquantum work to identify thermal phase transitions remains largely unexplored.\nIn this paper, we examine several types of thermal phase transitions in a\nsudden-quench hard-core boson model, including Ising, three-state Potts, and\nBerezinskii-Kosterlitz-Thouless transitions. Through finite-size scaling\nanalysis, we conclude that work statistics can also characterize the critical\nbehaviors of thermal phase transitions in generic many-body systems. Our\ninvestigation paves the way for applying work statistics to characterize\ncritical behavior in many-body systems, with implications that may extend to\nbroader contexts.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:08:01Z"}
{"aid":"http://arxiv.org/abs/2504.05838v1","title":"Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and\n  Deceptive Jailbreaking","summary":"Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-08T09:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.05852v1","title":"Physics-aware generative models for turbulent fluid flows through\n  energy-consistent stochastic interpolants","summary":"Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.","main_category":"cs.CE","categories":"cs.CE,cs.AI,cs.NA,math.NA","published":"2025-04-08T09:29:01Z"}
{"aid":"http://arxiv.org/abs/2504.05858v1","title":"Structural and Electrical Transport Properties of NASICON type\n  Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$ 0.1-0.4) Solid\n  Electrolyte Materials","summary":"We report the structural, resistivity, impedance, and dielectric studies of\nisovalent substituted Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$\n0.1--0.4) NASICON type solid electrolyte materials. The Rietveld refinement of\nXRD patterns shows the monoclinic phase with space group of C 2/c for all the\nsamples. The resistivity analysis shows the Arrhenius-type thermal conduction\nwith an increase in activation energy with doping is explained based on\ndecreased unit cell volume. We use Maxwell-Wagner-Sillars (MWS) relaxation and\nspace charge or interfacial polarization models to explain the frequency and\ntemperature-dependent variations of electric permittivity. The double\nrelaxation peaks in the dielectric loss data show the two types of relaxation\nmechanisms of different activation energy. The real ($\\epsilon^{'}$) and\nimaginary ($\\epsilon^{''}$) parts of permittivity are fitted using the modified\nCole-Cole equation, including the conductivity term, which show the non-Debye\ntype relaxation over the measured frequency and temperature range. The\nimpedance analysis shows the contributions from grain and grain boundary\nrelaxation. The fitting performed using the impedance and constant-phase\nelement (CPE) confirm the non-Debye type relaxation. Moreover, the electric\nmodulus analysis confirms the ionic nature having thermally activated\nrelaxation and the modulus scaling analysis shows a similar type of relaxation\nin the measured temperature range. The modified power law is used to understand\nthe frequency dependence of {\\it a.c.} conductivity data. The temperature\ndependence of exponent ($s$) in modified power law suggests the change in the\nconduction mechanism from near small polaron tunneling (NSPT) to correlated\nbarrier hopping (CBH) above room temperature. The larger values of\n$\\epsilon$$_{r}$ indicate these materials as a potential candidate for\ncharge-storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T09:36:05Z"}
{"aid":"http://arxiv.org/abs/2504.05901v1","title":"Improvement Ergodic Theory For The Infinite Word\n  $\\mathfrak{F}=\\mathfrak{F}_{b}:=\\left({ }_{b} f_{n}\\right)_{n \\geqslant 0}$\n  on Fibonacci Density","summary":"The paper explores combinatorial properties of Fibonacci words and their\ngeneralizations within the framework of combinatorics on words. These infinite\nsequences, measures the diversity of subwords in Fibonacci words, showing\nnon-decreasing growth for infinite sequences. Extends factor analysis to\narithmetic progressions of symbols, highlighting generalized pattern\ndistributions. Recent results link Sturmian sequences (including Fibonacci\nwords) to unbounded binomial complexity and gap inequivalence, with\nimplications for formal language theory and automata. This work underscores the\ninterplay between substitution rules, algebraic number theory, and\ncombinatorial complexity in infinite words, providing tools for applications in\nfractal geometry and theoretical computer science.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T10:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.05912v1","title":"Financial resilience of agricultural and food production companies in\n  Spain: A compositional cluster analysis of the impact of the Ukraine-Russia\n  war (2021-2023)","summary":"This study analyzes the financial resilience of agricultural and food\nproduction companies in Spain amid the Ukraine-Russia war using cluster\nanalysis based on financial ratios. This research utilizes centered log-ratios\nto transform financial ratios for compositional data analysis. The dataset\ncomprises financial information from 1197 firms in Spain's agricultural and\nfood sectors over the period 2021-2023. The analysis reveals distinct clusters\nof firms with varying financial performance, characterized by metrics of\nsolvency and profitability. The results highlight an increase in resilient\nfirms by 2023, underscoring sectoral adaptation to the conflict's economic\nchallenges. These findings together provide insights for stakeholders and\npolicymakers to improve sectorial stability and strategic planning.","main_category":"q-fin.ST","categories":"q-fin.ST,stat.AP","published":"2025-04-08T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.05932v1","title":"The complete trans-series for conserved charges in the Lieb-Liniger\n  model","summary":"We determine the complete trans-series solution for the (non-relativistic)\nmoments of the rapidity density in the Lieb-Liniger model. The trans-series is\nwritten explicitly in terms of a perturbative basis, which can be obtained from\nthe already known perturbative expansion of the density by solving several\nordinary differential equations. Unknown integration constants are fixed from\nVolin's method. We have checked that our solution satisfies the analytical\nconsistency requirements including the newly derived resurgence relations and\nagrees with the high precision numerical solution. Our results also provides\nthe full analytic trans-series for the capacitance of the coaxial circular\nplate capacitor.","main_category":"hep-th","categories":"hep-th,cond-mat.quant-gas,cond-mat.stat-mech","published":"2025-04-08T11:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.05935v1","title":"Stabilization of solutions of the controlled non-local continuity\n  equation","summary":"Non-local continuity equation describes an infinite system of identical\nparticles, which interact with each other through the common field. Solution of\nthis equation is a probability measure that stands for spatial distribution of\nparticles. The paper is concerned with stabilization of this solution in the\ncase of controlled dynamic. By generalizing methods used control-Lyapunov\nfunction to the case of Wasserstein spaces, we construct a feedback strategy\nthat provides local stabilization, i.e. leads the trajectory to a small\nneighbourhood of stabilization target. Based on this strategy, we construct a\nfeedback that makes global stabilization, i.e. leads the trajectory infinitely\nclose to stabilization target.","main_category":"math.DS","categories":"math.DS,math.OC","published":"2025-04-08T11:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.05939v1","title":"Collision-free landing of multiple UAVs on moving ground vehicles using\n  time-varying control barrier functions","summary":"In this article, we present a centralized approach for the control of\nmultiple unmanned aerial vehicles (UAVs) for landing on moving unmanned ground\nvehicles (UGVs) using control barrier functions (CBFs). The proposed control\nframework employs two kinds of CBFs to impose safety constraints on the UAVs'\nmotion. The first class of CBFs (LCBF) is a three-dimensional exponentially\ndecaying function centered above the landing platform, designed to safely and\nprecisely land UAVs on the UGVs. The second set is a spherical CBF (SCBF),\ndefined between every pair of UAVs, which avoids collisions between them. The\nLCBF is time-varying and adapts to the motions of the UGVs. In the proposed CBF\napproach, the control input from the UAV's nominal tracking controller designed\nto reach the landing platform is filtered to choose a minimally-deviating\ncontrol input that ensures safety (as defined by the CBFs). As the control\ninputs of every UAV are shared in establishing multiple CBF constraints, we\nprove that the control inputs are shared without conflict in rendering the safe\nsets forward invariant. The performance of the control framework is validated\nthrough a simulated scenario involving three UAVs landing on three moving\ntargets.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T11:54:45Z"}
{"aid":"http://arxiv.org/abs/2504.05943v1","title":"New inequalities for the extended Euler-Poincar theorem","summary":"In [Acta Math. 161 (3--4) (1988) 279--303], Bj\\\"{o}rner and Kalai extended\nthe classic Euler-Poincar\\'{e} theorem by introducing certain nonlinear\nrelations between the $f$-vector and the Betti sequence of simplicial\ncomplexes. In this paper, we present an equivalent characterization of\nBj\\\"{o}rner and Kalai's nonlinear relations using a number-theoretic approach.\nMoreover, we strengthen a result of Bj\\\"{o}rner and Kalai concerning the\nmaximal element of Betti sequences with respect to a fixed $f$-vector and the\nminimal element of $f$-vectors with respect to a fixed Betti sequence.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05945v1","title":"CKGAN: Training Generative Adversarial Networks Using Characteristic\n  Kernel Integral Probability Metrics","summary":"In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-08T11:58:56Z"}
{"aid":"http://arxiv.org/abs/2504.05982v1","title":"Have you tried turning it off and on again? Stochastic resetting for\n  enhanced sampling","summary":"Molecular dynamics simulations are widely used across chemistry, physics, and\nbiology, providing quantitative insight into complex processes with atomic\ndetail. However, their limited timescale of a few microseconds is a significant\nobstacle in describing phenomena such as conformational transitions of\nbiomolecules and polymorphism in molecular crystals. Recently, stochastic\nresetting, i.e., randomly stopping and restarting the simulations, emerged as a\npowerful enhanced sampling approach, which is collective variable-free, highly\nparallelized, and easily implemented in existing molecular dynamics codes.\nResetting expedites sampling rare events while enabling the inference of\nkinetic observables of the underlying process. It can be employed as a\nstandalone tool or in combination with other enhanced sampling methods, such as\nMetadynamics, with each technique compensating for the drawbacks of the other.\nHere, we comprehensively describe resetting and its theoretical background,\nreview recent developments in stochastic resetting for enhanced sampling, and\nprovide instructive guidelines for practitioners.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-08T12:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.05986v1","title":"Nehari's Theorem for Schatten class Hankel operators for convex domains","summary":"Recently it was proven that for a convex subset of $\\mathbb{R}^{n}$ that has\ninfinitely many extreme vectors, the Nehari theorem fails, that is, there\nexists a bounded Hankel operator $H_{\\phi}$ on the Paley--Wiener space\n$PW(\\Omega)$ that does not admit a bounded symbol. In this paper we examine\nwhether Nehari's theorem can hold under the stronger assumption that the Hankel\noperator $H_{\\phi}$ is in the Schatten class $S^{p}(PW(\\Omega))$. We prove that\nthis fails for $p>4$ for any convex subset of $\\mathbb{R}^{n}$, $n\\geq2$, of\nboundary with a $C^{2}$ neighborhood of nonzero curvature. Furthermore we prove\nthat for a simple polytope $P$ in $\\mathbb{R}^{n}$, the inequality\n$$\\int_{\\mathbb{R}^{n}}\\dfrac{|\\widehat{f}(x)|^{2}}{m(P\\cap (x-P))}dx\\leq\nC\\|f\\|_{L^{1}}^{2},$$ holds for all $f\\in PW^{1}(2P)$, and consequently any\nHilbert--Schmidt Hankel operator on a Paley--Wiener space of a simple polytope\nis generated by a bounded function.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T12:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.05992v1","title":"Under-Sampled High-Dimensional Data Recovery via Symbiotic Multi-Prior\n  Tensor Reconstruction","summary":"The advancement of sensing technology has driven the widespread application\nof high-dimensional data. However, issues such as missing entries during\nacquisition and transmission negatively impact the accuracy of subsequent\ntasks. Tensor reconstruction aims to recover the underlying complete data from\nunder-sampled observed data by exploring prior information in high-dimensional\ndata. However, due to insufficient exploration, reconstruction methods still\nface challenges when sampling rate is extremely low. This work proposes a\ntensor reconstruction method integrating multiple priors to comprehensively\nexploit the inherent structure of the data. Specifically, the method combines\nlearnable tensor decomposition to enforce low-rank constraints of the\nreconstructed data, a pre-trained convolutional neural network for smoothing\nand denoising, and block-matching and 3D filtering regularization to enhance\nthe non-local similarity in the reconstructed data. An alternating direction\nmethod of the multipliers algorithm is designed to decompose the resulting\noptimization problem into three subproblems for efficient resolution. Extensive\nexperiments on color images, hyperspectral images, and grayscale videos\ndatasets demonstrate the superiority of our method in extreme cases as compared\nwith state-of-the-art methods.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T12:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05997v1","title":"Note on the Universality of Parameterized IQP Circuits with Hidden Units\n  for Generating Probability Distributions","summary":"In a series of recent works, an interesting quantum generative model based on\nparameterized instantaneous polynomial quantum (IQP) circuits has emerged as\nthey can be trained efficiently classically using any loss function that\ndepends only on the expectation values of observables of the model. The model\nis proven not to be universal for generating arbitrary distributions, but it is\nsuspected that marginals can be - much like Boltzmann machines achieve\nuniversality by utilizing hidden (traced-out in quantum jargon) layers. In this\nshort note, we provide two simple proofs of this fact. The first is\nnear-trivial and asymptotic, and the second shows universality can be achieved\nwith a reasonable number of additional qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:03:23Z"}
{"aid":"http://arxiv.org/abs/2504.06009v1","title":"Linear time-and-space-invariant relaxation systems","summary":"This paper generalizes the physical property of relaxation from linear\ntime-invariant (LTI) to linear time-and-space-invariant (LTSI) systems. It is\nshown that the defining features of relaxation -- complete monotonicity,\npassivity, and memory-based storage -- carry over seamlessly to the\nspatio-temporal domain. An LTSI system is shown to be of relaxation type if and\nonly if its associated spatio-temporal Hankel operator is cyclically monotone.\nThis implies the existence of an intrinsic quadratic storage functional defined\nuniquely by past inputs, independently of any state-space realization. As in\nthe LTI case, LTSI relaxation systems are shown to be those systems for which\nthe state-space concept of storage coincides with the input-output concept of\nfading memory functional.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-08T13:16:47Z"}
{"aid":"http://arxiv.org/abs/2504.06014v1","title":"Sparse Reconstruction of Multi-Dimensional Kinetic Distributions","summary":"In the present work, we propose a novel method for reconstruction of\nmulti-dimensional kinetic distributions, based on their representation as a\nmixture of Dirac delta functions. The representation is found as a solution of\nan optimization problem. Different target functionals are considered, with a\nfocus on sparsity-promoting regularization terms. The proposed algorithm\nguarantees non-negativity of the distribution by construction, and avoids an\nexponential dependence of the computational cost on the dimensionality of the\nproblem.\n  Numerical comparisons with other classical methods for reconstruction of\nkinetic distributions are provided for model problems, and the role of the\ndifferent parameters governing the optimization problem is studied.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-08T13:19:27Z"}
{"aid":"http://arxiv.org/abs/2504.06035v1","title":"Cosmic inflation in non-perturbative quantum gravity","summary":"String field theory motivated infinite-derivative models lead to non-local\ngravity modifications which form a promising class of quantum gravity\ncandidates. In this paper we investigate effects of non-locality on the\nthree-point function (the bi-spectrum) during cosmic inflation. The study is\ndone in an Einstein frame with an infinite-derivative scalar field Lagrangian\nminimally coupled to the Einstein-Hilbert term. A non-local generalization of\nthe Mukhanov-Sasaki equation is derived. Infinite-derivative operators present\nin this equation lead to an appearance of infinitely many new background\ninduced states in the perturbation spectrum during inflation with complex\nmasses on top of a usual nearly massless inflaton. On contrary to a flat\nbackground such states can be classically stable in a de Sitter space-time.\nThis helps preserving observational constraints on the scalar power-spectrum.\nWe proceed by studying a particular configuration assuming that the generalized\nMukhanov-Sasaki equation gives rise to an inflaton and one pair of new states\nwith complex conjugate masses as perturbative degrees of freedom. The\ncorresponding scalar bi-spectrum is computed numerically in squeezed and\nequilateral limits. We use the latest observational constraints on amplitude of\nthe bi-spectrum $f_{NL}$ from Planck 2018 dataset as a guideline for possible\nvalues of masses of new emerging states. We find that $f_{NL}$ is non-trivially\nsensitive to the values of complex masses and this can reduce the parameter\nspace of gravity modifications. In particular we find that the amplitude of the\nsqueezed limit gets easily enhanced while of the equilateral limit can stay\nlike in a local single-field model of inflation. We end up discussing open\nquestions relevant for this class of models of inflation.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-08T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.06067v1","title":"GPU-accelerated Evolutionary Many-objective Optimization Using\n  Tensorized NSGA-III","summary":"NSGA-III is one of the most widely adopted algorithms for tackling\nmany-objective optimization problems. However, its CPU-based design severely\nlimits scalability and computational efficiency. To address the limitations, we\npropose {TensorNSGA-III}, a fully tensorized implementation of NSGA-III that\nleverages GPU parallelism for large-scale many-objective optimization. Unlike\nconventional GPU-accelerated evolutionary algorithms that rely on heuristic\napproximations to improve efficiency, TensorNSGA-III maintains the exact\nselection and variation mechanisms of NSGA-III while achieving significant\nacceleration. By reformulating the selection process with tensorized data\nstructures and an optimized caching strategy, our approach effectively\neliminates computational bottlenecks inherent in traditional CPU-based and\nna\\\"ive GPU implementations. Experimental results on widely used numerical\nbenchmarks show that TensorNSGA-III achieves speedups of up to $3629\\times$\nover the CPU version of NSGA-III. Additionally, we validate its effectiveness\nin multiobjective robotic control tasks, where it discovers diverse and\nhigh-quality behavioral solutions. Furthermore, we investigate the critical\nrole of large population sizes in many-objective optimization and demonstrate\nthe scalability of TensorNSGA-III in such scenarios. The source code is\navailable at https://github.com/EMI-Group/evomo","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-08T14:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.06068v1","title":"A Liouville-type property for degenerate-elliptic equations modeled on\n  Hrmander vector fields","summary":"We obtain Liouville type theorems for degenerate elliptic equation with a\ndrift term and a potential. The diffusion is driven by H\\\"ormander operators.\nWe show that the conditions imposed on the coefficients of the operator are\noptimal. Indeed, when they fail we prove that infinitely many bounded solutions\nexist.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.06070v1","title":"PINP: Physics-Informed Neural Predictor with latent estimation of fluid\n  flows","summary":"Accurately predicting fluid dynamics and evolution has been a long-standing\nchallenge in physical sciences. Conventional deep learning methods often rely\non the nonlinear modeling capabilities of neural networks to establish mappings\nbetween past and future states, overlooking the fluid dynamics, or only\nmodeling the velocity field, neglecting the coupling of multiple physical\nquantities. In this paper, we propose a new physics-informed learning approach\nthat incorporates coupled physical quantities into the prediction process to\nassist with forecasting. Central to our method lies in the discretization of\nphysical equations, which are directly integrated into the model architecture\nand loss function. This integration enables the model to provide robust,\nlong-term future predictions. By incorporating physical equations, our model\ndemonstrates temporal extrapolation and spatial generalization capabilities.\nExperimental results show that our approach achieves the state-of-the-art\nperformance in spatiotemporal prediction across both numerical simulations and\nreal-world extreme-precipitation nowcasting benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T14:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.06072v1","title":"Black hole quasinormal mode resonances","summary":"Black hole quasinormal mode frequencies can be very close to each other\n(\"avoided crossings\") or even completely degenerate (\"exceptional points\") when\nthe system is characterized by more than one parameter. We investigate this\nresonant behavior and demonstrate that near exceptional points, the two modes\nare just different covers of the same complex function on a Riemann surface. We\nalso study the characteristic time domain signal due to the resonance in the\nfrequency domain, illustrating the analogy between black hole signals at\nresonance and harmonic oscillators driven by a resonant external force. We\ncarry out a numerical study of resonances between the fundamental mode and the\nfirst overtone in a specific toy model. We find that quasinormal mode\nfrequencies will not be accurately constrained unless we take into account the\neffect of resonances.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-08T14:12:04Z"}
{"aid":"http://arxiv.org/abs/2504.06127v1","title":"Optimal classification with outcome performativity","summary":"I consider the problem of classifying individual behavior in a simple setting\nof outcome performativity where the behavior the algorithm seeks to classify is\nitself dependent on the algorithm. I show in this context that the most\naccurate classifier is either a threshold or a negative threshold rule. A\nthreshold rule offers the \"good\" classification to those individuals whose\noutcome likelihoods are greater than some cutpoint, while a negative threshold\nrule offers the \"good\" outcome to those whose outcome likelihoods are less than\nsome cutpoint. While seemingly pathological, I show that a negative threshold\nrule can be the most accurate classifier when outcomes are performative. I\nprovide an example of such a classifier, and extend the analysis to more\ngeneral algorithm objectives, allowing the algorithm to differentially weigh\nfalse negatives and false positives, for example.","main_category":"econ.TH","categories":"econ.TH,cs.GT","published":"2025-04-08T15:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.06128v1","title":"Singularity and regularity of the critical 2D Stochastic Heat Flow","summary":"The Critical 2D Stochastic Heat Flow (SHF) provides a natural candidate\nsolution to the ill-posed 2D Stochastic Heat Equation with multiplicative\nspace-time white noise. In this paper, we initiate the investigation of the\nspatial properties of the SHF. We prove that, as a random measure on\n$\\mathbb{R}^2$, it is a.s. singular w.r.t. the Lebesgue measure. This is\nobtained by probing a \"quasi-critical\" regime and showing the asymptotic\nlog-normality of the mass assigned to vanishing balls, as the disorder strength\nis sent to zero at a suitable rate, accompanied by similar results for critical\n2D directed polymers. We also describe the regularity of the SHF, showing that\nit is a.s. H\\\"older $C^{-\\epsilon}$ for any $\\epsilon>0$, implying the absence\nof atoms, and we establish local convergence to zero in the long time limit.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-08T15:21:44Z"}
{"aid":"http://arxiv.org/abs/2504.06132v1","title":"Stochastic numerical approximation for nonlinear Fokker-Planck equations\n  with singular kernels","summary":"This paper studies the convergence rate of the Euler-Maruyama scheme for\nsystems of interacting particles used to approximate solutions of nonlinear\nFokker-Planck equations with singular interaction kernels, such as the\nKeller-Segel model. We derive explicit error estimates in the large-particle\nlimit for two objects: the empirical measure of the interacting particle system\nand the density distribution of a single particle. Specifically, under certain\nassumptions on the interaction kernel and initial conditions, we show that the\nconvergence rate of both objects towards solutions of the corresponding\nnonlinear FokkerPlanck equation depends polynomially on N (the number of\nparticles) and on h (the discretization step). The analysis shows that the\nscheme converges despite singularities in the drift term. To the best of our\nknowledge, there are no existing results in the literature of such kind for the\nsingular kernels considered in this work.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-08T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.06156v1","title":"ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile\n  Manipulation Interface","summary":"Tactile information plays a crucial role for humans and robots to interact\neffectively with their environment, particularly for tasks requiring the\nunderstanding of contact properties. Solving such dexterous manipulation tasks\noften relies on imitation learning from demonstration datasets, which are\ntypically collected via teleoperation systems and often demand substantial time\nand effort. To address these challenges, we present ViTaMIn, an embodiment-free\nmanipulation interface that seamlessly integrates visual and tactile sensing\ninto a hand-held gripper, enabling data collection without the need for\nteleoperation. Our design employs a compliant Fin Ray gripper with tactile\nsensing, allowing operators to perceive force feedback during manipulation for\nmore intuitive operation. Additionally, we propose a multimodal representation\nlearning strategy to obtain pre-trained tactile representations, improving data\nefficiency and policy robustness. Experiments on seven contact-rich\nmanipulation tasks demonstrate that ViTaMIn significantly outperforms baseline\nmethods, demonstrating its effectiveness for complex manipulation tasks.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.06189v1","title":"Accessible and Pedagogically-Grounded Explainability for Human-Robot\n  Interaction: A Framework Based on UDL and Symbolic Interfaces","summary":"This paper presents a novel framework for accessible and\npedagogically-grounded robot explainability, designed to support human-robot\ninteraction (HRI) with users who have diverse cognitive, communicative, or\nlearning needs. We combine principles from Universal Design for Learning (UDL)\nand Universal Design (UD) with symbolic communication strategies to facilitate\nthe alignment of mental models between humans and robots. Our approach employs\nAsterics Grid and ARASAAC pictograms as a multimodal, interpretable front-end,\nintegrated with a lightweight HTTP-to-ROS 2 bridge that enables real-time\ninteraction and explanation triggering. We emphasize that explainability is not\na one-way function but a bidirectional process, where human understanding and\nrobot transparency must co-evolve. We further argue that in educational or\nassistive contexts, the role of a human mediator (e.g., a teacher) may be\nessential to support shared understanding. We validate our framework with\nexamples of multimodal explanation boards and discuss how it can be extended to\ndifferent scenarios in education, assistive robotics, and inclusive AI.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-08T16:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.06191v1","title":"Impact of MvdW Equation of State and Neutrino Mass on r and s Process\n  Heavy Element Nucleosynthesis in Spiral, Elliptical and Dwarf Galactic\n  Environments and Kilonovae Events","summary":"We present an analysis of heavy element production with massive neutrinos in\ngalaxies of varying types (spiral, elliptical, and dwarf) and kilonovae events\nby incorporating a Multicomponent van der Waals (MvdW) equation of state (EoS)\nfor the opacity functions. This EoS is applied to derive opacities and\ncalculate the yields of isotopes formed in r-process and s-process\nnucleosynthesis, with and without the influence of neutrino masses or\noscillations. We look at both the lanthanide and actinide sequences using the\nMvdW parameters that involve the interaction strength and excluded volume\neffects. Our results reflect the characteristic differences found in r and s\nprocesses in the synthesis and long-term evolution of isotopes from the U, Th,\nand Sr chain across galactic environments. The inclusion of neutrino masses\nenhances the neutron-to-proton ratio, favoring heavier r-process isotopes and\naltering the overall galactic yields by cross section suppression. These\nfindings offer insights into the interplay of nuclear physics and astrophysical\nenvironments, highlighting the sensitivity of nucleosynthetic pathways to EoS\nmodifications and neutrino physics. We compare these results to metallicity\nprofiles of similar models: the Galactic Leaky Box, the Galactic Inflow, and\nthe Galactic Closed Box models and to the kilonova event GW170781.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T16:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06200v1","title":"Day algebras","summary":"In this paper we show that the Day monoidal product generalises in a\nstraightforward way to other algebraic constructions and partial algebraic\nconstructions on categories. This generalisation was motivated by its\napplications in logic, for example in hybrid and separation logic. We use the\ndescription of the Day monoidal product using profunctors to show that the\ndefinition generalises to an extension of an arbitrary algebraic structure on a\ncategory to a pseudo-algebraic structure on a functor category. We provide two\nfurther extensions. First we consider the case where some of the operations on\nthe category are partial, and second we show that the resulting operations on\nthe functor category have adjoints (they are residuated).","main_category":"math.CT","categories":"math.CT","published":"2025-04-08T16:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.06202v1","title":"Up-to-constants estimates on four-arm events for simple conformal loop\n  ensemble","summary":"We prove up-to-constants estimates for a general class of four-arm events in\nsimple conformal loop ensembles, i.e. CLE$_\\kappa$ for $\\kappa\\in (8/3,4]$. The\nfour-arm events that we consider can be created by either one or two loops,\nwith no constraint on the topology of the crossings. Our result is a key input\nin our series of works arxiv:2409.16230 and arxiv:2409.16273 on percolation of\nthe two-sided level sets in the discrete Gaussian free field (and level sets in\nthe occupation field of the random walk loop soup).\n  In order to get rid of all constraints on the topology of the crossings, we\nrely on the Brownian loop-soup representation of simple CLE [Ann. Math. 176\n(2012) 1827-1917], and a \"cluster version\" of a separation lemma for the\nBrownian loop soup. As a corollary, we also obtain up-to-constants estimates\nfor a general version of four-arm events for SLE$_\\kappa$ for $\\kappa\\in\n(8/3,4]$. This fixes (in the case of four arms and $\\kappa\\in(8/3,4]$) an\nessential gap in [Ann. Probab. 46 (2018) 2863-2907] and improves some estimates\ntherein.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-08T16:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06205v1","title":"HRMedSeg: Unlocking High-resolution Medical Image segmentation via\n  Memory-efficient Attention Modeling","summary":"High-resolution segmentation is critical for precise disease diagnosis by\nextracting micro-imaging information from medical images. Existing\ntransformer-based encoder-decoder frameworks have demonstrated remarkable\nversatility and zero-shot performance in medical segmentation. While\nbeneficial, they usually require huge memory costs when handling large-size\nsegmentation mask predictions, which are expensive to apply to real-world\nscenarios. To address this limitation, we propose a memory-efficient framework\nfor high-resolution medical image segmentation, called HRMedSeg. Specifically,\nwe first devise a lightweight gated vision transformer (LGViT) as our image\nencoder to model long-range dependencies with linear complexity. Then, we\ndesign an efficient cross-multiscale decoder (ECM-Decoder) to generate\nhigh-resolution segmentation masks. Moreover, we utilize feature distillation\nduring pretraining to unleash the potential of our proposed model. Extensive\nexperiments reveal that HRMedSeg outperforms state-of-the-arts in diverse\nhigh-resolution medical image segmentation tasks. In particular, HRMedSeg uses\nonly 0.59GB GPU memory per batch during fine-tuning, demonstrating low training\ncosts. Besides, when HRMedSeg meets the Segment Anything Model (SAM), our\nHRMedSegSAM takes 0.61% parameters of SAM-H. The code is available at\nhttps://github.com/xq141839/HRMedSeg.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T16:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.06221v1","title":"Quantum-stabilized states in magnetic dipolar quantum gases","summary":"A decade ago, a universal stabilization mechanism driven by quantum\nfluctuations was discovered in ultracold Bose gases of highly magnetic atoms.\nThis mechanism prevents these systems from collapsing and instead allows exotic\nstates of matter to arise, including ultradilute quantum droplets, crystallized\nquantum states, and specifically supersolids. We review the experimental and\ntheoretical progress in understanding these quantum-stabilized states, their\nemergence, and intriguing properties.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.stat-mech,physics.atom-ph,quant-ph","published":"2025-04-08T17:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.06234v1","title":"Observing radio transients with Phased ALMA: Pulses from the Galactic\n  Centre magnetar","summary":"Radio transients, such as pulsars and Fast Radio Bursts (FRBs), are primarily\ndetected at centimetre radio wavelengths, where higher luminosities are found.\nHowever, observations of sources in dense environments are heavily affected by\npropagation effects which may hinder a detection. Millimetre wave observations\nbypass this complication but require the largest radio telescopes to compensate\nfor the lower flux densities. When used in phased mode, the ALMA radio\ntelescope provides an equivalent dish size of 84m, being the most sensitive\ninstrument at mm/sub mm. With its high time resolution it offers a unique\nopportunity to study radio transients in an unexplored window. We study the\nGalactic Centre (GC) magnetar, PSR J1745$-$2900, as a laboratory for magnetars\nin complex magneto-turbulent environments and to link with FRBs. We showcase\nthe potential of ALMA in phased mode to observe radio transients and to\nachieve, for some sources, the first ever detections outside the cm wave range.\nWe studied the GC magnetar using ALMA archival data of Sgr A* at Band 3 from\nthe 2017 GMVA campaign. We searched in intensity and classified the pulses\nbased on their circular and linear polarisation properties and arrival phase.\nWe detected eight pulses with energies in the range of 10$^{29}$ erg. We\nconstructed its cumulative energy distribution and we fit a power law, where\nthe event rate scales with energy as $R \\propto E^{\\gamma}$. The result is an\nexponent of $\\gamma = -2.4 \\pm 0.1$. With the $\\gamma -$value and the system\nproperties of phased ALMA, we estimate that over 160 known pulsars could be\ndetected by ALMA. For repeating FRBs, observing during their peak activity\nwindow could lead to several detections. We expect that ALMA's lower frequency\nbands with polarisation capabilities, will serve as a pioneer on mm wave\nsearches for pulsars and to study complex environments involving radio\ntransients.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T17:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.06249v1","title":"Electronic Structure Guided Inverse Design Using Generative Models","summary":"The electronic structure of a material fundamentally determines its\nunderlying physical, and by extension, its functional properties. Consequently,\nthe ability to identify or generate materials with desired electronic\nproperties would enable the design of tailored functional materials.\nTraditional approaches relying on human intuition or exhaustive computational\nscreening of known materials remain inefficient and resource-prohibitive for\nthis task. Here, we introduce DOSMatGen, the first instance of a machine\nlearning method which generates crystal structures that match a given desired\nelectronic density of states. DOSMatGen is an E(3)-equivariant joint diffusion\nframework, and utilizes classifier-free guidance to accurately condition the\ngenerated materials on the density of states. Our experiments find this\napproach can successfully yield materials which are both stable and match\nclosely with the desired density of states. Furthermore, this method is highly\nflexible and allows for finely controlled generation which can target specific\ntemplates or even individual sites within a material. This method enables a\nmore physics-driven approach to designing new materials for applications\nincluding catalysts, photovoltaics, and superconductors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.06257v1","title":"PainNet: Statistical Relation Network with Episode-Based Training for\n  Pain Estimation","summary":"Despite the span in estimating pain from facial expressions, limited works\nhave focused on estimating the sequence-level pain, which is reported by\npatients and used commonly in clinics. In this paper, we introduce a novel\nStatistical Relation Network, referred to as PainNet, designed for the\nestimation of the sequence-level pain. PainNet employs two key modules, the\nembedding and the relation modules, for comparing pairs of pain videos, and\nproducing relation scores indicating if each pair belongs to the same pain\ncategory or not. At the core of the embedding module is a statistical layer\nmounted on the top of a RNN for extracting compact video-level features. The\nstatistical layer is implemented as part of the deep architecture. Doing so,\nallows combining multiple training stages used in previous research, into a\nsingle end-to-end training stage. PainNet is trained using the episode-based\ntraining scheme, which involves comparing a query video with a set of videos\nrepresenting the different pain categories. Experimental results show the\nbenefit of using the statistical layer and the episode-based training in the\nproposed model. Furthermore, PainNet outperforms the state-of-the-art results\non self-reported pain estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:52Z"}
{"aid":"http://arxiv.org/abs/2504.06262v1","title":"Paraxial fluids of light","summary":"Paraxial fluids of light are a promising platform for exploring collective\nphenomena in a highly tunable environment. These systems, which map the\npropagation of light through nonlinear media onto the wavefunction of effective\n2D quantum fluids, offer a complementary approach to traditional platforms such\nas cold atomic gases or superfluid helium. In this review, we present a\ndetailed overview of the theoretical framework underlying paraxial fluids of\nlight, including the nonlinear Schr\\\"odinger equation (NLSE) and its mapping to\nthe 2D+1 Gross-Pitaevskii equation (GPE). We explore the hydrodynamic\nformulation of these systems and we provide a comparative analysis of fluids of\nlight and cold atomic gases, examining key parameters and figures of merit.\n  We then review the recent experimental advances and the experimental\nplatforms currently used to realize paraxial fluids of light, including hot\natomic vapors, photorefractive crystals, and thermo-optic media. Additionally,\nwe question the geometry of the system extending the analogy from 2D+1 to lower\nor higher dimensions.\n  Looking forward, we outline the potential future directions for the field,\nincluding the use of laser cooled atoms as nonlinear media, the study of\ntwo-component mixtures, and the exploration of quantum effects beyond the\nmean-field approximation. These developments promise to deepen our\nunderstanding of quantum fluids and potentially contribute to advances in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,quant-ph","published":"2025-04-08T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.06553v1","title":"ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis","summary":"While recent work in scene reconstruction and understanding has made strides\nin grounding natural language to physical 3D environments, it is still\nchallenging to ground abstract, high-level instructions to a 3D scene.\nHigh-level instructions might not explicitly invoke semantic elements in the\nscene, and even the process of breaking a high-level task into a set of more\nconcrete subtasks, a process called hierarchical task analysis, is\nenvironment-dependent. In this work, we propose ASHiTA, the first framework\nthat generates a task hierarchy grounded to a 3D scene graph by breaking down\nhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assisted\nhierarchical task analysis, to generate the task breakdown, with task-driven 3D\nscene graph construction to generate a suitable representation of the\nenvironment. Our experiments show that ASHiTA performs significantly better\nthan LLM baselines in breaking down high-level tasks into environment-dependent\nsubtasks and is additionally able to achieve grounding performance comparable\nto state-of-the-art methods.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-09T03:22:52Z"}
{"aid":"http://arxiv.org/abs/2504.06570v1","title":"Data quality or data quantity? Prioritizing data collection under\n  distribution shift with the data usefulness coefficient","summary":"Researchers often have access to multiple data sources of varying quality.\nFor example, in psychology, a researcher may decide between running an\nexperiment on an online platform or on a representative sample of the\npopulation of interest. Collecting a representative sample will result in\nhigher quality data but is often more expensive. This raises the question of\nhow to optimally prioritize data collection under resource constraints. We\nstudy this question in a setting where the distribution shift arises through\nmany independent random changes in the population. We introduce a \"data\nusefulness coefficient\" (DUC) and show that it allows us to predict how much\nthe risk of empirical risk minimization would decrease if a specific data set\nwere added to the training data. An advantage of our procedure is that it does\nnot require access to any outcome data $Y$. Instead, we rely on a random shift\nassumption, which implies that the strength of covariate ($X$) shift is\npredictive of the shift in $Y \\mid X$. We also derive methods for sampling\nunder budget and size constraints. We demonstrate the benefits of data\ncollection based on DUC and our optimal sampling strategy in several numerical\nexperiments.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T04:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.06585v1","title":"Sim-to-Real of Humanoid Locomotion Policies via Joint Torque Space\n  Perturbation Injection","summary":"This paper proposes a novel alternative to existing sim-to-real methods for\ntraining control policies with simulated experiences. Prior sim-to-real methods\nfor legged robots mostly rely on the domain randomization approach, where a\nfixed finite set of simulation parameters is randomized during training.\nInstead, our method adds state-dependent perturbations to the input joint\ntorque used for forward simulation during the training phase. These\nstate-dependent perturbations are designed to simulate a broader range of\nreality gaps than those captured by randomizing a fixed set of simulation\nparameters. Experimental results show that our method enables humanoid\nlocomotion policies that achieve greater robustness against complex reality\ngaps unseen in the training domain.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T05:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.06586v1","title":"Diversity-aware Dual-promotion Poisoning Attack on Sequential\n  Recommendation","summary":"Sequential recommender systems (SRSs) excel in capturing users' dynamic\ninterests, thus playing a key role in various industrial applications. The\npopularity of SRSs has also driven emerging research on their security aspects,\nwhere data poisoning attack for targeted item promotion is a typical example.\nExisting attack mechanisms primarily focus on increasing the ranks of target\nitems in the recommendation list by injecting carefully crafted interactions\n(i.e., poisoning sequences), which comes at the cost of demoting users' real\npreferences. Consequently, noticeable recommendation accuracy drops are\nobserved, restricting the stealthiness of the attack. Additionally, the\ngenerated poisoning sequences are prone to substantial repetition of target\nitems, which is a result of the unitary objective of boosting their overall\nexposure and lack of effective diversity regularizations. Such homogeneity not\nonly compromises the authenticity of these sequences, but also limits the\nattack effectiveness, as it ignores the opportunity to establish sequential\ndependencies between the target and many more items in the SRS. To address the\nissues outlined, we propose a Diversity-aware Dual-promotion Sequential\nPoisoning attack method named DDSP for SRSs. Specifically, by theoretically\nrevealing the conflict between recommendation and existing attack objectives,\nwe design a revamped attack objective that promotes the target item while\nmaintaining the relevance of preferred items in a user's ranking list. We\nfurther develop a diversity-aware, auto-regressive poisoning sequence\ngenerator, where a re-ranking method is in place to sequentially pick the\noptimal items by integrating diversity constraints.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T05:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.06588v1","title":"A Digital Twin of an Electrical Distribution Grid: SoCal 28-Bus Dataset","summary":"We provide an open-access dataset of phasor & waveform measurement units\n(PMUs/WMUs) of a real-world electrical distribution network. The network\nconsists of diverse sets of generation resources (including solar panels, fuel\ncells, natural gas generators, and utility interconnections), loads (including\nlarge-scale electric vehicle charging, data centers, central cooling, offices),\ntopology changes (such as line outages and load transfers), as well as a\nmixture of single- and three-phase networks. We describe a densely deployed PMU\nsensor network in a distribution grid, in which all buses with non-zero power\ninjections are measured. This approach enables a range of applications such as\nstate estimation, system identification, power flow optimization, and feedback\ncontrol, several of which are discussed in this paper. Additionally, we provide\na synchronized waveform dataset which allows the analysis of harmonics,\ntransient events, dynamic grid impedance, and stability. Data collection\nstarted in 2023 while new data is generated continuously and made available\nonline. A characterization of measurement error is provided. Finally, we\nprovide circuit topology and parameters as a part of the dataset. Together, the\ncircuit and timeseries data offer an opportunity for researchers to develop and\ntest algorithms on a real-world system.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T05:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.06601v1","title":"Rounding of discrete variables","summary":"Let $X$ be a random variable that takes its values in\n$\\frac{1}{q}\\mathbb{Z}$, for some integer $q\\ge2$, and consider $X$ rounded to\nan integer, either downwards or upwards or to the nearest integer. We give\ngeneral formulas for the characteristic function and moments of the rounded\nvariable. These formulas complement the related but different formulas in the\ncase that $X$ has a continuous distribution, which was studied by Janson\n(2006).","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T05:59:14Z"}
{"aid":"http://arxiv.org/abs/2504.06608v1","title":"A Cross-Domain Few-Shot Learning Method Based on Domain Knowledge\n  Mapping","summary":"In task-based few-shot learning paradigms, it is commonly assumed that\ndifferent tasks are independently and identically distributed (i.i.d.).\nHowever, in real-world scenarios, the distribution encountered in few-shot\nlearning can significantly differ from the distribution of existing data. Thus,\nhow to effectively leverage existing data knowledge to enable models to quickly\nadapt to class variations under non-i.i.d. assumptions has emerged as a key\nresearch challenge. To address this challenge, this paper proposes a new\ncross-domain few-shot learning approach based on domain knowledge mapping,\napplied consistently throughout the pre-training, training, and testing phases.\nIn the pre-training phase, our method integrates self-supervised and supervised\nlosses by maximizing mutual information, thereby mitigating mode collapse.\nDuring the training phase, the domain knowledge mapping layer collaborates with\na domain classifier to learn both domain mapping capabilities and the ability\nto assess domain adaptation difficulty. Finally, this approach is applied\nduring the testing phase, rapidly adapting to domain variations through\nmeta-training tasks on support sets, consequently enhancing the model's\ncapability to transfer domain knowledge effectively. Experimental validation\nconducted across six datasets from diverse domains demonstrates the\neffectiveness of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.06630v1","title":"Two-Axis planar Hall magnetic field sensors with sub nanoTesla\n  resolution","summary":"Planar Hall effect (PHE) magnetic sensors are attractive for various\napplications where the field resolution is required in the range of sub-nano\nTesla or in Pico Tesla. Here we present a detailed noise study of the PHE\nsensors consisting of two or three intersecting ellipses. It can be used to\nmeasure two axes of the magnetic field in the sensor plane in particular along\nthe two perpendicular easy axes in the overlapping region for two intersecting\nellipses and three easy axes at an angle of 60 degrees for three crossing\nellipses. Thus, for each remanent magnetic state in the overlap area, the\nsensor can measure the vector component of the magnetic field perpendicular to\nthe direction of the remanent magnetization. The two field components are\nmeasured with a field resolution less than 200 pT/sqrt(Hz) at 10 Hz and 350\npT/sqrt(Hz) at 1 Hz in the same region, while maintaining a similar size and\nnoise level of a single-axis sensor. Furthermore, we discuss here the possible\nroute for future improvement of the field resolution","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T07:07:27Z"}
{"aid":"http://arxiv.org/abs/2504.06648v1","title":"Semiclassical concentration estimates for Berezin-Toeplitz quasimodes\n  for regular energies","summary":"The purpose of this article is to prove sharp $L^p$ bounds for quasimodes of\nBerezin-Toeplitz operators. We consider examples with explicit computations and\na general situation on compact spaces and $\\Cm^n$. In both cases the eigenvalue\nis a regular value of the operator symbol. We then use the link between\npseudodifferential and Berezin-Toeplitz operators to obtain an $L^p$ bound of\nthe FBI transform of quasimodes of pseudodifferential operators.","main_category":"math.CV","categories":"math.CV,math.SG,math.SP","published":"2025-04-09T07:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.06667v1","title":"Toward Holistic Evaluation of Recommender Systems Powered by Generative\n  Models","summary":"Recommender systems powered by generative models (Gen-RecSys) extend beyond\nclassical item ranking by producing open-ended content, which simultaneously\nunlocks richer user experiences and introduces new risks. On one hand, these\nsystems can enhance personalization and appeal through dynamic explanations and\nmulti-turn dialogues. On the other hand, they might venture into unknown\nterritory-hallucinating nonexistent items, amplifying bias, or leaking private\ninformation. Traditional accuracy metrics cannot fully capture these\nchallenges, as they fail to measure factual correctness, content safety, or\nalignment with user intent.\n  This paper makes two main contributions. First, we categorize the evaluation\nchallenges of Gen-RecSys into two groups: (i) existing concerns that are\nexacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new\nrisks (e.g., item hallucinations, contradictory explanations). Second, we\npropose a holistic evaluation approach that includes scenario-based assessments\nand multi-metric checks-incorporating relevance, factual grounding, bias\ndetection, and policy compliance. Our goal is to provide a guiding framework so\nresearchers and practitioners can thoroughly assess Gen-RecSys, ensuring\neffective personalization and responsible deployment.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T08:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.06668v1","title":"A Novel Nonlinear Fertility Catastrophe Model Based on Thom's\n  Differential Equations of Morphogenesis","summary":"A novel fertility model based on Thom's nonlinear differential equations of\nmorphogenesis is presented, utilizing a three-dimensional catastrophe surface\nto capture the interaction between latent non-catastrophic fertility factors\nand catastrophic shocks. The model incorporates key socioeconomic and\nenvironmental variables and is applicable at macro-, meso-, and\nmicro-demographic levels, addressing global fertility declines, regional\npopulation disparities, and micro-level phenomena such as teenage pregnancies.\nThis approach enables a comprehensive analysis of reproductive health at\naggregate, sub-national, and age-group-specific levels. An agent-based model\nfor teenage pregnancy is described to illustrate how latent factors -- such as\neducation, contraceptive use, and parental guidance -- interact with\ncatastrophic shocks like socioeconomic deprivation, violence, and substance\nabuse. The bifurcation set analysis shows how minor shifts in socioeconomic\nconditions can lead to significant changes in fertility rates, revealing\ncritical points in fertility transitions. By integrating Thom's morphogenesis\nequations with traditional fertility theory, this paper proposes a\ngroundbreaking approach to understanding fertility dynamics, offering valuable\ninsights for the development of public health policies that address both stable\nfertility patterns and abrupt demographic shifts.","main_category":"physics.soc-ph","categories":"physics.soc-ph,math.DS","published":"2025-04-09T08:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.06673v1","title":"Are Molecules Magical? Non-Stabilizerness in Molecular Bonding","summary":"Isolated atoms as well as molecules at equilibrium are presumed to be simple\nfrom the point of view of quantum computational complexity. Here we show that\nthe process of chemical bond formation is accompanied by a marked increase in\nthe quantum complexity of the electronic ground state. By studying the hydrogen\ndimer H$_{2}$ as a prototypical example, we demonstrate that when two hydrogen\natoms form a bond, a specific measure of quantum complexity exhibits a\npronounced peak that closely follows the behavior of the binding energy. This\nmeasure of quantum complexity, known as magic in the quantum information\nliterature, reflects how difficult it is to simulate the state using classical\nmethods. This observation suggests that regions of strong bonding formation or\nbreaking are also regions of enhanced intrinsic quantum complexity. This\ninsight suggests a connection of quantum information measures to chemical\nreactivity and advocates the use of stretched molecules as a quantum\ncomputational resource.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-04-09T08:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.06678v1","title":"Geometric Quantum Gates of Non-closed Paths Under Counterdiabatic\n  Driving","summary":"Non-adiabatic and non-closed evolutionary paths play a significant role in\nthe fidelity of quantum gates. We propose a high-fidelity quantum control\nframework based on the quasi-topological number ($\\nu_{\\text{qua}}$), which\nextends the traditional Chern number to characterize geometric responses in\nnon-closed paths. By introducing a counterdiabatic gauge potential (AGP) that\ndynamically suppresses non-adiabatic transitions and reconstructs path\ncurvature, we demonstrate that $\\nu_{\\text{qua}}$ -a relative homotopy\ninvariant of compact manifolds in parameter space-quantifies the robustness of\ngeometric phases during open-path quantum evolution. This integer invariant\nensures gauge-invariant suppression of decoherence errors arising from\ndynamical phase coupling. By introducing nonlinear parametric ring paths, we\naddress the defects caused by intermediate states in the Rydberg atomic system.\nNumerical simulations in the Kitaev superconducting chain and 2D\ntransverse-field Ising model confirm that our protocol achieves quantum gate\nfidelity exceeding $\\mathcal{F} > 0.9999$. We bridges geometric quantum control\nwith topological protection, offering a universal approach to noise-resistant\nquantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T08:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.06687v1","title":"Response to an external field of a generalized Langevin equation with\n  stochastic resetting of the memory kernel","summary":"We study a generalized Langevin equation (GLE) framework that incorporates\nstochastic resetting of a truncation power-law memory kernel. The inclusion of\nstochastic resetting enables the emergence of resonance phenomena even in\nparameter regimes where conventional settings (without resetting) do not\nexhibit such behavior. Specifically, we explore the response of the system to\nan external field under three scenarios: (i) a free particle, (ii) a particle\nin a harmonic potential, and (iii) the effect of truncation in the memory\nkernel. In each case, the primary focus is on understanding how the resetting\nmechanism interacts with standard parameters to induce stochastic resonance. In\naddition, we explore the effect of resetting on the dielectric loss.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-09T08:48:11Z"}
{"aid":"http://arxiv.org/abs/2504.06691v1","title":"Wake instability of a fixed spherical droplet with a high drop-to-fluid\n  viscosity ratio","summary":"Direct numerical simulations of a uniform flow past a fixed spherical droplet\nare performed to investigate the parameter range within which the axisymmetric\nflow becomes unstable due to an external flow bifurcation. The hydrodynamics is\ngoverned by three dimensionless numbers: the viscosity ratio, $\\mu^\\ast$, and\nthe external and internal Reynolds numbers, $\\Rey^e$ and $\\Rey^i$,\nrespectively. The drop-to-fluid density ratio is related to these parameters as\n$\\rho^\\ast=\\mu^\\ast \\Rey^i/\\Rey^e$. This study focuses on highly viscous\ndroplets with $\\mu^\\ast \\geq 5$, where wake instability is driven by the\nvorticity flux transferred from the droplet surface into the surrounding fluid.\nBy analysing the wake structure, we confirm that the onset of the external\nbifurcation is linked to the tilting of the azimuthal vorticity, $\\omega_\\phi$,\nin the wake and that the bifurcation occurs once the isocontours of\n$\\omega_\\phi$ align nearly perpendicular to the symmetry axis. We propose an\nempirical criterion for predicting the onset of the external bifurcation,\nformulated in terms of the maximum vorticity on the external side of the\ndroplet surface. This criterion is applicable for sufficiently high $\\Rey^i$\nand holds over a wide range of $\\mu^\\ast$ and $\\Rey^e$. Additionally, we\nexamine the bifurcation sequence for two specific external Reynolds numbers,\n$\\Rey^e=300$ and $\\Rey^e=500$, and show that, beyond a critical viscosity\nratio, the axisymmetric wake first transitions to a steady planar-symmetric\nstate before undergoing a secondary Hopf bifurcation. Finally, we highlight the\ninfluence of $\\Rey^i$ on external bifurcation and show that, at moderate\n$\\Rey^i$, wake instability may set in at a lower vorticity threshold than\npredicted by our criterion. These findings provide new insights into the\nexternal flow bifurcation of viscous droplets.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T08:53:06Z"}
{"aid":"http://arxiv.org/abs/2504.06697v1","title":"\"Sorry for bugging you so much.\" Exploring Developers' Behavior Towards\n  Privacy-Compliant Implementation","summary":"While protecting user data is essential, software developers often fail to\nfulfill privacy requirements. However, the reasons why they struggle with\nprivacy-compliant implementation remain unclear. Is it due to a lack of\nknowledge, or is it because of insufficient support? To provide foundational\ninsights in this field, we conducted a qualitative 5-hour programming study\nwith 30 professional software developers implementing 3 privacy-sensitive\nprogramming tasks that were designed with GDPR compliance in mind. To explore\nif and how developers implement privacy requirements, participants were divided\ninto 3 groups: control, privacy prompted, and privacy expert-supported. After\ntask completion, we conducted follow-up interviews. Alarmingly, almost all\nparticipants submitted non-GDPR-compliant solutions (79/90). In particular,\nnone of the 3 tasks were solved privacy-compliant by all 30 participants, with\nthe non-prompted group having the lowest number of 3 out of 30\nprivacy-compliant solution attempts. Privacy prompting and expert support only\nslightly improved participants' submissions, with 6/30 and 8/30\nprivacy-compliant attempts, respectively. In fact, all participants reported\nsevere issues addressing common privacy requirements such as purpose\nlimitation, user consent, or data minimization. Counterintuitively, although\nmost developers exhibited minimal confidence in their solutions, they rarely\nsought online assistance or contacted the privacy expert, with only 4 out of 10\nexpert-supported participants explicitly asking for compliance confirmation.\nInstead, participants often relied on existing implementations and focused on\nimplementing functionality and security first.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T08:59:17Z"}
{"aid":"http://arxiv.org/abs/2504.06699v1","title":"Benchmarking Convolutional Neural Network and Graph Neural Network based\n  Surrogate Models on a Real-World Car External Aerodynamics Dataset","summary":"Aerodynamic optimization is crucial for developing eco-friendly, aerodynamic,\nand stylish cars, which requires close collaboration between aerodynamicists\nand stylists, a collaboration impaired by the time-consuming nature of\naerodynamic simulations. Surrogate models offer a viable solution to reduce\nthis overhead, but they are untested in real-world aerodynamic datasets. We\npresent a comparative evaluation of two surrogate modeling approaches for\npredicting drag on a real-world dataset: a Convolutional Neural Network (CNN)\nmodel that uses a signed distance field as input and a commercial tool based on\nGraph Neural Networks (GNN) that directly processes a surface mesh. In contrast\nto previous studies based on datasets created from parameterized geometries,\nour dataset comprises 343 geometries derived from 32 baseline vehicle\ngeometries across five distinct car projects, reflecting the diverse, free-form\nmodifications encountered in the typical vehicle development process. Our\nresults show that the CNN-based method achieves a mean absolute error of 2.3\ndrag counts, while the GNN-based method achieves 3.8. Both methods achieve\napproximately 77% accuracy in predicting the direction of drag change relative\nto the baseline geometry. While both methods effectively capture the broader\ntrends between baseline groups (set of samples derived from a single baseline\ngeometry), they struggle to varying extents in capturing the finer\nintra-baseline group variations. In summary, our findings suggest that\naerodynamicists can effectively use both methods to predict drag in under two\nminutes, which is at least 600 times faster than performing a simulation.\nHowever, there remains room for improvement in capturing the finer details of\nthe geometry.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:04:59Z"}
{"aid":"http://arxiv.org/abs/2504.06713v1","title":"Almost everywhere convergence of the convolution type Laguerre\n  expansions","summary":"For a fixed d-tuple $\\alpha=(\\alpha_1,...,\\alpha_d)\\in(-1,\\infty)^d$,\nconsider the product space $\\mathbb{R}_+^d:=(0,\\infty)^d$ equipped with\nEuclidean distance $\\arrowvert \\cdot \\arrowvert$ and the measure\n$d\\mu_{\\alpha}(x)=x_1^{2\\alpha_1+1}\\cdot\\cdot\\cdot\nx_{d}^{\\alpha_d}dx_1\\cdot\\cdot\\cdot dx_d$. We consider the Laguerre operator\n$L_{\\alpha}=-\\Delta+\\sum_{i=1}^{d}\\frac{2\\alpha_j+1}{x_j}\\frac{d}{dx_j}+\\arrowvert\nx\\arrowvert^2$ which is a compact, positive, self-adjoint operator on\n$L^2(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$. In this paper, we study almost\neverywhere convergence of the Bochner-Riesz means associated with $L_\\alpha$\nwhich is defined by\n$S_R^{\\lambda}(L_\\alpha)f(x)=\\sum_{n=0}^{\\infty}(1-\\frac{e_n}{R^2})_{+}^{\\lambda}P_nf(x)$.\nHere $e_n$ is n-th eigenvalue of $L_{\\alpha}$, and $P_nf(x)$ is the n-th\nLaguerre spectral projection operator. This corresponds to the convolution-type\nLaguerre expansions introduced in Thangavelu's lecture \\cite{TS3}. For $2\\leq\np<\\infty$, we prove that $$\\lim_{R\\rightarrow\\infty}\nS_R^{\\lambda}(L_\\alpha)f=f\\,\\,\\,\\,-a.e.$$ for all $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$, provided that\n$\\lambda>\\lambda(\\alpha,p)/2$, where\n$\\lambda(\\alpha,p)=\\max\\{2(\\arrowvert\\alpha\\arrowvert_1+d)(1/2-1/p)-1/2,0\\}$,\nand $\\arrowvert\\alpha\\arrowvert_1:=\\sum_{j=1}^{d}\\alpha_{j}$. Conversely, if\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d>1$, we will show the convergence generally\nfails if $\\lambda<\\lambda(\\alpha,p)/2$ in the sense that there is an $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ for\n$(4\\arrowvert\\alpha\\arrowvert_{1}+4d)/(2\\arrowvert\\alpha\\arrowvert_{1}+2d-1)<\np$ such that the convergence fails. When\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d\\leq1$, our results show that a.e.\nconvergence holds for $f\\in L^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ with $p\\geq\n2$ whenever $\\lambda>0$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T09:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.06726v1","title":"On the Vinogradov bound by the Diophantine type","summary":"In this article, we give an asymptotic bound for the exponential sum of the\nM\\\"obius function $\\sum_{n \\le x} \\mu(n) e(\\alpha n)$ for a fixed irrational\nnumber $\\alpha\\in\\mathbb{R}$. This exponential sum was originally studied by\nDavenport and he obtained an asymptotic bound of $x(\\log x)^{-A}$ for any\n$A\\ge0$. Our bound depends on the irrationality exponent $\\eta$ of $\\alpha$. If\n$\\eta \\le 5/2$, we obtain a bound of $x^{4/5 + \\varepsilon}$ and, when $\\eta\n\\ge 5/2$, then our bound becomes $x^{(2\\eta-1)/2\\eta + \\varepsilon}$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T09:31:12Z"}
{"aid":"http://arxiv.org/abs/2504.06736v1","title":"On a weighted version of the BBM formula","summary":"We prove a weighted version of the Bourgain-Brezis-Mironescu (BBM) formula,\nboth in the pointwise and $\\Gamma$-convergence sense, together with a\ncompactness criterion for energy-bounded sequences. The non-negative weights\nneed only be $L^\\infty$ convergent to a bounded and uniformly continuous limit.\nWe apply the BBM formula to show a Poincar\\'e-type inequality and the stability\nof the first eigenvalues relative to the energies. Finally, we discuss a\nnon-local analogue of the weighted BBM formula.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-09T09:48:20Z"}
{"aid":"http://arxiv.org/abs/2504.06743v1","title":"Kinematic formulas in convex geometry for non-compact groups","summary":"We generalize classical kinematic formulas for convex bodies in a real vector\nspace $V$ to the setting of non-compact Lie groups admitting a Cartan\ndecomposition. Specifically, let $G$ be a closed linear group with Cartan\ndecomposition $G \\cong K \\times \\exp(\\mathfrak{p}_0)$, where $K$ is a maximal\ncompact subgroup acting transitively on the unit sphere. For $K$-invariant\ncontinuous valuations on convex bodies, we establish an integral geometric-type\nformula for $\\overline{G} = G \\ltimes V$. Key to our approach is the\nintroduction of a Gaussian measure on $\\mathfrak{p}_0$, which ensures\nconvergence of the non-compact part of the integral. In the special case $K =\nO(n)$, we recover a Hadwiger-type formula involving intrinsic volumes, with\nexplicit constants $c_j$ computed via a Weyl integration formula.","main_category":"math.MG","categories":"math.MG","published":"2025-04-09T09:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.06747v1","title":"An introduction to memory competitions, records and techniques","summary":"This article provides an overview of memory competitions, analyzes\ndifferences between disciplines and explains current state-of-the-art\ntechniques. Performances have increased dramatically over the past three\ndecades. Nowadays, information processing reaches up to 42 bit/s in short\ndisciplines with most of the time spent on reading, suggesting that mental\nassociations are formed even faster. Records show a remarkable concordance\nacross all time scales: the processing speed depends on memorization time as a\npower law.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-09T10:07:46Z"}
{"aid":"http://arxiv.org/abs/2504.06759v1","title":"Rhombohedral graphite junctions as a platform for continuous tuning\n  between topologically trivial and non-trivial electronic phases","summary":"Manipulating the topological properties of quantum states can provide a way\nto protect them against disorder. However, typically, changing the topology of\nelectronic states in a crystalline material is challenging because their nature\nis underpinned by chemical composition and lattice symmetry that are difficult\nto modify. We propose junctions between rhombohedral graphite crystals as a\nplatform that enables smooth transition between topologically trivial and\nnon-trivial regimes distinguished by the absence or presence of topological\njunction states. By invoking an analogy with the Su-Schrieffer-Heeger model,\nthe appearance of topological states is related to the symmetry of the atomic\nstacking at the interface between the crystals. The possibility to explore both\nthe topological and non-topological phases is provided by sliding the crystals\nwith respect to each other.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-04-09T10:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.06769v1","title":"Evolutionary dynamics of continuous public goods games in structured\n  populations","summary":"Over the past few decades, many works have studied the evolutionary dynamics\nof continuous games. However, previous works have primarily focused on\ntwo-player games with pairwise interactions. Indeed, group interactions rather\nthan pairwise interactions are usually found in real situations. The public\ngoods game serves as a paradigm of multi-player interactions. Notably, various\ntypes of benefit functions are typically considered in public goods games,\nincluding linear, saturating, and sigmoid functions. Thus far, the evolutionary\ndynamics of cooperation in continuous public goods games with these benefit\nfunctions remain unknown in structured populations. In this paper, we consider\nthe continuous public goods game in structured populations. By employing the\npair approximation approach, we derive the analytical expressions for invasion\nfitness. Furthermore, we explore the adaptive dynamics of cooperative\ninvestments in the game with various benefit functions. First, for the linear\npublic goods game, we find that there is no singular strategy, and the\ncooperative investments evolve to either the maximum or minimum depending on\nthe benefit-to-cost ratio. Subsequently, we examine the game with saturating\nbenefit functions and demonstrate the potential existence of an evolutionarily\nstable strategy (ESS). Additionally, for the game with the sigmoid benefit\nfunction, we observe that the evolutionary outcomes are closely related to the\nthreshold value. When the threshold is small, a unique ESS emerges. For\nintermediate threshold values, both the ESS and repellor singular strategies\ncan coexist. When the threshold value is large, a unique repellor displays.\nFinally, we perform individual-based simulations to validate our theoretical\nresults.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-09T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.06775v1","title":"Variational Quantum Machine Learning with Quantum Error Detection","summary":"Quantum machine learning (QML) is an emerging field that promises advantages\nsuch as faster training, improved reliability and superior feature extraction\nover classical counterparts. However, its implementation on quantum hardware is\nchallenging due to the noise inherent in these systems, necessitating the use\nof quantum error correction (QEC) codes. Current QML research remains primarily\ntheoretical, often assuming noise-free environments and offering little insight\ninto the integration of QEC with QML implementations. To address this, we\ninvestigate the performance of a simple, parity-classifying Variational Quantum\nClassifier (VQC) implemented with the [[4,2,2]] error-detecting stabiliser code\nin a simulated noisy environment, marking the first study into the\nimplementation of a QML algorithm with a QEC code. We invoke ancilla qubits to\nlogically encode rotation gates, and classically simulate the logically-encoded\nVQC under two simple noise models representing gate noise and environmental\nnoise. We demonstrate that the stabiliser code improves the training accuracy\nat convergence compared to noisy implementations without QEC. However, we find\nthat the effectiveness and reliability of error detection is contingent upon\nkeeping the ancilla qubit error rates below a specific threshold, due to the\npropagation of ancilla errors to the physical qubits. Our results provide an\nimportant insight: for QML implementations with QEC codes that both require\nancilla qubits for logical rotations and cannot fully correct errors propagated\nbetween ancilla and physical qubits, the maximum achievable accuracy of the QML\nmodel is limited. This highlights the need for additional error correction or\nmitigation strategies to support the practical implementation of QML algorithms\nwith QEC on quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T10:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.06782v1","title":"Probabilistic Grading and Classification System for End-of-Life Building\n  Components Toward Circular Economy Loop","summary":"The longevity and viability of construction components in a circular economy\ndemand a robust, data-informed framework for reuse decision-making. This paper\nintroduces a multi-level grading and classification system that combines\nBayesian probabilistic modeling with scenario-based performance thresholds to\nassess the reusability of end-of-life modular components. By grading components\nacross a five-tier scale, the system supports strategic decisions for reuse,\nup-use, or down-use, ensuring alignment with engineering standards and\nsustainability objectives. The model's development is grounded in empirical\ndata from precast concrete wall panels, and its explainability is enhanced\nthrough decision tree logic and Sankey visualizations that trace the influence\nof contextual scenarios on classification outcomes. MGCS addresses the\nenvironmental, economic, and operational challenges of EoL management--reducing\nmaterial waste, optimizing value recovery, and improving workflow efficiency.\nThrough dynamic feature weighting and transparent reasoning, the system offers\na practical yet rigorous pathway to embed circular thinking into construction\nindustry practices.","main_category":"econ.GN","categories":"econ.GN,cs.NA,math.NA,q-fin.EC","published":"2025-04-09T11:14:02Z"}
{"aid":"http://arxiv.org/abs/2504.06784v1","title":"Modified gravity realizations of quintom dark energy after DESI DR2","summary":"We investigate the realization of quintom scenario for dynamical dark energy\nwithin modified gravity theories that can efficiently fit the recent\nobservational datasets. Starting from a general effective field theory\nformulation of dark energy in metric-affine geometry, we derive the background\naction in unitary gauge and we demonstrate how both $f(T)$ and $f(Q)$ gravity\ncan naturally realize quintom behavior through appropriate forms and parameter\nchoices. Additionally, using the Gaussian process reconstruction of the latest\nDESI DR2 BAO data combined with SNe and CMB observations, we extract the\nreconstructed dark-energy equation-of-state parameter, showing that it exhibits\nquintom-type evolution, crossing the phantom divide from below. Moreover,\nthrough detailed parameter estimations and application of information criteria,\nwe compare the model with the quadratic one. Our results show that, due to its\nrich structure, modified gravity stands as one of the main candidates for the\nrealization of the data-favoured dynamical dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T11:17:20Z"}
{"aid":"http://arxiv.org/abs/2504.06787v1","title":"Communicating complex statistical models to a public health audience:\n  translating science into action with the FARSI approach","summary":"Background. Effectively communicating complex statistical model outputs is a\nmajor challenge in public health. This study introduces the FARSI approach\n(Fast, Accessible, Reliable, Secure, Informative) as a framework to enhance the\ntranslation of intricate statistical findings into actionable insights for\npolicymakers and stakeholders. We apply this framework in a real-world case\nstudy on chronic disease monitoring in Italy.\n  Methods. The FARSI framework outlines key principles for developing\nuser-friendly tools that improve the translation of statistical results. We\napplied these principles to create an open-access web application using R\nShiny, designed to communicate chronic disease prevalence estimates from a\nBayesian spatio-temporal logistic model. The case study highlights the\nimportance of an intuitive design for fast accessibility, validated data and\nexpert feedback for reliability, aggregated data for security, and insights\ninto prevalence population subgroups, which were previously unobservable, for\ninformativeness.\n  Results. The web application enables stakeholders to explore disease\nprevalence across populations and geographical area through dynamic\nvisualizations. It facilitates public health monitoring by, for instance,\nidentifying disparities at the local level and assessing risk factors such as\nsmoking. Its user-friendly interface enhances accessibility, making statistical\nfindings more actionable. Conclusions. The FARSI framework provides a\nstructured approach to improving the communication of complex research\nfindings. By making statistical models more accessible and interpretable, it\nsupports evidence-based decision-making in public health and increases the\nsocietal impact of research.","main_category":"stat.OT","categories":"stat.OT,stat.AP,stat.ME","published":"2025-04-09T11:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.06794v1","title":"A new model for all $C$-sequences are trivial","summary":"We construct a model in which all $C$-sequences are trivial, yet there exists\na $\\kappa$-Souslin tree with full vanishing levels. This answers a question of\nLambie-Hanson and Rinot, and provides an optimal combination of compactness and\nincompactness. It is obtained by incorporating a so-called mutually exclusive\nascent path to Kunen's original forcing construction.","main_category":"math.LO","categories":"math.LO","published":"2025-04-09T11:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06800v1","title":"A Meaningful Perturbation Metric for Evaluating Explainability Methods","summary":"Deep neural networks (DNNs) have demonstrated remarkable success, yet their\nwide adoption is often hindered by their opaque decision-making. To address\nthis, attribution methods have been proposed to assign relevance values to each\npart of the input. However, different methods often produce entirely different\nrelevance maps, necessitating the development of standardized metrics to\nevaluate them. Typically, such evaluation is performed through perturbation,\nwherein high- or low-relevance regions of the input image are manipulated to\nexamine the change in prediction. In this work, we introduce a novel approach,\nwhich harnesses image generation models to perform targeted perturbation.\nSpecifically, we focus on inpainting only the high-relevance pixels of an input\nimage to modify the model's predictions while preserving image fidelity. This\nis in contrast to existing approaches, which often produce out-of-distribution\nmodifications, leading to unreliable results. Through extensive experiments, we\ndemonstrate the effectiveness of our approach in generating meaningful rankings\nacross a wide range of models and attribution methods. Crucially, we establish\nthat the ranking produced by our metric exhibits significantly higher\ncorrelation with human preferences compared to existing approaches,\nunderscoring its potential for enhancing interpretability in DNNs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.06822v1","title":"Investigation of triply heavy spin-3/2 baryons in their ground and\n  excited states","summary":"We calculate the masses and residues of triply heavy baryons with spin-3/2,\nincluding $\\Omega^*_{ccc}$, $\\Omega^*_{ccb}$, $\\Omega^*_{bbc}$ and\n$\\Omega^*_{bbb}$, using the QCD sum rules method. Our calculations primarily\nfocus on obtaining the masses of the first three resonances, that is, the\nground state (1S), the first orbital excited state (1P), and the first radial\nexcited state (2S), for the mentioned baryons. We additionally determine the\nresidues of these baryons, which serve as key parameters for studying their\npossible decay channels and interactions with other particles. To achieve\nhigher accuracy compared to previous studies, we consider nonperturbative\noperators up to eight mass dimensions. We present our calculated outcomes in\ntwo distinct energy schemes, referred to as pole and $\\mathrm{\\overline{MS}}$.\nGiven the absence of experimental data for these states, we compare our results\nwith previous theoretical calculations that are reported in relevant studies\nemploying various approaches. These results may provide valuable insights for\nexperimental groups searching for the triply heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat","published":"2025-04-09T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.06832v1","title":"On a Characterization of Spartan Graphs","summary":"The eternal vertex cover game is played between an attacker and a defender on\nan undirected graph $G$. The defender identifies $k$ vertices to position\nguards on to begin with. The attacker, on their turn, attacks an edge $e$, and\nthe defender must move a guard along $e$ to defend the attack. The defender may\nmove other guards as well, under the constraint that every guard moves at most\nonce and to a neighboring vertex. The smallest number of guards required to\ndefend attacks forever is called the eternal vertex cover number of $G$,\ndenoted $evc(G)$.\n  For any graph $G$, $evc(G)$ is at least the vertex cover number of $G$,\ndenoted $mvc(G)$. A graph is Spartan if $evc(G) = mvc(G)$. It is known that a\nbipartite graph is Spartan if and only if every edge belongs to a perfect\nmatching. We show that the only K\\\"onig graphs that are Spartan are the\nbipartite Spartan graphs. We also give new lower bounds for $evc(G)$,\ngeneralizing a known lower bound based on cut vertices. We finally show a new\nmatching-based characterization of all Spartan graphs.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-04-09T12:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.06840v1","title":"Interference Mitigation and Spectral Efficiency Enhancement in a\n  Multi-BD Symbiotic Radio","summary":"This study presents a framework designed to mitigate direct-link interference\n(DLI) and inter-backscatter device interference (IBDI) in multi-backscatter\northogonal frequency division multiplexing (OFDM)-based symbiotic radio (SR)\nsystems. The framework employs OFDM signal designs with strategic allocation of\nnull subcarriers and incorporates two backscatter modulation techniques: on-off\nfrequency shift keying (OFSK) and multiple frequency shift keying (MFSK) for\nsymbiotic backscatter communication (SBC). Additionally, we propose\nFully-Orthogonal and Semi-Orthogonal multiple access schemes to facilitate SBC\nalongside primary communication. The Fully-Orthogonal scheme maintains\northogonality between direct link and SBC signals, thereby ensuring\ninterference-free SBC, albeit at a reduced spectral efficiency. In contrast,\nthe Semi-Orthogonal schemes eliminate IBDI but permit partial DLI, striking a\nbalance between reliability and spectral efficiency. To address the partial DLI\ninherent in Semi-Orthogonal schemes, successive interference cancellation (SIC)\nis employed at the receiver, enhancing SBC reliability. To tackle channel\nestimation challenges in SBC within the SR system, we implement non-coherent\ndetection techniques at the receiver. The performance of the proposed system is\nevaluated based on average bit error rate (BER) and sum-rate metrics,\ndemonstrating the effectiveness of our schemes. We provide analytical results\nfor the system's detection performance under both proposed modulation\ntechniques and multiple access schemes, which are subsequently validated\nthrough extensive simulations. These simulations indicate a notable error-rate\nreduction of up to $10^{-3}$ at $20$ dB with the Fully-Orthogonal scheme with\nMFSK.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T12:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.06851v1","title":"Mixing trichotomy for random walks on directed stochastic block models","summary":"We consider a directed version of the classical Stochastic Block Model with\n$m\\ge 2$ communities and a parameter $\\alpha$ controlling the inter-community\nconnectivity. We show that, depending on the scaling of $\\alpha$, the mixing\ntime of the random walk on this graph can exhibit three different behaviors,\nwhich we refer to as subcritical, critical and supercritical. In the\nsubcritical regime, the total variation distance to equilibrium decays\nabruptly, providing the occurrence of the so-called cutoff phenomenon. In the\nsupercritical regime, the mixing is governed by the inter-community jumps, and\nthe random walk exhibits a metastable behavior: at first it collapses to a\nlocal equilibrium, then, on a larger timescale, it can be effectively described\nas a mean-field process on the $m$ communities, with a decay to equilibrium\nwhich is asymptotically smooth and exponential. Finally, for the critical\nregime, we show a sort of interpolation of the two above-mentioned behaviors.\nAlthough the metastable behavior shown in the supercritical regime appears\nnatural from a heuristic standpoint, a substantial part of our analysis can be\nread as a control on the homogenization of the underlying random environment.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T13:05:55Z"}
{"aid":"http://arxiv.org/abs/2504.06886v1","title":"High-order fluctuations of temperature in hot QCD matter","summary":"We study the temperature fluctuations in hot quantum chromodynamics (QCD)\nmatter. A new thermodynamic state function is introduced to describe the mean\ntransverse momentum fluctuations of charged particles in heavy-ion collisions,\nenabling analytic expressions for the temperature fluctuations of different\norders. This formalism is applied to the QCD thermodynamics described by a 2+1\nflavor low energy effective field theory within the functional renormalization\ngroup approach. It is found that the temperature fluctuations are suppressed\nremarkably as the matter is evolved from the phase of hadron resonance gas to\nthe quark-gluon plasma phase with increasing temperature or baryon chemical\npotential, which is attributed to the significant increase of the heat capacity\nof matter. Furthermore, the same mechanism leads to a negative skewness in the\ntemperature fluctuations.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-09T13:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.06891v1","title":"Helioseismic inference of the solar radiative opacity","summary":"The Sun is the most studied of all stars, and thus constitutes a benchmark\nfor stellar models. However, our vision of the Sun is still incomplete, as\nillustrated by the current debate on its chemical composition. The problem\nreaches far beyond chemical abundances and is intimately linked to microscopic\nand macroscopic physical ingredients of solar models such as radiative opacity,\nfor which experimental results have been recently measured that still await\ntheoretical explanations. We present opacity profiles derived from helioseismic\ninferences and compare them with detailed theoretical computations of\nindividual element contributions using three different opacity computation\ncodes, in a complementary way to experimental results. We find that our seismic\nopacity is about 10% higher than theoretical values used in current solar\nmodels around 2 million degrees, but lower by 35% than some recent available\ntheoretical values. Using the Sun as a laboratory of fundamental physics, we\nshow that quantitative comparisons between various opacity tables are required\nto understand the origin of the discrepancies between reported helioseismic,\ntheoretical and experimental opacity values.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-09T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.06908v1","title":"UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image\n  Segmentation","summary":"In medical imaging, the primary challenge is collecting large-scale labeled\ndata due to privacy concerns, logistics, and high labeling costs. In this work,\nwe present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset\nof body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D\nimages) and more than 1.37 billion 2D segmentation masks of 72 organs, all\nbased on the UK Biobank MRI dataset. We utilize automatic labeling, introduce\nan automated label cleaning pipeline with organ-specific filters, and manually\nannotate a subset of 300 MRIs with 11 abdominal classes to validate the quality\n(referred to as UKBOB-manual). This approach allows for scaling up the dataset\ncollection while maintaining confidence in the labels. We further confirm the\nvalidity of the labels by demonstrating zero-shot generalization of trained\nmodels on the filtered UKBOB to other small labeled datasets from similar\ndomains (e.g., abdominal MRI). To further mitigate the effect of noisy labels,\nwe propose a novel method called Entropy Test-time Adaptation (ETTA) to refine\nthe segmentation output. We use UKBOB to train a foundation model, Swin-BOB,\nfor 3D medical image segmentation based on the Swin-UNetr architecture,\nachieving state-of-the-art results in several benchmarks in 3D medical imaging,\nincluding the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the\nBTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained\nmodels and the code are available at https://emmanuelleb985.github.io/ukbob ,\nand the filtered labels will be made available with the UK Biobank.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T14:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.06920v1","title":"S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in\n  Remote Sensing Applications","summary":"We introduce the S-EO dataset: a large-scale, high-resolution dataset,\ndesigned to advance geometry-aware shadow detection. Collected from diverse\npublic-domain sources, including challenge datasets and government providers\nsuch as USGS, our dataset comprises 702 georeferenced tiles across the USA,\neach covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3\npansharpened RGB images, panchromatic images, and a ground-truth DSM of the\narea obtained from LiDAR scans. For each image, we provide a shadow mask\nderived from geometry and sun position, a vegetation mask based on the NDVI\nindex, and a bundle-adjusted RPC model. With approximately 20,000 images, the\nS-EO dataset establishes a new public resource for shadow detection in remote\nsensing imagery and its applications to 3D reconstruction. To demonstrate the\ndataset's impact, we train and evaluate a shadow detector, showcasing its\nability to generalize, even to aerial images. Finally, we extend EO-NeRF - a\nstate-of-the-art NeRF approach for satellite imagery - to leverage our shadow\npredictions for improved 3D reconstructions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:25:35Z"}
{"aid":"http://arxiv.org/abs/2504.06924v1","title":"Longitudinal Assessment of Lung Lesion Burden in CT","summary":"In the U.S., lung cancer is the second major cause of death. Early detection\nof suspicious lung nodules is crucial for patient treatment planning,\nmanagement, and improving outcomes. Many approaches for lung nodule\nsegmentation and volumetric analysis have been proposed, but few have looked at\nlongitudinal changes in total lung tumor burden. In this work, we trained two\n3D models (nnUNet) with and without anatomical priors to automatically segment\nlung lesions and quantified total lesion burden for each patient. The 3D model\nwithout priors significantly outperformed ($p < .001$) the model trained with\nanatomy priors. For detecting clinically significant lesions $>$ 1cm, a\nprecision of 71.3\\%, sensitivity of 68.4\\%, and F1-score of 69.8\\% was\nachieved. For segmentation, a Dice score of 77.1 $\\pm$ 20.3 and Hausdorff\ndistance error of 11.7 $\\pm$ 24.1 mm was obtained. The median lesion burden was\n6.4 cc (IQR: 2.1, 18.1) and the median volume difference between manual and\nautomated measurements was 0.02 cc (IQR: -2.8, 1.2). Agreements were also\nevaluated with linear regression and Bland-Altman plots. The proposed approach\ncan produce a personalized evaluation of the total tumor burden for a patient\nand facilitate interval change tracking over time.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:30:43Z"}
{"aid":"http://arxiv.org/abs/2504.07001v1","title":"Leveraging GCN-based Action Recognition for Teleoperation in Daily\n  Activity Assistance","summary":"Caregiving of older adults is an urgent global challenge, with many older\nadults preferring to age in place rather than enter residential care. However,\nproviding adequate home-based assistance remains difficult, particularly in\ngeographically vast regions. Teleoperated robots offer a promising solution,\nbut conventional motion-mapping teleoperation imposes unnatural movement\nconstraints on operators, leading to muscle fatigue and reduced usability. This\npaper presents a novel teleoperation framework that leverages action\nrecognition to enable intuitive remote robot control. Using our simplified\nSpatio-Temporal Graph Convolutional Network (S-ST-GCN), the system recognizes\nhuman actions and executes corresponding preset robot trajectories, eliminating\nthe need for direct motion synchronization. A finite-state machine (FSM) is\nintegrated to enhance reliability by filtering out misclassified actions. Our\nexperiments demonstrate that the proposed framework enables effortless operator\nmovement while ensuring accurate robot execution. This proof-of-concept study\nhighlights the potential of teleoperation with action recognition for enabling\ncaregivers to remotely assist older adults during activities of daily living\n(ADLs). Future work will focus on improving the S-ST-GCN's recognition accuracy\nand generalization, integrating advanced motion planning techniques to further\nenhance robotic autonomy in older adult care, and conducting a user study to\nevaluate the system's telepresence and ease of control.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07006v1","title":"Quasipolynomial bounds for the corners theorem","summary":"Let $G$ be a finite abelian group and $A$ be a subset of $G \\times G$ which\nis corner-free, meaning that there are no $x, y \\in G$ and $d \\in G \\setminus\n\\{0\\}$ such that $(x, y)$, $(x+d, y)$, $(x, y+d) \\in A$. We prove that \\[|A|\n\\le |G|^2 \\cdot \\exp(-(\\log |G|)^{\\Omega(1)}).\\] As a consequence, we obtain\npolynomial (in the input length) lower bounds on the non-deterministic\ncommunication complexity of Exactly-N in the 3-player Number-on-Forehead model.\nWe also obtain the first \"reasonable'' lower bounds on the coloring version of\nthe $3$-dimensional corners problem and equivalently the deterministic\ncommunication complexity of Exactly-N in the 4-player Number-on-Forehead model.","main_category":"math.CO","categories":"math.CO,cs.CC,math.NT","published":"2025-04-09T16:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.07012v1","title":"Assessing dominance in survival functions: A test for right-censored\n  data","summary":"This paper proposes a new statistical test to assess the dominance of\nsurvival functions in the presence of right-censored data. Traditional methods,\nsuch as the log-rank test, are inadequate for determining whether one survival\nfunction consistently dominates another, especially when survival curves cross.\nThe proposed test is based on the supremum of the difference between\nKaplan-Meier estimators and allows for distinguishing between dominance and\ncrossing survival curves. The paper presents the test's asymptotic properties,\nalong with simulations and applications to real datasets. The results\ndemonstrate that the test has high sensitivity for detecting crossings and\ndominance compared to conventional methods.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-09T16:30:39Z"}
{"aid":"http://arxiv.org/abs/2504.07013v1","title":"Thin Coalgebraic Behaviours Are Inductive","summary":"Coalgebras for analytic functors uniformly model graph-like systems where the\nsuccessors of a state may admit certain symmetries. Examples of successor\nstructure include ordered tuples, cyclic lists and multisets. Motivated by\ngoals in automata-based verification and results on thin trees, we introduce\nthin coalgebras as those coalgebras with only countably many infinite paths\nfrom each state. Our main result is an inductive characterisation of thinness\nvia an initial algebra. To this end, we develop a syntax for thin behaviours\nand capture with a single equation when two terms represent the same thin\nbehaviour. Finally, for the special case of polynomial functors, we retrieve\nfrom our syntax the notion of Cantor-Bendixson rank of a thin tree.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07024v1","title":"Data Augmentation and Hyperparameter Tuning for Low-Resource MFA","summary":"A continued issue for those working with computational tools and endangered\nand under-resourced languages is the lower accuracy of results for languages\nwith smaller amounts of data. We attempt to ameliorate this issue by using data\naugmentation methods to increase corpus size, comparing augmentation to\nhyperparameter tuning for multilingual forced alignment. Unlike text\naugmentation methods, audio augmentation does not lead to substantially\nincreased performance. Hyperparameter tuning, on the other hand, results in\nsubstantial improvement without (for this amount of data) infeasible additional\ntraining time. For languages with small to medium amounts of training data,\nthis is a workable alternative to adapting models from high-resource languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07034v1","title":"Low Regularity of Self-Similar Solutions of Two-Dimensional Riemann\n  problems with Shocks for the Isentropic Euler system","summary":"We are concerned with the low regularity of self-similar solutions of\ntwo-dimensional Riemann problems for the isentropic Euler system. We establish\na general framework for the analysis of the local regularity of such solutions\nfor a class of two-dimensional Riemann problems for the isentropic Euler\nsystem, which includes the regular shock reflection problem, the Prandtl\nreflection problem, the Lighthill diffraction problem, and the four-shock\nRiemann problem. We prove that it is not possible that both the density and the\nvelocity are in $H^1$ in the subsonic domain for the self-similar solutions of\nthese problems in general. This indicates that the self-similar solutions of\nthe Riemann problems with shocks for the isentropic Euler system are of much\nmore complicated structure than those for the Euler system for potential flow;\nin particular, the density and the velocity are not necessarily continuous in\nthe subsonic domain. The proof is based on a regularization of the isentropic\nEuler system to derive the transport equation for the vorticity, a\nrenormalization argument extended to the case of domains with boundary, and\nDiPerna-Lions-type commutator estimates.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,nlin.PS,physics.flu-dyn","published":"2025-04-09T16:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.07037v1","title":"VQE calculations on a NISQ era trapped ion quantum computer using a\n  multireference unitary coupled cluster ansatz: application to the BeH$_2$\n  insertion problem","summary":"In this study, we employ the variational quantum eigensolver algorithm with a\nmultireference unitary coupled cluster ansatz to report the ground state energy\nof the BeH$_2$ molecule in a geometry where strong correlation effects are\nsignificant. We consider the two most important determinants in the\nconstruction of the reference state for our ansatz. Furthermore, in order to\ncarry out our intended 12-qubit computation on a noisy intermediate scale\nquantum era trapped ion hardware (the commercially available IonQ Forte-I), we\nperform a series of resource reduction techniques to a. decrease the number of\ntwo-qubit gates by 99.84% (from 12515 to 20 two-qubit gates) relative to the\nunoptimized circuit, and b. reduce the number of measurements via the idea of\nsupercliques, while losing 2.69% in the obtained ground state energy (with\nerror mitigation and post-selection) relative to that computed classically for\nthe same resource-optimized problem setting.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atom-ph,quant-ph","published":"2025-04-09T16:52:37Z"}
{"aid":"http://arxiv.org/abs/2504.07056v1","title":"The Lyman-alpha and Continuum Origins Survey I: Survey description and\n  Ly$$ imaging","summary":"Understanding the mechanisms driving the escape of ionizing or Lyman\ncontinuum (LyC) emission from the interstellar medium of galaxies is necessary\nto constrain the evolution of Reionization, and the sources responsible for it.\nWhile progress has been made into identifying the global galaxy properties\nlinked to the escape fraction of ionizing radiation, f$_{esc}^{LyC}$, little is\ncurrently known about how spatially resolved galaxy properties impact this\nparameter. We present Hubble Space Telescope (HST) imaging data obtained as\npart of the Lyman $\\alpha$ and Continuum Origins Survey (LaCOS). LaCOS consists\nof HST imaging in 5 filters covering rest-frame optical and UV bands for a\nsubsample of 42 galaxies in the Low redshift Lyman Continuum Survey, 22 being\nLyman continuum emitters ($f_{esc}^{LyC}=0.01-0.49$). These data allow for\ninvestigations of the connection between sub-kpc stellar and nebular\nproperties, including Ly$\\alpha$ emission, and $f_{esc}^{LyC}$. Here, we\ndescribe the sample selection, observations and data reduction methods.\nAdditionally, we present results on the link between global and resolved\nLy$\\alpha$ photometry and $f_{esc}^{LyC}$. We find similar trends between\nglobal photometric observables ($L_{Ly\\alpha}$, $EW_{Ly\\alpha}$,\n$f_{esc}^{Ly\\alpha}$, $r_{50}$, $\\Sigma_{SFR}$) and $f_{esc}^{LyC}$ as\npreviously found with spectroscopy, but the correlations generally show a\nslightly smaller degree of correlations. However, we do find strong\ncorrelations between Ly$\\alpha$ observables ($L_{Ly\\alpha}$,$EW_{Ly\\alpha}$)\nand $f_{esc}^{LyC}$ when measured in a small aperture around the brightest UV\nsource in each galaxy. We interpret these results as evidence that LyC photons\nescaping on the line-of-sight are contributed by a small number of UV-bright\ncompact regions in most galaxies in our sample.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-09T17:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.07081v1","title":"Self-Steering Language Models","summary":"While test-time reasoning enables language models to tackle complex tasks,\nsearching or planning in natural language can be slow, costly, and error-prone.\nBut even when LMs struggle to emulate the precise reasoning steps needed to\nsolve a problem, they often excel at describing its abstract structure--both\nhow to verify solutions and how to search for them. This paper introduces\nDisCIPL, a method for \"self-steering\" LMs where a Planner model generates a\ntask-specific inference program that is executed by a population of Follower\nmodels. Our approach equips LMs with the ability to write recursive search\nprocedures that guide LM inference, enabling new forms of verifiable and\nefficient reasoning. When instantiated with a small Follower (e.g.,\nLlama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models,\nincluding GPT-4o and o1, on challenging constrained generation tasks. In\ndecoupling planning from execution, our work opens up a design space of\nhighly-parallelized Monte Carlo inference strategies that outperform standard\nbest-of-N sampling, require no finetuning, and can be implemented automatically\nby existing LMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07409v1","title":"RLibm-MultiRound: Correctly Rounded Math Libraries Without Worrying\n  about the Application's Rounding Mode","summary":"Our RLibm project generates a single implementation for an elementary\nfunction that produces correctly rounded results for multiple rounding modes\nand representations with up to 32-bits. They are appealing for developing fast\nreference libraries without double rounding issues. The key insight is to build\npolynomials that produce the correctly rounded result for a representation with\ntwo additional bits when compared to the largest target representation and with\nthe \"non-standard\" round-to-odd rounding mode, which makes double rounding the\nRLibm math library result to any smaller target representation innocuous. The\nresulting approximations generated by the RLibm approach are implemented with\nmachine supported floating-point operations with the round-to-nearest rounding\nmode. When an application uses a rounding mode other than the round-to-nearest\nmode, the RLibm math library saves the application's rounding mode, changes the\nsystem's rounding mode to round-to-nearest, computes the correctly rounded\nresult, and restores the application's rounding mode. This frequent change of\nrounding modes has a performance cost.\n  This paper proposes two new methods, which we call rounding-invariant outputs\nand rounding-invariant input bounds, to avoid the frequent changes to the\nrounding mode and the dependence on the round-to-nearest mode. First, our new\nrounding-invariant outputs method proposes using the round-to-zero rounding\nmode to implement RLibm's polynomial approximations. We propose fast,\nerror-free transformations to emulate a round-to-zero result from any standard\nrounding mode without changing the rounding mode. Second, our\nrounding-invariant input bounds method factors any rounding error due to\ndifferent rounding modes using interval bounds in the RLibm pipeline. Both\nmethods make a different set of trade-offs and improve the performance of\nresulting libraries by more than 2X.","main_category":"cs.MS","categories":"cs.MS","published":"2025-04-10T03:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.07412v1","title":"Toda-type presentations for the quantum K theory of partial flag\n  varieties","summary":"We prove a determinantal, Toda-type, presentation for the equivariant K\ntheory of a partial flag variety $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. The proof\nrelies on pushing forward the Toda presentation obtained by Maeno, Naito and\nSagaki for the complete flag variety $\\mathrm{Fl}(n)$, via Kato's\n$\\mathrm{K}_T(\\mathrm{pt})$-algebra homomorphism from the quantum K ring of\n$\\mathrm{Fl}(n)$ to that of $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. Starting instead\nfrom the Whitney presentation for $\\mathrm{Fl}(n)$, we show that the same\npush-forward technique gives a recursive formula for polynomial representatives\nof quantum K Schubert classes in any partial flag variety which do not depend\non quantum parameters. In an appendix, we include another proof of the Toda\npresentation for the equivariant quantum K ring of $\\mathrm{Fl}(n)$, following\nAnderson, Chen, and Tseng, which is based on the fact that the $\\mathrm{K}$\ntheoretic $J$-function is an eigenfunction of the finite difference Toda\nHamiltonians.","main_category":"math.AG","categories":"math.AG,math.CO,math.RT","published":"2025-04-10T03:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.07435v1","title":"Opportunity-Cost-Driven Reward Mechanisms for Crowd-Sourced Computing\n  Platforms","summary":"This paper introduces a game-theoretic model tailored for reward distribution\non crowd-sourced computing platforms. It explores a repeated game framework\nwhere miners, as computation providers, decide their computation power\ncontribution in each round, guided by the platform's designed reward\ndistribution mechanism. The reward for each miner in every round is based on\nthe platform's randomized task payments and the miners' computation\ntranscripts. Specifically, it defines Opportunity-Cost-Driven Incentive\nCompatibility (OCD-IC) and Dynamic OCD-IC (DOCD-IC) for scenarios where\nstrategic miners might allocate some computation power to more profitable\nactivities, such as Bitcoin mining. The platform must also achieve Budget\nBalance (BB), aiming for a non-negative total income over the long term. This\npaper demonstrates that traditional Pay-Per-Share (PPS) reward schemes require\nassumptions about task demand and miners' opportunity costs to ensure OCD-IC\nand BB, yet they fail to satisfy DOCD-IC. The paper then introduces\nPay-Per-Share with Subsidy (PPSS), a new reward mechanism that allows the\nplatform to provide subsidies to miners, thus eliminating the need for\nassumptions on opportunity cost to achieve OCD-IC, DOCD-IC, and long-term BB.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-10T04:05:48Z"}
{"aid":"http://arxiv.org/abs/2504.07464v1","title":"Stable and Efficient Charging of Superconducting C-shunt Flux Quantum\n  Batteries","summary":"Quantum batteries, as miniature energy storage devices, have sparked\nsignificant research interest in recent years. However, achieving rapid and\nstable energy transfer in quantum batteries while obeying quantum speed limits\nremains a critical challenge. In this work, we experimentally optimize the\ncharging process by leveraging the unique energy level structure of a\nsuperconducting capacitively-shunted flux qubit, using counterdiabatic pulses\nin the stimulated Raman adiabatic passage. Compared to previous studies, we\nimpose two different norm constraints on the driving Hamiltonian, achieving\noptimal charging without exceeding the overall driving strength. Furthermore,\nwe experimentally demonstrate a charging process that achieves the quantum\nspeed limit. In addition, we introduce a dimensionless parameter $\\mathcal{S}$\nto unify charging speed and stability, offering a universal metric for\nperformance optimization. In contrast to metrics such as charging power and\nthermodynamic efficiency, the $\\mathcal{S}$ criterion quantitatively captures\nthe stability of ergentropy while also considering the charging speed. Our\nresults highlight the potential of the capacitively-shunted qubit platform as\nan ideal candidate for realizing three-level quantum batteries and deliver\nnovel strategies for optimizing energy transfer protocols.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T05:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.07485v1","title":"Rendering Large Volume Datasets in Unreal Engine 5: A Survey","summary":"In this technical report, we discuss several approaches to in-core rendering\nof large volumetric datasets in Unreal Engine 5 (UE5). We explore the following\nmethods: the TBRayMarcher Plugin, the Niagara Fluids Plugin , and various\napproaches using Sparse Volume Textures (SVT), with a particular focus on\nHeterogeneous Volumes (HV). We found the HV approach to be the most promising.\nThe biggest challenge we encountered with other approaches was the need to\nchunk datasets so that each fits into volume textures smaller than one\ngigavoxel. While this enables display of the entire dataset at reasonable frame\nrates, it introduces noticeable artifacts at chunk borders due to incorrect\nlighting, as each chunk lacks information about its neighbors. After addressing\nsome (signed) int32 overflows in the Engine's SVT-related source code by\nconverting them to to (unsigned) uint32 or int64, the SVT-based HV system\nallows us to render sparse datasets up to 32k x 32k x 16k voxels, provided the\ncompressed tile data (including MIP data and padding for correct interpolation)\ndoes not exceed 4 gigavoxels. In the future, we intend to extend the existing\nSVT streaming functionality to support out-of-core rendering, in order to\neventually overcome VRAM limitations, graphics API constraints, and the\nperformance issues associated with 64-bit arithmetic in GPU shaders.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-10T06:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.07489v1","title":"Constraining the 3HDM Parameter Space","summary":"One of the standard ways to study scenarios beyond the Standard Model\ninvolves extending the Higgs Sector. This work examines the Three Higgs Doublet\nModel (3HDM) in a Type-Z or democratic setup, where each Higgs doublet couples\nexclusively to a specific type of fermion. The particle spectrum of the 3HDM\nincludes four charged Higgs bosons, two CP-odd scalars, and three CP-even\nscalars. This work investigates the allowed mass and coupling parameter space\nin the Type-Z 3HDM after imposing all theoretical and experimental constraints.\nWe extract the allowed parameter space under three distinct alignment-limit\nconditions or mass hierarchies leveraging machine learning techniques.\nSpecifically, we analyze scenarios where the 125 GeV Higgs is the lightest, an\nintermediary, or the heaviest CP-even Higgs boson. Our findings indicate that\nwhile a single lighter CP-even Higgs boson below 125 GeV still remains a\npossibility, the presence of two lighter Higgses is ruled out.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T06:46:09Z"}
{"aid":"http://arxiv.org/abs/2504.07494v1","title":"Apt-Serve: Adaptive Request Scheduling on Hybrid Cache for Scalable LLM\n  Inference Serving","summary":"Large language model (LLM) inference serving systems are essential to various\nLLM-based applications. As demand for LLM services continues to grow, scaling\nthese systems to handle high request rates while meeting latency Service-Level\nObjectives (SLOs), referred to as effective throughput, becomes critical.\nHowever, existing systems often struggle to improve effective throughput,\nprimarily due to a significant decline in Time To First Token (TTFT) SLO\nattainment. We identify two major causes of this bottleneck: (1)\nmemory-intensive KV cache that limits batch size expansion under GPU memory\nconstraints, and (2) rigid batch composition enforced by the default\nFirst-Come-First-Serve scheduling policy. In this paper, we introduce\nApt-Serve, a scalable framework designed to enhance effective throughput in LLM\ninference serving. Apt-Serve features a new hybrid cache scheme that combines\nKV cache with a memory-efficient hidden cache for reusable input hidden state\nvectors, allowing large batch sizes and improving request concurrency. Based on\nthe hybrid cache, Apt-Serve employs an adaptive runtime scheduling mechanism\nthat dynamically optimizes batch composition. We formally define the adaptive\nscheduling optimization problem and propose an efficient algorithm with\ntheoretical guarantees. Extensive evaluations on three real-world datasets and\nLLMs ranging from 13B to 66B parameters demonstrate that Apt-Serve achieves up\nto 8.8x improvement in effective throughput compared to the state-of-the-art\ninference serving systems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T06:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.07496v1","title":"Modular Control of Discrete Event System for Modeling and Mitigating\n  Power System Cascading Failures","summary":"Cascading failures in power systems caused by sequential tripping of\ncomponents are a serious concern as they can lead to complete or partial\nshutdowns, disrupting vital services and causing damage and inconvenience. In\nprior work, we developed a new approach for identifying and preventing\ncascading failures in power systems. The approach uses supervisory control\ntechnique of discrete event systems (DES) by incorporating both on-line\nlookahead control and forcible events. In this paper, we use modular\nsupervisory control of DES to reduce computation complexity and increase the\nrobustness and reliability of control. Modular supervisory control allows us to\npredict and mitigate cascading failures in power systems more effectively. We\nimplemented the proposed control technique on a simulation platform developed\nin MATLAB and applied the proposed DES controller. The calculations of modular\nsupervisory control of DES are performed using an external tool and imported\ninto the MATLAB platform. We conduct simulation studies for the IEEE 30-bus,\n118-bus and 300-bus systems, and the results demonstrate the effectiveness of\nour proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T06:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.07499v1","title":"Digital quantum simulation of the Su-Schrieffer-Heeger model using a\n  parameterized quantum circuit","summary":"We perform digital quantum simulations of the noninteracting\nSu-Schrieffer-Heeger (SSH) model using a parameterized quantum circuit. The\ncircuit comprises two main components: the first prepares the initial state\nfrom the product state $|0\\rangle^{\\otimes L}$, where $L$ is the system size;\nthe second consists of $M$ layers of brick-wall unitaries simulating time\nevolution. The evolution times, encoded as the rotation angles of quantum gates\nin the second part, are optimized variationally to minimize the energy. The SSH\nmodel exhibits two distinct topological phases, depending on the relative\nstrengths of inter- and intra-cell hopping amplitudes. We investigate the\nevolution of the energy, entanglement entropy, and mutual information towards\ntopologically trivial and nontrivial ground states. Our results find the\nfollows: (i) When the initial and target ground states belong to the same\ntopological phase, the variational energy decreases exponentially, the\nentanglement entropy quickly saturates in a system-size-independent manner, and\nthe mutual information remains spatially localized, as the number of layers\nincreases. (ii) When the initial and target ground states belong to different\ntopological phases, the variational energy decreases polynomially, the\nentanglement entropy initially grows logarithmically before decreasing, and the\nmutual information spreads ballistically across the entire system, with\nincreasing the number of layers. Furthermore, by calculating the polarization,\nwe identify a topological phase transition occurring at an intermediate circuit\nlayer when the initial and final target states lie in different topological\ncharacters. Finally, we experimentally confirm this topological phase\ntransition in an 18-site system using 19 qubits on a trapped-ion quantum\ncomputer provided by Quantinuum.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T06:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.07506v1","title":"Normalized solutions to mixed dispersion nonlinear Schrdinger system\n  with coupled nonlinearity","summary":"In this paper, we consider the existence of normalized solutions for the\nfollowing biharmonic nonlinear Schr\\\"{o}dinger system\n  \\[ \\begin{aligned}\n  \\begin{cases}\n  &\\Delta^2u+\\alpha_{1}\\Delta u+\\lambda u=\\beta r_{1}|u|^{r_{1}-2}|v|^{r_{2}} u\n&&\\text{ in } \\mathbb{R}^{N},\n  & \\Delta^2v+\\alpha_{2}\\Delta v+\\lambda v=\\beta r_{2}|u|^{r_{1}}|v|^{r_{2}-2}\nv && \\text{ in } \\mathbb{R}^{N},\\\\ & \\int_{\\mathbb{R}^{N}} (u^{2}+v^{2}){\\rm d}\nx=\\rho^{2},&&\n  \\end{cases} \\end{aligned}\n  \\]\n  where $\\Delta^2u=\\Delta(\\Delta u)$ is the biharmonic operator, $\\alpha_{1}$,\n$\\alpha_{2}$, $\\beta>0$, $r_{1}$, $r_{2}>1$, $N\\geq 1$. $\\rho^2$ stands for the\nprescribed mass, and $\\lambda\\in\\mathbb{R}$ arises as a Lagrange multiplier.\nSuch single constraint permits mass transformation in two materials. When\n$r_{1}+r_{2}\\in\\left(2,2+\\frac{8}{N}\\right]$, we obtain a dichotomy result for\nthe existence of nontrivial ground states. Especially when $\\alpha_1=\\alpha_2$,\nthe ground state exists for all $\\rho>0$ if and only if\n$r_1+r_2<\\min\\left\\{\\max\\left\\{4, 2+\\frac{8}{N+1}\\right\\},\n2+\\frac{8}{N}\\right\\}$. When $r_{1}+r_{2}\\in\\left(2+\\frac{8}{N},\n\\frac{2N}{(N-4)^{+}}\\right)$ and $N\\geq 2$, we obtain the existence of radial\nnontrivial mountain pass solution for small $\\rho>0$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:08:19Z"}
{"aid":"http://arxiv.org/abs/2504.07524v1","title":"DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy\n  Prediction","summary":"Monocular 3D occupancy prediction, aiming to predict the occupancy and\nsemantics within interesting regions of 3D scenes from only 2D images, has\ngarnered increasing attention recently for its vital role in 3D scene\nunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from\n2D images is ill-posed and resource-intensive. In this paper, we present\n\\textbf{DGOcc}, a \\textbf{D}epth-aware \\textbf{G}lobal query-based network for\nmonocular 3D \\textbf{Occ}upancy prediction. We first explore prior depth maps\nto extract depth context features that provide explicit geometric information\nfor the occupancy network. Then, in order to fully exploit the depth context\nfeatures, we propose a Global Query-based (GQ) Module. The cooperation of\nattention mechanisms and scale-aware operations facilitates the feature\ninteraction between images and 3D voxels. Moreover, a Hierarchical Supervision\nStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxel\nfeatures to full resolution, which mitigates GPU memory utilization and time\ncost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasets\ndemonstrate that the proposed method achieves the best performance on monocular\nsemantic occupancy prediction while reducing GPU and time overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:44:55Z"}
{"aid":"http://arxiv.org/abs/2504.07533v1","title":"Quantitative uniqueness of continuation for the Schrdinger equation :\n  explicit dependence on the potential","summary":"We demonstrate a quantitative version of the usual properties related to\nunique continuation from an interior datum for the Schr\\\"odinger equation with\nbounded or unbounded potential. The inequalities we establish have constants\nthat explicitly depend on the potential. We also indicate how the\nabove-mentioned inequalities can be extended to elliptic equations with bounded\nor unbounded first-order derivatives. The case of unique continuation from\nCauchy data is also considered.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.07545v1","title":"Convexity Helps Iterated Search in 3D","summary":"Inspired by the classical fractional cascading technique, we introduce new\ntechniques to speed up the following type of iterated search in 3D: The input\nis a graph $\\mathbf{G}$ with bounded degree together with a set $H_v$ of 3D\nhyperplanes associated with every vertex of $v$ of $\\mathbf{G}$. The goal is to\nstore the input such that given a query point $q\\in \\mathbb{R}^3$ and a\nconnected subgraph $\\mathbf{H}\\subset \\mathbf{G}$, we can decide if $q$ is\nbelow or above the lower envelope of $H_v$ for every $v\\in \\mathbf{H}$. We show\nthat using linear space, it is possible to answer queries in roughly $O(\\log n\n+ |\\mathbf{H}|\\sqrt{\\log n})$ time which improves trivial bound of\n$O(|\\mathbf{H}|\\log n)$ obtained by using planar point location data\nstructures. Our data structure can in fact answer more general queries (it\ncombines with shallow cuttings) and it even works when $\\mathbf{H}$ is given\none vertex at a time. We show that this has a number of new applications and in\nparticular, we give improved solutions to a set of natural data structure\nproblems that up to our knowledge had not seen any improvements.\n  We believe this is a very surprising result because obtaining similar results\nfor the planar point location problem was known to be impossible.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-10T08:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.07548v1","title":"On the variety of solutions of 1-dimensional nonlinear eigenvalue\n  problems","summary":"Second order nonlinear eigenvalue problems are considered for which the\nspectrum is an interval. The boundary conditions are of Robin and Dirichlet\ntype. The shape and the number of solutions are discussed by means of a phase\nplane analysis. A new type of asymmetric solutions are discovered. Some\nnumerical illustrations are given.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T08:23:38Z"}
{"aid":"http://arxiv.org/abs/2504.07549v1","title":"STeP: A General and Scalable Framework for Solving Video Inverse\n  Problems with Spatiotemporal Diffusion Priors","summary":"We study how to solve general Bayesian inverse problems involving videos\nusing diffusion model priors. While it is desirable to use a video diffusion\nprior to effectively capture complex temporal relationships, due to the\ncomputational and data requirements of training such a model, prior work has\ninstead relied on image diffusion priors on single frames combined with\nheuristics to enforce temporal consistency. However, these approaches struggle\nwith faithfully recovering the underlying temporal relationships, particularly\nfor tasks with high temporal uncertainty. In this paper, we demonstrate the\nfeasibility of practical and accessible spatiotemporal diffusion priors by\nfine-tuning latent video diffusion models from pretrained image diffusion\nmodels using limited videos in specific domains. Leveraging this plug-and-play\nspatiotemporal diffusion prior, we introduce a general and scalable framework\nfor solving video inverse problems. We then apply our framework to two\nchallenging scientific video inverse problems--black hole imaging and dynamic\nMRI. Our framework enables the generation of diverse, high-fidelity video\nreconstructions that not only fit observations but also recover multi-modal\nsolutions. By incorporating a spatiotemporal diffusion prior, we significantly\nimprove our ability to capture complex temporal relationships in the data while\nalso enhancing spatial fidelity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T08:24:26Z"}
{"aid":"http://arxiv.org/abs/2504.07577v1","title":"Optimization Of The Survival Threshold For Anisotropic Logistic\n  Equations With Mixed Boundary Conditions","summary":"In this paper we study a reaction diffusion problem with anisotropic\ndiffusion and mixed Dirichlet-Neumann boundary conditions on the boundary of\nthe domain. First, we prove that the parabolic problem has a unique positive,\nbounded solution. Then, we show that this solution converges as t tends to\ninfinity to the unique nonnegative solution of the elliptic associated problem.\nThe existence of the unique positive solution to this problem depends on a\nprincipal eigenvalue of a suitable linearized problem with a sign-changing\nweights. Next, we study the minimization of such eigenvalue with respect to the\nsign-changing weight, showing that there exists an optimal bang-bang weight,\nnamely a piece-wise constant weight that takes only two values. Finally, we\ncompletely solve the problem in dimension one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T09:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.07578v1","title":"Privacy-Preserving Vertical K-Means Clustering","summary":"Clustering is a fundamental data processing task used for grouping records\nbased on one or more features. In the vertically partitioned setting, data is\ndistributed among entities, with each holding only a subset of those features.\nA key challenge in this scenario is that computing distances between records\nrequires access to all distributed features, which may be privacy-sensitive and\ncannot be directly shared with other parties. The goal is to compute the joint\nclusters while preserving the privacy of each entity's dataset. Existing\nsolutions using secret sharing or garbled circuits implement privacy-preserving\nvariants of Lloyd's algorithm but incur high communication costs, scaling as\nO(nkt), where n is the number of data points, k the number of clusters, and t\nthe number of rounds. These methods become impractical for large datasets or\nseveral parties, limiting their use to LAN settings only. On the other hand, a\ndifferent line of solutions rely on differential privacy (DP) to outsource the\nlocal features of the parties to a central server. However, they often\nsignificantly degrade the utility of the clustering outcome due to excessive\nnoise. In this work, we propose a novel solution based on homomorphic\nencryption and DP, reducing communication complexity to O(n+kt). In our method,\nparties securely outsource their features once, allowing a computing party to\nperform clustering operations under encryption. DP is applied only to the\nclusters' centroids, ensuring privacy with minimal impact on utility. Our\nsolution clusters 100,000 two-dimensional points into five clusters using only\n73MB of communication, compared to 101GB for existing works, and completes in\njust under 3 minutes on a 100Mbps network, whereas existing works take over 1\nday. This makes our solution practical even for WAN deployments, all while\nmaintaining accuracy comparable to plaintext k-means algorithms.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T09:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.07595v1","title":"High-Level Synthesis using SDF-AP, Template Haskell, QuasiQuotes, and\n  GADTs to Generate Circuits from Hierarchical Input Specification","summary":"FPGAs provide highly parallel and customizable hardware solutions but are\ntraditionally programmed using low-level Hardware Description Languages (HDLs)\nlike VHDL and Verilog. These languages have a low level of abstraction and\nrequire engineers to manage control and scheduling manually. High-Level\nSynthesis (HLS) tools attempt to lift this level of abstraction by translating\nC/C++ code into hardware descriptions, but their reliance on imperative\nparadigms leads to challenges in deriving parallelism due to pointer aliasing\nand sequential execution models.\n  Functional programming, with its inherent purity, immutability, and\nparallelism, presents a more natural abstraction for FPGA design. Existing\nfunctional hardware description tools such as Clash enable high-level circuit\ndescriptions but lack automated scheduling and control mechanisms. Prior work\nby Folmer introduced a framework integrating SDF-AP graphs into Haskell for\nautomatic hardware generation, but it lacked hierarchy and reusability.\n  This paper extends that framework by introducing hierarchical pattern\nspecification, enabling structured composition and scalable parallelism. Key\ncontributions include: (1) automatic hardware generation, where both data and\ncontrol paths are derived from functional specifications with hierarchical\npatterns, (2) parameterized buffers using GADTs, eliminating the need for\nmanual buffer definitions and facilitating component reuse, and (3) provision\nof a reference \"golden model\" that can be simulated in the integrated\nenvironment for validation.\n  The core focus of this paper is on methodology. But we also evaluate our\napproach against Vitis HLS, comparing both notation and resulting hardware\narchitectures. Experimental results demonstrate that our method provides\ngreater transparency in resource utilization and scheduling, often\noutperforming Vitis in both scheduling and predictability.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.07600v1","title":"System Concept and Demonstration of Bistatic MIMO-OFDM-based ISAC","summary":"In future sixth-generation (6G) mobile networks, radar sensing is expected to\nbe offered as an additional service to its original purpose of communication.\nMerging these two functions results in integrated sensing and communication\n(ISAC) systems. In this context, bistatic ISAC appears as a possibility to\nexploit the distributed nature of cellular networks while avoiding highly\ndemanding hardware requirements such as full-duplex operation. Recent studies\nhave introduced strategies to perform required synchronization and data\nexchange between nodes for bistatic ISAC operation, based on orthogonal\nfrequency-division multiplexing (OFDM), however, only for single-input\nsingle-output architectures. In this article, a system concept for a bistatic\nmultiple-input multiple-output (MIMO)-OFDM-based ISAC system with beamforming\nat both transmitter and receiver is proposed, and a distribution\nsynchronization concept to ensure coherence among the different receive\nchannels for direction-of-arrival estimation is presented. After a discussion\non the ISAC processing chain, including relevant aspects for practical\ndeployments such as transmitter digital pre-distortion and receiver\ncalibration, a 4x8 MIMO measurement setup at 27.5 GHz and results are presented\nto validate the proposed system and distribution synchronization concepts.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T09:54:15Z"}
{"aid":"http://arxiv.org/abs/2504.07603v1","title":"RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception\n  in Adverse Conditions","summary":"Current autonomous driving algorithms heavily rely on the visible spectrum,\nwhich is prone to performance degradation in adverse conditions like fog, rain,\nsnow, glare, and high contrast. Although other spectral bands like\nnear-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception\nin such situations, they have limitations and lack large-scale datasets and\nbenchmarks. Short-wave infrared (SWIR) imaging offers several advantages over\nNIR and LWIR. However, no publicly available large-scale datasets currently\nincorporate SWIR data for autonomous driving. To address this gap, we introduce\nthe RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000\nsynchronized and spatially aligned RGB-SWIR image pairs collected across\ndiverse locations, lighting, and weather conditions. In addition, we provide a\nsubset for RGB-SWIR translation and object detection annotations for a subset\nof challenging traffic scenarios to demonstrate the utility of SWIR imaging\nthrough experiments on both object detection and RGB-to-SWIR image translation.\nOur experiments show that combining RGB and SWIR data in an ensemble framework\nsignificantly improves detection accuracy compared to RGB-only approaches,\nparticularly in conditions where visible-spectrum sensors struggle. We\nanticipate that the RASMD dataset will advance research in multispectral\nimaging for autonomous driving and robust perception systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T09:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.07657v1","title":"Single-Pixel Imaging Technology in Holographic Microscopy","summary":"We propose a holographic microscopy method based on single-pixel imaging\ntechnology (HM-SPI). We used a holographic microscopy method based on in-line\nGabor holography. In single-pixel imaging technology, cyclic binary masks and\namplitude-phase masks are used instead of cyclic Hadamard masks. These masks\nare generated using the quadratic residue and twin-prime techniques. Numerical\nresults are presented for both cases. Unlike the traditional approach of using\nDMD technology, our model considers a photodetector as a single-pixel detector.\nWe propose a method based on the fast Fourier transform (FFT) algorithm to\nreconstruct the original field, which has a computational complexity of\nO(NlogN). This approach opens up prospects for the development of compact\nholographic systems capable of operating across a wide spectral range and under\nlimited computational resources.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.07675v1","title":"Low-Complexity Optimization of Antenna Switching Schemes for Dynamic\n  Channel Sounding","summary":"Understanding wireless channels is crucial for the design of wireless\nsystems. For mobile communication, sounders and antenna arrays with short\nmeasurement times are required to simultaneously capture the dynamic and\nspatial channel characteristics. Switched antenna arrays are an attractive\noption that can overcome the high cost of real arrays and the long measurement\ntimes of virtual arrays. Optimization of the switching sequences is then\nessential to avoid aliasing and increase the accuracy of channel parameter\nestimates. This paper provides a novel and comprehensive analysis of the design\nof switching sequences. We first review the conventional spatio-temporal\nambiguity function, extend it to dual-polarized antenna arrays, and analyze its\nprohibitive complexity when designing for ultra-massive antenna arrays. We thus\npropose a new method that uses the Fisher information matrix to tackle the\nestimation accuracy. We also propose to minimize the ambiguity by choosing a\nswitching sequence that minimizes side lobes in its Fourier spectrum. In this\nsense, we divide the sequence design problem into Fourier-based ambiguity\nreduction and Fisher-based accuracy improvement, and coin the resulting design\napproach as Fourier-Fisher. Simulations and measurements show that the\nFourier-Fisher approach achieves identical performance and significantly lower\ncomputational complexity than that of the conventional ambiguity-based\napproach.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:56:37Z"}
{"aid":"http://arxiv.org/abs/2504.07677v1","title":"Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal\n  Localization","summary":"Reliable localization is critical for robot navigation in complex indoor\nenvironments. In this paper, we propose an uncertainty-aware localization\nmethod that enhances the reliability of localization outputs without modifying\nthe prediction model itself. This study introduces a percentile-based rejection\nstrategy that filters out unreliable 3-DoF pose predictions based on aleatoric\nand epistemic uncertainties the network estimates. We apply this approach to a\nmulti-modal end-to-end localization that fuses RGB images and 2D LiDAR data,\nand we evaluate it across three real-world datasets collected using a\ncommercialized serving robot. Experimental results show that applying stricter\nuncertainty thresholds consistently improves pose accuracy. Specifically, the\nmean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean\norientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70%\nthresholds, respectively. Furthermore, the rejection strategy effectively\nremoves extreme outliers, resulting in better alignment with ground truth\ntrajectories. To the best of our knowledge, this is the first study to\nquantitatively demonstrate the benefits of percentile-based uncertainty\nrejection in multi-modal end-to-end localization tasks. Our approach provides a\npractical means to enhance the reliability and accuracy of localization systems\nin real-world deployments.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-10T12:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.07680v1","title":"Synthetic Fluency: Hallucinations, Confabulations, and the Creation of\n  Irish Words in LLM-Generated Translations","summary":"This study examines hallucinations in Large Language Model (LLM) translations\ninto Irish, specifically focusing on instances where the models generate novel,\nnon-existent words. We classify these hallucinations within verb and noun\ncategories, identifying six distinct patterns among the latter. Additionally,\nwe analyse whether these hallucinations adhere to Irish morphological rules and\nwhat linguistic tendencies they exhibit. Our findings show that while both\nGPT-4.o and GPT-4.o Mini produce similar types of hallucinations, the Mini\nmodel generates them at a significantly higher frequency. Beyond\nclassification, the discussion raises speculative questions about the\nimplications of these hallucinations for the Irish language. Rather than\nseeking definitive answers, we offer food for thought regarding the increasing\nuse of LLMs and their potential role in shaping Irish vocabulary and linguistic\nevolution. We aim to prompt discussion on how such technologies might influence\nlanguage over time, particularly in the context of low-resource,\nmorphologically rich languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:08:47Z"}
{"aid":"http://arxiv.org/abs/2504.07687v1","title":"FMNV: A Dataset of Media-Published News Videos for Fake News Detection","summary":"News media, particularly video-based platforms, have become deeply embedded\nin daily life, concurrently amplifying risks of misinformation dissemination.\nConsequently, multimodal fake news detection has garnered significant research\nattention. However, existing datasets predominantly comprise user-generated\nvideos characterized by crude editing and limited public engagement, whereas\nprofessionally crafted fake news videos disseminated by media outlets often\npolitically or virally motivated pose substantially greater societal harm. To\naddress this gap, we construct FMNV, a novel dataset exclusively composed of\nnews videos published by media organizations. Through empirical analysis of\nexisting datasets and our curated collection, we categorize fake news videos\ninto four distinct types. Building upon this taxonomy, we employ Large Language\nModels (LLMs) to automatically generate deceptive content by manipulating\nauthentic media-published news videos. Furthermore, we propose FMNVD, a\nbaseline model featuring a dual-stream architecture integrating CLIP and Faster\nR-CNN for video feature extraction, enhanced by co-attention mechanisms for\nfeature refinement and multimodal aggregation. Comparative experiments\ndemonstrate both the generalization capability of FMNV across multiple\nbaselines and the superior detection efficacy of FMNVD. This work establishes\ncritical benchmarks for detecting high-impact fake news in media ecosystems\nwhile advancing methodologies for cross-modal inconsistency analysis.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-10T12:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.07698v1","title":"Proactive User Information Acquisition via Chats on User-Favored Topics","summary":"Chat-oriented dialogue systems designed to provide tangible benefits, such as\nsharing the latest news or preventing frailty in senior citizens, often require\nProactive acquisition of specific user Information via chats on user-faVOred\nTopics (PIVOT). This study proposes the PIVOT task, designed to advance the\ntechnical foundation for these systems. In this task, a system needs to acquire\nthe answers of a user to predefined questions without making the user feel\nabrupt while engaging in a chat on a predefined topic. We found that even\nrecent large language models (LLMs) show a low success rate in the PIVOT task.\nWe constructed a dataset suitable for the analysis to develop more effective\nsystems. Finally, we developed a simple but effective system for this task by\nincorporating insights obtained through the analysis of this dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:32:16Z"}
{"aid":"http://arxiv.org/abs/2504.07705v1","title":"Electroweak baryogenesis in 2HDM without EDM cancellation","summary":"We study two Higgs doublet models with successful electroweak baryogenesis\nbut without cancellations of electric dipole moments (EDMs). For the\nbaryogenesis, additional scalar bosons are favored to couple mainly with the\ntop quark with CP violations. However, if they also couple to light fermions of\nthe Standard Model, the model is limited severely by EDMs, and additional CP\nphases irrelevant to the baryogenesis are often introduced to cancel the\ncontributions to the EDMs. Alternatively, we consider a scenario where the\nlight-fermion couplings are suppressed to avoid the constraints. In our\nscenario, it is found that the leading contributions arise in the top-quark\nEDMs at the two-loop level. They induce the electron, neutron, and proton EDMs\nvia radiative corrections. Since there is no additional CP-violating phase,\nthey are correlated with the baryon asymmetry. We show that our scenario is\ncompatible with the current experimental bounds and is within the scope of\nfuture EDM experiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T12:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.07723v1","title":"Low-Thrust Many-Revolution Transfer between Near Rectilinear Halo Orbit\n  and Low Lunar Orbit Using Hybrid Differential Dynamic Programming","summary":"Low-thrust, many-revolution transfers between near-rectilinear halo orbits\nand low lunar orbits are challenging due to the many-revolutions and is further\ncomplicated by three-body perturbation. To address these challenges, we extend\nhybrid differential dynamic programming by enhancing with a continuation of\ndynamical system. The optimization begins with the Sundman-transformed two-body\nproblem and gradually transitions to the Sundman-transformed circular\nrestricted three-body problem expressed in the moon-centered inertial frame.\nNumerical examples demonstrate the robust convergence of our method, where\noptimal transfers from low lunar orbit to near-rectilinear halo orbit are\nobtained with a poor initial guess of low lunar orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,math.OC","published":"2025-04-10T13:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.07742v1","title":"Gradient-based Sample Selection for Faster Bayesian Optimization","summary":"Bayesian optimization (BO) is an effective technique for black-box\noptimization. However, its applicability is typically limited to\nmoderate-budget problems due to the cubic complexity in computing the Gaussian\nprocess (GP) surrogate model. In large-budget scenarios, directly employing the\nstandard GP model faces significant challenges in computational time and\nresource requirements. In this paper, we propose a novel approach,\ngradient-based sample selection Bayesian Optimization (GSSBO), to enhance the\ncomputational efficiency of BO. The GP model is constructed on a selected set\nof samples instead of the whole dataset. These samples are selected by\nleveraging gradient information to maintain diversity and representation. We\nprovide a theoretical analysis of the gradient-based sample selection strategy\nand obtain explicit sublinear regret bounds for our proposed framework.\nExtensive experiments on synthetic and real-world tasks demonstrate that our\napproach significantly reduces the computational cost of GP fitting in BO while\nmaintaining optimization performance comparable to baseline methods.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-10T13:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07752v1","title":"Linear relations between face numbers of levels in arrangements","summary":"We study linear relations between face numbers of levels in arrangements. Let\n$V = \\{ v_1, \\ldots, v_n \\} \\subset \\mathbf{R}^{r}$ be a vector configuration\nin general position, and let $\\mathcal{A}(V)$ be polar dual arrangement of\nhemispheres in the $d$-dimensional unit sphere $S^d$, where $d=r-1$. For $0\\leq\ns \\leq d$ and $0 \\leq t \\leq n$, let $f_{s,t}(V)$ denote the number of faces of\n\\emph{level} $t$ and dimension $d-s$ in the arrangement $\\mathcal{A}(V)$ (these\ncorrespond to partitions $V=V_-\\sqcup V_0 \\sqcup V_+$ by linear hyperplanes\nwith $|V_0|=s$ and $|V_-|=t$). We call the matrix $f(V):=[f_{s,t}(V)]$ the\n\\emph{$f$-matrix} of $V$.\n  Completing a long line of research on linear relations between face numbers\nof levels in arrangements, we determine, for every $n\\geq r \\geq 1$, the affine\nspace $\\mathfrak{F}_{n,r}$ spanned by the $f$-matrices of configurations of $n$\nvectors in general position in $\\mathbf{R}^r$; moreover, we determine the\nsubspace $\\mathfrak{F}^0_{n,r} \\subset \\mathfrak{F}_{n,r}$ spanned by all\n\\emph{pointed} vector configurations (i.e., such that $V$ is contained in some\nopen linear halfspace), which correspond to point sets in $\\mathbf{R}^d$. This\ngeneralizes the classical fact that the Dehn--Sommerville relations generate\nall linear relations between the face numbers of simple polytopes (the faces at\nlevel $0$) and answers a question posed by Andrzejak and Welzl in 2003.\n  The key notion for the statements and the proofs of our results is the\n$g$-matrix of a vector configuration, which determines the $f$-matrix and\ngeneralizes the classical $g$-vector of a polytope.\n  By Gale duality, we also obtain analogous results for partitions of vector\nconfigurations by sign patterns of nontrivial linear dependencies, and for\n\\emph{Radon partitions} of point sets in $\\mathbf{R}^d$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.07753v1","title":"Virtual-mask Informed Prior for Sparse-view Dual-Energy CT\n  Reconstruction","summary":"Sparse-view sampling in dual-energy computed tomography (DECT) significantly\nreduces radiation dose and increases imaging speed, yet is highly prone to\nartifacts. Although diffusion models have demonstrated potential in effectively\nhandling incomplete data, most existing methods in this field focus on the\nimage do-main and lack global constraints, which consequently leads to\ninsufficient reconstruction quality. In this study, we propose a dual-domain\nvirtual-mask in-formed diffusion model for sparse-view reconstruction by\nleveraging the high inter-channel correlation in DECT. Specifically, the study\ndesigns a virtual mask and applies it to the high-energy and low-energy data to\nperform perturbation operations, thus constructing high-dimensional tensors\nthat serve as the prior information of the diffusion model. In addition, a\ndual-domain collaboration strategy is adopted to integrate the information of\nthe randomly selected high-frequency components in the wavelet domain with the\ninformation in the projection domain, for the purpose of optimizing the global\nstruc-tures and local details. Experimental results indicated that the present\nmethod exhibits excellent performance across multiple datasets.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.07755v1","title":"Renormalization and blow ups for the nonlinear Schrdinger equation","summary":"Existence of finite-time blow ups in the classical one-dimensional nonlinear\nSchr\\\"odinger equation (NLS)\n  (1) i \\partial_t u + u_{x x} + |u|^{2r} u = 0, u(x,0) = u_0(x)\n  has been one of the central problems in the studies of the singularity\nformation in the PDEs.\n  We revisit this problem using an approach based on the ideas borrowed from\nDynamical Systems.\n  To that end, we reformulate the initial value problem for (1), with r \\in\n\\mathbb{N}, r \\ge 1, as a fixed point problem for a certain renormalization\noperator, and use the ideas of apriori bounds to prove existence of a\nrenormalization fixed point. Existence of such fixed points leads to existence\nof self-similar solutions of the form\n  u(x,t) = (T-t)^{-{1 \\over 2 r}} U((T-t)^{-{1 \\over 2}} x),\n  whose L^{2 r +2}-norms are bounded up-to a finite time T and whose energy\nblows up at T.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:55:08Z"}
{"aid":"http://arxiv.org/abs/2504.07769v1","title":"Inflection Point Inflation in Supergravity","summary":"In this paper, we study the inflection point inflation generated by a\npolynomial superpotential and a canonical K\\\"ahler potential under the\nsupergravity framework, where only one chiral superfield is needed. We find\nthat the special form of the scalar potential limits the inflationary Hubble\nparameter to values $\\lesssim 10^{10}\\, \\textrm{GeV}$ and the inflaton mass to\n$\\lesssim 10^{11} \\, \\textrm{GeV}$. We obtain analytic results for small field\ncases and present numerical results for large field ones. We find the\ntensor-to-scalar ratio $r<10^{-8}$ is always suppressed in these models, while\nthe running of spectral index $\\alpha\\approx \\mathcal{O}(-10^{-3})$ may be\ntestable in next-generation CMB experiments. We also discuss the possible\neffects of SUSY breaking Polonyi term presented in the superpotential where we\nfind a general upper bound for the SUSY breaking scale for a given value of the\nHubble parameter.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:08:14Z"}
{"aid":"http://arxiv.org/abs/2504.07776v1","title":"SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified\n  Flow","summary":"Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-10T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.07792v1","title":"Breaking the Barriers: Video Vision Transformers for Word-Level Sign\n  Language Recognition","summary":"Sign language is a fundamental means of communication for the deaf and\nhard-of-hearing (DHH) community, enabling nuanced expression through gestures,\nfacial expressions, and body movements. Despite its critical role in\nfacilitating interaction within the DHH population, significant barriers\npersist due to the limited fluency in sign language among the hearing\npopulation. Overcoming this communication gap through automatic sign language\nrecognition (SLR) remains a challenge, particularly at a dynamic word-level,\nwhere temporal and spatial dependencies must be effectively recognized. While\nConvolutional Neural Networks have shown potential in SLR, they are\ncomputationally intensive and have difficulties in capturing global temporal\ndependencies between video sequences. To address these limitations, we propose\na Video Vision Transformer (ViViT) model for word-level American Sign Language\n(ASL) recognition. Transformer models make use of self-attention mechanisms to\neffectively capture global relationships across spatial and temporal\ndimensions, which makes them suitable for complex gesture recognition tasks.\nThe VideoMAE model achieves a Top-1 accuracy of 75.58% on the WLASL100 dataset,\nhighlighting its strong performance compared to traditional CNNs with 65.89%.\nOur study demonstrates that transformer-based architectures have great\npotential to advance SLR, overcome communication barriers and promote the\ninclusion of DHH individuals.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07801v1","title":"FairEval: Evaluating Fairness in LLM-Based Recommendations with\n  Personality Awareness","summary":"Recent advances in Large Language Models (LLMs) have enabled their\napplication to recommender systems (RecLLMs), yet concerns remain regarding\nfairness across demographic and psychological user dimensions. We introduce\nFairEval, a novel evaluation framework to systematically assess fairness in\nLLM-based recommendations. FairEval integrates personality traits with eight\nsensitive demographic attributes,including gender, race, and age, enabling a\ncomprehensive assessment of user-level bias. We evaluate models, including\nChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's\nfairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997\nfor Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results\nhighlight the importance of robustness in prompt sensitivity and support more\ninclusive recommendation systems.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.HC","published":"2025-04-10T14:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07823v1","title":"A new look into the atmospheric composition of WASP-39 b","summary":"Being one of the first exoplanets observed by the James Webb Space Telescope\n(JWST), WASP-39 b has become an iconic target and many transit spectra recorded\nwith different instruments (NIRISS, NIRCAM, NIRSpec G395H, NIRSpec PRISM and\nMIRI) are currently available, allowing in-depth studies of its atmosphere. We\npresent here a novel approach to interpret WASP-39 b's transit spectroscopic\ndata, consisting of a multi-step process where ab initio equilibrium chemistry\nmodels and blind retrievals are used iteratively to find physically robust,\noptimal solutions. Following this approach, we have identified a new scenario\nto explain WASP-39 b's atmospheric composition, in which silicon-based\nchemistry plays a major role. In this scenario, SiO may explain the spectral\nabsorption at 4.1 $\\mu$m, currently interpreted as being due to SO$_2$. SiO and\nthe other gas species identified by the retrieval models, i.e. H$_2$O, CO$_2$,\nNa and K, are consistent with an atmosphere in chemical equilibrium with a\ntemperature-pressure profile constrained by H$_2$O and CO$_2$ absorption bands.\nIn addition, silicate clouds and hazes can produce the spectral features\nobserved by MIRI in the spectral window 5-12 $\\mu$m. While we advocate the need\nfor more data, possibly at higher spectral resolution, to confirm our results\nfor WASP-39 b's atmospheric composition, we highlight a refined atmospheric\nretrieval strategy with pre-selection and post-reconstruction to guide the next\ngeneration of transit spectroscopy.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-10T15:01:28Z"}
{"aid":"http://arxiv.org/abs/2504.07832v1","title":"A character theoretic formula for base size II","summary":"A base for a permutation group $G$ acting on a set $\\Omega$ is a sequence\n$\\mathcal{B}$ of points of $\\Omega$ such that the pointwise stabiliser\n$G_{\\mathcal{B}}$ is trivial. The base size of $G$ is the size of a smallest\nbase for $G$. Extending the results of a recent paper of the author, we prove a\n2013 conjecture of Fritzsche, K\\\"ulshammer, and Reiche. Moreover, we generalise\nthis conjecture and derive an alternative character theoretic formula for the\nbase size of a certain class of permutation groups. As a consequence of our\nwork, a third formula for the base size of the symmetric group of degree $n$\nacting on the subsets of $\\{1,2,\\dots, n\\}$ is obtained.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-04-10T15:09:00Z"}
{"aid":"http://arxiv.org/abs/2504.07838v1","title":"Large anisotropies in the gravitational wave background from\n  baryogenesis","summary":"Affleck-Dine (AD) baryogenesis can produce the baryon asymmetry of the\nUniverse through the $CP$-violating dynamics of AD field. The field generally\nfragments into Q-balls, whose rapid decay induces enhanced gravitational waves.\nIn this Letter, we investigate the anisotropies in this gravitational wave\nbackground as a new essential observable for AD baryogenesis. The evolution of\nAD field causes non-Gaussian baryonic isocurvature perturbations, and the\nnon-Gaussianity modulates the spatial distribution of Q-balls on large scales,\nresulting in large-scale anisotropies in the Q-ball-induced gravitational wave\nbackground. We present that the anisotropies can be significantly large with a\nreduced angular power spectrum $\\sim 10^{-2}$, and can be detected by future\nexperiments like LISA. Moreover, these anisotropies universally reveal the\n$CP$-violating dynamics of AD field, opening a novel road to explore the\nlongstanding baryon asymmetry puzzle.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-10T15:18:29Z"}
{"aid":"http://arxiv.org/abs/2504.07850v1","title":"Probabilistic Multi-Criteria Decision-Making for Circularity Performance\n  of Modern Methods of Construction Products","summary":"The construction industry faces increasingly more significant pressure to\nreduce resource consumption, minimise waste, and enhance environmental\nperformance. Towards the transition to a circular economy in the construction\nindustry, one of the challenges is the lack of a standardised assessment\nframework and methods to measure circularity at the product level. To support a\nmore sustainable and circular construction industry through robust and enhanced\nscenario analysis, this paper integrates probabilistic analysis into the\ncoupled assessment framework; this research addresses uncertainties associated\nwith multiple criteria and diverse stakeholders in the construction industry to\nenable more robust decision-making support on both circularity and\nsustainability performance. By demonstrating the application in three\nreal-world MMC products, the proposed framework offers a novel approach to\nsimultaneously assess the circularity and sustainability of MMC products with\nrobustness and objectiveness.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.AP","published":"2025-04-10T15:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.07865v1","title":"Equidistribution in 2-Nilpotent Polish Groups and triple restricted\n  sumsets","summary":"The aim of this paper is to establish a Ratner-type equidistribution theorem\nfor orbits on homogeneous spaces associated with \\(2\\)-nilpotent locally\ncompact Polish groups under the action of a countable discrete abelian group.\nWe apply this result to establish the existence of triple restricted sumsets in\nsubsets of positive density in arbitrary countable discrete abelian groups,\nsubject to a necessary finiteness condition.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-10T15:40:48Z"}
{"aid":"http://arxiv.org/abs/2504.07886v1","title":"Conformal product structures on compact Einstein manifolds","summary":"In this note we generalize our previous result, stating that if $(M_1,g_1)$\nand $(M_2,g_2)$ are compact Riemannian manifolds, then any Einstein metric on\nthe product $M:=M_1\\times M_2$ of the form $g=e^{2f_1}g_1+e^{2f_2}g_2$, with\n$f_1\\in C^\\infty(M_2)$ and $f_2\\in C^\\infty(M_1\\times M_2)$, is a warped\nproduct metric. Namely, we show that the same conclusion holds if we replace\nthe assumption that the manifold $M$ is globally the product of two compact\nmanifolds by the weaker assumption that $M$ is compact and carries a conformal\nproduct structure.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.07891v1","title":"SpecReason: Fast and Accurate Inference-Time Compute via Speculative\n  Reasoning","summary":"Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves 1.5-2.5$\\times$ speedup over vanilla LRM inference while improving\naccuracy by 1.0-9.9\\%. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional 19.4-44.2\\% latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T16:05:19Z"}
{"aid":"http://arxiv.org/abs/2504.07903v1","title":"Spectral delineation of Markov Generators: Classical vs Quantum","summary":"The celebrated theorem of Perron and Frobenius implies that spectra of\nclassical Markov operators, represented by stochastic matrices, are restricted\nto the unit disk. This property holds also for spectra of quantum stochastic\nmaps (quantum channels), which describe quantum Markovian evolution in discrete\ntime. Moreover, the spectra of stochastic $N \\times N$ matrices are\nadditionally restricted to a subset of the unit disk, called Karpelevi\\u{c}\nregion, the shape of which depends on $N$. We address the question of whether\nthe spectra of generators, which induce Markovian evolution in continuous time,\ncan be bound in a similar way. We propose a rescaling that allows us to answer\nthis question affirmatively. The eigenvalues of the rescaled classical\ngenerators are confined to the modified Karpelevi\\u{c} regions, whereas the\neigenvalues of the rescaled quantum generators fill the entire unit disk.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-10T16:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.07905v1","title":"From Winter Storm Thermodynamics to Wind Gust Extremes: Discovering\n  Interpretable Equations from Data","summary":"Reliably identifying and understanding temporal precursors to extreme wind\ngusts is crucial for early warning and mitigation. This study proposes a simple\ndata-driven approach to extract key predictors from a dataset of historical\nextreme European winter windstorms and derive simple equations linking these\nprecursors to extreme gusts over land. A major challenge is the limited\ntraining data for extreme events, increasing the risk of model overfitting.\nTesting various mitigation strategies, we find that combining dimensionality\nreduction, careful cross-validation, feature selection, and a nonlinear\ntransformation of maximum wind gusts informed by Generalized Extreme Value\ndistributions successfully reduces overfitting. These measures yield\ninterpretable equations that generalize across regions while maintaining\nsatisfactory predictive skill. The discovered equations reveal the association\nbetween a steady drying low-troposphere before landfall and wind gust intensity\nin Northwestern Europe.","main_category":"physics.ao-ph","categories":"physics.ao-ph,stat.AP","published":"2025-04-10T16:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.07913v1","title":"Optimal Control For Anti-Abeta Treatment in Alzheimer's Disease using a\n  Reaction-Diffusion Model","summary":"Alzheimer's disease is a progressive neurodegenerative disorder that\nsignificantly impairs patient survival and quality of life. While current\npharmacological treatments aim to slow disease progression, they remain\ninsufficient in halting cognitive decline. Mathematical modeling has emerged as\na powerful tool for understanding the dynamics of AD and optimizing treatment\nstrategies. However, most existing models focus on temporal dynamics using\nordinary differential equation-based approaches, often neglecting the critical\nrole of spatial heterogeneity in disease progression.\n  In this study, we employ a spatially explicit reaction-diffusion model to\ndescribe amyloid-beta (A beta) dynamics in the brain, incorporating treatment\noptimization while accounting for potential side effects. Our objective is to\nminimize amyloid-beta plaque concentration while balancing therapeutic efficacy\nagainst adverse effects, such as amyloid-related imaging abnormalities (ARIA).\nUnder specific assumptions, we establish the well-posedness and uniqueness of\nthe optimal solution. We employ numerical methods based on the Finite Element\nMethod to compute personalized treatment strategies, leveraging real patient\namyloid-beta positron emission tomography (PET) scan data.\n  Our results demonstrate that optimal treatment strategies outperform constant\ndosing regimens, achieving significant reductions in amyloid burden while\nminimizing side effects. By integrating spatial dynamics and personalized\ntreatment planning, our framework offers a novel approach to refining\ntherapeutic interventions for Alzheimer's disease.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T17:22:09Z"}
{"aid":"http://arxiv.org/abs/2504.07916v1","title":"Semantically Encoding Activity Labels for Context-Aware Human Activity\n  Recognition","summary":"Prior work has primarily formulated CA-HAR as a multi-label classification\nproblem, where model inputs are time-series sensor data and target labels are\nbinary encodings representing whether a given activity or context occurs. These\nCA-HAR methods either predicted each label independently or manually imposed\nrelationships using graphs. However, both strategies often neglect an essential\naspect: activity labels have rich semantic relationships. For instance,\nwalking, jogging, and running activities share similar movement patterns but\ndiffer in pace and intensity, indicating that they are semantically related.\nConsequently, prior CA-HAR methods often struggled to accurately capture these\ninherent and nuanced relationships, particularly on datasets with noisy labels\ntypically used for CA-HAR or situations where the ideal sensor type is\nunavailable (e.g., recognizing speech without audio sensors). To address this\nlimitation, we propose SEAL, which leverage LMs to encode CA-HAR activity\nlabels to capture semantic relationships. LMs generate vector embeddings that\npreserve rich semantic information from natural language. Our SEAL approach\nencodes input-time series sensor data from smart devices and their associated\nactivity and context labels (text) as vector embeddings. During training, SEAL\naligns the sensor data representations with their corresponding\nactivity/context label embeddings in a shared embedding space. At inference\ntime, SEAL performs a similarity search, returning the CA-HAR label with the\nembedding representation closest to the input data. Although LMs have been\nwidely explored in other domains, surprisingly, their potential in CA-HAR has\nbeen underexplored, making our approach a novel contribution to the field. Our\nresearch opens up new possibilities for integrating more advanced LMs into\nCA-HAR tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:30:07Z"}
{"aid":"http://arxiv.org/abs/2504.07917v1","title":"SKK groups of manifolds and non-unitary invertible TQFTs","summary":"This work considers the computation of controllable cut-and-paste groups\n$\\mathrm{SKK}^{\\xi}_n$ of manifolds with tangential structure $\\xi:B_n\\to\nBO_n$. To this end, we apply the work of Galatius-Madsen-Tillman-Weiss, Genauer\nand Schommer-Pries, who showed that for a wide range of structures $\\xi$ these\ngroups fit into a short exact sequence that relates them to bordism groups of\n$\\xi$-manifolds with kernel generated by the disc-bounding $\\xi$-sphere. The\norder of this sphere can be computed by knowing the possible values of the\nEuler characteristic of $\\xi$-manifolds. We are thus led to address two key\nquestions: the existence of $\\xi$-manifolds with odd Euler characteristic of a\ngiven dimension and conditions for the exact sequence to admit a splitting. We\nresolve these questions in a wide range of cases.\n  $\\mathrm{SKK}$ groups are of interest in physics as they play a role in the\nclassification of non-unitary invertible topological quantum field theories,\nwhich classify anomalies and symmetry protected topological (SPT) phases of\nmatter. Applying our topological results, we give a complete classification of\nnon-unitary invertible topological quantum field theories in the tenfold way in\ndimensions 1-5.","main_category":"math.AT","categories":"math.AT,math-ph,math.GT,math.MP","published":"2025-04-10T17:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.07928v1","title":"Riemann zeros and the KKR determinant","summary":"We transform the counting function for the Riemann zeros into a\nKorringa-Kohn-Rostoker (KKR) determinant, assisted by Krein's theorem. This is\nbased on our observation that the function derived from a few methods can all\nbe recast into two terms: one corresponds to the scattering phase, and the\nother is similar to structure constants related to the Green function. We also\ndiscuss the possible physical realizations. Our method provides a new physical\npathway towards the solution of the Riemann hypothesis.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.07929v1","title":"Market-Based Portfolio Selection","summary":"We show that Markowitz's (1952) decomposition of a portfolio variance as a\nquadratic form in the variables of the relative amounts invested into the\nsecurities, which has been the core of classical portfolio theory for more than\n70 years, is valid only in the approximation when all trade volumes with all\nsecurities of the portfolio are assumed constant. We derive the market-based\nportfolio variance and its decomposition by its securities, which accounts for\nthe impact of random trade volumes and is a polynomial of the 4th degree in the\nvariables of the relative amounts invested into the securities. To do that, we\ntransform the time series of market trades with the securities of the portfolio\nand obtain the time series of trades with the portfolio as a single market\nsecurity. The time series of market trades determine the market-based means and\nvariances of prices and returns of the portfolio in the same form as the means\nand variances of any market security. The decomposition of the market-based\nvariance of returns of the portfolio by its securities follows from the\nstructure of the time series of market trades of the portfolio as a single\nsecurity. The market-based decompositions of the portfolio's variances of\nprices and returns could help the managers of multi-billion portfolios and the\ndevelopers of large market and macroeconomic models like BlackRock's Aladdin,\nJP Morgan, and the U.S. Fed adjust their models and forecasts to the reality of\nrandom markets.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,q-fin.GN,q-fin.PM,q-fin.PR","published":"2025-04-10T17:44:57Z"}
{"aid":"http://arxiv.org/abs/2504.07933v1","title":"Geometric and Dosimetric Validation of Deformable Image Registration for\n  Prostate MR-guided Adaptive Radiotherapy","summary":"Objective: Quantify geometric and dosimetric accuracy of a novel prostate\nMR-to-MR deformable image registration (DIR) approach to support MR-guided\nadaptive radiation therapy dose accumulation.\n  Approach: We evaluated DIR accuracy in 25 patients treated with 30 Gy in 5\nfractions on a 1.5 T MR-linac using an adaptive workflow. A reference MR was\nused for planning, with three images collected at each fraction: adapt MR for\nadaptive planning, verify MR for pretreatment position verification and beam-on\nfor capturing anatomy during radiation delivery. We assessed three DIR\napproaches: intensity-based, intensity-based with controlling structures (CS)\nand novel intensity based with controlling structures and points of interest\n(CS+P). DIRs were performed between the reference and fraction images and\nwithin fractions. We propagated CTV, bladder, and rectum contours using the\nDIRs and compared to manual contours using Dice similarity coefficient, mean\ndistance to agreement (DTAmean), and dose-volume metrics.\n  Results: CS and CS+P improved geometric agreement between contours over\nintensity-only DIR. DTAmean for reference-to-beam-on intensity-only DIR was\n0.131+/-0.009cm (CTV), 0.46+/-0.08cm (bladder), and 0.154+/-0.013cm (rectum).\nFor the CS, the values were 0.018+/-0.002cm, 0.388+/-0.14cm, and\n0.036+/-0.013cm. For CS+P these values were 0.015+/-0.001cm, 0.025+/-0.004cm,\nand 0.021+/-0.002cm. Dosimetrically, comparing CS and CS+P for reference to\nbeam-on DIRs resulted in a change of CTV D98% from [-29cGy, 19cGy] to [-18cGy,\n26cGy], rectum D1cc from [-106cGy, 72cGy] to [-52cGy, 74cGy], and bladder D5cc\nfrom [-51cGy, 544cGy] to [-79cGy, 36cGy].\n  Significance: CS improved geometric and dosimetric accuracy over\nintensity-only DIR, with CS+P providing the most consistent performance.\nHowever, session image segmentation remains a challenge, which may be addressed\nwith automated contouring.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T17:47:47Z"}
{"aid":"http://arxiv.org/abs/2504.07937v1","title":"Baryon asymmetry constraints on magnetic field from the Electroweak\n  epoch","summary":"Decay of helical (hyper)magnetic fields that may have been present in the\nUniverse during the Electroweak epoch can contribute to generation of the\nbaryon asymmetry of the Universe. We revise constraints on the strength and\ncorrelation length of such fields from the requirement that their decay does\nnot lead to over-production of the baryon asymmetry. We show that the helical\nfields with strength down to 1e-5 of the maximal possible strength during the\nElectroweak epoch should have had their correlation at least ~1e-6 of the\nHubble radius during this epoch. For weaker fields this lower bound on the\ncorrelation length relaxes proportionally to the square of magnetic field\nstrength. A field with parameters saturating the bound may actually be\nresponsible for the baryon asymmetry observed today. We show that relic of such\na field, surviving in the present day Universe in the form of intergalactic\nmagnetic field detectable with Cherenkov Telescope Array Observatory, may have\nthe strength up to 10-100 pG and can have parameters needed to affect the\ncosmological recombination and relax the Hubble tension. We also show that\nthere is no constraint on the parameters of helical or non-helical magnetic\nfields stemming from the requirement that the baryon isocurvature perturbations\nproduced by such fields during the Electroweak epoch are within the\nobservational limits.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE","published":"2025-04-10T17:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.07962v1","title":"GLUS: Global-Local Reasoning Unified into A Single Large Language Model\n  for Video Segmentation","summary":"This paper proposes a novel framework utilizing multi-modal large language\nmodels (MLLMs) for referring video object segmentation (RefVOS). Previous\nMLLM-based methods commonly struggle with the dilemma between \"Ref\" and \"VOS\":\nthey either specialize in understanding a few key frames (global reasoning) or\ntracking objects on continuous frames (local reasoning), and rely on external\nVOS or frame selectors to mitigate the other end of the challenge. However, our\nframework GLUS shows that global and local consistency can be unified into a\nsingle video segmentation MLLM: a set of sparse \"context frames\" provides\nglobal information, while a stream of continuous \"query frames\" conducts local\nobject tracking. This is further supported by jointly training the MLLM with a\npre-trained VOS memory bank to simultaneously digest short-range and long-range\ntemporal information. To improve the information efficiency within the limited\ncontext window of MLLMs, we introduce object contrastive learning to\ndistinguish hard false-positive objects and a self-refined framework to\nidentify crucial frames and perform propagation. By collectively integrating\nthese insights, our GLUS delivers a simple yet effective baseline, achieving\nnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our\nproject page is at https://glus-video.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07966v1","title":"What it takes to solve the Hubble tension through scale-dependent\n  modifications of the primordial power spectrum","summary":"We investigate scale-dependent modifications to the primordial scalar power\nspectrum as potential solutions to the Hubble tension. We use the Fisher-bias\nformalism, recently adapted to examine perturbed recombination solutions to the\nHubble tension, and extend its range of validity with an iterative method. We\nfirst analyze the Planck cosmic microwave background (CMB) anisotropy data,\ndemonstrating the existence of modifications to the primordial power spectrum\ncapable of fully resolving the tension between Planck and SH0ES. As a proof of\nconcept, we interpret these solutions in terms of small, time-dependent\nvariations in the first slow roll parameter or in the sound speed of curvature\nperturbations during a stage of primordial inflation. However, these solutions\nare associated with a low total matter density $\\Omega_m$, which makes them\ninconsistent with baryon acoustic oscillations (BAO) and uncalibrated\nsupernovae (SNIa) data. When incorporating additional BOSS and PantheonPlus\ndata, the solutions that reduce the Hubble tension tend to overfit Planck CMB\ndata to compensate for the worsened fit to BAO and SNIa data, making them less\ncompelling. These findings suggest that modifying the primordial power spectrum\nalone is unlikely to provide a robust resolution to the tension and highlight\nhow the viability of such data-driven solutions depends on the specific\ndatasets considered, emphasizing the role of future high-precision observations\nin further constraining possible resolutions to the tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.09894v1","title":"A mechanical approach to facilitate the formation of dodecagonal\n  quasicrystals and their approximants","summary":"The conditions for forming quasicrystals and their approximants are\nstringent, normally requiring multiple length scales to stabilize the\nquasicrystalline order. Here we report an unexpected finding that the\napproximants and motifs of dodecagonal quasicrystals can be spontaneously\nformed in the simplest system of identical hard disks, utilizing the unstable\nfeature of the initial square packing subject to mechanical perturbations.\nBecause there is only one length scale involved, this finding challenges\nexisting theories of quasicrystals and their approximants. By applying the same\napproach to a system known to form a dodecagonal quasicrystal, we develop\ndecent quasicrystalline order in a purely mechanical manner. With the aid of\nthermal treatment, we achieve a significantly better quasicrystalline order\nthan that from the direct self-assembly of the liquid state within the same\nperiod of time. In sufficiently low temperatures where the self-assembly of a\nliquid is significantly hindered, our approach still promotes the formation of\nquasicrystals. Our study thus opens a venue for high-efficiency search and\nformation of quasicrystals, and may have broader implications for the design\nand synthesis of quasicrystalline materials.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T05:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.09898v1","title":"The Milky Way Project MOBStIRS: Parametrizing Infrared Stellar-Wind Bow\n  Shock Morphologies with Citizen Science","summary":"Mass-loss influences stellar evolution, especially for massive stars with\nstrong winds. Stellar wind bow shock nebulae driven by Galactic OB stars can be\nused to measure mass-loss rates ($\\dot{M}$). The standoff distance ($R_{0}$)\nbetween the star and the bow shock is set by momentum flux balance between the\nstellar wind and the surrounding interstellar medium (ISM). We created the\nMilky Way Project: MOBStIRS (Mass-loss rates for OB Stars driving IR bow\nShocks) using the online Zooniverse citizen science platform. We enlisted\nseveral hundred students to measure $R_0$ and two other projected shape\nparameters for 764 cataloged IR bow shocks. MOBStIRS incorporated 1528 JPEG\ncutout images produced from Spitzer GLIMPSE and MIPSGAL survey data.\nMeasurements were aggregated to compute shape parameters for each bow shock\nimage deemed high-quality by participants. The average statistical uncertainty\non $R_0$ is $12.5\\%$ but varies from ${<}5\\%$ to ${\\sim}40\\%$ among individual\nbow shocks, contributing significantly to the total error budget of $\\dot{M}$.\nThe derived nebular morphologies agree well with (magneto)hydrodynamic\nsimulations of bow shocks driven by the winds of OB stars moving at $V_a =\n10-40~km~s^{-1}$ with respect to the ambient interstellar medium (ISM). A\nsystematic correction to $R_0$ to account for viewing angle appears unnecessary\nfor computing $\\dot{M}$. Slightly more than half of MOBStIRS bow shocks are\nasymmetric, which could indicate anisotropic stellar winds, ISM clumping on\nsub-pc scales, time-dependent instabilities, and/or misalignments between the\nlocal ISM magnetic field and the star-bow shock axis.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-14T05:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.09903v1","title":"Refining Financial Consumer Complaints through Multi-Scale Model\n  Interaction","summary":"Legal writing demands clarity, formality, and domain-specific\nprecision-qualities often lacking in documents authored by individuals without\nlegal training. To bridge this gap, this paper explores the task of legal text\nrefinement that transforms informal, conversational inputs into persuasive\nlegal arguments. We introduce FinDR, a Chinese dataset of financial dispute\nrecords, annotated with official judgments on claim reasonableness. Our\nproposed method, Multi-Scale Model Interaction (MSMI), leverages a lightweight\nclassifier to evaluate outputs and guide iterative refinement by Large Language\nModels (LLMs). Experimental results demonstrate that MSMI significantly\noutperforms single-pass prompting strategies. Additionally, we validate the\ngeneralizability of MSMI on several short-text benchmarks, showing improved\nadversarial robustness. Our findings reveal the potential of multi-model\ncollaboration for enhancing legal document generation and broader text\nrefinement tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.09904v1","title":"LiteTracker: Leveraging Temporal Causality for Accurate Low-latency\n  Tissue Tracking","summary":"Tissue tracking plays a critical role in various surgical navigation and\nextended reality (XR) applications. While current methods trained on large\nsynthetic datasets achieve high tracking accuracy and generalize well to\nendoscopic scenes, their runtime performances fail to meet the low-latency\nrequirements necessary for real-time surgical applications. To address this\nlimitation, we propose LiteTracker, a low-latency method for tissue tracking in\nendoscopic video streams. LiteTracker builds on a state-of-the-art long-term\npoint tracking method, and introduces a set of training-free runtime\noptimizations. These optimizations enable online, frame-by-frame tracking by\nleveraging a temporal memory buffer for efficient feature reuse and utilizing\nprior motion for accurate track initialization. LiteTracker demonstrates\nsignificant runtime improvements being around 7x faster than its predecessor\nand 2x than the state-of-the-art. Beyond its primary focus on efficiency,\nLiteTracker delivers high-accuracy tracking and occlusion prediction,\nperforming competitively on both the STIR and SuPer datasets. We believe\nLiteTracker is an important step toward low-latency tissue tracking for\nreal-time surgical applications in the operating room.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.09905v1","title":"Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted\n  Positioning Approach","summary":"Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.09908v1","title":"Laser-induced spectral diffusion and excited-state mixing of silicon T\n  centres","summary":"To find practical application as photon sources for entangled optical\nresource states or as spin-photon interfaces in entangled networks,\nsemiconductor emitters must produce indistinguishable photons with high\nefficiency and spectral stability. Nanophotonic cavity integration increases\nefficiency and bandwidth, but it also introduces environmental charge\ninstability and spectral diffusion. Among various candidates, silicon colour\ncentres have emerged as compelling platforms for integrated-emitter quantum\ntechnologies. Here we investigate the dynamics of spectral wandering in\nnanophotonics-coupled, individual silicon T centres using spectral correlation\nmeasurements. We observe that spectral fluctuations are driven predominantly by\nthe near-infrared excitation laser, consistent with a power-dependent\nOrnstein-Uhlenbeck process, and show that the spectrum is stable for up to 1.5\nms in the dark. We demonstrate a 35x narrowing of the emitter linewidth to 110\nMHz using a resonance-check scheme and discuss the advantage for pairwise\nentanglement rates and optical resource state generators. Finally, we report\nlaser-induced spin-mixing in the excited state and discuss potential mechanisms\ncommon to both phenomena. These effects must be considered in calibrating T\ncentre devices for high-performance entanglement generation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T06:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.09910v1","title":"Learning to Erase Private Knowledge from Multi-Documents for\n  Retrieval-Augmented Large Language Models","summary":"Retrieval-Augmented Generation (RAG) is a promising technique for applying\nLLMs to proprietary domains. However, retrieved documents may contain sensitive\nknowledge, posing risks of privacy leakage in generative results. Thus,\neffectively erasing private information from retrieved documents is a key\nchallenge for RAG. Unlike traditional text anonymization, RAG should consider:\n(1) the inherent multi-document reasoning may face de-anonymization attacks;\n(2) private knowledge varies by scenarios, so users should be allowed to\ncustomize which information to erase; (3) preserving sufficient publicly\navailable knowledge for generation tasks. This paper introduces the privacy\nerasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which\neffectively removes user-defined private knowledge from documents while\npreserving sufficient public knowledge for generation. Specifically, we first\nconstruct a global knowledge graph to identify potential knowledge across\ndocuments, aiming to defend against de-anonymization attacks. Then we randomly\nsplit it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite\nthe retrieved documents excluding private triples. Finally, PPO algorithm\noptimizes the rewriting model to minimize private triples and maximize public\ntriples retention. Experiments on four QA datasets demonstrate that Eraser4RAG\nachieves superior erase performance than GPT-4o.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.09915v1","title":"StePO-Rec: Towards Personalized Outfit Styling Assistant via\n  Knowledge-Guided Multi-Step Reasoning","summary":"Advancements in Generative AI offers new opportunities for FashionAI,\nsurpassing traditional recommendation systems that often lack transparency and\nstruggle to integrate expert knowledge, leaving the potential for personalized\nfashion styling remain untapped. To address these challenges, we present PAFA\n(Principle-Aware Fashion), a multi-granular knowledge base that organizes\nprofessional styling expertise into three levels of metadata, domain\nprinciples, and semantic relationships. Using PAFA, we develop StePO-Rec, a\nknowledge-guided method for multi-step outfit recommendation. StePO-Rec\nprovides structured suggestions using a scenario-dimension-attribute framework,\nemploying recursive tree construction to align recommendations with both\nprofessional principles and individual preferences. A preference-trend\nre-ranking system further adapts to fashion trends while maintaining the\nconsistency of the user's original style. Experiments on the widely used\npersonalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in\nMAP. Furthermore, case studies highlight improved explainability, traceability,\nresult reliability, and the seamless integration of expertise and\npersonalization.","main_category":"cs.IR","categories":"cs.IR,cs.MM","published":"2025-04-14T06:24:56Z"}
{"aid":"http://arxiv.org/abs/2504.09930v1","title":"Multi-objective Bayesian Optimization With Mixed-categorical Design\n  Variables for Expensive-to-evaluate Aeronautical Applications","summary":"This work aims at developing new methodologies to optimize computational\ncostly complex systems (e.g., aeronautical engineering systems). The proposed\nsurrogate-based method (often called Bayesian optimization) uses adaptive\nsampling to promote a trade-off between exploration and exploitation. Our\nin-house implementation, called SEGOMOE, handles a high number of design\nvariables (continuous, discrete or categorical) and nonlinearities by combining\nmixtures of experts for the objective and/or the constraints. Additionally, the\nmethod handles multi-objective optimization settings, as it allows the\nconstruction of accurate Pareto fronts with a minimal number of function\nevaluations. Different infill criteria have been implemented to handle multiple\nobjectives with or without constraints. The effectiveness of the proposed\nmethod was tested on practical aeronautical applications within the context of\nthe European Project AGILE 4.0 and demonstrated favorable results. A first\nexample concerns a retrofitting problem where a comparison between two\noptimizers have been made. A second example introduces hierarchical variables\nto deal with architecture system in order to design an aircraft family. The\nthird example increases drastically the number of categorical variables as it\ncombines aircraft design, supply chain and manufacturing process. In this\narticle, we show, on three different realistic problems, various aspects of our\noptimization codes thanks to the diversity of the treated aircraft problems.","main_category":"cs.LG","categories":"cs.LG,math.OC,stat.AP","published":"2025-04-14T06:44:13Z"}
{"aid":"http://arxiv.org/abs/2504.09933v1","title":"On the $N$th $2$-adic complexity of binary sequences identified with\n  algebraic $2$-adic integers","summary":"We identify a binary sequence $\\mathcal{S}=(s_n)_{n=0}^\\infty$ with the\n$2$-adic integer $G_\\mathcal{S}(2)=\\sum\\limits_{n=0}^\\infty s_n2^n$. In the\ncase that $G_\\mathcal{S}(2)$ is algebraic over $\\mathbb{Q}$ of degree $d\\ge 2$,\nwe prove that the $N$th $2$-adic complexity of $\\mathcal{S}$ is at least\n$\\frac{N}{d}+O(1)$, where the implied constant depends only on the minimal\npolynomial of $G_\\mathcal{S}(2)$. This result is an analog of the bound of\nM\\'erai and the second author on the linear complexity of automatic sequences,\nthat is, sequences with algebraic $G_\\mathcal{S}(X)$ over the rational function\nfield $\\mathbb{F}_2(X)$. We further discuss the most important case $d=2$ in\nboth settings and explain that the intersection of the set of $2$-adic\nalgebraic sequences and the set of automatic sequences is the set of\n(eventually) periodic sequences. Finally, we provide some experimental results\nsupporting the conjecture that $2$-adic algebraic sequences can have also a\ndesirable $N$th linear complexity and automatic sequences a desirable $N$th\n$2$-adic complexity, respectively.","main_category":"math.NT","categories":"math.NT,cs.IT,math.IT","published":"2025-04-14T06:52:47Z"}
{"aid":"http://arxiv.org/abs/2504.09949v1","title":"Pseudo-Label Guided Real-World Image De-weathering: A Learning Framework\n  with Imperfect Supervision","summary":"Real-world image de-weathering aims at removingvarious undesirable\nweather-related artifacts, e.g., rain, snow,and fog. To this end, acquiring\nideal training pairs is crucial.Existing real-world datasets are typically\nconstructed paired databy extracting clean and degraded images from live\nstreamsof landscape scene on the Internet. Despite the use of strictfiltering\nmechanisms during collection, training pairs inevitablyencounter inconsistency\nin terms of lighting, object position, scenedetails, etc, making de-weathering\nmodels possibly suffer fromdeformation artifacts under non-ideal supervision.\nIn this work,we propose a unified solution for real-world image\nde-weatheringwith non-ideal supervision, i.e., a pseudo-label guided\nlearningframework, to address various inconsistencies within the realworld\npaired dataset. Generally, it consists of a de-weatheringmodel (De-W) and a\nConsistent Label Constructor (CLC), bywhich restoration result can be\nadaptively supervised by originalground-truth image to recover sharp textures\nwhile maintainingconsistency with the degraded inputs in non-weather\ncontentthrough the supervision of pseudo-labels. Particularly, a Crossframe\nSimilarity Aggregation (CSA) module is deployed withinCLC to enhance the\nquality of pseudo-labels by exploring thepotential complementary information of\nmulti-frames throughgraph model. Moreover, we introduce an Information\nAllocationStrategy (IAS) to integrate the original ground-truth imagesand\npseudo-labels, thereby facilitating the joint supervision forthe training of\nde-weathering model. Extensive experimentsdemonstrate that our method exhibits\nsignificant advantageswhen trained on imperfectly aligned de-weathering\ndatasets incomparison with other approaches.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-14T07:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.09988v1","title":"Equivariant bordism classification of five-dimensional\n  $(\\mathbb{Z}_2)^3$-manifolds with isolated fixed points","summary":"Denote by $\\mathcal{Z}_5((\\mathbb{Z}_2)^3)$ the group, which is also a vector\nspace over $\\mathbb{Z}_2$, generated by equivariant unoriented bordism classes\nof all five-dimensional closed smooth manifolds with effective smooth\n$(\\mathbb{Z}_2)^3$-actions fixing isolated points. We show that\n$\\dim_{\\mathbb{Z}_2} \\mathcal{Z}_5((\\mathbb{Z}_2)^3) = 77$ and determine a\nbasis of $\\mathcal{Z}_5((\\mathbb{Z}_2)^3)$, each of which is explicitly chosen\nas the projectivization of a real vector bundle. Thus this gives a complete\nclassification up to equivariant unoriented bordism of all five-dimensional\nclosed smooth manifolds with effective smooth $(\\mathbb{Z}_2)^3$-actions with\nisolated fixed points.","main_category":"math.AT","categories":"math.AT","published":"2025-04-14T08:52:27Z"}
{"aid":"http://arxiv.org/abs/2504.09993v1","title":"AimTS: Augmented Series and Image Contrastive Learning for Time Series\n  Classification","summary":"Time series classification (TSC) is an important task in time series\nanalysis. Existing TSC methods mainly train on each single domain separately,\nsuffering from a degradation in accuracy when the samples for training are\ninsufficient in certain domains. The pre-training and fine-tuning paradigm\nprovides a promising direction for solving this problem. However, time series\nfrom different domains are substantially divergent, which challenges the\neffective pre-training on multi-source data and the generalization ability of\npre-trained models. To handle this issue, we introduce Augmented Series and\nImage Contrastive Learning for Time Series Classification (AimTS), a\npre-training framework that learns generalizable representations from\nmulti-source time series data. We propose a two-level prototype-based\ncontrastive learning method to effectively utilize various augmentations in\nmulti-source pre-training, which learns representations for TSC that can be\ngeneralized to different domains. In addition, considering augmentations within\nthe single time series modality are insufficient to fully address\nclassification problems with distribution shift, we introduce the image\nmodality to supplement structural information and establish a series-image\ncontrastive learning to improve the generalization of the learned\nrepresentations for TSC tasks. Extensive experiments show that after\nmulti-source pre-training, AimTS achieves good generalization performance,\nenabling efficient learning and even few-shot learning on various downstream\nTSC datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:55:16Z"}
{"aid":"http://arxiv.org/abs/2504.09996v1","title":"Nonlinear transport of Wigner solid phase surrounding the two-flux\n  composite fermion liquid","summary":"We have investigated the low temperature (T) transport properties of\nfractional quantum Hall (FQH) states in a high-mobility two-dimensional hole\ngas. According to the composite fermion (CF) model, FQH states stemming from a\nhalf-filled Landau level, specifically at filling factors ${\\nu}=p/(2p+1)\n(p=\\pm 1,\\pm 2,\\pm 3,...)$, can be associated with two-flux-attached CFs at the\ncorresponding Lambda filling factor p. The zero-resistance minima and Hall\nplateaus of these states exhibit unusual temperature dependencies,\ncharacterized by rapid increases in width below a threshold temperature around\n100 mK. Differential conductivity measurements from Corbino samples reveal that\nthe regimes surrounding the CF liquid display clear nonlinear transport\ncharacteristics. This nonlinearity implies that each CF liquid is surrounded by\nCF solid phase composed of dilute CF excitations. Quantitatively, the applied\nelectric field E influences the motion of CF solid in a way analogous to T,\nwhich is dubbed the \"E-T duality\". Our analysis indicates that this E-T duality\nis consistent with the Berezinskii-Kosterlitz-Thouless theory in\ntwo-dimensional phase transitions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T09:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.10033v1","title":"The law of large numbers for discrete generalized quantum channels","summary":"We consider random linear operators $\\Omega \\to \\mathcal{L}(\\mathcal{T}_p,\n\\mathcal{T}_p)$ acting in a $p$-th Schatten class $\\mathcal{T}_p$ in a\nseparable Hilbert space $\\mathcal{H}$ for some $1 \\leqslant p < \\infty$. Such a\nsuperoperator is called a pre-channel since it is an extension of a quantum\nchannel to a wider class of operators without requirements of trace-preserving\nand positivity. Instead of the sum of i.i.d. variables there may be considered\nthe composition of random semigroups $e^{A_i t/n}$ in the Banach space\n$\\mathcal{T}_p$. The law of large numbers is known in the case $p=2$ in the\nform of the usual law of large numbers for random operators in a Hilbert space.\nWe obtain the law of large numbers for the case $1\\leqslant p \\leqslant 2$.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-14T09:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.10042v1","title":"Search for $B^0 \\to K^{\\ast 0} ^+ ^-$ decays at the Belle II\n  experiment","summary":"We present a search for the rare flavor-changing neutral-current decay $B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-$ with data collected by the Belle II experiment at\nthe SuperKEKB electron-positron collider. The analysis uses a 365 fb$^{-1}$\ndata sample recorded at the center-of-mass energy of the $\\Upsilon(4S)$\nresonance. One of the $B$ mesons produced in the $\\Upsilon(4S)\\to B^0\n\\bar{B}^0$ process is fully reconstructed in a hadronic decay mode, while its\ncompanion $B$ meson is required to decay into a $K^{\\ast 0}$ and two $\\tau$\nleptons of opposite charge. The $\\tau$ leptons are reconstructed in final\nstates with a single electron, muon, charged pion or charged $\\rho$ meson, and\nadditional neutrinos. We set an upper limit on the branching ratio of $BR(B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-) < 1.8 \\times 10^{-3}$ at the 90% confidence\nlevel, which is the most stringent constraint reported to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-14T09:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.10055v1","title":"Joint Action Language Modelling for Transparent Policy Execution","summary":"An agent's intention often remains hidden behind the black-box nature of\nembodied policies. Communication using natural language statements that\ndescribe the next action can provide transparency towards the agent's behavior.\nWe aim to insert transparent behavior directly into the learning process, by\ntransforming the problem of policy learning into a language generation problem\nand combining it with traditional autoregressive modelling. The resulting model\nproduces transparent natural language statements followed by tokens\nrepresenting the specific actions to solve long-horizon tasks in the\nLanguage-Table environment. Following previous work, the model is able to learn\nto produce a policy represented by special discretized tokens in an\nautoregressive manner. We place special emphasis on investigating the\nrelationship between predicting actions and producing high-quality language for\na transparent agent. We find that in many cases both the quality of the action\ntrajectory and the transparent statement increase when they are generated\nsimultaneously.","main_category":"cs.RO","categories":"cs.RO,cs.CL","published":"2025-04-14T09:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.10058v1","title":"Data Cooperatives: Democratic Models for Ethical Data Stewardship","summary":"Data cooperatives offer a new model for fair data governance, enabling\nindividuals to collectively control, manage, and benefit from their information\nwhile adhering to cooperative principles such as democratic member control,\neconomic participation, and community concern. This paper reviews data\ncooperatives, distinguishing them from models like data trusts, data commons,\nand data unions, and defines them based on member ownership, democratic\ngovernance, and data sovereignty. It explores applications in sectors like\nhealthcare, agriculture, and construction. Despite their potential, data\ncooperatives face challenges in coordination, scalability, and member\nengagement, requiring innovative governance strategies, robust technical\nsystems, and mechanisms to align member interests with cooperative goals. The\npaper concludes by advocating for data cooperatives as a sustainable,\ndemocratic, and ethical model for the future data economy.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T10:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.10068v1","title":"Mavors: Multi-granularity Video Representation for Multimodal Large\n  Language Model","summary":"Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-14T10:14:44Z"}
{"aid":"http://arxiv.org/abs/2504.10069v1","title":"Relativistic Quantum Simulation of Hydrogen Sulfide for Hydrogen Energy\n  via Hybrid Quantum-Classical Algorithms","summary":"We present a relativistic quantum simulation framework for modeling hydrogen\nsulfide (H2S) decomposition relevant to hydrogen energy applications. The\napproach integrates Dirac-Coulomb relativistic quantum chemistry with the\nvariational quantum eigensolver (VQE), implemented on a hybrid\nquantum-classical architecture. Using quantum algorithms based on Jordan-Wigner\nencoding and relativistic integrals, we simulate ground-state energies and\npotential energy surfaces for H2, H2O, and H2S molecules. Results demonstrate\nthat the relativistic VQE correctly reproduces known energy shifts and\nmolecular trends. Optimizer performance, energy variance, and Pauli term\ncomplexity are also evaluated. The findings offer insight into scalable quantum\nsimulations of chemically and physically significant systems involving heavy\natoms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T10:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.10076v1","title":"Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian\n  Neural Networks","summary":"Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T10:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.10101v1","title":"The Human Visual System Can Inspire New Interaction Paradigms for LLMs","summary":"The dominant metaphor of LLMs-as-minds leads to misleading conceptions of\nmachine agency and is limited in its ability to help both users and developers\nbuild the right degree of trust and understanding for outputs from LLMs. It\nmakes it harder to disentangle hallucinations from useful model interactions.\nThis position paper argues that there are fundamental similarities between\nvisual perception and the way LLMs process and present language. These\nsimilarities inspire a metaphor for LLMs which could open new avenues for\nresearch into interaction paradigms and shared representations. Our visual\nsystem metaphor introduces possibilities for addressing these challenges by\nunderstanding the information landscape assimilated by LLMs. In this paper we\nmotivate our proposal, introduce the interrelating theories from the fields\nthat inspired this view and discuss research directions that stem from this\nabstraction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.10114v1","title":"$t$-$J$ model for strongly correlated two-orbital systems: Application\n  to bilayer nickelate superconductors","summary":"We derive a $t$-$J$ model applicable to strongly correlated two-orbital\nsystems including bilayer nickelate superconductors. Using the Schrieffer-Wolff\ntransformation, we exclude the doubly occupied states raising the on-site\nCoulomb energy and derive resulting spin interactions from the two-orbital\nHubbard model. We also introduce effective interactions attributed to the\ninterorbital Coulomb interaction. To adapt the effective model to bilayer\nnickelates that exhibit high-temperature superconductivity, we quantitatively\nevaluate the strengths of the spin interactions based on the hopping parameters\nin La$_3$Ni$_2$O$_7$. Considering the evaluated effective interactions, we\npropose a simplified $t$-$J$ model for bilayer nickelate superconductors.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-14T11:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10132v1","title":"Asymptotic Optimality of Projected Inventory Level Policies for Lost\n  Sales Inventory Systems with Large Leadtime and Penalty Cost","summary":"We study the canonical periodic review lost sales inventory system with\npositive leadtime and independent and identically distributed (i.i.d.) demand\nunder the average cost criterion. We demonstrate that the relative value\nfunction under the constant order policy satisfies the Wiener-Hopf equation. We\nemploy ladder processes associated with a random walk featuring i.i.d.\nincrements, to obtain an explicit solution for the relative value function.\nThis solution can be expressed as a quadratic form and a term that grows\nsublinearly. Then we perform an approximate policy iteration step on the\nconstant order policy and bound the approximation errors as a function of the\ncost of losing a sale. This leads to our main result that projected inventory\nlevel policies are asymptotically optimal as the leadtime grows when the cost\nof losing a sale is sufficiently large and demand has a finite second moment.\nUnder these conditions, we also show that the optimal cost rate approaches\ninfinity, proportional to the square root of the cost of losing a sale.","main_category":"math.PR","categories":"math.PR,math.OC,G.3","published":"2025-04-14T11:38:35Z"}
{"aid":"http://arxiv.org/abs/2504.10147v1","title":"A Survey of Personalization: From RAG to Agent","summary":"Personalization has become an essential capability in modern AI systems,\nenabling customized interactions that align with individual user preferences,\ncontexts, and goals. Recent research has increasingly concentrated on\nRetrieval-Augmented Generation (RAG) frameworks and their evolution into more\nadvanced agent-based architectures within personalized settings to enhance user\nsatisfaction. Building on this foundation, this survey systematically examines\npersonalization across the three core stages of RAG: pre-retrieval, retrieval,\nand generation. Beyond RAG, we further extend its capabilities into the realm\nof Personalized LLM-based Agents, which enhance traditional RAG systems with\nagentic functionalities, including user understanding, personalized planning\nand execution, and dynamic generation. For both personalization in RAG and\nagent-based personalization, we provide formal definitions, conduct a\ncomprehensive review of recent literature, and summarize key datasets and\nevaluation metrics. Additionally, we discuss fundamental challenges,\nlimitations, and promising research directions in this evolving field. Relevant\npapers and resources are continuously updated at\nhttps://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:57:52Z"}
{"aid":"http://arxiv.org/abs/2504.10153v1","title":"Searching for quasi-periodicities in short transients: the curious case\n  of GRB 230307A","summary":"Gamma-ray bursts (GRBs) are the most powerful explosions in the Universe;\ntheir energy release reache s us from the end of the re-ionization era, making\nthem invaluable cosmological probes. GRB 230307A i s the second-brightest GRB\never observed in the 56 years of observations since the discovery of the\nphenomenon in 1967. Follow-up observations of the event at longer wavelengths\nrevealed a lanthanide-ri ch kilonova with long-lasting X-ray emission\nimmediately following the prompt gamma-rays. Moreover, t he gamma-ray light\ncurve of GRB 230307A collected with INTEGRAL's SPectrometer of INTEGRAL\nAntiCoincidence Shield (SPI-ACS) and Fermi's Gamma-Ray Burst Monitor (GBM). We\nuse Fourier analysis, wavelets and Gaussian Processes to search for periodic\nand quasi-periodic oscillations (QPOs) in the prompt gamma-ray emission of GRB\n230307A. We critically assess all three methods in terms of their robustness\nfor detections of QPOs in fast transients such as GRBs. Our analyses reveal\nQPOs at a frequency of $\\sim 1.2$ Hz (0.82s period) near the burst's peak\nemission phase, consistent across instruments and detection methods. We also\nidentify a second, less significant QPO at $\\sim 2.9$ Hz (0.34s) nearly\nsimultaneously. We hypothesise that the two QPOs originate from the transition\nepoch at the end of the jet acceleration phase. These QPOs re present plasma\ncirculation periods in vorticity about the jet axis carried outwards to the\nprompt radiation zone at much larger radii. They are sampled by colliding\nstructures (e.g., shocks) in the spinning jet, possibly marking the evolution\nof plasma rotation during the final stages of the progenitor neutron star\ncoalescence event.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T12:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.10154v1","title":"The energy content of Alfven waves in the stratified solar atmosphere","summary":"Alfven waves propagating in a vertically stratified plasma, such as those\ntravelling from the solar photosphere to the corona, are partially reflected\ndue to the gradient in the Alfven speed. Wave reflection naturally results in\nthe superposition of upward- and downward-propagating waves. A simple analytic\nmodel demonstrates that this superposition leads to the non-equipartition of\nkinetic and magnetic energies in the Alfven wave perturbations and slows down\nthe net energy transport. A numerical model of Alfven wave propagation in the\nlower solar atmosphere reveals significant wave reflection below the transition\nregion, leading to highly variable kinetic and magnetic energy content in the\nlower chromosphere. At higher altitudes, the kinetic energy eventually\ndominates, depending on the wave frequency. The velocity at which net energy\npropagates upward is significantly smaller than the local Alfven speed\nthroughout the chromosphere. Consequently, the commonly used expression for\nunidirectional Alfven waves in a uniform plasma, which relates the energy flux\nto the kinetic energy density, is not generally applicable in the stratified\nlower solar atmosphere and cannot be reliably used to estimate the energy\ncontent of observed waves. A generalized expression is given, incorporating\ncorrection factors that account for wave reflection and energy\nnon-equipartition. The applicability of the expression is discussed.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T12:07:51Z"}
{"aid":"http://arxiv.org/abs/2504.10155v1","title":"A Buium--Coleman bound for the Mordell--Lang conjecture","summary":"For $X$ a hyperbolic curve of genus $g$ with good reduction at $p\\geq 2g$, we\ngive an explicit bound on the Mordell--Lang locus $X(\\mathbb{C})\\cap \\Gamma $,\nwhen $\\Gamma \\subset J(\\mathbb{C})$ is the divisible hull of a subgroup of\n$J(\\mathbb{Q} _p ^{\\mathrm{nr}})$ of rank less than $g$. Without any\nassumptions on the rank (but with all the other assumptions) we show that\n$X(\\mathbb{C})\\cap \\Gamma $ is unramified at $p$, and bound the size of its\nimage in $X(\\overline{\\mathbb{F} }_p )$. As a corollary, we show that Mordell\nimplies Mordell--Lang for curves.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-14T12:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.10157v1","title":"SocioVerse: A World Model for Social Simulation Powered by LLM Agents\n  and A Pool of 10 Million Real-World Users","summary":"Social simulation is transforming traditional social science research by\nmodeling human behavior through interactions between virtual individuals and\ntheir environments. With recent advances in large language models (LLMs), this\napproach has shown growing potential in capturing individual differences and\npredicting group behaviors. However, existing methods face alignment challenges\nrelated to the environment, target users, interaction mechanisms, and\nbehavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven\nworld model for social simulation. Our framework features four powerful\nalignment components and a user pool of 10 million real individuals. To\nvalidate its effectiveness, we conducted large-scale simulation experiments\nacross three distinct domains: politics, news, and economics. Results\ndemonstrate that SocioVerse can reflect large-scale population dynamics while\nensuring diversity, credibility, and representativeness through standardized\nprocedures and minimal manual adjustments.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-14T12:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.10162v1","title":"When Do We Feel Present in a Virtual Reality? Towards Sensitivity and\n  User Acceptance of Presence Questionnaires","summary":"Presence is an important and widely used metric to measure the quality of\nvirtual reality (VR) applications. Given the multifaceted and subjective nature\nof presence, the most common measures for presence are questionnaires. But\nthere is little research on their validity regarding specific presence\ndimensions and their responsiveness to differences in perception among users.\nWe investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their\nresponsiveness to intensity variations of known presence dimensions and asked\nusers about their consistency with their experience. Therefore, we created five\nVR scenarios that were designed to emphasize a specific presence dimension. Our\nfindings showed heterogeneous sensitivity of the questionnaires dependent on\nthe different dimensions of presence. This highlights a context-specific\nsuitability of presence questionnaires. The questionnaires' sensitivity was\nfurther stated as lower than actually perceived. Based on our findings, we\noffer guidance on selecting these questionnaires based on their suitability for\nparticular use cases.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.10184v1","title":"Dispatching Odyssey: Exploring Performance in Computing Clusters under\n  Real-world Workloads","summary":"Recent workload measurements in Google data centers provide an opportunity to\nchallenge existing models and, more broadly, to enhance the understanding of\ndispatching policies in computing clusters. Through extensive data-driven\nsimulations, we aim to highlight the key features of workload traffic traces\nthat influence response time performance under simple yet representative\ndispatching policies. For a given computational power budget, we vary the\ncluster size, i.e., the number of available servers. A job-level analysis\nreveals that Join Idle Queue (JIQ) and Least Work Left (LWL) exhibit an optimal\nworking point for a fixed utilization coefficient as the number of servers is\nvaried, whereas Round Robin (RR) demonstrates monotonously worsening\nperformance. Additionally, we explore the accuracy of simple G/G queue\napproximations. When decomposing jobs into tasks, interesting results emerge;\nnotably, the simpler, non-size-based policy JIQ appears to outperform the more\n\"powerful\" size-based LWL policy. Complementing these findings, we present\npreliminary results on a two-stage scheduling approach that partitions tasks\nbased on service thresholds, illustrating that modest architectural\nmodifications can further enhance performance under realistic workload\nconditions. We provide insights into these results and suggest promising\ndirections for fully explaining the observed phenomena.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T12:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.10209v1","title":"Continuity of differential operators for nonarchimedean Banach algebras","summary":"Given a nonarchimedean field $K$ and a commutative, noetherian, Banach\n$K$-algebra $A$, we study continuity of $K$-linear differential operators (in\nthe sense of Grothendieck) between finitely generated Banach $A$-modules. When\n$K$ is of characteristic zero we show that every such operator is continuous if\nand only if $A/\\mathfrak{m}$ is a finite extension of $K$ for every maximal\nideal $\\mathfrak{m}\\subset A$.","main_category":"math.AG","categories":"math.AG,math.FA","published":"2025-04-14T13:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.10222v1","title":"PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam\n  Annealing Search","summary":"Recent work increasingly focuses on improving the reasoning capabilities of\nMultimodal Large Language Models (MLLMs). Among existing methods, Process\nReward Models (PRMs) stand out for offering dense, step-wise supervision to\nguide intermediate reasoning. However, how to effectively integrate PRMs into\nsearch strategies remains an open question. In this paper, we introduce PRM-BAS\n(PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided\nreasoning that dynamically adjusts beam size -- starting with a broader search\nspace and gradually narrowing it as contextual information accumulates, thereby\nbalancing performance and efficiency. We further propose a unified framework\nfor data construction and PRM training. Specifically, we construct the\nPRM-BAS-300k dataset by selecting 300k questions from existing datasets and\nperforming rollouts at each step to estimate the probability of reaching a\ncorrect final answer. The PRM is then trained using a combination of value loss\nfor absolute action quality and rank loss for relative action quality.\nExtensive experiments on challenging multimodal reasoning benchmarks\ndemonstrate that PRM-BAS significantly improves reasoning performance while\nmaintaining low computational cost. Moreover, it generalizes well across\ndifferent model scales and architectures, showcasing strong robustness and\nplug-and-play capability.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T13:44:11Z"}
{"aid":"http://arxiv.org/abs/2504.10230v1","title":"Extracting cosmological information from the abundance of galaxy\n  clusters with simulation-based inference","summary":"The abundance of galaxy clusters as a function of mass and redshift is a\nwell-established and powerful cosmological probe. Cosmological analyses based\non galaxy cluster number counts have traditionally relied on explicitly\ncomputed likelihoods, which are often challenging to develop with the required\naccuracy and expensive to evaluate. In this work, we implement an alternative\napproach based on simulation-based inference (SBI) methods that relies solely\non synthetic galaxy cluster catalogues generated under a given model. These\ncatalogues are much easier to produce than it is to develop and validate a\nlikelihood. We validate this approach in the context of the galaxy cluster\nsurvey of the upcoming Simons Observatory for a setup in which we can also\nevaluate an exact explicit likelihood. We find that our SBI-based approach\nyields cosmological parameter posterior means that are within $0.2\\,\\sigma$ of\nthose obtained with the explicit likelihood and with biases smaller than\n$0.1\\,\\sigma$. We also introduce and validate a procedure to assess the\ngoodness of fit using only synthetic catalogues similar to those used for\ntraining. This demonstrates, for the first time, that a galaxy cluster number\ncount cosmological analysis can be performed fully without resorting to a\nlikelihood at any stage. Finally, we apply our SBI-based approach to the real\nPlanck MMF3 cosmology sample, obtaining cosmological parameter constraints that\nare within $0.1\\,\\sigma$ of their likelihood-based counterparts. This\nconstitutes the first SBI-based number count cosmological analysis of a real\ngalaxy cluster catalogue.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T13:51:55Z"}
{"aid":"http://arxiv.org/abs/2504.10238v1","title":"Highly Hydrogenated Monolayer Graphene with Wide Band Gap Opening","summary":"A thorough spectroscopic characterisation of highly hydrogenated monolayer\ngraphene trasferred on TEM grids is herein reported. The graphene hydrogenation\nhas the effect to distort the $sp^2$ arrangement of carbon atoms in the lattice\ntoward a $sp^3$-like coordination, through the breaking of the $\\pi$-bonds, as\ndetermined by X ray photoelectron spectroscopy of the C 1s core level. The\nhydrogen bonding was found to be favoured for a more distorted graphene\nlattice. Indeed, a 100$\\%$ $sp^3$-saturation - the highest ever achieved - was\nobserved after the hydrogenation of a sample with more pristine $sp^3$-like\ndeformed bonds, while the flatter, more $sp^2$-arranged, sample reached a\n59$\\%$ $sp^3$-saturation. Electron energy loss spectroscopy confirmed the\nphotoemission result showing the $\\pi$-plasmon excitation quenching, in the\ntotally hydrogenated sample, and significant reduction, for the other one. High\nloading levels of hydrogenation were also witnessed by the opening of a wide\noptical band gap (6.3 and 6.2 eV). The observation of the C-H stretching\nvibrational mode is also reported, as a direct footprint of graphene\nhydrogenation. Finally, valence band measurements of the 59$\\%$ saturated\nsample suggest the coexistence of one-side and two-side hydrogenation\nmorphologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T14:01:40Z"}
{"aid":"http://arxiv.org/abs/2504.10247v1","title":"Exponentially Decaying Quantum Simulation Error with Noisy Devices","summary":"Quantum simulation is a promising way toward practical quantum advantage, but\nnoise in current quantum hardware poses a significant obstacle. We\ntheoretically and numerically revealed that not only the physical error but\nalso the algorithmic error in a single Trotter step decreases exponentially\nwith the circuit depth. In particular, according to our results, we derive the\noptimal number of Trotter steps and the noise requirement to guarantee total\nsimulation precision. At last, we demonstrate that our improved error analysis\nleads to significant resource-saving for fault-tolerant Trotter simulation. By\naddressing these aspects, this work systematically characterizes the robustness\nof Trotter simulation errors in noisy quantum devices and paves the way toward\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T14:10:24Z"}
{"aid":"http://arxiv.org/abs/2504.10254v1","title":"MASSeg : 2nd Technical Report for 4th PVUW MOSE Track","summary":"Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T14:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.10264v1","title":"Multidimensional non-uniform hyperbolicity, robust exponential mixing\n  and the basin problem","summary":"We show that the ergodic, topological and geometric basins coincide for\nhyperbolic dominated ergodic $cu$-Gibbs states, solving the ``basin problem''\nfor a wide class of non-uniformly hyperbolic systems.\n  We obtain robust examples of exponential mixing physical measures for systems\nwith multidimensional nonuniform hyperbolic dominated splitting, without\nuniformly expanding or contracting subbundles.\n  Both results are a consequence of extending the construction of\nGibbs-Markov-Young structures from partial hyperbolic systems to systems with\nonly a dominated splitting, using the existence of an ``improved hyperbolic\nblock'', with respect to Pesin's Nonuniform Hyperbolic Theory, for hyperbolic\ndominated measures of smooth maps, obtained through hyperbolic times and\nassociated ``coherent schedules'' introduced by one of the coauthors.","main_category":"math.DS","categories":"math.DS","published":"2025-04-14T14:29:23Z"}
{"aid":"http://arxiv.org/abs/2504.10283v1","title":"$$-Flow: A Unified Framework for Continuous-State Discrete Flow\n  Matching Models","summary":"Recent efforts have extended the flow-matching framework to discrete\ngenerative modeling. One strand of models directly works with the continuous\nprobabilities instead of discrete tokens, which we colloquially refer to as\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\nsignificantly in their representations and geometric assumptions. This work\npresents a unified framework for CS-DFM models, under which the existing\nvariants can be understood as operating on different $\\alpha$-representations\nof probabilities. Building upon the theory of information geometry, we\nintroduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the\ncanonical $\\alpha$-geometry of the statistical manifold, and demonstrate its\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\nthat the flow matching loss for $\\alpha$-flow establishes a unified variational\nbound for the discrete negative log-likelihood. We comprehensively evaluate\ndifferent instantiations of $\\alpha$-flow on various discrete generation\ndomains to demonstrate their effectiveness in discrete generative modeling,\nincluding intermediate values whose geometries have never been explored before.\n$\\alpha$-flow significantly outperforms its discrete-state counterpart in image\nand protein sequence generation and better captures the entropy in language\nmodeling.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.10286v1","title":"Characterizing LLM-driven Social Network: The Chirper.ai Case","summary":"Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-14T14:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.10289v1","title":"Optimal Graph Stretching for Distributed Averaging","summary":"The performance of distributed averaging depends heavily on the underlying\ntopology. In various fields, including compressed sensing, multi-party\ncomputation, and abstract graph theory, graphs may be expected to be free of\nshort cycles, i.e. to have high girth. Though extensive analyses and heuristics\nexist for optimising the performance of distributed averaging in general\nnetworks, these studies do not consider girth. As such, it is not clear what\nhappens to convergence time when a graph is stretched to a higher girth.\n  In this work, we introduce the optimal graph stretching problem, wherein we\nare interested in finding the set of edges for a particular graph that ensures\noptimal convergence time under constraint of a minimal girth. We compare\nvarious methods for choosing which edges to remove, and use various convergence\nheuristics to speed up the searching process. We generate many graphs with\nvarying parameters, stretch and optimise them, and measure the duration of\ndistributed averaging. We find that stretching by itself significantly\nincreases convergence time. This decrease can be counteracted with a subsequent\nrepair phase, guided by a convergence time heuristic. Existing heuristics are\ncapable, but may be suboptimal.","main_category":"cs.DC","categories":"cs.DC,cs.DM","published":"2025-04-14T15:01:24Z"}
{"aid":"http://arxiv.org/abs/2504.10303v1","title":"Row completion of polynomial and rational matrices","summary":"We characterize the existence of a polynomial (rational) matrix when its\neigenstructure (complete structural data) and some of its rows are prescribed.\nFor polynomial matrices, this problem was solved in a previous work when the\npolynomial matrix has the same degree as the prescribed submatrix. In that\npaper, the following row completion problems were also solved arising when the\neigenstructure was partially prescribed, keeping the restriction on the degree:\nthe eigenstructure but the row (column) minimal indices, and the finite and/or\ninfinite structures. Here we remove the restriction on the degree, allowing it\nto be greater than or equal to that of the submatrix. We also generalize the\nresults to rational matrices. Obviously, the results obtained hold for the\ncorresponding column completion problems.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T15:11:19Z"}
{"aid":"http://arxiv.org/abs/2504.10304v1","title":"Extended-BMS Anomalies and Flat Space Holography","summary":"We classify the Lagrangians and anomalies of an extended BMS field theory\nusing BRST methods. To do so, we establish an intrinsic gauge-fixing procedure\nfor the geometric data, which allows us to derive the extended BMS symmetries\nand the correct transformation law of the shear, encoded in the connection. Our\nanalysis reveals that the invariant Lagrangians are always topological, thereby\nreducing the 4d bulk to a 2d boundary theory. Moreover, we find that\nsupertranslations are anomaly-free, while superrotations exhibit independent\ncentral charges. This BMS field theory is dual to Einstein gravity in\nasymptotically flat spacetimes when the superrotation anomalies coincide and\nare dictated by the bulk. Meanwhile, the absence of supertranslation anomalies\naligns with Weinberg's soft graviton theorem being tree-level exact. This work\nprovides a first-principle derivation of the structure of the null boundary\nfield theory, intrinsic and independent of bulk considerations, offering\nfurther evidence for the holographic principle in flat space, and its\ndimensional reduction.","main_category":"hep-th","categories":"hep-th,gr-qc,math-ph,math.MP","published":"2025-04-14T15:12:30Z"}
{"aid":"http://arxiv.org/abs/2504.10312v1","title":"Investigating two-zero texture in the light of gauged Type-II seesaw","summary":"Neutrino oscillation, discovered over two decades ago, confirmed that\nneutrinos have nonzero masses. Since then, two mass-squared differences have\nbeen measured with unprecedented precision, yet the absolute neutrino mass\nscale remains unknown. Additionally, the fundamental symmetry governing the\nneutrino mixing pattern is still undetermined. Among various theoretical\npossibilities, the two-zero texture in the neutrino mass matrix ($m_\\nu$)\nstands out as an attractive framework due to its reduced number of free\nparameters, enabling definite predictions for the unknown parameters of the\nPMNS matrix. In this work, we present a comprehensive analysis of the two-zero\ntexture, focusing on its implications for the Dirac CP phase ($\\delta$) and the\neffective Majorana mass ($m_{\\beta\\beta}$), the latter being crucial for\nneutrinoless double beta decay. We find that for certain two-zero textures,\n$m_{\\beta\\beta}$ reaches a few tens of meV, placing it within the sensitivity\nrange of KamLAND-Zen. Furthermore, we demonstrate how a two-zero texture can\nnaturally emerge in a well-motivated neutrino mass model, specifically the\ngauged Type-II seesaw mechanism, which requires multiple scalar triplets.\nNotably, some two-zero patterns cannot be realized in this framework, as more\nthan two independent zeros can appear in $m_\\nu$. Finally, we discuss key\nphenomenological consequences of the gauged Type-II seesaw model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-14T15:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.10322v1","title":"Efficient Prompt Tuning for Hierarchical Ingredient Recognition","summary":"Fine-grained ingredient recognition presents a significant challenge due to\nthe diverse appearances of ingredients, resulting from different cutting and\ncooking methods. While existing approaches have shown promising results, they\nstill require extensive training costs and focus solely on fine-grained\ningredient recognition. In this paper, we address these limitations by\nintroducing an efficient prompt-tuning framework that adapts pretrained\nvisual-language models (VLMs), such as CLIP, to the ingredient recognition task\nwithout requiring full model finetuning. Additionally, we introduce three-level\ningredient hierarchies to enhance both training performance and evaluation\nrobustness. Specifically, we propose a hierarchical ingredient recognition\ntask, designed to evaluate model performance across different hierarchical\nlevels (e.g., chicken chunks, chicken, meat), capturing recognition\ncapabilities from coarse- to fine-grained categories. Our method leverages\nhierarchical labels, training prompt-tuned models with both fine-grained and\ncorresponding coarse-grained labels. Experimental results on the VireoFood172\ndataset demonstrate the effectiveness of prompt-tuning with hierarchical\nlabels, achieving superior performance. Moreover, the hierarchical ingredient\nrecognition task provides valuable insights into the model's ability to\ngeneralize across different levels of ingredient granularity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T15:30:49Z"}
{"aid":"http://arxiv.org/abs/2504.10326v1","title":"AlayaDB: The Data Foundation for Efficient and Effective Long-context\n  LLM Inference","summary":"AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.","main_category":"cs.AI","categories":"cs.AI,cs.DB,cs.IR","published":"2025-04-14T15:34:26Z"}
{"aid":"http://arxiv.org/abs/2504.10339v1","title":"Gyroscopically stabilized quantum spin rotors","summary":"Recent experiments demonstrate all-electric spinning of levitated\nnanodiamonds with embedded nitrogen-vacancy spins. Here, we argue that such\ngyroscopically stabilized spin rotors offer a promising platform for probing\nand exploiting quantum spin-rotation coupling of particles hosting a single\nspin degree of freedom. Specifically, we derive the effective Hamiltonian\ndescribing how an embedded spin affects the rotation of rapidly revolving\nquantum rotors due to the Einstein-de Haas and Barnett effects, which we use to\ndevise experimental protocols for observing this coupling in state-of-the-art\nexperiments. This will open the door for future exploitations of quantum spin\nrotors for superposition experiments with massive objects.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.10343v1","title":"Domain-Adversarial Neural Network and Explainable AI for Reducing\n  Tissue-of-Origin Signal in Pan-cancer Mortality Classification","summary":"Tissue-of-origin signals dominate pan-cancer gene expression, often obscuring\nmolecular features linked to patient survival. This hampers the discovery of\ngeneralizable biomarkers, as models tend to overfit tissue-specific patterns\nrather than capture survival-relevant signals. To address this, we propose a\nDomain-Adversarial Neural Network (DANN) trained on TCGA RNA-seq data to learn\nrepresentations less biased by tissue and more focused on survival. Identifying\ntissue-independent genetic profiles is key to revealing core cancer programs.\nWe assess the DANN using: (1) Standard SHAP, based on the original input space\nand DANN's mortality classifier; (2) A layer-aware strategy applied to hidden\nactivations, including an unsupervised manifold from raw activations and a\nsupervised manifold from mortality-specific SHAP values. Standard SHAP remains\nconfounded by tissue signals due to biases inherent in its computation. The raw\nactivation manifold was dominated by high-magnitude activations, which masked\nsubtle tissue and mortality-related signals. In contrast, the layer-aware SHAP\nmanifold offers improved low-dimensional representations of both tissue and\nmortality signals, independent of activation strength, enabling subpopulation\nstratification and pan-cancer identification of survival-associated genes.","main_category":"cs.LG","categories":"cs.LG,q-bio.QM","published":"2025-04-14T15:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.10351v1","title":"Multimodal Representation Learning Techniques for Comprehensive Facial\n  State Analysis","summary":"Multimodal foundation models have significantly improved feature\nrepresentation by integrating information from multiple modalities, making them\nhighly suitable for a broader set of applications. However, the exploration of\nmultimodal facial representation for understanding perception has been limited.\nUnderstanding and analyzing facial states, such as Action Units (AUs) and\nemotions, require a comprehensive and robust framework that bridges visual and\nlinguistic modalities. In this paper, we present a comprehensive pipeline for\nmultimodal facial state analysis. First, we compile a new Multimodal Face\nDataset (MFA) by generating detailed multilevel language descriptions of face,\nincorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.\nSecond, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)\ntailored for Action Unit (AU) and emotion recognition. Our model incorporates\ncomprehensive visual feature modeling at both local and global levels of face\nimage, enhancing its ability to represent detailed facial appearances. This\ndesign aligns visual representations with structured AU and emotion\ndescriptions, ensuring effective cross-modal integration. Third, we develop a\nDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various\ntasks and datasets. This approach not only reduces computational overhead but\nalso broadens the applicability of the foundation model to diverse scenarios.\nExperimentation show superior performance for AU and emotion detection tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:57Z"}
{"aid":"http://arxiv.org/abs/2504.10352v1","title":"Pseudo-Autoregressive Neural Codec Language Models for Efficient\n  Zero-Shot Text-to-Speech Synthesis","summary":"Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://anonymous-palle.github.io.","main_category":"eess.AS","categories":"eess.AS,cs.CL","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10362v1","title":"Proteinoid spikes: from protocognitive to universal approximating agents","summary":"Proteinoids, as soft matter fluidic systems, are computational substrates\nthat have been recently proposed for their analog computing capabilities. Such\nsystems exhibit oscillatory electrical activity because of cationic and anionic\nexchange inside and outside such gels. It has also been recently shown that\nthis (analog) electrical activity, when sampled at fixed time intervals, can be\nused to reveal their underlying information-theoretic, computational code. This\ncode, for instance, can be expressed in the (digital) language of Boolean gates\nand QR codes. Though, this might seem as a good evidence that proteinoid\nsubstrates have computing abilities when subjected to analog-to-digital\ntransition, the leap from their underlying computational code to computing\nabilities is not well explained yet. How can the electrical activity inside\nproteinoids, whilst of chemical origin, be able them to perform computational\ntasks at the first place? In addition, proteinoids are also hypothesised to be\nthe chemical manifestation of the primordial soup, i.e., as potential entities\nwith proto-cognitive abilities. In this work, we show that the proteinoid\nsubstrate, owing to its chemical makeup and proto-cognitive abilities, can be\ninterpreted as an universal approximator, thanks to a novel equivalence between\nthe electrical activity exhibited by the substrate and a deep Rectified Linear\nUnit (deep ReLU) network. We exemplify this equivalence by constructing a\nprediction algorithm which acts as a binary classification model and extract\n16-dimensional vector data from the proteinoid spike, in order to perform\npredictions with 70.41\\% accuracy. We conclude by drawing an equivalence\nbetween the the deep ReLU network and the Kolmogorov-Arnold representation\ntheorem, whose origin can be traced back to Hilbert's thirteenth problem.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.chem-ph","published":"2025-04-14T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.10367v1","title":"On the universality of the split monopole black hole magnetosphere","summary":"Black holes can acquire magnetic flux from their magnetized progenitor or via\nprolonged accretion. We study the evolution of black hole magnetospheres by\nmeans of axisymmetric general relativistic magnetohydrodynamic simulations. We\nshow that all simulated initial magnetic field geometries of varying complexity\nultimately evolve into a split monopole magnetosphere. The magnetospheric\nevolution consists of two phases. In the first phase, the magnetosphere evolves\ntoward pressure equilibrium accompanied by a large magnetic flux decrease on\nthe event horizon on a fast Alfv\\'enic timescale of $\\sim 60$ light-crossing\ntimes of the gravitational radius. The second phase proceeds in a pressure\nbalance in which the magnetic flux decays and current sheets shift in polar\nangle over the event horizon on slower resistive timescales. We present an\nanalytic model for the second phase. Furthermore, we show that in a split\nmonopole magnetosphere the magnetic flux on the event horizon decays\nexponentially with a timescale that depends on the black hole spin, where\nhigher spin results in slower decay. Our results can have an implications for\nthe timescales of reconnection-powered flares and for multimessenger\ncounterparts to gravitational wave events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.10377v1","title":"Groups with finitely many long commutators of maximal order","summary":"Given a group $G$ and elements $x_1,x_2,\\dots, x_\\ell\\in G$, the commutator\nof the form $[x_1,x_2,\\dots, x_\\ell]$ is called a commutator of length $\\ell$.\nThe present paper deals with groups having only finitely many commutators of\nlength $\\ell$ of maximal order. We establish the following results.\n  Let $G$ be a residually finite group with finitely many commutators of length\n$\\ell$ of maximal order. Then $G$ contains a subgroup $M$ of finite index such\nthat $\\gamma_\\ell(M)=1$. Moreover, if $G$ is finitely generated, then\n$\\gamma_\\ell(G)$ is finite.\n  Let $\\ell,m,n,r$ be positive integers and $G$ an $r$-generator group with at\nmost $m$ commutators of length $\\ell$ of maximal order $n$. Suppose that either\n$n$ is a prime power, or $n=p^{\\alpha}q^{\\beta}$, where $p$ and $q$ are odd\nprimes, or $G$ is nilpotent. Then $\\gamma_\\ell(G)$ is finite of\n$(m,\\ell,r)$-bounded order and there is a subgroup $M\\le G$ of\n$(m,\\ell,r)$-bounded index such that $\\gamma_\\ell(M)=1$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-14T16:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.10383v1","title":"A monotonicity formula for a semilinear fractional parabolic equation","summary":"By applying a high-dimensional parabolic-to-elliptic transformation, we\nestablish a monotonicity formula for the extension problem of the fractional\nparabolic semilinear equation $(\\partial_t -\\Delta)^s u = |u|^{p-1}u$, where\n$0<s<1$. This is an analogous result to the Giga-Kohn monotonicity formula for\nthe equation $\\partial_t u - \\Delta u = |u|^{p-1}u.$","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.10393v1","title":"Quantum Liouvillian Tomography","summary":"Characterization of near-term quantum computing platforms requires the\nability to capture and quantify dissipative effects. This is an inherently\nchallenging task, as these effects are multifaceted, spanning a broad spectrum\nfrom Markovian to strongly non-Markovian dynamics. We introduce Quantum\nLiouvillian Tomography (QLT), a protocol to capture and quantify non-Markovian\neffects in time-continuous quantum dynamics. The protocol leverages\ngradient-based quantum process tomography to reconstruct dynamical maps and\nutilizes regression over the derivatives of Pauli string probability\ndistributions to extract the Liouvillian governing the dynamics. We benchmark\nthe protocol using synthetic data and quantify its accuracy in recovering\nHamiltonians, jump operators, and dissipation rates for two-qubit systems.\nFinally, we apply QLT to analyze the evolution of an idling two-qubit system\nimplemented on a superconducting quantum platform to extract characteristics of\nHamiltonian and dissipative components and, as a result, detect inherently\nnon-Markovian dynamics. Our work introduces the first protocol capable of\nretrieving generators of generic open quantum evolution from experimental data,\nthus enabling more precise characterization of many-body non-Markovian effects\nin near-term quantum computing platforms.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-14T16:42:17Z"}
{"aid":"http://arxiv.org/abs/2504.10407v1","title":"Enhancing DESI DR1 Full-Shape analyses using HOD-informed priors","summary":"We present an analysis of DESI Data Release 1 (DR1) that incorporates Halo\nOccupation Distribution (HOD)-informed priors into Full-Shape (FS) modeling of\nthe power spectrum based on cosmological perturbation theory (PT). By\nleveraging physical insights from the galaxy-halo connection, these\nHOD-informed priors on nuisance parameters substantially mitigate projection\neffects in extended cosmological models that allow for dynamical dark energy.\nThe resulting credible intervals now encompass the posterior maximum from the\nbaseline analysis using gaussian priors, eliminating a significant posterior\nshift observed in baseline studies. In the $\\Lambda$CDM framework, a combined\nDESI DR1 FS information and constraints from the DESI DR1 baryon acoustic\noscillations (BAO)-including Big Bang Nucleosynthesis (BBN) constraints and a\nweak prior on the scalar spectral index-yields $\\Omega_{\\rm m} = 0.2994\\pm\n0.0090$ and $\\sigma_8 = 0.836^{+0.024}_{-0.027}$, representing improvements of\napproximately 4% and 23% over the baseline analysis, respectively. For the\n$w_0w_a$CDM model, our results from various data combinations are highly\nconsistent, with all configurations converging to a region with $w_0 > -1$ and\n$w_a < 0$. This convergence not only suggests intriguing hints of dynamical\ndark energy but also underscores the robustness of our HOD-informed prior\napproach in delivering reliable cosmological constraints.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T16:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.10418v1","title":"CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical\n  Interview Dialogue Reconstruction and Evaluation","summary":"Large language models (LLMs) hold great promise for assisting clinical\ninterviews due to their fluent interactive capabilities and extensive medical\nknowledge. However, the lack of high-quality interview dialogue data and widely\naccepted evaluation methods has significantly impeded this process. So we\npropose CliniChat, a framework that integrates multi-source knowledge to enable\nLLMs to simulate real-world clinical interviews. It consists of two modules:\nClini-Recon and Clini-Eval, each responsible for reconstructing and evaluating\ninterview dialogues, respectively. By incorporating three sources of knowledge,\nClini-Recon transforms clinical notes into systematic, professional, and\nempathetic interview dialogues. Clini-Eval combines a comprehensive evaluation\nmetric system with a two-phase automatic evaluation approach, enabling LLMs to\nassess interview performance like experts. We contribute MedQA-Dialog, a\nhigh-quality synthetic interview dialogue dataset, and CliniChatGLM, a model\nspecialized for clinical interviews. Experimental results demonstrate that\nCliniChatGLM's interview capabilities undergo a comprehensive upgrade,\nparticularly in history-taking, achieving state-of-the-art performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.10426v1","title":"Spectral Mode Enhancement in Coherent-harmonic Dual-comb Spectroscopy\n  Enables Exceeding 300-fold Averaging Time Reduction","summary":"Dual-comb spectroscopy (DCS) is a novel Fourier-transform spectroscopy not\nrelying on mechanical scanning and capable of simultaneously achieving\nhigh-speed, high spectral resolution, and broad optical bandwidth. Despite\nthis, conventional DCS suffers from low signal-to-noise ratio (SNR) per single\nacquisition due to the dynamic range limitation of photodetectors imposed by\nthe high peak power of mode-locked pulses, necessitating coherent averaging.\nConsequently, averaging numerous interferograms compromises both the\nexceptional time resolution and places greater demands on long-term mutual\ncoherence and stability. In this study, we demonstrate a novel approach to\nenhance SNR by exploiting the spectral mode enhancement mechanism in\ncoherent-harmonic pulses. As a proof-of-concept, we employ two frequency combs\nwith mode spacing of $\\sim$12.5 MHz, operating at a 20th harmonic repetition\nrate of $\\sim$250 MHz. The result demonstrates a $>$300-fold reduction in\naveraging time while achieving comparable SNR in conventional DCS. This\nreduction is expected to be further enhancement through integration with\nultra-high repetition rate combs, such as microresonator combs. This approach\npromises both a recovery of the inherent high-speed capability and a mitigation\nof the coherence-time requirements, thereby making it possible to significantly\nfacilitate subsequent DCS investigations, as well as field-deployed\nimplementations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T17:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.10436v1","title":"Capacities of highly Markovian divisible quantum channels","summary":"We analyze information transmission capacities of quantum channels acting on\n$d$-dimensional quantum systems that are highly Markovian divisible, i.e.,\nchannels of the form \\begin{equation*}\n  \\Phi = \\underbrace{\\Psi\\circ \\Psi \\circ \\ldots \\circ \\Psi}_{l\n\\,\\operatorname{times}} \\end{equation*} with $l \\geq \\gamma d^2 \\log d$ for\nsome constant $\\gamma=\\gamma(\\Psi)$ that depends on the spectral gap of the\ndividing channel $\\Psi$. We prove that capacities of such channels are\napproximately strongly additive and can be efficiently approximated in terms of\nthe structure of their peripheral spaces. Furthermore, the quantum and private\nclassical capacities of such channels approximately coincide and approximately\nsatisfy the strong converse property. We show that these approximate results\nbecome exact for the corresponding zero-error capacities when $l \\geq d^2$. To\nprove these results, we show that for any channel $\\Psi$, the classical,\nprivate classical, and quantum capacities of $\\Psi_\\infty$, which is its\nso-called asymptotic part, satisfy the strong converse property and are\nstrongly additive. In the zero-error case, we introduce the notion of the\nstabilized non-commutative confusability graph of a quantum channel and\ncharacterize its structure for any given channel.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-14T17:27:43Z"}
{"aid":"http://arxiv.org/abs/2504.10437v1","title":"Model Order Reduction of Linear Systems via $(,)$-Similarity","summary":"Model order reduction aims to determine a low-order approximation of\nhigh-order models with least possible approximation errors. For application to\nphysical systems, it is crucial that the reduced order model (ROM) is robust to\nany disturbance that acts on the full order model (FOM) -- in the sense that\nthe output of the ROM remains a good approximation of that of the FOM, even in\nthe presence of such disturbances. In this work, we present a framework for\nmodel order reduction for a class of continuous-time linear systems that\nensures this property for any $L_2$ disturbance. Apart from robustness to\ndisturbances in this sense, the proposed framework also displays other\ndesirable properties for model order reduction: (1) a provable bound on the\nerror defined as the $L_2$ norm of the difference between the output of the ROM\nand FOM, (2) preservation of stability, (3) compositionality properties and a\nprovable error bound for arbitrary interconnected systems, (4) a provable bound\non the output of the FOM when the controller designed for the ROM is used with\nthe FOM, and finally, (5) compatibility with existing approaches such as\nbalanced truncation and moment matching. Property (4) does not require\ncomputation of any gap metric and property (5) is beneficial as existing\napproaches can also be equipped with some of the preceding properties. The\ntheoretical results are corroborated on numerical case studies, including on a\nbuilding model.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.10442v1","title":"Pinching-Antenna System (PASS) Enhanced Covert Communications","summary":"A Pinching-Antenna SyStem (PASS)-assisted convert communication framework is\nproposed. PASS utilizes dielectric waveguides with freely positioned pinching\nantennas (PAs) to establish strong line-of-sight links. Capitalizing on this\nhigh reconfigurable flexibility of antennas, the potential of PASS for covert\ncommunications is investigated. 1)~For the single-waveguide single-PA (SWSP)\nscenario, a closed-form optimal PA position that maximizes the covert rate is\nfirst derived. Subsequently, a one-dimensional power search is employed to\nenable low-complexity optimization for covert communications. With antenna\nmobility on a scale of meters, PASS can deal with the challenging situation of\nthe eavesdropper enjoying better channel conditions than the legal user. 2)~For\nthe multi-waveguide multi-PA (MWMP) scenario, the positions of multiple PAs are\noptimized to enable effective pinching beamforming, thereby enhancing the\ncovert rate. To address the resultant multimodal joint transmit and pinching\nbeamforming problem, a twin particle swarm optimization (TwinPSO) approach is\nproposed. Numerical results demonstrate that: i)~the proposed approaches can\neffectively resolve the optimization problems; ii)~PASS achieves a higher\ncovert rate than conventional fixed-position antenna architectures; and\niii)~with enhanced flexibility, the MWMP setup outperforms the SWSP\ncounterpart.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T17:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.10443v1","title":"Multimodal Long Video Modeling Based on Temporal Dynamic Context","summary":"Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG,cs.MM","published":"2025-04-14T17:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.10453v1","title":"Anchors no more: Using peculiar velocities to constrain $H_0$ and the\n  primordial Universe without calibrators","summary":"We develop a novel approach to constrain the Hubble parameter $H_0$ and the\nprimordial power spectrum amplitude $A_\\mathrm{s}$ using supernovae type Ia\n(SNIa) data. By considering SNIa as tracers of the peculiar velocity field, we\ncan model their distance and their covariance as a function of cosmological\nparameters without the need of calibrators like Cepheids; this yields a new\nindependent probe of the large-scale structure based on SNIa data without\ndistance anchors. Crucially, we implement a differentiable pipeline in JAX,\nincluding efficient emulators and affine sampling, reducing inference time from\nyears to hours on a single GPU. We first validate our method on mock datasets,\ndemonstrating that we can constrain $H_0$ and $\\log 10^{10}A_\\mathrm{s}$ within\n$\\sim10\\%$ using $\\sim10^3$ SNIa. We then test our pipeline with SNIa from an\n$N$-body simulation, obtaining $7\\%$-level unbiased constraints on $H_0$ with a\nmoderate noise level. We finally apply our method to Pantheon+ data,\nconstraining $H_0$ at the $10\\%$ level without Cepheids when fixing\n$A_\\mathrm{s}$ to its $\\it{Planck}$ value. On the other hand, we obtain\n$15\\%$-level constraints on $\\log 10^{10}A_\\mathrm{s}$ in agreement with\n$\\it{Planck}$ when including Cepheids in the analysis. In light of upcoming\nobservations of low redshift SNIa from the Zwicky Transient Facility and the\nVera Rubin Legacy Survey of Space and Time, surveys for which our method will\ndevelop its full potential, we make our code publicly available.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM,cs.LG,gr-qc","published":"2025-04-14T17:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.10463v1","title":"Influence of excitonic coupling, static disorder, and coherent dynamics\n  in action-2D electronic spectroscopy of a molecular dimer model","summary":"We investigate the spectral features of Action-2D Electronic Spectroscopy\n(A-2DES) in a molecular dimer model across different regimes of excitonic\ncoupling. By explicitly including a second-excited state for each chromophore,\nwe simulate A-2DES spectra ranging from the non-interacting limit to the\nstrong-coupling case, focusing on the significance of cross peaks. While for\nweak excitonic coupling, cross peaks can be understood as the incoherent mixing\nof linear signals of the two chromophores, these features reflect excitonic\ndelocalization as the coupling increases. We highlight that A-2DES offers\nenhanced sensitivity to coherent excited-state dynamics, particularly in the\nintermediate-coupling regime, where it provides higher contrast compared to its\ncoherent-detected counterpart. Finally, we show that static disorder reduces\nthe relative amplitude of cross peaks compared to diagonal features in a way\nthat depends on the excitonic coupling. Notably, the relative suppression of\ncross peaks decreases with the strength of the excitonic coupling, implying\nthat spectral features related to incoherent mixing are less prominent in\ninhomogeneous samples. These findings support the potential of A-2DES for\ninvestigating excitonic dynamics in small multi-chromophoric systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T17:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.10469v1","title":"Bounds as blueprints: towards optimal and accelerated photonic inverse\n  design","summary":"Our ability to structure materials at the nanoscale has, and continues to,\nenable key advances in optical control. In pursuit of optimal photonic designs,\nsubstantial progress has been made on two complementary fronts: bottom-up\nstructural optimizations (inverse design) discover complex high-performing\nstructures but offer no guarantees of optimality; top-down field optimizations\n(convex relaxations) reveal fundamental performance limits but offer no\nguarantees that structures meeting the limits exist. We bridge the gap between\nthese two parallel paradigms by introducing a ``verlan'' initialization method\nthat exploits the encoded local and global wave information in duality-based\nconvex relaxations to guide inverse design towards better-performing\nstructures. We illustrate this technique via the challenging problem of Purcell\nenhancement, maximizing the power extracted from a small emitter in the\nvicinity of a photonic structure, where ill-conditioning and the presence of\ncompeting local maxima lead to sub-optimal designs for adjoint optimization.\nStructures discovered by our verlan method outperform standard (random)\ninitializations by close to an order of magnitude and approach fundamental\nperformance limits within a factor of two, highlighting the possibility of\naccessing significant untapped performance improvements.","main_category":"physics.optics","categories":"physics.optics,math.OC","published":"2025-04-14T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.10481v1","title":"xVerify: Efficient Answer Verifier for Reasoning Model Evaluations","summary":"With the release of the o1 model by OpenAI, reasoning models adopting slow\nthinking strategies have gradually emerged. As the responses generated by such\nmodels often include complex reasoning, intermediate steps, and\nself-reflection, existing evaluation methods are often inadequate. They\nstruggle to determine whether the LLM output is truly equivalent to the\nreference answer, and also have difficulty identifying and extracting the final\nanswer from long, complex responses. To address this issue, we propose xVerify,\nan efficient answer verifier for reasoning model evaluations. xVerify\ndemonstrates strong capability in equivalence judgment, enabling it to\neffectively determine whether the answers produced by reasoning models are\nequivalent to reference answers across various types of objective questions. To\ntrain and evaluate xVerify, we construct the VAR dataset by collecting\nquestion-answer pairs generated by multiple LLMs across various datasets,\nleveraging multiple reasoning models and challenging evaluation sets designed\nspecifically for reasoning model assessment. A multi-round annotation process\nis employed to ensure label accuracy. Based on the VAR dataset, we train\nmultiple xVerify models of different scales. In evaluation experiments\nconducted on both the test set and generalization set, all xVerify models\nachieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest\nvariant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o,\nwhile xVerify-3B-Ib surpasses GPT-4o in overall performance. These results\nvalidate the effectiveness and generalizability of xVerify.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10484v1","title":"Generalized Symmetries of Non-SUSY and Discrete Torsion String\n  Backgrounds","summary":"String / M-theory backgrounds with degrees of freedom at a localized\nsingularity provide a general template for generating strongly correlated\nsystems decoupled from lower-dimensional gravity. There are by now several\ncomplementary procedures for extracting the associated generalized symmetry\ndata from orbifolds of the form $\\mathbb{R}^6 / \\Gamma$, including methods\nbased on the boundary topology of the asymptotic geometry, as well as the\nadjacency matrix for fermionic degrees of freedom in the quiver gauge theory of\nprobe branes. In this paper we show that this match between the two methods\nalso works in non-supersymmetric and discrete torsion backgrounds. In\nparticular, a refinement of geometric boundary data based on Chen-Ruan\ncohomology matches the expected answer based on quiver data. Additionally, we\nalso show that free (i.e., non-torsion) factors count the number of\nhigher-dimensional branes which couple to the localized singularity. We use\nthis to also extract quadratic pairing terms in the associated symmetry theory\n(SymTh) for these systems, and explain how these considerations generalize to a\nbroader class of backgrounds.","main_category":"hep-th","categories":"hep-th,math.AT,math.RT","published":"2025-04-14T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.10486v1","title":"DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar\n  Relighting","summary":"Creating relightable and animatable human avatars from monocular videos is a\nrising research topic with a range of applications, e.g. virtual reality,\nsports, and video games. Previous works utilize neural fields together with\nphysically based rendering (PBR), to estimate geometry and disentangle\nappearance properties of human avatars. However, one drawback of these methods\nis the slow rendering speed due to the expensive Monte Carlo ray tracing. To\ntackle this problem, we proposed to distill the knowledge from implicit neural\nfields (teacher) to explicit 2D Gaussian splatting (student) representation to\ntake advantage of the fast rasterization property of Gaussian splatting. To\navoid ray-tracing, we employ the split-sum approximation for PBR appearance. We\nalso propose novel part-wise ambient occlusion probes for shadow computation.\nShadow prediction is achieved by querying these probes only once per pixel,\nwhich paves the way for real-time relighting of avatars. These techniques\ncombined give high-quality relighting results with realistic shadow effects.\nOur experiments demonstrate that the proposed student model achieves comparable\nor even better relighting results with our teacher model while being 370 times\nfaster at inference time, achieving a 67 FPS rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.10839v1","title":"Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered\n  Perspective","summary":"The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-15T03:44:43Z"}
{"aid":"http://arxiv.org/abs/2504.10842v1","title":"A comprehensive review of remote sensing in wetland classification and\n  mapping","summary":"Wetlands constitute critical ecosystems that support both biodiversity and\nhuman well-being; however, they have experienced a significant decline since\nthe 20th century. Back in the 1970s, researchers began to employ remote sensing\ntechnologies for wetland classification and mapping to elucidate the extent and\nvariations of wetlands. Although some review articles summarized the\ndevelopment of this field, there is a lack of a thorough and in-depth\nunderstanding of wetland classification and mapping: (1) the scientific\nimportance of wetlands, (2) major data, methods used in wetland classification\nand mapping, (3) driving factors of wetland changes, (4) current research\nparadigm and limitations, (5) challenges and opportunities in wetland\nclassification and mapping under the context of technological innovation and\nglobal environmental change. In this review, we aim to provide a comprehensive\nperspective and new insights into wetland classification and mapping for\nreaders to answer these questions. First, we conduct a meta-analysis of over\n1,200 papers, encompassing wetland types, methods, sensor types, and study\nsites, examining prevailing trends in wetland classification and mapping. Next,\nwe review and synthesize the wetland features and existing data and methods in\nwetland classification and mapping. We also summarize typical wetland mapping\nproducts and explore the intrinsic driving factors of wetland changes across\nmultiple spatial and temporal scales. Finally, we discuss current limitations\nand propose future directions in response to global environmental change and\ntechnological innovation. This review consolidates our understanding of wetland\nremote sensing and offers scientific recommendations that foster transformative\nprogress in wetland science.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T03:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10848v1","title":"Ichiyo: Fragile and Transient Interaction in Neighborhood","summary":"As the Internet develops, social networking and other communication tools\nhave transformed people's relationships into something fast, visible, and\ngeographically huge. However, these communication tools have not expanded\nopportunities for acquainting oneself with neighbors outside one's social\nnetwork; rather, they have comparatively diminished occasions for interacting\nwith unfamiliar neighbors by prioritizing communication with existing friends.\nTherefore, we invented the medium Ichiyo to increase the opportunities to think\nof neighbors walking along the same street or in the same neighborhood and to\nexpand the imagination of those who pass by and those who used to be there.\nThus, users can engage in indirect interaction. We used commercially available\nlaser cutters to engrave QR codes on leaves that are naturally found in our\nliving space to prevent environmental invasion. The QR codes lead to a communal\nspace on the web where users can freely leave messages. By engraving QR codes,\ninformation can be virtually expanded to be presented. To get the feedback of\nIchiyo, we let a total of several thousand people experience a new way of\ncommunication as a part of the exhibition ''iii Exhibition 2022'', an art\nexhibition at the University of Tokyo. A total of more than 1,000 leaves\nengraved with QR codes were prepared and scattered at the exhibition site and\nalong the road from the nearest station to the venue.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-15T04:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.10858v1","title":"Universal thermodynamic topological classes of three-dimensional BTZ\n  black holes","summary":"We establish a universal thermodynamic topological classification for\nthree-dimensional static neutral Ba\\~{n}ados-Teitelboim-Zanelli (BTZ), charged\nBTZ, and rotating BTZ black holes. We demonstrate that in all three cases\n(static neutral BTZ, charged BTZ, and rotating BTZ black holes), both the\ninnermost small black hole states and the outermost large black hole states\nexhibit stable thermodynamic behavior. In the low-temperature limit, all three\ncases exhibit a thermodynamically stable small black hole state. Conversely, in\nthe high-temperature limit, each system admits a thermodynamically stable large\nblack hole state. Through this analysis, we have rigorously shown that static\nneutral, charged, and rotating BTZ black holes are consistently classified\nwithin the $W^{1+}$ category. Our results demonstrate that neither the charge\nparameter nor the rotation parameter exerts significant influence on the\nuniversal thermodynamic topological classification of three-dimensional static\nneutral BTZ black holes. This reveals a fundamental dichotomy: while angular\nmomentum and electric charge dominate the thermodynamic topology of\nfour-dimensional static black holes, their effects become negligible in the\nthree-dimensional static BTZ case, highlighting a dimension-driven divergence\nin black hole thermodynamic behavior.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T04:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.10863v1","title":"Intertwined fluctuations and isotope effects in the Hubbard-Holstein\n  model on the square lattice from functional renormalization","summary":"Electron-electron and electron-phonon interactions are responsible for the\nformation of spin, charge, and superconducting correlations in layered quantum\nmaterials. A paradigmatic model for such materials that captures both kinds of\ninteractions is the two-dimensional Hubbard-Holstein model with a\ndispersionless Einstein phonon. In this work, we provide a detailed analysis of\nthe magnetic, density, and superconducting fluctuations at and away from\nhalf-filling. To that end, we employ the functional renormalization group using\nthe recently introduced extension of the single-boson exchange formulation.\nMore precisely, we go beyond previous approaches to the model by resolving the\nfull frequency dependence of the two-particle vertex and taking into account\nthe feedback from the electronic self-energy. We perform broad parameter scans\nin the space of Hubbard repulsion, electron-phonon coupling strength, and\nphonon frequency to explore the leading magnetic, density, and superconducting\nsusceptibilities from the adiabatic to the anti-adiabatic regime. Our numerical\ndata reveal that self-energy effects lead to an enhancement of the $d$-wave\nsuperconducting susceptibility towards larger phonon frequencies, in contrast\nto earlier isotope-effect studies. At small phonon frequencies, large density\ncontributions to the $s$-wave superconducting susceptibility change sign and\neventually lead to a reduction of $s$-wave superconductivity with increasing\nelectron-phonon coupling, signaling the breakdown of Migdal-Eliashberg theory.\nWe analyze our findings systematically, employing detailed diagnostics of the\nintertwined fluctuations and pinning down the various positive and negative\nisotope effects of the physical susceptibilities.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-15T04:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.10869v1","title":"Unveiling a young thick disk in the Milky Way","summary":"The thickness of a galaxy's disk provides a valuable probe of its formation\nand evolution history. Observations of the Milky Way and local galaxies have\nrevealed an ubiquitous disk structure with two distinctive components: an old\nthick disk and a relatively young thin disk. The formation of this dual-disk\nstructure and the mechanisms that develop the thickness of the disk are still\nunclear. Whether the disk thickness inherit from the birth environment or is\nestablished through secular dynamical heating after formation is under debate.\nIn this work we identify a relatively young ($\\sim$6.6 billion years old)\ngeometric thick disk in the Milky Way, with a scale height of $0.64$ kpc at the\nSolar Circle. This young thick component exhibits comparable thickness and\nflaring strength to the canonical old thick disk but is more radially extended\nand systematically younger. We also identify thin disk components that formed\nbefore and after this young thick disk. Detailed analysis of the solar vicinity\nstructure suggests that the young thick disk marks the onset of a new phase of\nupside-down disk formation. These findings strongly discount the role of\nsecular dynamical heating and support a turbulent, bursty birth environment as\nthe primary mechanism behind thick disk formation. The existence of two thick\ndisk components suggests that the Milky Way has undergone at least two episodes\nof turbulent and bursty star formation, likely triggered by galaxy mergers.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-15T05:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.10870v1","title":"Algorithmic Advances Towards a Realizable Quantum Lattice Boltzmann\n  Method","summary":"The Quantum Lattice Boltzmann Method (QLBM) is one of the most promising\napproaches for realizing the potential of quantum computing in simulating\ncomputational fluid dynamics. Many recent works mostly focus on classical\nsimulation, and rely on full state tomography. Several key algorithmic issues\nlike observable readout, data encoding, and impractical circuit depth remain\nunsolved. As a result, these are not directly realizable on any quantum\nhardware. We present a series of novel algorithmic advances which allow us to\nimplement the QLBM algorithm, for the first time, on a quantum computer.\nHardware results for the time evolution of a 2D Gaussian initial density\ndistribution subject to a uniform advection-diffusion field are presented.\nFurthermore, 3D simulation results are presented for particular non-uniform\nadvection fields, devised so as to avoid the problem of diminishing probability\nof success due to repeated post-selection operations required for multiple\ntimesteps. We demonstrate the evolution of an initial quantum state governed by\nthe advection-diffusion equation, accounting for the iterative nature of the\nexplicit QLBM algorithm. A tensor network encoding scheme is used to represent\nthe initial condition supplied to the advection-diffusion equation,\nsignificantly reducing the two-qubit gate count affording a shorter circuit\ndepth. Further reductions are made in the collision and streaming operators.\nCollectively, these advances give a path to realizing more practical, 2D and 3D\nQLBM applications with non-trivial velocity fields on quantum hardware.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-15T05:02:41Z"}
{"aid":"http://arxiv.org/abs/2504.10876v1","title":"Non-Minimal RT Coupling and its Impact on Inflationary Evolution in f(R,\n  T) Gravity","summary":"We examine inflationary models in the $f(R, T)$ gravity framework where we\nhave a conformal constant and an $RT$-mixing term apart from an R term. The\nRT-mixing term introduces non-minimal coupling between gravity and matter. We\nconsider the exponential SUSY potential $V(\\p)=M^4 \\lt(1-e^{-\\l \\p/\\mp}\\rt)$\nand a novel potential $V(\\p)=\\l \\mp^{4-2\\a} \\p^{2\\a} \\sin^2\\lt(\\frac{\\b\n\\mp^\\a}{\\p^\\a}\\rt)$. With the help of COBE normalization, we constrain values\nof different parameters and extract the field value at the time of Hubble\ncrossing. The end of inflation is marked by $\\tep(\\p_i)=1$ where $\\p_i$ is the\nfield value at the end of inflation. Equipped with these values, we then move\non to calculate values of spectral index $n_s$ and tensor-to-scalar ratio $r$.\nOur predicted values of $n_s$ and $r$ fall within their observed values from\nthe Planck 2018 survey and BICEP/Keck array measurement for both potential,\nmaking them plausible candidates for the inflationary model. We also display\nthe variation of the tensor-to-scalar ratio and spectral index with the\ncoefficient of RT-mixing term for fixed values of e-fold number. There, we find\nthe existence of two local maxima of $n_s$, which occur at a negative and a\npositive value of $\\x$, the coefficient of $RT$-mixing term. Our analysis finds\na significant impact of $\\x$ on values of observables","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T05:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.10881v1","title":"A Nonparametric Bayesian Local-Global Model for Enhanced Adverse Event\n  Signal Detection in Spontaneous Reporting System Data","summary":"Spontaneous reporting system databases are key resources for post-marketing\nsurveillance, providing real-world evidence (RWE) on the adverse events (AEs)\nof regulated drugs or other medical products. Various statistical methods have\nbeen proposed for AE signal detection in these databases, flagging\ndrug-specific AEs with disproportionately high observed counts compared to\nexpected counts under independence. However, signal detection remains\nchallenging for rare AEs or newer drugs, which receive small observed and\nexpected counts and thus suffer from reduced statistical power. Principled\ninformation sharing on signal strengths across drugs/AEs is crucial in such\ncases to enhance signal detection. However, existing methods typically ignore\ncomplex between-drug associations on AE signal strengths, limiting their\nability to detect signals. We propose novel local-global mixture Dirichlet\nprocess (DP) prior-based nonparametric Bayesian models to capture these\nassociations, enabling principled information sharing between drugs while\nbalancing flexibility and shrinkage for each drug, thereby enhancing\nstatistical power. We develop efficient Markov chain Monte Carlo algorithms for\nimplementation and employ a false discovery rate (FDR)-controlled, false\nnegative rate (FNR)-optimized hypothesis testing framework for AE signal\ndetection. Extensive simulations demonstrate our methods' superior sensitivity\n-- often surpassing existing approaches by a twofold or greater margin -- while\nstrictly controlling the FDR. An application to FDA FAERS data on statin drugs\nfurther highlights our methods' effectiveness in real-world AE signal\ndetection. Software implementing our methods is provided as supplementary\nmaterial.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-04-15T05:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.10929v1","title":"Cross-Frequency Implicit Neural Representation with Self-Evolving\n  Parameters","summary":"Implicit neural representation (INR) has emerged as a powerful paradigm for\nvisual data representation. However, classical INR methods represent data in\nthe original space mixed with different frequency components, and several\nfeature encoding parameters (e.g., the frequency parameter $\\omega$ or the rank\n$R$) need manual configurations. In this work, we propose a self-evolving\ncross-frequency INR using the Haar wavelet transform (termed CF-INR), which\ndecouples data into four frequency components and employs INRs in the wavelet\nspace. CF-INR allows the characterization of different frequency components\nseparately, thus enabling higher accuracy for data representation. To more\nprecisely characterize cross-frequency components, we propose a cross-frequency\ntensor decomposition paradigm for CF-INR with self-evolving parameters, which\nautomatically updates the rank parameter $R$ and the frequency parameter\n$\\omega$ for each frequency component through self-evolving optimization. This\nself-evolution paradigm eliminates the laborious manual tuning of these\nparameters, and learns a customized cross-frequency feature encoding\nconfiguration for each dataset. We evaluate CF-INR on a variety of visual data\nrepresentation and recovery tasks, including image regression, inpainting,\ndenoising, and cloud removal. Extensive experiments demonstrate that CF-INR\noutperforms state-of-the-art methods in each case.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.10934v1","title":"Induced magnetic moment at two-dimensional MXene/ferromagnetic interface\n  evaluated by angle-dependent hard X-ray photoemission spectroscopy","summary":"Emergent ferromagnetism on the surface of recent two-dimensional (2D) MXene\nis investigated by X-ray magnetic circular dichroism (XMCD) and angle-dependent\nhard X-ray photoemission spectroscopy (HAXPES). Focusing on the Cr2N as one of\nthe 2D-MXenes, the bilayers of Cr2N/Co and Cr2N/Pt are prepared by magnetron\nsputtering technique. XMCD reveals the induced magnetic moment of Cr in the\nCr2N/Co interface, while it is not observed in the Cr2N/Pt interface at room\ntemperature. To distinguish the possible origins of either the interlayer\nmagnetic exchange coupling or the charge transfer at the interfaces, the\nadditional controlled Cr2N/Cu bilayer, whose work function of Cu is consistent\nwith Co, is prepared. HAXPES spectra for the Cr 2p core level near the\ninterface of Cr2N/Cu is consistent with that of Cr2N/Co, indicating that the\ninduced magnetic moment of Cr observed by XMCD for the Cr2N/Co can be\nattributed to the interlayer magnetic exchange coupling, rather than the charge\ntransfer, which is a specific characteristics emerged at the interface with\n2D-MXene.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T07:27:39Z"}
{"aid":"http://arxiv.org/abs/2504.10956v1","title":"The effects of asymptotically flat $R^2$ spacetime on black hole image\n  of Sagittarius A*","summary":"A new class of analytically expressible vacuum solutions has recently been\ndiscovered for pure ${R}^2$ gravity, building upon Buchdahl's seminal work from\n1962. These solutions, inspired by Buchdahl's framework, offer a promising\navenue for testing ${R}^2$ gravity against astrophysical observations. Within a\nsubset of asymptotically flat Buchdahl-inspired vacuum spacetimes, we introduce\na free parameter $\\epsilon$ to characterize deviations from the Schwarzschild\nmetric, which is recovered in the limit $\\epsilon = 0$. In this study, we\nemploy the publicly available code \\textit{ipole} to simulate black hole images\nunder the Buchdahl-inspired metric, with a focus on the black hole at the\ncenter of the Milky Way, Sagittarius A* (Sgr A*). Our simulations show that\nboth the shadow size and photon ring diameter decrease monotonically with\nincreasing $\\epsilon$. By exploring a range of observational inclination\nangles, we find that the photon ring diameter being a direct observable is only\nweakly sensitive to the inclination angle. We further constrain the parameter\n$\\epsilon$ by comparing our simulation results with the Event Horizon Telescope\n(EHT) observations of Sgr A*. The obtained bounds are consistent with those\npreviously derived from the orbital motion of the S2 star, but provide tighter\nconstraints. In addition, we analyze the influence of the Buchdahl-inspired\nspacetime on the polarization patterns near the black hole and find its impact\nto be minimal. In contrast, the observational inclination angle has a\nsubstantial effect on the observed polarization structure, highlighting the\ndominant role of viewing geometry in shaping polarization features.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T08:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.10960v1","title":"A Linear Push-Pull Average Consensus Algorithm for Delay-Prone Networks","summary":"In this paper, we address the average consensus problem of multi-agent\nsystems for possibly unbalanced and delay-prone networks with directional\ninformation flow. We propose a linear distributed algorithm (referred to as\nRPPAC) that handles asynchronous updates and time-varying heterogeneous\ninformation delays. Our proposed distributed algorithm utilizes a\nsurplus-consensus mechanism and information regarding the number of incoming\nand outgoing links to guarantee state averaging, despite the imbalanced and\ndelayed information flow in directional networks. The convergence of the RPPAC\nalgorithm is examined using key properties of the backward product of\ntime-varying matrices that correspond to different snapshots of the directional\naugmented network.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.10962v1","title":"$$-MPPI: A Projection-based Model Predictive Path Integral Scheme for\n  Smooth Optimal Control of Fixed-Wing Aerial Vehicles","summary":"Model Predictive Path Integral (MPPI) is a popular sampling-based Model\nPredictive Control (MPC) algorithm for nonlinear systems. It optimizes\ntrajectories by sampling control sequences and averaging them. However, a key\nissue with MPPI is the non-smoothness of the optimal control sequence, leading\nto oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing\nsolutions use post-hoc smoothing, which fails to bound control derivatives.\nThis paper introduces a new approach: we add a projection filter $\\pi$ to\nminimally correct control samples, ensuring bounds on control magnitude and\nhigher-order derivatives. The filtered samples are then averaged using MPPI,\nleading to our $\\pi$-MPPI approach. We minimize computational overhead by using\na neural accelerated custom optimizer for the projection filter. $\\pi$-MPPI\noffers a simple way to achieve arbitrary smoothness in control sequences. While\nwe focus on FWVs, this projection filter can be integrated into any MPPI\npipeline. Applied to FWVs, $\\pi$-MPPI is easier to tune than the baseline,\nresulting in smoother, more robust performance.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-15T08:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.10964v1","title":"Distributed Optimization with Gradient Tracking over Heterogeneous\n  Delay-Prone Directed Networks","summary":"In this paper, we address the distributed optimization problem over\nunidirectional networks with possibly time-invariant heterogeneous bounded\ntransmission delays. In particular, we propose a modified version of the\nAccelerated Distributed Directed OPTimization (ADD-OPT) algorithm, herein\ncalled Robustified ADD-OPT (R-ADD-OPT), which is able to solve the distributed\noptimization problem, even when the communication links suffer from\nheterogeneous but bounded transmission delays. We show that if the gradient\nstep-size of the R-ADD-OPT algorithm is within a certain range, which also\ndepends on the maximum time delay in the network, then the nodes are guaranteed\nto converge to the optimal solution of the distributed optimization problem.\nThe range of the gradient step-size that guarantees convergence can be computed\na priori based on the maximum time delay in the network.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T08:14:30Z"}
{"aid":"http://arxiv.org/abs/2504.10971v1","title":"The Effectiveness of Business Process Visualisations: a Systematic\n  Literature Review","summary":"Business Process Visualisations (BPVs) have become indispensable tools for\norganisations seeking to enhance their operational efficiency, decision-making\ncapabilities, and overall performance. The burgeoning interest in process\nmodeling and tool development, coupled with the rise of data visualisation\nfield, underscores the significant role of visual tools in leveraging human\ncognition. Unlike traditional models, data visualisation approaches graphics\nfrom a novel angle, emphasising the potency of visual representations. This\nreview aims to integrate the domains of BPV and data visualisation to assess\ntheir combined influence on organisational effectiveness comprehensively.\nThrough a meticulous analysis of existing literature, this study aims to\namalgamate insights on BPVs impact from a data visualisation standpoint,\nadvocating for a design philosophy that prioritises user engagement to bolster\norganisational outcomes. Additionally, our systematic review has unveiled\npromising avenues for future research, identifying underexplored variables that\ninfluence the efficacy of BPVs, thereby charting a path for forthcoming\nscholarly inquiries.","main_category":"cs.HC","categories":"cs.HC,cs.GR","published":"2025-04-15T08:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.10977v1","title":"Phonon-polaritons in Zn(1-x)MgxTe (x<0.09): A Raman scattering study","summary":"Phonon-polaritons (PP) are phonon-photon coupled modes. Using near-forward\nRaman scattering, the PP of the cubic Zn(1-x)MgxTe (x<0.09) semiconductor alloy\ncould be measured. While the PP-coupling hardly develops in pure ZnTe, minor\nMg-alloying suffices to stabilize a long-lifetime PP strongly bound to the\nlattice, i.e., with a pronounced phonon character, and yet a fast one\noriginating from the highly dispersive photon-like bottleneck of the\nPP-dispersion. By combining the advantages of a phonon and of a photon, the\nlong-lifetime PP generated by minor Mg-alloying of ZnTe marks an improvement\nover the PP of pristine ZnTe, that, from the Raman cross section calculation,\ncan only achieve a balanced compromise between the two kinds of advantages,\nintensity and speed. The discussion of the PP-related lattice dynamics of\nZn(1-x)MgxTe (x<0.09) is grounded in a preliminary study of the lattice macro-\nand microstructure using X-ray diffraction and solid-state nuclear magnetic\nresonance, respectively, and further relies on ab initio calculations of the\nnative phonon modes behind the PP in the Mg-dilute limit of Zn(1-x)MgxTe (x~0),\nconsidering various Mg-isotopes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,J.2","published":"2025-04-15T08:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.10984v1","title":"Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera","summary":"Cephalopods exhibit unique colour discrimination capabilities despite having\none type of photoreceptor, relying instead on chromatic aberration induced by\ntheir ocular optics and pupil shapes to perceive spectral information. We took\ninspiration from this biological mechanism to design a spectral imaging system\nthat combines a ball lens with an event-based camera. Our approach relies on a\nmotorised system that shifts the focal position, mirroring the adaptive lens\nmotion in cephalopods. This approach has enabled us to achieve\nwavelength-dependent focusing across the visible light and near-infrared\nspectrum, making the event a spectral sensor. We characterise chromatic\naberration effects, using both event-based and conventional frame-based\nsensors, validating the effectiveness of bio-inspired spectral discrimination\nboth in simulation and in a real setup as well as assessing the spectral\ndiscrimination performance. Our proposed approach provides a robust spectral\nsensing capability without conventional colour filters or computational\ndemosaicing. This approach opens new pathways toward new spectral sensing\nsystems inspired by nature's evolutionary solutions. Code and analysis are\navailable at: https://samiarja.github.io/neuromorphic_octopus_eye/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.11002v1","title":"Dopamine Audiobook: A Training-free MLLM Agent for Emotional and\n  Human-like Audiobook Generation","summary":"Audiobook generation, which creates vivid and emotion-rich audio works, faces\nchallenges in conveying complex emotions, achieving human-like qualities, and\naligning evaluations with human preferences. Existing text-to-speech (TTS)\nmethods are often limited to specific scenarios, struggle with emotional\ntransitions, and lack automatic human-aligned evaluation benchmarks, instead\nrelying on either misaligned automated metrics or costly human assessments. To\naddress these issues, we propose Dopamine Audiobook, a new unified\ntraining-free system leveraging a multimodal large language model (MLLM) as an\nAI agent for emotional and human-like audiobook generation and evaluation.\nSpecifically, we first design a flow-based emotion-enhanced framework that\ndecomposes complex emotional speech synthesis into controllable sub-tasks.\nThen, we propose an adaptive model selection module that dynamically selects\nthe most suitable TTS methods from a set of existing state-of-the-art (SOTA)\nTTS methods for diverse scenarios. We further enhance emotional expressiveness\nthrough paralinguistic augmentation and prosody retrieval at word and utterance\nlevels. For evaluation, we propose a novel GPT-based evaluation framework\nincorporating self-critique, perspective-taking, and psychological MagicEmo\nprompts to ensure human-aligned and self-aligned assessments. Experiments show\nthat our method generates long speech with superior emotional expression to\nSOTA TTS models in various metrics. Importantly, our evaluation framework\ndemonstrates better alignment with human preferences and transferability across\naudio tasks. Project website with audio samples can be found at\nhttps://dopamine-audiobook.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.MM,eess.AS","published":"2025-04-15T09:19:44Z"}
{"aid":"http://arxiv.org/abs/2504.11019v1","title":"DRIFT open dataset: A drone-derived intelligence for traffic analysis in\n  urban environmen","summary":"Reliable traffic data are essential for understanding urban mobility and\ndeveloping effective traffic management strategies. This study introduces the\nDRone-derived Intelligence For Traffic analysis (DRIFT) dataset, a large-scale\nurban traffic dataset collected systematically from synchronized drone videos\nat approximately 250 meters altitude, covering nine interconnected\nintersections in Daejeon, South Korea. DRIFT provides high-resolution vehicle\ntrajectories that include directional information, processed through video\nsynchronization and orthomap alignment, resulting in a comprehensive dataset of\n81,699 vehicle trajectories. Through our DRIFT dataset, researchers can\nsimultaneously analyze traffic at multiple scales - from individual vehicle\nmaneuvers like lane-changes and safety metrics such as time-to-collision to\naggregate network flow dynamics across interconnected urban intersections. The\nDRIFT dataset is structured to enable immediate use without additional\npreprocessing, complemented by open-source models for object detection and\ntrajectory extraction, as well as associated analytical tools. DRIFT is\nexpected to significantly contribute to academic research and practical\napplications, such as traffic flow analysis and simulation studies. The dataset\nand related resources are publicly accessible at\nhttps://github.com/AIxMobility/The-DRIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.11020v1","title":"\"Even explanations will not help in trusting [this] fundamentally biased\n  system\": A Predictive Policing Case-Study","summary":"In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-15T09:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11039v1","title":"Modeling dislocations in quasicrystals through amplitude equations","summary":"Quasicrystals (QCs) are a class of aperiodic ordered structures that emerge\nin various systems, from metallic alloys to soft matter and driven\nnon-equilibrium systems. Within a mesoscale theory based on slowly-varying\ncomplex amplitudes for QCs, we track dislocations as topological defects\nharbored by the amplitudes and characterize their Burgers vectors and induced\ndeformations. We study the formation of dislocations at semicoherent\ninterfaces, particularly those emerging from rotated inclusions, and find a\nhierarchy of dislocations forming at such interfaces. We further analyze\ninterfaces in strained systems, revealing conditions for the emergence of\nperiodic dislocation arrays and discussing the energetics of dislocations\nassociated with different phonon and phason deformations. The stability,\ninteraction, and motion of dislocation dipoles and quadrupoles are also\ndiscussed. These findings provide new insights into the mesoscale modeling of\ndislocations in QCs and their distinct behavior compared to conventional\ncrystals, while demonstrating a versatile framework for studying dislocations\nin systems exhibiting quasicrystalline order.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.soft","published":"2025-04-15T10:03:41Z"}
{"aid":"http://arxiv.org/abs/2504.11042v1","title":"LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews","summary":"Peer review is a cornerstone of quality control in scientific publishing.\nWith the increasing workload, the unintended use of `quick' heuristics,\nreferred to as lazy thinking, has emerged as a recurring issue compromising\nreview quality. Automated methods to detect such heuristics can help improve\nthe peer-reviewing process. However, there is limited NLP research on this\nissue, and no real-world dataset exists to support the development of detection\ntools. This work introduces LazyReview, a dataset of peer-review sentences\nannotated with fine-grained lazy thinking categories. Our analysis reveals that\nLarge Language Models (LLMs) struggle to detect these instances in a zero-shot\nsetting. However, instruction-based fine-tuning on our dataset significantly\nboosts performance by 10-20 performance points, highlighting the importance of\nhigh-quality training data. Furthermore, a controlled experiment demonstrates\nthat reviews revised with lazy thinking feedback are more comprehensive and\nactionable than those written without such feedback. We will release our\ndataset and the enhanced guidelines that can be used to train junior reviewers\nin the community. (Code available here:\nhttps://github.com/UKPLab/arxiv2025-lazy-review)","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T10:07:33Z"}
{"aid":"http://arxiv.org/abs/2504.11053v1","title":"QualiTagger: Automating software quality detection in issue trackers","summary":"A systems quality is a major concern for development teams when it evolve.\nUnderstanding the effects of a loss of quality in the codebase is crucial to\navoid side effects like the appearance of technical debt. Although the\nidentification of these qualities in software requirements described in natural\nlanguage has been investigated, most of the results are often not applicable in\npractice, and rely on having been validated on small datasets and limited\namount of projects. For many years, machine learning (ML) techniques have been\nproved as a valid technique to identify and tag terms described in natural\nlanguage. In order to advance previous works, in this research we use cutting\nedge models like Transformers, together with a vast dataset mined and curated\nfrom GitHub, to identify what text is usually associated with different quality\nproperties. We also study the distribution of such qualities in issue trackers\nfrom openly accessible software repositories, and we evaluate our approach both\nwith students from a software engineering course and with its application to\nrecognize security labels in industry.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T10:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.11068v1","title":"Uma extenso de Raft com propagao epidmica","summary":"The Raft agreement algorithm is recognized for its ease of understanding and\npractical implementation, and is currently adopted in systems such as\nKubernetes. However, it has some limitations in terms of scalability and\nperformance as it concentrates effort on the leader. In this paper we present a\nnew algorithm that expands Raft by incorporating epidemic propagation\nmechanisms to decentralize the replication effort. Our proposal is evaluated\nexperimentally with a Go implementation and tested with a significant number of\nprocesses. -- --\n  O algoritmo de acordo Raft \\'e reconhecido pela sua facilidade de\ncompreens\\~ao e implementa\\c{c}\\~ao pr\\'atica, sendo atualmente adotado em\nsistemas como o Kubernetes. No entanto, tem algumas limita\\c{c}\\~oes em termos\nde escalabilidade e desempenho por concentrar o esfor\\c{c}o no l\\'ider. Neste\ntrabalho apresentamos um novo algoritmo que expande o Raft com a\nincorpora\\c{c}\\~ao de mecanismos de propaga\\c{c}\\~ao epid\\'emica para\ndescentralizar o esfor\\c{c}o da replica\\c{c}\\~ao. A nossa proposta \\'e avaliada\nexperimentalmente com uma implementa\\c{c}\\~ao em Go e testada com um n\\'umero\nsignificativo de processos.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T11:05:25Z"}
{"aid":"http://arxiv.org/abs/2504.11079v1","title":"Scalability and Maintainability Challenges and Solutions in Machine\n  Learning: Systematic Literature Review","summary":"This systematic literature review examines the critical challenges and\nsolutions related to scalability and maintainability in Machine Learning (ML)\nsystems. As ML applications become increasingly complex and widespread across\nindustries, the need to balance system scalability with long-term\nmaintainability has emerged as a significant concern. This review synthesizes\ncurrent research and practices addressing these dual challenges across the\nentire ML life-cycle, from data engineering to model deployment in production.\nWe analyzed 124 papers to identify and categorize 41 maintainability challenges\nand 13 scalability challenges, along with their corresponding solutions. Our\nfindings reveal intricate inter dependencies between scalability and\nmaintainability, where improvements in one often impact the other.\n  The review is structured around six primary research questions, examining\nmaintainability and scalability challenges in data engineering, model\nengineering, and ML system development. We explore how these challenges\nmanifest differently across various stages of the ML life-cycle.\n  This comprehensive overview offers valuable insights for both researchers and\npractitioners in the field of ML systems. It aims to guide future research\ndirections, inform best practices, and contribute to the development of more\nrobust, efficient, and sustainable ML applications across various domains.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.11080v1","title":"Change State Space Models for Remote Sensing Change Detection","summary":"Despite their frequent use for change detection, both ConvNets and Vision\ntransformers (ViT) exhibit well-known limitations, namely the former struggle\nto model long-range dependencies while the latter are computationally\ninefficient, rendering them challenging to train on large-scale datasets.\nVision Mamba, an architecture based on State Space Models has emerged as an\nalternative addressing the aforementioned deficiencies and has been already\napplied to remote sensing change detection, though mostly as a feature\nextracting backbone. In this article the Change State Space Model is\nintroduced, that has been specifically designed for change detection by\nfocusing on the relevant changes between bi-temporal images, effectively\nfiltering out irrelevant information. By concentrating solely on the changed\nfeatures, the number of network parameters is reduced, enhancing significantly\ncomputational efficiency while maintaining high detection performance and\nrobustness against input degradation. The proposed model has been evaluated via\nthree benchmark datasets, where it outperformed ConvNets, ViTs, and Mamba-based\ncounterparts at a fraction of their computational complexity. The\nimplementation will be made available at https://github.com/Elman295/CSSM upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.11082v1","title":"DeepMLF: Multimodal language model with learnable tokens for deep fusion\n  in sentiment analysis","summary":"While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T11:28:02Z"}
{"aid":"http://arxiv.org/abs/2504.11089v1","title":"InfoClus: Informative Clustering of High-dimensional Data Embeddings","summary":"Developing an understanding of high-dimensional data can be facilitated by\nvisualizing that data using dimensionality reduction. However, the\nlow-dimensional embeddings are often difficult to interpret. To facilitate the\nexploration and interpretation of low-dimensional embeddings, we introduce a\nnew concept named partitioning with explanations. The idea is to partition the\ndata shown through the embedding into groups, each of which is given a sparse\nexplanation using the original high-dimensional attributes. We introduce an\nobjective function that quantifies how much we can learn through observing the\nexplanations of the data partitioning, using information theory, and also how\ncomplex the explanations are. Through parameterization of the complexity, we\ncan tune the solutions towards the desired granularity. We propose InfoClus,\nwhich optimizes the partitioning and explanations jointly, through greedy\nsearch constrained over a hierarchical clustering. We conduct a qualitative and\nquantitative analysis of InfoClus on three data sets. We contrast the results\non the Cytometry data with published manual analysis results, and compare with\ntwo other recent methods for explaining embeddings (RVX and VERA). These\ncomparisons highlight that InfoClus has distinct advantages over existing\nprocedures and methods. We find that InfoClus can automatically create good\nstarting points for the analysis of dimensionality-reduction-based scatter\nplots.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T11:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.11137v1","title":"Asymmetric Resonant Ferroelectric Tunnel Junctions for Simultaneous High\n  Tunnel Electroresistance and Low Resistance-Area Product","summary":"Ferroelectric tunnel junctions offer potential for non-volatile memory with\nlow power, fast switching, and scalability, but their performance is limited by\na high resistance-area product and a low tunnel electroresistance ratio. To\naddress these challenges, we propose a doped HfO2-based, silicon-compatible\nasymmetric resonant ferroelectric tunnel junction design with a quantum well\nembedded between two ferroelectric layers, replacing the conventional\nmetal-ferroelectric-metal structure. Using a self-consistent coupling of the\nnon-equilibrium Green's function method with a Preisach-based model, we\ndemonstrate that the quantum well enhances resonant tunneling effects, leading\nto a simultaneous reduction in the resistance-area product and a boost in the\ntunnel electroresistance ratio. The low-resistance state becomes more robust,\nwhile the high-resistance state is suppressed, improving readout speed and\nreducing power usage. We observed that incorporating a 2 nm quantum well\nsignificantly enhances the tunnel electroresistance ratio, achieving a peak\nvalue of approximately 6.15 x 10^4 percent, while simultaneously minimizing the\nresistance-area product to 47.1 Ohm-cm^2 at 0.175 V. Additionally, the device\nexhibits negative differential resistance, further enhancing its functionality.\nOur results confirm that this design enables scalable, energy-efficient, and\nhigh-performance non-volatile memory, making it a strong candidate for future\nmemory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T12:39:54Z"}
{"aid":"http://arxiv.org/abs/2504.11140v1","title":"An Unsupervised Network Architecture Search Method for Solving Partial\n  Differential Equations","summary":"Solving partial differential equations (PDEs) has been indispensable in\nscientific and engineering applications. Recently, deep learning methods have\nbeen widely used to solve high-dimensional problems, one of which is the\nphysics-informed neural network (PINN). Typically, a deep learning method has\nthree main components: a neural network, a loss function, and an optimizer.\nWhile the construction of the loss function is rooted in the definition of\nsolution space, how to choose a optimal neural network is somewhat ad hoc,\nleaving much room for improvement. In the framework of PINN, we propose an\nunsupervised network architecture search method for solving PDEs, termed\nPINN-DARTS, which applies the differentiable architecture search (DARTS) to\nfind the optimal network architecture structure in a given set of neural\nnetworks. In this set, the number of layers and the number of neurons in each\nlayer can change. In the searching phase, both network and architecture\nparameters are updated simultaneously, so the running time is close to that of\nPINN with a pre-determined network structure. Unlike available works, our\napproach is unsupervised and purely based on the PDE residual without any prior\nusage of solutions. PINN-DARTS outputs the optimal network structure as well as\nthe associated numerical solution. The performance of PINN-DARTS is verified on\nseveral benchmark PDEs, including elliptic, parabolic, wave, and Burgers'\nequations. Compared to traditional architecture search methods, PINN-DARTS\nachieves significantly higher architectural accuracy. Another interesting\nobservation is that both the solution complexity and the PDE type have a\nprominent impact on the optimal network architecture. Our study suggests that\narchitectures with uneven widths from layer to layer may have superior\nperformance across different solution complexities and different PDE types.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T12:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.11141v1","title":"A definition of the background state of the atmosphere using optimal\n  transport","summary":"The dynamics of atmospheric disturbances are often described in terms of\ndisplacements of air parcels relative to their locations in a notional\nbackground state. Modified Lagrangian Mean (MLM) states have been proposed by\nM. E. McIntyre using the Lagrangian conserved variables potential vorticity and\npotential temperature to label air parcels, thus avoiding the need to calculate\ntrajectories explicitly. Methven and Berrisford further defined a zonally\nsymmetric MLM state for global atmospheric flow in terms of mass in zonal\nangular momentum ($z$) and potential temperature ($\\theta$) coordinates. We\nprove that for any snapshot of an atmospheric flow in a single hemisphere,\nthere exists a unique energy-minimising MLM state in geophysical coordinates\n(latitude and pressure). Since the state is an energy minimum, it is suitable\nfor quantification of finite amplitude disturbances and examining atmospheric\ninstability. This state is obtained by solving a free surface problem, which we\nframe as the minimisation of an optimal transport cost over a class of source\nmeasures. The solution consists of a source measure, encoding surface pressure,\nand an optimal transport map, connecting the distribution of mass in\ngeophysical coordinates to the known distribution of mass in $(z, \\theta)$. We\nshow that this problem reduces to an optimal transport problem with a known\nsource measure, which has a numerically feasible discretisation. Additionally,\nour results hold for a large class of cost functions, and generalise analogous\nresults on free surface variants of the semi-geostrophic equations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T12:42:42Z"}
{"aid":"http://arxiv.org/abs/2504.11145v1","title":"Nonreciprocal Spin-Wave Propagation in Anisotropy-Graded Iron Films\n  Prepared by Nitrogen Implantation","summary":"Gradual modification of the magnetic properties in ferromagnetic films has\nrecently been proposed as an effective method to channel and control spin waves\nfor the development of new functionalities in magnonic devices. Here, we\ninvestigate graded FeN films prepared by low-dose nitrogen implantation of Fe\nepitaxial thin films. Combining Brillouin light scattering measurements and a\nspin-wave theoretical approach, we show that nitrogen implantation induces a\ngraded profile of both the in-plane and the perpendicular anisotropies along\nthe film thickness. This graduation leads to a significant modification of the\nspin-wave spatial localization and generates a marked frequency asymmetry in\nthe spin-wave dispersion. Moreover, we find that the anisotropy profile, and as\na consequence the dispersion relation, can be tuned on changing the\nimplantation dose, opening a way for the potential use of the graded Fe-N films\nin magnonic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-15T12:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.11155v1","title":"There are no exotic compact moduli of sheaves on a curve","summary":"We study moduli of coherent sheaves of some given degree and positive rank on\na curve. We show that there is only one nonempty open condition on families of\nsheaves that yields a universally closed adequate moduli space, namely, the one\nthat recovers the classical moduli of slope semistable vector bundles.","main_category":"math.AG","categories":"math.AG","published":"2025-04-15T12:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.11160v1","title":"DMAGaze: Gaze Estimation Based on Feature Disentanglement and\n  Multi-Scale Attention","summary":"Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T13:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.11176v1","title":"Wonderful Blow-Ups of Weighted Building Sets and Configuration Spaces of\n  Filtered Manifolds","summary":"Fulton and MacPherson famously constructed a configuration space that encodes\ninfinitesimal collision data by blowing up the diagonals. We observe that when\ngeneralizing their approach to configuration spaces of filtered manifolds (e.g.\njet spaces or sub-Riemannian manifolds), these blow-ups have to be modified\nwith weights in order for the collisions to be compatible with higher-order\ndata.\n  In the present article, we provide a general framework for blowing up\narrangements of submanifolds that are equipped with a weighting in the sense of\nLoizides and Meinrenken. We prove in particular smoothness of the blow-up under\nreasonable assumptions, extending a result of Li to the weighted setting. Our\ndiscussion covers both spherical and projective blow-ups, as well as the\n(restricted) functoriality of the construction.\n  Alongside a self-contained introduction to weightings, we also give a new\ncharacterization thereof in terms of their vanishing ideals and prove that\ncleanly intersecting weightings locally yield a weighting.\n  As our main application, we construct configuration spaces of filtered\nmanifolds, including convenient local models. We also discuss a variation of\nthe construction tailored to certain fiber bundles equipped with a filtration.\nThis is necessary for the special case of jet configuration spaces, which we\ninvestigate in a future article.","main_category":"math.DG","categories":"math.DG,math.GT","published":"2025-04-15T13:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.11179v1","title":"Semistable reduction of plane quartics at $p=3$","summary":"We explain how to compute the semistable reduction of plane quartic curves\nover local fields of residue characteristic $p=3$. Our approach is based on\nfinding suitable degree-$3$ coverings of the projective line by such plane\nquartics and on the different function of Cohen, Temkin, and Trushin associated\nto the analytifications of these coverings. In particular, we give an explicit\nformula for computing the different function on a given interval. The resulting\nalgorithm for computing the semistable reduction of plane quartics is\nimplemented in SageMath, and we illustrate it by determining the semistable\nreduction of a particular plane quartic at $p=3$ that arises as a quotient of\nthe non-split Cartan modular curve $X^+_{ns}(27)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T13:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.11187v1","title":"A Spatial-Sign based Direct Approach for High Dimensional Sparse\n  Quadratic Discriminant Analysis","summary":"In this paper, we study the problem of high-dimensional sparse quadratic\ndiscriminant analysis (QDA). We propose a novel classification method, termed\nSSQDA, which is constructed via constrained convex optimization based on the\nsample spatial median and spatial sign covariance matrix under the assumption\nof an elliptically symmetric distribution. The proposed classifier is shown to\nachieve the optimal convergence rate over a broad class of parameter spaces, up\nto a logarithmic factor. Extensive simulation studies and real data\napplications demonstrate that SSQDA is both robust and efficient, particularly\nin the presence of heavy-tailed distributions, highlighting its practical\nadvantages in high-dimensional classification tasks.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T13:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.11203v1","title":"Braiding vineyards","summary":"Vineyards are a common way to study persistence diagrams of a data set which\nis changing, as strong stability means that it is possible to pair points in\n``nearby'' persistence diagrams, yielding a family of point sets which connect\ninto curves when stacked. Recent work has also studied monodromy in the\npersistent homology transform, demonstrating some interesting connections\nbetween an input shape and monodromy in the persistent homology transform for\n0-dimensional homology embedded in $\\mathbb{R}^2$. In this work, we\nre-characterize monodromy in terms of periodicity of the associated vineyard of\npersistence diagrams.\n  We construct a family of objects in any dimension which have non-trivial\nmonodromy for $l$-persistence of any periodicity and for any $l$. More\ngenerally we prove that any knot or link can appear as a vineyard for a shape\nin $\\mathbb{R}^d$, with $d\\geq 3$. This shows an intriguing and, to the best of\nour knowledge, previously unknown connection between knots and persistence\nvineyards. In particular this shows that vineyards are topologically as rich as\none could possibly hope.","main_category":"cs.CG","categories":"cs.CG,math.AT,math.GT,I.3.5","published":"2025-04-15T14:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.11221v1","title":"Global asymptotic behavior of solutions to the generalized derivative\n  nonlinear Schrdinger equation","summary":"This article is concerned with the global asymptotic behavior for the\ngeneralized derivative nonlinear Schr\\\"odinger (gDNLS) equation. When the\nnonlinear effect is not strong, we show pointwise-in-time dispersive decay for\nsolutions to the gDNLS equation with small initial data in\n$H^{\\frac{1}{2}+}(\\mathbb{R})$ utilizing crucially Lorentz-space improvements\nof the traditional Strichartz inequality. When the nonlinear effect is\nespecially dominant, there exists a sequence of solitary waves that are\narbitrary small in the energy space, which means the small data scattering is\nnot true. However, there is evidence that it is not possible for the solitons\nto be localized in $L^{2}(\\mathbb{R})$ and small in $H^{1}(\\mathbb{R})$. With\nsmall and localized data assumption, we obtain global asymptotic behavior for\nsolutions to the gDNLS equation by using vector field methods combined with the\ntesting by wave packets method.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T14:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.11248v1","title":"Probing Lorentz Invariance Violation in Z Boson Mass Measurements at\n  High-Energy Colliders","summary":"We propose a minimal extension to the Standard Model by introducing a Lorentz\nInvariance Violation (LIV) term into the Z boson's dispersion relation,\nexpressed as $p_\\mu p^\\mu = M_Z^2 + \\delta_{LIV} (p_\\mu n^\\mu)^2$, where\n$\\delta_{LIV}$ defines the violation scale and $n^\\mu$ is a unit Lorentz vector\nspecifying the direction. This modification alters the Z boson propagator and\ndecay rate, impacting the Drell-Yan process cross-section at high-energy\ncolliders. Observable effects are most pronounced near the resonance region at\nhigh rapidities ($|Y| > 4$), potentially shifting the perceived Z boson mass\nand inducing sidereal-time modulations for spacelike and lightlike LIV due to\nEarth's rotation. We outline a targeted search strategy for ATLAS and CMS,\nachieving sensitivity to LIV signatures down to $|\\delta_{LIV}| \\approx\n10^{-8}$ (or $10^{-9}$ optimistically), offering new insights into historical\nand future collider data. Our model predicts systematic shifts in weak boson\nmasses at higher collision energies, relevant to past Tevatron and LHC\ndiscrepancies, though current data are now consistent.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-15T14:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.11253v1","title":"Large deformations of Tr($^3$) and the world at infinity","summary":"The amplitudes of the non-linear sigma model can be obtained from those of\nTr($\\Phi^3$) theory by sending the kinematic (Mandelstam) variables to infinity\nin a certain direction. In this paper we characterize the behavior of\nTr($\\Phi^3$) amplitudes under a general class of large kinematic shifts called\n$g$-vector shifts. The objects that live in this world at infinity retain\ncertain key amplitude-like properties, most notably factorization, and admit\ndescriptions in terms of polytopes, but they are not generally amplitudes of\nany cognizable theory. We identify particular $g$-vector shifts that lead at\ninfinity to mixed amplitudes involving two pions and any number of scalars,\nallowing us to provide polytopal descriptions of these amplitudes.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T14:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.11261v1","title":"Robust MPC for Uncertain Linear Systems -- Combining Model Adaptation\n  and Iterative Learning","summary":"This paper presents a robust adaptive learning Model Predictive Control (MPC)\nframework for linear systems with parametric uncertainties and additive\ndisturbances performing iterative tasks. The approach iteratively refines the\nparameter estimates using set membership estimation. Performance enhancement\nover iterations is achieved by learning the terminal cost from data. Safety is\nenforced using a terminal set, which is also learned iteratively. The proposed\nmethod guarantees recursive feasibility, constraint satisfaction, and a robust\nbound on the closed-loop cost. Numerical simulations on a mass-spring-damper\nsystem demonstrate improved computational efficiency and control performance\ncompared to an existing robust adaptive MPC approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.11264v1","title":"DeepSelective: Feature Gating and Representation Matching for\n  Interpretable Clinical Prediction","summary":"The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T15:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.11335v1","title":"Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java","summary":"This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG","published":"2025-04-15T16:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.11337v1","title":"REWARD CONSISTENCY: Improving Multi-Objective Alignment from a\n  Data-Centric Perspective","summary":"Multi-objective preference alignment in language models often encounters a\nchallenging trade-off: optimizing for one human preference (e.g., helpfulness)\nfrequently compromises others (e.g., harmlessness) due to the inherent\nconflicts between competing objectives. While prior work mainly focuses on\nalgorithmic solutions, we explore a novel data-driven approach to uncover the\ntypes of data that can effectively mitigate these conflicts. Specifically, we\npropose the concept of Reward Consistency (RC), which identifies samples that\nalign with multiple preference objectives, thereby reducing conflicts during\ntraining. Through gradient-based analysis, we demonstrate that RC-compliant\nsamples inherently constrain performance degradation during multi-objective\noptimization. Building on these insights, we further develop Reward Consistency\nSampling, a framework that automatically constructs preference datasets that\neffectively mitigate conflicts during multi-objective alignment. Our generated\ndata achieves an average improvement of 13.37% in both the harmless rate and\nhelpfulness win rate when optimizing harmlessness and helpfulness, and can\nconsistently resolve conflicts in varying multi-objective scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.11345v1","title":"Erzeugunsgrad, VC-Dimension and Neural Networks with rational activation\n  function","summary":"The notion of Erzeugungsgrad was introduced by Joos Heintz in 1983 to bound\nthe number of non-empty cells occurring after a process of quantifier\nelimination. We extend this notion and the combinatorial bounds of Theorem 2 in\nHeintz (1983) using the degree for constructible sets defined in\nPardo-Sebasti\\'an (2022). We show that the Erzeugungsgrad is the key ingredient\nto connect affine Intersection Theory over algebraically closed fields and the\nVC-Theory of Computational Learning Theory for families of classifiers given by\nparameterized families of constructible sets. In particular, we prove that the\nVC-dimension and the Krull dimension are linearly related up to logarithmic\nfactors based on Intersection Theory. Using this relation, we study the density\nof correct test sequences in evasive varieties. We apply these ideas to analyze\nparameterized families of neural networks with rational activation function.","main_category":"cs.LG","categories":"cs.LG,math.AG","published":"2025-04-15T16:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.11350v1","title":"Adaptive Compressible Smoothed Particle Hydrodynamics","summary":"Modulating the number of particles in a region is key to accurately capturing\nthe nuances in compressible flows with Smoothed Particle Hydrodynamics (SPH).\nThis paper details the implementation of a volume-based adaptive refinement and\nderefinement procedure, incorporating state-of-the-art features such as\nautomatic local adaptivity and solution adaptivity. A shock-aware particle\nshifting procedure is introduced to regularize the particle distribution while\npreserving the integrity of shocks. To our knowledge, this is the first\ndemonstration of shock-based solution adaptivity and shock-aware particle\nshifting in the literature. A wide variety of test problems, which involve flow\nin and around boundaries, are employed to highlight the utility of these\nadaptivity features in improving the results and in making simulations faster.\nFor instance, the adaptive resolution procedure is shown to deliver an order of\nmagnitude speedup. We also demonstrate the effectiveness of the adaptivity\nprocedure in resolving existing issues like errors due to interaction with\ndifferently spaced ghost particles at boundaries, formation of spot-like\nstructures due to particle clumping, and poorly resolved low-density regions.\nIn essence, the adaptivity technique presented in this paper is positioned as a\npowerful tool for simulating compressible flows with enhanced accuracy and\nefficiency.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T16:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.11359v1","title":"Deciphering the Structure of Push-Pull Conjugated Polymer Aggregates in\n  Solution and Film","summary":"The morphology of conjugated polymer films is highly tunable, influencing\ntheir performance in organic electronics. Specifically, molecular packing or\ncrystal structure strongly influence electronic processes such as light\nabsorption and charge transfer. However, the unit cells of high-performance\nelectron donor polymers remain unknown, limiting the understanding of how\nprocessing affects structure and device performance. This study characterizes\nthe aggregate structure of PM6-type push-pull polymers using X-ray scattering,\ncryogenic electron microscopy, and molecular dynamics (MD) simulations. A novel\nforward simulation approach linking grazing-incidence wide-angle X-ray\nscattering (GIWAXS) with MD resolves a monoclinic unit cell that accurately\ndescribes PM6-type polymer aggregates in both thin films and casting solutions.\nIntimate pi-pi stacking between donor and acceptor units emerges from this unit\ncell. Analysis of experimental GIWAXS using this unit cell quantifies sliding\ndisorder in these aggregates, which may impact device performance. The shape\nand internal structure of solution aggregates are also identified in\nchlorobenzene. These findings enhance our understanding of PM6-type polymer\npacking, outline a strategy for elucidating the crystal structure of weakly\nordered materials, and provide an opportunity to control optoelectronic\nperformance through aggregate formation in PM6 and other push-pull conjugated\npolymers.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-15T16:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11361v1","title":"Dynamical Casimir effect in superconducting cavities: from photon\n  generation to universal quantum gates","summary":"This chapter explores various aspects of the Dynamical Casimir Effect (DCE)\nand its implications in the context of circuit quantum electrodynamics (cQED).\nWe begin by reviewing the origin and fundamental properties of the DCE,\nincluding three equivalent mathematical frameworks that offer complementary\nperspectives on the phenomenon. These formulations will serve as a foundation\nfor the subsequent analyses. We then turn our attention to the practical\nrealization of the DCE in cQED-based architectures, discussing how modern\nsuperconducting circuits can be engineered to exhibit this inherently quantum\neffect. Building on this, we examine how the presence of the DCE influences the\nperformance of a quantum thermal machine operating with a quantum field,\nshedding light on the interplay between quantum fluctuations and thermodynamic\nprocesses. Further, we demonstrate how the DCE can be harnessed to implement a\ncontrolled-squeeze gate within a cQED platform, opening a path toward advanced\nquantum control and quantum information processing. The chapter concludes with\na synthesis of the main results and a discussion of potential future\ndirections.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-15T16:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.11364v1","title":"Teaching Large Language Models to Reason through Learning and Forgetting","summary":"Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11366v1","title":"A Decade of Wheat Mapping for Lebanon","summary":"Wheat accounts for approximately 20% of the world's caloric intake, making it\na vital component of global food security. Given this importance, mapping wheat\nfields plays a crucial role in enabling various stakeholders, including policy\nmakers, researchers, and agricultural organizations, to make informed decisions\nregarding food security, supply chain management, and resource allocation. In\nthis paper, we tackle the problem of accurately mapping wheat fields out of\nsatellite images by introducing an improved pipeline for winter wheat\nsegmentation, as well as presenting a case study on a decade-long analysis of\nwheat mapping in Lebanon. We integrate a Temporal Spatial Vision Transformer\n(TSViT) with Parameter-Efficient Fine Tuning (PEFT) and a novel post-processing\npipeline based on the Fields of The World (FTW) framework. Our proposed\npipeline addresses key challenges encountered in existing approaches, such as\nthe clustering of small agricultural parcels in a single large field. By\nmerging wheat segmentation with precise field boundary extraction, our method\nproduces geometrically coherent and semantically rich maps that enable us to\nperform in-depth analysis such as tracking crop rotation pattern over years.\nExtensive evaluations demonstrate improved boundary delineation and field-level\nprecision, establishing the potential of the proposed framework in operational\nagricultural monitoring and historical trend analysis. By allowing for accurate\nmapping of wheat fields, this work lays the foundation for a range of critical\nstudies and future advances, including crop monitoring and yield estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:31:54Z"}
{"aid":"http://arxiv.org/abs/2504.11376v1","title":"A Multi-Stage Potts Machine based on Coupled CMOS Ring Oscillators","summary":"This work presents a multi-stage coupled ring oscillator\n  based Potts machine, designed with phase-shifted Sub\nHarmonic-Injection-Locking (SHIL) to represent multi valued Potts spins at\ndifferent solution stages with os cillator phases. The proposed Potts machine\nis able to\n  solve a certain class of combinatorial optimization prob lems that natively\nrequire multivalued spins with a divide and-conquer approach, facilitated\nthrough the alternating\n  phase-shifted SHILs acting on the oscillators. The pro posed architecture\neliminates the need for any external in termediary mappings or usage of\nexternal memory, as the\n  influence of SHIL allows oscillators to act as both mem ory and computation\nunits. Planar 4-coloring problems\n  of sizes up to 2116 nodes are mapped to the proposed\n  architecture. Simulations demonstrate that the proposed\n  Potts machine provides exact solutions for smaller prob lems (e.g. 49 nodes)\nand generates solutions reaching up\n  to 97% accuracy for larger problems (e.g. 2116 nodes).","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-15T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.11377v1","title":"Improving Swimming Performance in Soft Robotic Fish with Distributed\n  Muscles and Embedded Kinematic Sensing","summary":"Bio-inspired underwater vehicles could yield improved efficiency,\nmaneuverability, and environmental compatibility over conventional\npropeller-driven underwater vehicles. However, to realize the swimming\nperformance of biology, there is a need for soft robotic swimmers with both\ndistributed muscles and kinematic feedback. This study presents the design and\nswimming performance of a soft robotic fish with independently controllable\nmuscles and embedded kinematic sensing distributed along the body. The soft\nswimming robot consists of an interior flexible spine, three axially\ndistributed sets of HASEL artificial muscles, embedded strain gauges, a\nstreamlined silicone body, and off-board electronics. In a fixed configuration,\nthe soft robot generates a maximum thrust of 7.9 mN when excited near its first\nresonant frequency (2 Hz) with synchronized antagonistic actuation of all\nmuscles. When excited near its second resonant frequency (8 Hz), synchronized\nmuscle actuation generates 5.0 mN of thrust. By introducing a sequential phase\noffset into the muscle actuation, the thrust at the second resonant frequency\nincreases to 7.2 mN, a 44% increase from simple antagonistic activation. The\nsequential muscle activation improves the thrust by increasing 1) the tail-beat\nvelocity and 2) traveling wave content in the swimming kinematics by four\ntimes. Further, the second resonant frequency (8 Hz) generates nearly as much\nthrust as the first resonance (2 Hz) while requiring only $\\approx25$% of the\ntail displacement, indicating that higher resonant frequencies have benefits\nfor swimming in confined environments where a smaller kinematic envelope is\nnecessary. These results demonstrate the performance benefits of independently\ncontrollable muscles and distributed kinematic sensing, and this type of soft\nrobotic swimmer provides a platform to address the open challenge of\nsensorimotor control.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T16:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.11379v1","title":"Omni$^2$: Unifying Omnidirectional Image Generation and Editing in an\n  Omni Model","summary":"$360^{\\circ}$ omnidirectional images (ODIs) have gained considerable\nattention recently, and are widely used in various virtual reality (VR) and\naugmented reality (AR) applications. However, capturing such images is\nexpensive and requires specialized equipment, making ODI synthesis increasingly\nimportant. While common 2D image generation and editing methods are rapidly\nadvancing, these models struggle to deliver satisfactory results when\ngenerating or editing ODIs due to the unique format and broad 360$^{\\circ}$\nField-of-View (FoV) of ODIs. To bridge this gap, we construct\n\\textbf{\\textit{Any2Omni}}, the first comprehensive ODI generation-editing\ndataset comprises 60,000+ training data covering diverse input conditions and\nup to 9 ODI generation and editing tasks. Built upon Any2Omni, we propose an\n\\textbf{\\underline{Omni}} model for \\textbf{\\underline{Omni}}-directional image\ngeneration and editing (\\textbf{\\textit{Omni$^2$}}), with the capability of\nhandling various ODI generation and editing tasks under diverse input\nconditions using one model. Extensive experiments demonstrate the superiority\nand effectiveness of the proposed Omni$^2$ model for both the ODI generation\nand editing tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.11383v1","title":"Accelerating Multiscale Modeling with Hybrid Solvers: Coupling FEM and\n  Neural Operators with Domain Decomposition","summary":"Numerical solvers for partial differential equations (PDEs) face challenges\nbalancing computational cost and accuracy, especially in multiscale and dynamic\nsystems. Neural operators can significantly speed up simulations; however, they\noften face challenges such as error accumulation and limited generalization in\nmultiphysics problems. This work introduces a novel hybrid framework that\nintegrates physics-informed DeepONet with FEM through domain decomposition. The\ncore innovation lies in adaptively coupling FEM and DeepONet subdomains via a\nSchwarz alternating method. This methodology strategically allocates\ncomputationally demanding regions to a pre-trained Deep Operator Network, while\nthe remaining computational domain is solved through FEM. To address dynamic\nsystems, we integrate the Newmark time-stepping scheme directly into the\nDeepONet, significantly mitigating error accumulation in long-term simulations.\nFurthermore, an adaptive subdomain evolution enables the ML-resolved region to\nexpand dynamically, capturing emerging fine-scale features without remeshing.\nThe framework's efficacy has been validated across a range of solid mechanics\nproblems, including static, quasi-static, and dynamic regimes, demonstrating\naccelerated convergence rates (up to 20% improvement compared to FE-FE\napproaches), while preserving solution fidelity with error < 1%. Our case\nstudies show that our proposed hybrid solver: (1) maintains solution continuity\nacross subdomain interfaces, (2) reduces computational costs by eliminating\nfine mesh requirements, (3) mitigates error accumulation in time-dependent\nsimulations, and (4) enables automatic adaptation to evolving physical\nphenomena. This work bridges the gap between numerical methods and AI-driven\nsurrogates, offering a scalable pathway for high-fidelity simulations in\nengineering and scientific applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.11403v1","title":"Counting irreducible representations of general linear groups and\n  unitary groups","summary":"Let $G$ be a general linear group over $\\BR$, $\\BC$, or $\\BH$, or a real\nunitary group. In this paper, we precisely describe the number of isomorphism\nclasses of irreducible Casselman-Wallach representations of $G$ with a given\ninfinitesimal character and a given associated variety, expressed in terms of\ncertain combinatorial data called painted Young diagrams and assigned Young\ndiagrams.","main_category":"math.RT","categories":"math.RT","published":"2025-04-15T17:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.11415v1","title":"Robustness and sex differences in skin cancer detection: logistic\n  regression vs CNNs","summary":"Deep learning has been reported to achieve high performances in the detection\nof skin cancer, yet many challenges regarding the reproducibility of results\nand biases remain. This study is a replication (different data, same analysis)\nof a study on Alzheimer's disease [28] which studied robustness of logistic\nregression (LR) and convolutional neural networks (CNN) across patient sexes.\nWe explore sex bias in skin cancer detection, using the PAD-UFES-20 dataset\nwith LR trained on handcrafted features reflecting dermatological guidelines\n(ABCDE and the 7-point checklist), and a pre-trained ResNet-50 model. We\nevaluate these models in alignment with [28]: across multiple training datasets\nwith varied sex composition to determine their robustness. Our results show\nthat both the LR and the CNN were robust to the sex distributions, but the\nresults also revealed that the CNN had a significantly higher accuracy (ACC)\nand area under the receiver operating characteristics (AUROC) for male patients\nthan for female patients. We hope these findings to contribute to the growing\nfield of investigating potential bias in popular medical machine learning\nmethods. The data and relevant scripts to reproduce our results can be found in\nour Github.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T17:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.11416v1","title":"Deep Learning-based Bathymetry Retrieval without In-situ Depths using\n  Remote Sensing Imagery and SfM-MVS DSMs with Data Gaps","summary":"Accurate, detailed, and high-frequent bathymetry is crucial for shallow\nseabed areas facing intense climatological and anthropogenic pressures. Current\nmethods utilizing airborne or satellite optical imagery to derive bathymetry\nprimarily rely on either SfM-MVS with refraction correction or Spectrally\nDerived Bathymetry (SDB). However, SDB methods often require extensive manual\nfieldwork or costly reference data, while SfM-MVS approaches face challenges\neven after refraction correction. These include depth data gaps and noise in\nenvironments with homogeneous visual textures, which hinder the creation of\naccurate and complete Digital Surface Models (DSMs) of the seabed. To address\nthese challenges, this work introduces a methodology that combines the\nhigh-fidelity 3D reconstruction capabilities of the SfM-MVS methods with\nstate-of-the-art refraction correction techniques, along with the spectral\nanalysis capabilities of a new deep learning-based method for bathymetry\nprediction. This integration enables a synergistic approach where SfM-MVS\nderived DSMs with data gaps are used as training data to generate complete\nbathymetric maps. In this context, we propose Swin-BathyUNet that combines\nU-Net with Swin Transformer self-attention layers and a cross-attention\nmechanism, specifically tailored for SDB. Swin-BathyUNet is designed to improve\nbathymetric accuracy by capturing long-range spatial relationships and can also\nfunction as a standalone solution for standard SDB with various training depth\ndata, independent of the SfM-MVS output. Experimental results in two completely\ndifferent test sites in the Mediterranean and Baltic Seas demonstrate the\neffectiveness of the proposed approach through extensive experiments that\ndemonstrate improvements in bathymetric accuracy, detail, coverage, and noise\nreduction in the predicted DSM. The code is available at\nhttps://github.com/pagraf/Swin-BathyUNet.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T17:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.11420v1","title":"Reinforcing Compositional Retrieval: Retrieving Step-by-Step for\n  Composing Informative Contexts","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet they often rely on external context to handle complex\ntasks. While retrieval-augmented frameworks traditionally focus on selecting\ntop-ranked documents in a single pass, many real-world scenarios demand\ncompositional retrieval, where multiple sources must be combined in a\ncoordinated manner. In this work, we propose a tri-encoder sequential retriever\nthat models this process as a Markov Decision Process (MDP), decomposing the\nprobability of retrieving a set of elements into a sequence of conditional\nprobabilities and allowing each retrieval step to be conditioned on previously\nselected examples. We train the retriever in two stages: first, we efficiently\nconstruct supervised sequential data for initial policy training; we then\nrefine the policy to align with the LLM's preferences using a reward grounded\nin the structural correspondence of generated programs. Experimental results\nshow that our method consistently and significantly outperforms baselines,\nunderscoring the importance of explicitly modeling inter-example dependencies.\nThese findings highlight the potential of compositional retrieval for tasks\nrequiring multiple pieces of evidence or examples.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:35:56Z"}
{"aid":"http://arxiv.org/abs/2504.11434v1","title":"Enhancing Out-of-Distribution Detection with Extended Logit\n  Normalization","summary":"Out-of-distribution (OOD) detection is essential for the safe deployment of\nmachine learning models. Recent advances have explored improved classification\nlosses and representation learning strategies to enhance OOD detection.\nHowever, these methods are often tailored to specific post-hoc detection\ntechniques, limiting their generalizability. In this work, we identify a\ncritical issue in Logit Normalization (LogitNorm), which inhibits its\neffectiveness in improving certain post-hoc OOD detection methods. To address\nthis, we propose Extended Logit Normalization ($\\textbf{ELogitNorm}$), a novel\nhyperparameter-free formulation that significantly benefits a wide range of\npost-hoc detection methods. By incorporating feature distance-awareness to\nLogitNorm, $\\textbf{ELogitNorm}$ shows more robust OOD separability and\nin-distribution (ID) confidence calibration than its predecessor. Extensive\nexperiments across standard benchmarks demonstrate that our approach\noutperforms state-of-the-art training-time methods in OOD detection while\nmaintaining strong ID classification accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.11435v1","title":"Robust Containment Queries over Collections of Trimmed NURBS Surfaces\n  via Generalized Winding Numbers","summary":"Efficient and accurate evaluation of containment queries for regions bound by\ntrimmed NURBS surfaces is important in many graphics and engineering\napplications. However, the algebraic complexity of surface-surface\nintersections makes gaps and overlaps between surfaces difficult to avoid for\nin-the-wild surface models. By considering this problem through the lens of the\ngeneralized winding number (GWN), a mathematical construction that is\nindifferent to the arrangement of surfaces in the shape, we can define a\ncontainment query that is robust to model watertightness. Applying contemporary\ntechniques for the 3D GWN on arbitrary curved surfaces would require some form\nof geometric discretization, potentially inducing containment\nmisclassifications near boundary components. In contrast, our proposed method\ncomputes an accurate GWN directly on the curved geometry of the input model. We\naccomplish this using a novel reformulation of the relevant surface integral\nusing Stokes' theorem, which in turn permits an efficient adaptive quadrature\ncalculation on the boundary and trimming curves of the model. While this is\nsufficient for \"far-field\" query points that are distant from the surface, we\naugment this approach for \"near-field\" query points (i.e., within a bounding\nbox) and even those coincident to the surface patches via a strategy that\ndirectly identifies and accounts for the jump discontinuity in the scalar\nfield. We demonstrate that our method of evaluating the GWN field is robust to\ncomplex trimming geometry in a CAD model, and is accurate up to arbitrary\nprecision at arbitrary distances from the surface. Furthermore, the derived\ncontainment query is robust to non-watertightness while respecting all curved\nfeatures of the input shape.","main_category":"cs.GR","categories":"cs.GR,cs.CG,cs.NA,math.NA,I.3.5","published":"2025-04-15T17:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.11455v1","title":"SimpleAR: Pushing the Frontier of Autoregressive Visual Generation\n  through Pretraining, SFT, and RL","summary":"This work presents SimpleAR, a vanilla autoregressive visual generation\nframework without complex architecure modifications. Through careful\nexploration of training and inference optimization, we demonstrate that: 1)\nwith only 0.5B parameters, our model can generate 1024x1024 resolution images\nwith high fidelity, and achieve competitive results on challenging\ntext-to-image benchmarks, e.g., 0.59 on GenEval and 79.66 on DPG; 2) both\nsupervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO)\ntraining could lead to significant improvements on generation aesthectics and\nprompt alignment; and 3) when optimized with inference acceleraton techniques\nlike vLLM, the time for SimpleAR to generate an 1024x1024 image could be\nreduced to around 14 seconds. By sharing these findings and open-sourcing the\ncode, we hope to reveal the potential of autoregressive visual generation and\nencourage more participation in this research field. Code is available at\nhttps://github.com/wdrink/SimpleAR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.11458v1","title":"Intermediate phases in $$-RuCl$_3$ under in-plane magnetic field\n  via interlayer spin interactions","summary":"$\\alpha$-RuCl$_3$ has attracted significant attention as a prime candidate\nfor the spin-1/2 Kitaev spin liquid in two-dimensional honeycomb lattices.\nAlthough its ground state is magnetically ordered, the order is suppressed\nunder a moderate in-plane magnetic field. The intermediate regime of the field\nhas exotic behaviours, some of which are claimed to originate from a Kitaev\nspin liquid. In resolving debates surrounding these behaviours, the interlayer\ninteractions in $\\alpha$-RuCl$_3$ have been largely overlooked due to their\nperceived weakness in van der Waals materials. However, near the transition,\nthey may become significant as the field energy approaches the interlayer\ncoupling scale. Here we investigate the effects of interlayer couplings in\n$\\alpha$-RuCl$_3$ with $R\\bar{3}$ and $C2/m$ structures. We first examine their\neffects on the transition temperature ($T_N$) using classical Monte Carlo\nsimulations. We found that the interlayer couplings have minimal effects on\n$T_N$, and the different $T_N$ between the two structures are mainly due to the\nanisotropy in the intralayer interactions. Focusing on the $R{\\bar 3}$\nstructure, we show that the nearest neighbour interlayer interaction is\nXXZ-type due to the symmetry, and the next nearest neighbor interaction of the\nKitaev-type is crucial for the transition between two zigzag orders under an\nin-plane field. Furthermore, an intermediate phase with a large unit cell\nemerges due to the interlayer interactions. Our findings provide new insights\ninto the exotic behaviours and sample dependence reported in $\\alpha$-RuCl$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.11776v1","title":"ALMASOP. Detection of Turbulence-induced Mass Assembly Shocks in\n  Starless Cores","summary":"Star formation is a series of mass assembly processes and starless cores,\nthose cold and dense condensations in molecular clouds, play a pivotal role as\ninitial seeds of stars. With only a limited sample of known starless cores,\nhowever, the origin and growth of such stellar precursors had not been well\ncharacterized previously. Meanwhile, the recent discovery of CH$_3$OH emission,\nwhich is generally associated with desorbed icy mantle in warm regions,\nparticularly at the periphery of starless cores also remains puzzling. We\npresent sensitive ALMA (Band~3) observations (at 3~mm) toward a sample of newly\nidentified starless cores in the Orion Molecular Cloud. The spatially resolved\nimages distinctly indicate that the observed CH$_3$OH and N$_2$H$^+$ emission\nassociated with these cores are morphologically anti-correlated and\nkinematically offset from each other. We postulate that the CH$_3$OH emission\nhighlights the desorption of icy mantle by shocks resulting from gas piling\nonto dense cores in the filaments traced by N$_2$H$^+$. Our magnetohydrodynamic\n(MHD) simulations of star formation in turbulent clouds combined with radiative\ntransfer calculations and imaging simulations successfully reproduced the\nobserved signatures and reaffirmed the above scenario at work. Our result\nserves as an intriguing and exemplary illustration, a snapshot in time, of the\ndynamic star-forming processes in turbulent clouds. The results offer\ncompelling insights into the mechanisms governing the growth of starless cores\nand the presence of gas-phase complex organic molecules associated with these\ncores.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-16T05:31:03Z"}
{"aid":"http://arxiv.org/abs/2504.11778v1","title":"Spectroscopic evidence for possible quantum spin liquid behavior in a\n  two-dimensional Mott insulator","summary":"Mott insulators with localized magnetic moments will exhibit a quantum spin\nliquid (QSL) state when the quantum fluctuations are strong enough to suppress\nthe ordering of the spins. Such an entangled state will give rise to collective\nexcitations, in which spin and charge information are carried separately. Our\nangle-resolved photoemission spectroscopy (ARPES) measurements on single-layer\n1T-TaS2 show a flat band around the zone center and a gap opening of about 200\nmeV in the low temperature, indicating 2D Mott insulating nature in the system.\nThis flat band is dispersionless in momentum space but shows anomalously broad\nwidth around the zone center and the spectral weight decays rapidly as momentum\nincreases. The observation is described as a spectral continuum from electron\nfractionalization, corroborated by a low energy effective model.The intensity\nof the flat band is reduced by surface doping with magnetic adatoms and the gap\nis closing, a result from the interaction between spin impurities coupled with\nspinons and the chargons, which gives rise to a charge redistribution. Doping\nwith nonmagnetic impurities behaves differently as the chemical potential shift\ndominates. These findings provide insight into the QSL states of strongly\ncorrelated electrons on 2D triangular lattices.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-16T05:31:42Z"}
{"aid":"http://arxiv.org/abs/2504.11783v1","title":"The Digital Cybersecurity Expert: How Far Have We Come?","summary":"The increasing deployment of large language models (LLMs) in the\ncybersecurity domain underscores the need for effective model selection and\nevaluation. However, traditional evaluation methods often overlook specific\ncybersecurity knowledge gaps that contribute to performance limitations. To\naddress this, we develop CSEBenchmark, a fine-grained cybersecurity evaluation\nframework based on 345 knowledge points expected of cybersecurity experts.\nDrawing from cognitive science, these points are categorized into factual,\nconceptual, and procedural types, enabling the design of 11,050 tailored\nmultiple-choice questions. We evaluate 12 popular LLMs on CSEBenchmark and find\nthat even the best-performing model achieves only 85.42% overall accuracy, with\nparticular knowledge gaps in the use of specialized tools and uncommon\ncommands. Different LLMs have unique knowledge gaps. Even large models from the\nsame family may perform poorly on knowledge points where smaller models excel.\nBy identifying and addressing specific knowledge gaps in each LLM, we achieve\nup to an 84% improvement in correcting previously incorrect predictions across\nthree existing benchmarks for two cybersecurity tasks. Furthermore, our\nassessment of each LLM's knowledge alignment with specific cybersecurity roles\nreveals that different models align better with different roles, such as GPT-4o\nfor the Google Senior Intelligence Analyst and Deepseek-V3 for the Amazon\nPrivacy Engineer. These findings underscore the importance of aligning LLM\nselection with the specific knowledge requirements of different cybersecurity\nroles for optimal performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T05:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.11787v1","title":"The AstroSat UV Deep Field South. III. Evolution of the UV Luminosity\n  Function and Luminosity Density from z~0.8-0.4","summary":"We characterise the rest-frame 1500 \\r{A} UV luminosity Function (UVLF) from\ndeep AstroSat/UVIT F154W and N242W imaging in the Great Observatories Origins\nSurvey South (GOODS-S) deep field. The UVLFs are constructed and subsequently\ncharacterised with fitted Schechter function parameters from FUV observations\nat z$<0.13$ and NUV observations in seven redshift bins in z~0.8-0.4. The UVLF\nslope ($\\alpha$) and characteristic magnitude ($M^*$) are consistent with\nprevious determinations for this redshift range based on AstroSat/UVIT\nGOODS-North observations, as well as with those from Galaxy evolution Explorer\nand Hubble Space Telescope observations. However, differences in the\nnormalisation factor ($\\phi_{*}$) are present for UVLFs for some redshift bins.\nWe compute the UV luminosity density, $\\rho_{\\rm UV}$, combining our determined\nUVLF parameters with literature determinations out to z$\\sim10$. The $\\rho_{\\rm\nUV}$ trend with redshift implies the rapid increase in cosmic star formation\ntill its peak at z$\\sim3$ (cosmic noon) followed by a slow decline till present\nday. Both the initial increase in cosmic star formation and subsequent decline\nare found to be more rapid than previous determinations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-16T05:40:32Z"}
{"aid":"http://arxiv.org/abs/2504.11789v1","title":"The vanishing discount problem for nonlocal Hamilton-Jacobi equations","summary":"We establish a convergence result for the vanishing discount problem in the\ncontext of nonlocal HJ equations. We consider a fairly general class of\ndiscounted first-order and convex HJ equations which incorporate an\nintegro-differential operator posed on the $d$-dimensional torus, and we show\nthat the solutions converge to a specific critical solution as the discount\nfactor tends to zero. Our approach relies on duality techniques for nonlocal\nconvex HJ equations, building upon Hahn-Banach separation theorems to develop a\ngeneralized notion of Mather measure. The results are applied to a specific\nclass of convex and superlinear Hamiltonians.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-16T05:42:24Z"}
{"aid":"http://arxiv.org/abs/2504.11807v1","title":"Entropy bounds from quantum thermodynamics","summary":"Within an inherently classical perspective, there is always an unavoidable\nenergy cost associated with the information deletion and this common lore is at\nthe heart of the Landauer's conjecture that does not impose, per se, any\nrelevant limit on the information acquisition. Although such a mindset should\ngenerally apply to systems of any size, its quantum mechanical implications are\nparticularly intriguing and, for this reason, we examine here a minimal\nphysical structure where the system and the environment are described,\nrespectively, by a pair of quantum oscillators coupled by an appropriate\nHermitian interaction able to amplify the entropy of the initial state. Since\nat the onset of the dynamical evolution the system is originally in a pure\nstate, its entropy variation is always positive semidefinite and the Landauer's\nconjecture should not impose any constraint. Nonetheless, provided the quantum\namplification is effective, it turns out that the entropy variation of the\nsystem always undershoots the heat transferred to the environment. When the\ninitial thermal state of the environment is characterized by a chemical\npotential, the entropy growth is bounded both by the particles and by the heat\nflowing to the environment. The limits deduced in the quantum thermodynamical\nframework are also scrutinized from a field theory standpoint where species of\ndifferent spins are copiously produced (especially in a cosmological context)\nthanks to the rapid variation of the space-time curvature.","main_category":"quant-ph","categories":"quant-ph,astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-16T06:41:50Z"}
{"aid":"http://arxiv.org/abs/2504.11809v1","title":"Efficient and Adaptive Simultaneous Speech Translation with Fully\n  Unidirectional Architecture","summary":"Simultaneous speech translation (SimulST) produces translations incrementally\nwhile processing partial speech input. Although large language models (LLMs)\nhave showcased strong capabilities in offline translation tasks, applying them\nto SimulST poses notable challenges. Existing LLM-based SimulST approaches\neither incur significant computational overhead due to repeated encoding of\nbidirectional speech encoder, or they depend on a fixed read/write policy,\nlimiting the efficiency and performance. In this work, we introduce Efficient\nand Adaptive Simultaneous Speech Translation (EASiST) with fully unidirectional\narchitecture, including both speech encoder and LLM. EASiST includes a\nmulti-latency data curation strategy to generate semantically aligned SimulST\ntraining samples and redefines SimulST as an interleaved generation task with\nexplicit read/write tokens. To facilitate adaptive inference, we incorporate a\nlightweight policy head that dynamically predicts read/write actions.\nAdditionally, we employ a multi-stage training strategy to align speech-text\nmodalities and optimize both translation and policy behavior. Experiments on\nthe MuST-C En$\\rightarrow$De and En$\\rightarrow$Es datasets demonstrate that\nEASiST offers superior latency-quality trade-offs compared to several strong\nbaselines.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T06:46:15Z"}
{"aid":"http://arxiv.org/abs/2504.11826v1","title":"When Should I Run My Application Benchmark?: Studying Cloud Performance\n  Variability for the Case of Stream Processing Applications","summary":"Performance benchmarking is a common practice in software engineering,\nparticularly when building large-scale, distributed, and data-intensive\nsystems. While cloud environments offer several advantages for running\nbenchmarks, it is often reported that benchmark results can vary significantly\nbetween repetitions -- making it difficult to draw reliable conclusions about\nreal-world performance. In this paper, we empirically quantify the impact of\ncloud performance variability on benchmarking results, focusing on stream\nprocessing applications as a representative type of data-intensive,\nperformance-critical system. In a longitudinal study spanning more than three\nmonths, we repeatedly executed an application benchmark used in research and\ndevelopment at Dynatrace. This allows us to assess various aspects of\nperformance variability, particularly concerning temporal effects. With\napproximately 591 hours of experiments, deploying 789 Kubernetes clusters on\nAWS and executing 2366 benchmarks, this is likely the largest study of its kind\nand the only one addressing performance from an end-to-end, i.e., application\nbenchmark perspective. Our study confirms that performance variability exists,\nbut it is less pronounced than often assumed (coefficient of variation of <\n3.7%). Unlike related studies, we find that performance does exhibit a daily\nand weekly pattern, although with only small variability (<= 2.5%). Re-using\nbenchmarking infrastructure across multiple repetitions introduces only a\nslight reduction in result accuracy (<= 2.5 percentage points). These key\nobservations hold consistently across different cloud regions and machine types\nwith different processor architectures. We conclude that for engineers and\nresearchers focused on detecting substantial performance differences (e.g., >\n5%) in...","main_category":"cs.SE","categories":"cs.SE,cs.DC,cs.PF","published":"2025-04-16T07:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.11829v1","title":"Dj Vu: Multilingual LLM Evaluation through the Lens of Machine\n  Translation Evaluation","summary":"Generation capabilities and language coverage of multilingual large language\nmodels (mLLMs) are advancing rapidly. However, evaluation practices for\ngenerative abilities of mLLMs are still lacking comprehensiveness, scientific\nrigor, and consistent adoption across research labs, which undermines their\npotential to meaningfully guide mLLM development. We draw parallels with\nmachine translation (MT) evaluation, a field that faced similar challenges and\nhas, over decades, developed transparent reporting standards and reliable\nevaluations for multilingual generative models. Through targeted experiments\nacross key stages of the generative evaluation pipeline, we demonstrate how\nbest practices from MT evaluation can deepen the understanding of quality\ndifferences between models. Additionally, we identify essential components for\nrobust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are\nrigorously assessed. We distill these insights into a checklist of actionable\nrecommendations for mLLM research and development.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T07:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.11836v1","title":"Non-centering for discrete-valued state transition models: an\n  application to ESBL-producing E. coli transmission in Malawi","summary":"Infectious disease transmission is often modelled by discrete-valued\nstochastic state-transition processes. Due to a lack of complete data, Bayesian\ninference for these models often relies on data-augmentation techniques. These\ntechniques are often inefficient or time consuming to implement. We introduce a\nnovel data-augmentation Markov chain Monte Carlo method for discrete-time\nindividual-based epidemic models, which we call the Rippler algorithm. This\nmethod uses the transmission model in the proposal step of the\nMetropolis-Hastings algorithm, rather than in the accept-reject step. We test\nthe Rippler algorithm on simulated data and apply it to data on\nextended-spectrum beta-lactamase (ESBL)-producing E. coli collected in\nBlantyre, Malawi. We compare the Rippler algorithm to two other commonly used\nBayesian inference methods for partially observed epidemic data, and find that\nit has a good balance between mixing speed and computational complexity.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T07:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.11837v1","title":"FiSMiness: A Finite State Machine Based Paradigm for Emotional Support\n  Conversations","summary":"Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Finite State Machine (FSM) on LLMs, and propose a framework called\nFiSMiness. Our framework allows a single LLM to bootstrap the planning during\nESC, and self-reason the seeker's emotion, support strategy and the final\nresponse upon each conversational turn. Substantial experiments on ESC datasets\nsuggest that FiSMiness outperforms many baselines, including direct inference,\nself-refine, chain of thought, finetuning, and external-assisted methods, even\nthose with many more parameters.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T07:52:06Z"}
{"aid":"http://arxiv.org/abs/2504.11838v1","title":"A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification","summary":"Despite the rapid evolution of learning and computer vision algorithms,\nFine-Grained Classification (FGC) still poses an open problem in many\npractically relevant applications. In the retail domain, for example, the\nidentification of fast changing and visually highly similar products and their\nproperties are key to automated price-monitoring and product recommendation.\nThis paper presents a novel Visual RAG pipeline that combines the Retrieval\nAugmented Generation (RAG) approach and Vision Language Models (VLMs) for\nfew-shot FGC. This Visual RAG pipeline extracts product and promotion data in\nadvertisement leaflets from various retailers and simultaneously predicts\nfine-grained product ids along with price and discount information. Compared to\nprevious approaches, the key characteristic of the Visual RAG pipeline is that\nit allows the prediction of novel products without re-training, simply by\nadding a few class samples to the RAG database. Comparing several VLM back-ends\nlike GPT-4o [23], GPT-4o-mini [24], and Gemini 2.0 Flash [10], our approach\nachieves 86.8% accuracy on a diverse dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T07:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.11847v1","title":"Ultra-Efficient Kidney Stone Fragment Removal via Spinner-Induced\n  Synergistic Circulation and Spiral Flow","summary":"Kidney stones can cause severe pain and complications such as chronic kidney\ndisease or kidney failure. Retrograde intrarenal surgery (RIRS), which uses\nlaser lithotripsy to fragment stones for removal via a ureteroscope, is widely\nadopted due to its safety and effectiveness. However, conventional fragment\nremoval methods using basketing and vacuum-assisted aspiration are inefficient,\nas they can capture only 1 to 3 fragments (1--3\\,mm in size) per pass, often\nrequiring dozens to hundreds of ureteroscope passes during a single procedure\nto completely remove the fragments. These limitations lead to prolonged\nprocedures and residual fragments that contribute to high recurrence rates. To\naddress these limitations, we present a novel spinner device that enables\nultra-efficient fragment removal through spinning-induced localized suction.\nThe spinner generates a three-dimensional spiral and circulating flow field\nthat dislodges and draws fragments into its cavity even from distances over\n20\\,mm, eliminating the need to chase fragments. It can capture over 60\nfragments (0.5--2\\,mm) or over 15 larger fragments (2--3\\,mm) in a single pass,\nsignificantly improving removal efficiency. In this work, the spinner design is\noptimized via computational fluid dynamics to maximize suction performance.\n\\textit{In vitro} testing demonstrates near 100\\% capture rates for up to 60\nfragments in a single operation and superior large-distance capture efficacy\ncompared to vacuum-assisted methods. \\textit{Ex vivo} testing of the integrated\nspinner-ureteroscope system in a porcine kidney confirmed its high performance\nby capturing 45 fragments in just 4 seconds during a single pass and achieving\ncomplete fragment clearance within a few passes.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.med-ph","published":"2025-04-16T08:10:16Z"}
{"aid":"http://arxiv.org/abs/2504.11856v1","title":"Cross-Frequency Collaborative Training Network and Dataset for\n  Semi-supervised First Molar Root Canal Segmentation","summary":"Root canal (RC) treatment is a highly delicate and technically complex\nprocedure in clinical practice, heavily influenced by the clinicians'\nexperience and subjective judgment. Deep learning has made significant\nadvancements in the field of computer-aided diagnosis (CAD) because it can\nprovide more objective and accurate diagnostic results. However, its\napplication in RC treatment is still relatively rare, mainly due to the lack of\npublic datasets in this field. To address this issue, in this paper, we\nestablished a First Molar Root Canal segmentation dataset called FMRC-2025.\nAdditionally, to alleviate the workload of manual annotation for dentists and\nfully leverage the unlabeled data, we designed a Cross-Frequency Collaborative\ntraining semi-supervised learning (SSL) Network called CFC-Net. It consists of\ntwo components: (1) Cross-Frequency Collaborative Mean Teacher (CFC-MT), which\nintroduces two specialized students (SS) and one comprehensive teacher (CT) for\ncollaborative multi-frequency training. The CT and SS are trained on different\nfrequency components while fully integrating multi-frequency knowledge through\ncross and full frequency consistency supervisions. (2) Uncertainty-guided\nCross-Frequency Mix (UCF-Mix) mechanism enables the network to generate\nhigh-confidence pseudo-labels while learning to integrate multi-frequency\ninformation and maintaining the structural integrity of the targets. Extensive\nexperiments on FMRC-2025 and three public dental datasets demonstrate that\nCFC-MT is effective for RC segmentation and can also exhibit strong\ngeneralizability on other dental segmentation tasks, outperforming\nstate-of-the-art SSL medical image segmentation methods. Codes and dataset will\nbe released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.11857v1","title":"Heat kernel estimates, fractional Riesz transforms and applications on\n  exterior domains","summary":"In this paper, we derive sharp two side heat kernel estimate on exterior\n$C^{1,1}$ domains in the plane, and sharp upper heat kernel bound on exterior\n$C^{1,\\mathrm{Dini}}$ domains in $\\mathbb{R}^n$, $n\\ge 2$. Estimates for\nGreen's function and Riesz potentials on exterior domains in the plane are also\npresented. Based on the heat kernel estimates, we show the boundedness of the\nfractional Riesz transforms on exterior $C^{1,\\mathrm{Dini}}$ domains in\n$\\mathbb{R}^n$, $n\\ge 2$. Some further applications to product and chain rules\nand nonlinear Schr\\\"odinger equation are also presented.","main_category":"math.CA","categories":"math.CA,math.AP","published":"2025-04-16T08:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.11858v1","title":"Synthetic Data for Blood Vessel Network Extraction","summary":"Blood vessel networks in the brain play a crucial role in stroke research,\nwhere understanding their topology is essential for analyzing blood flow\ndynamics. However, extracting detailed topological vessel network information\nfrom microscopy data remains a significant challenge, mainly due to the\nscarcity of labeled training data and the need for high topological accuracy.\nThis work combines synthetic data generation with deep learning to\nautomatically extract vessel networks as graphs from volumetric microscopy\ndata. To combat data scarcity, we introduce a comprehensive pipeline for\ngenerating large-scale synthetic datasets that mirror the characteristics of\nreal vessel networks. Our three-stage approach progresses from abstract graph\ngeneration through vessel mask creation to realistic medical image synthesis,\nincorporating biological constraints and imaging artifacts at each stage. Using\nthis synthetic data, we develop a two-stage deep learning pipeline of 3D\nU-Net-based models for node detection and edge prediction. Fine-tuning on real\nmicroscopy data shows promising adaptation, improving edge prediction F1 scores\nfrom 0.496 to 0.626 by training on merely 5 manually labeled samples. These\nresults suggest that automated vessel network extraction is becoming\npractically feasible, opening new possibilities for large-scale vascular\nanalysis in stroke research.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.11863v1","title":"Understanding the evolution of the magnetic ground state in\n  Ba$_4$NaRu$_3$O$_{12}$","summary":"We report a comprehensive investigation of the quadruple perovskite\nBa$_4$NaRu$_3$O$_{12}$, in which we discover a robust spin-lattice coupled\nground state characterized by a long-range antiferromagnetic ordering at $T_N\n\\sim$ 257 K. The system's unique structural motif of three symmetrically\ndistinct magnetic ions, including Ru dimers separated by non-magnetic layers,\nis intimately correlated with its magnetic behavior, as evidenced by\ntemperature-dependent diffraction measurements and specific heat data. The\npowder neutron diffraction patterns at 13 K showed that the spins within the\ndimers are antiparallel, leading to a net zero moment contribution and a\nstaggered arrangement of the triangular layers formed by the Ru moments within\nthe corner-shared octahedra along the $c$-axis. The low-temperature specific\nheat revealed an extra boson peak contribution from optical modes with a\nmaximum vibrational energy of $\\sim$55cm$^{-1}$. The charge transport exhibited\nvariable-range hopping (VRH) behaviour below $T_N$, with a stronger\nenergy-dependence than expected from the Efros-Shklovskii model, suggesting the\npresence of multiparticle correlation effects.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-16T08:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11866v1","title":"On the Problem of Best Arm Retention","summary":"This paper presents a comprehensive study on the problem of Best Arm\nRetention (BAR), which has recently found applications in streaming algorithms\nfor multi-armed bandits. In the BAR problem, the goal is to retain $m$ arms\nwith the best arm included from $n$ after some trials, in stochastic\nmulti-armed bandit settings. We first investigate pure exploration for the BAR\nproblem under different criteria, and then minimize the regret with specific\nconstraints, in the context of further exploration in streaming algorithms.\n  - We begin by revisiting the lower bound for the $(\\varepsilon,\\delta)$-PAC\nalgorithm for Best Arm Identification (BAI) and adapt the classical\nKL-divergence argument to derive optimal bounds for $(\\varepsilon,\\delta)$-PAC\nalgorithms for BAR.\n  - We further study another variant of the problem, called $r$-BAR, which\nrequires the expected gap between the best arm and the optimal arm retained is\nless than $r$. We prove tight sample complexity for the problem.\n  - We explore the regret minimization problem for $r$-BAR and develop\nalgorithm beyond pure exploration. We conclude with a conjecture on the optimal\nregret in this setting.","main_category":"cs.LG","categories":"cs.LG,cs.DS","published":"2025-04-16T08:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11873v1","title":"Transferable Deployment of Semantic Edge Inference Systems via\n  Unsupervised Domain Adaption","summary":"This paper investigates deploying semantic edge inference systems for\nperforming a common image clarification task. In particular, each system\nconsists of multiple Internet of Things (IoT) devices that first locally encode\nthe sensing data into semantic features and then transmit them to an edge\nserver for subsequent data fusion and task inference. The inference accuracy is\ndetermined by efficient training of the feature encoder/decoder using labeled\ndata samples. Due to the difference in sensing data and communication channel\ndistributions, deploying the system in a new environment may induce high costs\nin annotating data labels and re-training the encoder/decoder models. To\nachieve cost-effective transferable system deployment, we propose an efficient\nDomain Adaptation method for Semantic Edge INference systems (DASEIN) that can\nmaintain high inference accuracy in a new environment without the need for\nlabeled samples. Specifically, DASEIN exploits the task-relevant data\ncorrelation between different deployment scenarios by leveraging the techniques\nof unsupervised domain adaptation and knowledge distillation. It devises an\nefficient two-step adaptation procedure that sequentially aligns the data\ndistributions and adapts to the channel variations. Numerical results show\nthat, under a substantial change in sensing data distributions, the proposed\nDASEIN outperforms the best-performing benchmark method by 7.09% and 21.33% in\ninference accuracy when the new environment has similar or 25 dB lower channel\nsignal to noise power ratios (SNRs), respectively. This verifies the\neffectiveness of the proposed method in adapting both data and channel\ndistributions in practical transfer deployment applications.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-16T08:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.11878v1","title":"A Novel Approach to Secure RSMA Networks","summary":"This letter introduces a novel data-dependent interleaving technique designed\nto enhance the security of rate-splitting multiple access (RSMA) networks by\nprotecting the common stream from eavesdropping threats. Specifically, we\nexploit the RSMA structure by interleaving the common bits of each user based\non a sequence derived from their private bits. By decoding its private stream,\nthe legitimate receiver reconstructs the interleaving sequence set by the\ntransmitter and successfully de-interleaves the common stream. Therefore, the\ncommon part is successfully prevented from being intercepted by an eavesdropper\nwho is unable to deduce the dynamic changing interleaving permutations. To\nensure dynamic interleaving sequences, a private bit selection approach that\nbalances the trade-off between security and system efficiency is proposed.\nSimulation findings confirm the effectiveness of the suggested method, showing\nnotable security improvements while maintaining robust overall system\nreliability.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T08:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.11885v1","title":"HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT\n  Problems","summary":"Graph neural networks (GNNs) have shown promising performance in solving both\nBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due\nto their ability to efficiently model and capture the structural dependencies\nbetween literals and clauses. However, GNN methods for solving Weighted MaxSAT\nproblems remain underdeveloped. The challenges arise from the non-linear\ndependency and sensitive objective function, which are caused by the\nnon-uniform distribution of weights across clauses. In this paper, we present\nHyperSAT, a novel neural approach that employs an unsupervised hypergraph\nneural network model to solve Weighted MaxSAT problems. We propose a hypergraph\nrepresentation for Weighted MaxSAT instances and design a cross-attention\nmechanism along with a shared representation constraint loss function to\ncapture the logical interactions between positive and negative literal nodes in\nthe hypergraph. Extensive experiments on various Weighted MaxSAT datasets\ndemonstrate that HyperSAT achieves better performance than state-of-the-art\ncompetitors.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T09:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.11886v1","title":"Detection of wave activity within a realistic 3D MHD quiet sun\n  simulation","summary":"Context. Tracing wave activity from the photosphere to the corona has\nimportant implications for coronal heating and prediction of the solar wind.\nDespite extensive theory and simulations, the detection of waves in realistic\nMHD simulations still presents a large challenge due to wave interaction, mode\nconversion, and damping mechanisms. Aims. We conducted this study to detect\nlocalised wave activity within a realistic MHD simulation of the solar\natmosphere by the Bifrost code. Methods. We present a new method of detecting\nthe most significant contributions of wave activity within localised areas of\nthe domain, aided by Discrete Fourier Transforms and frequency filtering. We\ncorrelate oscillations in the vertical & horizontal magnetic field, velocities\nparallel & perpendicular to the magnetic field, and pressure to infer the\nnature of the dominant wave modes. Results. Our method captures the most\npowerful frequencies and wavenumbers, as well as providing a new diagnostic for\ndamping processes. We infer the presence of magnetoacoustic waves in the\nboundaries of prominent chromospheric/coronal swirling features. We find these\nwaves are likely damped by viscous heating in the swirl boundaries,\ncontributing to heating in the upper atmosphere. Conclusions. Using the most\nsignificant frequencies decomposition, we highlight that energy can be\ntransported from the lower atmosphere to the upper atmosphere through waves and\nfluctuations along the swirl boundaries. Although further analysis is needed to\nconfirm these findings, our new method provides a path forward to investigate\nwave activity in the solar atmosphere","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-16T09:14:14Z"}
{"aid":"http://arxiv.org/abs/2504.11902v1","title":"The axial-vector form factor of the nucleon in a finite box","summary":"We consider the axial-vector form factor of the nucleon in a finite box.\nStarting from the chiral Lagrangian with nucleon and Delta-isobar degrees of\nfreedom, we address, at the one-loop level, the impact of two types of\nfinite-volume effects. On the one hand, there are the implicit effects from the\nin-box values of the nucleon and Delta-isobar masses. On the other hand, there\nare the explicit effects caused by computing the in-box loop integrals with the\nvalues of the nucleon and Delta-isobar masses obtained in the infinite-volume\nlimit. Selected numerical results are shown for three lattice ensembles. We\nshow that the implicit effects dominate the in-box form factor. Our results are\npresented in terms of a set of basis functions that generalize the\nPassarino-Veltman reduction scheme to the finite-box case, such that only\nscalar loop integrals have to be performed. The techniques we developed are\nmore generally relevant for lattice studies of hadronic quantities.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-16T09:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.11917v1","title":"Dirac Representation for Lattice Spin Operators: Spin-$1/2$ and Spin-$1$\n  cases","summary":"A novel quantum representation of lattice spin operators (LSOs) is achieved\nby mapping quantum spins onto their classical analogues for spin size $S=1/2$\nand $S=1$. The \"braket\" representations of LSOs are attained thanks to a\nprofound inspection into the binary/ternary distribution of classical\nbits/trits in non-negative integers. We claim the possility of getting the\n$j$th digit of a positive integer without performing any binary/ternary\ndecomposition. Analytical formulas returning the $j$th bits/trits of an integer\nare presented. Impacts of our achievements in Physics are highlighted by\nrevisiting the $1D$ spin-$1/2$ {XXZ} Heisenberg model with open boundaries in a\nmagnetic field in both absence (uniform magnetic field) and presence of\ndisorder (random magnetic field). In the absence of disorder (clean system), we\ndemonstrate that the corresponding eigenvalues problem can be reduced to a\ntight-binding problem on a graph and solved without resorting to any spinless\ntransformation nor the Bethe Anzath. In the presence of disorder, a convergent\nperturbation theory is elaborated. Our analytical results are compared with\ndata from exact diagonalization for relatively large spin systems ($K\\leq 18$\nspins with $K$ denoting the total number of spins) obtained by implementing\nboth the global $U(1)$ symmetry to block-diagonalize the Hamiltonian and the\nspin-inversion symmetry for two-fold block-diagonalization in the sector with\ntotal magnetization $\\mathcal{J}^z=0$. We observe a good agreement between both\nresults.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-16T09:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.11920v1","title":"Lagrangian finite elements in Sobolev-like spaces of order $3/2$","summary":"This paper introduces a Sobolev-like space of order $3/2$, denoted as\n$\\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$\nelements. It is motivated by the limitations of current stability analysis of\nthe evolving surface finite element method (ESFEM), which relies exclusively on\nan energy estimate framework. To establish a PDE-based analysis framework for\nESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the\n$C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity\nfor solutions. To overcome this difficulty, we first examine the properties of\nthe continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang\ntype interpolation operators to bridge to the discrete $\\widehat{H}^{3/2}$\nspace. Our new $\\widehat{H}^{3/2}$ space is shown to be compatible with the\nelliptic PDE regularity theory, the trace inequality, and the inverse\ninequality. Notably, we extend the critical domain deformation estimate in\nESFEM to the $\\widehat{H}^{3/2}$ setting. The $\\widehat{H}^{3/2}$ theory\nprovides a foundation for establishing a PDE-based convergence analysis\nframework of ESFEM.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11927v1","title":"Super-LoRa: Enhancing LoRa Throughput via Payload Superposition","summary":"This paper presents Super-LoRa, a novel approach to enhancing the throughput\nof LoRa networks by leveraging the inherent robustness of LoRa modulation\nagainst interference. By superimposing multiple payload symbols, Super-LoRa\nsignificantly increases the data rate while maintaining lower transmitter and\nreceiver complexity. Our solution is evaluated through both simulations and\nreal-world experiments, showing a potential throughput improvement of up to 5x\ncompared to standard LoRa. This advancement positions Super-LoRa as a viable\nsolution for data-intensive IoT applications such as smart cities and precision\nagriculture, which demand higher data transmission rates.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T10:02:38Z"}
{"aid":"http://arxiv.org/abs/2504.11928v1","title":"The Jade Gateway to Trust: Exploring How Socio-Cultural Perspectives\n  Shape Trust Within Chinese NFT Communities","summary":"Today's world is witnessing an unparalleled rate of technological\ntransformation. The emergence of non-fungible tokens (NFTs) has transformed how\nwe handle digital assets and value. Despite their initial popularity, NFTs face\ndeclining adoption influenced not only by cryptocurrency volatility but also by\ntrust dynamics within communities. From a social computing perspective,\nunderstanding these trust dynamics offers valuable insights for the development\nof both the NFT ecosystem and the broader digital economy. China presents a\ncompelling context for examining these dynamics, offering a unique intersection\nof technological innovation and traditional cultural values. Through a content\nanalysis of eight Chinese NFT-focused WeChat groups and 21 semi-structured\ninterviews, we examine how socio-cultural factors influence trust formation and\ndevelopment. We found that trust in Chinese NFT communities is significantly\nmolded by local cultural values. To be precise, Confucian virtues, such as\nbenevolence, propriety, and integrity, play a crucial role in shaping these\ntrust relationships. Our research identifies three critical trust dimensions in\nChina's NFT market: (1) technological, (2) institutional, and (3) social. We\nexamined the challenges in cultivating each dimension. Based on these insights,\nwe developed tailored trust-building guidelines for Chinese NFT stakeholders.\nThese guidelines address trust issues that factor into NFT's declining\npopularity and could offer valuable strategies for CSCW researchers,\ndevelopers, and designers aiming to enhance trust in global NFT communities.\nOur research urges CSCW scholars to take into account the unique socio-cultural\ncontexts when developing trust-enhancing strategies for digital innovations and\nonline interactions.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-16T10:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.11931v1","title":"Local-in-time well-posedness for 2D compressible magneto-micropolar\n  boundary layer in Sobolev spaces","summary":"In this paper, we study the two-dimensional compressible magneto-micropolar\nboundary layer equations on the half-plane, which are derived from 2D\ncompressible magneto-micropolar fluid equations with the non-slip boundary\ncondition on velocity, Dirichlet boundary condition on micro-rotational\nvelocity and perfectly conducting boundary condition on magnetic field. Based\non a nonlinear coordinate transformation proposed in \\cite{LXY2019}, we first\nprove the local-in-time well-posedness for the compressible magneto-micropolar\nboundary layer system in Sobolev spaces, provided that initial tangential\nmagnetic field is non-degenerate.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.11938v1","title":"Exact noise and dissipation operators for quantum stochastic\n  thermodynamics","summary":"The theory of open quantum systems plays a fundamental role in several\nscientific and technological disciplines, from quantum computing and\ninformation science to molecular electronics and quantum thermodynamics.\nDespite its widespread relevance, a rigorous formulation of quantum dissipation\nin conjunction with thermal noise remains a topic of active research. In this\nwork, we establish a formal correspondence between classical stochastic\nthermodynamics, in particular the Fokker-Planck and Klein-Kramers equations,\nand the quantum master equation. Building on prior studies of multiplicative\nnoise in classical stochastic differential equations, we demonstrate that\nthermal noise at the quantum level manifests as a multidimensional geometric\nstochastic process. By applying canonical quantization, we introduce a novel\nHermitian dissipation operator that serves as a quantum analogue of classical\nviscous friction. This operator not only preserves the mathematical rigor of\nopen quantum system dynamics but also allows for a well-defined expression of\nheat exchange between a system and its environment, enabling the formulation of\nan alternative quantum equipartition theorem. Our framework ensures a precise\nenergy balance that aligns with the first law of thermodynamics and an entropy\nbalance consistent with the second law. The theoretical formalism is applied to\ntwo prototypical quantum systems, the harmonic oscillator and a particle in an\ninfinite potential well, for whom it provides new insights into nonequilibrium\nthermodynamics at the quantum scale. Our results advance the understanding of\ndissipation in quantum systems and establish a foundation for future studies on\nstochastic thermodynamics in the quantum domain.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-16T10:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.11939v1","title":"Assessing WGC Compatibility in ModMax Black Holes via Photon Spheres\n  Analysis and WCCC Validation","summary":"It seems that the regime of Hawking radiation and evaporation ultimately\ndrives charged black holes toward super-extremality of the charge parameter and\nthe dominance of extremal conditions. This progression, in turn, lays the\ngroundwork for satisfying the necessary conditions for the Weak Gravity\nConjecture (WGC). Preliminary studies indicate that black holes such as the\nReissner-Nordstr$\\\"o$m (RN) model, in their initial form, lack the capacity to\nsustain super-extremality of the charge parameter. If such conditions arise,\nthese black holes transition into naked singularities-a scenario that is highly\nundesirable due to the loss of causality and the breakdown of space-time\ngeometry. This raises whether the inability to sustain super-extremality is an\ninherent property of the model or a consequence of the approximations and\nprecision limitations employed in its construction. To address this, we turned\nto the ModMax model, which represents an extension of the RN model. Our\nanalysis revealed that the ModMax model not only accommodates super-extremality\nof the charge parameter but also, under certain conditions, emerges as a\npromising candidate for investigating the WGC. Furthermore, we independently\nobserved how the inclusion of the de Sitter radius ($\\ell$) in the AdS model\nand $f(R)$ gravitational corrections-both of which enhance and complicate the\nmodel-can have a direct impact on the range of super-extremal charge tolerance\nwhich, in turn, provides the realization of the conditions necessary for the\nWGC.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T10:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.11976v1","title":"Stochastic Quadrature Rules for Solving PDEs using Neural Networks","summary":"In this article, we consider issues surrounding integration when using Neural\nNetworks to solve Partial Differential Equations. We focus on the Deep Ritz\nMethod as it is of practical interest and sensitive to integration errors. We\nshow how both deterministic integration rules as well as biased, stochastic\nquadrature can lead to erroneous results, whilst high order, unbiased\nstochastic quadrature rules on integration meshes can significantly improve\nconvergence at an equivalent computational cost. Furthermore, we propose novel\nstochastic quadrature rules for triangular and tetrahedral elements, offering\ngreater flexibility when designing integration meshes in more complex\ngeometries. We highlight how the variance in the stochastic gradient limits\nconvergence, whilst quadrature rules designed to give similar errors when\nintegrating the loss function may lead to disparate results when employed in a\ngradient-based optimiser.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:15:38Z"}
{"aid":"http://arxiv.org/abs/2504.11979v1","title":"On the Regularity of Random 2-SAT and 3-SAT","summary":"We consider the random $k$-SAT problem with $n$ variables, $m=m(n)$ clauses,\nand clause density $\\alpha=\\lim_{n\\to\\infty}m/n$ for $k=2,3$. It is known that\nif $\\alpha$ is small enough, then the random $k$-SAT problem admits a solution\nwith high probability, which we interpret as the problem being\nunder-constrained. In this paper, we quantify exactly how under-constrained the\nrandom $k$-SAT problems are by determining their degrees of freedom, which we\ndefine as the threshold for the number of variables we can fix to an arbitrary\nvalue before the problem no longer is solvable with high probability. We show\nthat the random $2$-SAT and $3$-SAT problems have $n/m^{1/2}$ and $n/m^{1/3}$\ndegrees of freedom, respectively. Our main result is an explicit computation of\nthe corresponding threshold functions. Our result shows that the threshold\nfunction for the random $2$-SAT problem is regular, while it is non-regular for\nthe random $3$-SAT problem. By regular, we mean continuous and analytic on the\ninterior of its support. This result shows that the random $3$-SAT problem is\nmore sensitive to small changes in the clause density $\\alpha$ than the random\n$2$-SAT problem.","main_category":"math.PR","categories":"math.PR,cs.DM","published":"2025-04-16T11:17:56Z"}
{"aid":"http://arxiv.org/abs/2504.11981v1","title":"Hardware-Friendly Delayed-Feedback Reservoir for Multivariate\n  Time-Series Classification","summary":"Reservoir computing (RC) is attracting attention as a machine-learning\ntechnique for edge computing. In time-series classification tasks, the number\nof features obtained using a reservoir depends on the length of the input\nseries. Therefore, the features must be converted to a constant-length\nintermediate representation (IR), such that they can be processed by an output\nlayer. Existing conversion methods involve computationally expensive matrix\ninversion that significantly increases the circuit size and requires processing\npower when implemented in hardware. In this article, we propose a simple but\neffective IR, namely, dot-product-based reservoir representation (DPRR), for RC\nbased on the dot product of data features. Additionally, we propose a\nhardware-friendly delayed-feedback reservoir (DFR) consisting of a nonlinear\nelement and delayed feedback loop with DPRR. The proposed DFR successfully\nclassified multivariate time series data that has been considered particularly\ndifficult to implement efficiently in hardware. In contrast to conventional DFR\nmodels that require analog circuits, the proposed model can be implemented in a\nfully digital manner suitable for high-level syntheses. A comparison with\nexisting machine-learning methods via field-programmable gate array\nimplementation using 12 multivariate time-series classification tasks confirmed\nthe superior accuracy and small circuit size of the proposed method.","main_category":"cs.LG","categories":"cs.LG,cs.AR","published":"2025-04-16T11:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.11999v1","title":"A Complex-valued SAR Foundation Model Based on Physically Inspired\n  Representation Learning","summary":"Vision foundation models in remote sensing have been extensively studied due\nto their superior generalization on various downstream tasks. Synthetic\nAperture Radar (SAR) offers all-day, all-weather imaging capabilities,\nproviding significant advantages for Earth observation. However, establishing a\nfoundation model for SAR image interpretation inevitably encounters the\nchallenges of insufficient information utilization and poor interpretability.\nIn this paper, we propose a remote sensing foundation model based on\ncomplex-valued SAR data, which simulates the polarimetric decomposition process\nfor pre-training, i.e., characterizing pixel scattering intensity as a weighted\ncombination of scattering bases and scattering coefficients, thereby endowing\nthe foundation model with physical interpretability. Specifically, we construct\na series of scattering queries, each representing an independent and meaningful\nscattering basis, which interact with SAR features in the scattering query\ndecoder and output the corresponding scattering coefficient. To guide the\npre-training process, polarimetric decomposition loss and power\nself-supervision loss are constructed. The former aligns the predicted\ncoefficients with Yamaguchi coefficients, while the latter reconstructs power\nfrom the predicted coefficients and compares it to the input image's power. The\nperformance of our foundation model is validated on six typical downstream\ntasks, achieving state-of-the-art results. Notably, the foundation model can\nextract stable feature representations and exhibits strong generalization, even\nin data-scarce conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T11:51:34Z"}
{"aid":"http://arxiv.org/abs/2504.12022v1","title":"Hardness and Approximation Schemes for Discrete Packing and Domination","summary":"We present polynomial-time approximation schemes based on local search}\ntechnique for both geometric (discrete) independent set (\\mdis) and geometric\n(discrete) dominating set (\\mdds) problems, where the objects are arbitrary\nradii disks and arbitrary side length axis-parallel squares. Further, we show\nthat the \\mdds~problem is \\apx-hard for various shapes in the plane. Finally,\nwe prove that both \\mdis~and \\mdds~problems are \\np-hard for unit disks\nintersecting a horizontal line and axis-parallel unit squares intersecting a\nstraight line with slope $-1$.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-16T12:28:34Z"}
{"aid":"http://arxiv.org/abs/2504.12031v1","title":"Proof-Carrying Neuro-Symbolic Code","summary":"This invited paper introduces the concept of \"proof-carrying neuro-symbolic\ncode\" and explains its meaning and value, from both the \"neural\" and the\n\"symbolic\" perspectives. The talk outlines the first successes and challenges\nthat this new area of research faces.","main_category":"cs.PL","categories":"cs.PL,cs.AI,cs.LO","published":"2025-04-16T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.12039v1","title":"RadMamba: Efficient Human Activity Recognition through Radar-based\n  Micro-Doppler-Oriented Mamba State-Space Model","summary":"Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\noffer improved modeling capabilities and have made efforts toward lightweight\ndesigns. However, their computational complexity remains relatively high. To\nleverage the strengths of transformer architectures while simultaneously\nenhancing accuracy and reducing computational complexity, this paper introduces\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\nspecifically tailored for radar-based HAR. Across three diverse datasets,\nRadMamba matches the top-performing previous model's 99.8% classification\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\nparameters. In scenarios with continuous sequences of actions evaluated on\nDataset UoG2020, RadMamba surpasses other models with significantly higher\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\ncode is available at: https://github.com/lab-emi/AIRHAR.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T12:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.12047v1","title":"Non-local Wasserstein Geometry, Gradient Flows, and Functional\n  Inequalities for Stationary Point Processes","summary":"We construct a non-local Benamou-Brenier-type transport distance on the space\nof stationary point processes and analyse the induced geometry. We show that\nour metric is a specific variant of the transport distance recently constructed\nin [DSHS24]. As a consequence, we show that the Ornstein-Uhlenbeck semigroup is\nthe gradient flow of the specific relative entropy w.r.t. the newly constructed\ndistance. Furthermore, we show the existence of stationary geodesics, establish\n$1$-geodesic convexity of the specific relative entropy, and derive stationary\nanalogues of functional inequalities such as a specific HWI inequality and a\nspecific Talagrand inequality. One of the key technical contributions is the\nexistence of solutions to the non-local continuity equation between arbitrary\npoint processes.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T13:03:48Z"}
{"aid":"http://arxiv.org/abs/2504.12056v1","title":"Refining the Understanding of Operator Size Dynamics in Open Quantum\n  Systems","summary":"Information scrambling refers to the phenomenon in which local quantum\ninformation in a many-body system becomes dispersed throughout the entire\nsystem under unitary evolution. It has been extensively studied in closed\nquantum systems, where it is quantified by operator size growth, revealing deep\nconnections between condensed matter physics, high-energy physics, and quantum\ninformation. However, when extending the study of operator size dynamics to\nopen quantum systems, two different definitions of operator size distributions\nemerge. These definitions are based on different treatments of the bath. In\nthis work, we aim to establish a unified picture for operator size dynamics in\nopen quantum systems, using the solvable Brownian SYK models at generic system\nsize. In particular, we provide the conditions under which the signature of\nscrambling transition, discovered using one particular definition, appears in\noperator size dynamics under the other definition. Additionally, we extend\nprevious studies by exploring finite-size effects that are not captured by the\nscramblon theory. Our results provide a refined understanding of operator size\ndynamics in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el,hep-th","published":"2025-04-16T13:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.12057v1","title":"Pressure-tuned spin chains in brochantite, Cu$_4$SO$_4$(OH)$_6$","summary":"Using high-pressure single-crystal x-ray diffraction combined with\nthermodynamic measurements and density-functional calculations, we uncover the\nmicroscopic magnetic model of the mineral brochantite, Cu$_4$SO$_4$(OH)$_6$,\nand its evolution upon compression. The formation of antiferromagnetic spin\nchains with the effective intrachain coupling of $J\\simeq 100$\\,K is attributed\nto the occurrence of longer Cu--Cu distances and larger Cu--O--Cu bond angles\nbetween the structural chains within the layers of the brochantite structure.\nThese zigzag spin chains are additionally stabilized by ferromagnetic couplings\n$J_2$ between second neighbors and moderately frustrated by several\nantiferromagnetic couplings that manifest themselves in the reduced N\\'eel\ntemperature of the material. Pressure tuning of the brochantite structure keeps\nits monoclinic symmetry unchanged and leads to the growth of antiferromagnetic\n$J$ with the rate of 3.2\\,K/GPa, although this trend is primarily caused by the\nenhanced ferromagnetic couplings $J_2$. Our results show that the nature of\nmagnetic couplings in brochantite and in other layered Cu$^{2+}$ minerals is\ncontrolled by the size of the lattice translation along their structural chains\nand by the extent of the layer buckling.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-16T13:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.12070v1","title":"A Light Lepton-flavor-violating Flavon: the Messenger of Neutrino Mixing\n  and Muon $g-2$","summary":"In neutrino physics, a class of models with local or global family symmetries\nmay be invoked, and then a flavon field is needed to realize the full neutrino\nmixing. This flavon may shed light on the long-standing muon $g-2$ puzzle. In\nthis work, we explore this idea in the $({B-L})_{13}$ gauge extension to the\nstandard model (SM), in which realistic neutrino mixing requires both a SM\nsinglet flavon $s$ and a vector-like lepton (VLL) doublet. The dominant\ncoupling between the flavon and leptons is in the manner of\nlepton-flavor-violation (LFV). Through an analytical analysis of the SM\nlepton-VLL mixing matrix, we find that the parameter space of the $s\\bar\\mu\ne$-type flavon to explain the muon $g-2$ has been completely excluded by the\nspecific LFV process, muonium-antimuonium oscillation. But the $s\\bar\\mu\n\\tau$-type flavon still has the opportunity; however, it confronts the strong\nconstraint from $\\tau\\to \\mu$ conservation and, in particular, the lepton\nflavor universality test of $Z$ boson decay, which arises due to our way to\nrealize the LFV flavon. The surviving flavon is highly predictable, with mass\nin the narrow window $m_\\tau\\lesssim m_s\\lesssim 1.5~ m_\\tau$ and LFV coupling\nstrength $\\sim 10^{-2}$. Besides, it leaves a TeV scale VLL with a multi-lepton\nsignature at the LHC.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.12072v1","title":"Observational properties of regular black holes in Asymptotic Safety","summary":"We consider the observational properties of a spherically symmetric, static\nregular black hole within the framework of asymptotic safety (AS) as proposed\nby Bonanno et al. The metric resembles the Schwarzschild solution in the\nclassical limit. The departure from Schwarzschild at small scales is controlled\nby a single free parameter related to the ultraviolet (UV) cutoff of the\ntheory. We investigated null and time-like geodesics around the AS metric,\nincluding circular orbits, photon rings and lensing effects. In particular we\nfocused on the optical properties of thin accretion disks in the equatorial\nplane of the object and compared them with those of accretion disks in the\nSchwarzschild metric. We found that the radiation flux, luminosity, and\nefficiency of the accretion disk increase with the value of the free parameter.\nUsing a spacetime generic open-source relativistic ray-tracing code, we\nsimulate the K$\\alpha$ iron line profiles emitted by the disk and analyze their\ndeviation from that of the Schwarzschild geometry.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T13:28:51Z"}
{"aid":"http://arxiv.org/abs/2504.12077v1","title":"Coincident onset of charge order and pseudogap in a homogeneous\n  high-temperature superconductor","summary":"Understanding high-temperature superconductivity in cuprates requires\nknowledge of the metallic phase it evolves from, particularly the pseudogap\nprofoundly affecting the electronic properties at low carrier densities. A key\nquestion is the influence of chemical disorder, which is ubiquitous but\nexceedingly difficult to model. Using resonant x-ray scattering, we identified\ntwo-dimensional charge order in stoichiometric YBa$_2$Cu$_4$O$_8$ ($T_c$ = 80\nK), which is nearly free of chemical disorder. The charge order amplitude shows\na concave temperature dependence and vanishes sharply at $T^*$ = 200 K, the\nonset of a prominent pseudogap previously determined by spectroscopy,\nsuggesting a causal link between these phenomena. The gradual onset of charge\norder in other cuprates is thus likely attributable to an inhomogeneous\ndistribution of charge ordering temperatures due to disorder induced by\nchemical substitution. The relationship between the pseudogap and the\ndisorder-induced gradual freeze-out of charge carriers remains a central issue\nin research on high-$T_c$ superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-16T13:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.12078v1","title":"Single-shot Star-convex Polygon-based Instance Segmentation for\n  Spatially-correlated Biomedical Objects","summary":"Biomedical images often contain objects known to be spatially correlated or\nnested due to their inherent properties, leading to semantic relations.\nExamples include cell nuclei being nested within eukaryotic cells and colonies\ngrowing exclusively within their culture dishes. While these semantic relations\nbear key importance, detection tasks are often formulated independently,\nrequiring multi-shot analysis pipelines. Importantly, spatial correlation could\nconstitute a fundamental prior facilitating learning of more meaningful\nrepresentations for tasks like instance segmentation. This knowledge has, thus\nfar, not been utilised by the biomedical computer vision community. We argue\nthat the instance segmentation of two or more categories of objects can be\nachieved in parallel. We achieve this via two architectures HydraStarDist (HSD)\nand the novel (HSD-WBR) based on the widely-used StarDist (SD), to take\nadvantage of the star-convexity of our target objects. HSD and HSD-WBR are\nconstructed to be capable of incorporating their interactions as constraints\ninto account. HSD implicitly incorporates spatial correlation priors based on\nobject interaction through a joint encoder. HSD-WBR further enforces the prior\nin a regularisation layer with the penalty we proposed named Within Boundary\nRegularisation Penalty (WBR). Both architectures achieve nested instance\nsegmentation in a single shot. We demonstrate their competitiveness based on\n$IoU_R$ and AP and superiority in a new, task-relevant criteria, Joint TP rate\n(JTPR) compared to their baseline SD and Cellpose. Our approach can be further\nmodified to capture partial-inclusion/-exclusion in multi-object interactions\nin fluorescent or brightfield microscopy or digital imaging. Finally, our\nstrategy suggests gains by making this learning single-shot and computationally\nefficient.","main_category":"cs.CV","categories":"cs.CV,q-bio.QM","published":"2025-04-16T13:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.12085v1","title":"Semiparametric Causal Discovery and Inference with Invalid Instruments","summary":"Learning causal relationships among a set of variables, as encoded by a\ndirected acyclic graph, from observational data is complicated by the presence\nof unobserved confounders. Instrumental variables (IVs) are a popular remedy\nfor this issue, but most existing methods either assume the validity of all IVs\nor postulate a specific form of relationship, such as a linear model, between\nthe primary variables and the IVs. To overcome these limitations, we introduce\na partially linear structural equation model for causal discovery and inference\nthat accommodates potentially invalid IVs and allows for general dependence of\nthe primary variables on the IVs. We establish identification under this\nsemiparametric model by constructing surrogate valid IVs, and develop a\nfinite-sample procedure for estimating the causal structures and effects.\nTheoretically, we show that our procedure consistently learns the causal\nstructures, yields asymptotically normal estimates, and effectively controls\nthe false discovery rate in edge recovery. Simulation studies demonstrate the\nsuperiority of our method over existing competitors, and an application to\ninferring gene regulatory networks in Alzheimer's disease illustrates its\nusefulness.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T13:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.12103v1","title":"Metric-Solver: Sliding Anchored Metric Depth Estimation from a Single\n  Image","summary":"Accurate and generalizable metric depth estimation is crucial for various\ncomputer vision applications but remains challenging due to the diverse depth\nscales encountered in indoor and outdoor environments. In this paper, we\nintroduce Metric-Solver, a novel sliding anchor-based metric depth estimation\nmethod that dynamically adapts to varying scene scales. Our approach leverages\nan anchor-based representation, where a reference depth serves as an anchor to\nseparate and normalize the scene depth into two components: scaled near-field\ndepth and tapered far-field depth. The anchor acts as a normalization factor,\nenabling the near-field depth to be normalized within a consistent range while\nmapping far-field depth smoothly toward zero. Through this approach, any depth\nfrom zero to infinity in the scene can be represented within a unified\nrepresentation, effectively eliminating the need to manually account for scene\nscale variations. More importantly, for the same scene, the anchor can slide\nalong the depth axis, dynamically adjusting to different depth scales. A\nsmaller anchor provides higher resolution in the near-field, improving depth\nprecision for closer objects while a larger anchor improves depth estimation in\nfar regions. This adaptability enables the model to handle depth predictions at\nvarying distances and ensure strong generalization across datasets. Our design\nenables a unified and adaptive depth representation across diverse\nenvironments. Extensive experiments demonstrate that Metric-Solver outperforms\nexisting methods in both accuracy and cross-dataset generalization.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:12:25Z"}
{"aid":"http://arxiv.org/abs/2504.12106v1","title":"A new description of the bicrystal $B(\\infty)$ and the extended crystal","summary":"We define new crystal maps on $B(\\infty)$ using its polyhedral realization,\nand show that the crystal $B(\\infty)$ equipped with the new crystal maps is\nisomorphic to Kashiwara's $B(\\infty)$ as bicrystals. In addition, we\ncombinatorially describe the bicrystal structure of $B(\\infty)$, which is\ncalled a sliding diamond rule. Using the bicrystal structure on $B(\\infty)$, we\ndefine the extended crystal and show that it is isomorphic to the extended\ncrystal introduced by Kashiwara and Park.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-16T14:14:51Z"}
{"aid":"http://arxiv.org/abs/2504.12119v1","title":"Weighted estimates for Multilinear Singular Integrals with Rough Kernels","summary":"We establish weighted norm inequalities for a class of multilinear singular\nintegral operators with rough kernels. Specifically, we consider the\nmultilinear singular integral operator $\\mathcal{L}_\\Omega$ associated with an\nintegrable function $\\Omega$ on the unit sphere $\\mathbb{S}^{mn-1}$ satisfying\nthe vanishing mean condition. Extending the classical results of Watson and\nDuoandikoetxea to the multilinear setting, we prove that $\\mathcal{L}_\\Omega$\nis bounded from $L^{p_1}(w_1)\\times\\cdots\\times L^{p_m}(w_m)$ to\n$L^p(v_{\\vec{\\boldsymbol{w}}})$ under the assumption that $\\Omega\\in\nL^q(\\mathbb{S}^{mn-1})$ and that the $m$ tuple of weights\n$\\vec{\\boldsymbol{w}}= (w_1,\\ldots,w_m)$ lies in the multiple weight class\n$A_{\\vec{\\boldsymbol{p}}/q'}((\\mathbb{R}^n)^m)$. Here, $q'$ denotes the\nH\\\"older conjugate of $q$, and we assume $q'\\le p_1,\\dots,p_m<\\infty$ with $1/p\n= 1/p_1 + \\cdots + 1/p_m$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-16T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.12132v1","title":"Weakly Semi-supervised Whole Slide Image Classification by Two-level\n  Cross Consistency Supervision","summary":"Computer-aided Whole Slide Image (WSI) classification has the potential to\nenhance the accuracy and efficiency of clinical pathological diagnosis. It is\ncommonly formulated as a Multiple Instance Learning (MIL) problem, where each\nWSI is treated as a bag and the small patches extracted from the WSI are\nconsidered instances within that bag. However, obtaining labels for a large\nnumber of bags is a costly and time-consuming process, particularly when\nutilizing existing WSIs for new classification tasks. This limitation renders\nmost existing WSI classification methods ineffective. To address this issue, we\npropose a novel WSI classification problem setting, more aligned with clinical\npractice, termed Weakly Semi-supervised Whole slide image Classification\n(WSWC). In WSWC, a small number of bags are labeled, while a significant number\nof bags remain unlabeled. The MIL nature of the WSWC problem, coupled with the\nabsence of patch labels, distinguishes it from typical semi-supervised image\nclassification problems, making existing algorithms for natural images\nunsuitable for directly solving the WSWC problem. In this paper, we present a\nconcise and efficient framework, named CroCo, to tackle the WSWC problem\nthrough two-level Cross Consistency supervision. CroCo comprises two\nheterogeneous classifier branches capable of performing both instance\nclassification and bag classification. The fundamental idea is to establish\ncross-consistency supervision at both the bag-level and instance-level between\nthe two branches during training. Extensive experiments conducted on four\ndatasets demonstrate that CroCo achieves superior bag classification and\ninstance classification performance compared to other comparative methods when\nlimited WSIs with bag labels are available. To the best of our knowledge, this\npaper presents for the first time the WSWC problem and gives a successful\nresolution.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.12136v1","title":"The Social Learning Barrier","summary":"We consider long-lived agents who interact repeatedly in a social network. In\neach period, each agent learns about an unknown state by observing a private\nsignal and her neighbors' actions in the previous period before taking an\naction herself. Our main result shows that the learning rate of the slowest\nlearning agent is bounded from above independently of the number of agents, the\nnetwork structure, and the agents' strategies. Applying this result to\nequilibrium learning with rational agents shows that the learning rate of all\nagents in any equilibrium is bounded under general conditions. This extends\nrecent findings on equilibrium learning and demonstrates that the limitation\nstems from an inherent tradeoff between optimal action choices and information\nrevelation rather than strategic considerations.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-16T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.12137v1","title":"Efficient Contrastive Decoding with Probabilistic Hallucination\n  Detection - Mitigating Hallucinations in Large Vision Language Models -","summary":"Despite recent advances in Large Vision Language Models (LVLMs), these models\nstill suffer from generating hallucinatory responses that do not align with the\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\nContrastive Decoding (ECD), a simple method that leverages probabilistic\nhallucination detection to shift the output distribution towards contextually\naccurate answers at inference time. By contrasting token probabilities and\nhallucination scores, ECD subtracts hallucinated concepts from the original\ndistribution, effectively suppressing hallucinations. Notably, our proposed\nmethod can be applied to any open-source LVLM and does not require additional\nLVLM training. We evaluate our method on several benchmark datasets and across\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\nhallucinations, outperforming state-of-the-art methods with respect to\nperformance on LVLM benchmarks and computation time.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-04-16T14:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.12151v1","title":"Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment\n  Analysis","summary":"Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\nof interpretability in the decision logic of multimodal fusion and modality\nimbalance caused by disparities in inter-modal information density. To address\nthese issues, we propose KAN-MCP, a novel framework that integrates the\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\nunivariate function decomposition to achieve transparent analysis of\ncross-modal interactions. This structural design allows direct inspection of\nfeature transformations without relying on external interpretation tools,\nthereby ensuring both high expressiveness and interpretability. Second, the\nproposed MCPareto enhances robustness by addressing modality imbalance and\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\nand reduces feature dimensionality. This approach provides KAN with\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\ndynamically balances gradient contributions across modalities using the\npurified features output by DRD-MIB, ensuring lossless transmission of\nauxiliary signals and effectively alleviating modality imbalance. This synergy\nof interpretability and robustness not only achieves superior performance on\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\nan intuitive visualization interface through KAN's interpretable architecture.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T15:00:06Z"}
{"aid":"http://arxiv.org/abs/2504.12162v1","title":"Spectral Analysis for Gaussian Quantum Markov Semigroups","summary":"We investigate the spectrum of the generator induced on the space of\nHilbert-Schmidt operators by a Gaussian quantum Markov semigroup with a\nfaithful normal invariant state in the general case, without any symmetry or\nquantum detailed balance assumptions. We prove that the eigenvalues are\nentirely determined by those of the drift matrix, similarly to classical\nOrnstein-Uhlenbeck semigroups. This result is established using a\nquasi-derivation property of the generator. Moreover, the same spectral\nproperty holds for the adjoint of the induced generator. Finally, we show that\nthese eigenvalues constitute the entire spectrum when the induced generator has\na spectral gap.","main_category":"math.FA","categories":"math.FA","published":"2025-04-16T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.12185v1","title":"SALAD: Improving Robustness and Generalization through Contrastive\n  Learning with Structure-Aware and LLM-Driven Augmented Data","summary":"In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.12187v1","title":"What Do Large Language Models Know? Tacit Knowledge as a Potential\n  Causal-Explanatory Structure","summary":"It is sometimes assumed that Large Language Models (LLMs) know language, or\nfor example that they know that Paris is the capital of France. But what -- if\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\ncertain architectural features of LLMs satisfy the constraints of semantic\ndescription, syntactic structure, and causal systematicity. Thus, tacit\nknowledge may serve as a conceptual framework for describing, explaining, and\nintervening on LLMs and their behavior.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-16T15:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.12196v1","title":"Loose paths in random ordered hypergraphs","summary":"We consider the length of {\\em ordered loose paths} in the random $r$-uniform\nhypergraph $H=H^{(r)}(n, p)$. A ordered loose path is a sequence of edges\n$E_1,E_2,\\ldots,E_\\ell$ where $\\max\\{j\\in E_i\\}=\\min\\{j\\in E_{i+1}\\}$ for\n$1\\leq i<\\ell$. We establish fairly tight bounds on the length of the longest\nordered loose path in $H$ that hold with high probability.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T15:48:06Z"}
{"aid":"http://arxiv.org/abs/2504.12202v1","title":"Correlations as a resource in molecular switches","summary":"Photoisomerization, a photochemical process underlying many biological\nmechanisms, has been modeled recently within the quantum resource theory of\nthermodynamics. This approach has emerged as a promising tool for studying\nfundamental limitations to nanoscale processes independently of the microscopic\ndetails governing their dynamics. On the other hand, correlations between\nphysical systems have been shown to play a crucial role in quantum\nthermodynamics by lowering the work cost of certain operations. Here, we\nexplore quantitatively how correlations between multiple photoswitches can\nenhance the efficiency of photoisomerization beyond that attainable for single\nmolecules. Furthermore, our analysis provides insights into the interplay\nbetween quantum and classical correlations in these transformations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T15:52:59Z"}
{"aid":"http://arxiv.org/abs/2504.12218v1","title":"Accountable Liveness","summary":"Safety and liveness are the two classical security properties of consensus\nprotocols. Recent works have strengthened safety with accountability: should\nany safety violation occur, a sizable fraction of adversary nodes can be proven\nto be protocol violators. This paper studies to what extent analogous\naccountability guarantees are achievable for liveness. To reveal the full\ncomplexity of this question, we introduce an interpolation between the\nclassical synchronous and partially-synchronous models that we call the\n$x$-partially-synchronous network model in which, intuitively, at most an $x$\nfraction of the time steps in any sufficiently long interval are asynchronous\n(and, as with a partially-synchronous network, all time steps are synchronous\nfollowing the passage of an unknown \"global stablization time\"). We prove a\nprecise characterization of the parameter regime in which accountable liveness\nis achievable: if and only if $x < 1/2$ and $f < n/2$, where $n$ denotes the\nnumber of nodes and $f$ the number of nodes controlled by an adversary. We\nfurther refine the problem statement and our analysis by parameterizing by the\nnumber of violating nodes identified following a liveness violation, and\nprovide evidence that the guarantees achieved by our protocol are near-optimal\n(as a function of $x$ and $f$). Our results provide rigorous foundations for\nliveness-accountability heuristics such as the \"inactivity leaks\" employed in\nEthereum.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T16:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.12230v1","title":"Suppression of composition g-modes in chemically-equilibrating warm\n  neutron stars","summary":"We investigate the impact of chemical equilibration and the resulting bulk\nviscosity on non-radial oscillation modes of warm neutron stars at temperatures\nup to T~5 MeV, relevant for protoneutron stars and neutron-star post-merger\nremnants. In this regime, the relaxation rate of weak interactions becomes\ncomparable to the characteristic frequencies of composition g-modes in the\ncore, resulting in resonant damping. To capture this effect, we introduce the\ndynamic sound speed, a complex, frequency-dependent generalization of the\nadiabatic sound speed that encodes both the restoring force and the dissipative\neffects of bulk compression. Using realistic weak reaction rates and three\nrepresentative equations of state, we compute the complex frequencies of\ncomposition g-modes with finite-temperature profiles. We find that bulk viscous\ndamping becomes increasingly significant with temperature and can completely\nsuppress composition g-modes. In contrast, the f-mode remains largely\nunaffected by bulk viscosity due to its nearly divergence-free character. Our\nresults highlight the sensitivity of g-mode behavior to thermal structure, weak\nreaction rates, and the equation of state, and establish the dynamic sound\nspeed as a valuable descriptor characterizing oscillation properties in\ndissipative neutron star matter.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-16T16:27:50Z"}
{"aid":"http://arxiv.org/abs/2504.12242v1","title":"On $p$-adic congruences involving $\\sqrt d$","summary":"Let $p$ be an odd prime and let $d$ be an integer not divisible by $p$. We\nprove that $$ \\prod_{1\\le m,n\\le p-1\\atop p\\nmid m^2-dn^2}\\ (x-(m+n\\sqrt{d}))\n\\equiv \\begin{cases}\\sum_{k=1}^{p-2}\\frac{k(k+1)}2x^{(k-1)(p-1)}\\pmod p\n&\\text{if}\\ (\\frac dp)=1,\\\\\\sum_{k=0}^{(p-1)/2}x^{2k(p-1)} \\pmod p&\\text {if}\\\n(\\frac dp)=-1, \\end{cases}$$ where $(\\frac dp)$ denotes the Legendre symbol.\nThis extends a recent conjecture of N. Kalinin. We also obtain the\nWolstenholme-type congruence $$\\sum_{1\\le m,n\\le p-1\\atop p\\nmid m^2-dn^2}\\ \\\n\\frac1{m+n\\sqrt d}\\equiv0\\pmod{p^2}.$$","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T16:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.12254v1","title":"Advancing Arabic Speech Recognition Through Large-Scale Weakly\n  Supervised Learning","summary":"Automatic speech recognition (ASR) is crucial for human-machine interaction\nin diverse applications like conversational agents, industrial robotics, call\ncenter automation, and automated subtitling. However, developing\nhigh-performance ASR models remains challenging, particularly for low-resource\nlanguages like Arabic, due to the scarcity of large, labeled speech datasets,\nwhich are costly and labor-intensive to produce. In this work, we employ weakly\nsupervised learning to train an Arabic ASR model using the Conformer\narchitecture. Our model is trained from scratch on 15,000 hours of weakly\nannotated speech data covering both Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), eliminating the need for costly manual transcriptions. Despite the\nabsence of human-verified labels, our approach attains state-of-the-art (SOTA)\nperformance, exceeding all previous efforts in the field of Arabic ASR on the\nstandard benchmarks. By demonstrating the effectiveness of weak supervision as\na scalable, cost-efficient alternative to traditional supervised approaches,\npaving the way for improved ASR systems in low resource settings.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-16T17:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.12258v1","title":"Experimental Analysis of Multipath Characteristics in Indoor Distributed\n  Massive MIMO Channels","summary":"Distributed massive multiple-input multiple-output (MIMO), also known as\ncell-free massive MIMO, has emerged as a promising technology for\nsixth-generation (6G) wireless networks. This letter introduces an indoor\nchannel measurement campaign designed to explore the behavior of multipath\ncomponents (MPCs) in distributed massive MIMO channels. Fully coherent channels\nwere measured between eight distributed uniform planar arrays (128 elements in\ntotal) and a 12-meter user equipment route. Furthermore, a method is introduced\nto determine the order (single- or multi-bounce) of MPC interaction by\nleveraging map information and MPC parameters. In addition, a Kalman\nfilter-based framework is used for identifying the MPC interaction mechanisms\n(reflection or scattering/diffraction/mixed). Finally, a comprehensive\nMPC-level characterization is performed based on the measured channels,\nincluding the significance of the single-bounce MPCs, the spherical wavefront\nfeatures, the birth-and-death processes of the MPCs, and the spatial\ndistribution of reflections. The findings serve as a valuable reference for\nunderstanding MPC propagation behavior, which is necessary for accurate\nmodeling of indoor distributed massive MIMO channels.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T17:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.12273v1","title":"Beyond Reconstruction: A Physics Based Neural Deferred Shader for\n  Photo-realistic Rendering","summary":"Deep learning based rendering has demonstrated major improvements for\nphoto-realistic image synthesis, applicable to various applications including\nvisual effects in movies and photo-realistic scene building in video games.\nHowever, a significant limitation is the difficulty of decomposing the\nillumination and material parameters, which limits such methods to reconstruct\nan input scene, without any possibility to control these parameters. This paper\nintroduces a novel physics based neural deferred shading pipeline to decompose\nthe data-driven rendering process, learn a generalizable shading function to\nproduce photo-realistic results for shading and relighting tasks, we also\nprovide a shadow estimator to efficiently mimic shadowing effect. Our model\nachieves improved performance compared to classical models and a state-of-art\nneural shading model, and enables generalizable photo-realistic shading from\narbitrary illumination input.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:32:50Z"}
{"aid":"http://arxiv.org/abs/2504.12607v1","title":"Solving Constrained Combinatorial Optimization Problems with Variational\n  Quantum Imaginary Time Evolution","summary":"Solving combinatorial optimization problems using variational quantum\nalgorithms (VQAs) has emerged as a promising research direction. Since the\nintroduction of the Quantum Approximate Optimization Algorithm (QAOA), numerous\nvariants have been proposed to enhance its performance. QAOA was later extended\nto the Quantum Alternating Operator Ansatz (QAOA+), which generalizes the\ninitial state, phase-separation operator, and mixer to address constrained\nproblems without relying on the standard Quadratic Unconstrained Binary\nOptimization (QUBO) formulation. However, QAOA+ often requires additional\nancilla qubits and a large number of multi-controlled Toffoli gates to prepare\nthe superposition of feasible states, resulting in deep circuits that are\nchallenging for near-term quantum devices. Furthermore, VQAs are generally\nhindered by issues such as barren plateaus and suboptimal local minima.\nRecently, Quantum Imaginary Time Evolution (QITE), a ground-state preparation\nalgorithm, has been explored as an alternative to QAOA and its variants. QITE\nhas demonstrated improved performance in quantum chemistry problems and has\nbeen applied to unconstrained combinatorial problems such as Max-Cut. In this\nwork, we apply the variational form of QITE (VarQITE) to solve the Multiple\nKnapsack Problem (MKP), a constrained problem, using a Max-Cut-tailored ansatz.\nTo the best of our knowledge, this is the first attempt to address constrained\noptimization using VarQITE. We show that VarQITE achieves significantly lower\nmean optimality gaps compared to QAOA and other conventional methods. Moreover,\nwe demonstrate that scaling the Hamiltonian coefficients can further reduce\noptimization costs and accelerate convergence.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T03:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.12612v1","title":"The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance","summary":"Provenance is the chronology of things, resonating with the fundamental\npursuit to uncover origins, trace connections, and situate entities within the\nflow of space and time. As artificial intelligence advances towards autonomous\nagents capable of interactive collaboration on complex tasks, the provenance of\ngenerated content becomes entangled in the interplay of collective creation,\nwhere contributions are continuously revised, extended or overwritten. In a\nmulti-agent generative chain, content undergoes successive transformations,\noften leaving little, if any, trace of prior contributions. In this study, we\ninvestigates the problem of tracking multi-agent provenance across the temporal\ndimension of generation. We propose a chronological system for post hoc\nattribution of generative history from content alone, without reliance on\ninternal memory states or external meta-information. At its core lies the\nnotion of symbolic chronicles, representing signed and time-stamped records, in\na form analogous to the chain of custody in forensic science. The system\noperates through a feedback loop, whereby each generative timestep updates the\nchronicle of prior interactions and synchronises it with the synthetic content\nin the very act of generation. This research seeks to develop an accountable\nform of collaborative artificial intelligence within evolving cyber ecosystems.","main_category":"cs.AI","categories":"cs.AI,cs.CR,cs.MA","published":"2025-04-17T03:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12621v1","title":"Revisiting multifunctionality in reservoir computing","summary":"Multifunctionality is ubiquitous in biological neurons. Several studies have\ntranslated the concept to artificial neural networks as well. Recently,\nmultifunctionality in reservoir computing (RC) has gained the widespread\nattention of researchers. Multistable dynamics of the reservoir can be\nconfigured to capture multiple tasks, each by one of the co-existing\nattractors. However, there are several limitations in the applicability of this\napproach. So far, multifunctional RC has been shown to be able to reconstruct\ndifferent attractor climates only when the attractors are well separated in the\nphase space. We propose a more flexible reservoir computing scheme capable of\nmultifunctioning beyond the earlier limitations. The proposed architecture\nholds striking similarity with the multifunctional biological neural networks\nand showcases superior performance. It is capable of learning multiple chaotic\nattractors with overlapping phase space. We successfully train the RC to\nachieve multifunctionality with wide range of tasks.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-17T03:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.12643v1","title":"RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating\n  Enhanced Rotary Position Embedding","summary":"This technical report introduces a targeted improvement to the StreamPETR\nframework, specifically aimed at enhancing velocity estimation, a critical\nfactor influencing the overall NuScenes Detection Score. While StreamPETR\nexhibits strong 3D bounding box detection performance as reflected by its high\nmean Average Precision our analysis identified velocity estimation as a\nsubstantial bottleneck when evaluated on the NuScenes dataset. To overcome this\nlimitation, we propose a customized positional embedding strategy tailored to\nenhance temporal modeling capabilities. Experimental evaluations conducted on\nthe NuScenes test set demonstrate that our improved approach achieves a\nstate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new\nbenchmark for camera-only 3D object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T05:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.12656v1","title":"Spherical collapse in DHOST theories and EFT of dark energy","summary":"We study the nonlinear evolution of matter overdensities using the spherical\ncollapse model in degenerate higher-order scalar-tensor (DHOST) theories beyond\nHorndeski, employing the effective field theory (EFT) of dark energy approach.\nWe investigate the impact of the EFT parameters characterising DHOST theories\non the formation of large-scale structure. We identify the parameter space in\nwhich the collapse of the spherical overdensity is prevented by the scalar\nfield turning imaginary at some moment, which allows us to place constraints on\nthe model parameters. We show how the collapse time and the critical density\ncontrast depend on the EFT parameters. To assess the observational\nimplications, we compute the halo mass function using the Press-Schechter\nformalism. We find that the number density of halos is suppressed compared to\nthe $\\Lambda$CDM model due to ``beyond Horndeski'' effects, upon imposing the\nstability of linear perturbations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-17T05:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.12659v1","title":"Topologically Directed Simulations Reveal the Impact of Geometric\n  Constraints on Knotted Proteins","summary":"Simulations of knotting and unknotting in polymers or other filaments rely on\nrandom processes to facilitate topological changes. Here we introduce a method\nof \\textit{topological steering} to determine the optimal pathway by which a\nfilament may knot or unknot while subject to a given set of physics. The method\ninvolves measuring the knotoid spectrum of a space curve projected onto many\nsurfaces and computing the mean unravelling number of those projections.\nSeveral perturbations of a curve can be generated stochastically, e.g. using\nthe Langevin equation or crankshaft moves, and a gradient can be followed that\nmaximises or minimises the topological complexity. We apply this method to a\npolymer model based on a growing self-avoiding tangent-sphere chain, which can\nbe made to model proteins by imposing a constraint that the bending and\ntwisting angles between successive spheres must maintain the distribution found\nin naturally occurring protein structures. We show that without these\nprotein-like geometric constraints, topologically optimised polymers typically\nform alternating torus knots and composites thereof, similar to the stochastic\nknots predicted for long DNA. However, when the geometric constraints are\nimposed on the system, the frequency of twist knots increases, similar to the\nobserved abundance of twist knots in protein structures.","main_category":"math.GT","categories":"math.GT,cond-mat.soft,cond-mat.stat-mech,q-bio.BM","published":"2025-04-17T05:39:30Z"}
{"aid":"http://arxiv.org/abs/2504.12693v1","title":"Counting degree-constrained orientations","summary":"We study the enumeration of graph orientations under local degree\nconstraints. Given a finite graph $G = (V, E)$ and a family of admissible sets\n$\\{\\mathsf P_v \\subseteq \\mathbb{Z} : v \\in V\\}$, let $\\mathcal N (G; \\prod_{v\n\\in V} \\mathsf P_v)$ denote the number of orientations in which the out-degree\nof each vertex $v$ lies in $P_v$. We prove a general duality formula expressing\n$\\mathcal N(G; \\prod_{v \\in V} \\mathsf P_v)$ as a signed sum over edge subsets,\ninvolving products of coefficient sums associated with $\\{\\mathsf P_v\\}_{v \\in\nV}$, from a family of polynomials. Our approach employs gauge transformations,\na technique rooted in statistical physics and holographic algorithms. We also\npresent a probabilistic derivation of the same identity, interpreting the\norientation-generating polynomial as the expectation of a random polynomial\nproduct. As applications, we obtain explicit formulas for the number of even\norientations and for mixed Eulerian-even orientations on general graphs. Our\nformula generalizes a result of Borb\\'enyi and Csikv\\'ari on Eulerian\norientations of graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T06:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.12710v1","title":"Quantum circuit synthesis with qudit phase gadget method","summary":"Current quantum devices have unutilized high-level quantum resources. More\nand more attention has been paid to the qudit quantum systems with larger than\ntwo dimensions to maximize the potential computing power of quantum\ncomputation. Then, a natural problem arises: How do we implement quantum\nalgorithms on qudit quantum systems? In this work, we propose a novel qudit\nphase gadget method for synthesizing the qudit diagonal unitary matrices. This\nmethod is suitable for the Noisy Intermediate-Scale Quantum (NISQ) and\nfault-tolerant eras due to its versatility in different connectivity\narchitectures and the optimality of its resource consumption. The method can\nwork on any connectivity architecture with asymptotic optimal circuit depth and\nsize. For a 10-qutrit diagonal unitary, our algorithm reduces the circuit depth\nform about 100000 to 500 with 300 ancillary qutrits. Further, this method can\nbe promoted to different quantum circuit synthesis problems, such as quantum\nstate preparation problems, general unitary synthesis problems, etc.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-17T07:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.12720v1","title":"Malicious Code Detection in Smart Contracts via Opcode Vectorization","summary":"With the booming development of blockchain technology, smart contracts have\nbeen widely used in finance, supply chain, Internet of things and other fields\nin recent years. However, the security problems of smart contracts become\nincreasingly prominent. Security events caused by smart contracts occur\nfrequently, and the existence of malicious codes may lead to the loss of user\nassets and system crash. In this paper, a simple study is carried out on\nmalicious code detection of intelligent contracts based on machine learning.\nThe main research work and achievements are as follows: Feature extraction and\nvectorization of smart contract are the first step to detect malicious code of\nsmart contract by using machine learning method, and feature processing has an\nimportant impact on detection results. In this paper, an opcode vectorization\nmethod based on smart contract text is adopted. Based on considering the\nstructural characteristics of contract opcodes, the opcodes are classified and\nsimplified. Then, N-Gram (N=2) algorithm and TF-IDF algorithm are used to\nconvert the simplified opcodes into vectors, and then put into the machine\nlearning model for training. In contrast, N-Gram algorithm and TF-IDF algorithm\nare directly used to quantify opcodes and put into the machine learning model\ntraining. Judging which feature extraction method is better according to the\ntraining results. Finally, the classifier chain is applied to the intelligent\ncontract malicious code detection.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T07:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.12736v1","title":"Incorporating a Deep Neural Network into Moving Horizon Estimation for\n  Embedded Thermal Torque Derating of an Electric Machine","summary":"This study introduces a novel state estimation framework that incorporates\nDeep Neural Networks (DNNs) into Moving Horizon Estimation (MHE), shifting from\ntraditional physics-based models to rapidly developed data-driven techniques. A\nDNN model with Long Short-Term Memory (LSTM) nodes is trained on synthetic data\ngenerated by a high-fidelity thermal model of a Permanent Magnet Synchronous\nMachine (PMSM), which undergoes thermal derating as part of the torque control\nstrategy in a battery electric vehicle. The MHE is constructed by integrating\nthe trained DNN with a simplified driving dynamics model in a discrete-time\nformulation, incorporating the LSTM hidden and cell states in the state vector\nto retain system dynamics. The resulting optimal control problem (OCP) is\nformulated as a nonlinear program (NLP) and implemented using the acados\nframework. Model-in-the-loop (MiL) simulations demonstrate accurate temperature\nestimation, even under noisy sensor conditions or failures. Achieving threefold\nreal-time capability on embedded hardware confirms the feasibility of the\napproach for practical deployment. The primary focus of this study is to assess\nthe feasibility of the MHE framework using a DNN-based plant model instead of\nfocusing on quantitative comparisons of vehicle performance. Overall, this\nresearch highlights the potential of DNN-based MHE for real-time,\nsafety-critical applications by combining the strengths of model-based and\ndata-driven methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T08:24:32Z"}
{"aid":"http://arxiv.org/abs/2504.12762v1","title":"Testing the Star-disk Collision Model for Quasi-periodic Eruptions","summary":"Quasi-periodic eruptions (QPEs), the repeated outbursts observed in soft\nX-ray bands, have attracted broad interest, but their physical origin is under\ndebate. One of the popular models, the star-disk collision model, suggests that\nQPEs can be produced through periodic collisions of an orbiting star with the\naccretion disk of a central black hole (BH). However, previous tests of the\nstar-disk collision model mainly focus on the timing analysis. Other observed\nproperties, such as peak luminosities $L_{\\rm{p}}$, durations $t_{\\rm{e}}$, and\nradiation temperatures $T_{\\rm{p}}$ of the eruptions, are not systematically\ninvestigated. For a sample of six QPE sources and two QPE-like sources, we test\nthe star-disk collision model by using these observables to derive the\nconstraints on the stellar radius $R_*$. We find that, except for two sources\n(eRo-QPE3 and eRo-QPE4), the rest of the sample either has no allowed $R_*$ to\nsimultaneously reproduce the observed $L_{\\rm{p}}$ and $t_{\\rm{e}}$, or the\nrequired $R_*$ is too large to avoid being disrupted by the central BH. For the\ntwo exceptions, a stellar radius of the order of $1\\ R_{\\rm{\\odot}}$ is\nnecessary to satisfy all the constraints. Another issue with the simplest\nversion of this model is that it predicts $k T_{\\rm{p}} \\sim 10\\ \\rm{eV}$, one\norder of magnitude lower than the observed value.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,astro-ph.SR,hep-ph","published":"2025-04-17T09:00:00Z"}
{"aid":"http://arxiv.org/abs/2504.12771v1","title":"Classification-Based Analysis of Price Pattern Differences Between\n  Cryptocurrencies and Stocks","summary":"Cryptocurrencies are digital tokens built on blockchain technology, with\nthousands actively traded on centralized exchanges (CEXs). Unlike stocks, which\nare backed by real businesses, cryptocurrencies are recognized as a distinct\nclass of assets by researchers. How do investors treat this new category of\nasset in trading? Are they similar to stocks as an investment tool for\ninvestors? We answer these questions by investigating cryptocurrencies' and\nstocks' price time series which can reflect investors' attitudes towards the\ntargeted assets. Concretely, we use different machine learning models to\nclassify cryptocurrencies' and stocks' price time series in the same period and\nget an extremely high accuracy rate, which reflects that cryptocurrency\ninvestors behave differently in trading from stock investors. We then extract\nfeatures from these price time series to explain the price pattern difference,\nincluding mean, variance, maximum, minimum, kurtosis, skewness, and first to\nthird-order autocorrelation, etc., and then use machine learning methods\nincluding logistic regression (LR), random forest (RF), support vector machine\n(SVM), etc. for classification. The classification results show that these\nextracted features can help to explain the price time series pattern difference\nbetween cryptocurrencies and stocks.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-17T09:12:27Z"}
{"aid":"http://arxiv.org/abs/2504.12774v1","title":"Phase field model of Coulomb explosion damage in solid induced by\n  ultrashort laser","summary":"Much experimental evidence reveals that Coulomb explosion governs non-thermal\nmaterial removal under femtosecond or even shorter laser pulses, and\nnon-thermal laser damage has been a topic widely discussed. Nevertheless, there\nis still no continuum mechanical model capable of describing the evolution of\nsuch damage. In this study, we develop a model that characterizes solid damage\nthrough a phase field variable governed by Allen-Cahn dynamics. The parameter\nof the model is defined by a conceptual mechanism: during Coulomb explosion,\nelectron pressure surpasses the interatomic barrier potential, dissociates\nmaterial from the solid surface as small equivalent particles and resulting in\nlocalized damage. The numerical simulation validates the model's availability\nand demonstrate its ability to predict damage morphology under varying laser\nconditions. This work advances the understanding of non-thermal ablation and\nprovides a tool for optimizing ultrafast laser processing.","main_category":"physics.optics","categories":"physics.optics,cond-mat.other,physics.comp-ph","published":"2025-04-17T09:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.12775v1","title":"Linear ordinary differential equations constrained Gaussian Processes\n  for solving optimal control problems","summary":"This paper presents an intrinsic approach for addressing control problems\nwith systems governed by linear ordinary differential equations (ODEs). We use\ncomputer algebra to constrain a Gaussian Process on solutions of ODEs. We\nobtain control functions via conditioning on datapoints. Our approach thereby\nconnects Algebra, Functional Analysis, Machine Learning and Control theory. We\ndiscuss the optimality of the control functions generated by the posterior mean\nof the Gaussian Process. We present numerical examples which underline the\npracticability of our approach.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T09:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.12781v1","title":"Hexagonal and k-hexagonal graph's normalized Laplacian spectrum and\n  applications","summary":"Substituting each edge of a simple connected graph $G$ by a path of length 1\nand $k$ paths of length 5 generates the $k$-hexagonal graph $H^k(G)$. Iterative\ngraph $H^k_n(G)$ is produced when the preceding constructions are repeated $n$\ntimes. According to the graph structure, we obtain a set of linear equations,\nand derive the entirely normalized Laplacian spectrum of $H^k_n(G)$ when $k =\n1$ and $k \\geqslant 2$ respectively by analyzing the structure of the solutions\nof these linear equations. We find significant formulas to calculate the\nKemeny's constant, multiplicative degree-Kirchhoff index and number of spanning\ntrees of $H^k_n(G)$ as applications.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T09:27:36Z"}
{"aid":"http://arxiv.org/abs/2504.12787v1","title":"Counting Irreducible Representations of a Finite Abelian Group","summary":"Let $q$ be a power of a prime $p$, $G$ be a finite abelian group, where $p$\ndoes not divide $|G|$,and let $n$ be a positive integer. In this paper we find\na formula for the number of irreducible representations of $G$ of a given\ndimension $n$ over the field of order $q$, up to equivalence, using Brauer\ncharacters. We also provide a formula for such $n$ using the prime\ndecomposition of the exponent of $G$ and an algorithm to compute the\nirreducible degrees and their multiplicities.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.12797v1","title":"Status of the Proton EDM Experiment (pEDM)","summary":"The Proton EDM Experiment (pEDM) is the first direct search for the proton\nelectric dipole moment (EDM) with the aim of being the first experiment to\nprobe the Standard Model (SM) prediction of any particle EDM. Phase-I of pEDM\nwill achieve $10^{-29} e\\cdot$cm, improving current indirect limits by four\norders of magnitude. This will establish a new standard of precision in nucleon\nEDM searches and offer a unique sensitivity to better understand the Strong CP\nproblem. The experiment is ideally positioned to explore physics beyond the\nStandard Model (BSM), with sensitivity to axionic dark matter via the signal of\nan oscillating proton EDM and across a wide mass range of BSM models from\n$\\mathcal{O}(1\\text{GeV})$ to $\\mathcal{O}(10^3\\text{TeV})$. Utilizing the\nfrozen-spin technique in a highly symmetric storage ring that leverages\nexisting infrastructure at Brookhaven National Laboratory (BNL), pEDM builds\nupon the technological foundation and experimental expertise of the highly\nsuccessful Muon $g$$-$$2$ Experiments. With significant R\\&D and prototyping\nalready underway, pEDM is preparing a conceptual design report (CDR) to offer a\ncost-effective, high-impact path to discovering new sources of CP violation and\nadvancing our understanding of fundamental physics. It will play a vital role\nin complementing the physics goals of the next-generation collider while\nsimultaneously contributing to sustaining particle physics research and\ntraining early career researchers during gaps between major collider\noperations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-17T09:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.12799v1","title":"TSGS: Improving Gaussian Splatting for Transparent Surface\n  Reconstruction via Normal and De-lighting Priors","summary":"Reconstructing transparent surfaces is essential for tasks such as robotic\nmanipulation in labs, yet it poses a significant challenge for 3D\nreconstruction techniques like 3D Gaussian Splatting (3DGS). These methods\noften encounter a transparency-depth dilemma, where the pursuit of\nphotorealistic rendering through standard $\\alpha$-blending undermines\ngeometric precision, resulting in considerable depth estimation errors for\ntransparent materials. To address this issue, we introduce Transparent Surface\nGaussian Splatting (TSGS), a new framework that separates geometry learning\nfrom appearance refinement. In the geometry learning stage, TSGS focuses on\ngeometry by using specular-suppressed inputs to accurately represent surfaces.\nIn the second stage, TSGS improves visual fidelity through anisotropic specular\nmodeling, crucially maintaining the established opacity to ensure geometric\naccuracy. To enhance depth inference, TSGS employs a first-surface depth\nextraction method. This technique uses a sliding window over $\\alpha$-blending\nweights to pinpoint the most likely surface location and calculates a robust\nweighted average depth. To evaluate the transparent surface reconstruction task\nunder realistic conditions, we collect a TransLab dataset that includes complex\ntransparent laboratory glassware. Extensive experiments on TransLab show that\nTSGS achieves accurate geometric reconstruction and realistic rendering of\ntransparent objects simultaneously within the efficient 3DGS framework.\nSpecifically, TSGS significantly surpasses current leading methods, achieving a\n37.3% reduction in chamfer distance and an 8.0% improvement in F1 score\ncompared to the top baseline. The code and dataset will be released at\nhttps://longxiang-ai.github.io/TSGS/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.12807v1","title":"Hybrid Dense-UNet201 Optimization for Pap Smear Image Segmentation Using\n  Spider Monkey Optimization","summary":"Pap smear image segmentation is crucial for cervical cancer diagnosis.\nHowever, traditional segmentation models often struggle with complex cellular\nstructures and variations in pap smear images. This study proposes a hybrid\nDense-UNet201 optimization approach that integrates a pretrained DenseNet201 as\nthe encoder for the U-Net architecture and optimizes it using the spider monkey\noptimization (SMO) algorithm. The Dense-UNet201 model excelled at feature\nextraction. The SMO was modified to handle categorical and discrete parameters.\nThe SIPaKMeD dataset was used in this study and evaluated using key performance\nmetrics, including loss, accuracy, Intersection over Union (IoU), and Dice\ncoefficient. The experimental results showed that Dense-UNet201 outperformed\nU-Net, Res-UNet50, and Efficient-UNetB0. SMO Dense-UNet201 achieved a\nsegmentation accuracy of 96.16%, an IoU of 91.63%, and a Dice coefficient score\nof 95.63%. These findings underscore the effectiveness of image preprocessing,\npretrained models, and metaheuristic optimization in improving medical image\nanalysis and provide new insights into cervical cell segmentation methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T10:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.12809v1","title":"Saliency-Aware Diffusion Reconstruction for Effective Invisible\n  Watermark Removal","summary":"As digital content becomes increasingly ubiquitous, the need for robust\nwatermark removal techniques has grown due to the inadequacy of existing\nembedding techniques, which lack robustness. This paper introduces a novel\nSaliency-Aware Diffusion Reconstruction (SADRE) framework for watermark\nelimination on the web, combining adaptive noise injection, region-specific\nperturbations, and advanced diffusion-based reconstruction. SADRE disrupts\nembedded watermarks by injecting targeted noise into latent representations\nguided by saliency masks although preserving essential image features. A\nreverse diffusion process ensures high-fidelity image restoration, leveraging\nadaptive noise levels determined by watermark strength. Our framework is\ntheoretically grounded with stability guarantees and achieves robust watermark\nremoval across diverse scenarios. Empirical evaluations on state-of-the-art\n(SOTA) watermarking techniques demonstrate SADRE's superiority in balancing\nwatermark disruption and image quality. SADRE sets a new benchmark for\nwatermark elimination, offering a flexible and reliable solution for real-world\nweb content. Code is available\non~\\href{https://github.com/inzamamulDU/SADRE}{\\textbf{https://github.com/inzamamulDU/SADRE}}.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-17T10:15:10Z"}
{"aid":"http://arxiv.org/abs/2504.12836v1","title":"Inverse iteration method for higher eigenvalues of the $p$-Laplacian","summary":"We propose a characterization of a $p$-Laplace higher eigenvalue based on the\ninverse iteration method with balancing the Rayleigh quotients of the positive\nand negative parts of solutions to consecutive $p$-Poisson equations. The\napproach relies on the second eigenvalue's minimax properties, but the actual\nlimiting eigenvalue depends on the choice of initial function. The\nwell-posedness and convergence of the iterative scheme are proved. Moreover, we\nprovide the corresponding numerical computations. As auxiliary results, which\nalso have an independent interest, we provide several properties of certain\n$p$-Poisson problems.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,math.SP","published":"2025-04-17T10:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.12845v1","title":"Can LLMs reason over extended multilingual contexts? Towards\n  long-context evaluation beyond retrieval and haystacks","summary":"Existing multilingual long-context benchmarks, often based on the popular\nneedle-in-a-haystack test, primarily evaluate a model's ability to locate\nspecific information buried within irrelevant texts. However, such a\nretrieval-centric approach is myopic and inherently limited, as successful\nrecall alone does not indicate a model's capacity to reason over extended\ncontexts. Moreover, these benchmarks are susceptible to data leakage,\nshort-circuiting, and risk making the evaluation a priori identifiable. To\naddress these limitations, we introduce MLRBench, a new synthetic benchmark for\nmultilingual long-context reasoning. Unlike existing benchmarks, MLRBench goes\nbeyond surface-level retrieval by including tasks that assess multi-hop\ninference, aggregation, and epistemic reasoning. Spanning seven languages,\nMLRBench is designed to be parallel, resistant to leakage, and scalable to\narbitrary context lengths. Our extensive experiments with an open-weight large\nlanguage model (LLM) reveal a pronounced gap between high- and low-resource\nlanguages, particularly for tasks requiring the model to aggregate multiple\nfacts or predict the absence of information. We also find that, in multilingual\nsettings, LLMs effectively utilize less than 30% of their claimed context\nlength. Although off-the-shelf Retrieval Augmented Generation helps alleviate\nthis to a certain extent, it does not solve the long-context problem. We\nopen-source MLRBench to enable future research in improved evaluation and\ntraining of multilingual LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T11:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.12857v1","title":"A note on distance-hereditary graphs whose complement is also\n  distance-hereditary","summary":"Distance-hereditary graphs are known to be the graphs that are totally\ndecomposable for the split decomposition. We characterise distance-hereditary\ngraphs whose complement is also distance-hereditary by their split\ndecomposition and by their modular decomposition.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-17T11:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12872v1","title":"On perfect sampling: ROCFTP with Metropolis-multishift coupler","summary":"ROCFTP is a perfect sampling algorithm that employs various random\noperations, and requiring a specific Markov chain construction for each target.\nTo overcome this requirement, the Metropolis algorithm is incorporated as a\nrandom operation within ROCFTP. While the Metropolis sampler functions as a\nrandom operation, it isn't a coupler. However, by employing normal multishift\ncoupler as a symmetric proposal for Metropolis, we obtain ROCFTP with\nMetropolis-multishift. Initially designed for bounded state spaces, ROCFTP's\napplicability to targets with unbounded state spaces is extended through the\nintroduction of the Most Interest Range (MIR) for practical use. It was\ndemonstrated that selecting MIR decreases the likelihood of ROCFTP hitting\n$MIR^C$ by a factor of (1 - {\\epsilon}), which is beneficial for practical\nimplementation. The algorithm exhibits a convergence rate characterized by\nexponential decay. Its performance is rigorously evaluated across various\ntargets, and tests ensure its goodness of fit. Lastly, an R package is provided\nfor generating exact samples using ROCFTP Metropolis-multishift.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.ME,stat.TH","published":"2025-04-17T12:00:03Z"}
{"aid":"http://arxiv.org/abs/2504.12884v1","title":"TOI-3493 b: A planet with a Neptune-like density transiting a bright\n  G0-type star","summary":"We report the discovery of TOI-3493 b, a sub-Neptune-sized planet on an\n8.15-d orbit transiting the bright (V=9.3) G0 star HD 119355 (aka TIC\n203377303) initially identified by NASA's TESS space mission. With the aim of\nconfirming the planetary nature of the transit signal detected by TESS and\ndetermining the mass of the planet, we performed an intensive Doppler campaign\nwith the HARPS spectrograph, collecting radial velocity measurements. We found\nthat TOI-3493 b lies in a nearly circular orbit and has a mass of 9.0+/-1.2\nM_earth and a radius of 3.22+/-0.08 R_earth, implying a bulk density of\n1.47+/-0.23 g/cm^3, consistent with a composition comprising a small solid core\nsurrounded by a thick H/He dominated atmosphere.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-17T12:20:27Z"}
{"aid":"http://arxiv.org/abs/2504.12891v1","title":"Are AI agents the new machine translation frontier? Challenges and\n  opportunities of single- and multi-agent systems for multilingual digital\n  communication","summary":"The rapid evolution of artificial intelligence (AI) has introduced AI agents\nas a disruptive paradigm across various industries, yet their application in\nmachine translation (MT) remains underexplored. This paper describes and\nanalyses the potential of single- and multi-agent systems for MT, reflecting on\nhow they could enhance multilingual digital communication. While single-agent\nsystems are well-suited for simpler translation tasks, multi-agent systems,\nwhich involve multiple specialized AI agents collaborating in a structured\nmanner, may offer a promising solution for complex scenarios requiring high\naccuracy, domain-specific knowledge, and contextual awareness. To demonstrate\nthe feasibility of multi-agent workflows in MT, we are conducting a pilot study\nin legal MT. The study employs a multi-agent system involving four specialized\nAI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and\n(iv) final editing. Our findings suggest that multi-agent systems may have the\npotential to significantly improve domain-adaptability and contextual\nawareness, with superior translation quality to traditional MT or single-agent\nsystems. This paper also sets the stage for future research into multi-agent\napplications in MT, integration into professional translation workflows, and\nshares a demo of the system analyzed in the paper.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-17T12:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.12896v1","title":"Performance guarantees of light-cone variational quantum algorithms for\n  the maximum cut problem","summary":"Variational quantum algorithms (VQAs) are promising to demonstrate the\nadvantage of near-term quantum computing over classical computing in practical\napplications, such as the maximum cut (MaxCut) problem. However, current VQAs\nsuch as the quantum approximate optimization algorithm (QAOA) have lower\nperformance guarantees compared to the best-known classical algorithm, and\nsuffer from hard optimization processes due to the barren plateau problem. We\npropose a light-cone VQA by choosing an optimal gate sequence of the standard\nVQAs, which enables a significant improvement in solution accuracy while\navoiding the barren plateau problem. Specifically, we prove that the light-cone\nVQA with one round achieves an approximation ratio of 0.7926 for the MaxCut\nproblem in the worst case of $3$-regular graphs, which is higher than that of\nthe 3-round QAOA, and can be further improved to 0.8333 by an angle-relaxation\nprocedure. Finally, these performance guarantees are verified by numerical\nsimulations and hardware demonstrations on IBM quantum devices. In a 72-qubit\ndemonstration, the single-round light-cone VQA achieves the exact MaxCut\nsolution whereas the $p$-round QAOA with $p=1,2,3$ only obtains approximate\nsolutions. Furthermore, the single-round light-cone VQA derives solutions\nsurpassing the hardness threshold in a 148-qubit demonstration while QAOA with\n$p=1,2,3$ does not. Our work highlights a promising route towards solving\npractical and classically hard problems on near-term quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:38:16Z"}
{"aid":"http://arxiv.org/abs/2504.12924v1","title":"The Monge--Kantorovich problem, the Schur--Horn theorem, and the\n  diffeomorphism group of the annulus","summary":"First, we analyze the discrete Monge--Kantorovich problem, linking it with\nthe minimization problem of linear functionals over adjoint orbits. Second, we\nconsider its generalization to the setting of area preserving diffeomorphisms\nof the annulus. In both cases, we show how the problem can be linked to\npermutohedra, majorization, and to gradient flows with respect to a suitable\nmetric.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T13:15:26Z"}
{"aid":"http://arxiv.org/abs/2504.12930v1","title":"Performance of the advanced gamma-ray trigger system for the High Energy\n  Cosmic Radiation Detection (HERD) facility","summary":"The High Energy Cosmic-Radiation Detection (HERD) facility has been proposed\nas a leading experiment on China's Space Station (CSS). Scheduled for\ninstallation around 2027, HERD is expected to operate for at least a decade.\nThe main scientific objectives include indirect detection of dark matter with\nunprecedented sensitivity, studying the cosmic-ray spectrum and composition up\nto the knee, and observing all-sky gamma rays with energies above 100 MeV. HERD\nis designed as a large-acceptance telescope with a unique design aimed at\nmaximizing its efficiency. It comprises a central 3D imaging calorimeter (CALO)\nmade of LYSO crystals, encircled by four complementary subdetectors on its top\nand four lateral faces: the scintillating fiber tracking detector (FIT), the\nplastic scintillator detector (PSD), the silicon charge detector (SCD), and a\ntransition radiation detector (TRD) on one lateral side. To fully harness HERD\ngamma-ray detection capabilities down to 100 MeV, an advanced ultra-low-energy\ngamma-ray (ULEG) trigger system has been developed. We present an extensive\noverview of the design, performance, and optimization of the gamma-ray trigger\nsystem supported by software simulations and preliminary results from the\nsuccessful implementation of the HERD prototype at CERN's PS and SPS beam test\ncampaigns in Fall 2023.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-17T13:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.12935v1","title":"Dynamical relationship between CAR algebras and determinantal point\n  processes: point processes at finite temperature and stochastically positive\n  KMS systems","summary":"The aim of this paper is threefold. Firstly, we develop the author's previous\nwork on the dynamical relationship between determinantal point processes and\nCAR algebras. Secondly, we present a novel application of the theory of\nstochastic processes associated with KMS states for CAR algebras and their\nquasi-free states. Lastly, we propose a unified theory of algebraic\nconstructions and analysis of stationary processes on point configuration\nspaces with respect to determinantal point processes. As a byproduct, we\nestablish an algebraic derivation of a determinantal formula for space-time\ncorrelations of stochastic processes, and we analyze several limiting behaviors\nof these processes.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP,math.OA","published":"2025-04-17T13:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.12936v1","title":"Relative magnetic helicity under turbulent relaxation","summary":"Magnetic helicity is a quantity that underpins many theories of magnetic\nrelaxation in electrically conducting fluids, both laminar and turbulent.\nAlthough much theoretical effort has been expended on magnetic fields that are\neverywhere tangent to their domain boundaries, many applications, both in\nastrophysics and laboratories, actually involve magnetic fields that are\nline-tied to the boundary, i.e. with a non-trivial normal component on the\nboundary. This modification of the boundary condition requires a modification\nof magnetic helicity, whose suitable replacement is called relative magnetic\nhelicity. In this work, we investigate rigorously the behaviour of relative\nmagnetic helicity under turbulent relaxation. In particular, we specify the\nnormal component of the magnetic field on the boundary and consider the\n\\emph{ideal limit} of resistivity tending to zero in order to model the\nturbulent evolution in the sense of Onsager's theory of turbulence. We show\nthat relative magnetic helicity is conserved in this distinguished limit and\nthat, for constant viscosity, the magnetic field can relax asymptotically to a\nmagnetohydrostatic equilibrium.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,math.AP","published":"2025-04-17T13:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.12954v1","title":"Phenomenology of Inverse Seesaw Using $S_3$ Modular Symmetry","summary":"Describing neutrino masses using the inverse seesaw mechanism with discrete\nflavor symmetry imposed through modular forms provides a testable framework at\nTeV scales with fewer parameters. However, $S_3$, the smallest modular group,\nremains relatively underexplored. In this work, we construct the minimal\nsupersymmetric inverse seesaw model based on the modular $S_3$ flavor symmetry.\nIn our model, the light neutrino mass matrix depends on 6 real parameters: the\ncomplex modulus, an overall scale for light neutrino mass, a real ratio and a\ncomplex ratio of Yukawa coupling. Thanks to its minimality, our model offers\nvarious definite predictions: the lightest neutrino is massless, the neutrino\nmasses are inverted ordering, the sum of the three light neutrino masses\n($\\sum_i m_i$) is 100 meV, the effective mass for the end point of the beta\ndecay spectrum is 50 meV, the effective mass for neutrinoless double beta decay\n($m_{ee}$) is in the range $38-58$ meV. In particular, the predicted values for\n$\\sum_i m_i$ and $m_{ee}$ from our model are within reach of the next\ngeneration experiments. Our model also predicts radiative lepton flavor\nviolating decays $\\ell\\to\\ell'\\gamma$ which are compatible with experimental\nconstraints.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T13:58:43Z"}
{"aid":"http://arxiv.org/abs/2504.12957v1","title":"Cavity-enhanced spectroscopy of individual nuclear spins in a dense bath","summary":"Echo-based spectroscopy of the superhyperfine interaction of an electronic\nspin with nuclear spins in its surroundings enables detailed insights into the\nmicroscopic magnetic environment of spins in solids. Still, it is an\noutstanding challenge to resolve individual nuclear spins in a dense bath, in\nwhich many of them exhibit a comparable coupling strength. This simultaneously\nrequires a high spectral resolution and a large signal-to-noise ratio. However,\nwhen probing spin ensembles, dipolar interactions between the dopants can lead\nto a concentration-dependent trade-off between resolution and signal. Here, we\nfully eliminate this limitation of previous optical-echo-envelope-modulation\nspectroscopy experiments by integrating the emitters into a high-finesse\nresonator, which allows for strong optical echoes even at very low\nconcentrations. To demonstrate its potential, the technique is applied to\nerbium dopants in yttrium-orthosilicate (Er:YSO). Achieving an unprecedented\nspectral resolution enables precise measurements of the superhyperfine\ninteraction with four of the Y nuclear spins densely surrounding each emitter.\nThe achieved boost of the signal, enabled by the resonator, allows for\nextending the approach to the lowest concentration possible -- to the level of\nsingle dopants, thereby providing a tool for detecting and studying individual\nnuclear spins. Thus, our technique paves the way for an improved understanding\nof dense nuclear spin baths in solids.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-17T14:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.12962v1","title":"Astronomical Refutation of the New Chronology by Fomenko and Nosovsky:\n  The 1151-Year Planetary Cycle and Dating of the Almagest via Speed/Error\n  Correlation","summary":"This paper introduces two astronomical methods developed through\ncomputational simulation to evaluate the historical dating of ancient\nastronomical sources. The first identifies a 1151-year planetary cycle based on\nthe recurrence of visible configurations of Mercury to Saturn, including the\nSun and Moon, from a geocentric perspective. The second, called SESCC\n(Speed-Error Signals Cross Correlation), statistically estimates the epoch of\nstar catalogs by analyzing the correlation between positional error and proper\nmotion in ecliptic latitude. Both methods are reproducible, data-driven, and\nyield results that contradict key tenets of the New Chronology proposed by\nFomenko and Nosovsky, most notably the claim that the Anno Domini began in 1152\nCE. Open-source code and analysis tools are provided for independent\nverification.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,physics.hist-ph","published":"2025-04-17T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.12975v1","title":"Computing $n$-time correlation functions without ancilla qubits","summary":"The $n$-time correlation function is pivotal for establishing connections\nbetween theoretical predictions and experimental observations of a quantum\nsystem. Conventional methods for computing $n$-time correlation functions on\nquantum computers, such as the Hadamard test, generally require an ancilla\nqubit that controls the entire system -- an approach that poses challenges for\ndigital quantum devices with limited qubit connectivity, as well as for analog\nquantum platforms lacking controlled operations. Here, we introduce a method to\ncompute $n$-time correlation functions using only unitary evolutions on the\nsystem of interest, thereby eliminating the need for ancillas and the control\noperations. This approach substantially relaxes hardware connectivity\nrequirements for digital processors and enables more practical measurements of\n$n$-time correlation functions on analog platforms. We demonstrate our protocol\non IBM quantum hardware up to 12 qubits to measure fermionic and bosonic\nsingle-particle spectra of the Su-Schrieffer-Heeger model and the Schwinger\nmodel, respectively, and the out-of-time-order correlator in the\ntransverse-field Ising model. In the experiment, we further introduce a\nsignal-processing strategy that integrates signal filtering and correlation\nanalysis, and successfully reproduces the noiseless simulation results from the\nnoisy hardware. Our work highlights a route to exploring complex quantum\nmany-body correlation functions in practice, even in the presence of realistic\nhardware limitations and noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T14:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.12979v1","title":"Weizscker-Williams Gluon Helicity Distribution and Inclusive Dijet\n  Production in Longitudinally Polarized Electron-Proton Collisions","summary":"It is well-known that the back-to-back (correlation) limit of inclusive\nquark-antiquark dijet production in unpolarized high energy electron-proton\ncollisions can probe the Weizs\\\"{a}cker-Williams (WW) gluon transverse\nmomentum-dependent distribution (TMD) at small $x$ \\cite{Dominguez:2010xd,\nDominguez:2011wm}. In this paper, we consider a helicity-dependent version of\nthe same process: we study the double-spin asymmetry for inclusive\nquark-antiquark dijet production in longitudinally polarized electron-proton\nscattering at high energies. We show that in the back-to-back limit this\nprocess probes the WW gluon helicity TMD. Furthermore, we derive the small-$x$\nevolution equation for the operator related to the WW gluon helicity\ndistribution. We find that in the double-logarithmic approximation and in the\nlarge-$N_c$ limit, the small-$x$ asymptotics of the WW gluon helicity\ndistribution is governed by exactly the same evolution equation as that for the\ndipole gluon helicity distribution. The longitudinal double-spin asymmetry for\ninclusive dijet production in the longitudinally polarized electron-proton\ncollisions can thus test the small-$x$ helicity evolution equations and\nfacilitate constraining the initial conditions for phenomenology based on these\nequations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T14:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12985v1","title":"Accurate Modeling of LEGO-like vdW Heterostructures: Integrating Machine\n  Learned with Anisotropic Interlayer Potentials","summary":"Accurately modeling the structural reconstruction and thermodynamic behavior\nof van der Waals (vdW) heterostructures remains a significant challenge due to\nthe limitations of conventional force fields in capturing their complex\nmechanical, thermal, electronic, and tribological properties. To address these\nlimitations, we develop a hybrid framework that combines single-layer\nmachine-learned potential ($s$MLP) with physics-based anisotropic interlayer\npotential (ILP), effectively decoupling intralayer and interlayer interactions.\nThis $s$MLP+ILP approach modularizes the modeling of vdW heterostructures like\nassembling LEGOs, reducing the required training configurations by at least an\norder of magnitude compared to the pure MLP approach, while retaining\npredictive accuracy and computational efficiency. We validate our framework by\naccurately reproducing the mechanical properties of graphite, and resolving\nintricate Moir\\'e patterns in graphene/$h$-BN bilayers and\ngraphene/graphene/$h$-BN trilayer heterostructures, achieving excellent\nagreement with experimental observations. Leveraging the developed $s$MLP+ILP\napproach, we reveal the stacking order-dependent formation of Moir\\'e\nsuperlattice in trilayer graphene/$h$-BN/MoS$_2$ heterostructures,\ndemonstrating its ability to accurately model large-scale vdW systems\ncomprising hundreds of thousands of atoms with near $ab$ $initio$ precision.\nThese findings demonstrate that hybrid $s$MLP+ILP framework remarkably\noutperforms existing pure machine-learned or empirical potentials, offering a\nscalable and transferable solution for accurately and extensively modeling\ncomplex vdW materials across diverse applications, including sliding\nferroelectricity, thermal management, resistive switching, and superlubric\nnanodevices.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-17T14:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.12997v1","title":"All-in-One Transferring Image Compression from Human Perception to\n  Multi-Machine Perception","summary":"Efficiently transferring Learned Image Compression (LIC) model from human\nperception to machine perception is an emerging challenge in vision-centric\nrepresentation learning. Existing approaches typically adapt LIC to downstream\ntasks in a single-task manner, which is inefficient, lacks task interaction,\nand results in multiple task-specific bitstreams. To address these limitations,\nwe propose an asymmetric adaptor framework that supports multi-task adaptation\nwithin a single model. Our method introduces a shared adaptor to learn general\nsemantic features and task-specific adaptors to preserve task-level\ndistinctions. With only lightweight plug-in modules and a frozen base codec,\nour method achieves strong performance across multiple tasks while maintaining\ncompression efficiency. Experiments on the PASCAL-Context benchmark demonstrate\nthat our method outperforms both Fully Fine-Tuned and other Parameter Efficient\nFine-Tuned (PEFT) baselines, and validating the effectiveness of multi-vision\ntransferring.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.13003v1","title":"Towards Optimal Distributed Edge Coloring with Small Palettes","summary":"We design a deterministic distributed $\\mathcal{O}(\\log n)$-round reduction\nfrom the $(2\\Delta-2)$-edge coloring problem to the much easier\n$(2\\Delta-1)$-edge coloring problem. This is almost optimal, as the\n$(2\\Delta-2)$-edge coloring problem admits an $\\Omega(\\log_\\Delta n)$ lower\nbound. Further, we also obtain an optimal $\\mathcal{O}(\\log_\\Delta n)$-round\nreduction, albeit to the harder maximal independent set (MIS) problem.\n  The current state-of-the-art for $(2\\Delta - 1)$-edge coloring actually comes\nfrom an MIS algorithm by [Ghaffari \\& Grunau, FOCS'24], which runs in\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} n)$ rounds. With our new reduction, this\nround complexity now carries over to the $(2\\Delta - 2)$-edge coloring problem\nas well. Alternatively, one can also plug in the $(\\mathrm{poly} \\log \\Delta +\n\\mathcal{O}(\\log^{\\ast} n))$-round $(2\\Delta - 1)$-edge coloring algorithm from\n[Balliu, Brandt, Kuhn \\& Olivetti, PODC'22], which yields an optimal runtime of\n$\\mathcal{O}(\\log n)$ rounds for $\\Delta \\leq \\mathrm{poly} \\log n$.\nPreviously, the fastest deterministic algorithm using less than $2\\Delta - 1$\ncolors for general graphs by [Brandt, Maus, Narayanan, Schager \\& Uitto,\nSODA'25] ran in $\\widetilde{\\mathcal{O}}(\\log^3 n)$ rounds. In addition, we\nalso obtain a $\\mathcal{O}(\\log \\log n)$-round randomized reduction of\n$(2\\Delta - 2)$-edge coloring to $(2\\Delta - 1)$-edge coloring. This improves\nupon the (very recent) best randomized algorithm using less than $2\\Delta - 1$\ncolors from [Bourreau, Brandt \\& Nolin, STOC'25] by reducing the round\ncomplexity from $\\widetilde{\\mathcal{O}}(\\log^{8/3}\\log n)$ down to\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} \\log n)$.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-17T15:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.13053v1","title":"Quantitative Resolvent and Eigenfunction Stability for the Faber-Krahn\n  Inequality","summary":"For a bounded open set $\\Omega \\subset \\mathbb{R}^n$ with the same volume as\nthe unit ball, the classical Faber-Krahn inequality says that the first\nDirichlet eigenvalue $\\lambda_1(\\Omega)$ of the Laplacian is at least that of\nthe unit ball $B$. We prove that the deficit $\\lambda_1(\\Omega)- \\lambda_1(B)$\nin the Faber-Krahn inequality controls the square of the distance between the\nresolvent operator $(-\\Delta_\\Omega)^{-1}$ for the Dirichlet Laplacian on\n$\\Omega$ and the resolvent operator on the nearest unit ball $B(x_\\Omega)$. The\ndistance is measured by the operator norm from $C^{0,\\alpha}$ to $L^2$. As a\nmain application, we show that the Faber-Krahn deficit $\\lambda_1(\\Omega)-\n\\lambda_1(B)$ controls the squared $L^2$ norm between $k$th eigenfunctions on\n$\\Omega$ and $B(x_\\Omega)$ for every $k \\in \\mathbb{N}.$ In both of these main\ntheorems, the quadratic power is optimal.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T16:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.13063v1","title":"An exact approach for the multi-depot electric vehicle scheduling\n  problem","summary":"The \"avoid - shift - improve\" framework and the European Clean Vehicles\nDirective set the path for improving the efficiency and ultimately\ndecarbonizing the transport sector. While electric buses have already been\nadopted in several cities, regional bus lines may pose additional challenges\ndue to the potentially longer distances they have to travel. In this work, we\nmodel and solve the electric bus scheduling problem, lexicographically\nminimizing the size of the bus fleet, the number of charging stops, and the\ntotal energy consumed, to provide decision support for bus operators planning\nto replace their diesel-powered fleet with zero emission vehicles. We propose a\ngraph representation which allows partial charging without explicitly relying\non time variables and derive 3-index and 2-index mixed-integer linear\nprogramming formulations for the multi-depot electric vehicle scheduling\nproblem. While the 3-index model can be solved by an off-the-shelf solver\ndirectly, the 2-index model relies on an exponential number of constraints to\nensure the correct depot pairing. These are separated in a cutting plane\nfashion. We propose a set of instances with up to 80 service trips to compare\nthe two approaches, showing that, with a small number of depots, the compact\n3-index model performs very well. However, as the number of depots increases\nthe developed branch-and-cut algorithm proves to be of value. These findings\nnot only offer algorithmic insights but the developed approaches also provide\nactionable guidance for transit agencies and operators, allowing to quantify\ntrade-offs between fleet size, energy efficiency, and infrastructure needs\nunder realistic operational conditions.","main_category":"math.OC","categories":"math.OC,cs.DM","published":"2025-04-17T16:18:56Z"}
{"aid":"http://arxiv.org/abs/2504.13079v1","title":"Retrieval-Augmented Generation with Conflicting Evidence","summary":"Large language model (LLM) agents are increasingly employing\nretrieval-augmented generation (RAG) to improve the factuality of their\nresponses. However, in practice, these systems often need to handle ambiguous\nuser queries and potentially conflicting information from multiple sources\nwhile also suppressing inaccurate information from noisy or irrelevant\ndocuments. Prior work has generally studied and addressed these challenges in\nisolation, considering only one aspect at a time, such as handling ambiguity or\nrobustness to noise and misinformation. We instead consider multiple factors\nsimultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and\nMisinformation in Documents), a new dataset that simulates complex and\nrealistic scenarios for conflicting evidence for a user query, including\nambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent\napproach in which LLM agents debate over the merits of an answer over multiple\nrounds, allowing an aggregator to collate responses corresponding to\ndisambiguated entities while discarding misinformation and noise, thereby\nhandling diverse sources of conflict jointly. We demonstrate the effectiveness\nof MADAM-RAG using both closed and open-source models on AmbigDocs -- which\nrequires presenting all valid answers for ambiguous queries -- improving over\nstrong RAG baselines by up to 11.40% and on FaithEval -- which requires\nsuppressing misinformation -- where we improve by up to 15.80% (absolute) with\nLlama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for\nexisting RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match\nscore). While MADAM-RAG begins to address these conflicting factors, our\nanalysis indicates that a substantial gap remains especially when increasing\nthe level of imbalance in supporting evidence and misinformation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.13080v1","title":"Instability and stress fluctuations of a probe driven through a\n  worm-like micellar fluid","summary":"A particle moving through a worm-like micellar fluid (WLM) shows instability\nand large fluctuations beyond a threshold. Despite many detailed studies, a\ndirect measurement of the time-dependent stress on the probe particle remains\nunexplored. To address this, we have designed a measuring geometry coupled with\na commercial rheometer to study the dynamics of a cylindrical probe through a\nWLM system of 2 wt.\\% cetyltrimethyl ammonium tosylate(CTAT) + 100 mM sodium\nchloride(NaCl) for a wide range of velocity and stress scales. We map out the\nin-situ velocity distribution using particle imaging velocimetry. Beyond a\ncertain velocity threshold, we observe large stress fluctuation events with\ngradual stress build-up followed by sudden stress drop indicating the storage\nand release of elastic energy. The length scale constructed from the stress\nbuild-up time scale and the probe's velocity match the length scale of\nextensile deformation in the sample just before the stress drop, further\nconfirming the strong correlation of such storage and release of energy with\nthe unstable motion of the probe. Interestingly, despite their significant\ndifference in magnitudes, the Weissenberg number ($Wi$) for the onset of flow\ninstability obtained from the shear and extensile components remains almost the\nsame. We also find that the turbulent motion of the probe at higher $Wi$\nresults from the complex mixing of the stick-slip events originating from the\npartial release of the stored elastic energy. Further, we show that the\nmagnitude of the stick-slip events depends on the detailed micellar structure\nand dynamics controlled by salt concentration and temperature.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13083v1","title":"Feedforward suppression of readout-induced faults in quantum error\n  correction","summary":"We propose a method to reduce readout-induced faults, applicable in settings\nlike quantum error correction with repeated measurement cycles. The method\nconsists of an adaptive readout sequence conditioned on each check qubit's\nreadout result from the previous cycle. For readout errors and\nmeasurement-induced leakage that are stronger in a particular qubit state, this\nfeedforward protocol can suppress the physical qubit errors. Focusing on a\nsimple realization of conditionally flipping (by an X gate) the state of check\nqubits before their measurement, we investigate the effect of such\nstate-dependent errors using simulations in the setup of a low-density parity\ncheck code. We show that the suggested protocol can reduce both logical errors\nand decoding time, two important aspects of fault-tolerant quantum\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T16:50:26Z"}
{"aid":"http://arxiv.org/abs/2504.13109v1","title":"UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models","summary":"Flow matching models have emerged as a strong alternative to diffusion\nmodels, but existing inversion and editing methods designed for diffusion are\noften ineffective or inapplicable to them. The straight-line, non-crossing\ntrajectories of flow models pose challenges for diffusion-based approaches but\nalso open avenues for novel solutions. In this paper, we introduce a\npredictor-corrector-based framework for inversion and editing in flow models.\nFirst, we propose Uni-Inv, an effective inversion method designed for accurate\nreconstruction. Building on this, we extend the concept of delayed injection to\nflow models and introduce Uni-Edit, a region-aware, robust image editing\napproach. Our methodology is tuning-free, model-agnostic, efficient, and\neffective, enabling diverse edits while ensuring strong preservation of\nedit-irrelevant regions. Extensive experiments across various generative models\ndemonstrate the superiority and generalizability of Uni-Inv and Uni-Edit, even\nunder low-cost settings. Project page: https://uniedit-flow.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.13122v1","title":"VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference\n  Optimization for Large Video Models","summary":"Large Video Models (LVMs) built upon Large Language Models (LLMs) have shown\npromise in video understanding but often suffer from misalignment with human\nintuition and video hallucination issues. To address these challenges, we\nintroduce VistaDPO, a novel framework for Video Hierarchical Spatial-Temporal\nDirect Preference Optimization. VistaDPO enhances text-video preference\nalignment across three hierarchical levels: i) Instance Level, aligning overall\nvideo content with responses; ii) Temporal Level, aligning video temporal\nsemantics with event descriptions; and iii) Perceptive Level, aligning spatial\nobjects with language tokens. Given the lack of datasets for fine-grained\nvideo-language preference alignment, we construct VistaDPO-7k, a dataset of\n7.2K QA pairs annotated with chosen and rejected responses, along with\nspatial-temporal grounding information such as timestamps, keyframes, and\nbounding boxes. Extensive experiments on benchmarks such as Video\nHallucination, Video QA, and Captioning performance tasks demonstrate that\nVistaDPO significantly improves the performance of existing LVMs, effectively\nmitigating video-language misalignment and hallucination. The code and data are\navailable at https://github.com/HaroldChen19/VistaDPO.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-17T17:39:41Z"}
{"aid":"http://arxiv.org/abs/2504.13153v1","title":"Training-Free Hierarchical Scene Understanding for Gaussian Splatting\n  with Superpoint Graphs","summary":"Bridging natural language and 3D geometry is a crucial step toward flexible,\nlanguage-driven scene understanding. While recent advances in 3D Gaussian\nSplatting (3DGS) have enabled fast and high-quality scene reconstruction,\nresearch has also explored incorporating open-vocabulary understanding into\n3DGS. However, most existing methods require iterative optimization over\nper-view 2D semantic feature maps, which not only results in inefficiencies but\nalso leads to inconsistent 3D semantics across views. To address these\nlimitations, we introduce a training-free framework that constructs a\nsuperpoint graph directly from Gaussian primitives. The superpoint graph\npartitions the scene into spatially compact and semantically coherent regions,\nforming view-consistent 3D entities and providing a structured foundation for\nopen-vocabulary understanding. Based on the graph structure, we design an\nefficient reprojection strategy that lifts 2D semantic features onto the\nsuperpoints, avoiding costly multi-view iterative training. The resulting\nrepresentation ensures strong 3D semantic coherence and naturally supports\nhierarchical understanding, enabling both coarse- and fine-grained\nopen-vocabulary perception within a unified semantic field. Extensive\nexperiments demonstrate that our method achieves state-of-the-art\nopen-vocabulary segmentation performance, with semantic field reconstruction\ncompleted over $30\\times$ faster. Our code will be available at\nhttps://github.com/Atrovast/THGS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:56:07Z"}
{"aid":"http://arxiv.org/abs/2504.13171v1","title":"Sleep-time Compute: Beyond Inference Scaling at Test-time","summary":"Scaling test-time compute has emerged as a key ingredient for enabling large\nlanguage models (LLMs) to solve difficult problems, but comes with high latency\nand inference cost. We introduce sleep-time compute, which allows models to\n\"think\" offline about contexts before queries are presented: by anticipating\nwhat queries users might ask and pre-computing useful quantities, we can\nsignificantly reduce the compute requirements at test-time. To demonstrate the\nefficacy of our method, we create modified versions of two reasoning tasks -\nStateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can\nreduce the amount of test-time compute needed to achieve the same accuracy by ~\n5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time\ncompute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic\nand 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic,\nwhich extends GSM-Symbolic by including multiple related queries per context.\nBy amortizing sleep-time compute across related queries about the same context\nusing Multi-Query GSM-Symbolic, we can decrease the average cost per query by\n2.5x. We then conduct additional analysis to understand when sleep-time compute\nis most effective, finding the predictability of the user query to be well\ncorrelated with the efficacy of sleep-time compute. Finally, we conduct a\ncase-study of applying sleep-time compute to a realistic agentic SWE task.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-17T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.13175v1","title":"Novel Demonstration Generation with Gaussian Splatting Enables Robust\n  One-Shot Manipulation","summary":"Visuomotor policies learned from teleoperated demonstrations face challenges\nsuch as lengthy data collection, high costs, and limited data diversity.\nExisting approaches address these issues by augmenting image observations in\nRGB space or employing Real-to-Sim-to-Real pipelines based on physical\nsimulators. However, the former is constrained to 2D data augmentation, while\nthe latter suffers from imprecise physical simulation caused by inaccurate\ngeometric reconstruction. This paper introduces RoboSplat, a novel method that\ngenerates diverse, visually realistic demonstrations by directly manipulating\n3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian\nSplatting (3DGS), directly edit the reconstructed scene, and augment data\nacross six types of generalization with five techniques: 3D Gaussian\nreplacement for varying object types, scene appearance, and robot embodiments;\nequivariant transformations for different object poses; visual attribute\nediting for various lighting conditions; novel view synthesis for new camera\nperspectives; and 3D content generation for diverse object types. Comprehensive\nreal-world experiments demonstrate that RoboSplat significantly enhances the\ngeneralization of visuomotor policies under diverse disturbances. Notably,\nwhile policies trained on hundreds of real-world demonstrations with additional\n2D data augmentation achieve an average success rate of 57.2%, RoboSplat\nattains 87.8% in one-shot settings across six types of generalization in the\nreal world.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T17:59:43Z"}
