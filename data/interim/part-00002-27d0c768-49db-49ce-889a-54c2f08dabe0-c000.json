{"aid":"http://arxiv.org/abs/2503.21658v1","title":"Numerical Analysis of the Stability of Iron Dust Bunsen Flames","summary":"This article presents numerical simulations of the response of an iron dust\nBunsen flame to particle seeding changes. A validated numerical model is used\nto study the impact of particle seeding fluctuations on flame stability.\nSimulations are conducted for the Bunsen setup in the right-side up and up-side\ndown configuration. No significant differences in flame response are identified\nin flame stability between the right-side up and up-side down configurations.\nWe find that the Bunsen flame is surprisingly robust to abrupt changes in\nparticle loading. The sudden change in particle loading does not excite any\nintrinsic instabilities in the flame. Based on our results, the iron dust\nflames are robust to imposed fluctuations. We hypothesize that this is due to\nthe lack of a feedback mechanism between the burned temperature and the heat\nrelease rate. This mechanism is present in conventional, chemistry-driven,\ngaseous flames. However, such a mechanism is absent in iron dust flames because\nthe combustion of individual iron particles is limited by oxygen diffusion,\nwhich is insensitive to temperature.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-27T16:22:50Z"}
{"aid":"http://arxiv.org/abs/2503.21664v1","title":"Functions of bounded variation and Lipschitz algebras in metric measure\n  spaces","summary":"Given a unital algebra $\\mathscr A$ of locally Lipschitz functions defined\nover a metric measure space $({\\mathrm X},{\\mathsf d},\\mathfrak m)$, we study\ntwo associated notions of function of bounded variation and their relations:\nthe space ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$, obtained by\napproximating in energy with elements of $\\mathscr A$, and the space ${\\mathrm\nBV}_{\\mathrm W}({\\mathrm X};\\mathscr A)$, defined through an\nintegration-by-parts formula that involves derivations acting in duality with\n$\\mathscr A$. Our main result provides a sufficient condition on the algebra\n$\\mathscr A$ under which ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$\ncoincides with the standard metric BV space ${\\mathrm BV}_{\\mathrm H}({\\mathrm\nX})$, which corresponds to taking as $\\mathscr A$ the collection of all locally\nLipschitz functions. Our result applies to several cases of interest, for\nexample to Euclidean spaces and Riemannian manifolds equipped with the algebra\nof smooth functions, or to Banach and Wasserstein spaces equipped with the\nalgebra of cylinder functions. Analogous results for metric Sobolev spaces\n${\\mathrm H}^{1,p}$ of exponent $p\\in(1,\\infty)$ were previously obtained by\nseveral different authors.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-03-27T16:32:47Z"}
{"aid":"http://arxiv.org/abs/2503.21671v1","title":"A Bespoke Design Approach to Low-Power Printed Microprocessors for\n  Machine Learning Applications","summary":"Printed electronics have gained significant traction in recent years,\npresenting a viable path to integrating computing into everyday items, from\ndisposable products to low-cost healthcare. However, the adoption of computing\nin these domains is hindered by strict area and power constraints, limiting the\neffectiveness of general-purpose microprocessors. This paper proposes a bespoke\nmicroprocessor design approach to address these challenges, by tailoring the\ndesign to specific applications and eliminating unnecessary logic. Targeting\nmachine learning applications, we further optimize core operations by\nintegrating a SIMD MAC unit supporting 4 precision configurations that boost\nthe efficiency of microprocessors. Our evaluation across 6 ML models and the\nlarge-scale Zero-Riscy core, shows that our methodology can achieve\nimprovements of 22.2%, 23.6%, and 33.79% in area, power, and speed,\nrespectively, without compromising accuracy. Against state-of-the-art printed\nprocessors, our approach can still offer significant speedups, but along with\nsome accuracy degradation. This work explores how such trade-offs can enable\nlow-power printed microprocessors for diverse ML applications.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-27T16:37:18Z"}
{"aid":"http://arxiv.org/abs/2503.21677v1","title":"A tale of two goals: leveraging sequentiality in multi-goal scenarios","summary":"Several hierarchical reinforcement learning methods leverage planning to\ncreate a graph or sequences of intermediate goals, guiding a lower-level\ngoal-conditioned (GC) policy to reach some final goals. The low-level policy is\ntypically conditioned on the current goal, with the aim of reaching it as\nquickly as possible. However, this approach can fail when an intermediate goal\ncan be reached in multiple ways, some of which may make it impossible to\ncontinue toward subsequent goals. To address this issue, we introduce two\ninstances of Markov Decision Process (MDP) where the optimization objective\nfavors policies that not only reach the current goal but also subsequent ones.\nIn the first, the agent is conditioned on both the current and final goals,\nwhile in the second, it is conditioned on the next two goals in the sequence.\nWe conduct a series of experiments on navigation and pole-balancing tasks in\nwhich sequences of intermediate goals are given. By evaluating policies trained\nwith TD3+HER on both the standard GC-MDP and our proposed MDPs, we show that,\nin most cases, conditioning on the next two goals improves stability and sample\nefficiency over other approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T16:47:46Z"}
{"aid":"http://arxiv.org/abs/2503.21686v1","title":"Molecular Quantum Transformer","summary":"The Transformer model, renowned for its powerful attention mechanism, has\nachieved state-of-the-art performance in various artificial intelligence tasks\nbut faces challenges such as high computational cost and memory usage.\nResearchers are exploring quantum computing to enhance the Transformer's\ndesign, though it still shows limited success with classical data. With a\ngrowing focus on leveraging quantum machine learning for quantum data,\nparticularly in quantum chemistry, we propose the Molecular Quantum Transformer\n(MQT) for modeling interactions in molecular quantum systems. By utilizing\nquantum circuits to implement the attention mechanism on the molecular\nconfigurations, MQT can efficiently calculate ground-state energies for all\nconfigurations. Numerical demonstrations show that in calculating ground-state\nenergies for H_2, LiH, BeH_2, and H_4, MQT outperforms the classical\nTransformer, highlighting the promise of quantum effects in Transformer\nstructures. Furthermore, its pretraining capability on diverse molecular data\nfacilitates the efficient learning of new molecules, extending its\napplicability to complex molecular systems with minimal additional effort. Our\nmethod offers an alternative to existing quantum algorithms for estimating\nground-state energies, opening new avenues in quantum chemistry and materials\nscience.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-03-27T16:54:15Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21718v1","title":"Outlier dimensions favor frequent tokens in language model","summary":"We study last-layer outlier dimensions, i.e.dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.7","published":"2025-03-27T17:30:50Z"}
{"aid":"http://arxiv.org/abs/2503.21729v1","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large\n  Reasoning Models with Iterative Retrieval Augmented Generation","summary":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:44:18Z"}
{"aid":"http://arxiv.org/abs/2503.21731v1","title":"Cylindrical Algebraic Decomposition in \\textit{Macaulay2}","summary":"\\texttt{CylindricalAlgebraicDecomposition.m2} is the first implementation of\nCylindrical Algebraic Decomposition (CAD) in \\textit{Macaulay2}. CAD decomposes\nspace into `cells' where input polynomials are sign-invariant. This package\ncomputes an Open CAD (full-dimensional cells only) for sets of real polynomials\nwith rational coefficients, enabling users to solve existential problems\ninvolving strict inequalities. With the construction of a full CAD (cells of\nall dimensions), this tool could be extended to solve any real quantifier\nelimination problem. The current implementation employs the Lazard projection\nand introduces a new heuristic for choosing the variable ordering.","main_category":"cs.SC","categories":"cs.SC,math.AG","published":"2025-03-27T17:46:24Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.21737v1","title":"High-intensity Voronoi percolation on manifolds","summary":"We study Voronoi percolation on a large class of $d$-dimensional Riemannian\nmanifolds, which includes hyperbolic space $\\mathbb{H}^d$ for $d\\geq 2$. We\nprove that as the intensity $\\lambda$ of the underlying Poisson point process\ntends to infinity, both critical parameters $p_c(M,\\lambda)$ and\n$p_u(M,\\lambda)$ converge to the Euclidean critical parameter\n$p_c(\\mathbb{R}^d)$. This extends a recent result of Hansen & M\\\"uller in the\nspecial case $M=\\mathbb{H}^2$ to a general class of manifolds of arbitrary\ndimension. A crucial step in our proof, which may be of independent interest,\nis to show that if $M$ is simply connected and one-ended, then embedded graphs\ninduced by a general class of tessellations on $M$ have connected minimal\ncutsets. In particular, this result applies to $\\varepsilon$-nets, allowing us\nto implement a \"fine-graining\" argument. We also develop an annealed way of\nexploring the Voronoi cells that we use to characterize the uniqueness phase.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:49:50Z"}
{"aid":"http://arxiv.org/abs/2503.21760v1","title":"MemInsight: Autonomous Memory Augmentation for LLM Agents","summary":"Large language model (LLM) agents have evolved to intelligently process\ninformation, make decisions, and interact with users or tools. A key capability\nis the integration of long-term memory capabilities, enabling these agents to\ndraw upon historical interactions and knowledge. However, the growing memory\nsize and need for semantic structuring pose significant challenges. In this\nwork, we propose an autonomous memory augmentation approach, MemInsight, to\nenhance semantic data representation and retrieval mechanisms. By leveraging\nautonomous augmentation to historical interactions, LLM agents are shown to\ndeliver more accurate and contextualized responses. We empirically validate the\nefficacy of our proposed approach in three task scenarios; conversational\nrecommendation, question answering and event summarization. On the LLM-REDIAL\ndataset, MemInsight boosts persuasiveness of recommendations by up to 14%.\nMoreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval.\nOur empirical results show the potential of MemInsight to enhance the\ncontextual performance of LLM agents across multiple tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-27T17:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.21761v1","title":"Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single\n  Video","summary":"This paper presents a unified approach to understanding dynamic scenes from\ncasual videos. Large pretrained vision foundation models, such as\nvision-language, video depth prediction, motion tracking, and segmentation\nmodels, offer promising capabilities. However, training a single model for\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\nmulti-stage optimization framework that harnesses multiple pretrained models to\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\npose estimation, and dense 3D motion tracking. Our results show\nstate-of-the-art performance in dynamic 4D modeling with superior visual\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\neffectiveness of repurposing visual foundation models for 4D understanding.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:32Z"}
{"aid":"http://arxiv.org/abs/2503.21766v1","title":"Stable-SCore: A Stable Registration-based Framework for 3D Shape\n  Correspondence","summary":"Establishing character shape correspondence is a critical and fundamental\ntask in computer vision and graphics, with diverse applications including\nre-topology, attribute transfer, and shape interpolation. Current dominant\nfunctional map methods, while effective in controlled scenarios, struggle in\nreal situations with more complex challenges such as non-isometric shape\ndiscrepancies. In response, we revisit registration-for-correspondence methods\nand tap their potential for more stable shape correspondence estimation. To\novercome their common issues including unstable deformations and the necessity\nfor careful pre-alignment or high-quality initial 3D correspondences, we\nintroduce Stable-SCore: A Stable Registration-based Framework for 3D Shape\nCorrespondence. We first re-purpose a foundation model for 2D character\ncorrespondence that ensures reliable and stable 2D mappings. Crucially, we\npropose a novel Semantic Flow Guided Registration approach that leverages 2D\ncorrespondence to guide mesh deformations. Our framework significantly\nsurpasses existing methods in challenging scenarios, and brings possibilities\nfor a wide array of real applications, as demonstrated in our results.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-27T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.23679v1","title":"The Devil is in the Distributions: Explicit Modeling of Scene Content is\n  Key in Zero-Shot Video Captioning","summary":"Zero-shot video captioning requires that a model generate high-quality\ncaptions without human-annotated video-text pairs for training.\nState-of-the-art approaches to the problem leverage CLIP to extract\nvisual-relevant textual prompts to guide language models in generating\ncaptions. These methods tend to focus on one key aspect of the scene and build\na caption that ignores the rest of the visual input. To address this issue, and\ngenerate more accurate and complete captions, we propose a novel progressive\nmulti-granularity textual prompting strategy for zero-shot video captioning.\nOur approach constructs three distinct memory banks, encompassing noun phrases,\nscene graphs of noun phrases, and entire sentences. Moreover, we introduce a\ncategory-aware retrieval mechanism that models the distribution of natural\nlanguage surrounding the specific topics in question. Extensive experiments\ndemonstrate the effectiveness of our method with 5.7%, 16.2%, and 3.4%\nimprovements in terms of the main metric CIDEr on MSR-VTT, MSVD, and VATEX\nbenchmarks compared to existing state-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T03:00:19Z"}
{"aid":"http://arxiv.org/abs/2503.23705v1","title":"Steering Large Agent Populations using Mean-Field Schrodinger Bridges\n  with Gaussian Mixture Models","summary":"The Mean-Field Schrodinger Bridge (MFSB) problem is an optimization problem\naiming to find the minimum effort control policy to drive a McKean-Vlassov\nstochastic differential equation from one probability measure to another. In\nthe context of multiagent control, the objective is to control the\nconfiguration of a swarm of identical, interacting cooperative agents, as\ncaptured by the time-varying probability measure of their state. Available\nmethods for solving this problem for distributions with continuous support rely\neither on spatial discretizations of the problem's domain or on approximating\noptimal solutions using neural networks trained through stochastic optimization\nschemes. For agents following Linear Time-Varying dynamics, and for Gaussian\nMixture Model boundary distributions, we propose a highly efficient\nparameterization to approximate the solutions of the corresponding MFSB in\nclosed form, without any learning steps. Our proposed approach consists of a\nmixture of elementary policies, each solving a Gaussian-to-Gaussian Covariance\nSteering problem from the components of the initial to the components of the\nterminal mixture. Leveraging the semidefinite formulation of the Covariance\nSteering problem, our proposed solver can handle probabilistic hard constraints\non the system's state, while maintaining numerical tractability. We illustrate\nour approach on a variety of numerical examples.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-03-31T04:01:04Z"}
{"aid":"http://arxiv.org/abs/2503.23713v1","title":"GNN-Based Candidate Node Predictor for Influence Maximization in\n  Temporal Graphs","summary":"In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-03-31T04:28:37Z"}
{"aid":"http://arxiv.org/abs/2503.23725v1","title":"Exploring Temporal Dynamics in Event-based Eye Tracker","summary":"Eye-tracking is a vital technology for human-computer interaction, especially\nin wearable devices such as AR, VR, and XR. The realization of high-speed and\nhigh-precision eye-tracking using frame-based image sensors is constrained by\ntheir limited temporal resolution, which impairs the accurate capture of rapid\nocular dynamics, such as saccades and blinks. Event cameras, inspired by\nbiological vision systems, are capable of perceiving eye movements with\nextremely low power consumption and ultra-high temporal resolution. This makes\nthem a promising solution for achieving high-speed, high-precision tracking\nwith rich temporal dynamics. In this paper, we propose TDTracker, an effective\neye-tracking framework that captures rapid eye movements by thoroughly modeling\ntemporal dynamics from both implicit and explicit perspectives. TDTracker\nutilizes 3D convolutional neural networks to capture implicit short-term\ntemporal dynamics and employs a cascaded structure consisting of a\nFrequency-aware Module, GRU, and Mamba to extract explicit long-term temporal\ndynamics. Ultimately, a prediction heatmap is used for eye coordinate\nregression. Experimental results demonstrate that TDTracker achieves\nstate-of-the-art (SOTA) performance on the synthetic SEET dataset and secured\nThird place in the CVPR event-based eye-tracking challenge 2025. Our code is\navailable at https://github.com/rhwxmx/TDTracker.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.23730v1","title":"KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large\n  Vision-Language Models in the Korean Language","summary":"The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-03-31T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2503.23731v1","title":"Investigation of intelligent barbell squat coaching system based on\n  computer vision and machine learning","summary":"Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV","published":"2025-03-31T05:08:52Z"}
{"aid":"http://arxiv.org/abs/2503.23740v1","title":"LANID: LLM-assisted New Intent Discovery","summary":"Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T05:34:32Z"}
{"aid":"http://arxiv.org/abs/2503.23752v1","title":"StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and\n  Latent Sequence Diffusion","summary":"In the field of sketch generation, raster-format trained models often produce\nnon-stroke artifacts, while vector-format trained models typically lack a\nholistic understanding of sketches, leading to compromised recognizability.\nMoreover, existing methods struggle to extract common features from similar\nelements (e.g., eyes of animals) appearing at varying positions across\nsketches. To address these challenges, we propose StrokeFusion, a two-stage\nframework for vector sketch generation. It contains a dual-modal sketch feature\nlearning network that maps strokes into a high-quality latent space. This\nnetwork decomposes sketches into normalized strokes and jointly encodes stroke\nsequences with Unsigned Distance Function (UDF) maps, representing sketches as\nsets of stroke feature vectors. Building upon this representation, our\nframework exploits a stroke-level latent diffusion model that simultaneously\nadjusts stroke position, scale, and trajectory during generation. This enables\nhigh-fidelity sketch generation while supporting stroke interpolation editing.\nExtensive experiments on the QuickDraw dataset demonstrate that our framework\noutperforms state-of-the-art techniques, validating its effectiveness in\npreserving structural integrity and semantic features. Code and models will be\nmade publicly available upon publication.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-03-31T06:03:03Z"}
{"aid":"http://arxiv.org/abs/2503.23759v1","title":"Word Break on SLP-Compressed Texts","summary":"Word Break is a prototypical factorization problem in string processing:\nGiven a word $w$ of length $N$ and a dictionary $\\mathcal{D} = \\{d_1, d_2,\n\\ldots, d_{K}\\}$ of $K$ strings, determine whether we can partition $w$ into\nwords from $\\mathcal{D}$. We propose the first algorithm that solves the Word\nBreak problem over the SLP-compressed input text $w$. Specifically, we show\nthat, given the string $w$ represented using an SLP of size $g$, we can solve\nthe Word Break problem in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$ time, where $m\n= \\max_{i=1}^{K} |d_i|$, $M = \\sum_{i=1}^{K} |d_i|$, and $\\omega \\geq 2$ is the\nmatrix multiplication exponent. We obtain our algorithm as a simple corollary\nof a more general result: We show that in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$\ntime, we can index the input text $w$ so that solving the Word Break problem\nfor any of its substrings takes $\\mathcal{O}(m^2 \\log N)$ time (independent of\nthe substring length). Our second contribution is a lower bound: We prove that,\nunless the Combinatorial $k$-Clique Conjecture fails, there is no combinatorial\nalgorithm for Word Break on SLP-compressed strings running in $\\mathcal{O}(g\n\\cdot m^{2-\\epsilon} + M)$ time for any $\\epsilon > 0$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-03-31T06:19:05Z"}
{"aid":"http://arxiv.org/abs/2503.23766v1","title":"Accelerating High-Efficiency Organic Photovoltaic Discovery via\n  Pretrained Graph Neural Networks and Generative Reinforcement Learning","summary":"Organic photovoltaic (OPV) materials offer a promising avenue toward\ncost-effective solar energy utilization. However, optimizing donor-acceptor\n(D-A) combinations to achieve high power conversion efficiency (PCE) remains a\nsignificant challenge. In this work, we propose a framework that integrates\nlarge-scale pretraining of graph neural networks (GNNs) with a GPT-2\n(Generative Pretrained Transformer 2)-based reinforcement learning (RL)\nstrategy to design OPV molecules with potentially high PCE. This approach\nproduces candidate molecules with predicted efficiencies approaching 21\\%,\nalthough further experimental validation is required. Moreover, we conducted a\npreliminary fragment-level analysis to identify structural motifs recognized by\nthe RL model that may contribute to enhanced PCE, thus providing design\nguidelines for the broader research community. To facilitate continued\ndiscovery, we are building the largest open-source OPV dataset to date,\nexpected to include nearly 3,000 donor-acceptor pairs. Finally, we discuss\nplans to collaborate with experimental teams on synthesizing and characterizing\nAI-designed molecules, which will provide new data to refine and improve our\npredictive and generative models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23768v1","title":"Texture or Semantics? Vision-Language Models Get Lost in Font\n  Recognition","summary":"Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic\ncapabilities, achieving impressive performance in various tasks such as image\nrecognition and object localization. However, their effectiveness in\nfine-grained tasks remains an open question. In everyday scenarios, individuals\nencountering design materials, such as magazines, typography tutorials,\nresearch papers, or branding content, may wish to identify aesthetically\npleasing fonts used in the text. Given their multimodal capabilities and free\naccessibility, many VLMs are often considered potential tools for font\nrecognition. This raises a fundamental question: Do VLMs truly possess the\ncapability to recognize fonts? To investigate this, we introduce the Font\nRecognition Benchmark (FRB), a compact and well-structured dataset comprising\n15 commonly used fonts. FRB includes two versions: (i) an easy version, where\n10 sentences are rendered in different fonts, and (ii) a hard version, where\neach text sample consists of the names of the 15 fonts themselves, introducing\na stroop effect that challenges model perception. Through extensive evaluation\nof various VLMs on font recognition tasks, we arrive at the following key\nfindings: (i) Current VLMs exhibit limited font recognition capabilities, with\nmany state-of-the-art models failing to achieve satisfactory performance. (ii)\nFew-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits\nin improving font recognition accuracy across different VLMs. (iii) Attention\nanalysis sheds light on the inherent limitations of VLMs in capturing semantic\nfeatures.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-03-31T06:33:21Z"}
{"aid":"http://arxiv.org/abs/2503.23771v1","title":"XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large\n  Ultra-High-Resolution Remote Sensing Imagery?","summary":"The astonishing breakthrough of multimodal large language models (MLLMs) has\nnecessitated new benchmarks to quantitatively assess their capabilities, reveal\ntheir limitations, and indicate future research directions. However, this is\nchallenging in the context of remote sensing (RS), since the imagery features\nultra-high resolution that incorporates extremely complex semantic\nrelationships. Existing benchmarks usually adopt notably smaller image sizes\nthan real-world RS scenarios, suffer from limited annotation quality, and\nconsider insufficient dimensions of evaluation. To address these issues, we\npresent XLRS-Bench: a comprehensive benchmark for evaluating the perception and\nreasoning capabilities of MLLMs in ultra-high-resolution RS scenarios.\nXLRS-Bench boasts the largest average image size (8500$\\times$8500) observed\nthus far, with all evaluation samples meticulously annotated manually, assisted\nby a novel semi-automatic captioner on ultra-high-resolution RS images. On top\nof the XLRS-Bench, 16 sub-tasks are defined to evaluate MLLMs' 10 kinds of\nperceptual capabilities and 6 kinds of reasoning capabilities, with a primary\nemphasis on advanced cognitive processes that facilitate real-world\ndecision-making and the capture of spatiotemporal changes. The results of both\ngeneral and RS-focused MLLMs on XLRS-Bench indicate that further efforts are\nneeded for real-world RS applications. We have open-sourced XLRS-Bench to\nsupport further research in developing more powerful MLLMs for remote sensing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:41:18Z"}
{"aid":"http://arxiv.org/abs/2503.23772v1","title":"TransVFC: A Transformable Video Feature Compression Framework for\n  Machines","summary":"Nowadays, more and more video transmissions primarily aim at downstream\nmachine vision tasks rather than humans. While widely deployed Human Visual\nSystem (HVS) oriented video coding standards like H.265/HEVC and H.264/AVC are\nefficient, they are not the optimal approaches for Video Coding for Machines\n(VCM) scenarios, leading to unnecessary bitrate expenditure. The academic and\ntechnical exploration within the VCM domain has led to the development of\nseveral strategies, and yet, conspicuous limitations remain in their\nadaptability for multi-task scenarios. To address the challenge, we propose a\nTransformable Video Feature Compression (TransVFC) framework. It offers a\ncompress-then-transfer solution and includes a video feature codec and Feature\nSpace Transform (FST) modules. In particular, the temporal redundancy of video\nfeatures is squeezed by the codec through the scheme-based inter-prediction\nmodule. Then, the codec implements perception-guided conditional coding to\nminimize spatial redundancy and help the reconstructed features align with\ndownstream machine perception.After that, the reconstructed features are\ntransferred to new feature spaces for diverse downstream tasks by FST modules.\nTo accommodate a new downstream task, it only requires training one lightweight\nFST module, avoiding retraining and redeploying the upstream codec and\ndownstream task networks. Experiments show that TransVFC achieves high\nrate-task performance for diverse tasks of different granularities. We expect\nour work can provide valuable insights for video feature compression in\nmulti-task scenarios. The codes are at https://github.com/Ws-Syx/TransVFC.","main_category":"eess.IV","categories":"eess.IV","published":"2025-03-31T06:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.23773v1","title":"Seasonal bias-correction of daily precipitation over France using a\n  stitch model designed for robust extremes representation","summary":"Highly resoluted and accurate daily precipitation data are required for\nimpact models to perform adequately and to correctly measure high-risk events'\nimpact. In order to produce such data, bias-correction is often needed. Most of\nthose statistical methods correct the probability distributions of daily\nprecipitation by modeling them using either empirical or parametric\ndistributions. A recent semi-parametric model based on a penalized Berk-Jones\n(BJ) statistical test which allows for an automatic and personalized splicing\nof parametric and nonparametric has been developed. This method, called\nStitch-BJ model, was found to be able to model daily precipitation correctly\nand showed interesting potential in a bias-correction setting. In the present\nstudy, we will consolidate these results by taking into account the seasonal\nproperties of daily precipitation in an out-of-sample context, and by\nconsidering dry days probabilities in our methodology. We evaluate the\nperformance of the Stitch-BJ method in this seasonal bias-correction setting\nagainst more classical models such as the Gamma, Exponentiated Weibull (ExpW),\nExtended Generalized Pareto (EGP) or empirical distributions. The Stitch-BJ\ndistribution was able to consistently perform as well or better than all the\nother models over the validation set, including the empirical distribution,\nwhich is often used due to its robustness.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2503.23789v1","title":"Reviewing the fundamentals and best practices to characterize\n  microplastics using state-of-the-art quantum-cascade laser\n  reflectance-absorbance spectroscopy","summary":"Microplastic pollution studies depend on reliable identification of the\nsuspicious particles. Out of the various analytical techniques available to\ncharacterize them, infrared transflectance using a tuneable mid-IR quantum\ncascade laser is a high-throughput state-of-the-art imaging option,\nspecifically Agilent QCL-LDIR (Quantum Cascade Laser Direct Infrared imaging).\nIts conceptual grounds are reviewed, instrumental developments are discussed,\nalong with a review of applications and best practices to overcome\nobstacles/difficulties in routine measurements, namely: the spectral range, the\nvariation of some peak intensities with the particles size, effects of the size\nof the particles, processing speed, and avoiding the use of measurement\naliquots. Objective procedures to avoid too many false positives when\nidentifying spectra and to distinguish fibers and fragments are given. These\npractices open a path to QCL-LDIR measurement standardization and potential use\nfor microplastics monitoring, as requested by many governmental bodies in\ncharge of setting environmental protection rules.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:04:13Z"}
{"aid":"http://arxiv.org/abs/2503.23816v1","title":"Two-electron edge states in a double SSH-chain of quantum dots","summary":"We study an interacting two-body model with adjustable spin tunneling in the\ncontext of the double SSH chains for a quantum dot system. We discovered that\nvarying interaction strengths and spin tunneling significantly influence the\nproperties of correlated edge states in the energy spectrum obtained through\nexact diagonalization. We observe that stronger interactions lead to longer\ndecay lengths of these states. Conversely, the decay length decreases as the\ndifference in intracell or intercell tunneling increases. Importantly, the\ndecay length is strongly correlated with the dynamical behavior of two\nparticles; specifically, an increase in decay length corresponds to a decrease\nin motion frequency. This conclusion is supported by the observation of the\nexpectation value of coordinate operators of the particles.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T07:50:06Z"}
{"aid":"http://arxiv.org/abs/2503.23829v1","title":"Expanding RL with Verifiable Rewards Across Diverse Domains","summary":"Reinforcement learning (RL) with verifiable rewards (RLVR) has shown\npromising results in mathematical reasoning and coding tasks where\nwell-structured reference answers are available. However, its applicability to\nbroader domains remains underexplored. In this work, we study the extension of\nRLVR to more diverse domains such as medicine, chemistry, psychology, and\neconomics. We observe high agreement in binary judgments across different large\nlanguage models (LLMs) when objective reference answers exist, which challenges\nthe necessity of large-scale annotation for training domain-specific reward\nmodels. To address the limitations of binary rewards when handling unstructured\nreference answers, we further incorporate model-based soft scoring into RLVR to\nimprove its flexibility. Our experiments show that a distilled generative\nreward model can serve as an effective cross-domain verifier, providing\nreliable reward signals for RL without requiring domain-specific annotations.\nBy fine-tuning a base 7B model using various RL algorithms against our reward\nmodel, we obtain policies that outperform state-of-the-art open-source aligned\nLLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a large\nmargin, across domains in free-form answer settings. This also strengthens\nRLVR's robustness and scalability, highlighting its potential for real-world\napplications with noisy or weak labels.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T08:22:49Z"}
{"aid":"http://arxiv.org/abs/2503.23832v1","title":"An extrapolated and provably convergent algorithm for nonlinear matrix\n  decomposition with the ReLU function","summary":"Nonlinear matrix decomposition (NMD) with the ReLU function, denoted\nReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ and\na factorization rank $r$, identify a rank-$r$ matrix $\\Theta$ such that\n$X\\approx \\max(0,\\Theta)$. This decomposition finds application in data\ncompression, matrix completion with entries missing not at random, and manifold\nlearning. The standard ReLU-NMD model minimizes the least squares error, that\nis, $\\|X - \\max(0,\\Theta)\\|_F^2$. The corresponding optimization problem is\nnondifferentiable and highly nonconvex. This motivated Saul to propose an\nalternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introduced\nand satisfies $\\max(0,Z)=X$ while minimizing $\\|Z - \\Theta\\|_F^2$ (``A\nnonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\nMath. Data Sci., 2022). Our first contribution is to show that the two\nformulations may yield different low-rank solutions $\\Theta$; in particular, we\nshow that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning that\nthere are instances in which the infimum of Latent-ReLU-NMD is not attained\nwhile that of ReLU-NMD is. We also consider another alternative model, called\n3B-ReLU-NMD, which parameterizes $\\Theta=WH$, where $W$ has $r$ columns and $H$\nhas $r$ rows, allowing one to get rid of the rank constraint in\nLatent-ReLU-NMD. Our second contribution is to prove the convergence of a block\ncoordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Our\nthird contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD,\nwhich we prove is also convergent under mild assumptions. We illustrate the\nsignificant acceleration effect of eBCD-NMD compared to BCD-NMD, and also show\nthat eBCD-NMD performs well against the state of the art on synthetic and\nreal-world data sets.","main_category":"cs.LG","categories":"cs.LG,eess.IV,math.OC,stat.ML","published":"2025-03-31T08:27:41Z"}
{"aid":"http://arxiv.org/abs/2503.23856v1","title":"Explodability criteria for the neutrino-driven supernova mechanism","summary":"Massive stars undergoing iron core collapse at the end of their evolution\nterminate their lives either in successful or failed supernovae (SNe). The\nphysics of core collapse supernovae (CCSNe) is complex, and their understanding\nrequires computationally expensive simulations. The sampling of large, densely\nsampled parameter spaces of SN progenitors, as is needed e.g. for population\nsynthesis studies, is thus not feasible. To remedy this situation, we present\ncriteria that allow us to predict the final fates of stars by evaluating\nmultiple explodability proxies derived from the stellar structure at the onset\nof core collapse. These are formulated based on the outcomes of a semi-analytic\nsupernova model, evaluated over a set of ~3,900 heterogeneous stellar\nprogenitors (single stars, binary-stripped and accretor stars). Over these, the\nexplodabiliy criteria achieve an accuracy of >99% agreement with the\nsemi-analytic model. The criteria are tested on 29 state-of-the-art 3D CCSN\nsimulation outcomes from two different groups. Furthermore, we find that all\nexplodability proxies needed for our pre-SN criteria have two distinct peaks\nand intervening valleys as a function of the carbon-oxygen (CO) core mass\n$M_\\mathrm{CO}$, which coincide with failed and successful SNe, respectively.\nThe CO core masses of explodability peaks shift systematically with\nmetallicity, $Z$, and with the timing of hydrogen-rich envelope removal in\nbinary-stripped stars. With these, we identify critical values in\n$M_\\mathrm{CO}$ that define windows over which black holes form by direct\ncollapse. The outcome is a CCSN recipe based on $M_\\mathrm{CO}$ and $Z$,\napplicable for rapid binary population synthesis and other studies. Our\nexplodability formalism is consistent with SN observations that constrain the\nprogenitor $M_\\mathrm{CO}$ and partially addresses the missing red supergiant\nproblem by direct black hole formation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T09:04:10Z"}
{"aid":"http://arxiv.org/abs/2503.23867v1","title":"Experimental Measurement of Non-Hermitian Left Eigenvectors","summary":"The duality of left and right eigenvectors underpins the comprehensive\nunderstanding of many physical phenomena. In Hermitian systems, left and right\neigenvectors are simply Hermitian-conjugate pairs. Non-Hermitian eigenstates in\ncontrast, have left and right eigenvectors that are distinct from each other.\nHowever, despite the tremendous interest in non-Hermitian physics in recent\nyears, the roles of non-Hermitian left eigenvectors (LEVs) are still\ninadequately explored-their physical consequences and observable effects remain\nelusive, so much so that LEVs seem largely like an object of primarily\nmathematical purpose. In this study, we present a method based on the\nnon-Hermitian Green's function for directly retrieving both LEVs and REVs from\nexperimentally measured steady-state responses. We validate the effectiveness\nof this approach in two separate acoustic experiments: one characterizes the\nnon-Hermitian Berry phase, and the other measures extended topological modes.\nOur results not only unambiguously demonstrate observable effects related to\nnon-Hermitian LEVs, but also highlight the under-appreciated role of LEVs in\nnon-Hermitian phenomena.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-03-31T09:17:30Z"}
{"aid":"http://arxiv.org/abs/2503.23868v1","title":"Modelling Gaia photometry signals of dark halos","summary":"We use the framework of microlensing to show that observations of binary\nsystems, such as those made by {\\it Gaia}, combined with follow-up weak lensing\nmeasurements, can provide a means to probe halos of exotic matter, possibly\nclumped around compact objects such as black holes. This could potentially\ncover a broad range of physical scenarios - from dark matter mini-halos to\nblack holes with bosonic configurations around them, known as hair. Assuming\nthat light can freely propagate through the halo of the exotic matter, the\ncompanion star will produce characteristic, sizable lensing signatures due to\nthe deviation from a central gravitational potential. The signature of the\nmultiple images, the magnification and the light-curve could be the smoking gun\nof such structures. We discuss how the precise observations of the {\\it Gaia}\nsurvey offer an opportunity to search for new, yet undiscovered fundamental\nfields interacting gravitationally with baryons.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-03-31T09:17:48Z"}
{"aid":"http://arxiv.org/abs/2503.23870v1","title":"A SAT-centered XAI method for Deep Learning based Video Understanding","summary":"This paper introduces a novel formal SAT-based explanation model for deep\nlearning in video understanding. The proposed method integrates SAT solving\ntechniques with the principles of formal explainable AI to address the\nlimitations of existing XAI techniques in this domain. By encoding deep\nlearning models and video data into a logical framework and formulating\nexplanation queries as satisfiability problems, the method aims to generate\nlogic-based explanations with formal guarantees. The paper details the\nconceptual framework, the process of encoding deep learning models and video\ndata, the formulation of \"Why?\" and \"Why not?\" questions, and a novel\narchitecture integrating a SAT solver with a deep learning video understanding\nmodel. While challenges related to computational complexity and the\nrepresentational power of propositional logic remain, the proposed approach\noffers a promising direction for enhancing the explainability of deep learning\nin the complex and critical domain of video understanding.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T09:20:06Z"}
{"aid":"http://arxiv.org/abs/2503.23879v1","title":"Network topology effects on the social circle polls","summary":"Election polls play a critical role in political discussions by probing\npublic opinion and enabling political parties to assess their performance\nbefore elections. However, traditional polling methods sometimes fail to\npredict election outcomes accurately, leading researchers to explore new\nmethodologies. One such approach is the \"social circle\" question, which asks\nrespondents about the voting preferences of their social contacts. This method\nleverages collective intelligence and has shown promise in improving predictive\naccuracy. Nevertheless, the influence of the social network's topology on the\neffectiveness of social circle polls remains unexplored. In this study, we\ndevelop a theoretical framework to analyse how social network structure affects\npolling accuracy. By simulating voter networks with varying levels of\npolarisation and connectivity, we assess the performance of both standard and\nsocial circle polling methods. Our findings indicate that while social circle\npolls generally outperform traditional approaches, certain network\ncharacteristics can introduce biases and undermine their performances,\nparticularly in polarised situations, which are increasingly frequent in the\ncurrent political landscape. To address these challenges, we propose a new\nestimator that combines information from both standard and social circle polls,\nimproving election outcome predictions. We demonstrate the applicability of our\nmethod using real-world polling data from the 2016 U.S. presidential election,\nshowcasing its practical utility and providing an estimate of the polarisation\nlevel in that society. This work establishes a foundation for enhancing polling\nmethodologies by assessing and integrating network features, which has\nsignificant implications for social and political research.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-03-31T09:28:09Z"}
{"aid":"http://arxiv.org/abs/2503.23880v1","title":"Can a ferroelectric diode be a selector-less, universal, non-volatile\n  memory?","summary":"Recent advances in silicon foundry-process compatible ferroelectric (FE) thin\nfilms have reinvigorated interest in FE-based non-volatile memory (NVM)\ndevices. Ferroelectric diodes (FeDs) are two-terminal NVM devices exhibiting\nrectifying current-voltage hysteretic characteristics that enable\nself-selecting designs critical for high-density memory. We examine progress in\nFeDs based on CMOS-compatible HZO, AlScN, and emerging van der Waals\nferroelectrics. While FeDs demonstrate promising ON/OFF ratios and\nrectification capabilities, they face persistent challenges including limited\nwrite-cycling endurance, elevated operating voltages, and insufficient read\ncurrents. We provide materials-focused strategies to enhance reliability and\nperformance of FeDs for energy-efficient electronic memory applications, with\nemphasis on their unique self-rectifying capabilities that eliminate the need\nfor selector elements in crossbar arrays for compute in memory applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:29:57Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23889v1","title":"Robust Predictive Routing for Internet of Vehicles Leveraging Both V2I\n  and V2V Links","summary":"With the developments of the Internet of Vehicles (IoV) from 4G to 5G,\nvehicle-to-infrastructure (V2I) communications are becoming attractive for\nvehicle users (VUEs) to obtain diverse cloud service through base stations\n(BSs). To tackle V2I link deterioration caused by blockage and out-of-coverage\ncases, multi-hop V2X routing with both vehicle-to-vehicle (V2V) and V2I links\nneeds to be investigated. However, traditional routing reacts to statistical or\nreal-time information, which may suffer link degradation during path switchover\nin fast-changing vehicular networks. Predictive routing protocols take timely\nactions by forecasting link connectivity, but they fail to satisfy specific QoS\nrequirements. Low robustness to link failures is also incurred without\nconsidering imperfect prediction. To build continual paths between VUEs and BSs\nfor QoS provision of cloud service, a robust predictive routing framework\n(ROPE) is proposed with three major components: 1) an early warning scheme\ndetects V2I link deterioration in advance via predicting vehicle mobility and\nlink signal strength to facilitate seamless path switchover; 2) a virtual\nrouting mechanism finds top3 paths that have the highest path strength and\nsatisfy the connectivity and hop count constraints based on the prediction\nresults to fulfill QoS requirements of cloud service; 3) a path verification\nprotocol checks availability and quality of the top3 paths shortly before\nswitchover and activates one qualified path for switchover to ensure routing\nrobustness. We implement ROPE in a simulation framework incorporating\nreal-world urban maps, microscopic traffic generation, geometry-based channel\nmodeling, and offline data analysis as well as online inference. Extensive\nsimulations demonstrate the superiority of ROPE over direct V2I communications\nand a connectivity-based predictive routing protocol under various scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T09:41:16Z"}
{"aid":"http://arxiv.org/abs/2503.23892v1","title":"Surveying Uncertainty Representation: A Unified Model for Cyber-Physical\n  Systems","summary":"Cyber-Physical Systems (CPS) operate in dynamic environments, leading to\ndifferent types of uncertainty. This work provides a comprehensive review of\nuncertainty representations and categorizes them based on the dimensions used\nto represent uncertainty. Through this categorization, key gaps and limitations\nin existing approaches are identified. To address these issues, a Conceptual\nModel of Uncertainty Representations in CPS is introduced, integrating and\nextending existing models. Its applicability is demonstrated through examples\nfrom the automotive domain, showing its effectiveness in capturing and\nstructuring uncertainty in real-world scenarios.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:42:51Z"}
{"aid":"http://arxiv.org/abs/2503.23901v1","title":"Existence of periodic solution of a non-autonomous allelopathic\n  phytoplankton model with fear effect","summary":"In this paper, we consider a non-autonomous allelopathic phytoplankton\ncompetition ODE model, incorporating the influence of fear effects observed in\nnatural biological phenomena. Based on Mawhin's coincidence degree theory some\nsufficient conditions for existence of periodic solutions are obtained. We\nvalidate our findings through an illustrative example and numerical\nsimulations, showing that constant coefficients lead to steady-state dynamics,\nwhile periodic variations induce oscillatory behavior.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T09:50:32Z"}
{"aid":"http://arxiv.org/abs/2503.23902v1","title":"First-Principle Investigation On Chromium Decorated Graphene-based\n  Systems for Hydrogen Storage","summary":"Sorbent materials like Cr decorated 2D materials are explored among its\nstorage options. 2D material like graphene has been used as it has a high\nsurface to volume ratio. A comparative study is done with Cr adsorbed in\ndefect-free and single vacancy defect graphene systems. Ab-initio calculations\nare performed with and without Van der Waals interaction to check the hydrogen\nstorage efficiency. Efficiency is determined by calculating the binding energy\nof the system. The preferred range for binding energy for reversible hydrogen\nstorage, as determined by the Department of Energy, US, is between 0.2-0.6 eV.\nThis work also visualizes the thermal stability spectrum of the efficient\nmaterials at 300 K using molecular dynamics calculations, predicting their\nstability at room temperature.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:51:56Z"}
{"aid":"http://arxiv.org/abs/2503.23907v1","title":"HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human\n  Image Aesthetic Assessment","summary":"Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:58:11Z"}
{"aid":"http://arxiv.org/abs/2503.23910v1","title":"Droplet breakup morphologies and the resultant size distribution in an\n  opposed-flow airstream at different Weber numbers","summary":"The present study investigates the morphology and breakup dynamics of a\nfreely falling drop in a vertical airstream using shadowgraphy and in-line\nholography. The in-line holography provides the temporal evolution of the\nvolumetric size distribution of child droplets formed during various\nfragmentation processes at different Weber numbers (We). The droplet undergoes\ndifferent fragmentation processes at significantly lower Weber numbers in\nopposed-flow configurations compared to cross-flow configurations. Our findings\nreveal distinct fragmentation modes, namely bag, bag-stamen, and dual-bag\nbreakup, observed at We=9.38, 16.9, and 18.9, respectively. At We = 9.38, the\ncombined effects of bag rupture, rim breakup, and node fragmentation generate\nchild droplets of varying sizes, driven by the interplay of the\nRayleigh-Plateau and Rayleigh-Taylor instabilities. At We = 16.9, the\ninteraction of aerodynamic and shear forces leads to bag-stamen fragmentation,\ncharacterized by forming a stamen-like structure along with the bag. Both bag\nand bag-stamen breakups result in tri-modal size distributions. However, at We\n= 16.9, fewer tiny droplets are produced compared to the bag breakup observed\nat lower Weber numbers. In contrast, at We = 18.9, a dual-bag breakup occurs,\nwhere both bags inflate and burst simultaneously. This process generates tiny\nchild droplets in the early stages, while larger child droplets form later due\nto the fragmentation of the rim and nodes, resulting in a bi-modal size\ndistribution. We have performed a theoretical analysis using a two-parameter\ngamma distribution, which satisfactorily predicts the size distributions\nobserved experimentally at different Weber numbers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T10:02:22Z"}
{"aid":"http://arxiv.org/abs/2503.23911v1","title":"FineCausal: A Causal-Based Framework for Interpretable Fine-Grained\n  Action Quality Assessment","summary":"Action quality assessment (AQA) is critical for evaluating athletic\nperformance, informing training strategies, and ensuring safety in competitive\nsports. However, existing deep learning approaches often operate as black boxes\nand are vulnerable to spurious correlations, limiting both their reliability\nand interpretability. In this paper, we introduce FineCausal, a novel\ncausal-based framework that achieves state-of-the-art performance on the\nFineDiving-HM dataset. Our approach leverages a Graph Attention Network-based\ncausal intervention module to disentangle human-centric foreground cues from\nbackground confounders, and incorporates a temporal causal attention module to\ncapture fine-grained temporal dependencies across action stages. This\ndual-module strategy enables FineCausal to generate detailed spatio-temporal\nrepresentations that not only achieve state-of-the-art scoring performance but\nalso provide transparent, interpretable feedback on which features drive the\nassessment. Despite its strong performance, FineCausal requires extensive\nexpert knowledge to define causal structures and depends on high-quality\nannotations, challenges that we discuss and address as future research\ndirections. Code is available at https://github.com/Harrison21/FineCausal.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:02:29Z"}
{"aid":"http://arxiv.org/abs/2503.23912v1","title":"Certified Approximate Reachability (CARe): Formal Error Bounds on Deep\n  Learning of Reachable Sets","summary":"Recent approaches to leveraging deep learning for computing reachable sets of\ncontinuous-time dynamical systems have gained popularity over traditional\nlevel-set methods, as they overcome the curse of dimensionality. However, as\nwith level-set methods, considerable care needs to be taken in limiting\napproximation errors, particularly since no guarantees are provided during\ntraining on the accuracy of the learned reachable set. To address this\nlimitation, we introduce an epsilon-approximate Hamilton-Jacobi Partial\nDifferential Equation (HJ-PDE), which establishes a relationship between\ntraining loss and accuracy of the true reachable set. To formally certify this\napproximation, we leverage Satisfiability Modulo Theories (SMT) solvers to\nbound the residual error of the HJ-based loss function across the domain of\ninterest. Leveraging Counter Example Guided Inductive Synthesis (CEGIS), we\nclose the loop around learning and verification, by fine-tuning the neural\nnetwork on counterexamples found by the SMT solver, thus improving the accuracy\nof the learned reachable set. To the best of our knowledge, Certified\nApproximate Reachability (CARe) is the first approach to provide soundness\nguarantees on learned reachable sets of continuous dynamical systems.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,math.OC","published":"2025-03-31T10:02:57Z"}
{"aid":"http://arxiv.org/abs/2503.23913v1","title":"Entropy-Based Adaptive Weighting for Self-Training","summary":"The mathematical problem-solving capabilities of large language models have\nbecome a focal point of research, with growing interests in leveraging\nself-generated reasoning paths as a promising way to refine and enhance these\nmodels. These paths capture step-by-step logical processes while requiring only\nthe correct answer for supervision. The self-training method has been shown to\nbe effective in reasoning tasks while eliminating the need for external models\nand manual annotations. However, optimizing the use of self-generated data for\nmodel training remains an open challenge. In this work, we propose\nEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive\nweighting strategy designed to prioritize uncertain data during self-training.\nSpecifically, EAST employs a mapping function with a tunable parameter that\ncontrols the sharpness of the weighting, assigning higher weights to data where\nthe model exhibits greater uncertainty. This approach guides the model to focus\non more informative and challenging examples, thereby enhancing its reasoning\nability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical\nresults show that, while the vanilla method yields virtually no improvement\n(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,\nEAST attains a further 1-2% performance boost compared to the vanilla method.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T10:04:35Z"}
{"aid":"http://arxiv.org/abs/2503.23914v1","title":"Scenarios for the Deployment of Automated Vehicles in Europe","summary":"The deployment of Automated Vehicles (AVs) is expected to address road\ntransport externalities (e.g., safety, traffic, environmental impact, etc.).\nFor this reason, a legal framework for their large-scale market introduction\nand deployment is currently being developed in the European Union. Despite the\nfirst steps towards road transport automation, the timeline for full automation\nand its potential economic benefits remains uncertain. The aim of this paper is\ntwofold. First, it presents a methodological framework to determine deployment\npathways of the five different levels of automation in EU27+UK to 2050 under\nthree scenarios (i.e., slow, medium baseline and fast) focusing on passenger\nvehicles. Second, it proposes an assessment of the economic impact of AVs\nthrough the calculation of the value-added. The method to define assumptions\nand uptake trajectories involves a comprehensive literature review, expert\ninterviews, and a model to forecast the new registrations of different levels\nof automation. In this way, the interviews provided insights that complemented\nthe literature and informed the design of assumptions and deployment\ntrajectories. The added-value assessment shows additional economic activity due\nto the introduction of automated technologies in all uptake scenarios.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T10:06:27Z"}
{"aid":"http://arxiv.org/abs/2503.23926v1","title":"Reliable Traffic Monitoring Using Low-Cost Doppler Radar Units","summary":"Road traffic monitoring typically involves the counting and recording of\nvehicles on public roads over extended periods. The data gathered from such\nmonitoring provides useful information to municipal authorities in urban areas.\nThis paper presents a low-cost, widely deployable sensing subsystem based on\nContinuous Wave Doppler radar. The proposed system can perform vehicle\ndetection and speed estimation with a total cost of less than 100 USD. The\nsensing system (including the hardware subsystem and the algorithms) is\ndesigned to be placed on the side of the road, allowing for easy deployment and\nserviceability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T10:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.23927v1","title":"Detecting Localized Density Anomalies in Multivariate Data via Coin-Flip\n  Statistics","summary":"Detecting localized density differences in multivariate data is a crucial\ntask in computational science. Such anomalies can indicate a critical system\nfailure, lead to a groundbreaking scientific discovery, or reveal unexpected\nchanges in data distribution. We introduce EagleEye, an anomaly detection\nmethod to compare two multivariate datasets with the aim of identifying local\ndensity anomalies, namely over- or under-densities affecting only localised\nregions of the feature space. Anomalies are detected by modelling, for each\npoint, the ordered sequence of its neighbours' membership label as a\ncoin-flipping process and monitoring deviations from the expected behaviour of\nsuch process. A unique advantage of our method is its ability to provide an\naccurate, entirely unsupervised estimate of the local signal purity. We\ndemonstrate its effectiveness through experiments on both synthetic and\nreal-world datasets. In synthetic data, EagleEye accurately detects anomalies\nin multiple dimensions even when they affect a tiny fraction of the data. When\napplied to a challenging resonant anomaly detection benchmark task in simulated\nLarge Hadron Collider data, EagleEye successfully identifies particle decay\nevents present in just 0.3% of the dataset. In global temperature data,\nEagleEye uncovers previously unidentified, geographically localised changes in\ntemperature fields that occurred in the most recent years. Thanks to its key\nadvantages of conceptual simplicity, computational efficiency, trivial\nparallelisation, and scalability, EagleEye is widely applicable across many\nfields.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T10:20:04Z"}
{"aid":"http://arxiv.org/abs/2503.23941v1","title":"Choco-Q: Commute Hamiltonian-based QAOA for Constrained Binary\n  Optimization","summary":"Constrained binary optimization aims to find an optimal assignment to\nminimize or maximize the objective meanwhile satisfying the constraints, which\nis a representative NP problem in various domains, including transportation,\nscheduling, and economy. Quantum approximate optimization algorithms (QAOA)\nprovide a promising methodology for solving this problem by exploiting the\nparallelism of quantum entanglement. However, existing QAOA approaches based on\npenalty-term or Hamiltonian simulation fail to thoroughly encode the\nconstraints, leading to extremely low success rate and long searching latency.\n  This paper proposes Choco-Q, a formal and universal framework for constrained\nbinary optimization problems, which comprehensively covers all constraints and\nexhibits high deployability for current quantum devices. The main innovation of\nChoco-Q is to embed the commute Hamiltonian as the driver Hamiltonian,\nresulting in a much more general encoding formulation that can deal with\narbitrary linear constraints. Leveraging the arithmetic features of commute\nHamiltonian, we propose three optimization techniques to squeeze the overall\ncircuit complexity, including Hamiltonian serialization, equivalent\ndecomposition, and variable elimination. The serialization mechanism transforms\nthe original Hamiltonian into smaller ones. Our decomposition methods only take\nlinear time complexity, achieving end-to-end acceleration. Experiments\ndemonstrate that Choco-Q shows more than 235$\\times$ algorithmic improvement in\nsuccessfully finding the optimal solution, and achieves 4.69$\\times$ end-to-end\nacceleration, compared to prior QAOA designs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:47:20Z"}
{"aid":"http://arxiv.org/abs/2503.23948v1","title":"AI2Agent: An End-to-End Framework for Deploying AI Projects as\n  Autonomous Agents","summary":"As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:58:34Z"}
{"aid":"http://arxiv.org/abs/2503.23950v1","title":"Plasmons in N-layer systems","summary":"In multilayer structures, the coupling between layers gives rise to unique\nplasmon modes, but analytic solutions are typically available only for bilayers\ndue to the increasing complexity as the number of layers increases. We\ninvestigate plasmons in multilayer structures, including the effects of\ninterlayer tunneling. By introducing the Coulomb eigenvector basis for\nmultilayer systems, which can be solved exactly using Kac-Murdock-Szeg\\H{o}\nToeplitz matrices, we analytically derive the long-wavelength plasmon\ndispersions both with and without interlayer tunneling. In the $N$-layer\nsystems, we find that, in the absence of interlayer tunneling, the out-of-phase\nacoustic or charge neutral plasmon modes with linear dispersions\n($\\omega_\\alpha\\propto q/\\sqrt{{1-\\cos{\\left(\\frac{\\alpha-1}{N}\\pi\\right)}}}$\nfor $\\alpha = 2, 3, \\cdots, N$) exist, while the in-phase classical plasmon\nmode exhibits its conventional dispersion ($\\omega_1\\propto \\sqrt{q}$). When\ninterlayer tunneling is present, the out-of-phase modes develop plasmon gaps\nthat are governed by specific interband transitions, whereas the classical mode\nremains unaffected. These findings have broad applicability to general\ncoupled-layer structures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T11:02:44Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23962v1","title":"On the kernel of the Stieltjes derivative and the space of bounded\n  Stieltjes-differentiable functions","summary":"We investigate the existence and uniqueness of solutions to first-order\nStieltjes differential problems, focusing on the role of the Stieltjes\nderivative and its kernel. Unlike the classical case, the kernel of the\nStieltjes derivative operator is nontrivial, leading to non-uniqueness issues\nin Cauchy problems. We characterize this kernel by providing necessary and\nsufficient conditions for a function to have a zero Stieltjes derivative. To\naddress the implications of this nontrivial kernel, we introduce a function\nspace which serves as a suitable framework for studying Stieltjes differential\nproblems. We explore its topological structure and propose a metric that\nfacilitates the formulation of existence and uniqueness results. Our findings\ndemonstrate that solutions to first-order Stieltjes differential equations are,\nin general, not unique, underscoring the need for a refined analytical approach\nto such problems.","main_category":"math.CA","categories":"math.CA","published":"2025-03-31T11:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.23969v1","title":"Electronic structure of UGe$_2$ at ambient pressure: comparison with\n  X-ray photoemission spectra","summary":"Based on experimental crystallographic data, electronic structure of UGe$_2$\nhave been calculated and compared with our results of X-ray photoelectron\nspectroscopy (XPS) measurements. We employed two different advanced full\npotential (FP) methods: FP-local-orbital (FPLO) and FP-linear augmented plane\nwaves (Wien2k) codes for non-magnetic and ferromagnetic states. Starting from\nthe local spin-density approximation (LSDA) or generalised gradient\napproximation (GGA), we verified either the orbital polarisation (OP)\ncorrection or the GGA+U approach for the U 5f-electrons, changing\nCoulomb-repulsion energies U in the range 0-4 eV. Satisfying agreement was\nachieved between experimental and our calculated magnetic moments using\nab-initio LSDA+OP and non-ab-initio GGA+U approaches, the latter for realistic\nU values of 2-3 eV. We proved by the LSDA+OP approach an existence of the Fermi\nsurface nesting vector along the a axis, possibly responsible for the triplet\nsuperconducting pairing. The calculated data reveal predominantly an itinerant\nU 5f-electron character of bands near the Fermi level, EF, with only small\ncontributions from the U 6d and Ge 4p states. The experimental XPS spectrum of\nvalence bands (VB) also contains the sharp main 5f-electron peak at EF, a wide\nhump (around -2 eV), and broad small peaks at higher energies. In the\ncalculated XPS spectrum, the width of the main 5f-electron peak varies between\n0.8 and 1.4 eV, depending on a method used in computations, but the hump\nremains unresolved. A newly observed asymmetric 1-eV satellite in the\nexperimental 4f-core XPS spectrum together with known 3-eV and 7-eV satellites\nsuggest dual behaviour of U-5f-electrons in UGe$_2$, the feature is inferred\nalso from the VB studies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el,physics.comp-ph","published":"2025-03-31T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2503.23970v1","title":"A predator-prey model with Allee effect for a type of predator","summary":"This paper investigates the dynamical behaviors of a Holling type I\nLeslie-Gower predator-prey model where the predator exhibits an Allee effect\nand is subjected to constant harvesting. The model demonstrates three types of\nequilibrium points under different parameter conditions, which could be either\nstable or unstable nodes (foci), saddle nodes, weak centers, or cusps. The\nsystem exhibits a saddle-node bifurcation near the saddle-node point and a Hopf\nbifurcation near the weak center. By calculating the first Lyapunov\ncoefficient, the conditions for the occurrence of both supercritical and\nsubcritical Hopf bifurcations are derived. Finally, it is proven that when the\npredator growth rate and the prey capture coefficient vary within a specific\nsmall neighborhood, the system undergoes a codimension-2 Bogdanov-Takens\nbifurcation near the cusp point.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T11:34:48Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.23987v1","title":"Revisiting cyclic elements in growth spaces","summary":"We revisit the problem of characterizing cyclic elements for the shift\noperator in a broad class of radial growth spaces of holomorphic functions on\nthe unit disk, focusing on functions of finite Nevanlinna characteristic. We\nprovide results in the range of Dini regular weights, and in the regime of\nlogarithmic integral divergence. Our proofs are largely constructive, enabling\nus to simplify and extend a classical result by Korenblum and Roberts, and a\nrecent Theorem due to El-Fallah, Kellay, and Seip.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-03-31T11:56:27Z"}
{"aid":"http://arxiv.org/abs/2503.23988v1","title":"Deep Learning Model Deployment in Multiple Cloud Providers: an\n  Exploratory Study Using Low Computing Power Environments","summary":"The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.PF","published":"2025-03-31T11:58:37Z"}
{"aid":"http://arxiv.org/abs/2503.23999v1","title":"Foreign Direct Investment and Job Creation in EU Regions","summary":"This study examines the impact of foreign direct investment (FDI) on job\ncreation across 109 regions in the old EU member states from 2012 to 2023.\nUsing dynamic and spatial econometric models combined with a unique dataset of\nFDI projects, we find that increased FDI inflows significantly enhance regional\njob creation, but the relationship is nonlinear. Sectoral specialization plays\na crucial role, as more concentrated FDI inflows lead to higher employment\ngrowth. Furthermore, FDI-driven job creation exhibits significant spatial\nspillover effects. However, regions attracting high-value FDI jobs, such as\nthose in R&D and management, tend to experience slower overall employment\ngrowth.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T12:21:51Z"}
{"aid":"http://arxiv.org/abs/2503.24005v1","title":"Attraction of a jerk","summary":"Jerk plays a pivotal role in the thrilling experience of many amusemement\npark rides. In addition to exploring the physical aspect of jerks, we tackle\nthe empirical observation of an attractive force between passengers in the\npopular attraction, the spinning teacups. By modeling the complex system of\nrotating platforms, we show that pseudotorques induced by changing acceleration\nlead to jerky movements and an attractive interaction among riders. Our\nnumerical analysis confirms the empirical observations, highlighting the\nconnection between attraction and jerks.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.pop-ph","published":"2025-03-31T12:30:57Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24017v1","title":"Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings\n  for Robust Image Classification","summary":"Crossmodal knowledge distillation (KD) aims to enhance a unimodal student\nusing a multimodal teacher model. In particular, when the teacher's modalities\ninclude the student's, additional complementary information can be exploited to\nimprove knowledge transfer. In supervised image classification, image datasets\ntypically include class labels that represent high-level concepts, suggesting a\nnatural avenue to incorporate textual cues for crossmodal KD. However, these\nlabels rarely capture the deeper semantic structures in real-world visuals and\ncan lead to label leakage if used directly as inputs, ultimately limiting KD\nperformance. To address these issues, we propose a multi-teacher crossmodal KD\nframework that integrates CLIP image embeddings with learnable WordNet-relaxed\ntext embeddings under a hierarchical loss. By avoiding direct use of exact\nclass names and instead using semantically richer WordNet expansions, we\nmitigate label leakage and introduce more diverse textual cues. Experiments\nshow that this strategy significantly boosts student performance, whereas noisy\nor overly precise text embeddings hinder distillation efficiency.\nInterpretability analyses confirm that WordNet-relaxed prompts encourage\nheavier reliance on visual features over textual shortcuts, while still\neffectively incorporating the newly introduced textual cues. Our method\nachieves state-of-the-art or second-best results on six public datasets,\ndemonstrating its effectiveness in advancing crossmodal KD.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T12:41:26Z"}
{"aid":"http://arxiv.org/abs/2503.24022v1","title":"Wasserstein KL-divergence for Gaussian distributions","summary":"We introduce a new version of the KL-divergence for Gaussian distributions\nwhich is based on Wasserstein geometry and referred to as WKL-divergence. We\nshow that this version is consistent with the geometry of the sample space\n${\\Bbb R}^n$. In particular, we can evaluate the WKL-divergence of the Dirac\nmeasures concentrated in two points which turns out to be proportional to the\nsquared distance between these points.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-03-31T12:49:01Z"}
{"aid":"http://arxiv.org/abs/2503.24024v1","title":"Degrees in the $β$- and $β'$-Delaunay graphs","summary":"We investigate the typical cells $\\widehat{Z}$ and $\\widehat{Z}^\\prime$ of\n$\\beta$- and $\\beta'$-Voronoi tessellations in $\\mathbb{R}^d$, establishing a\nComplementary Theorem which entails: 1) a gamma distribution of the\n$\\Phi$-content (a suitable homogeneous functional) of the typical cell with\n$n$-facets; 2) the independence of this $\\Phi$-content with the shape of the\ncell; 3) a practical integral representation of the distribution of\n$Z^{(\\prime)}$. We exploit the latter to derive bounds on the distribution of\nthe facet numbers. Using duality, we get bounds on the typical degree\ndistributions of $\\beta$- and $\\beta'$-Delaunay triangulations. For\n$\\beta'$-Delaunay, the resulting exponential lower bound seems to be the first\nof its kind for random spatial graphs arising as the skeletons of random\ntessellations. For $\\beta$-Delaunay, matching super-exponential bounds allow us\nto show concentration of the maximal degree in a growing window to only a\nfinite number of deterministic values (in particular, only two values for\n$d=2$).","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T12:50:40Z"}
{"aid":"http://arxiv.org/abs/2503.24030v1","title":"Jacquetium, a new, naturally-occurring chemical element","summary":"I report the discovery of jacquetium ($_0$Jq), the first naturally occurring\nelement found since more than 80 years.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.EP","published":"2025-03-31T12:57:10Z"}
{"aid":"http://arxiv.org/abs/2503.24031v1","title":"An ANN-Enhanced Approach for Flatness-Based Constrained Control of\n  Nonlinear Systems","summary":"Neural networks have proven practical for a synergistic combination of\nadvanced control techniques. This work analyzes the implementation of rectified\nlinear unit neural networks to achieve constrained control in differentially\nflat systems. Specifically, the class of flat systems enjoys the benefit of\nfeedback linearizability, i.e., the systems can be linearized by means of a\nproper variable transformation. However, the price for linearizing the dynamics\nis that the constraint descriptions are distorted geometrically. Our results\nshow that, by using neural networks, these constraints can be represented as a\nunion of polytopes, enabling the use of mixed-integer programming tools to\nguarantee constraint satisfaction. We further analyze the integration of the\ncharacterization into efficient settings such as control Lyapunov\nfunction-based and model predictive control (MPC). Interestingly, this\ndescription also allows us to explicitly compute the solution of the MPC\nproblem for the nonlinear system. Several examples are provided to illustrate\nthe effectiveness of our framework.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-03-31T12:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.24036v1","title":"Automated Discovery of Tactic Libraries for Interactive Theorem Proving","summary":"Enabling more concise and modular proofs is essential for advancing formal\nreasoning using interactive theorem provers (ITPs). Since many ITPs, such as\nRocq and Lean, use tactic-style proofs, learning higher-level custom tactics is\ncrucial for proof modularity and automation. This paper presents a novel\napproach to tactic discovery, which leverages Tactic Dependence Graphs (TDGs)\nto identify reusable proof strategies across multiple proofs. TDGs capture\nlogical dependencies between tactic applications while abstracting away\nirrelevant syntactic details, allowing for both the discovery of new tactics\nand the refactoring of existing proofs into more modular forms. We have\nimplemented this technique in a tool called TacMiner and compare it against an\nanti-unification-based approach Peano to tactic discovery. Our evaluation\ndemonstrates that TacMiner can learn 3x as many tactics as Peano and reduces\nthe size of proofs by 26% across all benchmarks. Furthermore, our evaluation\ndemonstrates the benefits of learning custom tactics for proof automation,\nallowing a state-of-the-art proof automation tool to achieve a relative\nincrease of 172% in terms of success rate.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T13:00:29Z"}
{"aid":"http://arxiv.org/abs/2503.24040v1","title":"Adventures in FRET and Specification","summary":"This paper gives an overview of previous work in which the authors used\nNASA's Formal Requirement Elicitation Tool (FRET) to formalise requirements. We\ndiscuss four case studies where we used FRET to capture the system's\nrequirements. These formalised requirements subsequently guided the case study\nspecifications in a combination of formal paradigms. For each case study we\nsummarise insights gained during this process, exploring the expressiveness and\nthe potential interoperability of these approaches. Our experience confirms\nFRET's suitability as a framework for the elicitation and understanding of\nrequirements and for providing traceability from requirements to specification.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:03:34Z"}
{"aid":"http://arxiv.org/abs/2503.24050v1","title":"A Deep Learning Framework for the Electronic Structure of Water: Towards\n  a Universal Model","summary":"Accurately modeling the electronic structure of water across scales, from\nindividual molecules to bulk liquid, remains a grand challenge. Traditional\ncomputational methods face a critical trade-off between computational cost and\nefficiency.We present an enhanced machine-learning Deep Kohn-Sham (DeePKS)\nmethod for improved electronic structure, DeePKS-ES, that overcomes this\ndilemma. By incorporating the Hamiltonian matrix and their eigenvalues and\neigenvectors into the loss function, we establish a universal model for water\nsystems, which can reproduce high-level hybrid functional (HSE06) electronic\nproperties from inexpensive generalized gradient approximation (PBE)\ncalculations. Validated across molecular clusters and liquid-phase simulations,\nour approach reliably predicts key electronic structure properties such as band\ngaps and density of states, as well as total energy and atomic forces. This\nwork bridges quantum-mechanical precision with scalable computation, offering\ntransformative opportunities for modeling aqueous systems in catalysis, climate\nscience, and energy storage.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atm-clus,physics.comp-ph","published":"2025-03-31T13:13:47Z"}
{"aid":"http://arxiv.org/abs/2503.24052v1","title":"Accelerated Airfoil Design Using Neural Network Approaches","summary":"In this paper, prediction of airfoil shape from targeted pressure\ndistribution (suction and pressure sides) and vice versa is demonstrated using\nboth Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs)\ntechniques. The dataset is generated for 1600 airfoil shapes, with simulations\ncarried out at Reynolds numbers (Re) ranging from 10,000 and 90,00,000 and\nangles of attack (AoA) ranging from 0 to 15 degrees, ensuring the dataset\ncaptured diverse aerodynamic conditions. Five different CNN and DNN models are\ndeveloped depending on the input/output parameters. Results demonstrate that\nthe refined models exhibit improved efficiency, with the DNN model achieving a\nmulti-fold reduction in training time compared to the CNN model for complex\ndatasets consisting of varying airfoil, Re, and AoA. The predicted airfoil\nshapes/pressure distribution closely match the targeted values, validating the\neffectiveness of deep learning frameworks. However, the performance of CNN\nmodels is found to be better compared to DNN models. Lastly, a flying wing\naircraft model of wingspan >10 m is considered for the prediction of pressure\ndistribution along the chordwise. The proposed CNN and DNN models show\npromising results. This research underscores the potential of deep learning\nmodels accelerating aerodynamic optimization and advancing the design of\nhigh-performance airfoils.","main_category":"cs.LG","categories":"cs.LG,math-ph,math.MP,physics.app-ph,physics.flu-dyn,physics.space-ph","published":"2025-03-31T13:14:14Z"}
{"aid":"http://arxiv.org/abs/2503.24053v1","title":"ReaLM: Reliable and Efficient Large Language Model Inference with\n  Statistical Algorithm-Based Fault Tolerance","summary":"The demand for efficient large language model (LLM) inference has propelled\nthe development of dedicated accelerators. As accelerators are vulnerable to\nhardware faults due to aging, variation, etc, existing accelerator designs\noften reserve a large voltage margin or leverage algorithm-based fault\ntolerance (ABFT) techniques to ensure LLM inference correctness. However,\nprevious methods often overlook the inherent fault tolerance of LLMs, leading\nto high computation and energy overhead. To enable reliable yet efficient LLM\ninference, in this paper, we propose a novel algorithm/circuit co-design\nframework, dubbed ReaLM. For the first time, we systematically characterize the\nfault tolerance of LLMs by performing a large-scale error injection study of\nrepresentative LLMs and natural language understanding tasks. Then, we propose\na statistical ABFT algorithm that fully leverages the error robustness to\nminimize error recovery as much as possible. We also customize the error\ndetection circuits to enable a low-cost online collection of error statistics.\nExtensive experiments show that with only 1.42% circuit area and 1.79% power\noverhead, our ReaLM can reduce perplexity degradation from 18.54 to 0.29.\nCompared to existing methods, ReaLM consistently reduces recovery costs across\ndifferent operating voltages and improves energy efficiency by up to 35.83%\nwithout compromising LLM performance. Our error injection code is available at\nhttps://github.com/2000012835xt/ReaLM-DAC.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T13:15:03Z"}
{"aid":"http://arxiv.org/abs/2503.24059v1","title":"Robust Magnetic Polaron Percolation in the Antiferromagnetic CMR System\n  EuCd$_2$P$_2$","summary":"Antiferromagnetic EuCd$_2$P$_2$ has attracted considerable attention due to\nits unconventional (magneto)transport properties. At a temperature $T_{\\rm\npeak}$ significantly above the magnetic ordering temperature $T_\\textrm{N} =\n11\\,$K a large peak in resistivity is observed which gets strongly suppressed\nin magnetic field, resulting in a colossal magnetoresistance (CMR), for which\nmagnetic fluctuations and the formation of ferromagnetic clusters have been\nproposed as underlying mechanisms. Employing a selection of sensitive probes\nincluding fluctuation spectroscopy and third-harmonic resistance, Hall effect,\nAC susceptibility and $\\mu$SR measurements, allows for a direct comparison of\nelectronic and magnetic properties on multiple time scales. We find compelling\nevidence for the formation and percolation of magnetic polarons, which explains\nthe CMR of the system. Large peaks in the weakly-nonlinear transport and the\nresistance noise power spectral density at zero magnetic field signify an\ninhomogeneous, percolating electronic system below $T^\\ast \\approx\n2\\,T_\\textrm{N}$ with a percolation threshold at $T_{\\rm peak}$. In magnetic\nfields, the onset of large negative MR in the paramagnetic regime occurs at a\nuniversal critical magnetization similar to ferromagnetic CMR materials. The\nsize of the magnetic polarons at the percolation threshold is estimated to\n$\\sim 1 - 2\\,$nm. The mechanism of magntic cluster formation and percolation in\nEuCd$_2$P$_2$ appears to be rather robust despite large variations in carrier\nconcentration and likely is relevant for other Eu-based antiferromagnetic CMR\nsystems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:21:07Z"}
{"aid":"http://arxiv.org/abs/2503.24061v1","title":"Simple general magnification of circuit lower bounds","summary":"We construct so-called distinguishers, sparse matrices that retain some\nproperties of error correcting codes. They provide a technically and\nconceptually simple approach to magnification. We generalize and strengthen\nknown general (not problem specific) magnification results and in particular\nachieve magnification thresholds below known lower bounds. For example, we show\nthat fixed polynomial formula size lower bounds for NP are implied by slightly\nsuperlinear formula size lower bounds for approximating any sufficiently sparse\nproblem in NP. We also show that the thresholds achieved are sharp.\nAdditionally, our approach yields a uniform magnification result for the\nminimum circuit size problem. This seems to sidestep the localization barrier.","main_category":"cs.CC","categories":"cs.CC","published":"2025-03-31T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2503.24067v1","title":"TransMamba: Flexibly Switching between Transformer and Mamba","summary":"Transformers are the cornerstone of modern large language models, but their\nquadratic computational complexity limits efficiency in long-sequence\nprocessing. Recent advancements in Mamba, a state space model (SSM) with linear\ncomplexity, offer promising efficiency gains but suffer from unstable\ncontextual learning and multitask generalization. This paper proposes\nTransMamba, a novel framework that unifies Transformer and Mamba through shared\nparameter matrices (e.g., QKV and CBx), and thus could dynamically switch\nbetween attention and SSM mechanisms at different token lengths and layers. We\ndesign the Memory converter to bridge Transformer and Mamba by converting\nattention outputs into SSM-compatible states, ensuring seamless information\nflow at TransPoints where the transformation happens. The TransPoint scheduling\nis also thoroughly explored for further improvements. We conducted extensive\nexperiments demonstrating that TransMamba achieves superior training efficiency\nand performance compared to baselines, and validated the deeper consistency\nbetween Transformer and Mamba paradigms, offering a scalable solution for\nnext-generation sequence modeling.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2503.24079v1","title":"Joint model for zero-inflated data combining fishery-dependent and\n  fishery-independent sources","summary":"Accurately identifying spatial patterns of species distribution is crucial\nfor scientific insight and societal benefit, aiding our understanding of\nspecies fluctuations. The increasing quantity and quality of ecological\ndatasets present heightened statistical challenges, complicating spatial\nspecies dynamics comprehension. Addressing the complex task of integrating\nmultiple data sources to enhance spatial fish distribution understanding in\nmarine ecology, this study introduces a pioneering five-layer Joint model. The\nmodel adeptly integrates fishery-independent and fishery-dependent data,\naccommodating zero-inflated data and distinct sampling processes. A\ncomprehensive simulation study evaluates the model performance across various\npreferential sampling scenarios and sample sizes, elucidating its advantages\nand challenges. Our findings highlight the model's robustness in estimating\npreferential parameters, emphasizing differentiation between presence-absence\nand biomass observations. Evaluation of estimation of spatial covariance and\nprediction performance underscores the model's reliability. Augmenting sample\nsizes reduces parameter estimation variability, aligning with the principle\nthat increased information enhances certainty. Assessing the contribution of\neach data source reveals successful integration, providing a comprehensive\nrepresentation of biomass patterns. Empirical validation within a real-world\ncontext further solidifies the model's efficacy in capturing species' spatial\ndistribution. This research advances methodologies for integrating diverse\ndatasets with different sampling natures further contributing to a more\ninformed understanding of spatial dynamics of marine species.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T13:33:58Z"}
{"aid":"http://arxiv.org/abs/2503.24082v1","title":"NUMEXO2: a versatile digitizer for nuclear physics","summary":"NUMEXO2 is a 16 channels 14bit/200MHz digitizer and processing board\ninitially developed for gamma-ray spectroscopy (for EXOGAM: EXOtic nuclei GAMma\nray). Numexo2 has been gradually extended and improved as a general purpose\ndigitizer to fulfill various needs in nuclear physics detection at GANIL. This\nwas possible thanks to reprogrammable components like FPGAs and the\noptimization of different algorithms. The originality of this work compared to\nsimilar systems is that all numerical operations follow the digital data flow\nfrom ADCs, without any storage step of samples. Some details are given on\ndigital processing of the signals, delivered by a large variety of detectors:\nHPGe, silicon strip detector, ionisation chamber, liquid and plastic\nscintillators read-out with photomultipliers, Multi Wire Proportional Counter\nand drift chamber.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-03-31T13:35:46Z"}
{"aid":"http://arxiv.org/abs/2503.24084v1","title":"Environmental effects in stellar mass gravitational wave sources I:\n  Expected fraction of signals with significant dephasing in the dynamical and\n  AGN channels","summary":"We present the first overview of the expected quantity of signals which will\nshowcase significant gravitational wave phase shifts caused by astrophysical\nenvironments, considering the upcoming A+ and A\\# LIGO/Virgo/KAGRA, Cosmic\nExplorer and Einstein Telescope detectors. We construct and analyse two general\nfamilies of dephasing prescriptions with extensions to eccentric sources, as\nwell as collect five specific prescriptions for the fundamental smoking gun\nphysical mechanisms at play in the dynamical and AGN formation channel for\nstellar mass binary black holes: Roemer delays, tidal forces and hydrodynamical\ninteractions. We compute the expected fraction of signals containing\nastrophysical dephasing, as a function of environmental properties and based on\nobserved distributions of binary parameters. We find that next generation\ndetectors can expect to find environmental effects in hundreds of detected\nsignals.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.GA,gr-qc","published":"2025-03-31T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2503.24100v1","title":"Fuzzing-based Mutation Testing of C/C++ CPS","summary":"Mutation testing can help minimize the delivery of faulty software.\nTherefore, it is a recommended practice for developing embedded software in\nsafety-critical cyber-physical systems (CPS). However, state-of-the-art\nmutation testing techniques for C and C++ software, which are common languages\nfor CPS, depend on symbolic execution. Unfortunately, symbolic execution's\nlimitations hinder its applicability (e.g., systems with black-box components).\n  We propose relying on fuzz testing, which has demonstrated its effectiveness\nfor C and C++ software. Fuzz testing tools automatically create test inputs\nthat explore program branches in various ways, exercising statements in\ndifferent program states, and thus enabling the detection of mutants, which is\nour objective.\n  We empirically evaluated our approach using software components from\noperational satellite systems. Our assessment shows that our approach can\ndetect between 40% and 90% of the mutants not detected by developers' test\nsuites. Further, we empirically determined that the best results are obtained\nby integrating the Clang compiler, a memory address sanitizer, and relying on\nlaf-intel instrumentation to collect coverage and guide fuzzing. Our approach\ndetects a significantly higher percentage of live mutants compared to symbolic\nexecution, with an increase of up to 50 percentage points; further, we observed\nthat although the combination of fuzzing and symbolic execution leads to\nadditional mutants being killed, the benefits are minimal (a gain of less than\none percentage point).","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:55:27Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24105v1","title":"Data-Driven Distributed Output Synchronization of Heterogeneous\n  Discrete-Time Multi-Agent Systems","summary":"In this paper, we assume that an autonomous exosystem generates a reference\noutput, and we consider the problem of designing a distributed data-driven\ncontrol law for a family of discrete-time heterogeneous LTI agents, connected\nthrough a directed graph, in order to synchronize the agents' outputs to the\nreference one. The agents of the network are split into two categories:\nleaders, with direct access to the exosystem output, and followers, that only\nreceive information from their neighbors. All agents aim to achieve output\nsynchronization by means of a state feedback that makes use of their own states\nas well as of an estimate of the exogenous system state, provided by an\ninternal state observer. Such observer has a different structure for leaders\nand followers. Necessary and sufficient conditions for the existence of a\nsolution are first derived in the model-based set-up and then in a data-driven\ncontext. An example illustrates both the implementation procedure and the\nperformance of the proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2503.24106v1","title":"Computing and software for LHCb Upgrade II","summary":"A second major upgrade of the LHCb experiment is necessary to allow full\nexploitation of the High Luminosity LHC for flavour physics. The new experiment\nwill operate in Run 5 of the LHC at a luminosity up to $1.5\\times\n10^{34}cm^{-2}s^{-1}$. The experiment will therefore experience extremely high\nparticle fluences and data rates, posing a high challenge not only for the\ndetector but also for the software and computing resources needed to readout,\nreconstruct, select and analyse the data. This document presents these\nchallenges and the ongoing and future R&D programme necessary to address them.\nThis programme will benefit not only the LHCb Upgrade II experiment, but the\nwhole particle physics community as similar challenges will be faced by the\nnext generation of experiments.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-03-31T13:57:27Z"}
{"aid":"http://arxiv.org/abs/2503.24117v1","title":"Organizations, teams, and job mobility: A social microdynamics approach","summary":"The internal structures of large organizations determine much of what occurs\ninside including the way in which tasks are performed, the workers that perform\nthem, and the mobility of those workers within the organization. However,\nregarding this latter process, most of the theoretical and modeling approaches\nused to understand organizational worker mobility are highly stylized, using\nidealizations such as structureless organizations, indistinguishable workers,\nand a lack of social bonding of the workers. In this article, aided by a decade\nof precise, temporally resolved data of a large US government organization, we\nintroduce a new model to describe organizations as composites of teams within\nwhich individuals perform specific tasks and where social connections develop.\nBy tracking the personnel composition of organizational teams, we find that\nworkers that change jobs are highly influenced by preferring to reunite with\npast co-workers. In this organization, 34\\% of all moves lead to worker\nreunions, a percentage well-above expectation. We find that the greater the\ntime workers spend together or the smaller the team they share both increase\ntheir likelihood to reunite, supporting the notion of increased familiarity and\ntrust behind such reunions and the dominant role of social capital in the\nevolution of large organizations.","main_category":"cs.CE","categories":"cs.CE","published":"2025-03-31T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2503.24121v1","title":"IMPACT: A Generic Semantic Loss for Multimodal Medical Image\n  Registration","summary":"Image registration is fundamental in medical imaging, enabling precise\nalignment of anatomical structures for diagnosis, treatment planning,\nimage-guided treatment or longitudinal monitoring. This work introduces IMPACT\n(Image Metric with Pretrained model-Agnostic Comparison for Transmodality\nregistration), a generic semantic similarity metric designed for seamless\nintegration into diverse image registration frameworks (such as Elastix and\nVoxelmorph). It compares deep learning-based features extracted from medical\nimages without requiring task-specific training, ensuring broad applicability\nacross various modalities. By leveraging the features of the large-scale\npretrained TotalSegmentator models and the ability to integrate Segment\nAnything Model (SAM) and other large-scale segmentation networks, this approach\noffers significant advantages. It provides robust, scalable, and efficient\nsolutions for multimodal image registration. The IMPACT loss was evaluated on\nfive challenging registration tasks involving thoracic CT/CBCT, and pelvic\nMR/CT datasets. Quantitative metrics, such as Target Registration Error and\nDice Similarity Coefficient, demonstrated significant improvements in\nanatomical alignment compared to baseline methods. Qualitative analyses further\nconfirmed the increased robustness of the proposed metric in the face of noise,\nartifacts, and modality variations. IMPACT's versatility and efficiency make it\na valuable tool for advancing registration performance in clinical and research\napplications, addressing critical challenges in multimodal medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:08:21Z"}
{"aid":"http://arxiv.org/abs/2503.24125v1","title":"Evidence for the collective nature of radial flow in Pb+Pb collisions\n  with the ATLAS detector","summary":"Anisotropic flow and radial flow are two key probes of the expansion dynamics\nand properties of the quark-gluon plasma (QGP). While anisotropic flow has been\nextensively studied, radial flow, which governs the system's radial expansion,\nhas received less attention. Notably, experimental evidence for the global and\ncollective nature of radial flow has been lacking. This Letter presents the\nfirst measurement of transverse momentum ($p_{\\mathrm{T}}$) dependence of\nradial flow fluctuations ($v_0(p_{\\mathrm{T}})$) over $0.5<p_{\\mathrm{T}}<10$\nGeV, using a two-particle correlation method in Pb+Pb collisions at\n$\\sqrt{s_{\\mathrm{NN}}}=5.02$ TeV. The data reveal three key features\nsupporting the collective nature of radial flow: long-range correlation in\npseudorapidity, factorization in $p_{\\mathrm{T}}$, and centrality-independent\nshape in $p_{\\mathrm{T}}$. The comparison with a hydrodynamic model\ndemonstrates the sensitivity of $v_0(p_{\\mathrm{T}})$ to bulk viscosity, a\ncrucial transport property of the QGP. These findings establish a new, powerful\ntool for probing collective dynamics and properties of the QGP.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-03-31T14:10:55Z"}
{"aid":"http://arxiv.org/abs/2503.24128v1","title":"Perfect circle-valued Morse functions on hyperbolic 6-manifolds","summary":"We build the first example of a hyperbolic 6-manifold that admits a perfect\ncircle-valued Morse function, which can be considered as the analogue of a\nfibration over the circle for manifolds with non-vanishing Euler\ncharacteristic. As a consequence, we obtain a new example of a subgroup of a\nhyperbolic group which is of type $\\mathcal{F}_2$ but not $\\mathcal{F}_3$.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-03-31T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2503.24130v1","title":"Graph Neural Network-Based Predictive Modeling for Robotic Plaster\n  Printing","summary":"This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.","main_category":"cs.CE","categories":"cs.CE,cs.AI,cs.LG,cs.RO","published":"2025-03-31T14:15:00Z"}
{"aid":"http://arxiv.org/abs/2503.24138v1","title":"AI-Assisted Colonoscopy: Polyp Detection and Segmentation using\n  Foundation Models","summary":"In colonoscopy, 80% of the missed polyps could be detected with the help of\nDeep Learning models. In the search for algorithms capable of addressing this\nchallenge, foundation models emerge as promising candidates. Their zero-shot or\nfew-shot learning capabilities, facilitate generalization to new data or tasks\nwithout extensive fine-tuning. A concept that is particularly advantageous in\nthe medical imaging domain, where large annotated datasets for traditional\ntraining are scarce. In this context, a comprehensive evaluation of foundation\nmodels for polyp segmentation was conducted, assessing both detection and\ndelimitation. For the study, three different colonoscopy datasets have been\nemployed to compare the performance of five different foundation models,\nDINOv2, YOLO-World, GroundingDINO, SAM and MedSAM, against two benchmark\nnetworks, YOLOv8 and Mask R-CNN. Results show that the success of foundation\nmodels in polyp characterization is highly dependent on domain specialization.\nFor optimal performance in medical applications, domain-specific models are\nessential, and generic models require fine-tuning to achieve effective results.\nThrough this specialization, foundation models demonstrated superior\nperformance compared to state-of-the-art detection and segmentation models,\nwith some models even excelling in zero-shot evaluation; outperforming\nfine-tuned models on unseen data.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-03-31T14:20:53Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24153v1","title":"Convexity of chance constraints for elliptical and skewed distributions\n  with copula structures dependent on decision variables","summary":"Chance constraints describe a set of given random inequalities depending on\nthe decision vector satisfied with a large enough probability. They are widely\nused in decision making under uncertain data in many engineering problems. This\npaper aims to derive the convexity of chance constraints with row dependent\nelliptical and skewed random variables via a copula depending on decision\nvectors. We obtain best thresholds of the $r$-concavity for any real number $r$\nand improve probability thresholds of the eventual convexity. We prove the\neventual convexity with elliptical distributions and a Gumbel-Hougaard copula\ndespite the copula's singularity near the origin. We determine the\n$\\alpha$-decreasing densities of generalized hyperbolic distributions by\nestimating the modified Bessel functions. By applying the $\\alpha$-decreasing\nproperty and a radial decomposition, we achieve the eventual convexity for\nthree types of skewed distributions. Finally, we provide an example to\nillustrate the eventual convexity of a feasible set containing the origin.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T14:38:27Z"}
{"aid":"http://arxiv.org/abs/2503.24155v1","title":"The Belle II Experiment at SuperKEKB -- Input to the European Particle\n  Physics Strategy","summary":"Belle II is an intensity-frontier experiment at the SuperKEKB collider in\nTsukuba, Japan. Over the coming decades, it will record the decays of billions\nof bottom mesons, charm hadrons, and tau leptons produced in 10 GeV\nelectron-positron collisions. The experiment's low-background environment and\nprecisely known kinematics enable high-precision measurements of hundreds of\nStandard Model (SM) parameters while probing for new particles at mass scales\nfar beyond the direct reach of high-energy colliders. We project Belle II's\nsensitivity for key measurements - where it will be uniquely positioned or\nworld-leading - over datasets ranging from 1 to 50 ab${}^{-1}$. By exploring\npreviously uncharted regions of non-SM parameter space with high precision,\nBelle II will either reveal new physics or set stringent constraints, guiding\nfuture experimental and theoretical efforts. Additionally, we outline near-term\nupgrades to the Belle II detector and SuperKEKB accelerator, which will enhance\nsensitivity in searches for new physics beyond the SM across flavor, tau,\nelectroweak, and dark sector physics. These improvements will ensure that Belle\nII remains both complementary to and competitive with the LHC and other\nexperiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-03-31T14:39:29Z"}
{"aid":"http://arxiv.org/abs/2503.24161v1","title":"Hypergenerated Carnot groups","summary":"In this paper we provide an algebraic characterization of those stratified\ngroups in which boundaries with locally constant normal are locally flat. We\nshow that these groups, which we call hypergenerated, are exactly the\nstratified groups where embeddings of non-characteristic hypersurfaces are\nlocally bi-Lipschitz. Finally, we extend these results to submanifolds of\narbitrary codimension.","main_category":"math.MG","categories":"math.MG,math.DG,math.GR","published":"2025-03-31T14:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.24165v1","title":"Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer\n  Using Multimodal Machine Learning","summary":"Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T14:47:02Z"}
{"aid":"http://arxiv.org/abs/2503.24173v1","title":"Worldvolume fermion as baryon with homogeneous instantons in holographic\n  $\\mathrm{QCD}_{3}$","summary":"We investigate holographically the effective theory of the worldvolume\nfermion on the flavor branes in the D3/D7 model with homogeneously smeared\nD(-1)-branes. As a top-down approach in gauge-gravity duality, the D(-1)-branes\nare instantons and violate the CP symmetry in the dual theory. The background\ngeometry of this model contains black brane (deconfined geometry) and bubble\nD3-brane solutions (confined geometry), all with a non-zero Romand-Romand zero\nform as axion. The dual theories to the backgrounds are respectively the Super\nYang-Mills theory at finite temperature and three-dimensional confining\nYang-Mills theory, all with a Chern-Simons term induced by instantons. In the\nconfined geometry, we introduce a baryon vertex as a D5-brane wrapped on\n$S^{5}$, then identify the fermionic flux on the D7-brane as a baryonic\noperator. Afterwards, we study the spectrum and the holographic correlation\nfunction of the flavored fermion on the D7-branes. Remarkably, the fermionic\nspectrum is in agreement with the dispersion curves obtained from the confined\ncorrelation function, and the mass ratio of the lowest baryon and meson in our\nmodel is close to the associated experimental data. Moreover, the effective\ninteraction terms of the holographic baryon and meson are derived and all the\ncoupling constants take order of $N_{c}^{1/2}$ agreeing with the evaluation\nfrom the large N field theory. In the deconfined geometry, the holographic\ncorrelation function is also evaluated numerically while the fermion on\nD7-brane is identified to plasmino instead of baryon. The dispersion curves\nfrom the deconfined correlation function basically covers the results from the\nhard thermal loop approximation and may imply the instanton-induced interaction\nwith spin. Overall, this work constructs a holographic theory about baryonic\nfermion and mesonic boson with instantons or CP violation.","main_category":"hep-th","categories":"hep-th,hep-ph,nucl-th","published":"2025-03-31T14:51:40Z"}
{"aid":"http://arxiv.org/abs/2503.24183v1","title":"Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees\n  via Constrained Mean-Field Reinforcement Learning","summary":"The rapid expansion of ride-sourcing services such as Uber, Lyft, and Didi\nChuxing has fundamentally reshaped urban transportation by offering flexible,\non-demand mobility via mobile applications. Despite their convenience, these\nplatforms confront significant operational challenges, particularly vehicle\nrebalancing - the strategic repositioning of thousands of vehicles to address\nspatiotemporal mismatches in supply and demand. Inadequate rebalancing results\nin prolonged rider waiting times, inefficient vehicle utilization, and\ninequitable distribution of services, leading to disparities in driver\navailability and income.\n  To tackle these complexities, we introduce scalable continuous-state\nmean-field control (MFC) and reinforcement learning (MFRL) models that\nexplicitly represent each vehicle's precise location and employ continuous\nrepositioning actions guided by the distribution of other vehicles. To ensure\nequitable service distribution, an accessibility constraint is integrated\nwithin our optimal control formulation, balancing operational efficiency with\nequitable access to the service across geographic regions. Our approach\nacknowledges realistic conditions, including inherent stochasticity in\ntransitions, the simultaneous occurrence of vehicle-rider matching, vehicles'\nrebalancing and cruising, and variability in rider behaviors. Crucially, we\nrelax the traditional mean-field assumption of equal supply-demand volume,\nbetter reflecting practical scenarios. Extensive empirical evaluation using\nreal-world data-driven simulation of Shenzhen demonstrates the real-time\nefficiency and robustness of our approach at the scale of tens of thousands of\nvehicles.\n  The code is available at\nhttps://github.com/mjusup1501/mf-vehicle-rebalancing.","main_category":"cs.LG","categories":"cs.LG,cs.MA","published":"2025-03-31T15:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.24186v1","title":"Annihilation of cohomology and (strong) generation of singularity\n  categories","summary":"Let R be a commutative Noetherian ring. We establish a close relationship\nbetween the (strong) generation of the singularity category of R, the\nnonvanishing of the annihilator of the singularity category of R, and the\nnonvanishing of the cohomological annihilator of modules. As an application, we\nprove that the singularity category of R has a strong generator if and only if\nthe annihilator of the singularity category of R is nonzero when R is a\nNoetherian domain with Krull dimension at most one. Furthermore, we relate the\ngeneration of the singularity category and the extension generation of the\nmodule category. Additionally, we introduce the notion of the co-cohomological\nannihilator of modules. If the category of finitely generated R-modules has a\nstrong generator, we show that the infinite injective dimension locus of a\nfinitely generated R-module M is closed, with the defining ideal given by the\nco-cohomological annihilator of M.","main_category":"math.AC","categories":"math.AC,math.RT","published":"2025-03-31T15:03:30Z"}
{"aid":"http://arxiv.org/abs/2503.24191v1","title":"Output Constraints as Attack Surface: Exploiting Structured Generation\n  to Bypass LLM Safety Mechanisms","summary":"Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-03-31T15:08:06Z"}
{"aid":"http://arxiv.org/abs/2503.24199v1","title":"Agent-Based Simulations of Online Political Discussions: A Case Study on\n  Elections in Germany","summary":"User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-03-31T15:17:04Z"}
{"aid":"http://arxiv.org/abs/2503.24213v1","title":"Closing the detection loophole in the triangle network with\n  high-dimensional photonic states","summary":"Bell nonlocality without input settings, e.g. in the triangle network, has\nbeen perceived to be particularly fragile, with low robustness to noise in\nphysical implementations. Here we show to the contrary that nonlocality based\non N00N states already for $N=2$ has an exceptionally high robustness to photon\nloss. For the dominant noise factor, single photon loss in the transmission\nchannels, we can certify noise robustness up to 10\\% loss, while for a\nrealistic noise model we use neural network-based heuristics to observe $\\sim\n50\\%$ robustness. Moreover we show that the robustness holds even for imperfect\nsources based on SPDC sources, where the heralding information of the sources\ncan be used to avoid any global post-processing of the outcomes, such as\ndiscarding rounds when photons fail to arrive, and thus demonstrate how the\ndetection loophole in the triangle network can be closed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:31:34Z"}
{"aid":"http://arxiv.org/abs/2503.24228v1","title":"PAARS: Persona Aligned Agentic Retail Shoppers","summary":"In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.MA","published":"2025-03-31T15:41:51Z"}
{"aid":"http://arxiv.org/abs/2503.24229v1","title":"Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance\n  Segmentation from 3D Synthetic Scenes","summary":"In the recent years, the research community has witnessed growing use of 3D\npoint cloud data for the high applicability in various real-world applications.\nBy means of 3D point cloud, this modality enables to consider the actual size\nand spatial understanding. The applied fields include mechanical control of\nrobots, vehicles, or other real-world systems. Along this line, we would like\nto improve 3D point cloud instance segmentation which has emerged as a\nparticularly promising approach for these applications. However, the creation\nof 3D point cloud datasets entails enormous costs compared to 2D image\ndatasets. To train a model of 3D point cloud instance segmentation, it is\nnecessary not only to assign categories but also to provide detailed\nannotations for each point in the large-scale 3D space. Meanwhile, the increase\nof recent proposals for generative models in 3D domain has spurred proposals\nfor using a generative model to create 3D point cloud data. In this work, we\npropose a pre-training with 3D synthetic data to train a 3D point cloud\ninstance segmentation model based on generative model for 3D scenes represented\nby point cloud data. We directly generate 3D point cloud data with Point-E for\ninserting a generated data into a 3D scene. More recently in 2025, although\nthere are other accurate 3D generation models, even using the Point-E as an\nearly 3D generative model can effectively support the pre-training with 3D\nsynthetic data. In the experimental section, we compare our pre-training method\nwith baseline methods indicated improved performance, demonstrating the\nefficacy of 3D generative models for 3D point cloud instance segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T15:42:10Z"}
{"aid":"http://arxiv.org/abs/2503.24240v1","title":"Analysis of the French system imbalance paving the way for a novel\n  operating reserve sizing approach","summary":"This paper examines the relationship between system imbalance and several\nexplanatory variables within the French electricity system. The factors\nconsidered include lagged imbalance values, observations of renewable energy\nsources (RES) generation and consumption, and forecasts for RES generation and\nconsumption. The study analyzes the distribution of system imbalance in\nrelation to these variables. Additionally, an HGBR machine-learning model is\nemployed to assess the predictability of imbalances and the explanatory power\nof the input variables studied.\n  The results indicate no clear correlation between RES generation or\nconsumption and the observed imbalances. However, it is possible to predict the\nimbalance adequately using forecasts available a few hours before real-time,\nalong with the lagged values of the imbalance. Predicting the imbalance a day\nin advance proves to be complex with the variables examined; however, the\nextreme quantiles of the imbalance used for reserve sizing and contracting can\nbe predicted with sufficient accuracy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T15:53:47Z"}
{"aid":"http://arxiv.org/abs/2503.24243v1","title":"Music Information Retrieval on Representative Mexican Folk Vocal\n  Melodies Through MIDI Feature Extraction","summary":"This study analyzes representative Mexican folk vocal melodies using MIDI\nfeature extraction, examining ambitus, pitch-class entropy, and interval\ndistribution. It also explores the relationship between these features and song\npopularity, as measured by Spotify plays. The study employs MATLAB and the MIDI\nToolbox for extracting musical features and performing statistical analysis.\nThe findings reveal a significant variation in ambitus, with values ranging\nfrom 8 to 27 semitones, indicating a diverse compositional style and vocal\ndemand across the genre. The analysis of pitch-class entropy showcases a broad\nspectrum of melodic complexity, with Armando Manzanero's `Somos Novios'\ndisplaying the highest entropy, suggesting varied and complex melodic\nstructures, while traditional pieces like `La Bamba' exhibit lower entropy,\nindicating simpler, more repetitive patterns. The interval distribution\npredominantly features prime intervals (P1), major and minor seconds (M2, m2),\npointing to a compositional preference for close, contiguous intervals that\ncontribute to the melodies' accessibility and appeal. Statistical analysis do\nnot establish a significant correlation between the ambitus or entropy and the\nnumber of Spotify plays.","main_category":"cs.SD","categories":"cs.SD,cs.IR","published":"2025-03-31T15:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.24253v1","title":"Deep Learning-Based Data Fusion of 6G Sensing and Inertial Information\n  for Target Positioning: Experimental Validation","summary":"The sixth-generation (6G) cellular technology will be deployed with a key\nfeature of Integrated Sensing and Communication (ISAC), allowing the cellular\nnetwork to map the environment through radar sensing on top of providing\ncommunication services. In this regard, the entire network can be considered as\na sensor with a broader Field of View (FoV) of the environment, assisting in\nboth the positioning of active and detection of passive targets. On the other\nhand, the non-3GPP sensors available on the target can provide additional\ninformation specific to the target that can be beneficially combined with ISAC\nsensing information to enhance the overall achievable positioning accuracy. In\nthis paper, we first study the performance of the ISAC system in terms of its\nachievable accuracy in positioning the mobile target in an indoor scenario.\nSecond, we study the performance gain achieved in the ISAC positioning accuracy\nafter fusing the information from the target's non-3GPP sensors. To this end,\nwe propose a novel data fusion solution based on the deep learning framework to\nfuse the information from ISAC and non-3GPP sensors.\n  We validate our proposed data fusion and positioning solution with a\nreal-world ISAC Proof-of-Concept (PoC) as the wireless infrastructure, an\nAutomated Guided Vehicle (AGV) as the target, and the Inertial Measurement Unit\n(IMU) sensor on the target as the non-3GPP sensor. The experimental results\nshow that our proposed solution achieves an average positioning error of\n$3~\\textrm{cm}$, outperforming the considered baselines.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T16:02:17Z"}
{"aid":"http://arxiv.org/abs/2503.24254v1","title":"PromoPlot: Covering open-access fees by filling wasted space in corner\n  plots","summary":"In an effort to reduce drain on grant funds and decrease unused space in\npublications, we have developed a Python package for inserting advertisements\ninto the space left empty by corner plots. This novel technique can allow\nauthors to reduce or eliminate publication charges for journals such as MNRAS\nand ApJ. In order to offset publication costs entirely, we recommend that\nauthors include anywhere from 200-700 corner plots per paper, with the exact\nnumber depending on the journal used. Finally, we discuss other opportunities\nto generate ad revenue through publications.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T16:02:37Z"}
{"aid":"http://arxiv.org/abs/2503.24256v1","title":"Ranked percolation model for the caking time of amorphous molecular\n  powders","summary":"When amorphous molecular powders are exposed to high humidity levels or\ntemperatures, the particle viscosity increases due to plasticization, promoting\nthe formation of sinter bridges between pairs of particles in contact. Over\ntime, these bridges facilitate particle agglomeration, eventually leading to\nthe formation of a macroscopic cake that alters the mechanical properties and\naffects product quality. In this work, we model the caking process of amorphous\npowders subjected to a temperature shock as a bond percolation problem and\ninvestigate how particle bed heterogeneities influence the percolation\nthreshold and, consequently, the expected caking times. Our findings indicate\nthat a slight dispersion in particle size lowers the percolation threshold\ncompared to a monodisperse bed or random percolation in polydisperse systems.\nFurthermore, we show that the expected caking time exhibits a non-monotonic\nbehavior with the size dispersion, initially decreasing for low dispersion\nvalues and increasing for higher values. These results provide insights into\nthe role of the particle size distribution on the caking dynamics of amorphous\nmolecular powders","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-03-31T16:03:56Z"}
{"aid":"http://arxiv.org/abs/2503.24272v1","title":"Learning Velocity and Acceleration: Self-Supervised Motion Consistency\n  for Pedestrian Trajectory Prediction","summary":"Understanding human motion is crucial for accurate pedestrian trajectory\nprediction. Conventional methods typically rely on supervised learning, where\nground-truth labels are directly optimized against predicted trajectories. This\namplifies the limitations caused by long-tailed data distributions, making it\ndifficult for the model to capture abnormal behaviors. In this work, we propose\na self-supervised pedestrian trajectory prediction framework that explicitly\nmodels position, velocity, and acceleration. We leverage velocity and\nacceleration information to enhance position prediction through feature\ninjection and a self-supervised motion consistency mechanism. Our model\nhierarchically injects velocity features into the position stream. Acceleration\nfeatures are injected into the velocity stream. This enables the model to\npredict position, velocity, and acceleration jointly. From the predicted\nposition, we compute corresponding pseudo velocity and acceleration, allowing\nthe model to learn from data-generated pseudo labels and thus achieve\nself-supervised learning. We further design a motion consistency evaluation\nstrategy grounded in physical principles; it selects the most reasonable\npredicted motion trend by comparing it with historical dynamics and uses this\ntrend to guide and constrain trajectory generation. We conduct experiments on\nthe ETH-UCY and Stanford Drone datasets, demonstrating that our method achieves\nstate-of-the-art performance on both datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T16:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24281v1","title":"Cylindrical boundary induced current in the cosmic string spacetime","summary":"In this paper we investigate the vacuum current associated with a charged\nbosonic field operator, induced by a cylindrical boundary in the idealized\ncosmic string spacetime. In this setup we assume that the cylindrical boundary\nis coaxial with the string, that by its turn carry a magnetic flux along its\ncore. In order to develop this analysis, we calculate the positive frequency\nWightman functions for both regions, inside and outside the boundary. Moreover,\nwe assume that the bosonic field obeys the Robin boundary condition on the\ncylindrical shell. Using this approach, the analytical expressions for the\nvacuum bosonic currents are presented in the form of the sum of boundary-free\nand boundary-induced parts. Because the boundary-free contribution is very well\nestablished in literature, our focus here is in the boundary-dependent part. As\nwe will see, our general results are presented in a cylindrically symmetric\nstatic structure. Some asymptotic behaviors for the boundary-induced vacuum\ncurrents are investigated in various limiting cases. In order to provide a\nbetter understanding of these currents, we provide some graphs exhibiting their\nbehavior as function of the distance to the string's core, and on the intensity\nof the magnetic flux running along it. These plots also present how the\nparameter associated with the planar angle deficit interfere in the intensity\nof the corresponding current.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T16:26:39Z"}
{"aid":"http://arxiv.org/abs/2503.24285v1","title":"Advanced Quantum Annealing Approach to Vehicle Routing Problems with\n  Time Windows","summary":"In this paper, we explore the potential for quantum annealing to solve\nrealistic routing problems. We focus on two NP-Hard problems, including the\nTraveling Salesman Problem with Time Windows and the Capacitated Vehicle\nRouting Problem with Time Windows. We utilize D-Wave's Quantum Annealer and\nConstrained Quadratic Model (CQM) solver within a hybrid framework to solve\nthese problems. We demonstrate that while the CQM solver effectively minimizes\nroute costs, it struggles to maintain time window feasibility as the problem\nsize increases. To address this limitation, we implement a heuristic method\nthat fixes infeasible solutions through a series of swapping operations.\nTesting on benchmark instances shows our method achieves promising results with\nan average optimality gap of 3.86%.","main_category":"cs.ET","categories":"cs.ET,quant-ph","published":"2025-03-31T16:32:40Z"}
{"aid":"http://arxiv.org/abs/2503.24291v1","title":"Quark production in the bottom-up thermalization","summary":"We investigate the impact of quark production on bottom-up thermalization in\nheavy-ion collisions. First, we extend the parametric estimates of bottom-up\nthermalization in pure gluon systems by incorporating quark production in the\nweak-coupling (high-energy) limit. Our analysis reveals that quark production\ndoes not alter the qualitative features of the three-stage thermalization\nprocess in this limit. Furthermore, we obtain the scaling behavior of the quark\nnumber density over time at each stage. Then, by solving the Boltzmann equation\nin diffusion approximation (BEDA) for longitudinally boost-invariant systems,\nwe demonstrate how our detailed numerical simulations approach the predicted\nthree-stage thermalization picture as the strong coupling $\\alpha_s$ decreases.\nFinally, we carry out a detailed comparison of our BEDA results with those\nobtained by solving the QCD effective kinetic theory for intermediate values of\n$\\alpha_s$, observing remarkably good quantitative agreement between the two\napproaches.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-03-31T16:37:53Z"}
{"aid":"http://arxiv.org/abs/2503.24300v1","title":"Solving the Best Subset Selection Problem via Suboptimal Algorithms","summary":"Best subset selection in linear regression is well known to be nonconvex and\ncomputationally challenging to solve, as the number of possible subsets grows\nrapidly with increasing dimensionality of the problem. As a result, finding the\nglobal optimal solution via an exact optimization method for a problem with\ndimensions of 1000s may take an impractical amount of CPU time. This suggests\nthe importance of finding suboptimal procedures that can provide good\napproximate solutions using much less computational effort than exact methods.\nIn this work, we introduce a new procedure and compare it with other popular\nsuboptimal algorithms to solve the best subset selection problem. Extensive\ncomputational experiments using synthetic and real data have been performed.\nThe results provide insights into the performance of these methods in different\ndata settings. The new procedure is observed to be a competitive suboptimal\nalgorithm for solving the best subset selection problem for high-dimensional\ndata.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T16:43:33Z"}
{"aid":"http://arxiv.org/abs/2503.24301v1","title":"QUADRO: A Hybrid Quantum Optimization Framework for Drone Delivery","summary":"Quantum computing holds transformative potential for optimizing large-scale\ndrone fleet operations, yet its near-term limitations necessitate hybrid\napproaches blending classical and quantum techniques. This work introduces\nQuantum Unmanned Aerial Delivery Routing Optimization (QUADRO), a novel hybrid\nframework addressing the Energy-Constrained Capacitated Unmanned Aerial Vehicle\nRouting Problem and the Unmanned Aerial Vehicle Scheduling Problem. By\nformulating these challenges as Quadratic Unconstrained Binary Optimization\nproblems, QUADRO leverages the Quantum Approximate Optimization Algorithm for\nrouting and scheduling, enhanced by classical heuristics and post-processing.\nWe minimize total transit time in routing, considering payload and battery\nconstraints, and optimize makespan scheduling across various drone fleets.\nEvaluated on adapted Augerat benchmarks (16-51 nodes), QUADRO competes against\nclassical and prior hybrid methods, achieving scalable solutions with fewer\nthan one hundred qubits. The proposed results underscore the viability of\nhybrid quantum-classical strategies for real-world drone logistics, paving the\nway for quantum-enhanced optimization in the Noisy Intermediate Scale Quantum\nera.","main_category":"cs.ET","categories":"cs.ET","published":"2025-03-31T16:44:42Z"}
{"aid":"http://arxiv.org/abs/2503.24308v1","title":"Johnson's contribution to the Discussion of `Statistical aspects of the\n  Covid-19 response' by Wood et al","summary":"This is a response to the paper \"Some statistical aspects of the Covid-19\nresponse\" by Wood et al, submitted to the discussion at the read paper meeting\nof the Royal Statistical Society on 10th April 2025.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T16:54:44Z"}
{"aid":"http://arxiv.org/abs/2503.24311v1","title":"Selective Inference in Graphical Models via Maximum Likelihood","summary":"The graphical lasso is a widely used algorithm for fitting undirected\nGaussian graphical models. However, for inference on functionals of edge values\nin the learned graph, standard tools lack formal statistical guarantees, such\nas control of the type I error rate. In this paper, we introduce a selective\ninference method for asymptotically valid inference after graphical lasso\nselection with added randomization. We obtain a selective likelihood,\nconditional on the event of selection, through a change of variable on the\nknown density of the randomization variables. Our method enables interval\nestimation and hypothesis testing for a wide range of functionals of edge\nvalues in the learned graph using the conditional maximum likelihood estimate.\nOur numerical studies show that introducing a small amount of randomization:\n(i) greatly increases power and yields substantially shorter intervals compared\nto other conditional inference methods, including data splitting; (ii) ensures\nintervals of bounded length in high-dimensional settings where data splitting\nis infeasible due to insufficient samples for inference; (iii) enables\ninference for a wide range of inferential targets in the learned graph,\nincluding measures of node influence and connectivity between nodes.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-03-31T16:57:04Z"}
{"aid":"http://arxiv.org/abs/2503.24312v1","title":"ALMA Band 3 Selection of Ultra-high Redshift Dropouts: The final\n  challenge to ΛCDM","summary":"The Lyman-break technique has been used to successfully identify\nhigh-redshift candidates in broad-band photometric data in the rest-frame\noptical and NIR using the dropout technique. We pioneer the application of this\ntechnique to new wavelength regimes, and search for dropouts in combined ALMA\nand JWST data. We find a candidate that is undetected in NIRCam imaging\nincluding and blueward of the F444W filter, but clearly identified in ALMA band\n3. Assuming this is a Lyman-break candidate, we measure a redshift in the range\n$40 < z < 21\\,380$. This is the highest redshift galaxy candidate discovered to\ndate, and is in significant tension with current and future predictions from\ncosmological simulations, with implications for galaxy evolution in the (very)\nearly Universe.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T16:59:15Z"}
{"aid":"http://arxiv.org/abs/2503.24313v1","title":"1-Tb/s/λ Transmission over Record 10714-km AR-HCF","summary":"We present the first single-channel 1.001-Tb/s DP-36QAM-PCS recirculating\ntransmission over 73 loops of 146.77-km ultra-low-loss & low-IMI DNANF-5 fiber,\nachieving a record transmission distance of 10,714.28 km.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-03-31T17:01:01Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24349v1","title":"Faster Releases, Fewer Risks: A Study on Maven Artifact Vulnerabilities\n  and Lifecycle Management","summary":"In modern software ecosystems, dependency management plays a critical role in\nensuring secure and maintainable applications. However, understanding the\nrelationship between release practices and their impact on vulnerabilities and\nupdate cycles remains a challenge. In this study, we analyze the release\nhistories of 10,000 Maven artifacts, covering over 203,000 releases and 1.7\nmillion dependencies. We evaluate how release speed affects software security\nand lifecycle. Our results show an inverse relationship between release speed\nand dependency outdatedness. Artifacts with more frequent releases maintain\nsignificantly shorter outdated times. We also find that faster release cycles\nare linked to fewer CVEs in dependency chains, indicating a strong negative\ncorrelation. These findings emphasize the importance of accelerated release\nstrategies in reducing security risks and ensuring timely updates. Our research\nprovides valuable insights for software developers, maintainers, and ecosystem\nmanagers.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T17:32:45Z"}
{"aid":"http://arxiv.org/abs/2503.24366v1","title":"StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian\n  Splatting","summary":"3D Gaussian splatting (3DGS) is a popular radiance field method, with many\napplication-specific extensions. Most variants rely on the same core algorithm:\ndepth-sorting of Gaussian splats then rasterizing in primitive order. This\nensures correct alpha compositing, but can cause rendering artifacts due to\nbuilt-in approximations. Moreover, for a fixed representation, sorted rendering\noffers little control over render cost and visual fidelity. For example, and\ncounter-intuitively, rendering a lower-resolution image is not necessarily\nfaster. In this work, we address the above limitations by combining 3D Gaussian\nsplatting with stochastic rasterization. Concretely, we leverage an unbiased\nMonte Carlo estimator of the volume rendering equation. This removes the need\nfor sorting, and allows for accurate 3D blending of overlapping Gaussians. The\nnumber of Monte Carlo samples further imbues 3DGS with a way to trade off\ncomputation time and quality. We implement our method using OpenGL shaders,\nenabling efficient rendering on modern GPU hardware. At a reasonable visual\nquality, our method renders more than four times faster than sorted\nrasterization.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-03-31T17:46:18Z"}
{"aid":"http://arxiv.org/abs/2503.24375v1","title":"Transverse orbital angular momentum: setting the record straight","summary":"The nature of the transverse orbital angular momentum (tOAM) associated with\nspatiotemporal optical vortex (STOV) pulses has been the subject of recent\ndebate. We demonstrate that the approaches to tOAM presented in several recent\npapers are incorrect and lead to unphysical results, including erroneous claims\nof zero total tOAM. We emphasize the importance of calculating the OAM of any\nextended physical object at a common instant of time, and reemphasize the\nspecial status of the centre of energy as a reference point for all OAM\ncalculations. The theory presented in [Phys. Rev. Lett. 127, 193901 (2021)] is\nthe only correct classical field-based framework that both agrees with\nexperiments and provides a self consistent understanding of transverse OAM in\nspatiotemporal light fields.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2503.24376v1","title":"Exploring the Effect of Reinforcement Learning on Video Understanding:\n  Insights from SEED-Bench-R1","summary":"Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-03-31T17:55:23Z"}
{"aid":"http://arxiv.org/abs/2503.24384v1","title":"High Energy Emission from the Intrabinary Shocks in Redback Pulsars","summary":"The intrabinary shocks (IBS) of spider pulsars emit non-thermal synchrotron\nX-rays from accelerated electrons and positrons in the shocked pulsar wind,\nlikely energized by magnetic reconnection. In redback spider pulsars, the IBS\ntypically wraps around the sub-stellar companion, leading to a near-normal IBS\nshock with relatively bright X-ray emission. The characteristic energies of\nradiating particles and the magnetic fields in the IBS suggest spectral\nfeatures in the hard X-ray band. Here we perform joint soft-hard X-ray analyses\nof three redback pulsars, J1723-2837, J2215+5135, and J2339-0533, including new\nJ2215 NuSTAR data. We identify a significant cooling break in J1723-2837 and a\nmarginal break in J2215+5135, while placing constraints on the break energy in\nJ2339-0533. Interpreting these as synchrotron cooling features allows us to\nestimate the IBS magnetic field $B_{\\rm IBS} \\sim 40-100$ G and place lower\nbounds on the maximum radiating electron energy. Our results constrain the\nmagnetization of the pulsar wind as well as pair-production in millisecond\npulsar magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.plasm-ph","published":"2025-03-31T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.24389v1","title":"SU-YOLO: Spiking Neural Network for Efficient Underwater Object\n  Detection","summary":"Underwater object detection is critical for oceanic research and industrial\nsafety inspections. However, the complex optical environment and the limited\nresources of underwater equipment pose significant challenges to achieving high\naccuracy and low power consumption. To address these issues, we propose Spiking\nUnderwater YOLO (SU-YOLO), a Spiking Neural Network (SNN) model. Leveraging the\nlightweight and energy-efficient properties of SNNs, SU-YOLO incorporates a\nnovel spike-based underwater image denoising method based solely on integer\naddition, which enhances the quality of feature maps with minimal computational\noverhead. In addition, we introduce Separated Batch Normalization (SeBN), a\ntechnique that normalizes feature maps independently across multiple time steps\nand is optimized for integration with residual structures to capture the\ntemporal dynamics of SNNs more effectively. The redesigned spiking residual\nblocks integrate the Cross Stage Partial Network (CSPNet) with the YOLO\narchitecture to mitigate spike degradation and enhance the model's feature\nextraction capabilities. Experimental results on URPC2019 underwater dataset\ndemonstrate that SU-YOLO achieves mAP of 78.8% with 6.97M parameters and an\nenergy consumption of 2.98 mJ, surpassing mainstream SNN models in both\ndetection accuracy and computational efficiency. These results underscore the\npotential of SNNs for engineering applications. The code is available in\nhttps://github.com/lwxfight/snn-underwater.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-03-31T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.01327v1","title":"Multi-wavelength properties of $z\\gtrsim 6$ LISA detectable events","summary":"We investigate the intrinsic and observational properties of $z\\gtrsim 6$\ngalaxies hosting coalescing massive black holes (MBHs) that gives rise to\ngravitational waves (GWs) detectable with the Laser Interferometer Space\nAntenna (LISA). We adopt a zoom-in cosmological hydrodynamical simulation of\ngalaxy formation and black hole (BH) co-evolution, zoomed-in on a $M_h \\sim\n10^{12}~\\rm M_{\\odot}$ dark matter halo at z = 6, which hosts a fast accreting\nsuper-massive black hole (SMBH) and a star-forming galaxy. Following the SMBH\nformation backward in time, we identify the merging events that concurred to\nits formation and we pick up the ones that are detectable with LISA. Among\nthese LISA detectable events (LDEs), we select those that, based on their\nintrinsic properties are expected to be bright in one or more electromagnetic\n(EM) bands. We post-process these events with dust radiative transfer\ncalculations to make predictions about their spectral energy distributions and\ncontinuum maps in the JWST to ALMA wavelength range. We compare the spectra\narising from galaxies hosting the merging MBHs with those arising from AGN\npowered by single accreting BHs. We find that it will be impossible to identify\nan LDE from the continuum SEDs because of the absence of specific imprints from\nthe merging MBHs. We also compute the profile of the H$_{\\rm \\alpha}$ line\narising from LDEs, considering the contribution from their star-forming regions\nand the accreting MBHs. We find that the presence of two accreting MBHs would\nbe difficult to infer even if both MBHs accrete at super-Eddington rates. We\nconclude that the combined detection of GW and EM signals from $z\\gtrsim 6$\nMBHs is challenging not only because of the poor sky-localization provided by\nLISA, but also because the loudest GW emitters are not massive enough to leave\nsignificant signatures in the emission lines arising from the broad line\nregion.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T03:24:35Z"}
{"aid":"http://arxiv.org/abs/2504.01329v1","title":"Flexible and Explainable Graph Analysis for EEG-based Alzheimer's\n  Disease Classification","summary":"Alzheimer's Disease is a progressive neurological disorder that is one of the\nmost common forms of dementia. It leads to a decline in memory, reasoning\nability, and behavior, especially in older people. The cause of Alzheimer's\nDisease is still under exploration and there is no all-inclusive theory that\ncan explain the pathologies in each individual patient. Nevertheless, early\nintervention has been found to be effective in managing symptoms and slowing\ndown the disease's progression. Recent research has utilized\nelectroencephalography (EEG) data to identify biomarkers that distinguish\nAlzheimer's Disease patients from healthy individuals. Prior studies have used\nvarious machine learning methods, including deep learning and graph neural\nnetworks, to examine electroencephalography-based signals for identifying\nAlzheimer's Disease patients. In our research, we proposed a Flexible and\nExplainable Gated Graph Convolutional Network (GGCN) with Multi-Objective\nTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a\nflexible solution that efficiently identifies the optimal number of GGCN blocks\nto achieve the optimized precision, specificity, and recall outcomes, as well\nas the optimized area under the Receiver Operating Characteristic (AUC). Our\nfindings demonstrated a high efficacy with an over 0.9 Receiver Operating\nCharacteristic score, alongside precision, specificity, and recall scores in\ndistinguishing health control with Alzheimer's Disease patients in Moderate to\nSevere Dementia using the power spectrum density (PSD) of\nelectroencephalography signals across various frequency bands. Moreover, our\nresearch enhanced the interpretability of the embedded adjacency matrices,\nrevealing connectivity differences in frontal and parietal brain regions\nbetween Alzheimer's patients and healthy individuals.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T03:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.01333v1","title":"Reconfigurable Codebook-Based Beamforming for RDARS-Aided mmWave MU-MIMO\n  Systems","summary":"Reconfigurable distributed antenna and reflecting surface (RDARS) is a new\narchitecture for the sixth-generation (6G) millimeter wave (mmWave)\ncommunications. In RDARS-aided mmWave systems, the active and passive\nbeamforming design and working mode configuration for reconfigurable elements\nare crucial for system performance. In this paper, we aim to maximize the\nweighted sum rate (WSR) in the RDARS-aided mmWave system. To take advantage of\nRDARS, we first design a reconfigurable codebook (RCB) in which the number and\ndimension of the codeword can be flexibly adjusted. Then, a low overhead beam\ntraining scheme based on hierarchical search is proposed. Accordingly, the\nactive and passive beamforming for data transmission is designed to achieve the\nmaximum WSR for both space-division multiple access (SDMA) and time-division\nmultiple access (TDMA) schemes. For the TDMA scheme, the optimal number of\nRDARS transmit elements and the allocated power budget for WSR maximization are\nderived in closed form. Besides, the superiority of the RDARS is verified and\nthe conditions under which RDARS outperforms RIS and DAS are given. For the\nSDMA scheme, we characterize the relationship between the number of RDARS\nconnected elements and the user distribution, followed by the derivation of the\noptimal placement positions of the RDARS transmit elements. High-quality\nbeamforming design solutions are derived to minimize the inter-user\ninterference (IUI) at the base station and RDARS side respectively, which\nnearly leads to the maximal WSR. Finally, simulation results confirm our\ntheoretical findings and the superiority of the proposed schemes.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T03:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.01342v1","title":"Foundations and Evaluations in NLP","summary":"This memoir explores two fundamental aspects of Natural Language Processing\n(NLP): the creation of linguistic resources and the evaluation of NLP system\nperformance. Over the past decade, my work has focused on developing a\nmorpheme-based annotation scheme for the Korean language that captures\nlinguistic properties from morphology to semantics. This approach has achieved\nstate-of-the-art results in various NLP tasks, including part-of-speech\ntagging, dependency parsing, and named entity recognition. Additionally, this\nwork provides a comprehensive analysis of segmentation granularity and its\ncritical impact on NLP system performance. In parallel with linguistic resource\ndevelopment, I have proposed a novel evaluation framework, the jp-algorithm,\nwhich introduces an alignment-based method to address challenges in\npreprocessing tasks like tokenization and sentence boundary detection (SBD).\nTraditional evaluation methods assume identical tokenization and sentence\nlengths between gold standards and system outputs, limiting their applicability\nto real-world data. The jp-algorithm overcomes these limitations, enabling\nrobust end-to-end evaluations across a variety of NLP tasks. It enhances\naccuracy and flexibility by incorporating linear-time alignment while\npreserving the complexity of traditional evaluation metrics. This memoir\nprovides key insights into the processing of morphologically rich languages,\nsuch as Korean, while offering a generalizable framework for evaluating diverse\nend-to-end NLP systems. My contributions lay the foundation for future\ndevelopments, with broader implications for multilingual resource development\nand system evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:14:03Z"}
{"aid":"http://arxiv.org/abs/2504.01348v1","title":"Prompt-Guided Attention Head Selection for Focus-Oriented Image\n  Retrieval","summary":"The goal of this paper is to enhance pretrained Vision Transformer (ViT)\nmodels for focus-oriented image retrieval with visual prompting. In real-world\nimage retrieval scenarios, both query and database images often exhibit\ncomplexity, with multiple objects and intricate backgrounds. Users often want\nto retrieve images with specific object, which we define as the Focus-Oriented\nImage Retrieval (FOIR) task. While a standard image encoder can be employed to\nextract image features for similarity matching, it may not perform optimally in\nthe multi-object-based FOIR task. This is because each image is represented by\na single global feature vector. To overcome this, a prompt-based image\nretrieval solution is required. We propose an approach called Prompt-guided\nattention Head Selection (PHS) to leverage the head-wise potential of the\nmulti-head attention mechanism in ViT in a promptable manner. PHS selects\nspecific attention heads by matching their attention maps with user's visual\nprompts, such as a point, box, or segmentation. This empowers the model to\nfocus on specific object of interest while preserving the surrounding visual\ncontext. Notably, PHS does not necessitate model re-training and avoids any\nimage alteration. Experimental results show that PHS substantially improves\nperformance on multiple datasets, offering a practical and training-free\nsolution to enhance model performance in the FOIR task.","main_category":"cs.CV","categories":"cs.CV,cs.IR","published":"2025-04-02T04:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.01349v1","title":"Tasks and Roles in Legal AI: Data Curation, Annotation, and Verification","summary":"The application of AI tools to the legal field feels natural: large legal\ndocument collections could be used with specialized AI to improve workflow\nefficiency for lawyers and ameliorate the \"justice gap\" for underserved\nclients. However, legal documents differ from the web-based text that underlies\nmost AI systems. The challenges of legal AI are both specific to the legal\ndomain, and confounded with the expectation of AI's high performance in\nhigh-stakes settings. We identify three areas of special relevance to\npractitioners: data curation, data annotation, and output verification. First,\nit is difficult to obtain usable legal texts. Legal collections are\ninconsistent, analog, and scattered for reasons technical, economic, and\njurisdictional. AI tools can assist document curation efforts, but the lack of\nexisting data also limits AI performance. Second, legal data annotation\ntypically requires significant expertise to identify complex phenomena such as\nmodes of judicial reasoning or controlling precedents. We describe case studies\nof AI systems that have been developed to improve the efficiency of human\nannotation in legal contexts and identify areas of underperformance. Finally,\nAI-supported work in the law is valuable only if results are verifiable and\ntrustworthy. We describe both the abilities of AI systems to support evaluation\nof their outputs, as well as new approaches to systematic evaluation of\ncomputational systems in complex domains. We call on both legal and AI\npractitioners to collaborate across disciplines and to release open access\nmaterials to support the development of novel, high-performing, and reliable AI\ntools for legal applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.01364v1","title":"Maximizing the number of stars in graphs with forbidden properties","summary":"Erd\\H{o}s proved an upper bound on the number of edges in an $n$-vertex\nnon-Hamiltonian graph with given minimum degree and showed sharpness via two\nmembers of a particular graph family. F\\\"{u}redi, Kostochka and Luo showed that\nthese two graphs play the same role when ``number of edges'' is replaced by\n``number of t-stars,'' and that two members of a more general graph family\nmaximize the number of edges among non-$k$-edge-Hamiltonian graphs. In this\npaper we generalize their former result from Hamiltonicity to related\nproperties (traceability, Hamiltonian-connectedness, $k$-edge Hamiltonicity,\n$k$-Hamiltonicity) and their latter result from edges to $t$-stars. We identify\na family of extremal graphs for each property that is forbidden. This problem\nwithout the minimum degree condition was also open; here we conjecture a\ncomplete description of the extremal family for each property, and prove the\ncharacterization in some cases. Finally, using a different family of extremal\ngraphs, we find the maximum number of $t$-stars in non-$k$-connected graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T05:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.01371v1","title":"A simple schematic model for a cross section deficit in\n  $^{12}$C+$^{12}$C fusion reactions","summary":"A cross section deficit phenomenon has been observed in $^{12}$C+$^{12}$C\nfusion reactions at astrophysical energies, at which fusion cross sections are\nsuppressed in the off-resonance regions as compared to fusion cross sections\nfor the $^{12}$C+$^{13}$C system. I here construct a simple schematic model\nwhich simulates this phenomenon. The model consists of a random matrix\nHamiltonian based on the Gaussian Orthogonal Ensemble (GOE), which is coupled\nto an entrance channel Hamiltonian in the discrete basis representation. I show\nthat the transmission coefficients are almost unity when both the level density\nand the decay widths of the GOE configurations are large, realizing the strong\nabsorption regime. On the other hand, when these parameters are small, the\ntransmission coefficients are significantly structured as a function of energy.\nIn that situation, the transmission coefficients at resonance energies reach\nunity in this model, that is consistent with the experimental finding of the\ncross section deficit.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-02T05:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.01375v1","title":"Simultaneous Pre-compensation for Bandwidth Limitation and Fiber\n  Dispersion in Cost-Sensitive IM/DD Transmission Systems","summary":"We propose a pre-compensation scheme for bandwidth limitation and fiber\ndispersion (pre-BL-EDC) based on the modified Gerchberg-Saxton (GS) algorithm.\nExperimental results demonstrate 1.0/1.0/2.0 dB gains compared to modified GS\npre-EDC for 20/28/32 Gbit/s bandwidth-limited systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T05:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.01385v1","title":"Dynamics of ring solitons in an expanding cloud of a Bose-Einstein\n  condensate","summary":"In this paper, we derive equations for the dynamics of ring dark solitons in\nan expanding cloud of a two-dimensional Bose-Einstein condensate. Assuming that\nthe soliton's width is much smaller than its radius, we obtain the Hamilton\nequations for its evolution. Then they are transformed into the Newton\nequation, which is more convenient for applications. The general theory is\nillustrated by the solution of the Newton equation for the case of the axially\nsymmetric condensate cloud, which expands after switching off a harmonic trap.\nThe validity of our approximate analytical approach is confirmed by comparison\nwith the results of numerical simulations of the Gross-Pitaevskii equation.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-02T05:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.01386v1","title":"DALIP: Distribution Alignment-based Language-Image Pre-Training for\n  Domain-Specific Data","summary":"Recently, Contrastive Language-Image Pre-training (CLIP) has shown promising\nperformance in domain-specific data (e.g., biology), and has attracted\nincreasing research attention. Existing works generally focus on collecting\nextensive domain-specific data and directly tuning the original CLIP models.\nIntuitively, such a paradigm takes no full consideration of the characteristics\nlying in domain-specific data (e.g., fine-grained nature of biological data)\nand so limits model capability, while mostly losing the original ability of\nCLIP in the general domain. In this paper, we propose a Distribution\nAlignment-based Language-Image Pre-Training (DALIP) method for biological data.\nSpecifically, DALIP optimizes CLIP models by matching the similarity between\nfeature distribution of image-text pairs instead of the original [cls] token,\nwhich can capture rich yet effective information inherent in image-text pairs\nas powerful representations, and so better cope with fine-grained nature of\nbiological data. Particularly, our DALIP efficiently approximates feature\ndistribution via its first- and second-order statistics, while presenting a\nMulti-head Brownian Distance Covariance (MBDC) module to acquire second-order\nstatistics of token features efficiently. Furthermore, we collect a new dataset\nfor plant domain (e.g., specific data in biological domain) comprising 10M\nplant data with 3M general-domain data (namely PlantMix-13M) according to data\nmixing laws. Extensive experiments show that DALIP clearly outperforms existing\nCLIP counterparts in biological domain, while well generalizing to remote\nsensing and medical imaging domains. Besides, our PlantMix-13M dataset further\nboosts performance of DALIP in plant domain, while preserving model ability in\ngeneral domain.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.01387v1","title":"Derived McKay correspondence for real reflection groups of rank three","summary":"We describe the derived McKay correspondence for real reflection groups of\nrank $3$ in terms of a maximal resolution of the logarithmic pair consisting of\nthe quotient variety and the discriminant divisor with coefficient\n$\\frac{1}{2}$. As an application, we verify a conjecture by Polishchuk and Van\nden Bergh on the existence of a certain semiorthgonal decomposition of the\nequivariant derived category into the derived categories of affine spaces for\nany real reflection group of rank $3$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T05:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01393v1","title":"Navigating the Uncharted Waters: A Gradual Approach to the Certification\n  and Integration of Maritime Autonomous Surface Ships (MASS) in Global\n  Maritime Operations","summary":"The integration of Maritime Autonomous Surface Ships (MASS) into global\nmaritime operations represents a transformative shift in the shipping industry,\npromising enhanced safety, efficiency, and cost-effectiveness. However, the\nwidespread adoption of autonomous ships necessitates a robust regulatory\nframework and rigorous certification processes to address the unique challenges\nposed by these advanced technologies. This paper proposes a gradual,\nmulti-stage approach to the certification and integration of MASS, beginning\nwith small-scale trials in controlled environments and progressing to\nlarge-scale international operations. Key considerations include the\ndevelopment of reliable control systems, cybersecurity measures, sensor\ntechnologies, and redundancy mechanisms to ensure safe and efficient\nnavigation. Additionally, the paper explores the economic and environmental\nimplications of autonomous shipping, as well as the evolving legal frameworks\nfor liability and compensation in the event of collisions. By adopting a\ncautious and methodical approach, the maritime industry can mitigate risks and\npave the way for the safe and sustainable integration of autonomous ships into\nglobal trade.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T06:19:21Z"}
{"aid":"http://arxiv.org/abs/2504.01396v1","title":"All Patches Matter, More Patches Better: Enhance AI-Generated Image\n  Detection via Panoptic Patch Learning","summary":"The exponential growth of AI-generated images (AIGIs) underscores the urgent\nneed for robust and generalizable detection methods. In this paper, we\nestablish two key principles for AIGI detection through systematic analysis:\n\\textbf{(1) All Patches Matter:} Unlike conventional image classification where\ndiscriminative features concentrate on object-centric regions, each patch in\nAIGIs inherently contains synthetic artifacts due to the uniform generation\nprocess, suggesting that every patch serves as an important artifact source for\ndetection. \\textbf{(2) More Patches Better}: Leveraging distributed artifacts\nacross more patches improves detection robustness by capturing complementary\nforensic evidence and reducing over-reliance on specific patches, thereby\nenhancing robustness and generalization. However, our counterfactual analysis\nreveals an undesirable phenomenon: naively trained detectors often exhibit a\n\\textbf{Few-Patch Bias}, discriminating between real and synthetic images based\non minority patches. We identify \\textbf{Lazy Learner} as the root cause:\ndetectors preferentially learn conspicuous artifacts in limited patches while\nneglecting broader artifact distributions. To address this bias, we propose the\n\\textbf{P}anoptic \\textbf{P}atch \\textbf{L}earning (PPL) framework, involving:\n(1) Random Patch Replacement that randomly substitutes synthetic patches with\nreal counterparts to compel models to identify artifacts in underutilized\nregions, encouraging the broader use of more patches; (2) Patch-wise\nContrastive Learning that enforces consistent discriminative capability across\nall patches, ensuring uniform utilization of all patches. Extensive experiments\nacross two different settings on several benchmarks verify the effectiveness of\nour approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T06:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.01400v1","title":"ToolACE-R: Tool Learning with Adaptive Self-Refinement","summary":"Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-02T06:38:56Z"}
{"aid":"http://arxiv.org/abs/2504.01402v1","title":"A Survey on Physics-based Differentiable Rendering","summary":"Physics-based differentiable rendering has emerged as a powerful technique in\ncomputer graphics and vision, with a broad range of applications in solving\ninverse rendering tasks. At its core, differentiable rendering enables the\ncomputation of gradients with respect to scene parameters, allowing\noptimization-based approaches to solve various problems. Over the past few\nyears, significant advancements have been made in both the underlying theory\nand the practical implementations of differentiable rendering algorithms. In\nthis report, we provide a comprehensive overview of the current state of the\nart in physics-based differentiable rendering, focusing on recent advances in\ngeneral differentiable rendering theory, Monte Carlo sampling strategy, and\ncomputational efficiency.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-02T06:39:50Z"}
{"aid":"http://arxiv.org/abs/2504.01417v1","title":"Hook fusion procedure for direct product of symmetric groups","summary":"In this work, we derive a new expression for the diagonal matrix elements of\nirreducible representations of the direct product group $S_r\\times S_s$ using\nGrime's hook fusion procedure for symmetric groups, which simplifies the fusion\nprocedure by reducing the number of auxiliary parameters needed. By extending\nthis approach to the product group setting, we provide a method for\nconstructing a complete set of orthogonal primitive idempotents.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T07:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.01423v1","title":"Dynamic Incentive Strategies for Smart EV Charging Stations: An\n  LLM-Driven User Digital Twin Approach","summary":"This paper presents an enhanced electric vehicle demand response system based\non large language models, aimed at optimizing the application of\nvehicle-to-grid technology. By leveraging an large language models-driven\nmulti-agent framework to construct user digital twins integrated with\nmultidimensional user profile features, it enables deep simulation and precise\nprediction of users' charging and discharging decision-making patterns.\nAdditionally, a data- and knowledge-driven dynamic incentive mechanism is\nproposed, combining a distributed optimization model under network constraints\nto optimize the grid-user interaction while ensuring both economic viability\nand security. Simulation results demonstrate that the approach significantly\nimproves load peak-valley regulation and charging/discharging strategies.\nExperimental validation highlights the system's substantial advantages in load\nbalancing, user satisfaction and grid stability, providing decision-makers with\na scalable V2G management tool that promotes the sustainable, synergistic\ndevelopment of vehicle-grid integration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T07:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.01429v1","title":"Refining Interactions: Enhancing Anisotropy in Graph Neural Networks\n  with Language Semantics","summary":"The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.01434v1","title":"Contribution of ALEGRO to the Update of the European Strategy on\n  Particle Physics","summary":"Advanced and novel accelerators (ANAs), driven a by laser pulse or a\nrelativistic particle bunch, have made remarkable progress over the last\ndecades. They accelerated electrons by 10GeV in 30cm (laser driven) and by\n42GeV in 85cm (particle bunch driven). Rapid progress continues with lasers,\nplasma sources, computational methods, and more. In this document we highlight\nthe main contributions made by the various major collaborations, facilities,\nand experiments that develop ANAs for applications to particle and high-energy\nphysics. These include: ALiVE, ANL-AWA, AWAKE, BNL-ATF, CEPC Injector,\nDESY-KALDERA, ELI ERIC, EuPRAXIA, HALHF, LBNL-BELLA, LBNL-kBELLA, LCvison,\nPETRA IV Injector, 10TeV Collider design, SLAC-FACET II, as well as the\ndevelopment of structures, lasers and plasma sources, and sustainability, and\ndemonstrate the intense activities in the field. ANAs can have, and already\nhave, applications to particle and high-energy physics as subsystems, the\nso-called intermediate applications: injectors, lower energy experiments, beam\ndump experiments, test beds for detectors, etc. Additionally, an ANA could be\nan upgrade for any Higgs factory based on a linear accelerator, as proposed in\nthe LCvison project. ANAs have advantages over other concepts for reaching\nmulti-TeV energies: lower geographical and environmental footprints, higher\nluminosity to power ratio, and are thus more sustainable than other\naccelerators. However, ANAs must still meet a number of challenges before they\ncan produce bunches with parameters and the luminosity required for a linear\ncollider at the energy frontier. It is therefore extremely important to\nstrongly support vigorous R&D of ANAs, because they are, at this time, the most\nsustainable acceleration scheme to reach very high energies with a linear\naccelerator.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-02T07:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.01438v1","title":"Precise Determination of Electric Quadrupole Moments and Isotope Shift\n  Constants of Yb$^+$ in Pursuance of Probing Fundamental Physics and Nuclear\n  Radii","summary":"Contemplating to register signature of a new vector boson unambiguously from\nthe measured non-linear isotope shift (IS) effects in three recent experiments\n[Phys. Rev. X {\\bf 12}, 021033 (2022); Phys. Rev. Lett. {\\bf 128}, 163201\n(2022) and Phys. Rev. Lett. {\\bf 134}, 063002 (2025)], very precise values of\nquadrupole moments and IS constants for the $6s ~ ^2S_{1/2} \\rightarrow 5d ~\n^2D_{3/2}$ and $6s ~ ^2S_{1/2} \\rightarrow 5d ~ ^2D_{5/2}$ clock transitions of\n$^{171}$Yb$^+$ are presented. This is accomplished by incorporating\ncontributions from the computationally challenging triply excited\nconfigurations through the relativistic coupled-cluster (RCC) theory. Testament\nof quality atomic wave functions of states of the above transitions, obtained\nusing the RCC theory, are gauged by comparing the calculated energies and\nmagnetic dipole hyperfine structure constants with their measurements. The\nimproved quadrupole moments from this work will be immensely useful to estimate\nquadrupole shifts of the clock transitions of Yb$^+$. Complementary approaches\nare employed to ascertain accuracy and comprehend roles of orbital relaxation\nand correlation effects in evaluating the IS constants. Combining these\nconstants with the IS measurements from Phys. Rev. Lett. {\\bf 128}, 163201\n(2022), differential nuclear charge radii of the Yb isotopes are inferred that\ndeviate by 6-7\\% from the literature data.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th,physics.comp-ph","published":"2025-04-02T07:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01459v1","title":"Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning","summary":"Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T08:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.01460v1","title":"K2: On Optimizing Distributed Transactions in a Multi-region Data Store\n  with TrueTime Clocks (Extended Version)","summary":"TrueTime clocks (TTCs) that offer accurate and reliable time within limited\nuncertainty bounds have been increasingly implemented in many clouds.\nMulti-region data stores that seek decentralized synchronization for high\nperformance represent an ideal application of TTC. However, the co-designs\nbetween the two were often undervalued or failed to realize their full\npotential.\n  This paper proposes K2, a multi-region data store that intensely explores the\nopportunity of using TTC for distributed transactions. Compared to its pioneer,\nGoogle Spanner, K2 augments TTC's semantics in three core design pillars.\nFirst, K2 carries a new timestamp-generating scheme that is capable of\nproviding a small time uncertainty bound at scale. Second, K2 revitalizes\nexisting multi-version timestamp-ordered concurrency control to realize\nmulti-version properties for read-write transactions. Third, K2 introduces a\nnew TTC-based visibility control protocol that provides efficient reads at\nreplicas. Our evaluation shows that, K2 achieves an order of magnitude higher\ntransaction throughput relative to other practical geo-distributed transaction\nprotocols while ensuring a lower visibility delay at asynchronous replicas.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.01464v1","title":"A Prefixed Patch Time Series Transformer for Two-Point Boundary Value\n  Problems in Three-Body Problems","summary":"Two-point boundary value problems for cislunar trajectories present\nsignificant challenges in circler restricted three body problem, making\ntraditional analytical methods like Lambert's problem inapplicable. This study\nproposes a novel approach using a prefixed patch time series Transformer model\nthat automates the solution of two-point boundary value problems from lunar\nflyby to arbitrary terminal conditions. Using prefix tokens of terminal\nconditions in our deep generative model enables solving boundary value problems\nin three-body dynamics. The training dataset consists of trajectories obtained\nthrough forward propagation rather than solving boundary value problems\ndirectly. The model demonstrates potential practical utility for preliminary\ntrajectory design in cislunar mission scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01471v1","title":"On the mean-field limit for the Vlasov-Poisson system","summary":"We present a probabilistic proof of the mean-field limit and propagation of\nchaos of a classical N-particle system in three dimensions with Coulomb\ninteraction force of the form $f^N(q)=\\pm\\frac{q}{|q|^3}$ and $N$-dependent\ncut-off at $|q|>N^{-\\frac{5}{12}+\\sigma}$ where $\\sigma>0$ can be chosen\narbitrarily small. This cut-off size is much smaller than the typical distance\nto the nearest neighbour. In particular, for typical initial data, we show\nconvergence of the Newtonian trajectories to the characteristics of the\nVlasov-Poisson system. The proof is based on a Gronwall estimate for the\nmaximal distance between the exact microscopic dynamics and the approximate\nmean-field dynamics. Thus our result leads to a derivation of the\nVlasov-Poisson equation from the microscopic $N$-particle dynamics with force\nterm arbitrary close to the physically relevant Coulomb force.","main_category":"math-ph","categories":"math-ph,math.DS,math.MP,physics.class-ph,G.3","published":"2025-04-02T08:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.01491v1","title":"How to Define the Quality of Data? A Feature-Based Literature Survey","summary":"The digital transformation of our society is a constant challenge, as data is\ngenerated in almost every digital interaction. To use data effectively, it must\nbe of high quality. This raises the question: what exactly is data quality? A\nsystematic literature review of the existing literature shows that data quality\nis a multifaceted concept, characterized by a number of quality dimensions.\nHowever, the definitions of data quality vary widely. We used feature-oriented\ndomain analysis to specify a taxonomy of data quality definitions and to\nclassify the existing definitions. This allows us to identify research gaps and\nfuture topics.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.01500v1","title":"The Polynomial Set Associated with a Fixed Number of Matrix-Matrix\n  Multiplications","summary":"We consider the problem of computing matrix polynomials $p(X)$, where $X$ is\na large matrix, with as few matrix-matrix multiplications as possible. More\nprecisely, let $ \\Pi_{2^{m}}^* $ represent the set of polynomials computable\nwith $m$ matrix-matrix multiplications, but with an arbitrary number of matrix\nadditions and scaling operations. We characterize this set through a tabular\nparameterization. By deriving equivalence transformations of the tabular\nrepresentation, we establish new methods that can be used to construct elements\nof $ \\Pi_{2^{m}}^* $ and determine general properties of the set. The\ntransformations allow us to eliminate variables and prove that the dimension is\nbounded by $m^2$. Numerical simulations suggest that this is a sharp bound.\nConsequently, we have identified a parameterization, which, to our knowledge,\nis the first minimal parameterization. Furthermore, we conduct a study using\ncomputational tools from algebraic geometry to determine the largest degree $d$\nsuch that all polynomials of that degree belong to $ \\Pi_{2^{m}}^* $, or its\nclosure. In many cases, the computational setup is constructive in the sense\nthat it can also be used to determine a specific evaluation scheme for a given\npolynomial.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.01501v1","title":"Vertex-Based Localization of Erdős-Gallai Theorems for Paths and\n  Cycles","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-02T08:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.01509v1","title":"PROPHET: An Inferable Future Forecasting Benchmark with Causal\n  Intervened Likelihood Estimation","summary":"Predicting future events stands as one of the ultimate aspirations of\nartificial intelligence. Recent advances in large language model (LLM)-based\nsystems have shown remarkable potential in forecasting future events, thereby\ngarnering significant interest in the research community. Currently, several\nbenchmarks have been established to evaluate the forecasting capabilities by\nformalizing the event prediction as a retrieval-augmented generation (RAG) and\nreasoning task. In these benchmarks, each prediction question is answered with\nrelevant retrieved news articles. However, because there is no consideration on\nwhether the questions can be supported by valid or sufficient supporting\nrationales, some of the questions in these benchmarks may be inherently\nnoninferable. To address this issue, we introduce a new benchmark, PROPHET,\nwhich comprises inferable forecasting questions paired with relevant news for\nretrieval. To ensure the inferability of the benchmark, we propose Causal\nIntervened Likelihood (CIL), a statistical measure that assesses inferability\nthrough causal inference. In constructing this benchmark, we first collected\nrecent trend forecasting questions and then filtered the data using CIL,\nresulting in an inferable benchmark for event prediction. Through extensive\nexperiments, we first demonstrate the validity of CIL and in-depth\ninvestigations into event prediction with the aid of CIL. Subsequently, we\nevaluate several representative prediction systems on PROPHET, drawing valuable\ninsights for future directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T08:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.01513v1","title":"Laser Annealing of Transparent ZnO Thin Films: A Route to Improve\n  Electrical Conductivity and Oxygen Sensing Capabilities","summary":"The chemical deposition of high-performance Zinc Oxide (ZnO) thin films is\nchallenging, thus significant efforts have been devoted during the past decades\nto develop cost-effective, scalable fabrication methods in gas phase. This work\ndemonstrates how ultra-short-pulse Laser Beam Scanning (LBS) can be used to\nmodulate electrical conductivity in ZnO thin films deposited on soda-lime glass\nby Spatial Atomic Layer Deposition (SALD), a high-throughput, low-temperature\ndeposition technique suitable for large-area applications. By systematically\noptimizing laser parameters, including pulse energy and hatching distance,\nsignificant improvements in the electrical performance of 90 nm-thick ZnO films\nwere achieved. The optimization of the laser annealing parameters, 0.21\nuJ/pulse energy and a 1 micron hatching distance, yielded ZnO films with an\nelectrical resistivity of (9 +- 2) 10-2 Ohm cm, 3 orders of magnitude lower\nthan as deposited films. This result suggests that laser\npost-deposition-processing can play an important role in tailoring the\nproperties of ZnO thin films. Excessive laser intensity can compromise\nstructural integrity of the films, however, degrading their electrical\ntransport properties. Notably, the electrical resistance of laser-annealed ZnO\nfilms exhibited high sensitivity to oxygen concentration in the surrounding\natmosphere, suggesting exciting prospects for application in devices based on\ntransparent oxygen sensors. This study thus positions ultra-short pulsed laser\nannealing as a versatile post-deposition method for fine-tuning the properties\nof ZnO thin films, enabling their use in advanced optoelectronic and\ngas-sensing technologies, particularly on temperature-sensitive substrates.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T09:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01515v1","title":"Training-free Dense-Aligned Diffusion Guidance for Modular Conditional\n  Image Synthesis","summary":"Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T09:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.01523v1","title":"Adapting Knowledge Prompt Tuning for Enhanced Automated Program Repair","summary":"Automated Program Repair (APR) aims to enhance software reliability by\nautomatically generating bug-fixing patches. Recent work has improved the\nstate-of-the-art of APR by fine-tuning pre-trained large language models\n(LLMs), such as CodeT5, for APR. However, the effectiveness of fine-tuning\nbecomes weakened in data scarcity scenarios, and data scarcity can be a common\nissue in practice, limiting fine-tuning performance. To alleviate this\nlimitation, this paper adapts prompt tuning for enhanced APR and conducts a\ncomprehensive study to evaluate its effectiveness in data scarcity scenarios,\nusing three LLMs of different sizes and six diverse datasets across four\nprogramming languages. Prompt tuning rewrites the input to a model by adding\nextra prompt tokens and tunes both the model and the prompts on a small\ndataset. These tokens provide task-specific knowledge that can improve the\nmodel for APR, which is especially critical in data scarcity scenarios.\nMoreover, domain knowledge has proven crucial in many code intelligence tasks,\nbut existing studies fail to leverage domain knowledge during the prompt tuning\nfor APR. To close this gap, we introduce knowledge prompt tuning, an approach\nthat adapts prompt tuning with six distinct types of code- or bug-related\ndomain knowledge for APR. Our work, to the best of our knowledge, is the first\nto adapt and evaluate prompt tuning and the effectiveness of code- or\nbug-related domain knowledge for APR, particularly under data scarcity\nsettings. Our evaluation results demonstrate that prompt tuning with knowledge\ngenerally outperforms fine-tuning under various experimental settings,\nachieving an average improvement of 87.33% over fine-tuning in data scarcity\nscenarios.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.01524v1","title":"On the limitations for causal inference in Cox models with time-varying\n  treatment","summary":"When using the Cox model to analyze the effect of a time-varying treatment on\na survival outcome, treatment is commonly included, using only the current\nlevel as a time-dependent covariate. Such a model does not necessarily assume\nthat past treatment is not associated with the outcome (the Markov property),\nsince it is possible to model the hazard conditional on only the current\ntreatment value. However, modeling the hazard conditional on the full treatment\nhistory is required in order to interpret the results causally, and such a full\nmodel assumes the Markov property when only including current treatment. This\nis, for example, common in marginal structural Cox models. We demonstrate that\nrelying on the Markov property is problematic, since it only holds in\nunrealistic settings or if the treatment has no causal effect. This is the case\neven if there are no confounders and the true causal effect of treatment really\nonly depends on its current level. Further, we provide an example of a scenario\nwhere the Markov property is not fulfilled, but the Cox model that includes\nonly current treatment as a covariate is correctly specified. Transforming the\nresult to the survival scale does not give the true intervention-specific\nsurvival probabilities, showcasing that it is unclear how to make causal\nstatements from such models.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T09:10:48Z"}
{"aid":"http://arxiv.org/abs/2504.01525v1","title":"Rapid Muon Tomography for Border Security","summary":"Cosmic-ray muon tomography is a promising technique for border security\napplications, leveraging highly penetrating cosmic-ray muons and their\ninteractions with various materials to generate 3D images of large and dense\nobjects, such as shipping containers. Using scattering and absorption of muons\nas they pass through dense cargo materials, muon tomography provides a viable\nsolution for customs and border security by enabling the verification of\nshipping container declarations and preventing illegal trafficking. In this\nstudy, we utilized Monte Carlo simulations to evaluate the effectiveness of\nmuon tomography for cargo characterization and contraband detection in various\nsmuggling scenarios. Our results demonstrate that muon tomography can offers a\nnovel approach to cargo inspection, moving beyond traditional 3D image\nreconstruction. Instead, it analyzes muon scattering and absorption rates in\nreal time during scanning, enabling the prompt detection of discrepancies\nbetween actual cargo contents and declared goods within just 10 to 20 seconds.\nThis method is particularly effective for cargo consisting of uniform loads\ncomposed of a single material or product, a common practice in shipping. Unlike\ntraditional X-ray radiography, which analyzes detailed 2D images, muon\ntomography begins evaluating scatter-absorption rates within the first few\nseconds of scanning. This early assessment enables cargo evaluation long before\na statistically reliable 3D image is formed, significantly improving scanning\nthroughput without disrupting trade flow.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-02T09:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.01530v1","title":"Predicting passenger injury distributions under uncertainty variables\n  using Gaussian process modeling with GHBMC","summary":"This work presents a Gaussian Process (GP) modeling method to predict\nstatistical characteristics of injury kinematics responses using Human Body\nModels (HBM) more accurately and efficiently. We validate the GHBMC model\nagainst a 50\\%tile male Post-Mortem Human Surrogate (PMHS) test. Using this\nvalidated model, we create various postured models and generate injury\nprediction data across different postures and personalized D-ring heights\nthrough parametric crash simulations. We then train the GP using this\nsimulation data, implementing a novel adaptive sampling approach to improve\naccuracy. The trained GP model demonstrates robustness by achieving target\nprediction accuracy at points with high uncertainty. The proposed method\nperforms continuous injury prediction for various crash scenarios using just 27\ncomputationally expensive simulation runs. This method can be effectively\napplied to designing highly reliable occupant restraint systems across diverse\ncrash conditions.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-02T09:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.01533v1","title":"LightDefense: A Lightweight Uncertainty-Driven Defense against\n  Jailbreaks via Shifted Token Distribution","summary":"Large Language Models (LLMs) face threats from jailbreak prompts. Existing\nmethods for defending against jailbreak attacks are primarily based on\nauxiliary models. These strategies, however, often require extensive data\ncollection or training. We propose LightDefense, a lightweight defense\nmechanism targeted at white-box models, which utilizes a safety-oriented\ndirection to adjust the probabilities of tokens in the vocabulary, making\nsafety disclaimers appear among the top tokens after sorting tokens by\nprobability in descending order. We further innovatively leverage LLM's\nuncertainty about prompts to measure their harmfulness and adaptively adjust\ndefense strength, effectively balancing safety and helpfulness. The\neffectiveness of LightDefense in defending against 5 attack methods across 2\ntarget LLMs, without compromising helpfulness to benign user queries,\nhighlights its potential as a novel and lightweight defense mechanism,\nenhancing security of LLMs.","main_category":"cs.CR","categories":"cs.CR,cs.CY","published":"2025-04-02T09:21:26Z"}
{"aid":"http://arxiv.org/abs/2504.01543v1","title":"Local Computation Algorithms for Knapsack: impossibility results, and\n  how to avoid them","summary":"Local Computation Algorithms (LCA), as introduced by Rubinfeld, Tamir, Vardi,\nand Xie (2011), are a type of ultra-efficient algorithms which, given access to\na (large) input for a given computational task, are required to provide fast\nquery access to a consistent output solution, without maintaining a state\nbetween queries. This paradigm of computation in particular allows for hugely\ndistributed algorithms, where independent instances of a given LCA provide\nconsistent access to a common output solution.\n  The past decade has seen a significant amount of work on LCAs, by and large\nfocusing on graph problems. In this paper, we initiate the study of Local\nComputation Algorithms for perhaps the archetypal combinatorial optimization\nproblem, Knapsack. We first establish strong impossibility results, ruling out\nthe existence of any non-trivial LCA for Knapsack as several of its\nrelaxations. We then show how equipping the LCA with additional access to the\nKnapsack instance, namely, weighted item sampling, allows one to circumvent\nthese impossibility results, and obtain sublinear-time and query LCAs. Our\npositive result draws on a connection to the recent notion of reproducibility\nfor learning algorithms (Impagliazzo, Lei, Pitassi, and Sorrell, 2022), a\nconnection we believe to be of independent interest for the design of LCAs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T09:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.01550v1","title":"Representation Bending for Large Language Model Safety","summary":"Large Language Models (LLMs) have emerged as powerful tools, but their\ninherent safety risks - ranging from harmful content generation to broader\nsocietal harms - pose significant challenges. These risks can be amplified by\nthe recent adversarial attacks, fine-tuning vulnerabilities, and the increasing\ndeployment of LLMs in high-stakes environments. Existing safety-enhancing\ntechniques, such as fine-tuning with human feedback or adversarial training,\nare still vulnerable as they address specific threats and often fail to\ngeneralize across unseen attacks, or require manual system-level defenses. This\npaper introduces RepBend, a novel approach that fundamentally disrupts the\nrepresentations underlying harmful behaviors in LLMs, offering a scalable\nsolution to enhance (potentially inherent) safety. RepBend brings the idea of\nactivation steering - simple vector arithmetic for steering model's behavior\nduring inference - to loss-based fine-tuning. Through extensive evaluation,\nRepBend achieves state-of-the-art performance, outperforming prior methods such\nas Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success\nrates across diverse jailbreak benchmarks, all with negligible reduction in\nmodel usability and general capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CR","published":"2025-04-02T09:47:01Z"}
{"aid":"http://arxiv.org/abs/2504.01552v1","title":"Identity-Based Language Shift Modeling","summary":"The preservation of endangered languages is a widely discussed issue\nnowadays. Languages represent essential cultural heritage and can provide\nvaluable botanical, biological, and geographical information. Therefore, it is\nnecessary to develop efficient measures to preserve and revitalize endangered\nlanguages. However, the language shift process is complex and requires an\ninterdisciplinary approach, including mathematical modeling techniques. This\npaper develops a new mathematical model that extends previous works on this\ntopic. We introduce the factor of ethnic identity, which is a proxy for a more\ncomplex nexus of variables involved in an individual's self-identity and/or a\ngroup's identity. This proxy is socially constructed rather than solely\ninherited, shaped by community-determined factors, with language both indexing\nand creating the identity. In our model, we divide speakers into groups\ndepending on with which language they identify themselves with. Moreover, every\ngroup includes monolinguals and bilinguals. The proposed model naturally allows\nus to consider cases of language coexistence and describe a broader class of\nlinguistic situations. For example, the simulation results show that our model\ncan result in cyclic language dynamics, drawing a parallel to cell population\nmodels. In this way, the proposed mathematical model can serve as a useful tool\nfor developing efficient measures for language preservation and revitalization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.NA,math.NA","published":"2025-04-02T09:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.01557v1","title":"FastER: Fast On-Demand Entity Resolution in Property Graphs","summary":"Entity resolution (ER) is the problem of identifying and linking database\nrecords that refer to the same real-world entity. Traditional ER methods use\nbatch processing, which becomes impractical with growing data volumes due to\nhigh computational costs and lack of real-time capabilities. In many\napplications, users need to resolve entities for only a small portion of their\ndata, making full data processing unnecessary -- a scenario known as\n\"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework\nfor property graphs. Our approach uses graph differential dependencies (GDDs)\nas a knowledge encoding language to design effective filtering mechanisms that\nleverage both structural and attribute semantics of graphs. We construct a\nblocking graph from filtered subgraphs to reduce the number of candidate entity\npairs requiring comparison. Additionally, FastER incorporates Progressive\nProfile Scheduling (PPS), allowing the system to incrementally produce results\nthroughout the resolution process. Extensive evaluations on multiple benchmark\ndatasets demonstrate that FastER significantly outperforms state-of-the-art ER\nmethods in computational efficiency and real-time processing for on-demand\ntasks while ensuring reliability. We make FastER publicly available at:\nhttps://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.01565v1","title":"Learning and criticality in a self-organizing model of connectome growth","summary":"The exploration of brain networks has reached an important milestone as\nrelatively large and reliable information has been gathered for connectomes of\ndifferent species. Analyses of connectome data sets reveal that the structural\nlength and the distributions of in- and out-node strengths follow heavy-tailed\nlognormal statistics, while the functional network properties exhibit powerlaw\ntails, suggesting that the brain operates close to a critical point where\ncomputational capabilities and sensitivity to stimulus is optimal. Because\nthese universal network features emerge from bottom-up (self-)organization, one\ncan pose the question of whether they can be modeled via a common framework,\nparticularly through the lens of criticality of statistical physical systems.\nHere, we simultaneously reproduce the powerlaw statistics of connectome edge\nweights and the lognormal distributions of node strengths from an\navalanche-type model with learning that operates on baseline networks that\nmimic the neuronal circuitry. We observe that the avalanches created by a\nsandpile-like model on simulated neurons connected by a hierarchical modular\nnetwork (HMN) produce robust powerlaw avalanche size distributions with\ncritical exponents of 3/2 characteristic of neuronal systems. Introducing\nHebbian learning, wherein neurons that `fire together, wire together,' recovers\nthe powerlaw distribution of edge weights and the lognormal distributions of\nnode degrees, comparable to those obtained from connectome data. Our results\nstrengthen the notion of a critical brain, one whose local interactions drive\nconnectivity and learning without a need for external intervention and precise\ntuning.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-02T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.01576v1","title":"Strong Nonlinear Flexoelectricity in Bulk Ferroelectrics","summary":"Flexoelectricity induced by strain gradient in dielectrics is highly\ndesirable for electromechanical actuating and sensing systems. It is broadly\nadopted that flexoelectric polarization responds linearly to strain gradient\nwithout considering nonlinearity. Consequently, the implication of nonlinear\nflexoelectricity in electromechanical systems remains unclear. Herein, we\nestablish a nonlinear constitutive model for flexoelectricity and thereby\npropose a strategy for quantitatively measuring its nonlinearity through the\nhigh-order harmonic generations. A strong nonlinear flexoelectricity in bulk\nferroelectrics is revealed and its coefficient is determined, as evidenced by\ntheir nonlinear dependence of harmonics on strain gradient. On this basis, we\nillustrate the nonlinear flexoelectricity manifests a functionality to\ntransduce mixed mechanical excitations into coherent electrical signals\nfeaturing difference- and sum-frequencies, thereby offering utilization in\nsignal processing for frequency conversion. These findings emphasize the\nsignificance of nonlinear flexoelectricity in ferroelectrics and open up new\nopportunities for designing electromechanical transducer based on nonlinear\nflexoelectricity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.01579v1","title":"Conditions for Unitarity in Timeless Quantum Theory","summary":"Quantum timeless approaches solve the problem of time by recovering the usual\nunitary evolution of quantum theory relative to a clock in a stationary quantum\nUniverse. For some Hamiltonians of the Universe, such as those including an\ninteraction term with the clock, the dynamics is substantially altered and can\nbe non-unitary. This work derives necessary and sufficient conditions for the\nrelative dynamics to be unitary and finds the general form of the unitary\nevolution operator. A physical interpretation of these conditions is given in\nterms of the clock's rate. Unitary dynamics is associated with rates that are\nconstant in time and independent of the clock's internal structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.01580v1","title":"The Basins Zoo","summary":"Research in multistable systems is a flourishing field with countless\nexamples and applications across scientific disciplines. I present a catalog of\nmultistable dynamical systems covering relevant fields of knowledge. This work\nis focused on providing a research tool to the community in the form classified\nexamples and computer code to reproduce basins of attraction. The companion\ncode to this article can be found at https://github.com/awage/BasinsCollection\nor https://doi.org/10.5281/zenodo.15124200.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-02T10:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.01582v1","title":"MERE: Hardware-Software Co-Design for Masking Cache Miss Latency in\n  Embedded Processors","summary":"Runahead execution is a technique to mask memory latency caused by irregular\nmemory accesses. By pre-executing the application code during occurrences of\nlong-latency operations and prefetching anticipated cache-missed data into the\ncache hierarchy, runahead effectively masks memory latency for subsequent cache\nmisses and achieves high prefetching accuracy; however, this technique has been\nlimited to superscalar out-of-order and superscalar in-order cores. For\nimplementation in scalar in-order cores, the challenges of\narea-/energy-constraint and severe cache contention remain.\n  Here, we build the first full-stack system featuring runahead, MERE, from SoC\nand a dedicated ISA to the OS and programming model. Through this deployment,\nwe show that enabling runahead in scalar in-order cores is possible, with\nminimal area and power overheads, while still achieving high performance. By\nre-constructing the sequential runahead employing a hardware/software co-design\napproach, the system can be implemented on a mature processor and SoC. Building\non this, an adaptive runahead mechanism is proposed to mitigate the severe\ncache contention in scalar in-order cores. Combining this, we provide a\ncomprehensive solution for embedded processors managing irregular workloads.\nOur evaluation demonstrates that the proposed MERE attains 93.5% of a 2-wide\nout-of-order core's performance while constraining area and power overheads\nbelow 5%, with the adaptive runahead mechanism delivering an additional 20.1%\nperformance gain through mitigating the severe cache contention issues.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T10:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.01583v1","title":"LL-Localizer: A Life-Long Localization System based on Dynamic i-Octree","summary":"This paper proposes an incremental voxel-based life-long localization method,\nLL-Localizer, which enables robots to localize robustly and accurately in\nmulti-session mode using prior maps. Meanwhile, considering that it is\ndifficult to be aware of changes in the environment in the prior map and robots\nmay traverse between mapped and unmapped areas during actual operation, we will\nupdate the map when needed according to the established strategies through\nincremental voxel map. Besides, to ensure high performance in real-time and\nfacilitate our map management, we utilize Dynamic i-Octree, an efficient\norganization of 3D points based on Dynamic Octree to load local map and update\nthe map during the robot's operation. The experiments show that our system can\nperform stable and accurate localization comparable to state-of-the-art LIO\nsystems. And even if the environment in the prior map changes or the robots\ntraverse between mapped and unmapped areas, our system can still maintain\nrobust and accurate localization without any distinction. Our demo can be found\non Blibili (https://www.bilibili.com/video/BV1faZHYCEkZ) and youtube\n(https://youtu.be/UWn7RCb9kA8) and the program will be available at\nhttps://github.com/M-Evanovic/LL-Localizer.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T10:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.01596v1","title":"DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and\n  RGB Image","summary":"Depth enhancement, which uses RGB images as guidance to convert raw signals\nfrom dToF into high-precision, dense depth maps, is a critical task in computer\nvision. Although existing super-resolution-based methods show promising results\non public datasets, they often rely on idealized assumptions like accurate\nregion correspondences and reliable dToF inputs, overlooking calibration errors\nthat cause misalignment and anomaly signals inherent to dToF imaging, limiting\nreal-world applicability. To address these challenges, we propose a novel\ncompletion-based method, named DEPTHOR, featuring advances in both the training\nstrategy and model architecture. First, we propose a method to simulate\nreal-world dToF data from the accurate ground truth in synthetic datasets to\nenable noise-robust training. Second, we design a novel network that\nincorporates monocular depth estimation (MDE), leveraging global depth\nrelationships and contextual information to improve prediction in challenging\nregions. On the ZJU-L5 dataset, our training strategy significantly enhances\ndepth completion models, achieving results comparable to depth super-resolution\nmethods, while our model achieves state-of-the-art results, improving Rel and\nRMSE by 27% and 18%, respectively. On a more challenging set of dToF samples we\ncollected, our method outperforms SOTA methods on preliminary stereo-based GT,\nimproving Rel and RMSE by 23% and 22%, respectively. Our Code is available at\nhttps://github.com/ShadowBbBb/Depthor","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T11:02:21Z"}
{"aid":"http://arxiv.org/abs/2504.01600v1","title":"Automatic Estimation of Pedestrian Gait Features using a single camera\n  recording: Algorithm and Statistical Analysis for Gender Difference and\n  Obstacle Interactions","summary":"The pedestrian gait features - body sway frequency, amplitude, stride length,\nand speed, along with pedestrian personal space and directional bias, are\nimportant parameters to be used in different pedestrian dynamics studies. Gait\nfeature measurements are paramount for wide-ranging applications, varying from\nthe medical field to the design of bridges. Personal space and choice of\ndirection (directional bias) play important roles during crowd simulations. In\nthis study, we formulate an automatic algorithm for calculating the gait\nfeatures of a trajectory extracted from video recorded using a single camera\nattached to the roof of a building. Our findings indicate that females have\n28.64% smaller sway amplitudes, 8.68% smaller stride lengths, and 8.14% slower\nspeeds compared to males, with no significant difference in frequency. However,\naccording to further investigation, our study reveals that the body parameters\nare the main variables that dominate gait features rather than gender. We have\nconducted three experiments in which the volunteers are walking towards the\ndestination a) without any obstruction, b) with a stationary non-living\nobstacle present in the middle of the path, and c) with a human being standing\nin the middle of the path. From a comprehensive statistical analysis, key\nobservations include no significant difference in gait features with respect to\ngender, no significant difference in gait features in the absence or presence\nof an obstacle, pedestrians treating stationary human beings and stationary\nobstacles the same given that the gender is same to match the comfort level,\nand a directional bias towards the left direction, likely influenced by\nleft-hand traffic rule in India.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T11:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01612v1","title":"The Mini-SiTian Array: first-two-year operation","summary":"The SiTian project, designed to utilize 60 telescopes distributed across\nmultiple sites in China, is a next-generation time-domain survey initiative. As\na pathfinder for the SiTian project, the Mini-SiTian (MST) has been proposed\nand implemented to test the SiTian's brain and data pipeline, and to evaluate\nthe feasibility of its technology and science cases. Mounted at the Xinglong\nObservatory, the MST project comprises three 30 cm telescopes and has been\noperated since Nov. 2022. Each telescope of the MST possesses a large field of\nview, covering $2.29^{\\circ}$ $\\times$ $1.53^{\\circ}$ FOV, and is equipped with\n$g'$, $r'$ and $i'$ filters, respectively. Acting as the pioneer of the\nforthcoming SiTian project, the MST is dedicated to the discovery of variable\nstars, transients, and outburst events, and has already obtained some\ninteresting scientific results. In this paper, we will summarize the\nfirst-two-year operation of the MST project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:07Z"}
{"aid":"http://arxiv.org/abs/2504.01613v1","title":"The Mini-SiTian Array: Design and application of Master Control System","summary":"The SiTian Project represents a groundbreaking initiative in astronomy,\naiming to deploy a global network of telescopes, each with a 1-meter aperture,\nfor comprehensive time-domain sky surveys. The network's innovative\narchitecture features multiple observational nodes, each comprising three\nstrategically aligned telescopes equipped with filters. This design enables\nthree-color (g, r, i) channel imaging within each node, facilitating precise\nand coordinated observations. As a pathfinder to the full-scale project, the\nMini-SiTian Project serves as the scientific and technological validation\nplatform, utilizing three 30-centimeter aperture telescopes to validate the\nmethodologies and technologies planned for the broader SiTian network. This\npaper focuses on the development and implementation of the Master Control\nSystem (MCS),and the central command hub for the Mini-SiTian array. The MCS is\ndesigned to facilitate seamless communication with the SiTian Brain, the\nproject's central processing and decision-making unit, while ensuring accurate\ntask allocation, real-time status monitoring, and optimized observational\nworkflows. The system adopts a robust architecture that separates front-end and\nback-end functionalities.A key innovation of the MCS is its ability to\ndynamically adjust observation plans in response to transient source alerts,\nenabling rapid and coordinated scans of target sky regions...(abridged)","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.01616v1","title":"The Mini-SiTian Array: Imaging Processing Pipeline","summary":"As a pathfinder of the SiTian project, the Mini-SiTian (MST) array, employed\nthree commercial CMOS cameras, represents a next-generation, cost-effective\noptical time-domain survey project. This paper focuses primarily on the precise\ndata processing pipeline designed for wide-field, CMOS-based devices, including\nthe removal of instrumental effects, astrometry, photometry, and flux\ncalibration. When applying this pipeline to approximately 3000 observations\ntaken in the Field 02 (f02) region by MST, the results demonstrate a remarkable\nastrometric precision of approximately 70--80\\,mas (about 0.1\\,pixel), an\nimpressive calibration accuracy of approximately 1\\,mmag in the MST zero\npoints, and a photometric accuracy of about 4\\,mmag for bright stars. Our\nstudies demonstrate that MST CMOS can achieve photometric accuracy comparable\nto that of CCDs, highlighting the feasibility of large-scale CMOS-based optical\ntime-domain surveys and their potential applications for cost optimization in\nfuture large-scale time-domain surveys, like the SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA,astro-ph.SR","published":"2025-04-02T11:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.01618v1","title":"The Mini-SiTian Array: Optical design","summary":"Time-domain astronomy is one of the most important areas. Large sky area,\ndeep-field, and short timescale are the priority of time-domain observations.\nSiTian is an ambitious ground-based project processing all sky optical\nmonitoring, aiming for sky-survey timescale of less than 1 day. It is developed\nby the Chinese Academy of Sciences, an integrated network of dozens of\n1-m-class telescopes deployed worldwide. The Mini-SiTian Telescope Array is\ncarried out for demonstrations on optical design, group scheduling, and\nsoftware pipeline developments, to overcome the high technical and financial\ndifficulties of SiTian project. One array contains three 300 mm F/3 telescope,\nwith FOV of 5 degrees over 400-1000 nm wavelength range. The Mini-SiTian\nTelescope Array is now under commissioning in Xinglong Observatory, and a\nperfect platform for technical research and educational purposes.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:36Z"}
{"aid":"http://arxiv.org/abs/2504.01637v1","title":"LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach","summary":"Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-02T11:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.01638v1","title":"Convex Computations for Controlled Safety Invariant Sets of Black-box\n  Discrete-time Dynamical Systems","summary":"Identifying controlled safety invariant sets (CSISs) is essential in\nsafety-critical applications. This paper tackles the problem of identifying\nCSISs for black-box discrete-time systems, where the model is unknown and only\nlimited simulation data is accessible. Traditionally, a CSIS is defined as a\nsubset of a safe set, encompassing initial states for which a control input\nexists that keeps the system within the set at the next time step-this is\nreferred to as the one-step invariance property. However, the requirement for\none-step invariance can be equivalently translated into a stricter condition of\n``always-invariance'', meaning that there exist control inputs capable of\nkeeping the system within this set indefinitely. Such a condition may prove\noverly stringent or impractical for black-box systems, where predictions can\nbecome unreliable beyond a single time step or a limited number of finite time\nsteps. To overcome the challenges posed by black-box systems, we reformulate\nthe one-step invariance property in a ``Probably Approximately Correct'' (PAC)\nsense. This approach allows us to assess the probability that a control input\nexists to keep the system within the CSIS at the next time step, with a\npredefined level of confidence. If the system successfully remains within the\nset at the next time step, we can then reapply the invariance evaluation to the\nnew state, thereby facilitating a recursive assurance of invariance. Our method\nemploys barrier functions and scenario optimization, resulting in a linear\nprogramming method to estimate PAC CSISs. Finally, the effectiveness of our\napproach is demonstrated on several examples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T11:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.01655v1","title":"Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive\n  Instruction Tuning","summary":"The rapid advancement of Large Multi-modal Foundation Models (LMM) has paved\nthe way for the possible Explainable Image Quality Assessment (EIQA) with\ninstruction tuning from two perspectives: overall quality explanation, and\nattribute-wise perception answering. However, existing works usually overlooked\nthe conflicts between these two types of perception explanations during joint\ninstruction tuning, leading to insufficient perception understanding. To\nmitigate this, we propose a new paradigm for perception-oriented instruction\ntuning, i.e., Q-Adapt, which aims to eliminate the conflicts and achieve the\nsynergy between these two EIQA tasks when adapting LMM, resulting in enhanced\nmulti-faceted explanations of IQA. Particularly, we propose a progressive\ninstruction tuning strategy by dividing the adaption process of LMM for EIQA\ninto two stages, where the first stage empowers the LMM with universal\nperception knowledge tailored for two tasks using an efficient transfer\nlearning strategy, i.e., LoRA, and the second stage introduces the\ninstruction-adaptive visual prompt tuning to dynamically adapt visual features\nfor the different instructions from two tasks. In this way, our proposed\nQ-Adapt can achieve a lightweight visual quality evaluator, demonstrating\ncomparable performance and, in some instances, superior results across\nperceptual-related benchmarks and commonly-used IQA databases. The source code\nis publicly available at https://github.com/yeppp27/Q-Adapt.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-02T12:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.01665v1","title":"On products of sets of natural density one","summary":"In a previous work, Bettin, Koukoulopoulos, and Sanna prove that if two sets\nof natural numbers $A$ and $B$ have natural density $1$, then their product set\n$A \\cdot B := \\{ab : a \\in A, b \\in B\\}$ also has natural density $1$. They\nalso provide an effective rate and pose the question of determining the optimal\nrate. We make progress on this question by constructing a set $A$ of density 1\nsuch that $A\\cdot A$ has a ''large'' complement.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T12:15:22Z"}
{"aid":"http://arxiv.org/abs/2504.01676v1","title":"Satellite Edge Artificial Intelligence with Large Models: Architectures\n  and Technologies","summary":"Driven by the growing demand for intelligent remote sensing applications,\nlarge artificial intelligence (AI) models pre-trained on large-scale unlabeled\ndatasets and fine-tuned for downstream tasks have significantly improved\nlearning performance for various downstream tasks due to their generalization\ncapabilities. However, many specific downstream tasks, such as extreme weather\nnowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield\nsurveillance, require real-time data processing. Traditional methods via\ntransferring raw data to ground stations for processing often cause significant\nissues in terms of latency and trustworthiness. To address these challenges,\nsatellite edge AI provides a paradigm shift from ground-based to on-board data\nprocessing by leveraging the integrated communication-and-computation\ncapabilities in space computing power networks (Space-CPN), thereby enhancing\nthe timeliness, effectiveness, and trustworthiness for remote sensing\ndownstream tasks. Moreover, satellite edge large AI model (LAM) involves both\nthe training (i.e., fine-tuning) and inference phases, where a key challenge\nlies in developing computation task decomposition principles to support\nscalable LAM deployment in resource-constrained space networks with\ntime-varying topologies. In this article, we first propose a satellite\nfederated fine-tuning architecture to split and deploy the modules of LAM over\nspace and ground networks for efficient LAM fine-tuning. We then introduce a\nmicroservice-empowered satellite edge LAM inference architecture that\nvirtualizes LAM components into lightweight microservices tailored for\nmulti-task multimodal inference. Finally, we discuss the future directions for\nenhancing the efficiency and scalability of satellite edge LAM, including\ntask-oriented communication, brain-inspired computing, and satellite edge AI\nnetwork optimization.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI,eess.SP","published":"2025-04-02T12:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.01680v1","title":"Arbitrary gauge quantisation of light-matter theories with\n  time-dependent constraints","summary":"We provide a general framework for the quantisation of light-matter theories\nwith time-dependent holonomic constraints. Unless time dependence is present\nfrom the outset at the Lagrangian level, different gauges generally produce\nnon-equivalent canonical theories. The irrotational gauge is defined as that\nwhich also yields a correct theory when time dependence is introduced at the\nHamiltonian level. We unify examples of such gauges found in existing\nliterature. In particular, we show that for describing time-dependent\nlight-matter interactions the Coulomb gauge is not generally irrotational, so\nit does not enjoy any special status, contradicting the conclusions in Phys.\nRev. A 107, 013722 (2023) and Phys. Rev. Research 3, 023079 (2021), while\nreaffirming the prior treatment and conclusions reported in Phys. Rev. Research\n3, 013116 (2021).","main_category":"quant-ph","categories":"quant-ph,cond-mat.supr-con,hep-th,physics.atom-ph,physics.optics","published":"2025-04-02T12:27:00Z"}
{"aid":"http://arxiv.org/abs/2504.01692v1","title":"Segmentation variability and radiomics stability for predicting\n  Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging","summary":"Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-04-02T12:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01703v1","title":"Computable Bounds on the Solution to Poisson's Equation for General\n  Harris Chains","summary":"Poisson's equation is fundamental to the study of Markov chains, and arises\nin connection with martingale representations and central limit theorems for\nadditive functionals, perturbation theory for stationary distributions, and\naverage reward Markov decision process problems. In this paper, we develop a\nnew probabilistic representation for the solution of Poisson's equation, and\nuse Lyapunov functions to bound this solution representation explicitly. In\ncontrast to most prior work on this problem, our bounds are computable. Our\ncontribution is closely connected to recent work of Herve and Ledoux (2025), in\nwhich they focus their study on a special class of Harris chains satisfying a\nparticular small set condition. However, our theory covers general Harris\nchains, and often provides a tighter bound. In addition to the new bound and\nrepresentation, we also develop a computable uniform bound on marginal\nexpectations for Harris chains, and a computable bound on the potential kernel\nrepresentation of the solution to Poisson's equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-02T13:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.01707v1","title":"InfiniteICL: Breaking the Limit of Context Window Size via Long\n  Short-term Memory Transformation","summary":"In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T13:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.01712v1","title":"Method for Mitigating Attention to Inappropriate Content Based on\n  Attention Dynamics Model","summary":"The expansion of the attention economy has led to the growing issue of\ninappropriate content being posted by profit-driven users. Previous\ncountermeasures against inappropriate content have relied on moderation, which\nraises ethical concerns, or information diffusion control, which requires\nconsidering larger scale networks, including general users. This study proposes\nan imitation strategy as an intervention method that does not rely on\nmoderation and focuses on a relatively smaller scale competitive network of\ninformation disseminators rather than the entire social network. The imitation\nstrategy is a novel approach that utilizes increased competition among\ninformation disseminators through imitation to reduce attention to\ninappropriate content. Through theoretical analysis and numerical simulations,\nI demonstrate that the imitation strategy is more effective when nodes with\nhigher eigenvector centrality are selected as targets and nodes with lower\neigenvector centrality are chosen as imitators.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-02T13:20:25Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01723v1","title":"Analytical Framework of Orbital Angular Momentum Beam in Misaligned\n  Detection","summary":"This work provides an analytical framework to model the detected orbital\nangular momentum (OAM) spectrum of an optical beam in the presence of tilt and\nlateral displacement in the impinging beam. We show how both tilt and\ndisplacement cause OAM sidebands following the same function, with both having\ntheir characteristic adimensional parameter related to the size and wavelength\nof the beam. We see how an increase in topological charge on the beam causes\nwider detected OAM distribution. Finally, we show how, in the case of both tilt\nand lateral displacement, we can tune the amount of OAM mode in the original\nmode by having a perpendicular direction for the tilt and off-axis\ndisplacement, causing the misalignment errors to interfere destructively.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.01727v1","title":"Acoustic Propagation/Refraction Through Diffuse Interface Models","summary":"We present a novel approach for simulating acoustic (pressure) wave\npropagation across different media separated by a diffuse interface through the\nuse of a weak compressibility formulation. Our method builds on our previous\nwork on an entropy-stable discontinuous Galerkin spectral element method for\nthe incompressible Navier-Stokes/Cahn-Hilliard system\n\\cite{manzanero2020entropyNSCH}, and incorporates a modified weak\ncompressibility formulation that allows different sound speeds in each phase.\nWe validate our method through numerical experiments, demonstrating spectral\nconvergence for acoustic transmission and reflection coefficients in one\ndimension and for the angle defined by Snell's law in two dimensions. Special\nattention is given to quantifying the modeling errors introduced by the width\nof the diffuse interface. Our results show that the method successfully\ncaptures the behavior of acoustic waves across interfaces, allowing exponential\nconvergence in transmitted waves. The transmitted angles in two dimensions are\naccurately captured for air-water conditions, up to the critical angle of\n$13^\\circ$. This work represents a step forward in modeling acoustic\npropagation in incompressible multiphase systems, with potential applications\nto marine aeroacoustics.","main_category":"math.NA","categories":"math.NA,cs.NA,physics.comp-ph,physics.flu-dyn","published":"2025-04-02T13:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.01730v1","title":"AI-Driven Framework for Multi-Service Multi-Modal Devices in NextG ORAN\n  Systems","summary":"In this paper, an artificial intelligence (AI)-driven efficient RAN\nmanagement framework is proposed. This framework introduces the concept of a\nintroducing the multi-service-modal UE (MSMU) system, which allows a single UE\nto handle both eMBB and uRLLC services. The proposed framework integrates\ntraffic demand prediction, route optimization, RAN slicing, service\nidentification, and radio resource management under uncertainty. The challenge\nof dynamic environments in such a system is addressed by decomposing the\noptimization problem into long-term (L-SP) and short-term (S-SP) subproblems.\nUsing a long short-term memory (LSTM) model, the proposed approach allows the\nprediction of eMBB and uRLLC traffic demands and optimal routes for RAN slicing\nin the L-SP. For the S-SP, another LSTM model is employed to handle real-time\nservice type identification and resource management based on long-term\npredictions. To support continuous adaptation, continual learning is\nincorporated into the S-SP framework, allowing the model to learn new service\ntypes while retaining prior knowledge. Experimental results show that the\nproposed framework efficiently manages dual-mode UEs, achieving low mean square\nerror for traffic demand (0.003), resource block prediction (0.003), and power\nprediction (0.002), with 99\\% accuracy in service type and route selection and\nover 95\\% average accuracy for continual service adaptation across seven tasks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T13:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.01732v1","title":"FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D\n  Scene Reconstruction and Benchmarking","summary":"The development of large-scale 3D scene reconstruction and novel view\nsynthesis methods mostly rely on datasets comprising perspective images with\nnarrow fields of view (FoV). While effective for small-scale scenes, these\ndatasets require large image sets and extensive structure-from-motion (SfM)\nprocessing, limiting scalability. To address this, we introduce a fisheye image\ndataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye\nlenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoor\nscenes. Each scene has sparse SfM point clouds and precise LIDAR-derived dense\npoint clouds that can be used as geometric ground-truth, enabling robust\nbenchmarking under challenging conditions such as occlusions and reflections.\nWhile the baseline experiments focus on vanilla Gaussian Splatting and NeRF\nbased Nerfacto methods, the dataset supports diverse approaches for scene\nreconstruction, novel view synthesis, and image-based rendering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.01736v1","title":"Design and Experimental Validation of an Urban Microclimate Tool\n  Integrating Indoor-Outdoor Detailed Longwave Radiative Fluxes at District\n  Scale","summary":"Numerical simulation is a powerful tool for assessing the causes of an Urban\nHeat Island (UHI) effect or quantifying the impact of mitigation solutions on\noutdoor and indoor thermal comfort. For that purpose, several models have been\ndeveloped at the district scale. At this scale, the outside surface energy\nbudget is detailed, however building models are very simplified and considered\nas a boundary condition of the district scale model. This shortcoming inhibits\nthe opportunity to investigate the effect of urban microclimate on the inside\nbuilding conditions. The aim of this work is to improve the representation of\nthe physical phenomena involved in the building models of a district model. For\nthat purpose, the model integrates inside and outside fully detailed long-wave\nradiative flux. The numerical model is based on finite differences to solve\nconduction through all the surfaces and the radiosity method to solve long-wave\nradiative heat fluxes inside and outside. Calculated temperatures and heat\nfluxes are evaluated with respect to \\textit{in situ} measurements from an\nexperimental demonstrator over 14 sensors and a 24-day period. Results are also\ncompared to state-of-the-art models simulation tool show improvement of the\nRMSE of $0.9 \\ \\mathsf{^{\\,\\circ}C}$ to $2.1 \\ \\mathsf{^{\\,\\circ}C}$ on the\nsurface temperature modeled.","main_category":"cs.CE","categories":"cs.CE,I.6","published":"2025-04-02T13:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.01739v1","title":"Understanding Cross-Model Perceptual Invariances Through Ensemble\n  Metamers","summary":"Understanding the perceptual invariances of artificial neural networks is\nessential for improving explainability and aligning models with human vision.\nMetamers - stimuli that are physically distinct yet produce identical neural\nactivations - serve as a valuable tool for investigating these invariances. We\nintroduce a novel approach to metamer generation by leveraging ensembles of\nartificial neural networks, capturing shared representational subspaces across\ndiverse architectures, including convolutional neural networks and vision\ntransformers. To characterize the properties of the generated metamers, we\nemploy a suite of image-based metrics that assess factors such as semantic\nfidelity and naturalness. Our findings show that convolutional neural networks\ngenerate more recognizable and human-like metamers, while vision transformers\nproduce realistic but less transferable metamers, highlighting the impact of\narchitectural biases on representational invariances.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.01765v1","title":"Existence and dimensional lower bound for the global attractor of a PDE\n  model for ant trail formation","summary":"We study the asymptotic behavior of a nonlinear PDE model for ant trail\nformation, which was introduced in [3]. We establish the existence of a compact\nglobal attractor and prove the nonlinear instability of the homogeneous steady\nstate under an inviscid instability condition. We also provide a dimensional\nlower bound on the attractor. Alternatively, we prove that if the interaction\nparameter is sufficiently small, the homogeneous steady state is globally\nasymptotically stable.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T14:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01771v1","title":"Enhancing Interpretability in Generative AI Through Search-Based Data\n  Influence Analysis","summary":"Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-02T14:29:37Z"}
{"aid":"http://arxiv.org/abs/2504.01800v1","title":"Motility and rotation of multi-timescale microswimmers in linear\n  background flows","summary":"Microswimming cells and robots exhibit diverse behaviours due to both their\nswimming and their environment. One of the core environmental features\nimpacting inertialess swimming is background flows. While the influence of\nselect flows, particularly shear flows, have been extensively investigated,\nthese are special cases. Here, we examine inertialess swimmers in more general\nflows, specifically general linear planar flows that may also possess rapid\noscillations. Relatively weak symmetry constraints are imposed on the swimmer\nto ensure planarity and to reduce complexity. A further constraint reflecting\ncommon observation is imposed, namely that the swimmer is inefficient, which we\nsuitably define. This introduces two separate timescales: a fast timescale\nassociated with swimmer actuation, and a second timescale associated with net\nswimmer movement, with inefficiency dictating that this latter timescale is\nmuch slower, allowing for a multiple timescale simplification of the governing\nequations. With the exception of mathematically precise edge cases, we find\nthat the behaviour of the swimmer is dictated by two parameter groupings, both\nof which measure balances between the angular velocity and rate of strain of\nthe background flow. While the measures of flow angular velocity and strain\nrates that primarily govern the rotational dynamics are modulated by swimmer\nproperties, the primary features of the translational motion are determined\nsolely by a ratio of flow angular velocity to strain rate. Hence, a simple\nclassification of the swimmer dynamics emerges. For example, this illustrates\nthe limited extent to which, and how, microswimmers may control their\norientations and trajectories in flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T15:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.01807v1","title":"Barrier Certificates for Unknown Systems with Latent States and\n  Polynomial Dynamics using Bayesian Inference","summary":"Certifying safety in dynamical systems is crucial, but barrier certificates -\nwidely used to verify that system trajectories remain within a safe region -\ntypically require explicit system models. When dynamics are unknown,\ndata-driven methods can be used instead, yet obtaining a valid certificate\nrequires rigorous uncertainty quantification. For this purpose, existing\nmethods usually rely on full-state measurements, limiting their applicability.\nThis paper proposes a novel approach for synthesizing barrier certificates for\nunknown systems with latent states and polynomial dynamics. A Bayesian\nframework is employed, where a prior in state-space representation is updated\nusing input-output data via a targeted marginal Metropolis-Hastings sampler.\nThe resulting samples are used to construct a candidate barrier certificate\nthrough a sum-of-squares program. It is shown that if the candidate satisfies\nthe required conditions on a test set of additional samples, it is also valid\nfor the true, unknown system with high probability. The approach and its\nprobabilistic guarantees are illustrated through a numerical simulation.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,stat.ML","published":"2025-04-02T15:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.01809v1","title":"Detector Response to Gravitational Wave Polarizations in Gravitational\n  Quantum Field Theory","summary":"We present an analysis of gravitational wave polarization modes within\nGravitational Quantum Field Theory (GQFT), a unified theoretical framework\nreconciling general relativity and quantum field theory. Our study focuses on\nfive fundamental polarization states predicted in GQFT: two tensor ($+,\n\\times$), two vector (x, y), and one scalar (breathing) mode, focusing on their\ndistinctive detection signatures in space-based interferometers like LISA and\nTaiji. Using first-order orbital dynamics in the Solar System Barycenter frame,\nwe identify three novel observational features: (1) characteristic interference\npatterns between polarization modes, (2) distinctive null-point signatures\nenabling mode discrimination, and (3) sky-position-dependent optimal detection\nwindows. Our approach provides complete sky coverage through polarization\nmapping while remaining fully compatible with existing mission designs, notably\navoiding the need for challenging direct breathing-mode measurements. The\nresults are presented through comprehensive sky maps, offering both theoretical\ninsights into gravitational wave polarization and practical tools for future\ndetector networks. This work establishes a new paradigm for testing fundamental\ngravity theories through their unique polarization fingerprints, with\nparticular relevance for upcoming multi-messenger gravitational wave astronomy.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-02T15:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.01810v1","title":"Parametrized scissors congruence $K$-theory of manifolds and cobordism\n  categories","summary":"We construct a parametrized version of scissors congruence $K$-theory of\nmanifolds, which in particular gives a topologized version of the scissors\ncongruence $K$-theory of oriented manifolds, and we describe this spectrum as\nmediating between the cobordism category and usual algebraic $K$-theory of\nspaces. We show that on $\\pi_0$, the scissors congruence $K$-theory of oriented\nmanifolds agrees with a version of the cobordism category where we allow free\nboundaries.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-04-02T15:16:00Z"}
{"aid":"http://arxiv.org/abs/2504.01816v1","title":"Random Phase Approximation Correlation Energy using Real-Space Density\n  Functional Perturbation Theory","summary":"We present a real-space method for computing the random phase approximation\n(RPA) correlation energy within Kohn-Sham density functional theory, leveraging\nthe low-rank nature of the frequency-dependent density response operator. In\nparticular, we employ a cubic scaling formalism based on density functional\nperturbation theory that circumvents the calculation of the response function\nmatrix, instead relying on the ability to compute its product with a vector\nthrough the solution of the associated Sternheimer linear systems. We develop a\nlarge-scale parallel implementation of this formalism using the subspace\niteration method in conjunction with the spectral quadrature method, while\nemploying the Kronecker product-based method for the application of the Coulomb\noperator and the conjugate orthogonal conjugate gradient method for the\nsolution of the linear systems. We demonstrate convergence with respect to key\nparameters and verify the method's accuracy by comparing with planewave\nresults. We show that the framework achieves good strong scaling to many\nthousands of processors, reducing the time to solution for a lithium hydride\nsystem with 128 electrons to around 150 seconds on 4608 processors.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-02T15:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.01825v1","title":"How the microphysical properties of external photoevaporation influence\n  the global evolution of protoplanetary discs","summary":"External photoevaporation is one of the dominant mechanisms for mass loss\nfrom protoplanetary discs. However this mass loss is theoretically expected to\ndepend upon the microphysical properties of protoplanetary discs, which are\ncurrently poorly constrained in observations. In this work we explore the\nimpact of microphysics on the bulk evolution of discs. The polycyclic aromatic\nhydrocarbon (PAH) abundance, and the extent to which grain growth has occurred\nin the disc have profound effects on the strength of mass loss rates due to\nexternal photoevaporation, which in turn can have a significant impact on the\ndisc evolution, impacting disc radii and accretion rates over time. The\nstrongest sensitivity is to whether grain growth has occurred in the disc,\nwhich reduces the amount of dust entrained in the wind to shield the disc, thus\nincreasing the rate at which gas is lost. Additionally, larger PAH abundances\nresult in stronger heating and higher mass loss rates, but to a lesser extent\nthan grain growth. We find that plausible variations in the PAH abundance and\ndisc dust evolution can leave observable differences in disc populations. This\nwork highlights the importance of obtaining observational constraints of the\nmicrophysical properties of protoplanetary discs. Future observations from JWST\nshould soon be able to provide these constraints.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T15:30:58Z"}
{"aid":"http://arxiv.org/abs/2504.01835v1","title":"Autonomous optical navigation for DESTINY+: Enhancing misalignment\n  robustness in flyby observations with a rotating telescope","summary":"DESTINY+ is an upcoming JAXA Epsilon medium-class mission to flyby multiple\nasteroids including Phaethon. As an asteroid flyby observation instrument, a\ntelescope mechanically capable of single-axis rotation, named TCAP, is mounted\non the spacecraft to track and observe the target asteroids during flyby. As in\npast flyby missions utilizing rotating telescopes, TCAP is also used as a\nnavigation camera for autonomous optical navigation during the closest-approach\nphase. To mitigate the degradation of the navigation accuracy, past missions\nperformed calibration of the navigation camera's alignment before starting\noptical navigation. However, such calibration requires significant operational\ntime to complete and imposes constraints on the operation sequence. From the\nabove background, the DESTINY+ team has studied the possibility of reducing\noperational costs by allowing TCAP alignment errors to remain. This paper\ndescribes an autonomous optical navigation algorithm robust to the misalignment\nof rotating telescopes, proposed in this context. In the proposed method, the\nmisalignment of the telescope is estimated simultaneously with the spacecraft's\norbit relative to the flyby target. To deal with the nonlinearity between the\nmisalignment and the observation value, the proposed method utilizes the\nunscented Kalman filter, instead of the extended Kalman filter widely used in\npast studies. The proposed method was evaluated with numerical simulations on a\nPC and with hardware-in-the-loop simulation, taking the Phaethon flyby in the\nDESTINY+ mission as an example. The validation results suggest that the\nproposed method can mitigate the misalignment-induced degradation of the\noptical navigation accuracy with reasonable computational costs suited for\nonboard computers.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.LG","published":"2025-04-02T15:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.01844v1","title":"BOGausS: Better Optimized Gaussian Splatting","summary":"3D Gaussian Splatting (3DGS) proposes an efficient solution for novel view\nsynthesis. Its framework provides fast and high-fidelity rendering. Although\nless complex than other solutions such as Neural Radiance Fields (NeRF), there\nare still some challenges building smaller models without sacrificing quality.\nIn this study, we perform a careful analysis of 3DGS training process and\npropose a new optimization methodology. Our Better Optimized Gaussian Splatting\n(BOGausS) solution is able to generate models up to ten times lighter than the\noriginal 3DGS with no quality degradation, thus significantly boosting the\nperformance of Gaussian Splatting compared to the state of the art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:49:23Z"}
{"aid":"http://arxiv.org/abs/2504.01851v1","title":"Virtual Target Trajectory Prediction for Stochastic Targets","summary":"Trajectory prediction of other vehicles is crucial for autonomous vehicles,\nwith applications from missile guidance to UAV collision avoidance. Typically,\ntarget trajectories are assumed deterministic, but real-world aerial vehicles\nexhibit stochastic behavior, such as evasive maneuvers or gliders circling in\nthermals. This paper uses Conditional Normalizing Flows, an unsupervised\nMachine Learning technique, to learn and predict the stochastic behavior of\ntargets of guided missiles using trajectory data. The trained model predicts\nthe distribution of future target positions based on initial conditions and\nparameters of the dynamics. Samples from this distribution are clustered using\na time series k-means algorithm to generate representative trajectories, termed\nvirtual targets. The method is fast and target-agnostic, requiring only\ntraining data in the form of target trajectories. Thus, it serves as a drop-in\nreplacement for deterministic trajectory predictions in guidance laws and path\nplanning. Simulated scenarios demonstrate the approach's effectiveness for\naerial vehicles with random maneuvers, bridging the gap between deterministic\npredictions and stochastic reality, advancing guidance and control algorithms\nfor autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T16:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.01879v1","title":"TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving\n  Semi-structured Tables","summary":"Humans continuously make new discoveries, and understanding temporal sequence\nof events leading to these breakthroughs is essential for advancing science and\nsociety. This ability to reason over time allows us to identify future steps\nand understand the effects of financial and political decisions on our lives.\nHowever, large language models (LLMs) are typically trained on static datasets,\nlimiting their ability to perform effective temporal reasoning. To assess the\ntemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES\ndataset, which comprises 3,971 questions derived from over 14,000 tables,\nspanning 1,238 entities across multiple time periods. We introduce a\ntemplate-based question-generation pipeline that harnesses LLMs to refine both\ntemplates and questions. Additionally, we establish baseline results using\nstate-of-the-art LLMs to create a benchmark. We also introduce novel modeling\nstrategies centered around task decomposition, enhancing LLM performance.","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.IR","published":"2025-04-02T16:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.01880v1","title":"Partition function zeros of quantum many-body systems","summary":"We present a method for calculating the Yang-Lee partition function zeros of\na translationally invariant model of lattice fermions, exemplified by the\nHubbard model. The method rests on a theorem involving the single electron\nself-energy $\\Sigma_\\sigma(k, i \\omega_n)$ in the imaginary time Matsubara\nformulation. The theorem maps the Yang-Lee zeros to a set of wavevector and\nspin labeled virtual energies $\\xi_{k \\sigma}$. These, thermodynamically\nderived virtual energies, are solutions of equations involving the self-energy\nat corresponding $k\\sigma$'s. Examples of the method in simplified situations\nare provided.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-02T16:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.01885v1","title":"Observing Spatial Charge and Spin Correlations in a Strongly-Interacting\n  Fermi Gas","summary":"Two-dimensional correlated fermions constitute a cornerstone of quantum\nmatter, covering a broad fundamental and technological scope, and have\nattracted increasing interest with the emergence of modern materials such as\nhigh-$T_{\\rm c}$ superconductors, graphene, topological insulators, and Moir\\'e\nstructures. Atom-based quantum simulators provide a new pathway to understand\nthe microscopic mechanisms occurring at the heart of such systems. In this\nwork, we explore two-dimensional attractive Fermi gases at the microscopic\nlevel by probing spatial charge and spin correlations in situ. Using\natom-resolved continuum quantum gas microscopy, we directly observe fermion\npairing and study the evolution of two- and three-point correlation functions\nas inter-spin attraction is increased. The precision of our measurement allows\nus to reveal a marked dip in the pair correlation function, fundamentally\nforbidden by the mean-field result based on Bardeen-Cooper-Schrieffer (BCS)\ntheory but whose existence we confirm in exact auxiliary-field quantum Monte\nCarlo calculations. We demonstrate that the BCS prediction is critically\ndeficient not only in the superfluid crossover regime but also deep in the\nweakly attractive side. Guided by our measurements, we find a remarkable\nrelation between two- and three-point correlations that establishes the\ndominant role of pair-correlations. Finally, leveraging local single-pair\nlosses, we independently characterize the short-range behavior of pair\ncorrelations, via the measurement of Tan's Contact, and find excellent\nagreement with numerical predictions. Our measurements provide an unprecedented\nmicroscopic view into two-dimensional Fermi gases and constitute a paradigm\nshift for future studies of strongly-correlated fermionic matter in the\ncontinuum.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-02T16:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.01886v1","title":"GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical\n  Reasoning","summary":"Recent advances in general medical AI have made significant strides, but\nexisting models often lack the reasoning capabilities needed for complex\nmedical decision-making. This paper presents GMAI-VL-R1, a multimodal medical\nreasoning model enhanced by reinforcement learning (RL) to improve its\nreasoning abilities. Through iterative training, GMAI-VL-R1 optimizes\ndecision-making, significantly boosting diagnostic accuracy and clinical\nsupport. We also develop a reasoning data synthesis method, generating\nstep-by-step reasoning data via rejection sampling, which further enhances the\nmodel's generalization. Experimental results show that after RL training,\nGMAI-VL-R1 excels in tasks such as medical image diagnosis and visual question\nanswering. While the model demonstrates basic memorization with supervised\nfine-tuning, RL is crucial for true generalization. Our work establishes new\nevaluation benchmarks and paves the way for future advancements in medical\nreasoning models. Code, data, and model will be released at\n\\href{https://github.com/uni-medical/GMAI-VL-R1}{this link}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T16:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.01892v1","title":"Synchro-curvature description of γ-ray light curves and spectra\n  of pulsars: concurrent fitting","summary":"We present a concurrent fitting of spectra and light curves of the whole\npopulation of detected gamma-ray pulsars. Using a synchro-curvature model we\ncompare our theoretical output with the observational data published in the\nThird Fermi Pulsar Catalog, which has significantly increased the number of\nknown gamma-ray pulsars. Our model properly fits all the spectra and reproduces\nwell a considerable fraction of light curves. Light curve fitting is carried\nout with two different techniques, whose strong points and caveats are\ndiscussed. We use a weighted reduced \\{chi}^2 of light curves in time domain,\nand the Euclidean distance of the Fourier transform of the light curves, i.e.\ntransforming the light curves to the frequency domain. The performance of both\nmethods is found to be qualitatively similar, but individual best-fit solutions\nmay differ. We also show that, in our model based on few effective parameters,\nthe light curve fitting is basically insensitive to the timing and spectral\nparameters of the pulsar. Finally, we look for correlations between model and\nphysical parameters, and recover trends found in previous studies but without\nany significant correlation involving geometrical parameters.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-02T16:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.01893v1","title":"A minimal Pati-Salam theory: from cosmic defects to gravitational waves\n  and colliders","summary":"We discuss a minimal renormalizable Pati-Salam theory based on the\n$SU(4)_{\\rm C}\\,\\times\\,SU(2)_{\\rm L}\\,\\times\\,SU(2)_{\\rm R}$ gauge group, with\nunification scale Higgs multiplets taken as $SU(2)_{\\rm L}$ and $SU(2)_{\\rm R}$\ndoublets, which lead to neutrino Dirac picture. Although a number of scalar\nparticles could be light, even lying at the LHC energies, the unification scale\nis hopelessly out of reach in any foreseeable future. Moreover, phase\ntransition in the early Universe leads to the production of magnetic monopoles\nand domain walls, both incompatible with the standard cosmological model. A\nsmall explicit breaking of the discrete left-right symmetry allows the domain\nwalls to decay, and in the process possibly sweep away the monopoles,\nanalogously to the previously discussed case of $SU(5)$ grand unified theory.\nThis leaves an important imprint of gravitational waves, within the reach of\nnext generation searches, correlated with monopole detection and new light\nparticles at collider energies. The theory has a dark matter candidate in the\nform of an inert scalar doublet, with a mass below TeV, which can further\ntrigger electroweak baryogenesis.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,hep-ex","published":"2025-04-02T16:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.01903v1","title":"STAR-1: Safer Alignment of Reasoning LLMs with 1K Data","summary":"This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.01908v1","title":"Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation\n  Framework","summary":"Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T17:10:30Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01923v1","title":"Sliding Dynamics of Skyrmion Molecular Crystals","summary":"Using both atomistic and particle-based simulations, we investigate the\ncurrent-driven dynamics of skyrmions on two-dimensional periodic substrates\nwhen there are multiple skyrmions per substrate minimum. At zero drive, the\nsystem forms pinned skyrmion molecular crystal states consisting of dimers,\ntrimers, or dimer-trimer mixtures that have both positional and orientational\norder. On a square substrate lattice, the motion above depinning occurs via a\nrunning soliton that travels completely transverse to the applied current. This\nmotion is generated by a torque from the Magnus force, which rotates the\n$n$-mer states perpendicular to the applied current. At higher drives, the flow\nbecomes disordered while the Hall angle diminishes and gradually approaches the\nintrinsic value. In some cases, we also find directional locking where the Hall\nangle becomes locked to certain symmetry directions of the substrate over a\nrange of currents. The transitions into and out of directionally locked states\nare accompanied by negative differential mobility in which the net velocity\ndecreases as the drive increases. On a triangular substrate, we find no\ntransverse mobility effects, but still observe directionally locked motion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T17:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.01925v1","title":"Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution\n  Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time","summary":"Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T17:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.01934v1","title":"ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and\n  Diffusion Refinement","summary":"We present ILLUME+ that leverages dual visual tokenization and a diffusion\ndecoder to improve both deep semantic understanding and high-fidelity image\ngeneration. Existing unified models have struggled to simultaneously handle the\nthree fundamental capabilities in a unified model: understanding, generation,\nand editing. Models like Chameleon and EMU3 utilize VQGAN for image\ndiscretization, due to the lack of deep semantic interaction, they lag behind\nspecialist models like LLaVA in visual understanding tasks. To mitigate this,\nLaViT and ILLUME employ semantic encoders for tokenization, but they struggle\nwith image editing due to poor texture preservation. Meanwhile, Janus series\ndecouples the input and output image representation, limiting their abilities\nto seamlessly handle interleaved image-text understanding and generation. In\ncontrast, ILLUME+ introduces a unified dual visual tokenizer, DualViTok, which\npreserves both fine-grained textures and text-aligned semantics while enabling\na coarse-to-fine image representation strategy for multimodal understanding and\ngeneration. Additionally, we employ a diffusion model as the image detokenizer\nfor enhanced generation quality and efficient super-resolution. ILLUME+ follows\na continuous-input, discrete-output scheme within the unified MLLM and adopts a\nprogressive training procedure that supports dynamic resolution across the\nvision tokenizer, MLLM, and diffusion decoder. This design allows for flexible\nand efficient context-aware image editing and generation across diverse tasks.\nILLUME+ (3B) exhibits competitive performance against existing unified MLLMs\nand specialized models across multimodal understanding, generation, and editing\nbenchmarks. With its strong performance, ILLUME+ provides a scalable and\nversatile foundation for future multimodal applications. Project Page:\nhttps://illume-unified-mllm.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.01944v1","title":"Graphon games and an idealized limit of large network games","summary":"Graphon games are a class of games with a continuum of agents, introduced to\napproximate the strategic interactions in large network games. The first result\nof this study is an equilibrium existence theorem in graphon games, under the\nsame conditions as those in network games. We prove the existence of an\nequilibrium in a graphon game with an infinite-dimensional strategy space,\nunder the continuity and quasi-concavity of the utility functions. The second\nresult characterizes Nash equilibria in graphon games as the limit points of\nasymptotic Nash equilibria in large network games. If a sequence of large\nnetwork games converges to a graphon game, any convergent sequence of\nasymptotic Nash equilibria in these large network games also converges to a\nNash equilibrium of the graphon game. In addition, for any graphon game and its\nequilibrium, there exists a sequence of large network games that converges to\nthe graphon game and has asymptotic Nash equilibria converging to the\nequilibrium. These results suggest that the concept of a graphon game is an\nidealized limit of large network games as the number of players tends to\ninfinity.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.01950v1","title":"Nucleon scattering from lattice QCD","summary":"Recent results from lattice QCD on baryon resonances and meson-baryon,\nbaryon-baryon scattering are presented. Such scattering processes and\nresonances can be determined in lattice QCD by first obtaining the\nfinite-volume energy spectrum of stationary states involving meson-baryon and\nbaryon-baryon systems. A well-known quantization condition involving the\nscattering $K$-matrix and a complicated ``box matrix'' also yields a\nfinite-volume energy spectrum. By appropriately parametrizing the scattering\n$K$-matrix, the best fit values of the $K$-matrix parameters are those which\nproduce a finite-volume spectrum which best matches that obtained from lattice\nQCD. The $\\Delta$ resonance, a recent study of the two-pole nature of\nscattering near the $\\Lambda(1405)$, and $NN$ scattering in the $SU(3)$ flavor\nlimit are highlighted.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T17:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.01952v1","title":"Image Difference Grounding with Natural Language","summary":"Visual grounding (VG) typically focuses on locating regions of interest\nwithin an image using natural language, and most existing VG methods are\nlimited to single-image interpretations. This limits their applicability in\nreal-world scenarios like automatic surveillance, where detecting subtle but\nmeaningful visual differences across multiple images is crucial. Besides,\nprevious work on image difference understanding (IDU) has either focused on\ndetecting all change regions without cross-modal text guidance, or on providing\ncoarse-grained descriptions of differences. Therefore, to push towards\nfiner-grained vision-language perception, we propose Image Difference Grounding\n(IDG), a task designed to precisely localize visual differences based on user\ninstructions. We introduce DiffGround, a large-scale and high-quality dataset\nfor IDG, containing image pairs with diverse visual variations along with\ninstructions querying fine-grained differences. Besides, we present a baseline\nmodel for IDG, DiffTracker, which effectively integrates feature differential\nenhancement and common suppression to precisely locate differences. Experiments\non the DiffGround dataset highlight the importance of our IDG dataset in\nenabling finer-grained IDU. To foster future research, both DiffGround data and\nDiffTracker model will be publicly released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.01954v1","title":"Towards Unified Referring Expression Segmentation Across Omni-Level\n  Visual Target Granularities","summary":"Referring expression segmentation (RES) aims at segmenting the entities'\nmasks that match the descriptive language expression. While traditional RES\nmethods primarily address object-level grounding, real-world scenarios demand a\nmore versatile framework that can handle multiple levels of target granularity,\nsuch as multi-object, single object or part-level references. This introduces\ngreat challenges due to the diverse and nuanced ways users describe targets.\nHowever, existing datasets and models mainly focus on designing grounding\nspecialists for object-level target localization, lacking the necessary data\nresources and unified frameworks for the more practical multi-grained RES. In\nthis paper, we take a step further towards visual granularity unified RES task.\nTo overcome the limitation of data scarcity, we introduce a new\nmulti-granularity referring expression segmentation (MRES) task, alongside the\nRefCOCOm benchmark, which includes part-level annotations for advancing\nfiner-grained visual understanding. In addition, we create MRES-32M, the\nlargest visual grounding dataset, comprising over 32.2M masks and captions\nacross 1M images, specifically designed for part-level vision-language\ngrounding. To tackle the challenges of multi-granularity RES, we propose\nUniRES++, a unified multimodal large language model that integrates\nobject-level and part-level RES tasks. UniRES++ incorporates targeted designs\nfor fine-grained visual feature exploration. With the joint model architecture\nand parameters, UniRES++ achieves state-of-the-art performance across multiple\nbenchmarks, including RefCOCOm for MRES, gRefCOCO for generalized RES, and\nRefCOCO, RefCOCO+, RefCOCOg for classic RES. To foster future research into\nmulti-grained visual grounding, our RefCOCOm benchmark, MRES-32M dataset and\nmodel UniRES++ will be publicly available at\nhttps://github.com/Rubics-Xuan/MRES.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:05Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.02223v1","title":"Motivic homotopy theory with ramification filtrations","summary":"The aim of this paper is to connect two important and apparently unrelated\ntheories: motivic homotopy theory and ramification theory. We construct motivic\nhomotopy categories over a qcqs base scheme $S$, in which cohomology theories\nwith ramification filtrations are representable. Every such cohomology theory\nenjoys basic properties such as the Nisnevich descent, the cube-invariance, the\nblow-up invariance, the smooth blow-up excision, the Gysin sequence, the\nprojective bundle formula and the Thom isomorphism. In case $S$ is the spectrum\nof a perfect field, the cohomology of every reciprocity sheaf is upgraded to a\ncohomology theory with a ramification filtration represented in our categories.\nWe also address relations of our theory with other non-$\\mathbb{A}^1$-invariant\nmotivic homotopy theories such as the logarithmic motivic homotopy theory of\nBinda, Park, and {\\O}stv{\\ae}r and the theory of motivic spectra of\nAnnala-Iwasa.","main_category":"math.AG","categories":"math.AG,math.KT","published":"2025-04-03T02:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02246v1","title":"C*: Unifying Programming and Verification in C","summary":"Ensuring the correct functionality of systems software, given its\nsafety-critical and low-level nature, is a primary focus in formal verification\nresearch and applications. Despite advances in verification tooling,\nconventional programmers are rarely involved in the verification of their own\ncode, resulting in higher development and maintenance costs for verified\nsoftware. A key barrier to programmer participation in verification practices\nis the disconnect of environments and paradigms between programming and\nverification practices, which limits accessibility and real-time verification.\n  We introduce C*, a proof-integrated language design for C programming. C*\nextends C with verification capabilities, powered by a symbolic execution\nengine and an LCF-style proof kernel. It enables real-time verification by\nallowing programmers to embed proof-code blocks alongside implementation code,\nfacilitating interactive updates to the current proof state. Its expressive and\nextensible proof support allows users to build reusable libraries of logical\ndefinitions, theorems, and programmable proof automation. Crucially, C* unifies\nimplementation and proof code development by using C as the common language.\n  We implemented a prototype of C* and evaluated it on a representative\nbenchmark of small C programs and a challenging real-world case study: the\nattach function of pKVM's buddy allocator. Our results demonstrate that C*\nsupports the verification of a broad subset of C programming idioms and\neffectively handles complex reasoning tasks in real-world scenarios.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-03T03:22:22Z"}
{"aid":"http://arxiv.org/abs/2504.02249v1","title":"Stock Price Prediction Using Triple Barrier Labeling and Raw OHLCV Data:\n  Evidence from Korean Markets","summary":"This paper demonstrates that deep learning models trained on raw OHLCV\n(open-high-low-close-volume) data can achieve comparable performance to\ntraditional machine learning models using technical indicators for stock price\nprediction in Korean markets. While previous studies have emphasized the\nimportance of technical indicators and feature engineering, we show that a\nsimple LSTM network trained on raw OHLCV data alone can match the performance\nof sophisticated ML models that incorporate technical indicators. Using a\ndataset of Korean stocks from 2006 to 2024, we optimize the triple barrier\nlabeling parameters to achieve balanced label proportions with a 29-day window\nand 9\\% barriers. Our experiments reveal that LSTM networks achieve similar\nperformance to traditional machine learning models like XGBoost, despite using\nonly raw OHLCV data without any technical indicators. Furthermore, we identify\nthat the optimal window size varies with model hidden size, with a\nconfiguration of window size 100 and hidden size 8 yielding the best\nperformance. Additionally, our results confirm that using full OHLCV data\nprovides better predictive accuracy compared to using only close price or close\nprice with volume. These findings challenge conventional approaches to feature\nengineering in financial forecasting and suggest that simpler approaches\nfocusing on raw data and appropriate model selection may be more effective than\ncomplex feature engineering strategies.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T03:30:50Z"}
{"aid":"http://arxiv.org/abs/2504.02253v1","title":"On energy-momentum tensor for gravitational waves in $f(R)$ gravity","summary":"The classical Isaacson's procedure for describing back-reaction of the\naveraged energy-momentum for high frequency gravitational waves is generalized\nto $f(R)$ gravity case. From the beginning it is assumed that an initial\nbackground could be arbitrary one. By next steps it is restricted to de Sitter\nspace that is a novelty for the study of a back-reaction in $f(R)$ gravity.\nConsideration of the de Sitter space as a background spacetime allows us to\nprovide the averaging procedure completely. Using the results on the de Sitter\nspace and generalizing the Isaacson procedure, we construct the averaged\nenergy-momentum on an additionally curved (averaged) background. Relations of\nparameters, which preserve the de Sitter picture, and which disturb it are\ngiven. Our results generalize results of previous authors who use flat\n(Minkowski) spacetime as the beginning background in $f(R)$ gravity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T03:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.02276v1","title":"Distortion from spheres into Euclidean space","summary":"Any function from a round $n$-dimensional sphere of radius $r$ into\n$n$-dimensional Euclidean space must distort the metric additively by at least\n$\\frac{2\\pi r}{2 + \\sqrt{3-2/n}}$. This is proved using a fixed-point theorem\nof Granas that generalizes the classical theorem of Borsuk--Ulam to set-valued\nfunctions.","main_category":"math.MG","categories":"math.MG,math.GN","published":"2025-04-03T04:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.02284v1","title":"Non-perturbative heavy quark diffusion coefficients in a weakly\n  magnetized thermal QCD medium","summary":"In this work, the perturbative and non-perturbative contributions to the\nheavy quark (HQ) momentum ($\\kappa$) as well as spatial ($D_s$) diffusion\ncoefficients are computed in a weak background magnetic field. The formalism\nadopted here involves calculation of the in-medium potential of the HQ in a\nweak magnetic field, which then serves as a proxy for the resummed gluon\npropagator in the calculation of HQ self-energy ($\\Sigma$). The self-energy\ndetermines the scattering rate of HQs with light thermal partons, which is\nsubsequently used to evaluate $\\kappa$ and $D_s$. It is observed that\nnon-perturbative effects play a dominant role at low temperature. The spatial\ndiffusion coefficient $2\\pi T D_s$, exhibits good agreement with recent LQCD\nresults. These findings can be applied to calculate the heavy quark directed\nflow at RHIC and LHC energies. An extension of this formalism to the case of\nfinite HQ momentum has also been attempted.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T05:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.02286v1","title":"Moment Quantization for Video Temporal Grounding","summary":"Video temporal grounding is a critical video understanding task, which aims\nto localize moments relevant to a language description. The challenge of this\ntask lies in distinguishing relevant and irrelevant moments. Previous methods\nfocused on learning continuous features exhibit weak differentiation between\nforeground and background features. In this paper, we propose a novel\nMoment-Quantization based Video Temporal Grounding method (MQVTG), which\nquantizes the input video into various discrete vectors to enhance the\ndiscrimination between relevant and irrelevant moments. Specifically, MQVTG\nmaintains a learnable moment codebook, where each video moment matches a\ncodeword. Considering the visual diversity, i.e., various visual expressions\nfor the same moment, MQVTG treats moment-codeword matching as a clustering\nprocess without using discrete vectors, avoiding the loss of useful information\nfrom direct hard quantization. Additionally, we employ effective\nprior-initialization and joint-projection strategies to enhance the maintained\nmoment codebook. With its simple implementation, the proposed method can be\nintegrated into existing temporal grounding models as a plug-and-play\ncomponent. Extensive experiments on six popular benchmarks demonstrate the\neffectiveness and generalizability of MQVTG, significantly outperforming\nstate-of-the-art methods. Further qualitative analysis shows that our method\neffectively groups relevant features and separates irrelevant ones, aligning\nwith our goal of enhancing discrimination.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:21:14Z"}
{"aid":"http://arxiv.org/abs/2504.02295v1","title":"Dynamical Mordell-Lang problem for automorphisms of surfaces in positive\n  characteristic","summary":"We solve the dynamical Mordell-Lang problem in positive characteristic for\nautomorphisms of projective surfaces.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-03T05:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.02301v1","title":"Synchronization in bus systems with partially overlapping routes","summary":"In an increasingly interconnected world, understanding congestion-related\nphenomena in transportation and their underlying mechanisms is crucial for\nimproving efficiency. As the transportation system becomes denser, different\nmodes of transportation have more opportunities to interact with each other,\ngiving rise to emergent dynamics that simple models cannot explain. In this\nstudy, we investigate the synchronized motion of indirectly coupled\ntransportation modes. We develop a numerical simulation model on a\none-dimensional periodic lattice, where each point represents a bus station. In\nthis system, two types of buses operate: multiple local buses with\nnon-overlapping routes, each serving a specific zone, and a single global bus\nthat partially overlaps with the routes of the local buses. We perform\nnumerical simulations to examine how close the arrival times of these buses are\nto each other -- that is, how synchronized their motions are. When the number\nof zones is two, three, or five, robust synchronization occurs not only between\nthe global bus and the local buses, but also among the local buses themselves.\nIn contrast, no synchronization is found for other numbers of zones. We\ndeveloped a mathematical model using self-consistent equations and found that\ntwo distinct arrival patterns at the terminals must be considered. A stability\nanalysis reveals which pattern is ultimately realized in the simulations. Our\nresults show that transportation modes can exhibit coherent motion even when\nsharing only partial or no direct route overlaps. This outcome highlights that\nemergent behavior depends not only on local interactions but is also strongly\nshaped by the system's overall structural configuration.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-03T06:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.02306v1","title":"Lepton emission rates of 43-64V isotopes under stellar conditions","summary":"In astrophysical conditions prevalent during the late times of stellar\nevolution, lepton ($e^-$ and $e^+$) emission processes compete with the\ncorresponding lepton capture processes. Prior to the collapse, lepton emissions\nsignificantly affect the cooling of the core and reduce its entropy. Therefore,\nthe lepton emission rates for Fe-group nuclei serve as an important input for\ncore-collapse simulations of high-mass stars.\n  From earlier simulation studies, isotopes of vanadium (V) have great\nastrophysical significance in regard to their weak-decay rates, which\nsubstantially affect $Y_e$ (fraction of lepton to baryon number) during the\nfinal developmental stages of massive stars. The current study involves the\ncomputation of the weak lepton emission (LE) rates for V isotopes by employing\nthe improved deformed proton-neutron Quasi-particle Random Phase Approximation\n(pn-QRPA) model. The mass numbers of the selected isotopes range from 43 to 64.\nThe LE rates on these isotopes have been estimated for a broad spectrum of\ndensity and temperature under astrophysical conditions. The ranges considered\nfor density and temperature are $10^1$ to $10^{11}$ (g/cm$^3$) and $10^7$ to $3\n\\times 10^{11}$ (K), respectively.\n  The lepton emission rates from the present study were also compared to the\nrates previously estimated by using the independent-particle model (IPM) and\nlarge-scale shell model (LSSM). IPM rates are generally bigger than QRPA rates,\nwhile LSSM rates overall show a good comparison with the reported rates.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.02309v1","title":"A sharp upper bound for the number of connected sets in any grid graph","summary":"A connected set in a graph is a subset of vertices whose induced subgraph is\nconnected. Although counting the number of connected sets in a graph is\ngenerally a \\#P-complete problem, it remains an active area of research. In\n2020, Vince posed the problem of finding a formula for the number of connected\nsets in the $(n\\times n)$-grid graph. In this paper, we establish a sharp upper\nbound for the number of connected sets in any grid graph by using multistep\nrecurrence formulas, which further derives enumeration formulas for the numbers\nof connected sets in $(3\\times n)$- and $(4\\times n)$-grid graphs, thus solving\na special case of the general problem posed by Vince. In the process, we also\ndetermine the number of connected sets of $K_{m}\\times P_{n}$ by employing the\ntransfer matrix method, where $K_{m}\\times P_{n}$ is the Cartesian product of\nthe complete graph of order $m$ and the path of order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T06:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.02310v1","title":"Improving Harmful Text Detection with Joint Retrieval and External\n  Knowledge","summary":"Harmful text detection has become a crucial task in the development and\ndeployment of large language models, especially as AI-generated content\ncontinues to expand across digital platforms. This study proposes a joint\nretrieval framework that integrates pre-trained language models with knowledge\ngraphs to improve the accuracy and robustness of harmful text detection.\nExperimental results demonstrate that the joint retrieval approach\nsignificantly outperforms single-model baselines, particularly in low-resource\ntraining scenarios and multilingual environments. The proposed method\neffectively captures nuanced harmful content by leveraging external contextual\ninformation, addressing the limitations of traditional detection models. Future\nresearch should focus on optimizing computational efficiency, enhancing model\ninterpretability, and expanding multimodal detection capabilities to better\ntackle evolving harmful content patterns. This work contributes to the\nadvancement of AI safety, ensuring more trustworthy and reliable content\nmoderation systems.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:37:55Z"}
{"aid":"http://arxiv.org/abs/2504.02316v1","title":"ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D\n  Generation","summary":"Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.02318v1","title":"X-Capture: An Open-Source Portable Device for Multi-Sensory Learning","summary":"Understanding objects through multiple sensory modalities is fundamental to\nhuman perception, enabling cross-sensory integration and richer comprehension.\nFor AI and robotic systems to replicate this ability, access to diverse,\nhigh-quality multi-sensory data is critical. Existing datasets are often\nlimited by their focus on controlled environments, simulated objects, or\nrestricted modality pairings. We introduce X-Capture, an open-source, portable,\nand cost-effective device for real-world multi-sensory data collection, capable\nof capturing correlated RGBD images, tactile readings, and impact audio. With a\nbuild cost under $1,000, X-Capture democratizes the creation of multi-sensory\ndatasets, requiring only consumer-grade tools for assembly. Using X-Capture, we\ncurate a sample dataset of 3,000 total points on 500 everyday objects from\ndiverse, real-world environments, offering both richness and variety. Our\nexperiments demonstrate the value of both the quantity and the sensory breadth\nof our data for both pretraining and fine-tuning multi-modal representations\nfor object-centric tasks such as cross-sensory retrieval and reconstruction.\nX-Capture lays the groundwork for advancing human-like sensory representations\nin AI, emphasizing scalability, accessibility, and real-world applicability.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T06:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.02324v1","title":"Dynamic Assortment Selection and Pricing with Censored Preference\n  Feedback","summary":"In this study, we investigate the problem of dynamic multi-product selection\nand pricing by introducing a novel framework based on a \\textit{censored\nmultinomial logit} (C-MNL) choice model. In this model, sellers present a set\nof products with prices, and buyers filter out products priced above their\nvaluation, purchasing at most one product from the remaining options based on\ntheir preferences. The goal is to maximize seller revenue by dynamically\nadjusting product offerings and prices, while learning both product valuations\nand buyer preferences through purchase feedback. To achieve this, we propose a\nLower Confidence Bound (LCB) pricing strategy. By combining this pricing\nstrategy with either an Upper Confidence Bound (UCB) or Thompson Sampling (TS)\nproduct selection approach, our algorithms achieve regret bounds of\n$\\tilde{O}(d^{\\frac{3}{2}}\\sqrt{T/\\kappa})$ and\n$\\tilde{O}(d^{2}\\sqrt{T/\\kappa})$, respectively. Finally, we validate the\nperformance of our methods through simulations, demonstrating their\neffectiveness.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T06:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02327v1","title":"LearNAT: Learning NL2SQL with AST-guided Task Decomposition for Large\n  Language Models","summary":"Natural Language to SQL (NL2SQL) has emerged as a critical task for enabling\nseamless interaction with databases. Recent advancements in Large Language\nModels (LLMs) have demonstrated remarkable performance in this domain. However,\nexisting NL2SQL methods predominantly rely on closed-source LLMs leveraging\nprompt engineering, while open-source models typically require fine-tuning to\nacquire domain-specific knowledge. Despite these efforts, open-source LLMs\nstruggle with complex NL2SQL tasks due to the indirect expression of user query\nobjectives and the semantic gap between user queries and database schemas.\nInspired by the application of reinforcement learning in mathematical\nproblem-solving to encourage step-by-step reasoning in LLMs, we propose LearNAT\n(Learning NL2SQL with AST-guided Task Decomposition), a novel framework that\nimproves the performance of open-source LLMs on complex NL2SQL tasks through\ntask decomposition and reinforcement learning. LearNAT introduces three key\ncomponents: (1) a Decomposition Synthesis Procedure that leverages Abstract\nSyntax Trees (ASTs) to guide efficient search and pruning strategies for task\ndecomposition, (2) Margin-aware Reinforcement Learning, which employs\nfine-grained step-level optimization via DPO with AST margins, and (3) Adaptive\nDemonstration Reasoning, a mechanism for dynamically selecting relevant\nexamples to enhance decomposition capabilities. Extensive experiments on two\nbenchmark datasets, Spider and BIRD, demonstrate that LearNAT enables a\n7B-parameter open-source LLM to achieve performance comparable to GPT-4, while\noffering improved efficiency and accessibility.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:59:44Z"}
{"aid":"http://arxiv.org/abs/2504.02336v1","title":"Spectral asymmetry via pseudodifferential projections: the massless\n  Dirac operator","summary":"A new approach to the study of spectral asymmetry for systems of partial\ndifferential equations (PDEs) on closed manifolds was proposed in a recent\nseries of papers by the first author and collaborator. They showed that\ninformation on spectral asymmetry can be encoded within and recovered from a\nnegative order pseudodifferential operator -- the asymmetry operator --\nconstructed from appropriately defined pseudodifferential (spectral)\nprojections. In this manuscript we apply these techniques to the study of the\nmassless Dirac operator; in particular, we compute the principal symbol of the\nasymmetry operator, accounting for the underlying gauge invariance.","main_category":"math-ph","categories":"math-ph,math.AP,math.DG,math.MP,math.SP","published":"2025-04-03T07:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02348v1","title":"Rigorous results for timelike Liouville field theory","summary":"Liouville field theory has long been a cornerstone of two-dimensional quantum\nfield theory and quantum gravity, which has attracted much recent attention in\nthe mathematics literature. Timelike Liouville field theory is a version of\nLiouville field theory where the kinetic term in the action appears with a\nnegative sign, which makes it closer to a theory of quantum gravity than\nordinary (spacelike) Liouville field theory. Making sense of this \"wrong sign\"\nrequires a theory of Gaussian random variables with negative variance. Such a\ntheory is developed in this paper, and is used to prove the timelike DOZZ\nformula for the $3$-point correlation function when the parameters satisfy the\nso-called \"charge neutrality condition\". Expressions are derived also for the\n$k$-point correlation functions for all $k\\ge 3$, and it is shown that these\nfunctions approach the correct semiclassical limits as the coupling constant is\nsent to zero.","main_category":"math.PR","categories":"math.PR,hep-th,math-ph,math.MP","published":"2025-04-03T07:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.02351v1","title":"Agglomerating Large Vision Encoders via Distillation for VFSS\n  Segmentation","summary":"The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T07:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.02352v1","title":"Liquid Neural Networks: Next-Generation AI for Telecom from First\n  Principles","summary":"Artificial intelligence (AI) has emerged as a transformative technology with\nimmense potential to reshape the next-generation of wireless networks. By\nleveraging advanced algorithms and machine learning techniques, AI offers\nunprecedented capabilities in optimizing network performance, enhancing data\nprocessing efficiency, and enabling smarter decision-making processes. However,\nexisting AI solutions face significant challenges in terms of robustness and\ninterpretability. Specifically, current AI models exhibit substantial\nperformance degradation in dynamic environments with varying data\ndistributions, and the black-box nature of these algorithms raises concerns\nregarding safety, transparency, and fairness. This presents a major challenge\nin integrating AI into practical communication systems. Recently, a novel type\nof neural network, known as the liquid neural networks (LNNs), has been\ndesigned from first principles to address these issues. In this paper, we\nexplore the potential of LNNs in telecommunications. First, we illustrate the\nmechanisms of LNNs and highlight their unique advantages over traditional\nnetworks. Then we unveil the opportunities that LNNs bring to future wireless\nnetworks. Furthermore, we discuss the challenges and design directions for the\nimplementation of LNNs. Finally, we summarize the performance of LNNs in two\ncase studies.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-03T07:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.02354v1","title":"Improving turbulence control through explainable deep learning","summary":"Turbulent-flow control aims to develop strategies that effectively manipulate\nfluid systems, such as the reduction of drag in transportation and enhancing\nenergy efficiency, both critical steps towards reducing global CO$_2$\nemissions. Deep reinforcement learning (DRL) offers novel tools to discover\nflow-control strategies, which we combine with our knowledge of the physics of\nturbulence. We integrate explainable deep learning (XDL) to objectively\nidentify the coherent structures containing the most informative regions in the\nflow, with a DRL model trained to reduce them. The trained model targets the\nmost relevant regions in the flow to sustain turbulence and produces a drag\nreduction which is higher than that of a model specifically trained to reduce\nthe drag, while using only half its power consumption. Moreover, the XDL model\nresults in a better drag reduction than other models focusing on specific\nclassically identified coherent structures. This demonstrates that combining\nDRL with XDL can produce causal control strategies that precisely target the\nmost influential features of turbulence. By directly addressing the core\nmechanisms that sustain turbulence, our approach offers a powerful pathway\ntowards its efficient control, which is a long-standing challenge in physics\nwith profound implications for energy systems, climate modeling and\naerodynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T07:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.02355v1","title":"Optical and magnetic response by design in GaAs quantum dots","summary":"Quantum networking technologies use spin qubits and their interface to single\nphotons as core components of a network node. This necessitates the ability to\nco-design the magnetic- and optical-dipole response of a quantum system. These\nproperties are notoriously difficult to design in many solid-state systems,\nwhere spin-orbit coupling and the crystalline environment for each qubit create\ninhomogeneity of electronic g-factors and optically active states. Here, we\nshow that GaAs quantum dots (QDs) obtained via the quasi-strain-free local\ndroplet etching epitaxy growth method provide spin and optical properties\npredictable from assuming the highest possible QD symmetry. Our measurements of\nelectron and hole g-tensors and of transition dipole moment orientations for\ncharged excitons agree with our predictions from a multiband k.p simulation\nconstrained only by a single atomic-force-microscopy reconstruction of QD\nmorphology. This agreement is verified across multiple wavelength-specific\ngrowth runs at different facilities within the range of 730 nm to 790 nm for\nthe exciton emission. Remarkably, our measurements and simulations track the\nin-plane electron g-factors through a zero-crossing from -0.1 to 0.3 and linear\noptical dipole moment orientations fully determined by an external magnetic\nfield. The robustness of our results demonstrates the capability to design -\nprior to growth - the properties of a spin qubit and its tunable optical\ninterface best adapted to a target magnetic and photonic environment with\ndirect application for high-quality spin-photon entanglement.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-03T07:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.02362v1","title":"Brightness Perceiving for Recursive Low-Light Image Enhancement","summary":"Due to the wide dynamic range in real low-light scenes, there will be large\ndifferences in the degree of contrast degradation and detail blurring of\ncaptured images, making it difficult for existing end-to-end methods to enhance\nlow-light images to normal exposure. To address the above issue, we decompose\nlow-light image enhancement into a recursive enhancement task and propose a\nbrightness-perceiving-based recursive enhancement framework for high dynamic\nrange low-light image enhancement. Specifically, our recursive enhancement\nframework consists of two parallel sub-networks: Adaptive Contrast and Texture\nenhancement network (ACT-Net) and Brightness Perception network (BP-Net). The\nACT-Net is proposed to adaptively enhance image contrast and details under the\nguidance of the brightness adjustment branch and gradient adjustment branch,\nwhich are proposed to perceive the degradation degree of contrast and details\nin low-light images. To adaptively enhance images captured under different\nbrightness levels, BP-Net is proposed to control the recursive enhancement\ntimes of ACT-Net by exploring the image brightness distribution properties.\nFinally, in order to coordinate ACT-Net and BP-Net, we design a novel\nunsupervised training strategy to facilitate the training procedure. To further\nvalidate the effectiveness of the proposed method, we construct a new dataset\nwith a broader brightness distribution by mixing three low-light datasets.\nCompared with eleven existing representative methods, the proposed method\nachieves new SOTA performance on six reference and no reference metrics.\nSpecifically, the proposed method improves the PSNR by 0.9 dB compared to the\nexisting SOTA method.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T07:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.02379v1","title":"The Spear and the Ring: Emergent Structures in Magnetic Colloidal\n  Suspensions","summary":"We study from a mathematical point of view the nanoparticle model of a\nmagnetic colloid, presented by G. Klughertz. Our objective is to obtain\nproperties of stable stationary structures that arise in the long-time limit\nfor the magnetic nanoparticles dynamics following this model. In this article,\nwe present a detailed study of two specific structures using techniques from\nthe calculus of variations. The first, called the spear, consists of a chain of\naligned particles interacting via a Lennard-Jones potential. We establish\nexistence and uniqueness results, derive bounds on the distances between\nneighboring particles, and provide a sharp asymptotic description as the number\nof particles tends to infinity. The second structure, the ring, features\nparticles uniformly distributed along a circle. We prove its existence and\nuniqueness and derive an explicit formula for its radius.","main_category":"math-ph","categories":"math-ph,math.MP,math.OC","published":"2025-04-03T08:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.02388v1","title":"Steiner Traveling Salesman Problem with Quantum Annealing","summary":"The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.","main_category":"quant-ph","categories":"quant-ph,cs.AI,cs.ET","published":"2025-04-03T08:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.02389v1","title":"Response of magnetic particle to rotating magnetic field in viscoelastic\n  fluid","summary":"The rotational dynamics of a freely suspended ferromagnetic particle in\nviscoelastic fluid subjected to a rotating magnetic field is studied by\nexperiments and theory. Our result reveals that when the characteristic\nrelaxation time of the fluid is much smaller than the inverse critical field\nfrequency, the particle's rotation behavior aligns with that in Newtonian\nfluids. Increasing the relaxation time enhances the time-averaged rotation\nfrequency of the particle that undergo asynchronous rotation. Moreover, the\ncritical frequency is shown to scale linearly with the magnetic field intensity\nand inversely with the fluid's zero-shear viscosity. Our work is expected to\nguide precise manipulation of ferromagnetic particles in biomedical systems\nwhere viscoelastic environments dominate.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-03T08:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.02395v1","title":"The quasi-semantic competence of LLMs: a case study on the part-whole\n  relation","summary":"Understanding the extent and depth of the semantic competence of \\emph{Large\nLanguage Models} (LLMs) is at the center of the current scientific agenda in\nArtificial Intelligence (AI) and Computational Linguistics (CL). We contribute\nto this endeavor by investigating their knowledge of the \\emph{part-whole}\nrelation, a.k.a. \\emph{meronymy}, which plays a crucial role in lexical\norganization, but it is significantly understudied. We used data from\nConceptNet relations \\citep{speer2016conceptnet} and human-generated semantic\nfeature norms \\citep{McRae:2005} to explore the abilities of LLMs to deal with\n\\textit{part-whole} relations. We employed several methods based on three\nlevels of analysis: i.) \\textbf{behavioral} testing via prompting, where we\ndirectly queried the models on their knowledge of meronymy, ii.) sentence\n\\textbf{probability} scoring, where we tested models' abilities to discriminate\ncorrect (real) and incorrect (asymmetric counterfactual) \\textit{part-whole}\nrelations, and iii.) \\textbf{concept representation} analysis in vector space,\nwhere we proved the linear organization of the \\textit{part-whole} concept in\nthe embedding and unembedding spaces. These analyses present a complex picture\nthat reveals that the LLMs' knowledge of this relation is only partial. They\nhave just a ``\\emph{quasi}-semantic'' competence and still fall short of\ncapturing deep inferential properties.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.02396v1","title":"High-Resolution Observations of a Small-Scale Cancellation Nanoflare:\n  Supporting Evidence for the Cancellation Nanoflare Model","summary":"An analytical cancellation nanoflare model has recently been established to\nshow the fundamental role that ubiquitous small-scale cancellation nanoflares\nplay in solar atmospheric heating. Although this model is well-supported by\nsimulations, observational evidence is needed to deepen our understanding of\ncancellation nanoflares. We present observations of a small-scale cancellation\nnanoflare event, analyzing its magnetic topology evolution, triggers, and\nphysical parameters. Using coordinated observations from Solar Dynamics\nObservatory and Goode Solar Telescope, we identify a photospheric flow-driven\ncancellation event with a flux cancellation rate of ~10^{15} Mx/s and a heating\nrate of 8.7 x 10^6 erg cm^{-2} s^{-1}. The event shows the characteristic\ntransition from $\\pi$-shaped to X-shaped magnetic configuration before forming\na two arcsecs current sheet, closely matching model predictions. This event\nprovides critical observational support for the cancellation nanoflare model\nand its role in solar atmospheric heating.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-03T08:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.02401v1","title":"Comparing the Sun to Sun-like stars. On the importance of addressing\n  faculae/spot domination","summary":"Whether the Sun is an ordinary G-type star is still an open scientific\nquestion. Stellar surveys by Kepler and TESS, however, revealed that Sun-like\nstars tend to show much stronger flare activity than the Sun. This study aims\nto reassess observed flare and spot activity of Sun-like Kepler stars by\nfine-tuning the criteria for a more robust definition of Sun-like conditions\nand better comparability between the current Sun and Sun-like stars. We update\none of the recent stellar Sun-like star samples by applying new empirical\nstellar relations between the starspot size and the effective stellar\ntemperature to derive more reliable starspot group sizes. From the 265\nsolar-type stars, we could select 48 stars supporting the Kepler 30-minute\ncadence light curves. These were analyzed by implementing the gradient of the\npower spectra method to distinguish between spot- and faculae-dominated stars.\nWe employed the $\\alpha$-factor to quantify the area ratio of bright and dark\nfeatures on the stellar surface. We were able to group the 48 stars as being\nspot- or faculae-dominated, revealing a preferential distribution of the Kepler\nSun-like stars towards the spot-dominated (44 stars) and transitional (four\nstars) regimes. As the current Sun is faculae-dominated, only the transitional\nstars were utilized for further evaluation. Additionally, accounting for\ncomparability in stellar mass, radius, and rotation period, we show that only\none of the utilized 265 Sun-like stars in the Kepler sample (i.e., KIC\n11599385) allows for direct comparison to the current Sun. We further show that\nthe single flare observed on KIC 11599385 falls right within the flare energy\nrange estimated for the AD774/775 event observed in the cosmogenic radionuclide\narchives of $^{10}$Be, $^{14}$C, and $^{36}$Cl.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T08:51:00Z"}
{"aid":"http://arxiv.org/abs/2504.02406v1","title":"Lifecycle Management of Trustworthy AI Models in 6G Networks: The REASON\n  Approach","summary":"Artificial Intelligence (AI) is expected to play a key role in 6G networks\nincluding optimising system management, operation, and evolution. This requires\nsystematic lifecycle management of AI models, ensuring their impact on services\nand stakeholders is continuously monitored. While current 6G initiatives\nintroduce AI, they often fall short in addressing end-to-end intelligence and\ncrucial aspects like trust, transparency, privacy, and verifiability.\nTrustworthy AI is vital, especially for critical infrastructures like 6G. This\npaper introduces the REASON approach for holistically addressing AI's native\nintegration and trustworthiness in future 6G networks. The approach comprises\nAI Orchestration (AIO) for model lifecycle management, Cognition (COG) for\nperformance evaluation and explanation, and AI Monitoring (AIM) for tracking\nand feedback. Digital Twin (DT) technology is leveraged to facilitate real-time\nmonitoring and scenario testing, which are essential for AIO, COG, and AIM. We\ndemonstrate this approach through an AI-enabled xAPP use case, leveraging a DT\nplatform to validate, explain, and deploy trustworthy AI models.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-03T08:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.02410v1","title":"Limits of group algebras for growing symmetric groups and wreath\n  products","summary":"Let $S(\\infty)$ denote the infinite symmetric group formed by the finitary\npermutations of the set of natural numbers; this is a countable group. We\nintroduce its virtual group algebra, a completion of the conventional group\nalgebra $\\mathbb C[S(\\infty)]$. The virtual group algebra is obtained by taking\nlarge-$n$ limits of the finite-dimensional group algebras $\\mathbb C[S(n)]$ in\nthe so-called tame representations of $S(\\infty)$. We establish a connection\nwith the centralizer construction of Molev-Olshanski [J. Algebra, 237 (2001),\n302-341; arXiv:math/0002165] and Drinfeld-Lusztig degenerate affine Hecke\nalgebras. This makes it possible to describe the structure of the virtual group\nalgebra. Then we extend the results to wreath products $G\\wr S(\\infty)$ with\narbitrary finite groups $G$.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-03T09:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.02426v1","title":"Narrative Studio: Visual narrative exploration using LLMs and Monte\n  Carlo Tree Search","summary":"Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T09:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.02430v1","title":"How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired\n  by Aristotle's Posterior Analytics","summary":"Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.","main_category":"cs.AI","categories":"cs.AI,cs.LO,I.2.4","published":"2025-04-03T09:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.02434v1","title":"Generalised Hajłasz-Besov spaces on $RD$-spaces","summary":"An $RD$ space is a doubling measure metric space $\\Omega$ with the additional\nproperty that it has a reverse doubling property. In this paper we introduce a\nnew class of Haj{\\l}asz-Besov spaces on $\\Omega$ and extend several results\nfrom classical theory, such as embeddings and Sobolev-type embeddings.","main_category":"math.FA","categories":"math.FA","published":"2025-04-03T09:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.02456v1","title":"The Amenability Framework: Rethinking Causal Ordering Without Estimating\n  Causal Effects","summary":"Who should we prioritize for intervention when we cannot estimate\nintervention effects? In many applied domains (e.g., advertising, customer\nretention, and behavioral nudging) prioritization is guided by predictive\nmodels that estimate outcome probabilities rather than causal effects. This\npaper investigates when these predictions (scores) can effectively rank\nindividuals by their intervention effects, particularly when direct effect\nestimation is infeasible or unreliable. We propose a conceptual framework based\non amenability: an individual's latent proclivity to be influenced by an\nintervention. We then formalize conditions under which predictive scores serve\nas effective proxies for amenability. These conditions justify using non-causal\nscores for intervention prioritization, even when the scores do not directly\nestimate effects. We further show that, under plausible assumptions, predictive\nmodels can outperform causal effect estimators in ranking individuals by\nintervention effects. Empirical evidence from an advertising context supports\nour theoretical findings, demonstrating that predictive modeling can offer a\nmore robust approach to targeting than effect estimation. Our framework\nsuggests a shift in focus, from estimating effects to inferring who is\namenable, as a practical and theoretically grounded strategy for prioritizing\ninterventions in resource-constrained environments.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-03T10:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.02457v1","title":"Size and shape of the trans-Neptunian object (470316) 2007 OC10:\n  Comparison with thermal data","summary":"The shapes of only 12 trans-Neptunian objects have been directly measured,\noffering crucial insights into their internal structure. These properties are\nstrongly connected to the processes that shaped the early Solar System, and\nprovide important clues about its evolution.\n  The aim of the present work is to characterise the size, shape, geometric\nalbedo, and beaming parameter of the TNO (470316) 2007 OC10 . We compared these\nvalues to the effective diameter and geometric albedo obtained from thermal\ndata by the TNOs are Cool survey. We also combined occultation and thermal data\nto constrain the size of a putative unresolved satellite.\n  We predicted an occultation of the star Gaia DR3 2727866328215869952 by 2007\nOC10 on 2022 August 22. Four stations detected the occultation. We implemented\nan elliptical shape model for the projection of 2007 OC10. Following a Bayesian\napproach, we obtained the posterior probability density in the model parameter\nspace using a Markov chain Monte Carlo method.\n  The elliptical limb of 2007 OC10 has semi-axes of $ 215^{+10}_{-7} \\times 141\n^{+24}_{-23}$ km, and thus the projected axis ratio is $b/a =\n0.58^{+0.16}_{-0.16}$. The area-equivalent diameter is $330^{+56}_{-55}$,km.\nFrom our own absolute magnitude value of $H_V = 5.40 \\pm 0.02$, the geometric\nalbedo is $p_V = 11.2 ^{+2.1}_{-5.0}$ %. Combining the occultation results with\nthermal data, we constrain the beaming parameter to $\\eta =\n1.42^{+0.75}_{-0.58}$. Occultation data reveal that the star is double. The\nsecondary star has a position angle with respect to the primary of\n$56^{+3}_{-17}$ degrees, has an angular separation of $57^{+4}_{-11}$ mas, and\nis $1.18^{+0.07}_{-0.07}$ magnitudes fainter than the primary.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T10:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.02464v1","title":"CornerPoint3D: Look at the Nearest Corner Instead of the Center","summary":"3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T10:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.02465v1","title":"RASP: Revisiting 3D Anamorphic Art for Shadow-Guided Packing of\n  Irregular Objects","summary":"Recent advancements in learning-based methods have opened new avenues for\nexploring and interpreting art forms, such as shadow art, origami, and sketch\nart, through computational models. One notable visual art form is 3D Anamorphic\nArt in which an ensemble of arbitrarily shaped 3D objects creates a realistic\nand meaningful expression when observed from a particular viewpoint and loses\nits coherence over the other viewpoints. In this work, we build on insights\nfrom 3D Anamorphic Art to perform 3D object arrangement. We introduce RASP, a\ndifferentiable-rendering-based framework to arrange arbitrarily shaped 3D\nobjects within a bounded volume via shadow (or silhouette)-guided optimization\nwith an aim of minimal inter-object spacing and near-maximal occupancy.\nFurthermore, we propose a novel SDF-based formulation to handle inter-object\nintersection and container extrusion. We demonstrate that RASP can be extended\nto part assembly alongside object packing considering 3D objects to be \"parts\"\nof another 3D object. Finally, we present artistic illustrations of multi-view\nanamorphic art, achieving meaningful expressions from multiple viewpoints\nwithin a single ensemble.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T10:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.02471v1","title":"Semantic segmentation of forest stands using deep learning","summary":"Forest stands are the fundamental units in forest management inventories,\nsilviculture, and financial analysis within operational forestry. Over the past\ntwo decades, a common method for mapping stand borders has involved delineation\nthrough manual interpretation of stereographic aerial images. This is a\ntime-consuming and subjective process, limiting operational efficiency and\nintroducing inconsistencies. Substantial effort has been devoted to automating\nthe process, using various algorithms together with aerial images and canopy\nheight models constructed from airborne laser scanning (ALS) data, but manual\ninterpretation remains the preferred method. Deep learning (DL) methods have\ndemonstrated great potential in computer vision, yet their application to\nforest stand delineation remains unexplored in published research. This study\npresents a novel approach, framing stand delineation as a multiclass\nsegmentation problem and applying a U-Net based DL framework. The model was\ntrained and evaluated using multispectral images, ALS data, and an existing\nstand map created by an expert interpreter. Performance was assessed on\nindependent data using overall accuracy, a standard metric for classification\ntasks that measures the proportions of correctly classified pixels. The model\nachieved an overall accuracy of 0.73. These results demonstrate strong\npotential for DL in automated stand delineation. However, a few key challenges\nwere noted, especially for complex forest environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.02473v1","title":"Adaptive path planning for efficient object search by UAVs in\n  agricultural fields","summary":"This paper presents an adaptive path planner for object search in\nagricultural fields using UAVs. The path planner uses a high-altitude coverage\nflight path and plans additional low-altitude inspections when the detection\nnetwork is uncertain. The path planner was evaluated in an offline simulation\nenvironment containing real-world images. We trained a YOLOv8 detection network\nto detect artificial plants placed in grass fields to showcase the potential of\nour path planner. We evaluated the effect of different detection certainty\nmeasures, optimized the path planning parameters, investigated the effects of\nlocalization errors and different numbers of objects in the field. The YOLOv8\ndetection confidence worked best to differentiate between true and false\npositive detections and was therefore used in the adaptive planner. The optimal\nparameters of the path planner depended on the distribution of objects in the\nfield, when the objects were uniformly distributed, more low-altitude\ninspections were needed compared to a non-uniform distribution of objects,\nresulting in a longer path length. The adaptive planner proved to be robust\nagainst localization uncertainty. When increasing the number of objects, the\nflight path length increased, especially when the objects were uniformly\ndistributed. When the objects were non-uniformly distributed, the adaptive path\nplanner yielded a shorter path than a low-altitude coverage path, even with\nhigh number of objects. Overall, the presented adaptive path planner allowed to\nfind non-uniformly distributed objects in a field faster than a coverage path\nplanner and resulted in a compatible detection accuracy. The path planner is\nmade available at https://github.com/wur-abe/uav_adaptive_planner.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.02482v1","title":"Berry-Esseen bound for the Moment Estimation of the fractional\n  Ornstein-Uhlenbeck model under fixed step size discrete observations","summary":"Let the Ornstein-Uhlenbeck process $\\{X_t,\\,t\\geq 0\\}$ driven by a fractional\nBrownian motion $B^H$ described by $d X_t=-\\theta X_t dt+ d B_t^H,\\, X_0=0$\nwith known parameter $H\\in (0,\\frac34)$ be observed at discrete time instants\n$t_k=kh, k=1,2,\\dots, n $. If $\\theta>0$ and if the step size $h>0$ is\narbitrarily fixed, we derive Berry-Ess\\'{e}en bound for the ergodic type\nestimator (or say the moment estimator) $\\hat{\\theta}_n$, i.e., the Kolmogorov\ndistance between the distribution of $\\sqrt{n}(\\hat{\\theta}_n-\\theta)$ and its\nlimit distribution is bounded by a constant $C_{\\theta, H,h}$ times\n$n^{-\\frac12}$ and $ n^{4H-3}$ when $H\\in (0,\\,\\frac58]$ and $H\\in\n(\\frac58,\\,\\frac34)$, respectively. This result greatly improve the previous\nresult in literature where $h$ is forced to go zero. Moreover, we extend the\nBerry-Esseen bound to the Ornstein-Uhlenbeck model driven by a lot of Gaussian\nnoises such as the sub-bifractional Brownian motion and others. A few ideas of\nthe present paper come from Haress and Hu (2021), Sottinen and Viitasaari\n(2018), and Chen and Zhou (2021).","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.02491v1","title":"ToMCCA-3: A realistic 3-body coalescence model","summary":"The formation of light nuclei in high-energy collisions provides valuable\ninsights into the underlying dynamics of the strong interaction and the\nstructure of the particle-emitting source. Understanding this process is\ncrucial not only for nuclear physics but also for astrophysical studies, where\nthe production of rare antinuclei could serve as a probe for new physics. This\nwork presents a three-body coalescence model based on the Wigner function\nformalism, offering a refined description of light-nucleus production. By\nincorporating realistic two- and three-body nuclear interaction potentials\nconstrained by modern scattering and femtoscopic correlation data, our approach\nimproves on traditional coalescence models. The framework is validated using\nevent generators applied to proton-proton collisions at $\\sqrt{s}=13$ TeV to\npredict the momentum spectra of light (anti) nuclear nuclei with mass number\n$A=3$, which are then compared with the experimental data from ALICE. Our\nresults demonstrate the sensitivity of light nucleus yields to the choice of\nnuclear wave functions, emphasizing the importance of an accurate description\nof the coalescence process. This model lays the foundation for the extension of\ncoalescence studies of $A=3$ light nuclei to a wider range of collision systems\nand energies.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T11:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.02495v1","title":"Inference-Time Scaling for Generalist Reward Modeling","summary":"Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T11:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.02499v1","title":"The Gradient of Mean Molecular Weight Across the Radius Valley","summary":"Photo-evaporation shapes the observed radii of small exoplanets and\nconstrains the underlying distributions of atmospheric and core masses.\nHowever, the diversity of atmospheric chemistries corresponding to these\ndistributions remains unelucidated. We develop a first-principles\ncarbon-hydrogen-oxygen-sulfur-silicon (CHOSSi) outgassing model that accounts\nfor non-ideal gas behavior (via fugacities) at high pressures, as well as the\ntendency for water and hydrogen to dissolve in melt (via solubility laws). We\nuse data-driven radius valley constraints to establish the relationship between\nthe atmospheric surface pressures and melt temperatures of sub-Neptunes.\nSub-Neptunes with less massive rocky cores retain less of their primordial\nhydrogen envelopes, which leads to less heat retention and diminished melt\ntemperatures at the surfaces of these cores. Lower melt temperatures lead\nthermodynamically to the dominance of carbon-, oxygen-, sulfur- and\nsilicon-bearing molecules over molecular hydrogen, which naturally produce a\ndiversity of mean molecular weights. Our geochemical outgassing calculations\nrobustly predict a gradient of mean molecular weight across the radius valley,\nwhere the strength of this gradient is primarily driven by the oxygen fugacity\nof the molten cores and not by the carbon enrichment (or \"metallicity\") of the\natmosphere. Smaller sub-Neptunes are predicted to have less hydrogen-dominated\natmospheres. The precise relationship between the observed and outgassed\nchemistries requires an understanding of how convection near the core interacts\nwith large-scale atmospheric circulation (driven by stellar heating) near the\nphotosphere, as well as the influence of photochemistry.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph,physics.geo-ph","published":"2025-04-03T11:22:08Z"}
{"aid":"http://arxiv.org/abs/2504.02500v1","title":"An Overview of Josephson Junctions Based QPUs","summary":"Quantum processing units (QPUs) based on superconducting Josephson junctions\npromise significant advances in quantum computing. However, they face critical\nchallenges. Decoherence, scalability limitations, and error correction overhead\nhinder practical, fault-tolerant implementations. This paper investigates these\nissues by exploring both fundamental quantum phenomena and practical\nengineering challenges. We analyze key quantum mechanical principles such as\nsuperposition, entanglement, and decoherence that govern the behavior of\nsuperconducting qubits. We also discuss quantum tunneling, Cooper pair\nformation, and the operational mechanics of Josephson junctions in detail.\nAdditionally, we present a comparative analysis with alternative architectures,\nincluding ion trap and photonic systems. This comparison highlights the unique\nadvantages and trade-offs of Josephson junction-based QPUs. Our findings\nemphasize the critical role of material innovations and optimized control\ntechniques. These advances are essential for mitigating noise and decoherence\nand for realizing robust, scalable quantum computing.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cs.ET,quant-ph","published":"2025-04-03T11:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.02508v1","title":"APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian\n  Based Reconstruction for Vision Transformers","summary":"Vision Transformers (ViTs) have become one of the most commonly used\nbackbones for vision tasks. Despite their remarkable performance, they often\nsuffer significant accuracy drops when quantized for practical deployment,\nparticularly by post-training quantization (PTQ) under ultra-low bits.\nRecently, reconstruction-based PTQ methods have shown promising performance in\nquantizing Convolutional Neural Networks (CNNs). However, they fail when\napplied to ViTs, primarily due to the inaccurate estimation of output\nimportance and the substantial accuracy degradation in quantizing post-GELU\nactivations. To address these issues, we propose \\textbf{APHQ-ViT}, a novel PTQ\napproach based on importance estimation with Average Perturbation Hessian\n(APH). Specifically, we first thoroughly analyze the current approximation\napproaches with Hessian loss, and propose an improved average perturbation\nHessian loss. To deal with the quantization of the post-GELU activations, we\ndesign an MLP Reconstruction (MR) method by replacing the GELU function in MLP\nwith ReLU and reconstructing it by the APH loss on a small unlabeled\ncalibration set. Extensive experiments demonstrate that APHQ-ViT using linear\nquantizers outperforms existing PTQ methods by substantial margins in 3-bit and\n4-bit across different vision tasks. The source code is available at\nhttps://github.com/GoatWu/APHQ-ViT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T11:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.02525v1","title":"Detection of cosmological dipoles aligned with transverse peculiar\n  velocities","summary":"We present the first observations of a novel dipole signature imprinted on\nthe CMB by transverse velocities. Cosmological peculiar velocities point\ntowards gravitational wells and away from potential hills, reflecting a\nlarge-scale dipole in the gravitational potential, coherent over hundreds of\nMpc. We predict large-scale dipoles in all fields correlated with the\npotential, observable via effects of gravitational lensing and the integrated\nSachs-Wolfe (ISW). The ISW dipole is distinct from the small-scale moving lens\neffect, which has a dipole of the opposite sign. We provide a unified framework\nfor analysing these dipoles, and make the first detections in galaxy density,\nCMB lensing convergence and the ISW effect. We show that the observed signals\nare consistent with LCDM predictions, and set limits on modified gravity. The\nCMB dipole signal is independent of galaxy bias, and orthogonal to the monopole\ncorrelation function, so this new observable provides additional cosmological\ninformation (abridged).","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-03T12:29:36Z"}
{"aid":"http://arxiv.org/abs/2504.02528v1","title":"RAFFLE: Active learning accelerated interface structure prediction","summary":"Interfaces between materials play a crucial role in the performance of most\ndevices. However, predicting the structure of a material interface is\ncomputationally demanding due to the vast configuration space, which requires\nevaluating an unfeasibly large number of highly complex structures. We\nintroduce RAFFLE, a software package designed to efficiently explore low-energy\ninterface configurations between any two crystals. RAFFLE leverages physical\ninsights and genetic algorithms to intelligently sample the configuration\nspace, using dynamically evolving 2-, 3-, and 4-body distribution functions as\ngeneralised structural descriptors. These descriptors are iteratively updated\nthrough active learning, which inform atom placement strategies. RAFFLE's\neffectiveness is demonstrated across a diverse set of systems, including bulk\nmaterials, intercalation structures, and interfaces. When tested on bulk\naluminium and MoS$_2$, it successfully identifies known ground-state and\nhigh-pressure phases. Applied to intercalation systems, it predicts stable\nintercalant phases. For Si|Ge interfaces, RAFFLE identifies intermixing as a\nstrain compensation mechanism, generating reconstructions that are more stable\nthan abrupt interfaces. By accelerating interface structure prediction, RAFFLE\noffers a powerful tool for materials discovery, enabling efficient exploration\nof complex configuration spaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn","published":"2025-04-03T12:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.02529v1","title":"Probabilistic Simulation of Aircraft Descent via a Hybrid Physics-Data\n  Approach","summary":"This paper presents a method for generating probabilistic descent\ntrajectories in simulations of real-world airspace. A dataset of 116,066\ntrajectories harvested from Mode S radar returns in UK airspace was used to\ntrain and test the model. Thirteen aircraft types with varying performance\ncharacteristics were investigated. It was found that the error in the mean\nprediction of time to reach the bottom of descent for the proposed method was\nless than that of the the Base of Aircraft Data (BADA) model by a factor of 10.\nFurthermore, the method was capable of generating a range of trajectories that\nwere similar to the held out test dataset when analysed in distribution. The\nproposed method is hybrid, with aircraft drag and calibrated airspeed functions\ngenerated probabilistically to parameterise the BADA equations, ensuring the\nphysical plausibility of generated trajectories.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T12:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.02543v1","title":"Probabilistic Pontryagin's Maximum Principle for Continuous-Time\n  Model-Based Reinforcement Learning","summary":"Without exact knowledge of the true system dynamics, optimal control of\nnon-linear continuous-time systems requires careful treatment of epistemic\nuncertainty. In this work, we propose a probabilistic extension to Pontryagin's\nmaximum principle by minimizing the mean Hamiltonian with respect to epistemic\nuncertainty. We show minimization of the mean Hamiltonian is a necessary\noptimality condition when optimizing the mean cost, and propose a multiple\nshooting numerical method scalable to large-scale probabilistic dynamical\nmodels, including ensemble neural ordinary differential equations. Comparisons\nagainst state-of-the-art methods in online and offline model-based\nreinforcement learning tasks show that our probabilistic Hamiltonian\nformulation leads to reduced trial costs in offline settings and achieves\ncompetitive performance in online scenarios. By bridging optimal control and\nreinforcement learning, our approach offers a principled and practical\nframework for controlling uncertain systems with learned dynamics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T12:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02547v1","title":"A smooth multi-group Gaussian Mixture Model for cellwise robust\n  covariance estimation","summary":"Are data groups which are pre-defined by expert opinions or medical diagnoses\ncorresponding to groups based on statistical modeling? For which reason might\nobservations be inconsistent? This contribution intends to answer both\nquestions by proposing a novel multi-group Gaussian mixture model that accounts\nfor the given group context while allowing high flexibility. This is achieved\nby assuming that the observations of a particular group originate not from a\nsingle distribution but from a Gaussian mixture of all group distributions.\nMoreover, the model provides robustness against cellwise outliers, thus against\natypical data cells of the observations. The objective function can be\nformulated as a likelihood problem and optimized efficiently. We also derive\nthe theoretical breakdown point of the estimators, an innovative result in this\ncontext to quantify the degree of robustness to cellwise outliers. Simulations\ndemonstrate the excellent performance and the advantages to alternative models\nand estimators. Applications from different areas illustrate the strength of\nthe method, particularly in investigating observations which are on the overlap\nof different groups.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T12:54:21Z"}
{"aid":"http://arxiv.org/abs/2504.02549v1","title":"Emergent version of Drinfeld's associator equations","summary":"The works of Alekseev and Torossian [AT] and Alekseev, Enriquez, and\nTorossian [AET] show that any solution of Drinfeld's associator equations gives\nrise to a solution of the Kashiwara-Vergne equations in an explicit way. We\nintroduce a weak version of Drinfeld's associator equations that we call the\nemergent version of the original equations. It is shown that solutions to the\nresulting linearized emergent Drinfeld's equations still lead to solutions to\nthe linearized Kashiwara-Vergne equations.\n  The emergent Drinfeld equations arise within a natural topological context of\nemergent braids, which we discuss. Our results are adjacent to the results of\nBar-Natan, Dancso, Hogan, Liu and Scherich [BDHLS] on the relationship between\nemergent tangles and the Goldman-Turaev Lie bialgebra. We hope that in time our\nresults will play a role in relating several bodies of work, on Drinfeld\nassociators, Kashiwara-Vergne equations, and on expansions for classical\ntangles, for w-tangles, and for the Goldman-Turaev Lie bialgebra.","main_category":"math.GT","categories":"math.GT,math.QA","published":"2025-04-03T13:02:04Z"}
{"aid":"http://arxiv.org/abs/2504.02561v1","title":"Digital Twins for Internet of Battlespace Things (IoBT) Coalitions","summary":"This paper presents a new framework for integrating Digital Twins (DTs)\nwithin Internet of battlespace Things (IoBT) coalitions. We introduce a novel\nthree-tier architecture that enables efficient coordination and management of\nDT models across coalition partners while addressing key challenges in\ninteroperability, security, and resource allocation. The architecture comprises\nspecialized controllers at each tier: Digital Twin Coalition Partner (DTCP)\ncontrollers managing individual coalition partners' DT resources, a central\nDigital Twin Coalition(DTC) controller orchestrating cross-partner\ncoordination, and Digital Twin Coalition Mission (DTCP) controllers handling\nmission-specific DT interactions. We propose a hybrid approach for DT model\nplacement across edge devices, tactical nodes, and cloud infrastructure,\noptimizing performance while maintaining security and accessibility. The\narchitecture leverages software-defined networking principles for dynamic\nresource allocation and slice management, enabling efficient sharing of\ncomputational and network resources between DT operations and primary IoBT\nfunctions. Our proposed framework aims to provide a robust foundation for\ndeploying and managing Digital Twins in coalition warfare, enhancing\nsituational awareness, decision-making capabilities, and operational\neffectiveness while ensuring secure and interoperable operations across diverse\ncoalition partners.","main_category":"cs.NI","categories":"cs.NI,cs.SY,eess.SY","published":"2025-04-03T13:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.02572v1","title":"Language Models reach higher Agreement than Humans in Historical\n  Interpretation","summary":"This paper compares historical annotations by humans and Large Language\nModels. The findings reveal that both exhibit some cultural bias, but Large\nLanguage Models achieve a higher consensus on the interpretation of historical\nfacts from short texts. While humans tend to disagree on the basis of their\npersonal biases, Large Models disagree when they skip information or produce\nhallucinations. These findings have significant implications for digital\nhumanities, enabling large-scale annotation and quantitative analysis of\nhistorical data. This offers new educational and research opportunities to\nexplore historical interpretations from different Language Models, fostering\ncritical thinking about bias.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.02588v1","title":"Topological signatures of collective dynamics and turbulent-like energy\n  cascades in active granular matter","summary":"Active matter refers to a broad class of non-equilibrium systems where energy\nis continuously injected at the level of individual ``particles.\" These systems\nexhibit emergent collective behaviors that have no direct thermal-equilibrium\ncounterpart. Their scale ranges from micrometer-sized swarms of bacteria to\nmeter-scale human crowds. In recent years, the role of topology and\nself-propelled topological defects in active systems has garnered significant\nattention, particularly in polar and nematic active matter. Building on these\nideas, we investigate emergent collective dynamics in apolar active granular\nfluids. Using granular vibrators as a model experimental system of apolar\nactive Brownian particles in a dry environment, we uncover a distinctive\nthree-stage time evolution arising from the intricate interplay between\nactivity and inelastic interactions. By analyzing the statistics, spatial\ncorrelations, and dynamics of vortex-like topological defects in the\ndisplacement vector field, we demonstrate their ability to describe and predict\nthis intrinsic collective motion. Furthermore, we show that topological defects\nplay a crucial role in the development of a turbulent-like inverse energy\ncascade, where kinetic energy transfers across different length scales over\ntime. As the system evolves, the power scaling of the energy transfer increases\nwith the duration of observation. Our findings demonstrate how topological\nconcepts can be applied to predict macroscopic collective phenomena in apolar\nactive matter. This establishes a direct link between microscopic topological\ndynamics and large-scale behaviors in active granular fluids.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T13:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.02592v1","title":"Unified Equation for Massless Spin Particles and New Spin Coefficient\n  Definitions","summary":"We introduce a new definition for the spin coefficients $\\rho$, $\\mu$,\n$\\tau$, and $\\pi$, which are defined as the directional derivatives of the\nlogarithm of a generating function along the null tetrad ($l^{\\mu}$, $n^{\\mu}$,\n$m^{\\mu}$, $\\bar{m}^{\\mu}$), respectively. This is the first discovery that\nthese spin coefficients are interconnected through a generating function. Using\nthe newly defined spin coefficients, we find that the field equations for\nmassless particles with spins 0, 1/2, 1, 3/2, and 2 in arbitrary black hole\nspacetimes can be described by a single unified equation. This finding is\nparticularly surprising, as unifying these field equations is already a\nsignificant challenge in flat spacetime, let alone in the intricate spacetime\naround black holes. Consequently, this work will inevitably prompt a\nre-examination of the shared characteristics among various types of particles\nin black hole spacetimes. Meanwhile, we verify the correctness of the new\ndefinition for the spin coefficients, and provide the explicit form of the\nunified equation for nearly all known black hole backgrounds. This lays a solid\nfoundation for studying the behavior of massless spin particles in any black\nhole background.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-03T13:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.02604v1","title":"LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech\n  Recognition in Tunisian Arabic Dialect","summary":"Developing Automatic Speech Recognition (ASR) systems for Tunisian Arabic\nDialect is challenging due to the dialect's linguistic complexity and the\nscarcity of annotated speech datasets. To address these challenges, we propose\nthe LinTO audio and textual datasets -- comprehensive resources that capture\nphonological and lexical features of Tunisian Arabic Dialect. These datasets\ninclude a variety of texts from numerous sources and real-world audio samples\nfeaturing diverse speakers and code-switching between Tunisian Arabic Dialect\nand English or French. By providing high-quality audio paired with precise\ntranscriptions, the LinTO audio and textual datasets aim to provide qualitative\nmaterial to build and benchmark ASR systems for the Tunisian Arabic Dialect.\n  Keywords -- Tunisian Arabic Dialect, Speech-to-Text, Low-Resource Languages,\nAudio Data Augmentation","main_category":"cs.CL","categories":"cs.CL,cs.SD,eess.AS","published":"2025-04-03T14:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.02606v1","title":"Improving Counterfactual Truthfulness for Molecular Property Prediction\n  through Uncertainty Quantification","summary":"Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T14:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.02620v1","title":"Efficient Model Editing with Task-Localized Sparse Fine-tuning","summary":"Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CV","published":"2025-04-03T14:20:06Z"}
{"aid":"http://arxiv.org/abs/2504.02623v1","title":"Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents\n  through Related and Dynamic Missions","summary":"Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T14:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.02635v1","title":"Continuous two-valued discrete-time dynamical systems and actions of\n  two-valued groups","summary":"We study continuous 2-valued dynamical systems with discrete time (dynamics)\non $\\mathbb{C}$. The main question addressed is whether a 2-valued dynamics can\nbe defined by the action of a 2-valued group. We construct a class of strongly\ninvertible continuous 2-valued dynamics on $\\mathbb{C}$ such that none of these\ndynamics can be given by the action of any 2-valued group. We also construct an\nexample of a continuous 2-valued dynamics on $\\mathbb{C}$ that is not strongly\ninvertible but can be defined by the action of a 2-valued group.","main_category":"math.GR","categories":"math.GR,math.DS,math.GT","published":"2025-04-03T14:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.02636v1","title":"A Framework for Developing University Policies on Generative AI\n  Governance: A Cross-national Comparative Study","summary":"As generative artificial intelligence (GAI) becomes more integrated into\nhigher education and research, universities adopt varied approaches to GAI\npolicy development. To explore these variations, this study conducts a\ncomparative analysis of leading universities in the United States, Japan, and\nChina, examining their institution-wide policies on GAI application and\ngovernance. Based on these findings, the study proposes a University Policy\nDevelopment Framework for GAI (UPDF-GAI) to provide both theoretical insights\nand practical guidance for universities in developing and refining their GAI\npolicies. A qualitative content analysis of 124 policy documents from 110\nuniversities was conducted, employing thematic coding to synthesize 20 key\nthemes and 9 sub-themes. These themes and sub-themes formed the basis for\ndeveloping the framework. The analysis reveals varying priorities and focus of\nGAI policy of universities in different countries. U.S. universities emphasize\nfaculty autonomy, practical application, and policy adaptability, shaped by\ncutting-edge research and peer collaboration. Japanese universities take a\ngovernment-regulated approach, prioritizing ethics and risk management, but\nprovide limited support for AI implementation and flexibility. Chinese\nuniversities follow a centralized, government-led model, focusing on technology\napplication over early policy development, while actively exploring GAI\nintegration in education and research. The UPDF-GAI framework offers a\nsystematic, adaptable framework for assessing and optimizing GAI policies\nacross different educational contexts. By identifying key policy\ncharacteristics, enhancing policy effectiveness, and balancing technology,\nethics, and education, enabling universities to develop sustainable,\ncontextually relevant policies that strengthen their digital competitiveness\nand institutional readiness for AI-driven education.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-03T14:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.02643v1","title":"A Dynamic, Ordinal Gaussian Process Item Response Theoretic Model","summary":"Social scientists are often interested in using ordinal indicators to\nestimate latent traits that change over time. Frequently, this is done with\nitem response theoretic (IRT) models that describe the relationship between\nthose latent traits and observed indicators. We combine recent advances in\nBayesian nonparametric IRT, which makes minimal assumptions on shapes of item\nresponse functions, and Gaussian process time series methods to capture dynamic\nstructures in latent traits from longitudinal observations. We propose a\ngeneralized dynamic Gaussian process item response theory (GD-GPIRT) as well as\na Markov chain Monte Carlo sampling algorithm for estimation of both latent\ntraits and response functions. We evaluate GD-GPIRT in simulation studies\nagainst baselines in dynamic IRT, and apply it to various substantive studies,\nincluding assessing public opinions on economy environment and congressional\nideology related to abortion debate.","main_category":"stat.ME","categories":"stat.ME,cs.LG","published":"2025-04-03T14:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.02645v1","title":"Black Holes, Moduli Stabilisation and the Swampland","summary":"In theories with moduli, extremal black holes behave such that for generic\ninitial conditions, the distance traveled by the scalars from infinity to the\nhorizon can grow with the size of the black hole. This, in turn, implies that\nlarger black holes can probe more of the UV ingredients of the theory, in\ncontrast with (naive) EFT expectations. We relate this discrepancy to the lack\nof cosmological moduli stabilisation. Indeed, for would-be scale-separated\nstring vacua with parametrically heavy stabilised scalars -- dubbed\n\\emph{rigid} compactifications -- one recovers the EFT intuition where only\nsmall black holes probe the UV. We make this explicit in a toy model and then\nturn to top-down models and construct near-horizon solutions in IIA\nscale-separated compactifications with stabilised moduli. In these top-down\nmodels we still observe large field variations for large black holes which can\nbe traced back to the absence of parametrically heavy moduli. We are led to\nspeculate that needing UV physics to allow for non-local effects near the\nhorizon of large black holes is at odds with having a rigid compactification,\nhinting to the possibility that such compactifications are in the Swampland.","main_category":"hep-th","categories":"hep-th","published":"2025-04-03T14:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.02647v1","title":"Adaptive Frequency Enhancement Network for Remote Sensing Image Semantic\n  Segmentation","summary":"Semantic segmentation of high-resolution remote sensing images plays a\ncrucial role in land-use monitoring and urban planning. Recent remarkable\nprogress in deep learning-based methods makes it possible to generate\nsatisfactory segmentation results. However, existing methods still face\nchallenges in adapting network parameters to various land cover distributions\nand enhancing the interaction between spatial and frequency domain features. To\naddress these challenges, we propose the Adaptive Frequency Enhancement Network\n(AFENet), which integrates two key components: the Adaptive Frequency and\nSpatial feature Interaction Module (AFSIM) and the Selective feature Fusion\nModule (SFM). AFSIM dynamically separates and modulates high- and low-frequency\nfeatures according to the content of the input image. It adaptively generates\ntwo masks to separate high- and low-frequency components, therefore providing\noptimal details and contextual supplementary information for ground object\nfeature representation. SFM selectively fuses global context and local detailed\nfeatures to enhance the network's representation capability. Hence, the\ninteractions between frequency and spatial features are further enhanced.\nExtensive experiments on three publicly available datasets demonstrate that the\nproposed AFENet outperforms state-of-the-art methods. In addition, we also\nvalidate the effectiveness of AFSIM and SFM in managing diverse land cover\ntypes and complex scenarios. Our codes are available at\nhttps://github.com/oucailab/AFENet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.02664v1","title":"How humans evaluate AI systems for person detection in automatic train\n  operation: Not all misses are alike","summary":"If artificial intelligence (AI) is to be applied in safety-critical domains,\nits performance needs to be evaluated reliably. The present study aimed to\nunderstand how humans evaluate AI systems for person detection in automatic\ntrain operation. In three experiments, participants saw image sequences of\npeople moving in the vicinity of railway tracks. A simulated AI had highlighted\nall detected people, sometimes correctly and sometimes not. Participants had to\nprovide a numerical rating of the AI's performance and then verbally explain\ntheir rating. The experiments varied several factors that might influence human\nratings: the types and plausibility of AI mistakes, the number of affected\nimages, the number of people present in an image, the position of people\nrelevant to the tracks, and the methods used to elicit human evaluations. While\nall these factors influenced human ratings, some effects were unexpected or\ndeviated from normative standards. For instance, the factor with the strongest\nimpact was people's position relative to the tracks, although participants had\nexplicitly been instructed that the AI could not process such information.\nTaken together, the results suggest that humans may sometimes evaluate more\nthan the AI's performance on the assigned task. Such mismatches between AI\ncapabilities and human expectations should be taken into consideration when\nconducting safety audits of AI systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.02666v1","title":"BECAME: BayEsian Continual Learning with Adaptive Model MErging","summary":"Continual Learning (CL) strives to learn incrementally across tasks while\nmitigating catastrophic forgetting. A key challenge in CL is balancing\nstability (retaining prior knowledge) and plasticity (learning new tasks).\nWhile representative gradient projection methods ensure stability, they often\nlimit plasticity. Model merging techniques offer promising solutions, but prior\nmethods typically rely on empirical assumptions and carefully selected\nhyperparameters. In this paper, we explore the potential of model merging to\nenhance the stability-plasticity trade-off, providing theoretical insights that\nunderscore its benefits. Specifically, we reformulate the merging mechanism\nusing Bayesian continual learning principles and derive a closed-form solution\nfor the optimal merging coefficient that adapts to the diverse characteristics\nof tasks. To validate our approach, we introduce a two-stage framework named\nBECAME, which synergizes the expertise of gradient projection and adaptive\nmerging. Extensive experiments show that our approach outperforms\nstate-of-the-art CL methods and existing merging strategies.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T15:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.02674v1","title":"Limitations of Religious Data and the Importance of the Target Domain:\n  Towards Machine Translation for Guinea-Bissau Creole","summary":"We introduce a new dataset for machine translation of Guinea-Bissau Creole\n(Kiriol), comprising around 40 thousand parallel sentences to English and\nPortuguese. This dataset is made up of predominantly religious data (from the\nBible and texts from the Jehovah's Witnesses), but also a small amount of\ngeneral domain data (from a dictionary). This mirrors the typical resource\navailability of many low resource languages. We train a number of\ntransformer-based models to investigate how to improve domain transfer from\nreligious data to a more general domain. We find that adding even 300 sentences\nfrom the target domain when training substantially improves the translation\nperformance, highlighting the importance and need for data collection for\nlow-resource languages, even on a small-scale. We additionally find that\nPortuguese-to-Kiriol translation models perform better on average than other\nsource and target language pairs, and investigate how this relates to the\nmorphological complexity of the languages involved and the degree of lexical\noverlap between creoles and lexifiers. Overall, we hope our work will stimulate\nresearch into Kiriol and into how machine translation might better support\ncreole languages in general.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.02689v1","title":"Plasmon-interband hybridization and anomalous production of hot\n  electrons in aluminum nanoantennas","summary":"Strong coupling typically occurs between two separate objects or between an\nobject and its environment (such as an atom and a cavity). However, it can also\noccur between two different excitations within the same object, a situation\nthat has been much less studied. In this study, we observe strong coupling\nbetween localized surface plasmon resonances and the interband transition in\naluminum nanorods, as evidenced by optical spectroscopy and electron energy\nloss spectroscopy, and corroborated with numerical simulations. Strong coupling\nis observed between the interband transition and multiple orders of the surface\nplasmon mode, including dark ones. We also obtain experimental maps of the\nhybrid modes at the nanoscale. In each case, the associated Rabi energy, which\ncorresponds to the energy splitting between the two polaritonic branches, is\nobtained. Finally, a dedicated numerical model was employed to calculate the\nhot electron generation rate in the nanorods. The calculations demonstrate that\nefficient generation of hot electrons can be achieved in the near-infrared\nregion, when the interband transition is strongly coupled with a plasmon\nresonance. This high generation rate stems from the hybrid nature of the mode,\nas its plasmonic component provides a high absorption cross-section, while the\nIT part ensures efficient conversion to hot electrons. Consequently, aluminum\nnanorods represent an efficient source of hot electrons in the visible and\nnear-infrared regions, with potential applications in local photochemistry,\nphotodetection, and solar energy harvesting.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-03T15:29:07Z"}
{"aid":"http://arxiv.org/abs/2504.02691v1","title":"Hong-Ou-Mandel interference of more than 10 indistinguishable atoms","summary":"When two indistinguishable bosons interfere at a beam splitter, they both\nexit through the same output port. This foundational quantum-mechanical\nphenomenon, known as the Hong-Ou-Mandel (HOM) effect, has become a cornerstone\nin the field of quantum information. It also extends to many indistinguishable\nparticles, resulting in complex interference patterns. However, despite of its\nfundamental and applied interest, the many-particle effect has only been\nobserved in notoriously lossy photonic systems, but a realization with atomic\nsystems has remained elusive until now. Here, we demonstrate HOM interference\nwith up to 12 indistinguishable neutral atoms in a system with negligible loss.\nOur single-particle counting clearly reveals parity oscillations, a bunching\nenvelope and genuine multi-partite entanglement, defining features of the\nmulti-particle HOM effect. Our technique offers the potential for scaling to\nmuch larger numbers, presenting promising applications in quantum information\nwith indistinguishable particles and Heisenberg-limited atom interferometry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.02708v1","title":"The Hidden Space of Safety: Understanding Preference-Tuned LLMs in\n  Multilingual context","summary":"Alignment tuning has enabled large language models to excel in reasoning,\ninstruction-following, and minimizing harmful generations. However, despite\ntheir widespread deployment, these models exhibit a monolingual bias, raising\nconcerns about the effectiveness of alignment across languages. Current\nalignment methods predominantly focus on English, leaving it unclear how\nalignment mechanism generalize to multilingual settings. To address this, we\nconduct a systematic analysis of distributional shifts in the embedding space\nof LLMs before and after alignment, uncovering its impact on model behavior\nacross diverse languages. We leverage the alignment-induced separation in\nsafety space as a quantitative tool to measure how alignment enforces safety\nconstraints. Our study evaluates seven LLMs using balanced toxicity datasets\nand parallel text-detoxification benchmarks, revealing substantial disparities\nin the latent representation space between high-resource and low-resource\nlanguages. These findings underscore the need for language-specific fine-tuning\nto ensure fair, reliable and robust multilingual alignment. Our insights\nprovide a foundation for developing truly safe multilingual LLMs, emphasizing\nthe urgency of addressing alignment gaps in underrepresented languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.02717v1","title":"Clustering in a preferential attachment network with triangles","summary":"We study a generalization of the affine preferential attachment model where\ntriangles are randomly added to the graph. We show that the model exhibits an\nasymptotically power-law degree distribution with adjustable parameter\n$\\gamma\\in (1,\\infty)$, and positive clustering. However, the clustering\nbehaviour depends on how it is measured. With high probability, the average\nlocal clustering coefficient remains positive, independently of $\\gamma$,\nwhereas the expectation of the global clustering coefficient does not vanish\nonly when $\\gamma>3$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T16:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.02719v1","title":"The Myth of Immutability: A Multivocal Review on Smart Contract\n  Upgradeability","summary":"The immutability of smart contracts on blockchain platforms like Ethereum\npromotes security and trustworthiness but presents challenges for updates, bug\nfixes, or adding new features post-deployment. These limitations can lead to\nvulnerabilities and outdated functionality, impeding the evolution and\nmaintenance of decentralized applications. Despite various upgrade mechanisms\nproposed in academic research and industry, a comprehensive analysis of their\ntrade-offs and practical implications is lacking. This study aims to\nsystematically identify, classify, and evaluate existing smart contract upgrade\nmechanisms, bridging the gap between theoretical concepts and practical\nimplementations. It introduces standardized terminology and evaluates the\ntrade-offs of different approaches using software quality attributes. We\nconducted a Multivocal Literature Review (MLR) to analyze upgrade mechanisms\nfrom both academic research and industry practice. We first establish a unified\ndefinition of smart contract upgradeability and identify core components\nessential for understanding the upgrade process. Based on this definition, we\nclassify existing methods into full upgrade and partial upgrade approaches,\nintroducing standardized terminology to harmonize the diverse terms used in the\nliterature. We then characterize each approach and assess its benefits and\nlimitations using software quality attributes such as complexity, flexibility,\nsecurity, and usability. The analysis highlights significant trade-offs among\nupgrade mechanisms, providing valuable insights into the benefits and\nlimitations of each approach. These findings guide developers and researchers\nin selecting mechanisms tailored to specific project requirements.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T16:02:46Z"}
{"aid":"http://arxiv.org/abs/2504.02726v1","title":"Constraining hot and cold nuclear matter properties from heavy-ion\n  collisions and deep-inelastic scattering","summary":"We perform a global analysis of deep-inelastic $e+p$ scattering data from\nHERA and transverse energy distributions in $p+p$ and $p+\\Pb$ collisions,\nalongside charged hadron multiplicities in $\\Pb+\\Pb$ collisions at\n$\\sqrt{s_{\\mathrm{NN}}} = 5.02\\;\\mathrm{TeV}$ from ALICE. Using a\nsaturation-based initial state model grounded in high-energy QCD, we determine\nthe early-time non-equilibrium shear viscosity to entropy density ratio\n$\\eta/s$ of the quark-gluon plasma. Our results provide new insights into the\nearly-time transport properties of nuclear matter under extreme conditions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-03T16:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.02729v1","title":"Vortex Flows in the Solar Atmosphere: Detection and Heating Mechanisms\n  in 3D MHD Numerical Simulations","summary":"Vortex flows are structures associated with the rotation of the plasma and/or\nthe magnetic field that are present throughout the solar atmosphere. In recent\nyears, their study has become increasingly important, as they are present on a\nwide variety of temporal and spatial scales and can connect several layers of\nthe solar atmosphere. In this work, we focused on the detection and analysis of\nthese structures in an automatic way. We use realistic 3D MHD numerical\nsimulations obtained with the Mancha3D code at different magnetic field\nconfigurations and spatial resolutions. The vortex detection has been performed\nusing the novel SWIRL code. We have been able to determine multiple structures\nassociated with small and large scale vortices that extend in height in our\nsimulations. We performed a statistical analysis of these structures,\nquantifying their number and typical sizes, as well as their temperature and\nheating profiles, confirming their importance in the energy transport.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T16:12:11Z"}
{"aid":"http://arxiv.org/abs/2504.02731v1","title":"How Election Shocks Move Markets: Evidence from Sectoral Stock Prices","summary":"This paper examines the effects of U.S. presidential election cycles on\nsectoral stock markets. Using a high-frequency identification approach, I\nconstruct a novel \"election shock'' series, which captures exogenous surprises\nin election probabilities. Aside from election outcomes, the largest shocks are\nassociated with events that are orthogonal to innovations in the macroeconomy,\ne.g., scandals and debates. These shocks have immediate effects on asset prices\nin sectors that are differentially impacted by the policy platforms of the two\nmajor U.S. political parties. In particular, shocks favoring Republican\n(Democratic) candidates increase (decrease) the asset prices in the energy and\ndefense sectors, while decreasing (increasing) prices in the clean energy\nsector. These effects persist overtime.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-03T16:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.02733v1","title":"Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study","summary":"Large Language Models (LLMs) are highly vulnerable to input perturbations, as\neven a small prompt change may result in a substantially different output.\nExisting methods to enhance LLM robustness are primarily focused on perturbed\ndata samples, whereas improving resiliency to perturbations of task-level\ninstructions has remained relatively underexplored. In this work, we focus on\ncharacter- and word-level edits of task-specific instructions, which\nsubstantially degrade downstream performance. We experiment with a variety of\ntechniques to enhance the robustness of LLMs, including self-denoising and\nrepresentation alignment, testing different models (Llama 3 and Flan-T5),\ndatasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and\nrole-oriented). We find that, on average, self-denoising -- whether performed\nby a frozen LLM or a fine-tuned model -- achieves substantially higher\nperformance gains than alternative strategies, including more complex baselines\nsuch as ensembling and supervised methods.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:56Z"}
{"aid":"http://arxiv.org/abs/2504.02735v1","title":"Pushing the Limit of PPG Sensing in Sedentary Conditions by Addressing\n  Poor Skin-sensor Contact","summary":"Photoplethysmography (PPG) is a widely used non-invasive technique for\nmonitoring cardiovascular health and various physiological parameters on\nconsumer and medical devices. While motion artifacts are well-known challenges\nin dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a\ncritical issue often overlooked in existing literature - can distort PPG signal\nmorphology, leading to the loss or shift of essential waveform features and\ntherefore degrading sensing performance. In this work, we propose CP-PPG, a\nnovel approach that transforms Contact Pressure-distorted PPG signals into ones\nwith the ideal morphology. CP-PPG incorporates a novel data collection\napproach, a well-crafted signal processing pipeline, and an advanced deep\nadversarial model trained with a custom PPG-aware loss function. We validated\nCP-PPG through comprehensive evaluations, including 1) morphology\ntransformation performance on our self-collected dataset, 2) downstream\nphysiological monitoring performance on public datasets, and 3) in-the-wild\nperformance. Extensive experiments demonstrate substantial and consistent\nimprovements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement\nover the original signal) as well as downstream performance across all\nevaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate\n(RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR;\n41-46% in HRV; 6% in RR; and 4-5% in BP). These findings highlight the critical\nimportance of addressing skin-sensor contact issues for accurate and dependable\nPPG-based physiological monitoring. Furthermore, CP-PPG can serve as a generic,\nplug-in API to enhance PPG signal quality.","main_category":"cs.HC","categories":"cs.HC,cs.LG","published":"2025-04-03T16:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.02742v1","title":"Quantum synchronization blockade induced by nonreciprocal coupling","summary":"Recently, the synchronization of coupled quantum oscillators has attracted a\ngreat deal of interest. Synchronization requires driven constituents, and in\nsuch systems, the coupling can be designed to be nonreciprocal.\nNonreciprocally-coupled oscillators exhibit a rich variety of behavior\nincluding active traveling-wave type states. In this work, we study the\ninterplay of three competing synchronization mechanisms in a setup of two\nnonreciprocally-coupled quantum van der Pol oscillators. One of the oscillators\nis driven externally which induces phase locking. A dissipative interaction\nleads to anti-phase locking, whereas a coherent interaction nurtures bistable\nphase locking and active states. We approximate the phase diagram of the\nquantum case by evaluating the synchronization measure of a perturbation\nexpansion of the steady state. Furthermore, we study the phase diagrams of two\nand three oscillators in the mean-field limit and find highly nontrivial active\nstates.","main_category":"quant-ph","categories":"quant-ph,nlin.PS","published":"2025-04-03T16:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.02749v1","title":"Bacon-Shor Board Games","summary":"We identify a period-4 measurement schedule for the checks of the Bacon-Shor\ncode that fully covers spacetime with constant-weight detectors, and is\nnumerically observed to provide the code with a threshold. Unlike previous\napproaches, our method does not rely on code concatenation and instead arises\nas the solution to a coloring game on a square grid. Under a uniform\ncircuit-level noise model, we observe a threshold of approximately $0.3\\%$ when\ndecoding with minimum weight perfect matching, and we conjecture that this\ncould be improved using a more tailored decoder.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-03T16:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.02752v1","title":"Anomalous vortex Hall effect in a ferromagnet/superconductor\n  heterostructure","summary":"The coexistence of superconductivity and ferromagnetism is a fascinating and\ncomplex phenomenon in condensed matter physics, as these two states are\ntypically mutually exclusive due to their competing spin configurations.\nHowever, the interplay between these two orders through the proximity effect\nhas been a subject of intense research as it opens up possibilities for novel\ntechnological applications. Here, we report the coexistence of\nsuperconductivity and ferromagnetism in superconducting\n{\\delta}-TaN/ferromagnetic CoFeB heterostructures grown by facing-target\nsputtering. Superconducting states are comprehensively investigated, with\nevidence of strong correlation between the superconducting and ferromagnetic\norder parameters. In particular, we observed an anomalous Hall signal without\nthe presence of the magnetic field in the mixed state of the superconducting\ntransition near the critical temperature. Systematic characterizations of the\nHall resistance under varying temperatures and magnetic fields attribute this\nbehavior to the vortex Hall effect (VHE), whereby superconducting vortices in\nthe mixed state undergo transverse motions near the critical temperature.\nUnlike previously reported VHEs in conventional type-II superconductors, the\nanomalous VHE in TaN is induced by the stray field in the underlying CoFeB\nlayers. The concurrency of strong spin-orbit coupling, the superconductivity in\nthe TaN layer, and the highly spin-polarized ferromagnetic ordering in the\nCoFeB layer offers new insights into proximity-induced vortex dynamics and the\ndesign of novel superconducting spintronic devices.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-03T16:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.02755v1","title":"The MaNGA Dwarf Galaxy Sample (MaNDala): stellar profiles and gradients\n  characterization","summary":"We derived radial profiles and inner/outer gradients of various stellar\npopulation (SP) properties for 124 bright dwarf galaxies, $10^{7.53}\\leq\nM_*/M_\\odot\\leq 10^{9.06}$, from the MaNDala sample, using integral field\nspectroscopy observations. Given the complex structure of dwarf galaxies, we\nused four different methods to derive SP radial profiles: two based on\nconcentric elliptical rings, and two exploiting the spatially resolved data.\nFor each method, we applied four approaches to calculate the inner ($0 \\leq\nR/R_e \\leq 1$) and outer ($0.75 \\leq R/R_e \\leq 1.5$) gradients of: luminosity-\nand mass-weighted age and stellar metallicity, dust attenuation, $D_{n4000}$\nindex, stellar mass and star formation rate (SFR) surface densities, and\nspecific SFR. While the PSF has a minor impact on the SP gradients, the\nmethodology for characterizing radial profiles significantly affects them. At\nfixed property, differences in inner gradients from concentric rings methods\nare $\\sim0.05\\text{-}0.1 \\text{ dex/}R_e$, while outer gradients can reach\n$0.5\\text{-}1 \\text{ dex/}R_e$, relative to the median of all gradients of that\nproperty, $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$. Spatially resolved\nmethods yield smaller differences, $\\lesssim0.1 \\text{ dex/}R_e$. For some SP\ngradients, e.g. $\\nabla_\\text{SFR}$, the dispersion among the methods is\ncomparable to $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$. While it is\nnot possible to select a single preferred method for determining SP gradients,\nwe suggest to use $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$ for each SP\nproperty. The resulting median age and metallicity suggest that, overall,\nbright dwarfs experienced moderate inside-out formation, and significant early\nSF from low-metallicity gas with outward radial migration of old SPs. The\nderived SP gradients provide strong constraints on feedback mechanisms in dwarf\ngalaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:49:08Z"}
{"aid":"http://arxiv.org/abs/2504.02756v1","title":"Stability of acoustic streaming jets","summary":"We study the stability of a steady Eckart streaming jet that is acoustically\nforced at one end of a closed cylindrical cavity and impinges the wall at the\nother end, where a recirculation forms. This configuration generically\nrepresents industrial processes where acoustic forcing offers a contactless\nmeans of stirring or controlling confined flows. Successfully doing so,\nhowever, requires sufficient insight into the topology of the acoustically\nforced flow. This raises the question of whether the base acoustic streaming\njet is stable and, when not, of which alternative states emerge. Using Linear\nStability Analysis (LSA) and three-dimensional nonlinear simulations, we\nidentify the instability mechanisms and determine the nature of the\nbifurcations that ensue. We show that the ratio $C_R$ between the cavity and\nthe maximum beam radii determines the dominant unstable mode. For $4 \\leq C_R\n\\leq 6$, a non-oscillatory perturbation rooted in the jet impingement triggers\na supercritical bifurcation. For $C_R = 3$, the flow destabilises through a\nsubcritical non-oscillatory bifurcation. Further reducing $C_R$ increases the\nshear within the flow, and gradually relocates the instability in the shear\nlayer between impingement-induced vortices: for $C_R = 2$, an unstable\ntravelling wave grows out of a subcritical bifurcation, which becomes\nsupercritical for $C_R=1$. For each geometry, the nonlinear 3D simulations\nvalidate the LSA, identify the saturated nonlinear state and its stability.\nThis study offers fundamental insight into the stability of acoustically-driven\nflows in general, but also opens possible pathways to either induce turbulence\nacoustically, or to avoid it in realistic configurations.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T16:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.02772v1","title":"Interpreting gravitational fields of Topologically Massive Gravity using\n  geodesic deviation","summary":"We study relative motion of nearby test particles in Topologically Massive\nGravity (TMG) in three spacetime dimensions, using the equation of geodesic\ndeviation. We show that, in a suitable reference frame, the influence of any\ngravitational field can be decomposed into transverse, longitudinal, and\nNewtonian components, which are directly related to the Cotton scalars of the\nNewman-Penrose-type. In particular, we prove that Cotton type N spacetimes\nexhibit a purely transverse gravitational effect on test particles, and can\nthus be reasonably interpreted as specific gravitational waves with a single\npolarization mode in TMG. The influence of the cosmological constant manifests\nitself as an isotropic effect. We also discuss the physical interpretation of\nspacetimes of specific algebraic types, as well as the influence of various\nmatter fields, namely pure radiation, perfect fluid, and electromagnetic field.\nAs an example, we provide an explicit analysis of TN-waves and pp-waves in\nthree-dimensional TMG.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:08:37Z"}
{"aid":"http://arxiv.org/abs/2504.02782v1","title":"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image\n  Generation","summary":"The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:23:16Z"}
{"aid":"http://arxiv.org/abs/2504.02797v1","title":"Spline-based Transformers","summary":"We introduce Spline-based Transformers, a novel class of Transformer models\nthat eliminate the need for positional encoding. Inspired by workflows using\nsplines in computer animation, our Spline-based Transformers embed an input\nsequence of elements as a smooth trajectory in latent space. Overcoming\ndrawbacks of positional encoding such as sequence length extrapolation,\nSpline-based Transformers also provide a novel way for users to interact with\ntransformer latent spaces by directly manipulating the latent control points to\ncreate new latent trajectories and sequences. We demonstrate the superior\nperformance of our approach in comparison to conventional positional encoding\non a variety of datasets, ranging from synthetic 2D to large-scale real-world\ndatasets of images, 3D shapes, and animations.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T17:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.02805v1","title":"The M31-M33 Interaction: Impact on M31's Center of Mass Motion and\n  Satellite Orbits","summary":"Inspired by recent studies of the Milky Way--LMC interaction and its\nimplications for the Milky Way's global dynamical history, we investigate how\nthe massive satellite galaxy M33 influences Andromeda's (M31) center of mass\n(COM) position and velocity as it passes through M31's halo. Using recent\n6-dimensional phase space measurements for both galaxies, we use backward\nintegration to revisit M33's orbital history in a massive M31 potential\n($3\\times10^{12}\\,M_{\\odot}$) for the first time. As previously concluded, we\nfind that a first infall orbit is still the most statistically significant\n($\\gtrsim$ 90%) orbital solution for M33, except for a high mass M31 combined\nwith M31 proper motions from HST (as opposed to Gaia), where there is a greater\nlikelihood (~65%) of a previous encounter. However, the minimum distance\nbetween M33 and M31 during this passage is typically $\\geq$ 100 kpc, two to\nthree times larger than the distance required to explain M33's warped stellar\nand gaseous disks. We quantify the magnitude and direction of M31's evolving\nCOM position ($R_{COM}$) and velocity ($V_{COM}$) owing to M33, finding\n$R_{COM}\\approx$100-150 kpc at maximum and $V_{COM}\\approx$20-40 km s$^{-1}$.\nFurthermore, we explore the implications of this phenomenon for the M31\nsatellite system, specifically whether M33's gravitational influence is linked\nto the lopsided distribution of M31 satellites and whether M33 significantly\nperturbs the orbits of other M31 satellites. While M33 alone may not explain\nthe lopsided nature of M31's satellite system, its dynamical impact is\nnon-negligible and must be accounted for in future dynamical studies of the M31\nsystem.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.02807v1","title":"MegaMath: Pushing the Limits of Open Math Corpora","summary":"Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T17:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.02810v1","title":"Generative Evaluation of Complex Reasoning in Large Language Models","summary":"With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T17:54:18Z"}
{"aid":"http://arxiv.org/abs/2504.02822v1","title":"Do Two AI Scientists Agree?","summary":"When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T17:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.02823v1","title":"STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage\n  Security Inspection","summary":"Advancements in Computer-Aided Screening (CAS) systems are essential for\nimproving the detection of security threats in X-ray baggage scans. However,\ncurrent datasets are limited in representing real-world, sophisticated threats\nand concealment tactics, and existing approaches are constrained by a\nclosed-set paradigm with predefined labels. To address these challenges, we\nintroduce STCray, the first multimodal X-ray baggage security dataset,\ncomprising 46,642 image-caption paired scans across 21 threat categories,\ngenerated using an X-ray scanner for airport security. STCray is meticulously\ndeveloped with our specialized protocol that ensures domain-aware, coherent\ncaptions, that lead to the multi-modal instruction following data in X-ray\nbaggage security. This allows us to train a domain-aware visual AI assistant\nnamed STING-BEE that supports a range of vision-language tasks, including scene\ncomprehension, referring threat localization, visual grounding, and visual\nquestion answering (VQA), establishing novel baselines for multi-modal learning\nin X-ray baggage security. Further, STING-BEE shows state-of-the-art\ngeneralization in cross-domain settings. Code, data, and models are available\nat https://divs1159.github.io/STING-BEE/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.04718v1","title":"T1: Tool-integrated Self-verification for Test-time Compute Scaling in\n  Small Language Models","summary":"Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.04719v1","title":"Observations of fast radio variations in microquasars by FAST","summary":"Microquasars are the compact objects generally including accreting black\nholes which produce relativistic jets. The physical mechanisms of jet\nlaunching, collimation, and acceleration are poorly understood. Microquasars\nshow strong variability in multi-wavelength observations. In X-rays, the\nsources show the fast variation features down to millisecond time scales, with\nthe prominent quasiperiodic oscillations (QPOs) around 0.1 Hz - tens of Hz in\nlight curves, however, physical origin of QPOs is still uncertain. FAST as the\nlargest radio telescope provides the opportunity to study fast variability of\nboth radio flux and polarization in microquasars. In the FAST observations from\n2020 - 2022, we reported the first evidence of radio subsecond quasi-periodic\noscillations of GRS 1915+105, providing the direct link between QPOs and the\ndynamics of relativistic jets. These QPOs with the centroid frequency around 5\nHz are transient, accompanied with strong evolution of the spectral index.\nCombined with multiwavelength observations, we discuss the possible physical\nmodels to produce radio QPOs in BH systems: the helical motion of jet knots or\nprecession of the jet base. In near future, high time resolution radio\nmonitoring of microquasars based on FAST is expected to discover more new\nphenomena in black hole systems, which will be important to understand the\nphysics in strong gravity.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T04:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04721v1","title":"Bridging the Gap between Continuous and Informative Discrete\n  Representations by Random Product Quantization","summary":"Self-supervised learning has become a core technique in speech processing,\nbut the high dimensionality of its representations makes discretization\nessential for improving efficiency. However, existing discretization methods\nstill suffer from significant information loss, resulting in a notable\nperformance gap compared to continuous representations. To overcome these\nlimitations, we propose two quantization-based discretization methods: Product\nQuantization (PQ) and Random Product Quantization (RPQ). PQ partitions the\noriginal feature space into multiple subspaces and independently quantizes each\nsub-vector, producing a fused set of discrete units that retain diverse\ninformation from different subspaces, thus mitigating the loss associated with\nsingle-cluster quantization. RPQ further enhances representation diversity by\nrandomly sampling a fixed proportion of feature dimensions multiple times to\nconstruct sub-vectors, thereby better capturing the variability in the data\ndistribution. Theoretical analysis shows that RPQ reduces the correlation\ncoefficient rho (where 0 <= rho <= 1) between sub-quantizers. Its quantization\nerror is lower-bounded by the product of rho and epsilon-kms, where epsilon-kms\ndenotes the quantization error of a single K-means quantizer. Experimental\nresults on a combined dataset built from LibriSpeech and ML-SUPERB show that PQ\nand RPQ outperform standard K-means discretization, achieving relative\nimprovements of 21.8 percent and 20.0 percent in WER on LibriSpeech, and 24.1\npercent and 19.6 percent in CER on ML-SUPERB, respectively. Moreover, their\nperformance is competitive with, and in some cases even surpasses, that of\ncontinuous SSL representations.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-07T04:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.04723v1","title":"Quantum Incompatibility in Parallel vs Antiparallel Spins","summary":"We investigate the joint measurability of incompatible quantum observables on\nensembles of parallel and antiparallel spin pairs. In parallel configuration,\ntwo systems are identically prepared, whereas in antiparallel configuration\neach system is paired with its spin-flipped counterpart. We demonstrate that\nthe antiparallel configuration enables exact simultaneous prediction of three\nmutually orthogonal spin components -- an advantage unattainable in the\nparallel case. As we show, this enhanced measurement compatibility in\nantiparallel configuration is better explained within the framework of\ngeneralized probabilistic theories, which allow a broader class of composite\nstructures while preserving quantum descriptions at the subsystem level.\nFurthermore, this approach extends the study of measurement incompatibility to\nmore general configurations beyond just the parallel and antiparallel cases,\nproviding deeper insights into the boundary between physical and unphysical\nquantum state evolutions. To this end, we discuss how the enhanced measurement\ncompatibility in antiparallel configuration can be observed on a finite\nensemble of qubit states, paving the way for an experimental demonstration of\nthis advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T04:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04731v1","title":"A High-Performance Curve25519 and Curve448 Unified Elliptic Curve\n  Cryptography Accelerator","summary":"In modern critical infrastructure such as power grids, it is crucial to\nensure security of data communications between network-connected devices while\nfollowing strict latency criteria. This necessitates the use of cryptographic\nhardware accelerators. We propose a high-performance unified elliptic curve\ncryptography accelerator supporting NIST standard Montgomery curves Curve25519\nand Curve448 at 128-bit and 224-bit security levels respectively. Our\naccelerator implements extensive parallel processing of Karatsuba-style\nlarge-integer multiplications, restructures arithmetic operations in the\nMontgomery Ladder and exploits special mathematical properties of the\nunderlying pseudo-Mersenne and Solinas prime fields for optimized performance.\nOur design ensures efficient resource sharing across both curve computations\nand also incorporates several standard side-channel countermeasures. Our ASIC\nimplementation achieves record performance and energy of 10.38 $\\mu$s / 54.01\n$\\mu$s and 0.72 $\\mu$J / 3.73 $\\mu$J respectively for Curve25519 / Curve448,\nwhich is significantly better than state-of-the-art.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T05:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.04753v1","title":"CADCrafter: Generating Computer-Aided Design Models from Unconstrained\n  Images","summary":"Creating CAD digital twins from the physical world is crucial for\nmanufacturing, design, and simulation. However, current methods typically rely\non costly 3D scanning with labor-intensive post-processing. To provide a\nuser-friendly design process, we explore the problem of reverse engineering\nfrom unconstrained real-world CAD images that can be easily captured by users\nof all experiences. However, the scarcity of real-world CAD data poses\nchallenges in directly training such models. To tackle these challenges, we\npropose CADCrafter, an image-to-parametric CAD model generation framework that\ntrains solely on synthetic textureless CAD data while testing on real-world\nimages. To bridge the significant representation disparity between images and\nparametric CAD models, we introduce a geometry encoder to accurately capture\ndiverse geometric features. Moreover, the texture-invariant properties of the\ngeometric features can also facilitate the generalization to real-world\nscenarios. Since compiling CAD parameter sequences into explicit CAD models is\na non-differentiable process, the network training inherently lacks explicit\ngeometric supervision. To impose geometric validity constraints, we employ\ndirect preference optimization (DPO) to fine-tune our model with the automatic\ncode checker feedback on CAD sequence quality. Furthermore, we collected a\nreal-world dataset, comprised of multi-view images and corresponding CAD\ncommand sequence pairs, to evaluate our method. Experimental results\ndemonstrate that our approach can robustly handle real unconstrained CAD\nimages, and even generalize to unseen general objects.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T06:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.04755v1","title":"Effects of Surface Corrugation on Gas-Surface Scattering and Macroscopic\n  Flows","summary":"Gas-surface scattering exhibits a transition from thermal to structure\nscattering regime as incident energy increases, characterized by changes in\nangular and energy distributions. Capturing scattering behavior across\ndifferent regimes is essential for modeling momentum and energy exchange at the\ngas-surface interface. This study presents a corrugated Cercignani-Lampis-Lord\n(CLL) model to account for surface corrugation in scattering. It extends the\nwashboard-CLL hybrid approach by incorporating tangential momentum\naccommodation in local collisions. The model is validated against molecular\nbeam scattering experiments, focusing on its ability to reproduce the variation\nin scattering behavior with increasing incident energy. Compared to the\nconventional CLL model, the proposed model qualitatively improves the\nrepresentation of key features across the scattering regimes. In particular, it\ncaptures broader angular distributions and increasing reflected energy with\nreflected angle at higher incident energy. It is further applied to Direct\nSimulation Monte-Carlo (DSMC) analysis of rarefied flows over a cylinder and\nwithin an intake to examine the influence of surface corrugation on macroscopic\nflow behavior. The results show that surface corrugation has limited impact on\ntotal drag, while decreasing pressure drag and increasing friction drag. In the\nintake, enhanced tangential accommodation reduces capture efficiency and\nincreases compression ratio. These findings highlight the importance of\nincorporating surface corrugation in rarefied flow simulations under VLEO\nconditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T06:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.04762v1","title":"Extension of Yager's negation of probability distribution based on\n  uncertainty measures","summary":"Existing research on negations primarily focuses on entropy and extropy.\nRecently, new functions such as varentropy and varextropy have been developed,\nwhich can be considered as\n  extensions of entropy and extropy. However, the impact of negation on these\nextended measures, particularly varentropy and varextropy, has not been\nextensively explored. To address\n  this gap, this paper investigates the effect of negation on Shannon entropy,\nvarentropy, and varextropy. We explore how the negation of a probability\ndistribution influences these\n  measures, showing that the negated distribution consistently leads to higher\nvalues of Shannon entropy, varentropy, and varextropy compared to the original\ndistribution.\n  Additionally, we prove that the negation of a probability distribution\nmaximizes these measures during the process. The paper provides theoretical\nproofs and a detailed analysis of\n  the behaviour of these measures, contributing to a better understanding of\nthe interplay between probability distributions, negation, and\ninformation-theoretic quantities.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T06:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.04770v1","title":"Bidirectional Hierarchical Protein Multi-Modal Representation Learning","summary":"Protein representation learning is critical for numerous biological tasks.\nRecently, large transformer-based protein language models (pLMs) pretrained on\nlarge scale protein sequences have demonstrated significant success in\nsequence-based tasks. However, pLMs lack structural information. Conversely,\ngraph neural networks (GNNs) designed to leverage 3D structural information\nhave shown promising generalization in protein-related prediction tasks, but\ntheir effectiveness is often constrained by the scarcity of labeled structural\ndata. Recognizing that sequence and structural representations are\ncomplementary perspectives of the same protein entity, we propose a multimodal\nbidirectional hierarchical fusion framework to effectively merge these\nmodalities. Our framework employs attention and gating mechanisms to enable\neffective interaction between pLMs-generated sequential representations and\nGNN-extracted structural features, improving information exchange and\nenhancement across layers of the neural network. Based on the framework, we\nfurther introduce local Bi-Hierarchical Fusion with gating and global\nBi-Hierarchical Fusion with multihead self-attention approaches. Through\nextensive experiments on a diverse set of protein-related tasks, our method\ndemonstrates consistent improvements over strong baselines and existing fusion\ntechniques in a variety of protein representation learning benchmarks,\nincluding react (enzyme/EC classification), model quality assessment (MQA),\nprotein-ligand binding affinity prediction (LBA), protein-protein binding site\nprediction (PPBS), and B cell epitopes prediction (BCEs). Our method\nestablishes a new state-of-the-art for multimodal protein representation\nlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging\nsequence and structural modalities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.MN","published":"2025-04-07T06:47:49Z"}
{"aid":"http://arxiv.org/abs/2504.04775v1","title":"Low-Count X-ray Polarimetry using the Bayesian Approach Reveals Fast\n  Polarization Angle Variations","summary":"X-ray polarimetry of accreting compact object has revealed fast time\nvariations in the polarization angle (PA), suggesting that the geometry and/or\noptical depth of the corona is changing rapidly. This prompts investigations\ninto how fast such variability can be. Conventionally, the data are often\nbinned to examine the time variability such that the measurement in each bin is\nabove the minimum detectable polarization (MDP). Here we demonstrate that this\nis unnecessary, and even below the MDP, one can infer the posterior\ndistribution of PA reliably using the Bayesian approach and still be able to\nplace useful constraints on the physics in many cases. With this approach, we\ndiscovered that the PA variation in one of the Imaging X-ray Polarimetry\nExplorer (IXPE) observations of GX 13+1 is not following a linear rotation mode\nas suggested previously. Instead, the PA swings between two discrete angles,\nsuggesting that there are two emitting components, e.g., the boundary layer and\nthe spreading layer, competing with each other. Also in one of the observations\nof GX 13+1 and Sco X-1, the PA is found to vary in correlation with the source\ncount rate, indicating that the mass accretion rate is shaping the corona\nproperties. Also, during the IXPE observation of Sco X-1, the PA in highest\nflux level seems to deviate from the averaged value and appear to be consistent\nwith previous measurement results with PolarLight and OSO-8.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T07:09:08Z"}
{"aid":"http://arxiv.org/abs/2504.04777v1","title":"Dispersion in Rotating Electron-Positron-Ion Quantum Plasma","summary":"Quantum plasmas in astrophysical environments are abundant due to extreme\nelectric, magnetic, and gravitational fields. These plasmas can be most clearly\nobserved in neutron stars, white dwarfs, brown dwarfs, red dwarfs, accretion\ndisks of black holes, pulsars, quasars, and more. This paper examines the\npropagation of electromagnetic waves in a three-component e-p-i quantum plasma\nwithin a rotating frame, considering the particles' spin, Fermi pressure, and\nquantum Bohm potential. Additionally, effects unique to this specific\nenvironment, such as rotation and gravity, are included. The dispersion of\nelectrons, ions, and positrons has been obtained separately, and their coupling\nhas been analyzed to understand the collective behavior. It has been noted that\nthe quantum effects of Fermi pressure and Bohm potential significantly\ninfluence particle dynamics.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T07:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.04780v1","title":"Bottom-Up Scattering Information Perception Network for SAR target\n  recognition","summary":"Deep learning methods based synthetic aperture radar (SAR) image target\nrecognition tasks have been widely studied currently. The existing deep methods\nare insufficient to perceive and mine the scattering information of SAR images,\nresulting in performance bottlenecks and poor robustness of the algorithms. To\nthis end, this paper proposes a novel bottom-up scattering information\nperception network for more interpretable target recognition by constructing\nthe proprietary interpretation network for SAR images. Firstly, the localized\nscattering perceptron is proposed to replace the backbone feature extractor\nbased on CNN networks to deeply mine the underlying scattering information of\nthe target. Then, an unsupervised scattering part feature extraction model is\nproposed to robustly characterize the target scattering part information and\nprovide fine-grained target representation. Finally, by aggregating the\nknowledge of target parts to form the complete target description, the\ninterpretability and discriminative ability of the model is improved. We\nperform experiments on the FAST-Vehicle dataset and the SAR-ACD dataset to\nvalidate the performance of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:15:08Z"}
{"aid":"http://arxiv.org/abs/2504.04792v1","title":"Uniqueness and Longtime Behavior of the Completely Positively Correlated\n  Symbiotic Branching Model","summary":"The symbiotic branching model in $\\mathbb{R}$ describes the behavior of two\nbranching populations migrating in space $\\mathbb{R}$ in terms of a\ncorresponding system of stochastic partial differential equations. The system\nis parametrized with a correlation parameter $\\rho$, which takes values in\n$[-1,1]$ and governs the correlation between the branching mechanisms of the\ntwo populations. While existence and uniqueness for this system were\nestablished for $\\rho \\in [-1,1)$, weak uniqueness for the completely\npositively correlated case of $\\rho = 1$ has been an open problem. In this\npaper, we resolve this problem, establishing weak uniqueness for the\ncorresponding system of stochastic partial differential equations. The proof\nuses a new duality between the symbiotic branching model and the well-known\nparabolic Anderson model. Furthermore, we use this duality to investigate the\nlong-term behavior of the completely positively correlated symbiotic branching\nmodel. We show that, under suitable initial conditions, after a long time, one\nof the populations dies out. We treat the case of integrable initial conditions\nand the case of bounded non-integrable initial conditions with well-defined\nmean.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.04803v1","title":"Out of Sight, Still at Risk: The Lifecycle of Transitive Vulnerabilities\n  in Maven","summary":"The modern software development landscape heavily relies on transitive\ndependencies. They enable seamless integration of third-party libraries.\nHowever, they also introduce security challenges. Transitive vulnerabilities\nthat arise from indirect dependencies expose projects to risks associated with\nCommon Vulnerabilities and Exposures (CVEs). It happens even when direct\ndependencies remain secure. This paper examines the lifecycle of transitive\nvulnerabilities in the Maven ecosystem. We employ survival analysis to measure\nthe time projects remain exposed after a CVE is introduced. Using a large\ndataset of Maven projects, we identify factors that influence the resolution of\nthese vulnerabilities. Our findings offer practical advice on improving\ndependency management.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-07T07:54:15Z"}
{"aid":"http://arxiv.org/abs/2504.04807v1","title":"Fast gates for bit-flip protected superconducting qubits","summary":"Superconducting qubits offer an unprecedentedly high degree of flexibility in\nterms of circuit encoding and parameter choices. However, in designing the\nqubit parameters one typically faces the conflicting goals of long coherence\ntimes and simple control capabilities. Both are determined by the wavefunction\noverlap of the qubit basis states and the corresponding matrix elements. Here,\nwe address this problem by introducing a qubit architecture with real-time\ntunable bit-flip protection. In the first, the `heavy' regime, the energy\nrelaxation time can be on the order of hours for fluxons located in two\nnear-degenerate ground states, as recently demonstrated in Ref. [Hassani et\nal., Nat.~Commun.~14 (2023)]. The second, `light' regime, on the other hand\nfacilitates high-fidelity control on nanosecond timescales without the need for\nmicrowave signals. We propose two different tuning mechanisms of the qubit\npotential and show that base-band flux-pulses of around 10 ns are sufficient to\nrealize a universal set of high-fidelity single- and two-qubit gates. We expect\nthat the concept of real-time wavefunction control can also be applied to other\nhardware-protected qubit designs.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-07T08:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.04814v1","title":"Explainability of AI Uncertainty: Application to Multiple Sclerosis\n  Lesion Segmentation on MRI","summary":"Trustworthy artificial intelligence (AI) is essential in healthcare,\nparticularly for high-stakes tasks like medical image segmentation. Explainable\nAI and uncertainty quantification significantly enhance AI reliability by\naddressing key attributes such as robustness, usability, and explainability.\nDespite extensive technical advances in uncertainty quantification for medical\nimaging, understanding the clinical informativeness and interpretability of\nuncertainty remains limited. This study introduces a novel framework to explain\nthe potential sources of predictive uncertainty, specifically in cortical\nlesion segmentation in multiple sclerosis using deep ensembles. The proposed\nanalysis shifts the focus from the uncertainty-error relationship towards\nrelevant medical and engineering factors. Our findings reveal that\ninstance-wise uncertainty is strongly related to lesion size, shape, and\ncortical involvement. Expert rater feedback confirms that similar factors\nimpede annotator confidence. Evaluations conducted on two datasets (206\npatients, almost 2000 lesions) under both in-domain and distribution-shift\nconditions highlight the utility of the framework in different scenarios.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-07T08:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.04824v1","title":"Optimal regularity for degenerate parabolic equations on a flat boundary","summary":"We establish the optimal regularity of viscosity solutions to\n  \\begin{equation*}\n  u_t - x_n^\\gamma \\Delta u = f,\n  \\end{equation*} which arises in the regularity theory for the porous medium\nequation. Specifically, we prove that under the zero Dirichlet boundary\ncondition on $\\{x_n=0\\}$, the optimal regularity of $u$ up to the flat boundary\n$\\{x_n=0\\}$ is $C^{1,1-\\gamma}$. Moreover, for the homogeneous equations, we\nestablish that the optimal regularity of $u$ is $C^{2,1-\\gamma}$ in the spatial\nvariables, and that $x_n^{-\\gamma}u$ is smooth in the variables $x'$ and $t$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T08:25:02Z"}
{"aid":"http://arxiv.org/abs/2504.04826v1","title":"A structure and asymptotic preserving scheme for the quasineutral limit\n  of the Vlasov-Poisson system","summary":"In this work, we propose a new numerical method for the Vlasov-Poisson system\nthat is both asymptotically consistent and stable in the quasineutral regime,\ni.e. when the Debye length is small compared to the characteristic spatial\nscale of the physical domain. Our approach consists in reformulating the\nVlasov-Poisson system as a hyperbolic problem by applying a spectral expansion\nin the basis of Hermite functions in the velocity space and in designing a\nstructure-preserving scheme for the time and spatial variables. Through this\nHermite formulation, we establish a convergence result for the electric field\ntoward its quasineutral limit together with optimal error estimates. Following\nthis path, we then propose a fully discrete numerical method for the\nVlasov-Poisson system, inspired by the approach in arXiv:2306.14605 , and\nrigorously prove that it is uniformly consistent in the quasineutral limit\nregime. Finally, we present several numerical simulations to illustrate the\nbehavior of the proposed scheme. These results demonstrate the capability of\nour method to describe quasineutral plasmas and confirm the theoretical\nfindings: stability and asymptotic preservation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T08:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.04833v1","title":"Explanation-Driven Interventions for Artificial Intelligence Model\n  Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology","summary":"The integration of Artificial Intelligence (AI) in modern society is heavily\nshifting the way that individuals carry out their tasks and activities.\nEmploying AI-based systems raises challenges that designers and developers must\naddress to ensure that humans remain in control of the interaction process,\nparticularly in high-risk domains. This article presents a novel End-User\nDevelopment (EUD) approach for black-box AI models through a redesigned user\ninterface in the Rhino-Cyt platform, a medical AI-based decision-support system\nfor medical professionals (more precisely, rhinocytologists) to carry out cell\nclassification. The proposed interface empowers users to intervene in AI\ndecision-making process by editing explanations and reconfiguring the model,\ninfluencing its future predictions. This work contributes to Human-Centered AI\n(HCAI) and EUD by discussing how explanation-driven interventions allow a blend\nof explainability, user intervention, and model reconfiguration, fostering a\nsymbiosis between humans and user-tailored AI systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-07T08:44:48Z"}
{"aid":"http://arxiv.org/abs/2504.04844v1","title":"Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM","summary":"Simultaneous localization and mapping (SLAM) technology now has\nphotorealistic mapping capabilities thanks to the real-time high-fidelity\nrendering capability of 3D Gaussian splatting (3DGS). However, due to the\nstatic representation of scenes, current 3DGS-based SLAM encounters issues with\npose drift and failure to reconstruct accurate maps in dynamic environments. To\naddress this problem, we present D4DGS-SLAM, the first SLAM method based on\n4DGS map representation for dynamic environments. By incorporating the temporal\ndimension into scene representation, D4DGS-SLAM enables high-quality\nreconstruction of dynamic scenes. Utilizing the dynamics-aware InfoModule, we\ncan obtain the dynamics, visibility, and reliability of scene points, and\nfilter stable static points for tracking accordingly. When optimizing Gaussian\npoints, we apply different isotropic regularization terms to Gaussians with\nvarying dynamic characteristics. Experimental results on real-world dynamic\nscene datasets demonstrate that our method outperforms state-of-the-art\napproaches in both camera pose tracking and map quality.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T08:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04863v1","title":"Dynamic hysteresis model of grain-oriented ferromagnetic material using\n  neural operators","summary":"Accurately capturing the behavior of grain-oriented (GO) ferromagnetic\nmaterials is crucial for modeling the electromagnetic devices. In this paper,\nneural operator models, including Fourier neural operator (FNO), U-net combined\nFNO (U-FNO) and Deep operator network (DeepONet) are used to approximate the\ndynamic hysteresis models of GO steel. Furthermore, two types of data\naugmentation strategies including cyclic rolling augmentation and Gaussian data\naugmentation (GDA) are implemented to enhance the learning ability of models.\nWith the inclusion of these augmentation techniques, the optimized models\naccount for not only the peak values of the magnetic flux density but also the\neffects of different frequencies and phase shifts. The accuracy of all models\nis assessed using the L2-norm of the test data and the mean relative error\n(MRE) of calculated core losses. Each model performs well in different\nscenarios, but FNO consistently achieves the best performance across all cases.","main_category":"eess.SY","categories":"eess.SY,cond-mat.mtrl-sci,cs.SY,physics.data-an","published":"2025-04-07T09:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.04864v1","title":"Statistical parametric simulation studies based on real data","summary":"Simulation studies are indispensable for evaluating and comparing statistical\nmethods. The most common simulation approach is parametric simulation, where\nthe data-generating mechanism (DGM) corresponds to a predefined parametric\nmodel from which observations are drawn. Many statistical simulation studies\naim to provide practical recommendations on a method's suitability for a given\napplication; however, parametric simulations in particular are frequently\ncriticized for being too simplistic and not reflecting reality. To overcome\nthis drawback, it is generally considered a sensible approach to employ real\ndata for constructing the parametric DGMs. However, while the concept of\nreal-data-based parametric DGMs is widely recognized, the specific ways in\nwhich DGM components are inferred from real data vary, and their implications\nmay not always be well understood. Additionally, researchers often rely on a\nlimited selection of real datasets, with the rationale for their selection\noften unclear. This paper addresses these issues by formally discussing how\ncomponents of parametric DGMs can be inferred from real data and how dataset\nselection can be performed more systematically. By doing so, we aim to support\nresearchers in conducting simulation studies with a lower risk of\novergeneralization and misinterpretation. We illustrate the construction of\nparametric DGMs based on a systematically selected set of real datasets using\ntwo examples: one on ordinal outcomes in randomized controlled trials and one\non differential gene expression analysis.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:19:28Z"}
{"aid":"http://arxiv.org/abs/2504.04867v1","title":"FedSAUC: A Similarity-Aware Update Control for Communication-Efficient\n  Federated Learning in Edge Computing","summary":"Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T09:21:43Z"}
{"aid":"http://arxiv.org/abs/2504.04872v1","title":"Simulating Persuasive Dialogues on Meat Reduction with Generative Agents","summary":"Meat reduction benefits human and planetary health, but social norms keep\nmeat central in shared meals. To date, the development of communication\nstrategies that promote meat reduction while minimizing social costs has\nrequired the costly involvement of human participants at each stage of the\nprocess. We present work in progress on simulating multi-round dialogues on\nmeat reduction between Generative Agents based on large language models (LLMs).\nWe measure our main outcome using established psychological questionnaires\nbased on the Theory of Planned Behavior and additionally investigate Social\nCosts. We find evidence that our preliminary simulations produce outcomes that\nare (i) consistent with theoretical expectations; and (ii) valid when compared\nto data from previous studies with human participants. Generative agent-based\nmodels are a promising tool for identifying novel communication strategies on\nmeat reduction-tailored to highly specific participant groups-to then be tested\nin subsequent studies with human participants.","main_category":"cs.CY","categories":"cs.CY,cs.HC,cs.MA","published":"2025-04-07T09:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.04875v1","title":"Note on some Gromoll filtration groups and fundamental groups of\n  $\\mathrm{Diff}_{\\partial}(D^n)$","summary":"In this note, we will compute some Gromoll filtration groups\n$\\Gamma^{n+1}_{i+1}$ for certain $i$ when $8\\leq n \\leq 17$ and $n=4k+2\\geq\n18$. We will also use these results to obtain some information of\n$\\pi_1\\mathrm{Diff}_{\\partial} (D^n)$ when $6\\leq n \\leq 15$ and $\\pi_2\n\\mathrm{Diff}_{\\partial} (D^{4k+3})$ when $4k+3\\geq 15$.","main_category":"math.AT","categories":"math.AT,math.GT","published":"2025-04-07T09:31:20Z"}
{"aid":"http://arxiv.org/abs/2504.04879v1","title":"Mixed memories in Hopfield networks","summary":"We consider the class of Hopfield models of associative memory with\nactivation function $F$ and state space $\\{-1,1\\}^N$, where each vertex of the\ncube describes a configuration of $N$ binary neurons. $M$ randomly chosen\nconfigurations, called patterns, are stored using an energy function designed\nto make them local minima. If they are, which is known to depend on how $M$\nscales with $N$, then they can be retrieved using a dynamics that decreases the\nenergy. However, storing the patterns in the energy function also creates\nunintended local minima, and thus false memories. Although this has been known\nsince the earliest work on the subject, it has only been supported by numerical\nsimulations and non-rigorous calculations, except in elementary cases.\n  Our results are twofold. For a generic function $F$, we explicitly construct\na set of configurations, called mixed memories, whose properties are intended\nto characterise the local minima of the energy function. For three prominent\nmodels, namely the classical, the dense and the modern Hopfield models,\nobtained for quadratic, polynomial and exponential functions $F$ respectively,\nwe give conditions on the growth rate of $M$ which guarantee that, as $N$\ndiverges, mixed memories are fixed points of the retrieval dynamics and thus\nexact minima of the energy. We conjecture that in this regime, all local minima\nare mixed memories.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04887v1","title":"A mechanism for growth of topological entropy and global changes of the\n  shape of chaotic attractors","summary":"The theoretical and numerical understanding of the key concept of topological\nentropy is an important problem in dynamical systems. Most studies have been\ncarried out on maps (discrete-time systems). We analyse a scenario of global\nchanges of the structure of an attractor in continuous-time systems leading to\nan unbounded growth of the topological entropy of the underlying dynamical\nsystem. As an example, we consider the classical Roessler system. We show that\nfor an explicit range of parameters a chaotic attractor exists. We also prove\nthe existence of a sequence of bifurcations leading to the growth of the\ntopological entropy. The proofs are computer-aided.","main_category":"math.DS","categories":"math.DS,cs.NA,math.NA,nlin.CD","published":"2025-04-07T09:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.04902v1","title":"Constructibility real degrees in the side-by-side Sacks model","summary":"We study the join-semilattice of constructibility real degrees in the\nside-by-side Sacks model, the model of set theory obtained by forcing with a\ncountable-support product of infinitely many Sacks forcings over the\nconstructible universe. In particular, we prove that in the side-by-side Sacks\nmodel the join-semilattice of constructibility real degrees is rigid, i.e. it\ndoes not have non-trivial automorphisms.","main_category":"math.LO","categories":"math.LO","published":"2025-04-07T10:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.04910v1","title":"Fault Localisation in Infinite-Dimensional Linear Electrical Networks","summary":"We present a novel fault localisation methodology for linear time-invariant\nelectrical networks with infinite-dimensional edge dynamics and uncertain fault\ndynamics. The theory accommodates instability and also bounded propagation\ndelays in the network. The goal is to estimate the location of a fault along a\ngiven network edge, using sensors positioned arbitrarily throughout the\nnetwork. Passive faults of unknown impedance are considered, along with stable\nfaults of known impedance. To illustrate the approach, we tackle a significant\nuse-case: a multi-conductor transmission line, with dynamics modelled by the\nTelegrapher's equation, subject to a line-to-ground fault. Frequency-domain\ninsights are used to reformulate the general fault localisation problem into a\nnon-convex scalar optimisation problem, of which the true fault location is\nguaranteed to be a global minimiser. Numerical experiments are run to quantify\nlocalisation performance over a range of fault resistances.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP,math.DS","published":"2025-04-07T10:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.04924v1","title":"Inter-event Interval Microscopy for Event Cameras","summary":"Event cameras, an innovative bio-inspired sensor, differ from traditional\ncameras by sensing changes in intensity rather than directly perceiving\nintensity and recording these variations as a continuous stream of \"events\".\nThe intensity reconstruction from these sparse events has long been a\nchallenging problem. Previous approaches mainly focused on transforming\nmotion-induced events into videos or achieving intensity imaging for static\nscenes by integrating modulation devices at the event camera acquisition end.\nIn this paper, for the first time, we achieve event-to-intensity conversion\nusing a static event camera for both static and dynamic scenes in fluorescence\nmicroscopy. Unlike conventional methods that primarily rely on event\nintegration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the\ntime interval between consecutive events at each pixel. With a fixed threshold\nin the event camera, the time interval can precisely represent the intensity.\nAt the hardware level, the proposed IEIM integrates a pulse light modulation\ndevice within a microscope equipped with an event camera, termed Pulse\nModulation-based Event-driven Fluorescence Microscopy.mAdditionally, we have\ncollected IEIMat dataset under various scenes including high dynamic range and\nhigh-speed scenarios. Experimental results on the IEIMat dataset demonstrate\nthat the proposed IEIM achieves superior spatial and temporal resolution, as\nwell as a higher dynamic range, with lower bandwidth compared to other methods.\nThe code and the IEIMat dataset will be made publicly available.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T11:05:13Z"}
{"aid":"http://arxiv.org/abs/2504.04929v1","title":"The Linearized Vlasov-Maxwell System as a Hamiltonian System","summary":"We present a Hamiltonian formulation for the linearized Vlasov-Maxwell system\nwith a Maxwellian background distribution function. We discuss the geometric\nproperties of the model at the continuous level, and how to discretize the\nmodel in the GEMPIC framework [1]. This method allows us to keep the structure\nof the system at the semi-discrete level. To integrate the model in time, we\nemploy a Poisson splitting and discuss how to integrate each subsystem\nseparately. We test the model against the full Vlasov-Maxwell model with a\ncontrol variate method for noise reduction; the two chosen test-cases are the\nweak Landau damping and the Bernstein waves. Both test-cases exhibit the same\nphysical properties for short simulations but our model enjoys better long-time\nstability and energy conservation due to its geometric construction. The model\nis implemented in the open-source Python library STRUPHY [2, 3].","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T11:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.04946v1","title":"Scalable chip-based 3D ion traps","summary":"Ion traps are used for a wide range of applications from metrology to quantum\nsimulations and quantum information processing. Microfabricated chip-based 3D\nion traps are scalable to store many ions for the realization of a large number\nof qubits, provide deep trapping potentials compared to surface traps, and very\ngood shielding from external electric fields. In this work, we give an overview\nof our recent developments on chip-based 3D ion traps. Different types of chip\nmaterials, the integration of electronic filter components on-chip and compact\nelectrical connections in vacuum are discussed. Further, based on finite\nelement method (FEM) simulations, we discuss how integrating micro-optics in 3D\nion traps is possible without disturbing the trapped ions.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-07T11:33:37Z"}
{"aid":"http://arxiv.org/abs/2504.04988v1","title":"RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with\n  a Multi-Modal Dataset and Retrieval-Augmented Generation Model","summary":"Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T12:13:43Z"}
{"aid":"http://arxiv.org/abs/2504.04993v1","title":"Duality invariance of Faltings heights, Hodge line bundles and global\n  periods","summary":"We prove that an abelian variety and its dual over a global field have the\nsame Faltings height and, more precisely, have isomorphic Hodge line bundles,\nincluding their natural metrized bundle structures. More carefully treating\nreal places, we also show that these abelian varieties have the same real and\nglobal periods that appear in the Birch-Swinnerton-Dyer conjecture.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-07T12:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.05007v1","title":"Measuring the right thing: justifying metrics in AI impact assessments","summary":"AI Impact Assessments are only as good as the measures used to assess the\nimpact of these systems. It is therefore paramount that we can justify our\nchoice of metrics in these assessments, especially for difficult to quantify\nethical and social values. We present a two-step approach to ensure metrics are\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\nfairness or fairness as solidarity) and then a metric can be fitted to that\nconception. Both steps require separate justifications, as conceptions can be\njudged on how well they fit with the function of, for example, fairness. We\nargue that conceptual engineering offers helpful tools for this step. Second,\nmetrics need to be fitted to a conception. We illustrate this process through\nan examination of competing fairness metrics to illustrate that here the\nadditional content that a conception offers helps us justify the choice for a\nspecific metric. We thus advocate that impact assessments are not only clear on\ntheir metrics, but also on the conceptions that motivate those metrics.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.ET","published":"2025-04-07T12:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.05027v1","title":"Indistinguishability of unbounded components in the occupied and vacant\n  sets of Boolean models on symmetric spaces","summary":"We study Boolean models on Riemannian symmetric spaces driven by homogeneous\ninsertion- or deletion-tolerant point processes. We prove that in both the set\ncovered by the balls (the occupied set) and its complement (the vacant set),\none cannot distinguish unbounded components from each other by any isometry\ninvariant component property. This implies the uniqueness monotonicity for the\noccupied and vacant sets of Poisson-Boolean models and an equivalence of\nnon-uniqueness to the decay of connectivity for both sets. These results are\ncontinuum analogues of those by Lyons and Schramm arXiv:math/9811170. However,\nunlike the proof of the indistinguishability in arXiv:math/9811170, our proof\ndoes not rely on transience of unbounded components. We also prove the\nexistence of a percolation phase transition for independent Poisson-Boolean\nmodel on unbounded connected components of both occupied and vacant sets and\nshow transience of a random walk on the occupied set. Apart from some technical\ndifferences, we treat the occupied and the vacant sets of Boolean models within\na single framework.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T12:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.05034v1","title":"Dominating Hyperplane Regularization for Variable Selection in\n  Multivariate Count Regression","summary":"Identifying relevant factors that influence the multinomial counts in\ncompositional data is difficult in high dimensional settings due to the complex\nassociations and overdispersion. Multivariate count models such as the\nDirichlet-multinomial (DM), negative multinomial, and generalized DM\naccommodate overdispersion but are difficult to optimize due to their\nnon-concave likelihood functions. Further, for the class of regression models\nthat associate covariates to the multivariate count outcomes, variable\nselection becomes necessary as the number of potentially relevant factors\nbecomes large. The sparse group lasso (SGL) is a natural choice for\nregularizing these models. Motivated by understanding the associations between\nwater quality and benthic macroinvertebrate compositions in Canada's Athabasca\noil sands region, we develop dominating hyperplane regularization (DHR), a\nnovel method for optimizing regularized regression models with the SGL penalty.\nUnder the majorization-minimization framework, we show that applying DHR to a\nSGL penalty gives rise to a surrogate function that can be expressed as a\nweighted ridge penalty. Consequently, we prove that for multivariate count\nregression models with the SGL penalty, the optimization leads to an\niteratively reweighted Poisson ridge regression. We demonstrate stable\noptimization and high performance of our algorithm through simulation and real\nworld application to benthic macroinvertebrate compositions.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-07T12:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05036v1","title":"Hybrid Nitsche for distributed computing","summary":"We extend the distributed finite element method of [1], built upon model\norder reduction, to arbitrary polynomial degree using a hybrid Nitsche scheme.\nThis new method considerably simplifies the transformation of the finite\nelement system to the reduced basis for large problems. We prove that the error\nof the reduced Nitsche solution converges optimally with respect to the\napproximation order of the finite element spaces and linearly with respect to\nthe dimension reduction parameter $\\epsilon$. Numerical tests with nontrivial\ntetrahedral meshes using second-degree polynomial bases support the theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05037v1","title":"Optimizing flow control with ensemble Kalman method for mitigating\n  flow-induced vibration","summary":"The ensemble Kalman method is introduced for optimizing flow control\nstrategies in order to mitigate the flow-induced vibration of structures.\nDifferent types of control strategies such as passive control, open-loop active\ncontrol, and closed-loop active control are tested, showing the flexibility of\nthe method in flow control optimization. The ensemble Kalman method is first\ntested to mitigate vortex shedding of flows around a circular cylinder by\noptimizing the placement of small cylinders downstream. Further, the method is\nassessed to suppress shock buffeting over the NACA 0012 airfoil by optimizing\nthe movement of a compliant aileron. Our results for all test cases show that\nthe ensemble-based method can effectively find optimal control strategies that\nsignificantly reduce the vibrations of aerodynamic force, and can be a useful\nalternative for flow control optimization, due to its merits in\nnon-intrusiveness and ease of implementation.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T12:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.05039v1","title":"Outerplanar and bounded treewidth support for hypergraphs","summary":"We study the existence and construction of sparse supports for hypergraphs\nderived from subgraphs of a graph $G$. For a hypergraph $(X,\\mathcal{H})$, a\nsupport $Q$ is a graph on $X$ s.t. $Q[H]$, the graph induced on vertices in $H$\nis connected for every $H\\in\\mathcal{H}$.\n  We consider \\emph{primal}, \\emph{dual}, and \\emph{intersection} hypergraphs\ndefined by subgraphs of a graph $G$ that are \\emph{non-piercing}, (i.e., each\nsubgraph is connected, their pairwise differences remain connected).\n  If $G$ is outerplanar, we show that the primal, dual and intersection\nhypergraphs admit supports that are outerplanar. For a bounded treewidth graph\n$G$, we show that if the subgraphs are non-piercing, then there exist supports\nfor the primal and dual hypergraphs of treewidth $O(2^{tw(G)})$ and\n$O(2^{4tw(G)})$ respectively, and a support of treewidth $2^{O(2^{tw(G)})}$ for\nthe intersection hypergraph. We also show that for the primal and dual\nhypergraphs, the exponential blow-up of treewidth is sometimes essential.\n  All our results are algorithmic and yield polynomial-time algorithms (when\nthe treewidth is bounded). The existence and construction of sparse supports is\na crucial step in the design and analysis of PTASs and/or sub-exponential time\nalgorithms for several packing and covering problems.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-07T13:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05055v1","title":"Detecting relevant dependencies under measurement error with\n  applications to the analysis of planetary system evolution","summary":"Exoplanets play an important role in understanding the mechanics of planetary\nsystem formation and orbital evolution. In this context the correlations of\ndifferent parameters of the planets and their host star are useful guides in\nthe search for explanatory mechanisms. Based on a reanalysis of the data set\nfrom \\cite{figueria14} we study the as of now still poorly understood\ncorrelation between planetary surface gravity and stellar activity of Hot\nJupiters. Unfortunately, data collection often suffers from measurement errors\ndue to complicated and indirect measurement setups, rendering standard\ninference techniques unreliable.\n  We present new methods to estimate and test for correlations in a\ndeconvolution framework and thereby improve the state of the art analysis of\nthe data in two directions. First, we are now able to account for additive\nmeasurement errors which facilitates reliable inference. Second we test for\nrelevant changes, i.e. we are testing for correlations exceeding a certain\nthreshold $\\Delta$. This reflects the fact that small nonzero correlations are\nto be expected for real life data almost always and that standard statistical\ntests will therefore always reject the null of no correlation given sufficient\ndata. Our theory focuses on quantities that can be estimated by U-Statistics\nwhich contain a variety of correlation measures. We propose a bootstrap test\nand establish its theoretical validity. As a by product we also obtain\nconfidence intervals. Applying our methods to the Hot Jupiter data set from\n\\cite{figueria14}, we observe that taking into account the measurement errors\nyields smaller point estimates and the null of no relevant correlation is\nrejected only for very small $\\Delta$. This demonstrates the importance of\nconsidering the impact of measurement errors to avoid misleading conclusions\nfrom the resulting statistical analysis.","main_category":"stat.ME","categories":"stat.ME,astro-ph.EP,astro-ph.IM,math.ST,stat.TH","published":"2025-04-07T13:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.05059v1","title":"MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal\n  Trajectory Prediction","summary":"Accurate vehicle trajectory prediction is critical for safe and efficient\nautonomous driving, especially in mixed traffic environments with both\nhuman-driven and autonomous vehicles. However, uncertainties introduced by\ninherent driving behaviors -- such as acceleration, deceleration, and left and\nright maneuvers -- pose significant challenges for reliable trajectory\nprediction. We introduce a Maneuver-Intention-Aware Transformer (MIAT)\narchitecture, which integrates a maneuver intention awareness mechanism with\nspatiotemporal interaction modeling to enhance long-horizon trajectory\npredictions. We systematically investigate the impact of varying awareness of\nmaneuver intention on both short- and long-horizon trajectory predictions.\nEvaluated on the real-world NGSIM dataset and benchmarked against various\ntransformer- and LSTM-based methods, our approach achieves an improvement of up\nto 4.7% in short-horizon predictions and a 1.6% in long-horizon predictions\ncompared to other intention-aware benchmark methods. Moreover, by leveraging an\nintention awareness control mechanism, MIAT realizes an 11.1% performance boost\nin long-horizon predictions, with a modest drop in short-horizon performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T13:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.05069v1","title":"Weak thermal fluctuations impede steering of chiral magnetic nanobots","summary":"Rotating magnetic field is an efficient method of actuation of synthetic\ncolloids in liquids. In this Letter we theoretically study the effect of the\nthermal noise on torque-driven steering of magnetic nanohelices. Using a\ncombination of numerical and analytical methods, we demonstrate that\nsurprisingly a weak thermal noise can substantially disrupt the orientation and\nrotation of the nanohelix, severely impeding its propulsion. The results of\nLangevin simulations are in excellent agreement with the numerical solution of\nthe Fokker-Planck equation and the analytical effective field approximation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.05091v1","title":"Morse Index Theorem for Sturm-Liouville Operators on the Real Line","summary":"The classical Morse index theorem establishes a fundamental connection\nbetween the Morse index-the number of negative eigenvalues that characterize\nkey spectral properties of linear self-adjoint differential operators-and the\ncount of corresponding conjugate points. In this paper, we extend these\nfoundational results to the Sturm-Liouville operator on $\\mathbb{R}$. In\nparticular, for autonomous Lagrangian systems, we employ a geometric argument\nto derive a lower bound for the Morse index. As concrete applications, we\nestablish a criterion for detecting instability in traveling waves within\ngradient reaction-diffusion systems.","main_category":"math.DS","categories":"math.DS","published":"2025-04-07T14:00:13Z"}
{"aid":"http://arxiv.org/abs/2504.05092v1","title":"Distortions in Periodicity Analysis of Blazars: The Impact of Flares","summary":"Blazars, a unique class of active galactic nuclei, exhibit highly variable\nemission across the electromagnetic spectrum. This variability frequently\nmanifests as intense flaring events, sparking an ongoing debate in recent\nliterature about whether these flares exhibit periodic behavior in certain\nsources. However, many blazars also show clear signs of stochastic,\nuncorrelated flares that do not follow a regular pattern. This paper explores\nhow the presence of one such of these stochastic flares can distort an\nintrinsically periodic pattern of emission in blazars. Our results demonstrate\nthat, depending on the specific circumstances, the deviations in significance\nand periods can exceed 100\\%. Sometimes, these deviations can be so severe that\nthey eliminate any evidence of a periodic pattern. These findings highlight the\ndramatic impact that flares can have on periodicity searches. To confront this\nchallenge, we propose an innovative approach, the Singular Spectrum Analysis\nmethod, which appears more robust against the effects of flares. As an\nalternative solution, we also propose the sigma clipping technique to mitigate\nthe impact of flares. This framework offers a valuable foundation for analyzing\nperiodicity in similar astrophysical sources that are also subject to\nstochastic flaring events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T14:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05095v1","title":"Dust Growth in ALMA Rings: II. Dusty Rossby Wave Instability","summary":"Annular substructures serve as ideal venues for planetesimal formation. In\nthis series, we investigate the linear stage of dust growth within rings. The\nfirst paper examines the global streaming instability, while this study focuses\non the dusty Rossby wave instability (DRWI). We perform a linear analysis of\nthe two-fluid equations on a background pressure bump, representing annular\nsubstructures. The spectral code \\textsc{Dedalus} is used to solve the linear\neigenvalue problem. We identify two distinct DRWI modes: Type I, which\noriginates from dust-modified gas RWI, and Type II, which results from dust-gas\ncoupling. These modes never coexist for a given azimuthal wavenumber $\\ky$, but\ntransition between each other as $\\ky$ varies. Type I modes are driven by the\nadvection of background vorticity, whereas Type II modes involve two primary\nwaves: Rossby waves, driven by advection, and thin waves, driven by dust-gas\ndrag. Finally, we assess the relevance of DRWI in ALMA rings using DSHARP\nsources. Our findings suggest that Type I modes could explain the absence of\nazimuthal asymmetries in many ALMA disks, whereas Type II modes are entirely\nabsent in all eight observed rings, implying that unresolved narrow rings or\nalternative mechanisms may play a role in dust growth within annular\nsubstructures.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-07T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.05101v1","title":"Safe and Efficient Coexistence of Autonomous Vehicles with Human-Driven\n  Traffic at Signalized Intersections","summary":"The proliferation of connected and automated vehicles (CAVs) has positioned\nmixed traffic environments, which encompass both CAVs and human driven vehicles\n(HDVs), as critical components of emerging mobility systems. Signalized\nintersections are paramount for optimizing transportation efficiency and\nenhancing energy economy, as they inherently induce stop and go traffic\ndynamics. In this paper, we present an integrated framework that concurrently\noptimizes signal timing and CAV trajectories at signalized intersections, with\nthe dual objectives of maximizing traffic throughput and minimizing energy\nconsumption for CAVs. We first formulate an optimal control strategy for CAVs\nthat prioritizes trajectory planning to circumvent state constraints, while\nincorporating the impact of signal timing and HDV behavior. Furthermore, we\nintroduce a traffic signal control methodology that dynamically adjusts signal\nphases based on vehicular density per lane, while mitigating disruption for\nCAVs scheduled to traverse the intersection. Acknowledging the system's\ninherent dynamism, we also explore event triggered replanning mechanisms that\nenable CAVs to iteratively refine their planned trajectories in response to the\nemergence of more efficient routing options. The efficacy of our proposed\nframework is evaluated through comprehensive simulations in MATLAB.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T14:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.05111v1","title":"Theory of quantum-enhanced interferometry with general Markovian light\n  sources","summary":"Quantum optical systems comprising quantum emitters interacting with\nengineered optical modes generate non-classical states of light that can be\nused as resource states for quantum-enhanced interferometry. However, outside\nof well-controlled systems producing either single-mode states (e.g. Fock\nstates or squeezed states) or highly symmetric multi-mode states (e.g.\nsuperradiant states), their potential for quantum advantage remains\nuncharacterized. In this work, we develop a framework to analyze quantum\nenhanced interferometry with general Markovian quantum light sources. First, we\nshow how to compute the quantum Fisher Information (QFI) of the photons emitted\nby a source efficiently by just tracking its internal dynamics and without\nexplicitly computing the state of the emitted photons. We then use this\nrelationship to elucidate the connection between the level structure and\nspectrum of the source to a potential quantum advantage in interferometry.\nFinally, we analyze optimal measurement protocols that can be used to achieve\nthis quantum advantage with experimentally available optical elements. In\nparticular, we show that tunable optical elements with Kerr non-linearity can\nalways be harnessed to implement the optimal measurement for any given source.\nSimultaneously, we also outline general conditions under which linear optics\nand photodetection is enough to implement the optimal measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T14:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.05114v1","title":"From Sound Workflow Nets to LTL$_f$ Declarative Specifications by\n  Casting Three Spells","summary":"In process management, effective behavior modeling is essential for\nunderstanding execution dynamics and identifying potential issues. Two\ncomplementary paradigms have emerged in the pursuit of this objective: the\nimperative approach, representing all allowed runs of a system in a graph-based\nmodel, and the declarative one, specifying the rules that a run must not\nviolate in a constraint-based specification. Extensive studies have been\nconducted on the synergy and comparisons of the two paradigms. To date, though,\nwhether a declarative specification could be systematically derived from an\nimperative model such that the original behavior was fully preserved (and if\nso, how) remained an unanswered question. In this paper, we propose a\nthree-fold contribution. (1) We introduce a systematic approach to synthesize\ndeclarative process specifications from safe and sound Workflow nets. (2) We\nprove behavioral equivalence of the input net with the output specification,\nalongside related guarantees. (3) We experimentally demonstrate the scalability\nand compactness of our encoding through tests conducted with synthetic and\nreal-world testbeds.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-07T14:17:34Z"}
{"aid":"http://arxiv.org/abs/2504.05115v1","title":"Inertia-induced scaling and criticality in martensites","summary":"Martensites subjected to quasistatic deformation are known to exhibit power\nlaw distributed acoustic emission in a broad range of scales. However, the\norigin of the observed scaling behavior and the mechanism of self organization\ntowards criticality remains obscure. Here we argue that the power law structure\nof the fluctuations spectrum can be interpreted as an effect of inertia. The\ngeneral insight is that inertial dynamics can become a crucial player when the\nunderlying mechanical system is only marginally stable. We first illustrate the\npossibility of inertia-induced criticality using an elementary example of mass\npoints connected by bi-stable springs. We then explore the effects of inertia\nin the fully realistic two and three dimensional continuum models of specific\nelastic phase transitions in crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-07T14:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.05120v1","title":"The intersections of the lower central series and the subgroups of\n  finite p-index of Generalized Baumslag-Solitar tree groups","summary":"For a Generalized Baumslag-Solitar group $G$ with underling graph a tree, we\ncalculate the intersection $\\gamma_{\\omega}(G)$ of the lower central series and\nthe intersection $(N_{p})_{\\omega}(G)$ of the subgroups of finite index some\npower of a prime $p$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T14:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.05129v1","title":"Superconductivity, Anomalous Hall Effect, and Stripe Order in\n  Rhombohedral Hexalayer Graphene","summary":"We report the discovery of a unique superconducting phase in rhombohedral\nhexalayer graphene characterized by its simultaneous emergence with both the\nanomalous Hall effect and stripe charge order. The onset of stripe charge order\nis revealed through angle-resolved transport measurements, which show thermally\nactivated insulating behavior along one axis and highly conductive transport\nalong the orthogonal direction. Superconductivity develops exclusively along\nthe high-conductivity axis, giving rise to a one-dimensional-like\nsuperconducting channel. This superconducting state exhibits first-order\ntransitions under an out-of-plane magnetic field, consistent with a chiral\norder parameter that breaks time-reversal symmetry. Most remarkably, thermally\ndriven superconducting transitions display pronounced hysteresis-an uncommon\nphenomenon that reflects the complex interplay among stripe formation, broken\ntime-reversal symmetry, and superconductivity. Together, these results uncover\na previously unidentified quantum phase: a chiral superconductor embedded\nwithin an anomalous Hall crystal.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-07T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.05146v1","title":"Query Smarter, Trust Better? Exploring Search Behaviours for Verifying\n  News Accuracy","summary":"While it is often assumed that searching for information to evaluate\nmisinformation will help identify false claims, recent work suggests that\nsearch behaviours can instead reinforce belief in misleading news, particularly\nwhen users generate queries using vocabulary from the source articles. Our\nresearch explores how different query generation strategies affect news\nverification and whether the way people search influences the accuracy of their\ninformation evaluation. A mixed-methods approach was used, consisting of three\nparts: (1) an analysis of existing data to understand how search behaviour\ninfluences trust in fake news, (2) a simulation of query generation strategies\nusing a Large Language Model (LLM) to assess the impact of different query\nformulations on search result quality, and (3) a user study to examine how\n'Boost' interventions in interface design can guide users to adopt more\neffective query strategies. The results show that search behaviour\nsignificantly affects trust in news, with successful searches involving\nmultiple queries and yielding higher-quality results. Queries inspired by\ndifferent parts of a news article produced search results of varying quality,\nand weak initial queries improved when reformulated using full SERP\ninformation. Although 'Boost' interventions had limited impact, the study\nsuggests that interface design encouraging users to thoroughly review search\nresults can enhance query formulation. This study highlights the importance of\nquery strategies in evaluating news and proposes that interface design can play\na key role in promoting more effective search practices, serving as one\ncomponent of a broader set of interventions to combat misinformation.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T14:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.05150v1","title":"A Reinforcement Learning Method for Environments with Stochastic\n  Variables: Post-Decision Proximal Policy Optimization with Dual Critic\n  Networks","summary":"This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T14:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05154v1","title":"CARE: Aligning Language Models for Regional Cultural Awareness","summary":"Existing language models (LMs) often exhibit a Western-centric bias and\nstruggle to represent diverse cultural knowledge. Previous attempts to address\nthis rely on synthetic data and express cultural knowledge only in English. In\nthis work, we study whether a small amount of human-written, multilingual\ncultural preference data can improve LMs across various model families and\nsizes. We first introduce CARE, a multilingual resource of 24.1k responses with\nhuman preferences on 2,580 questions about Chinese and Arab cultures, all\ncarefully annotated by native speakers and offering more balanced coverage.\nUsing CARE, we demonstrate that cultural alignment improves existing LMs beyond\ngeneric resources without compromising general capabilities. Moreover, we\nevaluate the cultural awareness of LMs, native speakers, and retrieved web\ncontent when queried in different languages. Our experiment reveals regional\ndisparities among LMs, which may also be reflected in the documentation gap:\nnative speakers often take everyday cultural commonsense and social norms for\ngranted, while non-natives are more likely to actively seek out and document\nthem. CARE is publicly available at https://github.com/Guochry/CARE (we plan to\nadd Japanese data in the near future).","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05156v1","title":"Blending Queries and Conversations: Understanding Tactics, Trust,\n  Verification, and System Choice in Web Search and Chat Interactions","summary":"This paper presents a user study (N=22) where participants used an interface\ncombining Web Search and a Generative AI-Chat feature to solve health-related\ninformation tasks. We study how people behaved with the interface, why they\nbehaved in certain ways, and what the outcomes of these behaviours were. A\nthink-aloud protocol captured their thought processes during searches. Our\nfindings suggest that GenAI is neither a search panacea nor a major regression\ncompared to standard Web Search interfaces. Qualitative and quantitative\nanalyses identified 78 tactics across five categories and provided insight into\nhow and why different interface features were used. We find evidence that\npre-task confidence and trust both influenced which interface feature was used.\nIn both systems, but particularly when using the chat feature, trust was often\nmisplaced in favour of ease-of-use and seemingly perfect answers, leading to\nincreased confidence post-search despite having incorrect results. We discuss\nwhat our findings mean in the context of our defined research questions and\noutline several open questions for future research.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-07T14:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.05166v1","title":"Effective spin model with anisotropic exchange interactions for the\n  spin-orbit coupled Hubbard model at half-filling","summary":"Spin-orbit coupling (SOC) in noncentrosymmetric materials is the source of\nincommensurate magnetic structures. In semiconductors, it drives the Rashba\nspin splitting and spin momentum locking, while in magnetic insulators based on\ntransition metals, it induces anisotropic spin exchange interactions, like\nDzyaloshinskii-Moriya (DM) interaction which drive chiral magnetism and\nskyrmion formation. Here, we establish a direct connection between SOC and spin\nexchange interactions by deriving an effective spin model from the SOC Hubbard\nmodel at half-filling. Using a strong-coupling expansion up to fourth order, we\nidentify Heisenberg, Ising-like, and ring exchange interactions, as well as a\nvariety of four-body terms for realistic Hubbard parameters. These parameters\nconstrain the relative strengths of spin interactions, providing a natural\ninterpolation between metallic and insulating phases that host complex magnetic\ntextures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-07T15:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.05180v1","title":"BRIDGES: Bridging Graph Modality and Large Language Models within EDA\n  Tasks","summary":"While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05184v1","title":"MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised\n  Prototypical Contrastive Loss for Coronary DSA Image Segmentation","summary":"The accurate segmentation of coronary Digital Subtraction Angiography (DSA)\nimages is essential for diagnosing and treating coronary artery diseases.\nDespite advances in deep learning-based segmentation, challenges such as low\ncontrast, noise, overlapping structures, high intra-class variance, and class\nimbalance limit precise vessel delineation. To overcome these limitations, we\npropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecture\nfor coronary DSA image segmentation. The framework combined Multi-Scale Dilated\nBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),\nwhich not only enhances multi-scale feature extraction but also preserve\nfine-grained details, and improve contextual understanding. Furthermore, we\npropose a new Supervised Prototypical Contrastive Loss (SPCL), which combines\nsupervised and prototypical contrastive learning to minimize class imbalance\nand high intra-class variance by focusing on hard-to-classified background\nsamples. Experiments carried out on a private coronary DSA dataset demonstrate\nthat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dice\ncoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced Average\nSurface Distance (ASD) and Average Contour Distance (ACD). The developed\nframework provides clinicians with precise vessel segmentation, enabling\naccurate identification of coronary stenosis and supporting informed diagnostic\nand therapeutic decisions. The code will be released at the following GitHub\nprofile link https://github.com/rayanmerghani/MSA-UNet3plus.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:35:30Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05191v1","title":"Distributed Quantum Advantage in Locally Checkable Labeling Problems","summary":"In this paper, we present the first known example of a locally checkable\nlabeling problem (LCL) that admits asymptotic distributed quantum advantage in\nthe LOCAL model of distributed computing: our problem can be solved in $O(\\log\nn)$ communication rounds in the quantum-LOCAL model, but it requires\n$\\Omega(\\log n \\cdot \\log^{0.99} \\log n)$ communication rounds in the classical\nrandomized-LOCAL model. We also show that distributed quantum advantage cannot\nbe arbitrarily large: if an LCL problem can be solved in $T(n)$ rounds in the\nquantum-LOCAL model, it can also be solved in $\\tilde O(\\sqrt{n T(n)})$ rounds\nin the classical randomized-LOCAL model. In particular, a problem that is\nstrictly global classically is also almost-global in quantum-LOCAL. Our second\nresult also holds for $T(n)$-dependent probability distributions. As a\ncorollary, if there exists a finitely dependent distribution over valid\nlabelings of some LCL problem $\\Pi$, then the same problem $\\Pi$ can also be\nsolved in $\\tilde O(\\sqrt{n})$ rounds in the classical randomized-LOCAL and\ndeterministic-LOCAL models. That is, finitely dependent distributions cannot\nexist for global LCL problems.","main_category":"cs.DC","categories":"cs.DC,cs.CC,quant-ph","published":"2025-04-07T15:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.05197v1","title":"P2Mark: Plug-and-play Parameter-intrinsic Watermarking for Neural Speech\n  Generation","summary":"Recently, a large number of advanced neural speech generation methods have\nemerged in the open-source community. Although this has facilitated the\napplication and development of technology, it has also increased the difficulty\nof preventing the abuse of generated speech and protecting copyrights. Audio\nwatermarking technology is an effective method for proactively protecting\ngenerated speech, but when the source codes and model weights of the neural\nspeech generation methods are open-sourced, audio watermarks based on previous\nwatermarking methods can be easily removed or manipulated. This paper proposes\na Plug-and-play Parameter-intrinsic WaterMarking (P2Mark) method for neural\nspeech generation system protection. The main advantage of P2Mark is that the\nwatermark information is flexibly integrated into the neural speech generation\nmodel in the form of parameters by training a watermark adapter rather than\ninjecting the watermark into the model in the form of features. After the\nwatermark adapter with the watermark embedding is merged with the pre-trained\ngeneration model, the watermark information cannot be easily removed or\nmanipulated. Therefore, P2Mark will be a reliable choice for proactively\ntracing and protecting the copyrights of neural speech generation models in\nopen-source white-box scenarios. We validated P2Mark on two main types of\ndecoders in neural speech generation: vocoder and codec. Experimental results\nshow that P2Mark achieves performance comparable to state-of-the-art audio\nwatermarking methods that cannot be used for open-source white-box protection\nscenarios in terms of watermark extraction accuracy, watermark\nimperceptibility, and robustness.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-07T15:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.05208v1","title":"On the cyclic behavior of singular inner functions in Besov and sequence\n  spaces","summary":"We show the existence of singular inner functions that are cyclic in some\nBesov-type spaces of analytic functions over the unit disc. Our sufficient\ncondition is stated only in terms of the modulus of smoothness of the\nunderlying measure. Such singular inner functions are cyclic also in the space\n$\\ell^p_A$ of holomorphic functions with coefficients in $\\ell^p$. This can\nonly happen for measures that place no mass on any Beurling-Carleson set.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-04-07T15:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.05209v1","title":"Detailed $SU(3)$ Flavour Symmetry Analysis of Charmless Two-Body\n  $B$-Meson Decays Including Factorizable Corrections","summary":"We study the decays of $B_{(s)}$ mesons into light pseudoscalar mesons under\nthe $SU(3)$ flavour symmetry. Assuming exact $SU(3)$ symmetry at the level of\nthe amplitudes leads to a simple parameterization. Using the available\nexperimental data and, for the first time, mixing effects in the $B_s^0$\ndecays, we find that the data cannot be described with this assumption. We\nimprove this parametrization by including {\\it factorizable}\n$SU(3)_\\mathrm{F}$-breaking effects. This new approach allows for an excellent\ndescription of the data, with a fit $p$ value of $32.3\\%$. We provide posterior\npredictions for all observables and identify several decay channels that would\nsignificantly impact our analysis. Finally, we briefly compare our results with\nthe predictions of QCD factorization, paving the way to a more detailed\nanalysis which could provide insights into QCD effects at low energy scales.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-07T15:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.05216v1","title":"Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood\n  Modeling","summary":"Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-07T16:03:59Z"}
{"aid":"http://arxiv.org/abs/2504.05235v1","title":"IAEmu: Learning Galaxy Intrinsic Alignment Correlations","summary":"The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,cs.LG","published":"2025-04-07T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.05238v1","title":"Federated Learning for Medical Image Classification: A Comprehensive\n  Benchmark","summary":"The federated learning paradigm is wellsuited for the field of medical image\nanalysis, as it can effectively cope with machine learning on isolated\nmulticenter data while protecting the privacy of participating parties.\nHowever, current research on optimization algorithms in federated learning\noften focuses on limited datasets and scenarios, primarily centered around\nnatural images, with insufficient comparative experiments in medical contexts.\nIn this work, we conduct a comprehensive evaluation of several state-of-the-art\nfederated learning algorithms in the context of medical imaging. We conduct a\nfair comparison of classification models trained using various federated\nlearning algorithms across multiple medical imaging datasets. Additionally, we\nevaluate system performance metrics, such as communication cost and\ncomputational efficiency, while considering different federated learning\narchitectures. Our findings show that medical imaging datasets pose substantial\nchallenges for current federated learning optimization algorithms. No single\nalgorithm consistently delivers optimal performance across all medical\nfederated learning scenarios, and many optimization algorithms may underperform\nwhen applied to these datasets. Our experiments provide a benchmark and\nguidance for future research and application of federated learning in medical\nimaging contexts. Furthermore, we propose an efficient and robust method that\ncombines generative techniques using denoising diffusion probabilistic models\nwith label smoothing to augment datasets, widely enhancing the performance of\nfederated learning on classification tasks across various medical imaging\ndatasets. Our code will be released on GitHub, offering a reliable and\ncomprehensive benchmark for future federated learning studies in medical\nimaging.","main_category":"cs.CV","categories":"cs.CV,cs.DC","published":"2025-04-07T16:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.05242v1","title":"Spectral correlations of dynamical Resonance Fluorescence","summary":"Frequency-filtered photon correlations have been proven to be extremely\nuseful in grasping how the detection process alters photon statistics.\nHarnessing the spectral correlations also permits refinement of the emission\nand unraveling of previously hidden strong correlations in a plethora of\nquantum-optical systems under continuous-wave excitation. In this work, we\ninvestigate such correlations for time-dependent excitation and develop a\nmethodology to compute efficiently time-integrated correlations, which are at\nthe heart of the photon-counting theory, and subsequently apply it to analyze\nthe photon emission of pulsed systems. By combining this formalism with the\nsensor method -- which facilitates frequency-resolved correlations -- we\ndemonstrate how spectral filtering enhances single-photon purity and suppresses\nmulti-photon noise in time-bin-encoded quantum states. Specifically, filtering\nthe central spectral peak of a dynamically driven two-level system boosts\ntemporal coherence and improves the fidelity of time-bin entanglement\npreparation, even under conditions favoring multi-photon emission. These\nresults establish spectral filtering as a critical tool for tailoring photon\nstatistics in pulsed quantum light sources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T16:27:13Z"}
{"aid":"http://arxiv.org/abs/2504.05244v1","title":"Behind the Spotlight: A systematic assessment of outshining using NIRCam\n  medium-bands in the JADES Origins Field","summary":"The spatial resolution and sensitivity of JWST's NIRCam instrument has\nrevolutionised our ability to probe the internal structure of early galaxies.\nBy leveraging deep medium-band imaging in the Jades Origins Field, we assemble\ncomprehensive spectral energy distributions (SEDs) using 19 photometric bands\nfor over 200 high-redshift galaxies ($z \\geq 4.5$). We present an analysis of\nthis sample with particular emphasis on investigating the \"outshining\"\nphenomenon, which can bias the inferred stellar populations by masking the\npresence of evolved stellar populations ($\\geq$ 100 Myr) with the light of\nbright, young O and B-type stars. We address this problem by performing\nspatially-resolved SED-fitting of both binned and full pixel-by-pixel\nphotometry, which we compare to the traditional integrated approach. We find\nevidence for systematic underestimation of stellar mass in low-mass galaxies\n($\\leq 10^9 \\rm M_\\odot$) with bursty star formation, which can exceed a factor\nof 10 in individual cases, but on average is typically a factor of 1.25-2.5,\ndepending on the binning methodology and SFH model used. The observed mass\noffset correlates with burstiness (SFR$_{10 \\ \\rm Myr}$/SFR$_{100 \\ \\rm Myr}$)\nand sSFR, such that galaxies with recently rising SFHs have larger mass\noffsets. The integrated SFH models which produce the most consistent stellar\nmasses are the double power-law and non-parametric `continuity' models,\nalthough no integrated model fully reproduces all resolved SFHs. We apply an\noutshining correction factor to the Stellar Mass Function at $z=7$, finding\nlittle impact within the uncertainties. We conclude that outshining can be\nimportant in individual low-mass galaxies, but the overall impact is limited\nand should be considered alongside other systematic SED fitting effects.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T16:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.05252v1","title":"Topological Hall effect in ferromagnetic Weyl semimetal Mn$_5$Ge$_3$\n  originating in competing dipolar interaction and magnetocrystalline\n  anisotropy","summary":"We report the anomalous and topological Hall effect of the ferromagnetic Weyl\nsemimetal Mn$_5$Ge$_3$. We observe a significant anisotropic anomalous Hall\neffect (AHE) due to nonzero Berry curvature in the momentum space, such that\nthe anomalous Hall conductivity (AHC) is 965 S/cm for the $xy$-plane and 233\nS/cm for the $zx$-plane of the single crystal. The band structure calculations\npredict several Weyl and nodal points span across the momentum space, gapped\nout under the spin-orbit coupling effect, leading to significant $k$-space\nBerry curvature and large AHC. Experimentally, we also demonstrate a sizeable\ntopological Hall effect that is originated by the non-coplanar chiral spin\nstructure due to the competition between the out-of-plane uniaxial\nmagnetocrystalline anisotropy and the dipole-dipole interaction between two Mn\nsublattices. This study hints at the importance of dipole-dipole interactions\nin producing the skyrmion lattice in Mn$_5$Ge$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T16:44:26Z"}
{"aid":"http://arxiv.org/abs/2504.05263v1","title":"An X-ray and Optical Study of the Dwarf Nova Candidate OGLE-BLG-DN-0064","summary":"The source OGLE-BLG-DN-0064 (hereafter OGLE64) was classified as a potential\ndwarf nova based on its regular outburst activity revealed by the OGLE optical\nsurvey. In this paper, we investigate the X-ray and optical emissions from the\nsource OGLE64 based on archival Chandra and Swift X-ray data and our optical\nobservations with the 6-m BTA telescope at the Special Astrophysical\nObservatory of the Russian Academy of Sciences. OGLE64 shows an X-ray\nluminosity $ L_X \\approx 1.6 \\times 10^{32} \\, \\text{erg s}^{-1} $ and a high\nX-ray-to-optical flux ratio $ F_X / F_{\\text{opt}} \\approx 1.5$, typical for\naccreting white dwarfs. The X-ray spectrum of OGLE64 is better fitted by the\nmodels of a power law with a photon index $\\Gamma \\approx 1.9$ and an optically\nthin plasma with a temperature $ kT \\approx 6.4 \\, \\text{keV} $. The optical\nspectrum shows hydrogen and neutral helium emission lines, in some of which a\ndouble-peaked structure is observed. An analysis of the outburst activity of\nOGLE64, based on data from the OGLE, ZTF, ATLAS, and ASAS-SN optical surveys,\nhas revealed superoutbursts with a characteristic supercycle $ P_{\\text{super}}\n\\approx 400 \\, \\text{days} $. We found no significant variability in either the\nX-ray or optical light curves of OGLE64 that could be associated with the\nchange in the visibility conditions for the emitting regions at different\norbital phases. Our estimates of the orbital period of the system by indirect\nmethods show that the period probably lies in the range $ P_{\\text{orb}} \\sim\n1.5 - 3.5 \\, \\text{h} $. The properties of the X-ray and optical emissions from\nOGLE64 lead us to conclude that the system is an SU UMa-type dwarf nova.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.05264v1","title":"Existence and characterizations of hyper-dual group inverse","summary":"Motivated by the recent work of Xiao and Zhong [AIMS Math. 9 (2024),\n35125--35150: MR4840882], we propose a generalized inverse for a hyper-dual\nmatrix called hyper-dual group generalized inverse (HDGGI). Under certain\nnecessary and sufficient conditions, we establish the existence of the HDGGI of\na hyper-dual matrix. We then show that the HDGGI is unique (whenever exists).\nThe HDGGI is then used to solve a linear hyper-dual system. We also exploit\nsome sufficient conditions under which the reverse and forward-order laws for a\nparticular form of the HDGGI and HDMPGI hold. We also discuss the least-squares\nproperties of hyper-dual group inverse. Using the definition of dual matrix of\norder $n$, we finally establish necessary and sufficient condition for the\nexistence of the group inverse of a dual matrix of order $n$.","main_category":"math.RA","categories":"math.RA,math.AC,math.FA","published":"2025-04-07T16:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.05265v1","title":"From Sparse Signal to Smooth Motion: Real-Time Motion Generation with\n  Rolling Prediction Models","summary":"In extended reality (XR), generating full-body motion of the users is\nimportant to understand their actions, drive their virtual avatars for social\ninteraction, and convey a realistic sense of presence. While prior works\nfocused on spatially sparse and always-on input signals from motion\ncontrollers, many XR applications opt for vision-based hand tracking for\nreduced user friction and better immersion. Compared to controllers, hand\ntracking signals are less accurate and can even be missing for an extended\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\nModel (RPM), an online and real-time approach that generates smooth full-body\nmotion from temporally and spatially sparse input signals. Our model generates\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\nplausible motion when inputs are missing (i.e., synthesis mode). More\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\nvice versa. To demonstrate the practical importance of handling noisy and\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\nfrom a commercial virtual reality (VR) headset with paired high quality body\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\nusing motion controllers (spatially sparse) and hand tracking (spatially and\ntemporally sparse). We benchmark RPM against the state of the art on both\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\napplications with a realistic dataset and by handling unreliable input signals.\nOur code, pretrained models, and GORP dataset are available in the project\nwebpage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05291v1","title":"Using Physiological Measures, Gaze, and Facial Expressions to Model\n  Human Trust in a Robot Partner","summary":"With robots becoming increasingly prevalent in various domains, it has become\ncrucial to equip them with tools to achieve greater fluency in interactions\nwith humans. One of the promising areas for further exploration lies in human\ntrust. A real-time, objective model of human trust could be used to maximize\nproductivity, preserve safety, and mitigate failure. In this work, we attempt\nto use physiological measures, gaze, and facial expressions to model human\ntrust in a robot partner. We are the first to design an in-person, human-robot\nsupervisory interaction study to create a dedicated trust dataset. Using this\ndataset, we train machine learning algorithms to identify the objective\nmeasures that are most indicative of trust in a robot partner, advancing trust\nprediction in human-robot interactions. Our findings indicate that a\ncombination of sensor modalities (blood volume pulse, electrodermal activity,\nskin temperature, and gaze) can enhance the accuracy of detecting human trust\nin a robot partner. Furthermore, the Extra Trees, Random Forest, and Decision\nTrees classifiers exhibit consistently better performance in measuring the\nperson's trust in the robot partner. These results lay the groundwork for\nconstructing a real-time trust model for human-robot interaction, which could\nfoster more efficient interactions between humans and robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.05299v1","title":"SmolVLM: Redefining small and efficient multimodal models","summary":"Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-07T17:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.05300v1","title":"Dimension-Free Convergence of Diffusion Models for Approximate Gaussian\n  Mixtures","summary":"Diffusion models are distinguished by their exceptional generative\nperformance, particularly in producing high-quality samples through iterative\ndenoising. While current theory suggests that the number of denoising steps\nrequired for accurate sample generation should scale linearly with data\ndimension, this does not reflect the practical efficiency of widely used\nalgorithms like Denoising Diffusion Probabilistic Models (DDPMs). This paper\ninvestigates the effectiveness of diffusion models in sampling from complex\nhigh-dimensional distributions that can be well-approximated by Gaussian\nMixture Models (GMMs). For these distributions, our main result shows that DDPM\ntakes at most $\\widetilde{O}(1/\\varepsilon)$ iterations to attain an\n$\\varepsilon$-accurate distribution in total variation (TV) distance,\nindependent of both the ambient dimension $d$ and the number of components $K$,\nup to logarithmic factors. Furthermore, this result remains robust to score\nestimation errors. These findings highlight the remarkable effectiveness of\ndiffusion models in high-dimensional settings given the universal approximation\ncapability of GMMs, and provide theoretical insights into their practical\nsuccess.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,math.ST,stat.ML,stat.TH","published":"2025-04-07T17:59:07Z"}
{"aid":"http://arxiv.org/abs/2504.05629v1","title":"PTRL: Prior Transfer Deep Reinforcement Learning for Legged Robots\n  Locomotion","summary":"In the field of legged robot motion control, reinforcement learning (RL)\nholds great promise but faces two major challenges: high computational cost for\ntraining individual robots and poor generalization of trained models. To\naddress these problems, this paper proposes a novel framework called Prior\nTransfer Reinforcement Learning (PTRL), which improves both training efficiency\nand model transferability across different robots. Drawing inspiration from\nmodel transfer techniques in deep learning, PTRL introduces a fine-tuning\nmechanism that selectively freezes layers of the policy network during\ntransfer, making it the first to apply such a method in RL. The framework\nconsists of three stages: pre-training on a source robot using the Proximal\nPolicy Optimization (PPO) algorithm, transferring the learned policy to a\ntarget robot, and fine-tuning with partial network freezing. Extensive\nexperiments on various robot platforms confirm that this approach significantly\nreduces training time while maintaining or even improving performance.\nMoreover, the study quantitatively analyzes how the ratio of frozen layers\naffects transfer results, providing valuable insights into optimizing the\nprocess. The experimental outcomes show that PTRL achieves better walking\ncontrol performance and demonstrates strong generalization and adaptability,\noffering a promising solution for efficient and scalable RL-based control of\nlegged robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05638v1","title":"TAGC: Optimizing Gradient Communication in Distributed Transformer\n  Training","summary":"The increasing complexity of large language models (LLMs) necessitates\nefficient training strategies to mitigate the high computational costs\nassociated with distributed training. A significant bottleneck in this process\nis gradient synchronization across multiple GPUs, particularly in the\nzero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware\nGradient Compression (TAGC), an optimized gradient compression algorithm\ndesigned specifically for transformer-based models. TAGC extends the lossless\nhomomorphic compression method by adapting it for sharded models and\nincorporating transformer-specific optimizations, such as layer-selective\ncompression and dynamic sparsification. Our experimental results demonstrate\nthat TAGC accelerates training by up to 15% compared to the standard Fully\nSharded Data Parallel (FSDP) approach, with minimal impact on model quality. We\nintegrate TAGC into the PyTorch FSDP framework, the implementation is publicly\navailable at https://github.com/ipolyakov/TAGC.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T03:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05657v1","title":"Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven\n  Speech Anti-spoofing","summary":"Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.SD","published":"2025-04-08T04:11:28Z"}
{"aid":"http://arxiv.org/abs/2504.05658v1","title":"Identification and estimation of causal peer effects using instrumental\n  variables","summary":"In social science researches, causal inference regarding peer effects often\nfaces significant challenges due to homophily bias and contextual confounding.\nFor example, unmeasured health conditions (e.g., influenza) and psychological\nstates (e.g., happiness, loneliness) can spread among closely connected\nindividuals, such as couples or siblings. To address these issues, we define\nfour effect estimands for dyadic data to characterize direct effects and\nspillover effects. We employ dual instrumental variables to achieve\nnonparametric identification of these causal estimands in the presence of\nunobserved confounding. We then derive the efficient influence functions for\nthese estimands under the nonparametric model. Additionally, we develop a\ntriply robust and locally efficient estimator that remains consistent even\nunder partial misspecification of the observed data model. The proposed robust\nestimators can be easily adapted to flexible approaches such as machine\nlearning estimation methods, provided that certain rate conditions are\nsatisfied. Finally, we illustrate our approach through simulations and an\nempirical application evaluating the peer effects of retirement on fluid\ncognitive perception among couples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T04:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.05696v1","title":"Diabetic Retinopathy Detection Based on Convolutional Neural Networks\n  with SMOTE and CLAHE Techniques Applied to Fundus Images","summary":"Diabetic retinopathy (DR) is one of the major complications in diabetic\npatients' eyes, potentially leading to permanent blindness if not detected\ntimely. This study aims to evaluate the accuracy of artificial intelligence\n(AI) in diagnosing DR. The method employed is the Synthetic Minority\nOver-sampling Technique (SMOTE) algorithm, applied to identify DR and its\nseverity stages from fundus images using the public dataset \"APTOS 2019\nBlindness Detection.\" Literature was reviewed via ScienceDirect, ResearchGate,\nGoogle Scholar, and IEEE Xplore. Classification results using Convolutional\nNeural Network (CNN) showed the best performance for the binary classes normal\n(0) and DR (1) with an accuracy of 99.55%, precision of 99.54%, recall of\n99.54%, and F1-score of 99.54%. For the multiclass classification No_DR (0),\nMild (1), Moderate (2), Severe (3), Proliferate_DR (4), the accuracy was\n95.26%, precision 95.26%, recall 95.17%, and F1-score 95.23%. Evaluation using\nthe confusion matrix yielded results of 99.68% for binary classification and\n96.65% for multiclass. This study highlights the significant potential in\nenhancing the accuracy of DR diagnosis compared to traditional human analysis","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG,q-bio.NC","published":"2025-04-08T05:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.05707v1","title":"Hamilton-Jacobi-Bellman equation and Viscosity solutions for an optimal\n  control problem for stochastic convective Brinkman-Forchheimer equations","summary":"In this work, we consider the following two- and three-dimensional stochastic\nconvective Brinkman-Forchheimer (SCBF) equations in torus $\\mathbb{T}^d,\\\nd\\in\\{2,3\\}$:\n  \\begin{align*}\n  \\mathrm{d}\\boldsymbol{u}+\\left[-\\mu\n\\Delta\\boldsymbol{u}+(\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}+\\alpha\\boldsymbol{u}+\\beta|\\boldsymbol{u}|^{r-1}\\boldsymbol{u}+\\nabla\np\\right]\\mathrm{d}t=\\mathrm{d}\\mathrm{W}, \\ \\nabla\\cdot\\boldsymbol{u}=0,\n  \\end{align*}\n  where $\\mu,\\alpha,\\beta>0$, $r\\in[1,\\infty)$ and $\\mathrm{W}$ is a Hilbert\nspace valued $\\mathrm{Q}-$Wiener process. The above system can be considered as\ndamped stochastic Navier-Stokes equations. Using the dynamic programming\napproach, we study the infinite-dimensional second-order Hamilton-Jacobi\nequation associated with an optimal control problem for SCBF equations. For the\nsupercritical case, that is, $r\\in(3,\\infty)$ for $d=2$ and $r\\in(3,5)$ for\n$d=3$ ($2\\beta\\mu\\geq 1$ for $r=3$ in $d\\in\\{2,3\\}$), we first prove the\nexistence of a viscosity solution for the infinite-dimensional HJB equation,\nwhich we identify with the value function of the associated control problem. By\nestablishing a comparison principle for $r\\in(3,\\infty)$ and $r=3$ with\n$2\\beta\\mu\\geq1$ in $d\\in\\{2,3\\}$, we prove that the value function is the\nunique viscosity solution and hence we resolve the global unique solvability of\nthe HJB equation in both two and three dimensions.","main_category":"math.OC","categories":"math.OC,math.AP","published":"2025-04-08T06:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.05712v1","title":"How I Learned to Stop Worrying and Love ChatGPT","summary":"In the dynamic landscape of software engineering, the emergence of\nChatGPT-generated code signifies a distinctive and evolving paradigm in\ndevelopment practices. We delve into the impact of interactions with ChatGPT on\nthe software development process, specifically analysing its influence on\nsource code changes. Our emphasis lies in aligning code with ChatGPT\nconversations, separately analysing the user-provided context of the code and\nthe extent to which the resulting code has been influenced by ChatGPT.\nAdditionally, employing survival analysis techniques, we examine the longevity\nof ChatGPT-generated code segments in comparison to lines written\ntraditionally. The goal is to provide valuable insights into the transformative\nrole of ChatGPT in software development, illuminating its implications for code\nevolution and sustainability within the ecosystem.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T06:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.05715v1","title":"On the evidence of a dark matter density spike around the primary black\n  hole in OJ 287","summary":"The central engine of blazar OJ~287 is arguably the most notable supermassive\nblack hole (SMBH) binary candidate that emits nano-Hertz (nHz) gravitational\nwaves. This inference is mainly due to our ability to predict and successfully\nmonitor certain quasi-periodic doubly peaked high brightness flares with a\nperiod of $\\sim$12 years from this blazer. The use of post-Newtonian accurate\nSMBH binary orbital description that includes the effects of higher order GW\nemission turned out to be a crucial ingredient for accurately predicting the\nepochs of such Bremsstrahlung flares in our SMBH binary central engine\ndescription for OJ~287. It was very recently argued that one should include the\neffects of dynamical friction, induced by certain dark matter density spikes\naround the primary SMBH, to explain the {\\it observed} decay of SMBH binary\norbit in OJ~287. Invoking binary pulsar timing-based arguments, measurements,\nand OJ~287's orbital description, we show that observationally relevant SMBH\nbinary orbital dynamics in OJ~287 are insensitive to dark matter-induced\ndynamical friction effects. This implies that we could only provide an upper\nbound on the spike index parameter rather than obtaining an observationally\nderived value, as argued by \\cite{Chan2024}.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,gr-qc","published":"2025-04-08T06:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.05718v1","title":"CVA6-VMRT: A Modular Approach Towards Time-Predictable Virtual Memory in\n  a 64-bit Application Class RISC-V Processor","summary":"The increasing complexity of autonomous systems has driven a shift to\nintegrated heterogeneous SoCs with real-time and safety demands. Ensuring\ndeterministic WCETs and low-latency for critical tasks requires minimizing\ninterference on shared resources like virtual memory. Existing techniques, such\nas software coloring and memory replication, introduce significant area and\nperformance overhead, especially with virtualized memory where address\ntranslation adds latency uncertainty. To address these limitations, we propose\nCVA6-VMRT, an extension of the open-source RISC-V CVA6 core, adding hardware\nsupport for predictability in virtual memory access with minimal area overhead.\nCVA6-VMRT features dynamically partitioned Translation Look-aside Buffers\n(TLBs) and hybrid L1 cache/scratchpad memory (SPM) functionality. It allows\nfine-grained per-thread control of resources, enabling the operating system to\nmanage TLB replacements, including static overwrites, to ensure single-cycle\naddress translation for critical memory regions. Additionally, CVA6-VMRT\nenables runtime partitioning of data and instruction caches into cache and SPM\nsections, providing low and predictable access times for critical data without\nimpacting other accesses. In a virtualized setting, CVA6-VMRT enhances\nexecution time determinism for critical guests by 94% during interference from\nnon-critical guests, with minimal impact on their average absolute execution\ntime compared to isolated execution of the critical guests only. This\ninterference-aware behaviour is achieved with just a 4% area overhead and no\ntiming penalty compared to the baseline CVA6 core.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-08T06:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.05727v1","title":"SAP-CoPE: Social-Aware Planning using Cooperative Pose Estimation with\n  Infrastructure Sensor Nodes","summary":"Autonomous driving systems must operate safely in human-populated indoor\nenvironments, where challenges such as limited perception and occlusion\nsensitivity arise when relying solely on onboard sensors. These factors\ngenerate difficulties in the accurate recognition of human intentions and the\ngeneration of comfortable, socially aware trajectories. To address these\nissues, we propose SAP-CoPE, a social-aware planning framework that integrates\ncooperative infrastructure with a novel 3D human pose estimation method and a\nmodel predictive control-based controller. This real-time framework formulates\nan optimization problem that accounts for uncertainty propagation in the camera\nprojection matrix while ensuring human joint coherence. The proposed method is\nadaptable to single- or multi-camera configurations and can incorporate sparse\nLiDAR point-cloud data. To enhance safety and comfort in human environments, we\nintegrate a human personal space field based on human pose into a model\npredictive controller, enabling the system to navigate while avoiding\ndiscomfort zones. Extensive evaluations in both simulated and real-world\nsettings demonstrate the effectiveness of our approach in generating socially\naware trajectories for autonomous systems.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T06:55:39Z"}
{"aid":"http://arxiv.org/abs/2504.05733v1","title":"The evolution of a curve induced by the Pohlmeyer-Lund-Regge equation","summary":"This paper investigates the evolution of space curves governed by the\nPohlmeyer-Lund-Regge (PLR) equation, an integrable extension of the sine-Gordon\nequation. We examine a specific type of curve evolution, known as the\nLund-Regge evolution, and derive its representation in the Frenet frame. We\nshow the Frenet frame evolution aligns with the Lax system of the PLR equation\nand develop a construction method for curve families via the Sym formula. In\nconclusion, we describe the Lund-Regge evolution corresponding to Date's\nmulti-soliton solutions to the PLR equation, with illustrations of curves and\nsurfaces.","main_category":"math.DG","categories":"math.DG,nlin.SI","published":"2025-04-08T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.05746v1","title":"Exploiting Temporal Audio-Visual Correlation Embedding for Audio-Driven\n  One-Shot Talking Head Animation","summary":"The paramount challenge in audio-driven One-shot Talking Head Animation\n(ADOS-THA) lies in capturing subtle imperceptible changes between adjacent\nvideo frames. Inherently, the temporal relationship of adjacent audio clips is\nhighly correlated with that of the corresponding adjacent video frames,\noffering supplementary information that can be pivotal for guiding and\nsupervising talking head animations. In this work, we propose to learn\naudio-visual correlations and integrate the correlations to help enhance\nfeature representation and regularize final generation by a novel Temporal\nAudio-Visual Correlation Embedding (TAVCE) framework. Specifically, it first\nlearns an audio-visual temporal correlation metric, ensuring the temporal audio\nrelationships of adjacent clips are aligned with the temporal visual\nrelationships of corresponding adjacent video frames. Since the temporal audio\nrelationship contains aligned information about the visual frame, we first\nintegrate it to guide learning more representative features via a simple yet\neffective channel attention mechanism. During training, we also use the\nalignment correlations as an additional objective to supervise generating\nvisual frames. We conduct extensive experiments on several publicly available\nbenchmarks (i.e., HDTF, LRW, VoxCeleb1, and VoxCeleb2) to demonstrate its\nsuperiority over existing leading algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T07:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.05755v1","title":"Unraveling Human-AI Teaming: A Review and Outlook","summary":"Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.","main_category":"cs.HC","categories":"cs.HC,cs.AI,econ.GN,q-fin.EC","published":"2025-04-08T07:37:25Z"}
{"aid":"http://arxiv.org/abs/2504.05757v1","title":"A Douglas-Rachford Splitting Method for Solving Monotone Variational\n  Inequalities in Linear-quadratic Dynamic Games","summary":"This paper considers constrained linear dynamic games with quadratic\nobjective functions, which can be cast as affine variational inequalities. By\nleveraging the problem structure, we apply the Douglas-Rachford splitting,\nwhich generates a solution algorithm with linear convergence rate. The fast\nconvergence of the method enables receding-horizon control architectures.\nFurthermore, we demonstrate that the associated VI admits a closed-form\nsolution within a neighborhood of the attractor, thus allowing for a further\nreduction in computation time. Finally, we benchmark the proposed method via\nnumerical experiments in an automated driving application.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-08T07:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.05767v1","title":"Cross-Document Contextual Coreference Resolution in Knowledge Graphs","summary":"Coreference resolution across multiple documents poses a significant\nchallenge in natural language processing, particularly within the domain of\nknowledge graphs. This study introduces an innovative method aimed at\nidentifying and resolving references to the same entities that appear across\ndiffering texts, thus enhancing the coherence and collaboration of information.\nOur method employs a dynamic linking mechanism that associates entities in the\nknowledge graph with their corresponding textual mentions. By utilizing\ncontextual embeddings along with graph-based inference strategies, we\neffectively capture the relationships and interactions among entities, thereby\nimproving the accuracy of coreference resolution. Rigorous evaluations on\nvarious benchmark datasets highlight notable advancements in our approach over\ntraditional methodologies. The results showcase how the contextual information\nderived from knowledge graphs enhances the understanding of complex\nrelationships across documents, leading to better entity linking and\ninformation extraction capabilities in applications driven by knowledge. Our\ntechnique demonstrates substantial improvements in both precision and recall,\nunderscoring its effectiveness in the area of cross-document coreference\nresolution.","main_category":"cs.CL","categories":"cs.CL,cs.MA","published":"2025-04-08T07:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.05773v1","title":"Simultaneous Multiphoton-Multiatom Processes in Atomic Gases under Laser\n  Fields","summary":"We investigate simultaneous multiphoton-multiatom processes in atomic gases\nexposed to laser fields under specific frequency conditions, where multiple\natoms are simultaneously excited through the absorption of one laser photon\neach. These processes represent natural high-order quantum electrodynamics\n(QED) effects that occur independently of inter-atomic interactions. A\ncharacteristic length scale emerges, governing the physical range over which\nthese phenomena manifest. We propose experiments to demonstrate the fundamental\naspects of these collective QED processes.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas","published":"2025-04-08T07:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.05777v1","title":"Monte-Carlo based model for the extraction of oil from oil-water\n  mixtures using wetting and surface acoustic waves","summary":"This work presents a Monte Carlo (MC) based microscopic model for simulating\nthe extraction of oil from oil-in-water emulsions under the influence of\nsurface acoustic waves (SAWs). The proposed model is a two-dimensional\nIsing-lattice gas model that employs Kawasaki dynamics to mimic the\ninteractions between oil, water, and air, as well as external forces such as\ngravity and acoustic stress. By incorporating both acoustic streaming and\nacoustic radiation pressure, the model captures key experimental observations,\nincluding selective oil extraction and droplet motion under SAW excitation. The\nresults highlight the critical role of acoustic radiation pressure in enabling\noil film formation and detachment, governed by the balance between capillary\nand acoustic stresses. The study provides qualitative agreement with\nexperimental findings and offers insights into the essential mechanisms driving\nacoustowetting-induced phase separation, demonstrating the utility of discrete\nmodeling for complex fluid dynamics problems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:59:18Z"}
{"aid":"http://arxiv.org/abs/2504.05778v1","title":"Residual U-Net for accurate and efficient prediction of hemodynamics in\n  two-dimensional asymmetric stenosis","summary":"This study presents residual U-Net (U-ResNet), a deep learning surrogate\nmodel for predicting hemodynamic fields in two-dimensional asymmetric stenotic\nchannels at Reynolds numbers ranging from 200 to 800. By integrating residual\nconnections with multi-scale feature extraction, U-ResNet achieves exceptional\naccuracy while significantly reducing computational costs compared to\ncomputational fluid dynamics (CFD) approaches. Comprehensive evaluation against\nU-Net, Fourier Neural Operator (FNO), and U-Net enhanced Fourier Neural\nOperator demonstrates U-ResNet's superior performance in capturing sharp\nhemodynamic gradients and complex flow features. Notably, U-ResNet demonstrates\nrobust generalization to interpolated Reynolds numbers without retraining - a\ncapability rarely achieved in existing models. The model's non-dimensional\nformulation ensures scalability across vessel sizes and anatomical locations,\nenhancing its applicability to diverse clinical scenarios. Statistical analysis\nof prediction errors reveals that U-ResNet maintains substantially narrower\nerror distributions compared to spectral methods, confirming its reliability\nfor critical hemodynamic assessment. These advances position U-ResNet as a\npromising tool for real-time clinical decision support, treatment planning, and\nmedical device optimization, with future work focusing on extension to\nthree-dimensional geometries and integration with patient-specific data.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.bio-ph,physics.comp-ph","published":"2025-04-08T07:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.05782v1","title":"MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in\n  Multimodal Large Language Models","summary":"Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:06:53Z"}
{"aid":"http://arxiv.org/abs/2504.05783v1","title":"Video Flow as Time Series: Discovering Temporal Consistency and\n  Variability for VideoQA","summary":"Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:08:03Z"}
{"aid":"http://arxiv.org/abs/2504.05793v1","title":"Negotiating Strict Latency Limits for Dynamic Real-Time Services in\n  Vehicular Time-Sensitive Networks","summary":"Future vehicles are expected to dynamically deploy in-vehicle applications\nwithin a Service-Oriented Architecture (SOA). Critical services operate under\nhard real-time constraints, which Time-Sensitive Networking (TSN) complements\non the in-vehicle Ethernet layer. TSN ensures deterministic communication\nbetween critical services and its Credit-Based Shaper (CBS) supports dynamic\nresource reservations. However, the dynamic nature of service deployment\nchallenges network resource configuration, since any new reservation may change\nthe latency of already validated flows. In addition, standard methods of\nworst-case latency analysis for CBS have been found incorrect, and current TSN\nstream reservation procedures lack mechanisms to signal application layer\nQuality-of-Service (QoS) requirements or verify deadlines. In this paper, we\npropose a QoS negotiation scheme within the automotive SOA that interacts with\nthe TSN network controller to reserve resources while ensuring latency bounds.\nWe comparatively evaluate reservation schemes using worst-case analysis and\nsimulations of a realistic In-Vehicle Network (IVN) for demonstrating their\nimpact on QoS guarantees, resource utilization, and setup times. We find that\nonly a reservation scheme utilizing per-queue delay budgets and network\ncalculus provides valid configurations and guarantees acceptable latency bounds\nthroughout the IVN. The proposed service negotiation mechanism efficiently\nestablishes 450 vehicular network reservations in just 11ms.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-08T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.05798v1","title":"A Simple yet Highly Accurate Prediction-Correction Algorithm for\n  Time-Varying Optimization","summary":"This paper proposes a simple yet highly accurate prediction-correction\nalgorithm, SHARP, for unconstrained time-varying optimization problems. Its\nprediction is based on an extrapolation derived from the Lagrange interpolation\nof past solutions. Since this extrapolation can be computed without Hessian\nmatrices or even gradients, the computational cost is low. To ensure the\nstability of the prediction, the algorithm includes an acceptance condition\nthat rejects the prediction when the update is excessively large. The proposed\nmethod achieves a tracking error of $O(h^{p})$, where $h$ is the sampling\nperiod, assuming that the $p$th derivative of the target trajectory is bounded\nand the convergence of the correction step is locally linear. We also prove\nthat the method can track a trajectory of stationary points even if the\nobjective function is non-convex. Numerical experiments demonstrate the high\naccuracy of the proposed algorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T08:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.05808v1","title":"Fast Sphericity and Roundness approximation in 2D and 3D using Local\n  Thickness","summary":"Sphericity and roundness are fundamental measures used for assessing object\nuniformity in 2D and 3D images. However, using their strict definition makes\ncomputation costly. As both 2D and 3D microscopy imaging datasets grow larger,\nthere is an increased demand for efficient algorithms that can quantify\nmultiple objects in large volumes. We propose a novel approach for extracting\nsphericity and roundness based on the output of a local thickness algorithm.\nFor sphericity, we simplify the surface area computation by modeling objects as\nspheroids/ellipses of varying lengths and widths of mean local thickness. For\nroundness, we avoid a complex corner curvature determination process by\napproximating it with local thickness values on the contour/surface of the\nobject. The resulting methods provide an accurate representation of the exact\nmeasures while being significantly faster than their existing implementations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.05811v1","title":"Effects of strange molecular partners of $P_c$ states in $γp \\to K\n  Σ$ reactions","summary":"Our previous studies revealed evidence of the strange molecular partners of\n$P_c$ states, $N(2080)3/2^-$ and $N(2270)3/2^-$, in the $\\gamma p \\to K^{*+}\n\\Sigma^0 / K^{*0} \\Sigma^+$ and $\\gamma p \\to \\phi p$ reactions. Motivated by\nthe differential cross-section data for $\\gamma p \\to K^+ \\Sigma^0$ from CLAS\n2010, which exhibits some bump structures at $W \\approx$ 1875, 2080 and 2270\nMeV, we extend our previous analysis by investigating the effects of\n$N(1535)1/2^-$, $N(1875)3/2^-$, $N(2080)1/2^- \\&\\ 3/2^-$ and $N(2270)1/2^- ,\n3/2^- \\&\\ 5/2^-$, as strange partners of $P_c$ molecular states, in the\nreactions $\\gamma p \\to K^+ \\Sigma^0$ and $\\gamma p \\to K^0 \\Sigma^+$. The\ntheoretical model employed in this study utilizes an effective Lagrangian\napproach in the tree-level Born approximation. It contains the contributions\nfrom $s$-channel with exchanges of $N$, $\\Delta$, $N^*$ (including the hadronic\nmolecules with hidden strangeness), and $\\Delta^*$; $t$-channel; $u$-channel;\nand the generalized contact term. The results corresponding to the final fitted\nparameters are in good agreement with all available experimental data of both\ncross-sections and polarization observables for $\\gamma p \\to K^+ \\Sigma^0$ and\n$\\gamma p \\to K^0 \\Sigma^+$. Notably, the $s$-channel exchanges of molecules\nsignificantly contribute to the bump structures in cross-sections for $\\gamma p\n\\to K \\Sigma$ at $W \\approx$ 1900, 2080 and 2270 MeV, and show considerable\ncoherence with contributions from $s$-channel exchanges of general resonances\nto construct the overall structures of cross-sections. More abundant\nexperiments, particularly for the reaction $\\gamma p \\to K^0 \\Sigma^+$, are\nnecessary to further strengthen the constraints on the theoretical models.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-08T08:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.05815v1","title":"Parasite: A Steganography-based Backdoor Attack Framework for Diffusion\n  Models","summary":"Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:53:47Z"}
{"aid":"http://arxiv.org/abs/2504.05817v1","title":"Combinatorial Ricci flows on infinite disk triangulations","summary":"In this paper, we introduce combinatorial Ricci flows (CRFs in short) in\nEuclidean and hyperbolic background geometries on infinite triangulations of\nthe open disk, which are discrete analogs of Ricci flows on simply connected\nopen surfaces. We establish well-posedness results, the existence and the\nuniqueness, of CRFs in both Euclidean and hyperbolic background geometries.\nMoreover, we prove convergence results of CRFs, which indicate a uniformization\ntheorem for CRFs on infinite disk triangulations. As an application, we prove\nan existence result of circle-packing metrics with infinite prescribed cone\nangles in hyperbolic background geometry. To our knowledge, these are the first\nresults of CRFs on infinite triangulations.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-08T08:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.05819v1","title":"Nonparametric local polynomial regression for functional covariates","summary":"We consider nonparametric regression with functional covariates, that is,\nthey are elements of an infinite-dimensional Hilbert space. A locally\npolynomial estimator is constructed, where an orthonormal basis and various\ntuning parameters remain to be selected. We provide a general asymptotic upper\nbound on the estimation error and show that this procedure achieves polynomial\nconvergence rates under appropriate tuning and supersmoothness of the\nregression function. Such polynomial convergence rates have usually been\nconsidered to be non-attainable in nonparametric functional regression without\nany additional strong structural constraints such as linearity of the\nregression function.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T09:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.05821v1","title":"On the Hopf envelope of finite-dimensional bialgebras","summary":"The Hopf envelope of a bialgebra is the free Hopf algebra generated by the\ngiven bialgebra. Its existence, as well as that of the cofree Hopf algebra, is\na well-known fact in Hopf algebra theory, but their construction is not\nparticularly handy or friendly. In this note, we offer a novel realisation of\nthe Hopf envelope and of the cofree Hopf algebra of a finite-dimensional\nbialgebra as a particular quotient and sub-bialgebra, respectively, of the\nbialgebra itself. Our construction can also be extended to the\ninfinite-dimensional case, provided that the bialgebra satisfies additional\nconditions, such as being left Artinian as an algebra or admitting a\n$n$-antipode, the latter being a notion hereby introduced.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA,math.RT","published":"2025-04-08T09:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05832v1","title":"Channel State Information Analysis for Jamming Attack Detection in\n  Static and Dynamic UAV Networks -- An Experimental Study","summary":"Networks built on the IEEE 802.11 standard have experienced rapid growth in\nthe last decade. Their field of application is vast, including smart home\napplications, Internet of Things (IoT), and short-range high throughput static\nand dynamic inter-vehicular communication networks. Within such networks,\nChannel State Information (CSI) provides a detailed view of the state of the\ncommunication channel and represents the combined effects of multipath\npropagation, scattering, phase shift, fading, and power decay. In this work, we\ninvestigate the problem of jamming attack detection in static and dynamic\nvehicular networks. We utilize ESP32-S3 modules to set up a communication\nnetwork between an Unmanned Aerial Vehicle (UAV) and a Ground Control Station\n(GCS), to experimentally test the combined effects of a constant jammer on\nrecorded CSI parameters, and the feasibility of jamming detection through CSI\nanalysis in static and dynamic communication scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.RO","published":"2025-04-08T09:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05848v1","title":"Relativistic limits on the discretization and temporal resolution of a\n  quantum clock","summary":"We provide a brief discussion regarding relativistic limits on the\ndiscretization and temporal resolution of time values in a quantum clock. Our\nclock is characterized by a time observable chosen to be the complement of a\nbounded and discrete Hamiltonian which can have an equally-spaced or a generic\nspectrum. In the first case the time observable can be described by an\nHermitian operator and we find a limit in the discretization for the time\neigenvalues. Nevertheless, in both cases, the time observable can be described\nby a POVM and, by increasing the number of time states, we can arbitrarily\nreduce the bound on the minimum time quantum, demonstrating that we can safely\ntake the time values as continuous when the number of time states tends to\ninfinity. Finally, we find a limit for temporal resolution of our time\nobservable when the clock is used (together with light signals) in a\nrelativistic framework for measuring spacetime distances.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:27:41Z"}
{"aid":"http://arxiv.org/abs/2504.05858v1","title":"Structural and Electrical Transport Properties of NASICON type\n  Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$ 0.1-0.4) Solid\n  Electrolyte Materials","summary":"We report the structural, resistivity, impedance, and dielectric studies of\nisovalent substituted Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$\n0.1--0.4) NASICON type solid electrolyte materials. The Rietveld refinement of\nXRD patterns shows the monoclinic phase with space group of C 2/c for all the\nsamples. The resistivity analysis shows the Arrhenius-type thermal conduction\nwith an increase in activation energy with doping is explained based on\ndecreased unit cell volume. We use Maxwell-Wagner-Sillars (MWS) relaxation and\nspace charge or interfacial polarization models to explain the frequency and\ntemperature-dependent variations of electric permittivity. The double\nrelaxation peaks in the dielectric loss data show the two types of relaxation\nmechanisms of different activation energy. The real ($\\epsilon^{'}$) and\nimaginary ($\\epsilon^{''}$) parts of permittivity are fitted using the modified\nCole-Cole equation, including the conductivity term, which show the non-Debye\ntype relaxation over the measured frequency and temperature range. The\nimpedance analysis shows the contributions from grain and grain boundary\nrelaxation. The fitting performed using the impedance and constant-phase\nelement (CPE) confirm the non-Debye type relaxation. Moreover, the electric\nmodulus analysis confirms the ionic nature having thermally activated\nrelaxation and the modulus scaling analysis shows a similar type of relaxation\nin the measured temperature range. The modified power law is used to understand\nthe frequency dependence of {\\it a.c.} conductivity data. The temperature\ndependence of exponent ($s$) in modified power law suggests the change in the\nconduction mechanism from near small polaron tunneling (NSPT) to correlated\nbarrier hopping (CBH) above room temperature. The larger values of\n$\\epsilon$$_{r}$ indicate these materials as a potential candidate for\ncharge-storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T09:36:05Z"}
{"aid":"http://arxiv.org/abs/2504.05868v1","title":"Energy-Conserving Neural Network Closure Model for Long-Time Accurate\n  and Stable LES","summary":"Machine learning-based closure models for LES have shown promise in capturing\ncomplex turbulence dynamics but often suffer from instabilities and physical\ninconsistencies. In this work, we develop a novel skew-symmetric neural\narchitecture as closure model that enforces stability while preserving key\nphysical conservation laws. Our approach leverages a discretization that\nensures mass, momentum, and energy conservation, along with a face-averaging\nfilter to maintain mass conservation in coarse-grained velocity fields. We\ncompare our model against several conventional data-driven closures (including\nunconstrained convolutional neural networks), and the physics-based Smagorinsky\nmodel. Performance is evaluated on decaying turbulence and Kolmogorov flow for\nmultiple coarse-graining factors. In these test cases we observe that\nunconstrained machine learning models suffer from numerical instabilities. In\ncontrast, our skew-symmetric model remains stable across all tests, though at\nthe cost of increased dissipation. Despite this trade-off, we demonstrate that\nour model still outperforms the Smagorinsky model in unseen scenarios. These\nfindings highlight the potential of structure-preserving machine learning\nclosures for reliable long-time LES.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-08T09:49:18Z"}
{"aid":"http://arxiv.org/abs/2504.05873v1","title":"Leptophilic ALPs in Laboratory Experiments","summary":"We study the collider phenomenology of leptophilic axion-like particles\n(ALPs), i.e. pseudoscalar particles that couple only to charged leptons. Loops\nof charged leptons induce effective interactions of the ALPs with photons,\nwhich depend on the momenta of the interacting particles and differ between\npseudoscalar and derivative lepton couplings. We systematically discuss the\nform of the interaction with photons for general external momenta and identify\nthe regimes when it can be safely approximated by an effective coupling\nconstant. We use these results to derive novel constraints from LEP and\ncalculate state-of-the-art limits from E137 and NA64 for four different\nscenarios, in which the ALPs couple either to a single lepton generation or\nuniversally to all, for both pseudoscalar and derivative lepton couplings. We\ncollect complementary bounds from astrophysics, flavour, and other laboratory\nexperiments to chart the allowed parameter space of leptophilic ALPs in the\nMeV-GeV mass range.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T09:58:09Z"}
{"aid":"http://arxiv.org/abs/2504.05878v1","title":"KAN-SAM: Kolmogorov-Arnold Network Guided Segment Anything Model for\n  RGB-T Salient Object Detection","summary":"Existing RGB-thermal salient object detection (RGB-T SOD) methods aim to\nidentify visually significant objects by leveraging both RGB and thermal\nmodalities to enable robust performance in complex scenarios, but they often\nsuffer from limited generalization due to the constrained diversity of\navailable datasets and the inefficiencies in constructing multi-modal\nrepresentations. In this paper, we propose a novel prompt learning-based RGB-T\nSOD method, named KAN-SAM, which reveals the potential of visual foundational\nmodels for RGB-T SOD tasks. Specifically, we extend Segment Anything Model 2\n(SAM2) for RGB-T SOD by introducing thermal features as guiding prompts through\nefficient and accurate Kolmogorov-Arnold Network (KAN) adapters, which\neffectively enhance RGB representations and improve robustness. Furthermore, we\nintroduce a mutually exclusive random masking strategy to reduce reliance on\nRGB data and improve generalization. Experimental results on benchmarks\ndemonstrate superior performance over the state-of-the-art methods.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05901v1","title":"Improvement Ergodic Theory For The Infinite Word\n  $\\mathfrak{F}=\\mathfrak{F}_{b}:=\\left({ }_{b} f_{n}\\right)_{n \\geqslant 0}$\n  on Fibonacci Density","summary":"The paper explores combinatorial properties of Fibonacci words and their\ngeneralizations within the framework of combinatorics on words. These infinite\nsequences, measures the diversity of subwords in Fibonacci words, showing\nnon-decreasing growth for infinite sequences. Extends factor analysis to\narithmetic progressions of symbols, highlighting generalized pattern\ndistributions. Recent results link Sturmian sequences (including Fibonacci\nwords) to unbounded binomial complexity and gap inequivalence, with\nimplications for formal language theory and automata. This work underscores the\ninterplay between substitution rules, algebraic number theory, and\ncombinatorial complexity in infinite words, providing tools for applications in\nfractal geometry and theoretical computer science.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T10:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.05911v1","title":"A note on the stability of self-similar blow-up solutions for\n  superconformal semilinear wave equations","summary":"In this note, we investigate the stability of self-similar blow-up solutions\nfor superconformal semilinear wave equations in all dimensions. A central\naspect of our analysis is the spectral equivalence of the linearized operators\nunder Lorentz transformations in self-similar variables. This observation\nserves as a useful tool in proving mode stability and provides insights that\nmay aid the study of self-similar solutions in related problems. As a direct\nconsequence, we establish the asymptotic stability of the ODE blow-up family,\nextending the classical results of Merle and Zaag [Merle-Zaag, 2007, 2016] to\nthe superconformal case and generalizing the recent findings of Ostermann\n[Ostermann, 2024] to include the entire ODE blow-up family.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T11:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.05935v1","title":"Stabilization of solutions of the controlled non-local continuity\n  equation","summary":"Non-local continuity equation describes an infinite system of identical\nparticles, which interact with each other through the common field. Solution of\nthis equation is a probability measure that stands for spatial distribution of\nparticles. The paper is concerned with stabilization of this solution in the\ncase of controlled dynamic. By generalizing methods used control-Lyapunov\nfunction to the case of Wasserstein spaces, we construct a feedback strategy\nthat provides local stabilization, i.e. leads the trajectory to a small\nneighbourhood of stabilization target. Based on this strategy, we construct a\nfeedback that makes global stabilization, i.e. leads the trajectory infinitely\nclose to stabilization target.","main_category":"math.DS","categories":"math.DS,math.OC","published":"2025-04-08T11:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.05937v1","title":"On the Hamilton-Jacobi approach to inflation beyond slow roll","summary":"The Hamilton-Jacobi approach is a powerful tool to describe super-Hubble\ndynamics during cosmological inflation in a non-linear way. A key assumption of\nthis framework is to neglect anisotropic perturbations on large scales. We show\nthat neglecting the anisotropic sector in the momentum constraint corresponds\nto discarding the non-adiabatic mode of scalar-field perturbations at large\nscales. Consequently, the Hamilton-Jacobi approach cannot be used to describe\nthe evolution of large-scale perturbations during inflation beyond slow roll,\nwhen non-adiabatic fluctuations play an important role on super-Hubble scales\ndue to the absence of an attractor trajectory. As an example, we analyse the\ncase of cosmological perturbations during a phase of ultra-slow-roll inflation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-08T11:52:44Z"}
{"aid":"http://arxiv.org/abs/2504.05938v1","title":"Umbral oscillations in the photosphere. A comprehensive statistical\n  study","summary":"It is well-known that the global acoustic oscillations of the Sun's\natmosphere can excite resonance modes within large-scale magnetic\nconcentrations. These structures are conduits of energy between the different\nlayers of the solar atmosphere, and understanding their dynamics can explain\nthe processes behind coronal heating and solar wind acceleration. In this work,\nwe studied the Doppler velocity spectrum of more than a thousand large-scale\nmagnetic structures (i.e., sunspots) in the solar photosphere that crossed near\nthe disk centre of the Sun. We exploited the excellent stability and\nseeing-free conditions of the Helioseismic and Magnetic Imager (HMI) instrument\nonboard the Solar Dynamics Observatory (SDO) to cover nearly seven years of\nobservations, providing the most comprehensive statistical analysis of its\nkind. Here, we show that the power spectra of the umbra of sunspots in the\nphotosphere is remarkably different from the one of quiet-Sun regions, with\nboth exhibiting a primary peak at 3.3 mHz, but the sunspot umbrae also\ndisplaying a closely packed series of secondary peaks in the $4-6$~mHz band.\nUnderstanding the origin of such peaks is a challenging task. Here, we explore\nseveral possible explanations for the observed oscillations, all pointing\ntoward a potential resonant interaction within these structures and an unknown\ndriver. Our observational result provides further insight into the magnetic\nconnectivity between the different layers of the dynamic atmosphere of the Sun.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.05940v1","title":"A Lorentz Covariant Matrix Model for Bosonic M2-Branes: Nambu Brackets\n  and Restricted Volume-Preserving Deformations","summary":"We propose a Lorentz covariant matrix model as a nonperturbative formulation\nof the bosonic M2-brane in M-theory. Unlike previous approaches relying on the\nlight-cone gauge or symmetry-based constructions, our model retains full\n11-dimensional Lorentz invariance by introducing a novel gauge-fixing condition\nthat restricts the symmetry of volume-preserving deformations (VPD) to a\nsubclass, which we call restricted VPD (RVPD). This restriction enables a\nconsistent matrix regularization of the Nambu bracket, bypassing the\nlong-standing obstructions related to the Leibniz rule and the Fundamental\nIdentity. The resulting model exhibits RVPD symmetry, admits particle-like and\nnoncommutative membrane solutions, and lays the foundation for a\nLorentz-invariant, nonperturbative matrix description of M2-branes. Our work\noffers a new paradigm for constructing Lorentz-invariant matrix models of\nmembranes, revisiting the algebraic structure underlying M-theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-08T11:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.05942v1","title":"Higher-order meshless schemes for hyperbolic equations","summary":"We discuss the order, efficiency, stability and positivity of several\nmeshless schemes for linear scalar hyperbolic equations. Meshless schemes are\nGeneralised Finite Difference Methods (GFDMs) for arbitrary irregular grids in\nwhich there is no connectivity between the grid points. We propose a new\nMUSCL-like meshless scheme that uses a central stencil, with which we can\nachieve arbitrarily high orders, and compare it to existing meshless upwind\nschemes and meshless WENO schemes. The stability of the newly proposed scheme\nis guaranteed by an upwind reconstruction to the midpoints of the stencil. The\nnew meshless MUSCL scheme is also efficient due to the reuse of the GFDM\nsolution in the reconstruction. We combine the new MUSCL scheme with a\nMulti-dimensional Optimal Order Detection (MOOD) procedure to avoid spurious\noscillations at discontinuities. In one spatial dimension, our fourth order\nMUSCL scheme outperforms existing WENO and upwind schemes in terms of stability\nand accuracy. In two spatial dimensions, our MUSCL scheme achieves similar\naccuracy to an existing WENO scheme but is significantly more stable.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T11:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.05949v1","title":"Sharp fractional Hardy's inequality for half-spaces in the Heisenberg\n  group","summary":"In this work we establish the following fractional Hardy's inequality\n  $$C\\int_{\\mathbb{H}^n_+}\\frac{|f(\\xi)|^p}{x_1^{sp+\\alpha}}d\\xi\\leq\n\\int_{\\mathbb{H}^n}\\int_{\\mathbb{H}^n}\\frac{|f(\\xi)-f(\\xi')|^p}{d({\\xi}^{-1}\\circ\n\\xi')^{Q+sp}|z'-z|^\\alpha}d\\xi'd\\xi,\\ \\ \\forall f\\in\nC_c^{\\infty}(\\mathbb{H}^n_+)$$\n  for the half-space\n$\\{\\xi=(x,y,t)=(x_1,\\ldots,x_n,y_1,\\ldots,y_n)\\in\\mathbb{H}^n:x_1>0\\}$ in the\nHeisenberg group $\\mathbb{H}^n$ without any restriction on parameters, and\ncompute the corresponding sharp constant. In a previous joint work, we\nestablished a variant of Hardy's inequality for the same half-space, but with\ncertain parameter restrictions. However, all integrals in that work were\nconsidered over half-spaces, and here the seminorm is taken over the entire\n$\\mathbb{H}^n$. Although this inequality holds for all values of the quantity\n$sp+\\alpha$, we are only able to compute the corresponding sharp constant when\n$sp+\\alpha>1$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.05955v1","title":"Fair Resource Allocation in UAV-based Semantic Communication System with\n  Fluid Antenna","summary":"In this paper, the problem of maximization of the minimum equivalent rate in\na unmanned-aerial-vehicle (UAV)-based multi-user semantic communication system\nis investigated. In the considered model, a multi-antenna UAV employs semantic\nextraction techniques to compress the data ready to be sent to the users, which\nare equipped with fluid antennas. Our aim is to jointly optimize the trajectory\nof the UAV, the transmit beamforming and the semantic compression rate at the\nUAV, as well as the selection of activated ports in fluid antenna system (FAS),\nto maximize the minimum equivalent transmission rate among all user. An\nalternating algorithm is designed to solve the problem. Simulation results\nvalidate the effectiveness of the proposed algorithm.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T12:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.05957v1","title":"Drought forecasting using a hybrid neural architecture for integrating\n  time series and static data","summary":"Reliable forecasting is critical for early warning systems and adaptive\ndrought management. Most previous deep learning approaches focus solely on\nhomogeneous regions and rely on single-structured data. This paper presents a\nhybrid neural architecture that integrates time series and static data,\nachieving state-of-the-art performance on the DroughtED dataset. Our results\nillustrate the potential of designing neural models for the treatment of\nheterogeneous data in climate related tasks and present reliable prediction of\nUSDM categories, an expert-informed drought metric. Furthermore, this work\nvalidates the potential of DroughtED for enabling location-agnostic training of\ndeep learning models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T12:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.05965v1","title":"Generalized Parameter Lifting: Finer Abstractions for Parametric Markov\n  Chains","summary":"Parametric Markov chains (pMCs) are Markov chains (MCs) with symbolic\nprobabilities. A pMC encodes a family of MCs, where each member is obtained by\nreplacing parameters with constants. The parameters allow encoding dependencies\nbetween transitions, which sets pMCs apart from interval MCs. The verification\nproblem for pMCs asks whether each MC in the corresponding family satisfies a\ngiven temporal specification. The state-of-the-art approach for this problem is\nparameter lifting (PL) -- an abstraction-refinement loop that abstracts the pMC\nto a non-parametric model analyzed with standard probabilistic model checking\ntechniques. This paper presents two key improvements to tackle the main\nlimitations of PL. First, we introduce generalized parameter lifting (GPL) to\nlift various restrictive assumptions made by PL. Second, we present a big-step\ntransformation algorithm that reduces parameter dependencies in pMCs and,\ntherefore, results in tighter approximations. Experiments show that GPL is\nwidely applicable and that the big-step transformation accelerates pMC\nverification by up to orders of magnitude.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-08T12:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05990v1","title":"AI analysis of medical images at scale as a health disparities probe: a\n  feasibility demonstration using chest radiographs","summary":"Health disparities (differences in non-genetic conditions that influence\nhealth) can be associated with differences in burden of disease by groups\nwithin a population. Social determinants of health (SDOH) are domains such as\nhealth care access, dietary access, and economics frequently studied for\npotential association with health disparities. Evaluating SDOH-related\nphenotypes using routine medical images as data sources may enhance health\ndisparities research. We developed a pipeline for using quantitative measures\nautomatically extracted from medical images as inputs into health disparities\nindex calculations. Our study focused on the use case of two SDOH demographic\ncorrelates (sex and race) and data extracted from chest radiographs of 1,571\nunique patients. The likelihood of severe disease within the lung parenchyma\nfrom each image type, measured using an established deep learning model, was\nmerged into a single numerical image-based phenotype for each patient. Patients\nwere then separated into phenogroups by unsupervised clustering of the\nimage-based phenotypes. The health rate for each phenogroup was defined as the\nmedian image-based phenotype for each SDOH used as inputs to four\nimaging-derived health disparities indices (iHDIs): one absolute measure\n(between-group variance) and three relative measures (index of disparity, Theil\nindex, and mean log deviation). The iHDI measures demonstrated feasible values\nfor each SDOH demographic correlate, showing potential for medical images to\nserve as a novel probe for health disparities. Large-scale AI analysis of\nmedical images can serve as a probe for a novel data source for health\ndisparities research.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-08T12:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.05997v1","title":"Note on the Universality of Parameterized IQP Circuits with Hidden Units\n  for Generating Probability Distributions","summary":"In a series of recent works, an interesting quantum generative model based on\nparameterized instantaneous polynomial quantum (IQP) circuits has emerged as\nthey can be trained efficiently classically using any loss function that\ndepends only on the expectation values of observables of the model. The model\nis proven not to be universal for generating arbitrary distributions, but it is\nsuspected that marginals can be - much like Boltzmann machines achieve\nuniversality by utilizing hidden (traced-out in quantum jargon) layers. In this\nshort note, we provide two simple proofs of this fact. The first is\nnear-trivial and asymptotic, and the second shows universality can be achieved\nwith a reasonable number of additional qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:03:23Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06009v1","title":"Linear time-and-space-invariant relaxation systems","summary":"This paper generalizes the physical property of relaxation from linear\ntime-invariant (LTI) to linear time-and-space-invariant (LTSI) systems. It is\nshown that the defining features of relaxation -- complete monotonicity,\npassivity, and memory-based storage -- carry over seamlessly to the\nspatio-temporal domain. An LTSI system is shown to be of relaxation type if and\nonly if its associated spatio-temporal Hankel operator is cyclically monotone.\nThis implies the existence of an intrinsic quadratic storage functional defined\nuniquely by past inputs, independently of any state-space realization. As in\nthe LTI case, LTSI relaxation systems are shown to be those systems for which\nthe state-space concept of storage coincides with the input-output concept of\nfading memory functional.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-08T13:16:47Z"}
{"aid":"http://arxiv.org/abs/2504.06014v1","title":"Sparse Reconstruction of Multi-Dimensional Kinetic Distributions","summary":"In the present work, we propose a novel method for reconstruction of\nmulti-dimensional kinetic distributions, based on their representation as a\nmixture of Dirac delta functions. The representation is found as a solution of\nan optimization problem. Different target functionals are considered, with a\nfocus on sparsity-promoting regularization terms. The proposed algorithm\nguarantees non-negativity of the distribution by construction, and avoids an\nexponential dependence of the computational cost on the dimensionality of the\nproblem.\n  Numerical comparisons with other classical methods for reconstruction of\nkinetic distributions are provided for model problems, and the role of the\ndifferent parameters governing the optimization problem is studied.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-08T13:19:27Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06024v1","title":"AriaQuanta: A Quantum Software for Quantum Computing","summary":"We introduce AriaQuanta, a powerful and flexible tool for designing,\nsimulating, and implementing quantum circuits. This open-source software is\ndesigned to make it easy for users of all experience levels to learn and use\nquantum computing. The first version includes a compiler for implementing\nvarious quantum circuits and algorithms. Additionally, parametric circuits\nallow for the implementation of variational quantum algorithms, and various\nnoise models are available for simulating noisy circuits. We performed numerous\nnumerical simulations on AriaQuanta in various applications, including quantum\nalgorithms and noisy circuits. The results, compared with popular counterparts,\ndemonstrate the high performance of AriaQuanta.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:27:58Z"}
{"aid":"http://arxiv.org/abs/2504.06029v1","title":"Red giant component of the recurrent nova T Coronae Borealis","summary":"We performed simultaneous V band photometry and spectroscopic observations of\nthe recurrent nova T CrB and estimate the V band magnitude of the red giant. We\nfind for the red giant of T CrB apparent and absolute V-band magnitudes m_V =\n10.17 +/- 0.06 and M_V = +0.14 +/- 0.08, respectively. At the maximum of the\nellipsoidal variation when these values are obtained, its absolute V-band\nmagnitude is similar but fainter than the typical M4/5III giants. The data are\navailable on : zenodo.org/records/15174720","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T13:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.06036v1","title":"Multi-Sense Embeddings for Language Models and Knowledge Distillation","summary":"Transformer-based large language models (LLMs) rely on contextual embeddings\nwhich generate different (continuous) representations for the same token\ndepending on its surrounding context. Nonetheless, words and tokens typically\nhave a limited number of senses (or meanings). We propose multi-sense\nembeddings as a drop-in replacement for each token in order to capture the\nrange of their uses in a language. To construct a sense embedding dictionary,\nwe apply a clustering algorithm to embeddings generated by an LLM and consider\nthe cluster centers as representative sense embeddings. In addition, we propose\na novel knowledge distillation method that leverages the sense dictionary to\nlearn a smaller student model that mimics the senses from the much larger base\nLLM model, offering significant space and inference time savings, while\nmaintaining competitive performance. Via thorough experiments on various\nbenchmarks, we showcase the effectiveness of our sense embeddings and knowledge\ndistillation approach. We share our code at\nhttps://github.com/Qitong-Wang/SenseDict","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T13:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06052v1","title":"Categorical matrix factorizations and monomorphism categories","summary":"This article generalizes the correspondence between matrix factorizations and\nmaximal Cohen-Macaulay modules over hypersurface rings due to Eisenbud and\nYoshino. We consider factorizations with several factors in a purely\ncategorical context, extending results of Sun and Zhang for Gorenstein\nprojective module factorizations. Our formulation relies on a notion of\nhypersurface category and replaces Gorenstein projectives by objects of general\nFrobenius exact subcategories. We show that factorizations over such categories\nform again a Frobenius category. Our main result is then a triangle equivalence\nbetween the stable category of factorizations and that of chains of\nmonomorphisms.","main_category":"math.CT","categories":"math.CT,math.AC","published":"2025-04-08T13:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.06056v1","title":"$L_\\textrm{dT}$: An ionospheric activity index based on distributions in\n  GNSS-derived TEC rates of change","summary":"Many aspects of our societies now depend upon satellite telecommunications,\nsuch as those requiring Global Navigation Satellite Systems (GNSS). GNSS is\nbased on radio waves that propagate through the ionosphere and experience\ncomplicated propagation effects caused by inhomogeneities in its electron\ndensity. The Earth's ionosphere forms part of the solar-terrestrial\nenvironment, and its state is determined by the spatial distribution and\ntemporal evolution of its electron density. It varies in response to the \"space\nweather\" combination of solar activity and geomagnetic conditions. Notably, the\nradio waves used in satellite telecommunications suffer due to the dispersive\nnature of the ionospheric plasma.\n  Scales and indices that summarise the state of the solar-terrestrial\nenvironment due to solar activity and geomagnetic conditions already exist.\nHowever, the response of the ionosphere to active geomagnetic conditions, its\ngeoeffectiveness, and its likely impact on systems and services are not\nencapsulated by these. This is due to the ionosphere's intrinsic day-to-day\nvariability, persistent seasonal patterns, and because radio wave measurements\nof the ionosphere depend upon many factors.\n  Here we develop a novel index that describes the state of the ionosphere\nduring specific space weather conditions. It is based on propagation\ndisturbances in GNSS signals, and is able to characterise the spatio-temporal\nevolution of ionospheric disturbances in near real time. This new scale\nencapsulates day-to-day variability, seasonal patterns, and the geo-effective\nresponse of the ionosphere to disturbed space weather conditions; and can be\napplied to data from any GNSS network. It is intended that this new scale will\nbe utilised by agencies providing space weather services, as well as by service\noperators to appreciate the current conditions in the ionosphere, thus\ninforming their operations.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-08T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.06067v1","title":"GPU-accelerated Evolutionary Many-objective Optimization Using\n  Tensorized NSGA-III","summary":"NSGA-III is one of the most widely adopted algorithms for tackling\nmany-objective optimization problems. However, its CPU-based design severely\nlimits scalability and computational efficiency. To address the limitations, we\npropose {TensorNSGA-III}, a fully tensorized implementation of NSGA-III that\nleverages GPU parallelism for large-scale many-objective optimization. Unlike\nconventional GPU-accelerated evolutionary algorithms that rely on heuristic\napproximations to improve efficiency, TensorNSGA-III maintains the exact\nselection and variation mechanisms of NSGA-III while achieving significant\nacceleration. By reformulating the selection process with tensorized data\nstructures and an optimized caching strategy, our approach effectively\neliminates computational bottlenecks inherent in traditional CPU-based and\nna\\\"ive GPU implementations. Experimental results on widely used numerical\nbenchmarks show that TensorNSGA-III achieves speedups of up to $3629\\times$\nover the CPU version of NSGA-III. Additionally, we validate its effectiveness\nin multiobjective robotic control tasks, where it discovers diverse and\nhigh-quality behavioral solutions. Furthermore, we investigate the critical\nrole of large population sizes in many-objective optimization and demonstrate\nthe scalability of TensorNSGA-III in such scenarios. The source code is\navailable at https://github.com/EMI-Group/evomo","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-08T14:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.06068v1","title":"A Liouville-type property for degenerate-elliptic equations modeled on\n  Hörmander vector fields","summary":"We obtain Liouville type theorems for degenerate elliptic equation with a\ndrift term and a potential. The diffusion is driven by H\\\"ormander operators.\nWe show that the conditions imposed on the coefficients of the operator are\noptimal. Indeed, when they fail we prove that infinitely many bounded solutions\nexist.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.06070v1","title":"PINP: Physics-Informed Neural Predictor with latent estimation of fluid\n  flows","summary":"Accurately predicting fluid dynamics and evolution has been a long-standing\nchallenge in physical sciences. Conventional deep learning methods often rely\non the nonlinear modeling capabilities of neural networks to establish mappings\nbetween past and future states, overlooking the fluid dynamics, or only\nmodeling the velocity field, neglecting the coupling of multiple physical\nquantities. In this paper, we propose a new physics-informed learning approach\nthat incorporates coupled physical quantities into the prediction process to\nassist with forecasting. Central to our method lies in the discretization of\nphysical equations, which are directly integrated into the model architecture\nand loss function. This integration enables the model to provide robust,\nlong-term future predictions. By incorporating physical equations, our model\ndemonstrates temporal extrapolation and spatial generalization capabilities.\nExperimental results show that our approach achieves the state-of-the-art\nperformance in spatiotemporal prediction across both numerical simulations and\nreal-world extreme-precipitation nowcasting benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T14:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.06071v1","title":"On Onsager-type conjecture for the Elsässer energies of the ideal\n  MHD equations","summary":"In this paper, we investigate the ideal magnetohydrodynamics (MHD) equations\non tours $\\TTT^d$. For $d=3$, we resolve the flexible part of Onsager-type\nconjecture for Els\\\"{a}sser energies of the ideal MHD equations. More\nprecisely, for \\(\\beta < 1/3\\), we construct weak solutions \\((u, b) \\in\nC^\\beta([0,T] \\times \\mathbb{T}^3)\\) with both the total energy dissipation and\nfailure of cross helicity conservation. The key idea of the proof relies on a\nsymmetry reduction that embeds the ideal MHD system into a 2$\\frac{1}{2}$D\nEuler flow and the Newton-Nash iteration technique recently developed in\n\\cite{GR}. For $d=2$, we show the non-uniqueness of H\\\"{o}lder-continuous weak\nsolutions with non-trivial magnetic fields. Specifically, for \\(\\beta < 1/5\\),\nthere exist infinitely many solutions \\((u, b) \\in C^\\beta([0,T] \\times\n\\mathbb{T}^2)\\) with the same initial data while satisfying the total energy\ndissipation with non-vanishing velocity and magnetic fields. The new ingredient\nis developing a spatial-separation-driven iterative scheme that incorporates\nthe magnetic field as a controlled perturbation within the convex integration\nframework for the velocity field, thereby providing sufficient oscillatory\nfreedom for Nash-type perturbations in the 2D setting. As a byproduct, we prove\nthat any H\\\"{o}lder-continuous Euler solution can be approximated by a sequence\nof $C^\\beta$-weak solutions for the ideal MHD equations in the $L^p$-topology\nfor $1\\le p<\\infty$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.06078v1","title":"Carbon, Cost and Capacity: Multi-objective Charging of Electric Buses","summary":"The public transport sector is in the process of decarbonizing by\nelectrifying its bus fleets. This results in challenges if the high electricity\ndemand resulting from battery charging demand is confronted with limited grid\ncapacity and high synchronicity at bus charging sites. In this paper, we\nexplore multi-objective scheduling for bus charging sites to minimize the\nemissions associated with charging processes and to aid the operation of the\nelectricity grid by mitigating peak consumption. In particular, we discuss and\nvalidate optimization approaches for those objectives, as well as their\nweighted combination, based on data from a real-life bus charging site in the\nNetherlands. The simulation results show that compared to uncontrolled\ncharging, power peaks can be reduced by up to 57%, while time-of-use emissions\nassociated with the charging of electric buses are also reduced significantly.\nFurthermore, by using a synthetic baseload, we illustrate the flexibility\npotential offered by bus charging sites, and advocate that such sites should\nshare a grid connection with other high-load assets.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T14:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.06085v1","title":"Contact embeddings of 3-dimensional contact groups","summary":"A 3-dimensional contact group is a 3-dimensional Lie group endowed with a\nleft-invariant contact structure. Making use of techniques from Riemannian\ngeometry, we prove that any simply connected 3-dimensional contact group not\nisomorphic to SU(2) satisfies a unique factorization property. As an\napplication, we develop a method to construct embeddings of 3-dimensional\nsimply connected contact groups into one among two model tight contact\nmanifolds.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-08T14:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.06088v1","title":"MCAT: Visual Query-Based Localization of Standard Anatomical Clips in\n  Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer","summary":"Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:29:15Z"}
{"aid":"http://arxiv.org/abs/2504.06089v1","title":"A Monotonicity Formula for the Extrinsic Biharmonic Map Heat Flow","summary":"We explore novel properties of the biharmonic heat kernel on Euclidean space\nand derive an entropy type quantity for the extrinsic biharmonic map heat flow\nwhich exhibits monotonicity behaviors for $n\\leq 4$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-08T14:30:03Z"}
{"aid":"http://arxiv.org/abs/2504.06090v1","title":"Low-Complexity SDP-ADMM for Physical-Layer Multicasting in Massive MIMO\n  Systems","summary":"There is a demand for the same data content from several user equipments\n(UEs) in many wireless communication applications. Physical-layer multicasting\ncombines the beamforming capability of massive MIMO (multiple-input\nmultiple-output) and the broadcast nature of the wireless channel to\nefficiently deliver the same data to a group of UEs using a single\ntransmission. This paper tackles the max-min fair (MMF) multicast beamforming\noptimization, which is an NP-hard problem. We develop an efficient semidefinite\nprogram-alternating direction method of multipliers (SDP-ADMM) algorithm to\nfind the near-global optimal rank-1 solution to the MMF multicast problem in a\nmassive MIMO system. Numerical results show that the proposed SDP-ADMM\nalgorithm exhibits similar spectral efficiency performance to state-of-the-art\nalgorithms running on standard SDP solvers at a vastly reduced computational\ncomplexity. We highlight that the proposed ADMM elimination procedure can be\nemployed as an effective low-complexity rank reduction method for other\nproblems utilizing semidefinite relaxation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T14:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.06092v1","title":"Greedy Emulators for Nuclear Two-Body Scattering","summary":"Applications of reduced basis method emulators are increasing in low-energy\nnuclear physics because they enable fast and accurate sampling of high-fidelity\ncalculations, enabling robust uncertainty quantification. In this paper, we\ndevelop, implement, and test two model-driven emulators based on\n(Petrov-)Galerkin projection using the prototypical test case of two-body\nscattering with the Minnesota potential and a more realistic local chiral\npotential. The high-fidelity scattering equations are solved with the matrix\nNumerov method, a reformulation of the popular Numerov recurrence relation for\nsolving special second-order differential equations as a linear system of\ncoupled equations. A novel error estimator based on reduced-space residuals is\napplied to an active learning approach (a greedy algorithm) to choosing\ntraining samples (\"snapshots\") for the emulator and contrasted with a proper\northogonal decomposition (POD) approach. Both approaches allow for\ncomputationally efficient offline-online decompositions, but the greedy\napproach requires much fewer snapshot calculations. These developments set the\ngroundwork for emulating scattering observables based on chiral nucleon-nucleon\nand three-nucleon interactions and optical models, where computational\nspeed-ups are necessary for Bayesian uncertainty quantification. Our emulators\nand error estimators are widely applicable to linear systems.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex,physics.data-an","published":"2025-04-08T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06098v1","title":"Extremely asymmetric bipolar magnetic field of the Bp star HD 57372","summary":"Fossil magnetic fields of early-type stars are typically characterised by\nsymmetric or slightly distorted oblique dipolar surface geometries. Contrary to\nthis trend, the late-B magnetic chemically peculiar star HD 57372 exhibits an\nunusually large rotational variation of its mean magnetic field modulus,\nsuggesting a highly atypical field configuration. In this study, we present a\nZeeman Doppler imaging analysis of HD 57372, revealing an exceptionally\nasymmetric bipolar magnetic topology, rarely observed in early-type stars.\nAccording to our magnetic field maps, reconstructed from the intensity and\ncircular polarisation profiles of Fe, Cr, and Ti lines, approximately 66 per\ncent of the stellar surface is covered by a diffuse outward-directed radial\nfield, with local field strengths reaching 11.6 kG, while the remaining 34 per\ncent hosts a highly concentrated inward-directed field with a strong horizontal\ncomponent and a peak strength of 17.8 kG. These unusual surface magnetic field\ncharacteristics make HD 57372 a notable object for testing fossil-field\ntheories and interpreting phase-resolved spectropolarimetric observations of\nearly-type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T14:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.06099v1","title":"Towards Varroa destructor mite detection using a narrow spectra\n  illumination","summary":"This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.06106v1","title":"A ROS2-based software library for inverse dynamics computation","summary":"Inverse dynamics computation is a critical component in robot control,\nplanning and simulation, enabling the calculation of joint torques required to\nachieve a desired motion. This paper presents a ROS2-based software library\ndesigned to solve the inverse dynamics problem for robotic systems. The library\nis built around an abstract class with three concrete implementations: one for\nsimulated robots and two for real UR10 and Franka robots. This contribution\naims to provide a flexible, extensible, robot-agnostic solution to inverse\ndynamics, suitable for both simulation and real-world scenarios involving\nplanning and control applications. The related software is available at\nhttps://github.com/ros2-gbp/ros2-gbp-github-org/issues/732.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T14:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.06116v1","title":"To Match or Not to Match: Revisiting Image Matching for Reliable Visual\n  Place Recognition","summary":"Visual Place Recognition (VPR) is a critical task in computer vision,\ntraditionally enhanced by re-ranking retrieval results with image matching.\nHowever, recent advancements in VPR methods have significantly improved\nperformance, challenging the necessity of re-ranking. In this work, we show\nthat modern retrieval systems often reach a point where re-ranking can degrade\nresults, as current VPR datasets are largely saturated. We propose using image\nmatching as a verification step to assess retrieval confidence, demonstrating\nthat inlier counts can reliably predict when re-ranking is beneficial. Our\nfindings shift the paradigm of retrieval pipelines, offering insights for more\nrobust and adaptive VPR systems.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.06117v1","title":"Some Analytical Properties of Multivariate Fractal Functions in Lebesgue\n  Spaces","summary":"In this article, we focus on the construction of multivariate fractal\nfunctions in Lebesgue spaces along with some properties of associated fractal\noperator. First, we give a detailed construction of the fractal functions\nbelonging to Lebesgue spaces. Then, we give analytical properties of the\ndefined fractal operator in Lebesgue spaces. We end this article by showing the\nexistence of Schauder basis of the associated fractal functions for the space\n$\\mathcal{L}^q(I^n, \\mu_p)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T15:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.06125v1","title":"Robo-taxi Fleet Coordination at Scale via Reinforcement Learning","summary":"Fleets of robo-taxis offering on-demand transportation services, commonly\nknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise\nfor societal benefits, such as reducing pollution, energy consumption, and\nurban congestion. However, orchestrating these systems at scale remains a\ncritical challenge, with existing coordination algorithms often failing to\nexploit the systems' full potential. This work introduces a novel\ndecision-making framework that unites mathematical modeling with data-driven\ntechniques. In particular, we present the AMoD coordination problem through the\nlens of reinforcement learning and propose a graph network-based framework that\nexploits the main strengths of graph representation learning, reinforcement\nlearning, and classical operations research tools. Extensive evaluations across\ndiverse simulation fidelities and scenarios demonstrate the flexibility of our\napproach, achieving superior system performance, computational efficiency, and\ngeneralizability compared to prior methods. Finally, motivated by the need to\ndemocratize research efforts in this area, we release publicly available\nbenchmarks, datasets, and simulators for network-level coordination alongside\nan open-source codebase designed to provide accessible simulation platforms and\nestablish a standardized validation process for comparing methodologies. Code\navailable at: https://github.com/StanfordASL/RL4AMOD","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-08T15:19:41Z"}
{"aid":"http://arxiv.org/abs/2504.06127v1","title":"Optimal classification with outcome performativity","summary":"I consider the problem of classifying individual behavior in a simple setting\nof outcome performativity where the behavior the algorithm seeks to classify is\nitself dependent on the algorithm. I show in this context that the most\naccurate classifier is either a threshold or a negative threshold rule. A\nthreshold rule offers the \"good\" classification to those individuals whose\noutcome likelihoods are greater than some cutpoint, while a negative threshold\nrule offers the \"good\" outcome to those whose outcome likelihoods are less than\nsome cutpoint. While seemingly pathological, I show that a negative threshold\nrule can be the most accurate classifier when outcomes are performative. I\nprovide an example of such a classifier, and extend the analysis to more\ngeneral algorithm objectives, allowing the algorithm to differentially weigh\nfalse negatives and false positives, for example.","main_category":"econ.TH","categories":"econ.TH,cs.GT","published":"2025-04-08T15:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.06131v1","title":"FaceCloak: Learning to Protect Face Templates","summary":"Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face raising security\nand privacy concerns. We present FaceCloak, a neural network framework that\nprotects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperforms leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. FaceCloak-based matching is\nextremely fast (inference time cost=0.28ms) and light-weight (0.57MB).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06132v1","title":"Stochastic numerical approximation for nonlinear Fokker-Planck equations\n  with singular kernels","summary":"This paper studies the convergence rate of the Euler-Maruyama scheme for\nsystems of interacting particles used to approximate solutions of nonlinear\nFokker-Planck equations with singular interaction kernels, such as the\nKeller-Segel model. We derive explicit error estimates in the large-particle\nlimit for two objects: the empirical measure of the interacting particle system\nand the density distribution of a single particle. Specifically, under certain\nassumptions on the interaction kernel and initial conditions, we show that the\nconvergence rate of both objects towards solutions of the corresponding\nnonlinear FokkerPlanck equation depends polynomially on N (the number of\nparticles) and on h (the discretization step). The analysis shows that the\nscheme converges despite singularities in the drift term. To the best of our\nknowledge, there are no existing results in the literature of such kind for the\nsingular kernels considered in this work.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-08T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.06136v1","title":"QGen Studio: An Adaptive Question-Answer Generation, Training and\n  Evaluation Platform","summary":"We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T15:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.06137v1","title":"Coexistence of magnetic and dielectric glassy states in alternating\n  kagome and triangular lattice LuBaCo$_4$O$_7$ cobaltite","summary":"To date, the alternating kagome and triangular lattice cobaltites,\nRBaCo$_4$O$_7$ (R = Ca, Y, and rare earth elements), have been well studied for\ntheir large structural distortions, anisotropic exchange interactions, chiral\nspin liquid states, and giant multiferroic properties. Here, we report the\nco-existence of magnetic and dielectric glassy states in LuBaCo$_4$O$_7$ below\n50 K. AC magnetization studies show an absence of conventional spin-freezing\nbehavior. The cooling and heating in unequal fields (CHUF), thermal cycling,\nand time-dependent magnetization measurements at low temperature ($T$) show the\npresence of magnetic glassy state. The $T$-dependent dielectric constant\n$\\epsilon'$ measurements exhibit a strong frequency-independent response at the\nfirst-order structural phase transition $T = 160$ K (trigonal $P31c$ to\nmonoclinic $Cc$) and also significant features at the $T = 110$ K (monoclinic\n$Cc$ to orthorhombic $Pbn2_1$) phase transition. Further, $\\epsilon'$ shows a\nfrequency-independent peak at 43 K ($Pbn2_1$) and also dipolar glassy features\nbelow 20 K ($Cc$). The non-equilibrium magnetic glassy dynamics and dipolar\nglassy state at low-$T$ arises from the kinetic arrest of $Cc$ and $Pbn2_1$\nphases. From the dielectric probe, we are able to clearly distinguish the\nkinetically arrested phases at low-$T$ , whereas the bulk magnetization studies\nare unable to do so as the arrested phases have low magnetic moments.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T15:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.06184v1","title":"The two-loop Higgs impact factor","summary":"In the HEFT, we consider the Regge limit of the two-loop amplitudes for Higgs\nboson production in association with a jet, expanded to NNLL accuracy. We\ndiscuss the issue of the Regge cuts versus poles in this context, and determine\nfor the first time the Higgs impact factor at two-loop accuracy.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T16:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.06205v1","title":"HRMedSeg: Unlocking High-resolution Medical Image segmentation via\n  Memory-efficient Attention Modeling","summary":"High-resolution segmentation is critical for precise disease diagnosis by\nextracting micro-imaging information from medical images. Existing\ntransformer-based encoder-decoder frameworks have demonstrated remarkable\nversatility and zero-shot performance in medical segmentation. While\nbeneficial, they usually require huge memory costs when handling large-size\nsegmentation mask predictions, which are expensive to apply to real-world\nscenarios. To address this limitation, we propose a memory-efficient framework\nfor high-resolution medical image segmentation, called HRMedSeg. Specifically,\nwe first devise a lightweight gated vision transformer (LGViT) as our image\nencoder to model long-range dependencies with linear complexity. Then, we\ndesign an efficient cross-multiscale decoder (ECM-Decoder) to generate\nhigh-resolution segmentation masks. Moreover, we utilize feature distillation\nduring pretraining to unleash the potential of our proposed model. Extensive\nexperiments reveal that HRMedSeg outperforms state-of-the-arts in diverse\nhigh-resolution medical image segmentation tasks. In particular, HRMedSeg uses\nonly 0.59GB GPU memory per batch during fine-tuning, demonstrating low training\ncosts. Besides, when HRMedSeg meets the Segment Anything Model (SAM), our\nHRMedSegSAM takes 0.61% parameters of SAM-H. The code is available at\nhttps://github.com/xq141839/HRMedSeg.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T16:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.06207v1","title":"An experimental survey and Perspective View on Meta-Learning for\n  Automated Algorithms Selection and Parametrization","summary":"Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T16:51:22Z"}
{"aid":"http://arxiv.org/abs/2504.06234v1","title":"Observing radio transients with Phased ALMA: Pulses from the Galactic\n  Centre magnetar","summary":"Radio transients, such as pulsars and Fast Radio Bursts (FRBs), are primarily\ndetected at centimetre radio wavelengths, where higher luminosities are found.\nHowever, observations of sources in dense environments are heavily affected by\npropagation effects which may hinder a detection. Millimetre wave observations\nbypass this complication but require the largest radio telescopes to compensate\nfor the lower flux densities. When used in phased mode, the ALMA radio\ntelescope provides an equivalent dish size of 84m, being the most sensitive\ninstrument at mm/sub mm. With its high time resolution it offers a unique\nopportunity to study radio transients in an unexplored window. We study the\nGalactic Centre (GC) magnetar, PSR J1745$-$2900, as a laboratory for magnetars\nin complex magneto-turbulent environments and to link with FRBs. We showcase\nthe potential of ALMA in phased mode to observe radio transients and to\nachieve, for some sources, the first ever detections outside the cm wave range.\nWe studied the GC magnetar using ALMA archival data of Sgr A* at Band 3 from\nthe 2017 GMVA campaign. We searched in intensity and classified the pulses\nbased on their circular and linear polarisation properties and arrival phase.\nWe detected eight pulses with energies in the range of 10$^{29}$ erg. We\nconstructed its cumulative energy distribution and we fit a power law, where\nthe event rate scales with energy as $R \\propto E^{\\gamma}$. The result is an\nexponent of $\\gamma = -2.4 \\pm 0.1$. With the $\\gamma -$value and the system\nproperties of phased ALMA, we estimate that over 160 known pulsars could be\ndetected by ALMA. For repeating FRBs, observing during their peak activity\nwindow could lead to several detections. We expect that ALMA's lower frequency\nbands with polarisation capabilities, will serve as a pioneer on mm wave\nsearches for pulsars and to study complex environments involving radio\ntransients.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T17:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.06235v1","title":"Decentralized Federated Domain Generalization with Style Sharing: A\n  Formal Modeling and Convergence Analysis","summary":"Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06238v1","title":"Infinite Boundary Friction Limit for Weak Solutions of the Stochastic\n  Navier-Stokes Equations","summary":"We address convergence of the unique weak solutions of the 2D stochastic\nNavier-Stokes equations with Navier boundary conditions, as the boundary\nfriction is taken uniformly to infinity, to the unique weak solution under the\nno-slip condition. Our result is that for initial velocity in $L^2_x$, the\nconvergence holds in probability in $C_tW^{-\\varepsilon,2}_x \\cap L^2_tL^2_x$\nfor any $0 < \\varepsilon$. The noise is of transport-stretching type, although\nthe theorem holds with other transport, multiplicative and additive noise\nstructures. This seems to be the first work concerning the large boundary\nfriction limit with noise, and convergence for weak solutions, due to only\n$L^2_{x}$ initial data, appears new even deterministically.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T17:34:29Z"}
{"aid":"http://arxiv.org/abs/2504.06239v1","title":"Canonical for Automated Theorem Proving in Lean","summary":"Canonical is a solver for type inhabitation in dependent type theory, that\nis, the problem of producing a term of a given type. We present a Lean tactic\nwhich invokes Canonical to generate proof terms and synthesize programs. The\ntactic supports higher-order and dependently-typed goals, structural recursion\nover indexed inductive types, and definitional equality. Canonical finds proofs\nfor 84% of Natural Number Game problems in 51 seconds total.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-08T17:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06249v1","title":"Electronic Structure Guided Inverse Design Using Generative Models","summary":"The electronic structure of a material fundamentally determines its\nunderlying physical, and by extension, its functional properties. Consequently,\nthe ability to identify or generate materials with desired electronic\nproperties would enable the design of tailored functional materials.\nTraditional approaches relying on human intuition or exhaustive computational\nscreening of known materials remain inefficient and resource-prohibitive for\nthis task. Here, we introduce DOSMatGen, the first instance of a machine\nlearning method which generates crystal structures that match a given desired\nelectronic density of states. DOSMatGen is an E(3)-equivariant joint diffusion\nframework, and utilizes classifier-free guidance to accurately condition the\ngenerated materials on the density of states. Our experiments find this\napproach can successfully yield materials which are both stable and match\nclosely with the desired density of states. Furthermore, this method is highly\nflexible and allows for finely controlled generation which can target specific\ntemplates or even individual sites within a material. This method enables a\nmore physics-driven approach to designing new materials for applications\nincluding catalysts, photovoltaics, and superconductors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06266v1","title":"Constraining the [CII] luminosity function from the power spectrum of\n  line intensity maps at redshift 3.6","summary":"Forthcoming measurements of the line-intensity-mapping power spectrum (PS)\nare expected to set precious constraints on several quantities of astrophysical\nand cosmological interest. Our study targets the [CII] luminosity function (LF)\nat high redshift, which is still highly uncertain, in particular at the faint\nend. As an example of future opportunities, we present forecasts for the Deep\nSpectroscopic Survey (DSS) that will be conducted with the Fred Young\nSubmillimeter Telescope at $z \\simeq 3.6$ and also make predictions for\neventual $10\\times$ wider and/or $\\sqrt{10}\\times$ more sensitive surveys. The\nhalo-occupation properties of [CII] emitters in the MARIGOLD simulations\nprovide us with the motivation to abundance match two versions of the ALPINE LF\nagainst the halo mass function. We employ the resulting luminosity-mass\nrelation within the halo model to predict the expected PS signal and its\nuncertainty. Finally, we use Bayesian inference to analyse mock PS data and\nforecast what constraints could be achieved on the first two moments of the LF\nand on Schechter fits. Depending on the actual LF, the DSS will measure the\nclustering and shot-noise amplitudes of the PS with a signal-to-noise ratio of\n$\\sim 3$ or higher. However, degeneracies with the bias parameter and\nredshift-space distortions make it unfeasible to extract the first moment of\nthe LF. Even the widest and most sensitive survey we consider can only\nconstrain it with a $50\\%$ uncertainty. By jointly fitting the PS and the LF,\nwe directly constrain Schechter-function parameters. We find that the\nnormalisation and the cutoff luminosity are precisely and accurately measured\nwhile the faint-end slope remains highly uncertain (unless the true value\napproaches $-2$). Overall, increasing the survey sensitivity at fixed sky\ncoverage yields greater improvements than covering a larger area at fixed\nsensitivity.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06562v1","title":"FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion","summary":"Heterogeneous model fusion enhances the performance of LLMs by integrating\nthe knowledge and capabilities of multiple structurally diverse models.\nHowever, existing approaches often rely solely on selecting the best output for\neach prompt from source models, which underutilizes their full potential due to\nlimited source knowledge and results in sparse optimization signals. To address\nthis limitation, we propose FuseRL, a novel two-stage framework comprising\nFuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT\nestablishes a robust initialization by integrating the strengths of\nheterogeneous source models through weighted supervised fine-tuning (SFT) on\ndiverse outputs for each prompt. FusePO optimizes weighted preferences based on\nthe outputs of multiple source models to enable superior alignment performance.\nExtensive experiments demonstrate the effectiveness of our framework across\nvarious preference alignment methods, including RLOO, DPO, and SimPO. Using\nLlama-3.1-8B-Instruct as the target model, our approach achieves\nstate-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard\nbenchmarks. Further analysis suggests that FuseSFT regularizes the training\nprocess to reduce overfitting, while FusePO introduces dense and diverse\nsignals for preference optimization.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.06580v1","title":"Exploring Ordinal Bias in Action Recognition for Instructional Videos","summary":"Action recognition models have achieved promising results in understanding\ninstructional videos. However, they often rely on dominant, dataset-specific\naction sequences rather than true video comprehension, a problem that we define\nas ordinal bias. To address this issue, we propose two effective video\nmanipulation methods: Action Masking, which masks frames of frequently\nco-occurring actions, and Sequence Shuffling, which randomizes the order of\naction segments. Through comprehensive experiments, we demonstrate that current\nmodels exhibit significant performance drops when confronted with nonstandard\naction sequences, underscoring their vulnerability to ordinal bias. Our\nfindings emphasize the importance of rethinking evaluation strategies and\ndeveloping models capable of generalizing beyond fixed action patterns in\ndiverse instructional videos.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T05:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.06606v1","title":"Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program","summary":"Recent advancements in reward signal usage for Large Language Models (LLMs)\nare remarkable. However, significant challenges exist when transitioning reward\nsignal to the multimodal domain, including labor-intensive annotations,\nover-reliance on one-step rewards, and inadequate evaluation. To address these\nissues, we propose SVIP, a novel approach to train a step-level\nmulti-dimensional Chain-of-Thought~(CoT) reward model automatically. It\ngenerates code for solving visual tasks and transforms the analysis of code\nblocks into the evaluation of CoT step as training samples. Then, we train\nSVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The\nadvantages of SVIP-Reward are evident throughout the entire process of MLLM. We\nalso introduce a benchmark for CoT reward model training and testing.\nExperimental results demonstrate that SVIP-Reward improves MLLM performance\nacross training and inference-time scaling, yielding better results on\nbenchmarks while reducing hallucinations and enhancing reasoning ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.06616v1","title":"Search for Type IL Gamma-ray Bursts: Criterion, Results, Verification\n  and Physical Implication","summary":"As an interesting subclass of gamma-ray burst (GRB), Type IL GRB (such as GRB\n211211A and GRB 230307A) features a long-duration prompt emission but\noriginating from compact binary merger. The \"long duration\" emisison of Type IL\nGRB are dominately composed of the main burst, rather than the extended\nemission, differentiating them from the traditional \"long-short\" GRB (e.g., GRB\n060614). Previous study has reported several Type IL GRBs by visual inspection\nof their light curves. In this work, we established a detailed criterion to\nidentify Type IL GRBs by light curve, and then systematically searched the\narchival \\textit{Fermi}/GBM data with this criterion, resulting in a sample of\n5 type IL GRBs from January 1, 2014 to January 1, 2024, i.e. GRB 230307A, GRB\n211211A, GRB 200914A, GRB 200311A and GRB 170228A. Apart from the light curve\npattern, we find that the temporal and spectral properties of these 5 GRBs also\nsupport this classification. Interestingly, we find that the energy ratio\nbetween extended emission and main emission is almost constant ($\\sim0.7$, with\nsmall scattering) for these GRBs, which have strong implication on the\nmechanism of Type IL burst. We discuss theoretical models to interpret the\nprogenitor, central engine, and extended emission of these Type IL bursts.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T06:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.06620v1","title":"InstantSticker: Realistic Decal Blending via Disentangled Object\n  Reconstruction","summary":"We present InstantSticker, a disentangled reconstruction pipeline based on\nImage-Based Lighting (IBL), which focuses on highly realistic decal blending,\nsimulates stickers attached to the reconstructed surface, and allows for\ninstant editing and real-time rendering. To achieve stereoscopic impression of\nthe decal, we introduce shadow factor into IBL, which can be adaptively\noptimized during training. This allows the shadow brightness of surfaces to be\naccurately decomposed rather than baked into the diffuse color, ensuring that\nthe edited texture exhibits authentic shading. To address the issues of warping\nand blurriness in previous methods, we apply As-Rigid-As-Possible (ARAP)\nparameterization to pre-unfold a specified area of the mesh and use the local\nUV mapping combined with a neural texture map to enhance the ability to express\nhigh-frequency details in that area. For instant editing, we utilize the Disney\nBRDF model, explicitly defining material colors with 3-channel diffuse albedo.\nThis enables instant replacement of albedo RGB values during the editing\nprocess, avoiding the prolonged optimization required in previous approaches.\nIn our experiment, we introduce the Ratio Variance Warping (RVW) metric to\nevaluate the local geometric warping of the decal area. Extensive experimental\nresults demonstrate that our method surpasses previous decal blending methods\nin terms of editing quality, editing speed and rendering speed, achieving the\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06622v1","title":"Quantum neural networks facilitating quantum state classification","summary":"The classification of quantum states into distinct classes poses a\nsignificant challenge. In this study, we address this problem using quantum\nneural networks in combination with a problem-inspired circuit and customised\nas well as predefined ans\\\"{a}tz. To facilitate the resource-efficient quantum\nstate classification, we construct the dataset of quantum states using the\nproposed problem-inspired circuit. The problem-inspired circuit incorporates\ntwo-qubit parameterised unitary gates of varying entangling power, which is\nfurther integrated with the ans\\\"{a}tz, developing an entire quantum neural\nnetwork. To demonstrate the capability of the selected ans\\\"{a}tz, we visualise\nthe mitigated barren plateaus. The designed quantum neural network demonstrates\nthe efficiency in binary and multi-class classification tasks. This work\nestablishes a foundation for the classification of multi-qubit quantum states\nand offers the potential for generalisation to multi-qubit pure quantum states.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-09T06:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.06625v1","title":"Decoupling spin relaxation and chemical kinetics in radical pair\n  magnetism: A master equation study","summary":"A leading theory for the biological effects of low-intensity magnetic fields\nis the spin-chemical Radical Pair Mechanism. This mechanism is best described\nby the master equation for the density matrix of an open quantum system, which\nincludes terms for Hamiltonian evolution, thermal spin relaxation, and chemical\nkinetics. In this study, we have found a solution to this equation for a\nsimplified radical pair model and shown that a significant magnetic effect\noccurs when the following condition is met: $\\gamma H \\tau \\gtrsim 1 + \\kappa\n\\tau$, where $\\gamma$ is the gyromagnetic ratio of the electron, $H$ is the\nmagnetic field strength, $\\tau$ is the relaxation time, and $\\kappa$ is the\nrate of chemical kinetics.","main_category":"physics.bio-ph","categories":"physics.bio-ph,quant-ph","published":"2025-04-09T06:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.06639v1","title":"Dielectronic recombination studies of ions relevant to kilonovae and\n  non-LTE plasma","summary":"This study presents calculations of rate coefficients, resonance strengths,\nand cross sections for the dielectronic recombination (DR) of Y^+, Sr^+, Te^2+,\nand Ce^2+--low-charge ions relevant to kilonovae and non-local thermodynamic\nequilibrium (non-LTE) plasmas. Using relativistic atomic structure methods, we\ncomputed DR rate coefficients under conditions typical of these environments.\nOur results highlight the critical role of low-lying DR resonances in shaping\nrate coefficients at kilonova temperatures (~ 10^4 K) and regulating\ncharge-state distributions. Pronounced near-threshold DR resonances\nsignificantly influence the evolving ionization states and opacity of neutron\nstar merger ejecta. Comparisons with previous studies emphasize the necessity\nof including high-n Rydberg states for accurate DR rate coefficients,\nespecially for complex heavy ions with dense energy levels. Discrepancies with\nexisting datasets underscore the need for refined computational techniques to\nminimize uncertainties. These results provide essential input for interpreting\nspectroscopic observations of neutron star mergers, including James Webb Space\nTelescope data. We also put forward suitable candidates for experimental\nstudies, recognizing the challenges involved in such measurements. The data\npresented here have potential to refine models of heavy-element\nnucleosynthesis, enhance plasma simulation accuracy, and improve non-LTE plasma\nmodeling in astrophysical and laboratory settings.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.atom-ph","published":"2025-04-09T07:30:19Z"}
{"aid":"http://arxiv.org/abs/2504.06652v1","title":"The Shortest Temporal Exploration Problem","summary":"A temporal graph is a graph for which the edge set can change from one time\nstep to the next. This paper considers undirected temporal graphs defined over\nL time steps and connected at each time step. We study the Shortest Temporal\nExploration Problem (STEXP) that, given all the evolution of the graph, asks\nfor a temporal walk that starts at a given vertex, moves over at most one edge\nat each time step, visits all the vertices, takes at most L time steps and\ntraverses the smallest number of edges. . We prove that every constantly\nconnected temporal graph with n vertices can be explored with O(n 1.5 ) edges\ntraversed within O(n 3.5 ) time steps. This result improves the upper bound of\nO(n 2 ) edges for an exploration provided by the upper bound of time steps for\nan exploration which is also O(n 2 ). Morever, we study the case where the\ngraph has a diameter bounded by a parameter k at each time step and we prove\nthat there exists an exploration which takes O(kn 2 ) time steps and traverses\nO(kn) edges. Finally, the case where the underlying graph is a cycle is studied\nand tight bounds are provided on the number of edges traversed in the\nworst-case if L $\\ge$ 2n -3.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T07:42:25Z"}
{"aid":"http://arxiv.org/abs/2504.06655v1","title":"Identifying the Nano Interface Through Phase","summary":"The quantum dots (QD) interface in solution can play significant roles in\nelectron transfer dynamics for quantum dots-sensitized solar cells and\ndifferent biological, environmental, and industrial systems. Here, we predict\nan avenue to identify the contribution of the quantum dots interface created\nstatic electric field on the nonlinear optical response (NLO) due to four-wave\nmixing (FWM), especially for the nanoparticles where surface contribution is\nhigh. We implement a way to disentangle the FWM response in QDs originating\nfrom the three incoming oscillating laser fields (NLOoscillating) and a\ncontribution (NLOstatic) arising from the three oscillating laser fields and\nthe static electric field caused by the interface. Advanced two-dimensional\nelectronic spectroscopy (2DES) employs phase-resolved heterodyne techniques\nwhere FWM response is measured in a particular phase-matched direction, and the\nresponse is distinctively phase sensitive. Theoretical analysis shows\nalteration in the interface can introduce phase variation in the NLOstatic\nsignal, resulting in a distinct change in the 2D-spectra. Our studies establish\na range of ionic strength, which can be important to untwine the usual NLO\nsignal (NLOoscillating) from the NLO (NLOstatic) contributed by the interface\nof quantum dots. This analysis may open up the possibility to study the\ndifferent kinds of dynamics occurring specifically in the interface and also\nwill pave the path towards different ion interactions through phase change in\n2D spectra, and enormous scope will be employing deep learning-assisted phase\nrecognition.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T07:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.06656v1","title":"Machine Learning in the Hunt for Heavy Charged Higgs Bosons at\n  Gamma-Gamma Colliders in the Type III Two Higgs Doublet Model","summary":"We conduct a detailed exploration of charged Higgs boson masses $M_{H^{\\pm}}$\nwithin the range of $100-190~GeV$. This investigation is grounded in the\nbenchmark points that comply with experimental constraints, allowing us to\nsystematically account for uncertainties inherent in the analysis. Our results\nindicate significant production prospects for the process $H^{+}H^{-}\n\\rightarrow \\tau \\nu_{\\tau} \\tau \\nu_{\\tau}$, which could provide essential\ninsights into the properties of $H^{\\pm}$ bosons. By examining these decay\nchannels, we aim to illuminate the interplay between the charged Higgs boson\nand the established Standard Model. The research uses machine learning methods\nlike Boosted Decision Trees (BDT) and Multilayer Perceptrons (MLP), as well as\nLikelihood and LikelihoodD, to improve the identification of heavy charged\nHiggs bosons compared to Standard Model backgrounds at a 3.0 TeV $\\gamma\\gamma$\ncollider with an integrated luminosity of $\\mathcal{L}_{int}=3000~fb^{-1}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T07:46:27Z"}
{"aid":"http://arxiv.org/abs/2504.06663v1","title":"Spectroscopic diagnostics of high-temperature plasma in stellar corona\n  using Fe XXIV--XXVI K-shell lines with XRISM","summary":"The RS CVn type binary star GT Mus was observed during its quiescence using\nthe Resolve X-ray microcalorimeter spectrometer onboard XRISM. The main and\nsatellite lines of the Fe XXIV--XXVI K-shell transitions were resolved for the\nfirst time from stellar sources. We conducted line ratio analysis to\ninvestigate any deviations from collisional onization equilibrium (CIE) and\nMaxwell electron energy distribution with a single-temperature. By using five\ncombinations of direct excitation lines and dielectronic recombination\nsatellite lines in three line complexes (Fe He$\\alpha$, Ly$\\alpha$, and\nHe$\\beta$), we found that the plasma is well characterized by two-temperature\nthermal plasmas with temperatures of 1.7 and 4.3 keV, which is consistent with\na thermal broadening of Fe XXV and the broadband fitting results in the 1.7--10\nkeV band. Other forms of deviation from a single-temperature plasma, such as\ndifferent ionization and electron temperatures or the $\\kappa$ distribution for\nthe electron energy distributions, are not favored, which is reasonable for\nstellar coronae at quiescence. This study demonstrates the utility of the Fe\nK-shell line ratio diagnostics to probe plasma conditions using X-ray\nmicrocalorimeters.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-09T07:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.06668v1","title":"A Novel Nonlinear Fertility Catastrophe Model Based on Thom's\n  Differential Equations of Morphogenesis","summary":"A novel fertility model based on Thom's nonlinear differential equations of\nmorphogenesis is presented, utilizing a three-dimensional catastrophe surface\nto capture the interaction between latent non-catastrophic fertility factors\nand catastrophic shocks. The model incorporates key socioeconomic and\nenvironmental variables and is applicable at macro-, meso-, and\nmicro-demographic levels, addressing global fertility declines, regional\npopulation disparities, and micro-level phenomena such as teenage pregnancies.\nThis approach enables a comprehensive analysis of reproductive health at\naggregate, sub-national, and age-group-specific levels. An agent-based model\nfor teenage pregnancy is described to illustrate how latent factors -- such as\neducation, contraceptive use, and parental guidance -- interact with\ncatastrophic shocks like socioeconomic deprivation, violence, and substance\nabuse. The bifurcation set analysis shows how minor shifts in socioeconomic\nconditions can lead to significant changes in fertility rates, revealing\ncritical points in fertility transitions. By integrating Thom's morphogenesis\nequations with traditional fertility theory, this paper proposes a\ngroundbreaking approach to understanding fertility dynamics, offering valuable\ninsights for the development of public health policies that address both stable\nfertility patterns and abrupt demographic shifts.","main_category":"physics.soc-ph","categories":"physics.soc-ph,math.DS","published":"2025-04-09T08:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.06675v1","title":"Probability Density Geodesics in Image Diffusion Latent Space","summary":"Diffusion models indirectly estimate the probability density over a data\nspace, which can be used to study its structure. In this work, we show that\ngeodesics can be computed in diffusion latent space, where the norm induced by\nthe spatially-varying inner product is inversely proportional to the\nprobability density. In this formulation, a path that traverses a high density\n(that is, probable) region of image latent space is shorter than the equivalent\npath through a low density region. We present algorithms for solving the\nassociated initial and boundary value problems and show how to compute the\nprobability density along the path and the geodesic distance between two\npoints. Using these techniques, we analyze how closely video clips approximate\ngeodesics in a pre-trained image diffusion space. Finally, we demonstrate how\nthese techniques can be applied to training-free image sequence interpolation\nand extrapolation, given a pre-trained image diffusion model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:28:53Z"}
{"aid":"http://arxiv.org/abs/2504.06677v1","title":"Setup-Invariant Augmented Reality for Teaching by Demonstration with\n  Surgical Robots","summary":"Augmented reality (AR) is an effective tool in robotic surgery education as\nit combines exploratory learning with three-dimensional guidance. However,\nexisting AR systems require expert supervision and do not account for\ndifferences in the mentor and mentee robot configurations. To enable novices to\ntrain outside the operating room while receiving expert-informed guidance, we\npresent dV-STEAR: an open-source system that plays back task-aligned expert\ndemonstrations without assuming identical setup joint positions between expert\nand novice. Pose estimation was rigorously quantified, showing a registration\nerror of 3.86 (SD=2.01)mm. In a user study (N=24), dV-STEAR significantly\nimproved novice performance on tasks from the Fundamentals of Laparoscopic\nSurgery. In a single-handed ring-over-wire task, dV-STEAR increased completion\nspeed (p=0.03) and reduced collision time (p=0.01) compared to dry-lab training\nalone. During a pick-and-place task, it improved success rates (p=0.004).\nAcross both tasks, participants using dV-STEAR exhibited significantly more\nbalanced hand use and reported lower frustration levels. This work presents a\nnovel educational tool implemented on the da Vinci Research Kit, demonstrates\nits effectiveness in teaching novices, and builds the foundation for further AR\nintegration into robot-assisted surgery.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.HC,cs.SY,eess.SY","published":"2025-04-09T08:34:25Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06683v1","title":"Hyperparameter Optimisation with Practical Interpretability and\n  Explanation Methods in Probabilistic Curriculum Learning","summary":"Hyperparameter optimisation (HPO) is crucial for achieving strong performance\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\ncurriculum learning strategy designed to improve RL performance by structuring\nthe agent's learning process, yet effective hyperparameter tuning remains\nchallenging and computationally demanding. In this paper, we provide an\nempirical analysis of hyperparameter interactions and their effects on the\nperformance of a PCL algorithm within standard RL tasks, including point-maze\nnavigation and DC motor control. Using the AlgOS framework integrated with\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\nAdditionally, we introduce a novel SHAP-based interpretability approach\ntailored specifically for analysing hyperparameter impacts, offering clear\ninsights into how individual hyperparameters and their interactions influence\nRL performance. Our work contributes practical guidelines and interpretability\ntools that significantly improve the effectiveness and computational\nfeasibility of hyperparameter optimisation in reinforcement learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T08:41:27Z"}
{"aid":"http://arxiv.org/abs/2504.06685v1","title":"Testing Multivariate Conditional Independence Using Exchangeable\n  Sampling and Sufficient Statistics","summary":"We consider testing multivariate conditional independence between a response\nY and a covariate vector X given additional variables Z. We introduce the\nMultivariate Sufficient Statistic Conditional Randomization Test (MS-CRT),\nwhich generates exchangeable copies of X by conditioning on sufficient\nstatistics of P(X|Z). MS-CRT requires no modelling assumption on Y and\naccommodates any test statistics, including those derived from complex\npredictive models. It relaxes the assumptions of standard conditional\nrandomization tests by allowing more unknown parameters in P(X|Z) than the\nsample size. MS-CRT avoids multiplicity corrections and effectively detects\njoint signals, even when individual components of X have only weak effects on Y\n. Our method extends to group selection with false discovery rate control. We\ndevelop efficient implementations for two important cases where P(X,Z) is\neither multivariate normal or belongs to a graphical model. For normal models,\nwe establish the minimax rate optimality. For graphical models, we demonstrate\nthe superior performance of our method compared to existing methods through\ncomprehensive simulations and real-data examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T08:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06691v1","title":"Wake instability of a fixed spherical droplet with a high drop-to-fluid\n  viscosity ratio","summary":"Direct numerical simulations of a uniform flow past a fixed spherical droplet\nare performed to investigate the parameter range within which the axisymmetric\nflow becomes unstable due to an external flow bifurcation. The hydrodynamics is\ngoverned by three dimensionless numbers: the viscosity ratio, $\\mu^\\ast$, and\nthe external and internal Reynolds numbers, $\\Rey^e$ and $\\Rey^i$,\nrespectively. The drop-to-fluid density ratio is related to these parameters as\n$\\rho^\\ast=\\mu^\\ast \\Rey^i/\\Rey^e$. This study focuses on highly viscous\ndroplets with $\\mu^\\ast \\geq 5$, where wake instability is driven by the\nvorticity flux transferred from the droplet surface into the surrounding fluid.\nBy analysing the wake structure, we confirm that the onset of the external\nbifurcation is linked to the tilting of the azimuthal vorticity, $\\omega_\\phi$,\nin the wake and that the bifurcation occurs once the isocontours of\n$\\omega_\\phi$ align nearly perpendicular to the symmetry axis. We propose an\nempirical criterion for predicting the onset of the external bifurcation,\nformulated in terms of the maximum vorticity on the external side of the\ndroplet surface. This criterion is applicable for sufficiently high $\\Rey^i$\nand holds over a wide range of $\\mu^\\ast$ and $\\Rey^e$. Additionally, we\nexamine the bifurcation sequence for two specific external Reynolds numbers,\n$\\Rey^e=300$ and $\\Rey^e=500$, and show that, beyond a critical viscosity\nratio, the axisymmetric wake first transitions to a steady planar-symmetric\nstate before undergoing a secondary Hopf bifurcation. Finally, we highlight the\ninfluence of $\\Rey^i$ on external bifurcation and show that, at moderate\n$\\Rey^i$, wake instability may set in at a lower vorticity threshold than\npredicted by our criterion. These findings provide new insights into the\nexternal flow bifurcation of viscous droplets.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T08:53:06Z"}
{"aid":"http://arxiv.org/abs/2504.06713v1","title":"Almost everywhere convergence of the convolution type Laguerre\n  expansions","summary":"For a fixed d-tuple $\\alpha=(\\alpha_1,...,\\alpha_d)\\in(-1,\\infty)^d$,\nconsider the product space $\\mathbb{R}_+^d:=(0,\\infty)^d$ equipped with\nEuclidean distance $\\arrowvert \\cdot \\arrowvert$ and the measure\n$d\\mu_{\\alpha}(x)=x_1^{2\\alpha_1+1}\\cdot\\cdot\\cdot\nx_{d}^{\\alpha_d}dx_1\\cdot\\cdot\\cdot dx_d$. We consider the Laguerre operator\n$L_{\\alpha}=-\\Delta+\\sum_{i=1}^{d}\\frac{2\\alpha_j+1}{x_j}\\frac{d}{dx_j}+\\arrowvert\nx\\arrowvert^2$ which is a compact, positive, self-adjoint operator on\n$L^2(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$. In this paper, we study almost\neverywhere convergence of the Bochner-Riesz means associated with $L_\\alpha$\nwhich is defined by\n$S_R^{\\lambda}(L_\\alpha)f(x)=\\sum_{n=0}^{\\infty}(1-\\frac{e_n}{R^2})_{+}^{\\lambda}P_nf(x)$.\nHere $e_n$ is n-th eigenvalue of $L_{\\alpha}$, and $P_nf(x)$ is the n-th\nLaguerre spectral projection operator. This corresponds to the convolution-type\nLaguerre expansions introduced in Thangavelu's lecture \\cite{TS3}. For $2\\leq\np<\\infty$, we prove that $$\\lim_{R\\rightarrow\\infty}\nS_R^{\\lambda}(L_\\alpha)f=f\\,\\,\\,\\,-a.e.$$ for all $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$, provided that\n$\\lambda>\\lambda(\\alpha,p)/2$, where\n$\\lambda(\\alpha,p)=\\max\\{2(\\arrowvert\\alpha\\arrowvert_1+d)(1/2-1/p)-1/2,0\\}$,\nand $\\arrowvert\\alpha\\arrowvert_1:=\\sum_{j=1}^{d}\\alpha_{j}$. Conversely, if\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d>1$, we will show the convergence generally\nfails if $\\lambda<\\lambda(\\alpha,p)/2$ in the sense that there is an $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ for\n$(4\\arrowvert\\alpha\\arrowvert_{1}+4d)/(2\\arrowvert\\alpha\\arrowvert_{1}+2d-1)<\np$ such that the convergence fails. When\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d\\leq1$, our results show that a.e.\nconvergence holds for $f\\in L^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ with $p\\geq\n2$ whenever $\\lambda>0$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T09:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.06731v1","title":"FJ-MM: The Friedkin-Johnsen Opinion Dynamics Model with Memory and\n  Higher-Order Neighbors","summary":"The Friedkin-Johnsen (FJ) model has been extensively explored and validated,\nspanning applications in social science, systems and control, game theory, and\nalgorithmic research. In this paper, we introduce an advanced generalization of\nthe FJ model, termed FJ-MM which incorporates both memory effects and multi-hop\n(higher-order neighbor) influence. This formulation allows agents to naturally\nincorporate both current and previous opinions at each iteration stage. Our\nnumerical results demonstrate that incorporating memory and multi-hop influence\nsignificantly reshapes the opinion landscape; for example, the final opinion\nprofile can exhibit reduced polarization. We analyze the stability and\nequilibrium properties of the FJ-MM model, showing that these properties can be\nreduced to those of a comparison model--namely, the standard FJ model with a\nmodified influence matrix. This reduction enables us to leverage established\nstability results from FJ dynamics. Additionally, we examine the convergence\nrate of the FJ-MM model and demonstrate that, as can be expected, the time lags\nintroduced by memory and higher-order neighbor influences result in slower\nconvergence.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC,physics.soc-ph","published":"2025-04-09T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.06738v1","title":"EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through\n  an Encoder-Decoder Architecture","summary":"In this paper, we propose EDIT (Encoder-Decoder Image Transformer), a novel\narchitecture designed to mitigate the attention sink phenomenon observed in\nVision Transformer models. Attention sink occurs when an excessive amount of\nattention is allocated to the [CLS] token, distorting the model's ability to\neffectively process image patches. To address this, we introduce a\nlayer-aligned encoder-decoder architecture, where the encoder utilizes\nself-attention to process image patches, while the decoder uses cross-attention\nto focus on the [CLS] token. Unlike traditional encoder-decoder framework,\nwhere the decoder depends solely on high-level encoder representations, EDIT\nallows the decoder to extract information starting from low-level features,\nprogressively refining the representation layer by layer. EDIT is naturally\ninterpretable demonstrated through sequential attention maps, illustrating the\nrefined, layer-by-layer focus on key image features. Experiments on ImageNet-1k\nand ImageNet-21k, along with transfer learning tasks, show that EDIT achieves\nconsistent performance improvements over DeiT3 models. These results highlight\nthe effectiveness of EDIT's design in addressing attention sink and improving\nvisual feature extraction.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T09:51:41Z"}
{"aid":"http://arxiv.org/abs/2504.06741v1","title":"Large Scale Supervised Pretraining For Traumatic Brain Injury\n  Segmentation","summary":"The segmentation of lesions in Moderate to Severe Traumatic Brain Injury\n(msTBI) presents a significant challenge in neuroimaging due to the diverse\ncharacteristics of these lesions, which vary in size, shape, and distribution\nacross brain regions and tissue types. This heterogeneity complicates\ntraditional image processing techniques, resulting in critical errors in tasks\nsuch as image registration and brain parcellation. To address these challenges,\nthe AIMS-TBI Segmentation Challenge 2024 aims to advance innovative\nsegmentation algorithms specifically designed for T1-weighted MRI data, the\nmost widely utilized imaging modality in clinical practice. Our proposed\nsolution leverages a large-scale multi-dataset supervised pretraining approach\ninspired by the MultiTalent method. We train a Resenc L network on a\ncomprehensive collection of datasets covering various anatomical and\npathological structures, which equips the model with a robust understanding of\nbrain anatomy and pathology. Following this, the model is fine-tuned on\nmsTBI-specific data to optimize its performance for the unique characteristics\nof T1-weighted MRI scans and outperforms the baseline without pretraining up to\n2 Dice points.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T09:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06750v1","title":"Robust Capacity Expansion Modelling for Renewable Energy Systems under\n  Weather and Demand Uncertainty","summary":"Future greenhouse gas neutral energy systems will be dominated by variable\nrenewable energy technologies. However, renewable electricity generation from\nwind and solar technologies, as well as electricity demand, varies with the\nweather. This work addresses the problem of determining optimal capacities for\nrenewable technologies in energy systems that ensure sufficient electricity\nsupply when dealing with multi-year time-series data. An iterative algorithm is\nproposed that starts by optimising an arbitrary starting time-series, followed\nby adding additional constraints and reoptimising the modified optimisation\nproblem until sufficient energy supply is provided for all time--series, i.e.\nthe solution is robust to weather and demand variations. This is evaluated in a\ncomputational study on a German energy system model.The results show that the\niterative algorithm finds robust solutions for an increase of 2-2.5% in total\nannual cost for a simplified model in gurobipy and 2.9% for a model built in\nthe model framework ETHOS.FINE. Testing the feasibility for non robust\nsolutions showed that supply gaps occurred in at least some of the remaining\nyears. Based on the results of this work, ensuring feasibility within an energy\nsystem model for multiple time-series boils down to two factors: ensuring\nsufficient back-up capacity to overcome periods of high demand combined with\nlow electricity generation from wind and photovoltaic, and enforcing sufficient\ntotal annual electricity generation. Our proposed open source iterative\nalgorithm is able to ensure this. For general modelling, it is recommended to\ncheck for systematic effects of different years' time--series on energy system\nmodels especially for wind, but also for photovoltaics, include dark lull and\ncold period effects on generation and demand in time--series, and assess the\nfeasibility of energy system models using different time-series.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,I.6","published":"2025-04-09T10:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.06755v1","title":"FANeRV: Frequency Separation and Augmentation based Neural\n  Representation for Video","summary":"Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block.This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06778v1","title":"Controllable Automatic Foley Artist","summary":"Foley is a key element in video production, refers to the process of adding\nan audio signal to a silent video while ensuring semantic and temporal\nalignment. In recent years, the rise of personalized content creation and\nadvancements in automatic video-to-audio models have increased the demand for\ngreater user control in the process. One possible approach is to incorporate\ntext to guide audio generation. While supported by existing methods, challenges\nremain in ensuring compatibility between modalities, particularly when the text\nintroduces additional information or contradicts the sounds naturally inferred\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\nArtist) a video-and-text-to-audio model that generates semantically and\ntemporally aligned audio for a given video, guided by text input. CAFA is built\nupon a text-to-audio model and integrates video information through a modality\nadapter mechanism. By incorporating text, users can refine semantic details and\nintroduce creative variations, guiding the audio synthesis beyond the expected\nvideo contextual cues. Experiments show that besides its superior quality in\nterms of semantic alignment and audio-visual synchronization the proposed\nmethod enable high textual controllability as demonstrated in subjective and\nobjective evaluations.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-09T10:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.06784v1","title":"Modified gravity realizations of quintom dark energy after DESI DR2","summary":"We investigate the realization of quintom scenario for dynamical dark energy\nwithin modified gravity theories that can efficiently fit the recent\nobservational datasets. Starting from a general effective field theory\nformulation of dark energy in metric-affine geometry, we derive the background\naction in unitary gauge and we demonstrate how both $f(T)$ and $f(Q)$ gravity\ncan naturally realize quintom behavior through appropriate forms and parameter\nchoices. Additionally, using the Gaussian process reconstruction of the latest\nDESI DR2 BAO data combined with SNe and CMB observations, we extract the\nreconstructed dark-energy equation-of-state parameter, showing that it exhibits\nquintom-type evolution, crossing the phantom divide from below. Moreover,\nthrough detailed parameter estimations and application of information criteria,\nwe compare the model with the quadratic one. Our results show that, due to its\nrich structure, modified gravity stands as one of the main candidates for the\nrealization of the data-favoured dynamical dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T11:17:20Z"}
{"aid":"http://arxiv.org/abs/2504.06787v1","title":"Communicating complex statistical models to a public health audience:\n  translating science into action with the FARSI approach","summary":"Background. Effectively communicating complex statistical model outputs is a\nmajor challenge in public health. This study introduces the FARSI approach\n(Fast, Accessible, Reliable, Secure, Informative) as a framework to enhance the\ntranslation of intricate statistical findings into actionable insights for\npolicymakers and stakeholders. We apply this framework in a real-world case\nstudy on chronic disease monitoring in Italy.\n  Methods. The FARSI framework outlines key principles for developing\nuser-friendly tools that improve the translation of statistical results. We\napplied these principles to create an open-access web application using R\nShiny, designed to communicate chronic disease prevalence estimates from a\nBayesian spatio-temporal logistic model. The case study highlights the\nimportance of an intuitive design for fast accessibility, validated data and\nexpert feedback for reliability, aggregated data for security, and insights\ninto prevalence population subgroups, which were previously unobservable, for\ninformativeness.\n  Results. The web application enables stakeholders to explore disease\nprevalence across populations and geographical area through dynamic\nvisualizations. It facilitates public health monitoring by, for instance,\nidentifying disparities at the local level and assessing risk factors such as\nsmoking. Its user-friendly interface enhances accessibility, making statistical\nfindings more actionable. Conclusions. The FARSI framework provides a\nstructured approach to improving the communication of complex research\nfindings. By making statistical models more accessible and interpretable, it\nsupports evidence-based decision-making in public health and increases the\nsocietal impact of research.","main_category":"stat.OT","categories":"stat.OT,stat.AP,stat.ME","published":"2025-04-09T11:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.06802v1","title":"The ALMA-ATOMS survey: A sample of weak hot core candidates identified\n  through line stacking","summary":"Hot cores represent critical astrophysical environments for high-mass star\nformation, distinguished by their rich spectra of organic molecular emission\nlines. We aim to utilize high-angular resolution molecular line data from ALMA\nto identify hot cores, with a particular focus on weak-emission candidates, and\nto provide one of the largest samples of hot core candidates. We propose to use\nspectral stacking and imaging techniques of complex organic molecules (COMs) in\nthe ALMA-ATOMS survey, including line identification & weights, segmentation of\nline datacubes, resampling, stacking and normalization, moment 0 maps, and data\nanalysis, to search for hot core candidates. We classify cores with dense\nemission of CH3OH and at least one molecule from the other six molecules as hot\ncore candidates. In addition to the existing sample of 60 strong hot cores from\nthe ALMA-ATOMS survey, we have detected 40 new weak candidates through\nstacking. All hot core candidates display compact emission from at least one of\nthe other six COM species. For the strong sample, the stacking method provides\nmolecular column density estimates that are consistent with previous fitting\nresults. For the newly identified weak candidates, all species except CH3CHO\nshow compact emission in the stacked image, which cannot be fully resolved\nspatially. These weak candidates exhibit column densities of COMs that are\napproximately one order of magnitude lower than those of the strong sample. The\nentire hot core sample, including the weak candidates, reveals tight\ncorrelations between the compact emission of CH3OH and other COM species,\nsuggesting they may share a similar chemical environment for COMs, with CH3OH\npotentially acting as a precursor for other COMs. The molecular line stacking\ntechnique is used to identify hot core candidates in this work, leading to the\nidentification of 40 new hot core candidates.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T11:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.06803v1","title":"DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation","summary":"Diffusion Transformer (DiT), an emerging diffusion model for visual\ngeneration, has demonstrated superior performance but suffers from substantial\ncomputational costs. Our investigations reveal that these costs primarily stem\nfrom the \\emph{static} inference paradigm, which inevitably introduces\nredundant computation in certain \\emph{diffusion timesteps} and \\emph{spatial\nregions}. To overcome this inefficiency, we propose \\textbf{Dy}namic\n\\textbf{Di}ffusion \\textbf{T}ransformer (DyDiT), an architecture that\n\\emph{dynamically} adjusts its computation along both \\emph{timestep} and\n\\emph{spatial} dimensions. Specifically, we introduce a \\emph{Timestep-wise\nDynamic Width} (TDW) approach that adapts model width conditioned on the\ngeneration timesteps. In addition, we design a \\emph{Spatial-wise Dynamic\nToken} (SDT) strategy to avoid redundant computation at unnecessary spatial\nlocations. TDW and SDT can be seamlessly integrated into DiT and significantly\naccelerates the generation process. Building on these designs, we further\nenhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with\nflow matching-based generation, enhancing its versatility. Furthermore, we\nenhance DyDiT to tackle more complex visual generation tasks, including video\ngeneration and text-to-image generation, thereby broadening its real-world\napplications. Finally, to address the high cost of full fine-tuning and\ndemocratize technology access, we investigate the feasibility of training DyDiT\nin a parameter-efficient manner and introduce timestep-based dynamic LoRA\n(TD-LoRA). Extensive experiments on diverse visual generation models, including\nDiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:48:37Z"}
{"aid":"http://arxiv.org/abs/2504.06822v1","title":"Investigation of triply heavy spin-3/2 baryons in their ground and\n  excited states","summary":"We calculate the masses and residues of triply heavy baryons with spin-3/2,\nincluding $\\Omega^*_{ccc}$, $\\Omega^*_{ccb}$, $\\Omega^*_{bbc}$ and\n$\\Omega^*_{bbb}$, using the QCD sum rules method. Our calculations primarily\nfocus on obtaining the masses of the first three resonances, that is, the\nground state (1S), the first orbital excited state (1P), and the first radial\nexcited state (2S), for the mentioned baryons. We additionally determine the\nresidues of these baryons, which serve as key parameters for studying their\npossible decay channels and interactions with other particles. To achieve\nhigher accuracy compared to previous studies, we consider nonperturbative\noperators up to eight mass dimensions. We present our calculated outcomes in\ntwo distinct energy schemes, referred to as pole and $\\mathrm{\\overline{MS}}$.\nGiven the absence of experimental data for these states, we compare our results\nwith previous theoretical calculations that are reported in relevant studies\nemploying various approaches. These results may provide valuable insights for\nexperimental groups searching for the triply heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat","published":"2025-04-09T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.06832v1","title":"On a Characterization of Spartan Graphs","summary":"The eternal vertex cover game is played between an attacker and a defender on\nan undirected graph $G$. The defender identifies $k$ vertices to position\nguards on to begin with. The attacker, on their turn, attacks an edge $e$, and\nthe defender must move a guard along $e$ to defend the attack. The defender may\nmove other guards as well, under the constraint that every guard moves at most\nonce and to a neighboring vertex. The smallest number of guards required to\ndefend attacks forever is called the eternal vertex cover number of $G$,\ndenoted $evc(G)$.\n  For any graph $G$, $evc(G)$ is at least the vertex cover number of $G$,\ndenoted $mvc(G)$. A graph is Spartan if $evc(G) = mvc(G)$. It is known that a\nbipartite graph is Spartan if and only if every edge belongs to a perfect\nmatching. We show that the only K\\\"onig graphs that are Spartan are the\nbipartite Spartan graphs. We also give new lower bounds for $evc(G)$,\ngeneralizing a known lower bound based on cut vertices. We finally show a new\nmatching-based characterization of all Spartan graphs.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-04-09T12:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.06834v1","title":"Green building blocks reveal the complex anatomy of climate change\n  mitigation technologies","summary":"Climate-change mitigating innovation is considered essential for the world's\ntransition toward a sustainable global economy. To guide this transition,\nintegrated assessment models map sectoral emissions reduction targets into\nlong-term trajectories towards carbon neutrality at the macro-level, while\ndetailed engineering studies at the micro-level develop concrete\ncarbon-mitigation technologies tailored to individual industries. However, we\nlack a meso-level understanding of how solutions connect across technological\ndomains. Building on the notion that innovating often entails combining\nexisting technologies in new ways, we identify Green Building Blocks (GBBs):\nmodules of technologies that can be added to nongreen technologies to mitigate\ntheir climate-change impact. Using natural language processing and\ndimensionality reduction techniques, we show how GBBs can be extracted from\nlarge-scale patent data. Next, we describe the anatomy of the green transition\nas a network that connects nongreen technologies to GBBs. This network has a\nnontrivial structure: whereas some nongreen technologies can connect to various\nGBBs, opening up a variety of ways to mitigate their impact on the global\nclimate, other nongreen technologies only connect to a single GBB. Similarly,\nsome GBBs are general purpose technologies that can reduce green house gases in\na vast range of applications, whereas others are tailored to specific use\ncases. Furthermore, GBBs prove predictive of the green technologies that firms\ndevelop, allowing us to map the green capabilities of firms not in terms of the\nspecific green technological solutions they invent, but in terms of their\ncapacity to develop broader classes of solutions with the GBBs they possess.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SI","published":"2025-04-09T12:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.06840v1","title":"Interference Mitigation and Spectral Efficiency Enhancement in a\n  Multi-BD Symbiotic Radio","summary":"This study presents a framework designed to mitigate direct-link interference\n(DLI) and inter-backscatter device interference (IBDI) in multi-backscatter\northogonal frequency division multiplexing (OFDM)-based symbiotic radio (SR)\nsystems. The framework employs OFDM signal designs with strategic allocation of\nnull subcarriers and incorporates two backscatter modulation techniques: on-off\nfrequency shift keying (OFSK) and multiple frequency shift keying (MFSK) for\nsymbiotic backscatter communication (SBC). Additionally, we propose\nFully-Orthogonal and Semi-Orthogonal multiple access schemes to facilitate SBC\nalongside primary communication. The Fully-Orthogonal scheme maintains\northogonality between direct link and SBC signals, thereby ensuring\ninterference-free SBC, albeit at a reduced spectral efficiency. In contrast,\nthe Semi-Orthogonal schemes eliminate IBDI but permit partial DLI, striking a\nbalance between reliability and spectral efficiency. To address the partial DLI\ninherent in Semi-Orthogonal schemes, successive interference cancellation (SIC)\nis employed at the receiver, enhancing SBC reliability. To tackle channel\nestimation challenges in SBC within the SR system, we implement non-coherent\ndetection techniques at the receiver. The performance of the proposed system is\nevaluated based on average bit error rate (BER) and sum-rate metrics,\ndemonstrating the effectiveness of our schemes. We provide analytical results\nfor the system's detection performance under both proposed modulation\ntechniques and multiple access schemes, which are subsequently validated\nthrough extensive simulations. These simulations indicate a notable error-rate\nreduction of up to $10^{-3}$ at $20$ dB with the Fully-Orthogonal scheme with\nMFSK.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T12:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.06845v1","title":"Probability density function for dispersion measure of fast radio burst\n  from extragalactic medium","summary":"Fast Radio Bursts (FRBs) have emerged as powerful probes in cosmology. An\noptimized method for extracting the cosmic baryon density from localized FRBs,\nbased on maximizing the joint likelihood function of the extragalactic\ndispersion measure ($\\mathrm{DM}_{\\mathrm{ext}}$), was proposed by Macquart et\nal. [Nature 581, 391 (2020)]. In this Letter, we identify a crucial term that\nwas omitted in their derivation of the probability density function (PDF) for\n$\\mathrm{DM}_{\\mathrm{ext}}$. Using simulated FRB data, we demonstrate that\nneglecting this term leads to a systematic bias in the inferred cosmic baryon\ndensity, with deviations exceeding the $1\\sigma$ confidence level. This\nhighlights the importance of the missing term for the reliable cosmological\napplication of FRBs. Furthermore, employing a sample of 88 real localized FRBs,\nwe find that the baryon density derived using the original PDF by Macquart et\nal. is inconsistent with the Planck 2018 CMB data, while our corrected PDF\nyields a result in excellent agreement. We conclude that the omitted term is\nessential and must be included in order to obtain accurate cosmological\nconstraints from FRB observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T13:02:33Z"}
{"aid":"http://arxiv.org/abs/2504.06846v1","title":"Solid-State Maser with Microwatt Output Power at Moderate Cryogenic\n  Temperatures","summary":"Solid-state masers are uniquely positioned to serve as ultra-low phase noise\nmicrowave sources due to their exceptionally low noise temperatures. However,\ntheir practical application has been historically limited by low output power\nand the need for deep cryogenic cooling. In this work, we present a novel\ndesign for a continuous-wave diamond-based maser oscillator operating at about\n14.5 GHz and moderate cryogenic temperatures (about 180 K), achieving output\npower levels exceeding -30 dBm (1 microW). This performance represents a\ntwo-orders-of-magnitude improvement over previous diamond or ruby-based maser\noscillators.Our system integrates a high-Q (about 2460) compact metallic\nmicrowave cavity with optically pumped (111)-oriented NV-rich diamond crystals.\nThe cavity supports efficient light coupling and thermal dissipation, enabling\nsustained high-power optical excitation (>1 W) using cost-effective green LEDs.\nWe demonstrate stable maser operation with good spectral quality and validate\nits output through both frequency- and time-domain analysis with phase noise\ndata when operated in \"free running\" mode. Additionally, we provide phase noise\nestimations based on Leeson's model and show that, when coupled to a high-Q\nexternal resonator, such masers could approach thermally limited phase noise\nlevels. These predictions suggest strong potential for diamond masers to\noutperform traditional ruby-based or similar maser systems, especially given\ntheir ability to operate at higher temperatures using rugged, He-free Stirling\ncoolers. Despite current limitations related to frequency stability and jitter,\nthis work establishes diamond-based masers as promising candidates for\nnext-generation ultra-low phase noise microwave oscillators. Further\nengineering optimization - particularly in field stability, thermal regulation,\nand feedback locking - will be key to unlocking their full potential.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-09T13:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.06852v1","title":"Quantum controlling and the topological properties of the magnon\n  photo-transport in two-dimensional collinear ferromagnet","summary":"In our work, we study magnon transport induced by light through\nAharonov-Casher (AC) effect, including magnon spin photocurrent (MSPC) and\nmagnon energy photocurrent (MEPC). Firstly, we regard the effect of the\nelectric field on the magnon through the AC effect as a perturbation. Then we\nderived the expressions of MSPC and MEPC in two-dimensional collinear\nferromagnetic system. And we apply our theory to the two-dimension\nferromagnetic Hexagonal and Kagome lattice. We find that the optical frequency\nand the relaxation time of the material can be used to control the\nphoto-transport of magnons. In addition, under the condition of low light\nfrequncy and infinite relaxation time, the longitudinal magnon photo-transport\nis related to the topological property of the magnon system.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.06872v1","title":"More connection, less community: network formation and local public\n  goods provision","summary":"This paper presents a model of network formation and public goods provision\nin local communities. Here, networks can sustain public good provision by\nspreading information about people's behaviour. I find a critical threshold in\nnetwork connectedness at which public good provision drops sharply, even though\nagents are highly heterogeneous. Technology change can tear a community's\nsocial fabric by pushing high-skilled workers to withdraw from their local\ncommunity. This can help explain rising resentment toward perceived ``elites''\n-- their withdrawal actively harms those left behind. Moreover, well-meaning\npolicies that upskill workers can make them worse off by reducing network\nconnectedness.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T13:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06886v1","title":"High-order fluctuations of temperature in hot QCD matter","summary":"We study the temperature fluctuations in hot quantum chromodynamics (QCD)\nmatter. A new thermodynamic state function is introduced to describe the mean\ntransverse momentum fluctuations of charged particles in heavy-ion collisions,\nenabling analytic expressions for the temperature fluctuations of different\norders. This formalism is applied to the QCD thermodynamics described by a 2+1\nflavor low energy effective field theory within the functional renormalization\ngroup approach. It is found that the temperature fluctuations are suppressed\nremarkably as the matter is evolved from the phase of hadron resonance gas to\nthe quark-gluon plasma phase with increasing temperature or baryon chemical\npotential, which is attributed to the significant increase of the heat capacity\nof matter. Furthermore, the same mechanism leads to a negative skewness in the\ntemperature fluctuations.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-09T13:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.06890v1","title":"Combining high-contrast imaging with high-resolution spectroscopy:\n  Actual on-sky MIRI/MRS results compared to expectations","summary":"CONTEXT: Combining high-contrast imaging with high-resolution spectroscopy\noffers a powerful way to detect and characterize exoplanets around nearby\nstars, despite challenges linked to their faintness. Instruments like\nVLT/SPHERE are state of the art in high-contrast imaging, but their spectral\nresolution (R=50) limits them to basic characterization of close companions.\nThese systems can detect planets down to 5-10 Mjup at 10 AU from their stars.\nDetection limits are mainly constrained by speckle noise, which dominates over\nphoton and detector noise at short separations, even with advanced differential\nimaging. Space-based high-contrast imaging is also limited by image stability.\nSpeckle noise can, however, be mitigated through molecular mapping, a technique\nthat leverages high-resolution spectroscopic data.\n  AIMS: We aim to predict detection limits in spectro-imaging after molecular\nmapping, analyzing how photon and detector noise propagate and comparing\npredictions with real data to assess performance losses from instrumental\neffects. We also propose mitigation strategies and validate our model using\nobservations.\n  METHODS: We analyzed JWST/MIRI/MRS data with FastCurves, an numerical tool,\nand compared results to outputs from the MIRI simulator. We also applied\nprincipal component analysis (PCA) to identify and isolate systematic effects,\nwith and without molecular mapping.\n  RESULTS: We studied various systematic effects and their impacts on signal\nand noise. PCA helped highlight and reduce straylight, fringes, and aliasing.\nWe further compared observed and modeled companion spectra.\n  CONCLUSIONS: FastCurves was improved to account for systematics and validated\nwith real data. In high-flux regimes, systematics impose contrast limits even\nwith molecular mapping. Our approach could benefit other instruments and inform\nthe planning of future facilities like ELT/ANDES and ELT/PCS.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-04-09T13:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.06891v1","title":"Helioseismic inference of the solar radiative opacity","summary":"The Sun is the most studied of all stars, and thus constitutes a benchmark\nfor stellar models. However, our vision of the Sun is still incomplete, as\nillustrated by the current debate on its chemical composition. The problem\nreaches far beyond chemical abundances and is intimately linked to microscopic\nand macroscopic physical ingredients of solar models such as radiative opacity,\nfor which experimental results have been recently measured that still await\ntheoretical explanations. We present opacity profiles derived from helioseismic\ninferences and compare them with detailed theoretical computations of\nindividual element contributions using three different opacity computation\ncodes, in a complementary way to experimental results. We find that our seismic\nopacity is about 10% higher than theoretical values used in current solar\nmodels around 2 million degrees, but lower by 35% than some recent available\ntheoretical values. Using the Sun as a laboratory of fundamental physics, we\nshow that quantitative comparisons between various opacity tables are required\nto understand the origin of the discrepancies between reported helioseismic,\ntheoretical and experimental opacity values.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-09T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.06910v1","title":"Identifying Aspects in Peer Reviews","summary":"Peer review is central to academic publishing, but the growing volume of\nsubmissions is straining the process. This motivates the development of\ncomputational approaches to support peer review. While each review is tailored\nto a specific paper, reviewers often make assessments according to certain\naspects such as Novelty, which reflect the values of the research community.\nThis alignment creates opportunities for standardizing the reviewing process,\nimproving quality control, and enabling computational support. While prior work\nhas demonstrated the potential of aspect analysis for peer review assistance,\nthe notion of aspect remains poorly formalized. Existing approaches often\nderive aspect sets from review forms and guidelines of major NLP venues, yet\ndata-driven methods for aspect identification are largely underexplored. To\naddress this gap, our work takes a bottom-up approach: we propose an\noperational definition of aspect and develop a data-driven schema for deriving\nfine-grained aspects from a corpus of peer reviews. We introduce a dataset of\npeer reviews augmented with aspects and show how it can be used for\ncommunity-level review analysis. We further show how the choice of aspects can\nimpact downstream applications, such as LLM-generated review detection. Our\nresults lay a foundation for a principled and data-driven investigation of\nreview aspects, and pave the path for new applications of NLP to support peer\nreview.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T14:14:42Z"}
{"aid":"http://arxiv.org/abs/2504.06920v1","title":"S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in\n  Remote Sensing Applications","summary":"We introduce the S-EO dataset: a large-scale, high-resolution dataset,\ndesigned to advance geometry-aware shadow detection. Collected from diverse\npublic-domain sources, including challenge datasets and government providers\nsuch as USGS, our dataset comprises 702 georeferenced tiles across the USA,\neach covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3\npansharpened RGB images, panchromatic images, and a ground-truth DSM of the\narea obtained from LiDAR scans. For each image, we provide a shadow mask\nderived from geometry and sun position, a vegetation mask based on the NDVI\nindex, and a bundle-adjusted RPC model. With approximately 20,000 images, the\nS-EO dataset establishes a new public resource for shadow detection in remote\nsensing imagery and its applications to 3D reconstruction. To demonstrate the\ndataset's impact, we train and evaluate a shadow detector, showcasing its\nability to generalize, even to aerial images. Finally, we extend EO-NeRF - a\nstate-of-the-art NeRF approach for satellite imagery - to leverage our shadow\npredictions for improved 3D reconstructions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:25:35Z"}
{"aid":"http://arxiv.org/abs/2504.06921v1","title":"Leveraging Anatomical Priors for Automated Pancreas Segmentation on\n  Abdominal CT","summary":"An accurate segmentation of the pancreas on CT is crucial to identify\npancreatic pathologies and extract imaging-based biomarkers. However, prior\nresearch on pancreas segmentation has primarily focused on modifying the\nsegmentation model architecture or utilizing pre- and post-processing\ntechniques. In this article, we investigate the utility of anatomical priors to\nenhance the segmentation performance of the pancreas. Two 3D full-resolution\nnnU-Net models were trained, one with 8 refined labels from the public PANORAMA\ndataset, and another that combined them with labels derived from the public\nTotalSegmentator (TS) tool. The addition of anatomical priors resulted in a 6\\%\nincrease in Dice score ($p < .001$) and a 36.5 mm decrease in Hausdorff\ndistance for pancreas segmentation ($p < .001$). Moreover, the pancreas was\nalways detected when anatomy priors were used, whereas there were 8 instances\nof failed detections without their use. The use of anatomy priors shows promise\nfor pancreas segmentation and subsequent derivation of imaging biomarkers.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.06924v1","title":"Longitudinal Assessment of Lung Lesion Burden in CT","summary":"In the U.S., lung cancer is the second major cause of death. Early detection\nof suspicious lung nodules is crucial for patient treatment planning,\nmanagement, and improving outcomes. Many approaches for lung nodule\nsegmentation and volumetric analysis have been proposed, but few have looked at\nlongitudinal changes in total lung tumor burden. In this work, we trained two\n3D models (nnUNet) with and without anatomical priors to automatically segment\nlung lesions and quantified total lesion burden for each patient. The 3D model\nwithout priors significantly outperformed ($p < .001$) the model trained with\nanatomy priors. For detecting clinically significant lesions $>$ 1cm, a\nprecision of 71.3\\%, sensitivity of 68.4\\%, and F1-score of 69.8\\% was\nachieved. For segmentation, a Dice score of 77.1 $\\pm$ 20.3 and Hausdorff\ndistance error of 11.7 $\\pm$ 24.1 mm was obtained. The median lesion burden was\n6.4 cc (IQR: 2.1, 18.1) and the median volume difference between manual and\nautomated measurements was 0.02 cc (IQR: -2.8, 1.2). Agreements were also\nevaluated with linear regression and Bland-Altman plots. The proposed approach\ncan produce a personalized evaluation of the total tumor burden for a patient\nand facilitate interval change tracking over time.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:30:43Z"}
{"aid":"http://arxiv.org/abs/2504.06940v1","title":"More-efficient Quantum Multivariate Mean Value Estimator from\n  Generalized Grover Gate","summary":"In this work, we present an efficient algorithm for multivariate mean value\nestimation. Our algorithm outperforms previous work by polylog factors and\nnearly saturates the known lower bound. We find an algorithm that uses\n$O\\left(n \\log \\frac{d}{\\delta}\\right)$ to achieve precision\n$\\frac{\\sqrt{\\text{tr } \\Sigma}}{n}$ in $\\lVert \\rVert_\\infty$ norm and hence\n$\\frac{\\sqrt{d \\text{ tr } \\Sigma}}{n}$ in $\\lVert \\rVert_2$ norm, where $d$ is\nthe dimension and $\\Sigma$ is the covariance matrix. We also presented another\nalgorithm that uses smaller memory but costs an extra $d^\\frac{1}{4}$ in\ncomplexity. The idea originates from the previous observations that the Grover\ngate, when generalized to allow for arbitrary phases instead of $\\pm 1$,\nbecomes a good mean value estimator in some mathematical notion. The only\nremaining $\\log \\frac{d}{\\delta}$ as opposed to $\\log \\frac{1}{\\delta}$ is due\nto the phase estimation primitive we employed, which so far is the only major\nknown method to tackle the problem. Our results demonstrates that our\nmethodology with generalized Grover gate can be used locate the optimal\nalgorithm, without polylog overhead, for different taks relating to mean value\nestimation.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-09T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.06947v1","title":"RuOpinionNE-2024: Extraction of Opinion Tuples from Russian News Texts","summary":"In this paper, we introduce the Dialogue Evaluation shared task on extraction\nof structured opinions from Russian news texts. The task of the contest is to\nextract opinion tuples for a given sentence; the tuples are composed of a\nsentiment holder, its target, an expression and sentiment from the holder to\nthe target. In total, the task received more than 100 submissions. The\nparticipants experimented mainly with large language models in zero-shot,\nfew-shot and fine-tuning formats. The best result on the test set was obtained\nwith fine-tuning of a large language model. We also compared 30 prompts and 11\nopen source language models with 3-32 billion parameters in the 1-shot and\n10-shot settings and found the best models and prompts.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-09T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.06953v1","title":"Exact Ground States of Two Dimensional $\\pm J$ Spin Glasses","summary":"We derive exact analytical expressions for the ground-state energy and\nentropy of the two-dimensional $\\pm J$ Ising spin glass, uncovering a nested\nhierarchy of frustrations. Each level in this hierarchy contributes through the\nkernel and pseudo-determinant of effective operators, capturing the energy and\nentropy, respectively. At leading order, the structure coincides with geometric\nplaquette frustrations, while subleading corrections arise from magnetic\nadjacency matrices defined on percolated clusters in the dual lattice. Our\nresults, supported by numerical simulations, provide a systematic framework for\nanalyzing spin-glass ground states and offer new insight into glass order in\nfinite dimensions.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-09T14:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.06955v1","title":"Parametric Reachable Sets Via Controlled Dynamical Embeddings","summary":"In this work, we propose a new framework for reachable set computation\nthrough continuous evolution of a set of parameters and offsets which define a\nparametope, through the intersection of constraints. This results in a\ndynamical approach towards nonlinear reachability analysis: a single trajectory\nof an embedding system provides a parametope reachable set for the original\nsystem, and uncertainties are accounted for through continuous parameter\nevolution. This is dual to most existing computational strategies, which define\nsets through some combination of generator vectors, and usually discretize the\nsystem dynamics. We show how, under some regularity assumptions of the dynamics\nand the set considered, any desired parameter evolution can be accommodated as\nlong as the offset dynamics are set accordingly, providing a virtual \"control\ninput\" for reachable set computation. In a special case of the theory, we\ndemonstrate how closing the loop for the parameter dynamics using the adjoint\nof the linearization results in a desirable first-order cancellation of the\noriginal system dynamics. Using interval arithmetic in JAX, we demonstrate the\nefficiency and utility of reachable parametope computation through two\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-09T15:02:46Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06971v1","title":"Extinction rates for nonradial solutions to the Stefan problem","summary":"We consider the one-phase Stefan problem describing the evolution of melting\nice. On the one hand, we focus on understanding the evolution of the free\nboundary near isolated singular points, and we establish for the first time\nupper and (more surprisingly) lower estimates for its evolution. In 2D, these\nbounds almost match the best known ones for radial solutions, but hold for all\nsolutions to the Stefan problem, with no extra assumption on the initial or\nboundary data. On the other hand, as a consequence of our results, we also\ncharacterize the global regularity of the free boundary, as follows: it can be\nwritten as a graph $t = \\Gamma(x)$, where $\\Gamma$ is $C^1$ (and not $C^2$)\nnear any singular points in the lower strata $\\Sigma_m$, $m \\leq n - 2$.\nMoreover, $\\Gamma$ is not $C^1$ at singular points in $\\Sigma_{n-1}$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T15:26:54Z"}
{"aid":"http://arxiv.org/abs/2504.06982v1","title":"SIGMAN:Scaling 3D Human Gaussian Generation with Millions of Assets","summary":"3D human digitization has long been a highly pursued yet challenging task.\nExisting methods aim to generate high-quality 3D digital humans from single or\nmultiple views, but remain primarily constrained by current paradigms and the\nscarcity of 3D human assets. Specifically, recent approaches fall into several\nparadigms: optimization-based and feed-forward (both single-view regression and\nmulti-view generation with reconstruction). However, they are limited by slow\nspeed, low quality, cascade reasoning, and ambiguity in mapping low-dimensional\nplanes to high-dimensional space due to occlusion and invisibility,\nrespectively. Furthermore, existing 3D human assets remain small-scale,\ninsufficient for large-scale training. To address these challenges, we propose\na latent space generation paradigm for 3D human digitization, which involves\ncompressing multi-view images into Gaussians via a UV-structured VAE, along\nwith DiT-based conditional generation, we transform the ill-posed\nlow-to-high-dimensional mapping problem into a learnable distribution shift,\nwhich also supports end-to-end inference. In addition, we employ the multi-view\noptimization approach combined with synthetic data to construct the HGS-1M\ndataset, which contains $1$ million 3D Gaussian assets to support the\nlarge-scale training. Experimental results demonstrate that our paradigm,\npowered by large-scale training, produces high-quality 3D human Gaussians with\nintricate textures, facial details, and loose clothing deformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.06998v1","title":"A Krylov projection algorithm for large symmetric matrices with dense\n  spectra","summary":"We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d.\n$A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times\np}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output\n(MIMO) transfer functions for large-scale discretizations of problems with\ncontinuous spectral measures, such as linear time-invariant (LTI) PDEs on\nunbounded domains. Traditional Krylov methods, such as the Lanczos or CG\nalgorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with\nreal positive $s$, resulting in an adaptation to the distinctively discrete and\nnonuniform spectra. However, the adaptation is damped for matrices with dense\nspectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of\nScientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss\n-Radau quadratures computed using the block-Lanczos method significantly\nreduces approximation errors for such problems. Here, we introduce an adaptive\nKre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing\nfurther acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau\nquadrature, a low-rank modification is applied to the (block) Lanczos matrix.\nHowever, unlike the Gau\\ss -Radau quadrature, this modification depends on\n$\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e\napproximants, which are known to be efficient for problems with branch-cuts,\nthat can be good approximations to dense spectral intervals. Numerical results\nfor large-scale discretizations of heat-diffusion and quasi-magnetostatic\nMaxwell's operators in unbounded domains confirm the efficiency of the proposed\napproach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07000v1","title":"Deviation Estimates for Extremal Relay Random Geometric Graphs","summary":"In this paper, we consider a deterministic graph~\\(\\Gamma\\) drawn on the unit\nsquare with straight line segments as edges and connect vertices of~\\(\\Gamma\\)\nusing edges of a random geometric graph (RGG)~\\(G\\) with adjacency\ndistance~\\(r_n\\) as relays. We call the resulting graph as a \\emph{relay} RGG\nand determine sufficient conditions under such relay RGGs exist and are also\nnear optimal, in terms of the graph parameters of~\\(\\Gamma.\\) We then equip\nedges of~\\(G\\) with independent, exponentially distributed weights and obtain\nbounds for the maximum possible weight~\\(W_n\\) of a relay RGG with a given\nlength~\\(L_n.\\)","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.07009v1","title":"Efficient Light Generation in Ultraviolet-A Band on Chip","summary":"Lithium niobate nano photonics provides highly efficient nonlinear optics\nprocesses covering a broad spectrum from ultraviolet to mid-infrared, yet\nstudies thus far have concentrated in the near-infrared regime. Here we\ndemonstrate light generation in the Ultraviolet-A band in a periodic poled\nwaveguide via second harmonic generation. The internal efficiency reaches 1797\n$\\% W^{-1}/cm^{-2}$, marking a 9.1-times improvement over the state of art,\nthanks to better mode overlap and poling. Our technique can find applications\nin atomic clocks, frequency comb generation, sensing, and visible entanglement\ngeneration.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-09T16:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07012v1","title":"Assessing dominance in survival functions: A test for right-censored\n  data","summary":"This paper proposes a new statistical test to assess the dominance of\nsurvival functions in the presence of right-censored data. Traditional methods,\nsuch as the log-rank test, are inadequate for determining whether one survival\nfunction consistently dominates another, especially when survival curves cross.\nThe proposed test is based on the supremum of the difference between\nKaplan-Meier estimators and allows for distinguishing between dominance and\ncrossing survival curves. The paper presents the test's asymptotic properties,\nalong with simulations and applications to real datasets. The results\ndemonstrate that the test has high sensitivity for detecting crossings and\ndominance compared to conventional methods.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-09T16:30:39Z"}
{"aid":"http://arxiv.org/abs/2504.07013v1","title":"Thin Coalgebraic Behaviours Are Inductive","summary":"Coalgebras for analytic functors uniformly model graph-like systems where the\nsuccessors of a state may admit certain symmetries. Examples of successor\nstructure include ordered tuples, cyclic lists and multisets. Motivated by\ngoals in automata-based verification and results on thin trees, we introduce\nthin coalgebras as those coalgebras with only countably many infinite paths\nfrom each state. Our main result is an inductive characterisation of thinness\nvia an initial algebra. To this end, we develop a syntax for thin behaviours\nand capture with a single equation when two terms represent the same thin\nbehaviour. Finally, for the special case of polynomial functors, we retrieve\nfrom our syntax the notion of Cantor-Bendixson rank of a thin tree.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07024v1","title":"Data Augmentation and Hyperparameter Tuning for Low-Resource MFA","summary":"A continued issue for those working with computational tools and endangered\nand under-resourced languages is the lower accuracy of results for languages\nwith smaller amounts of data. We attempt to ameliorate this issue by using data\naugmentation methods to increase corpus size, comparing augmentation to\nhyperparameter tuning for multilingual forced alignment. Unlike text\naugmentation methods, audio augmentation does not lead to substantially\nincreased performance. Hyperparameter tuning, on the other hand, results in\nsubstantial improvement without (for this amount of data) infeasible additional\ntraining time. For languages with small to medium amounts of training data,\nthis is a workable alternative to adapting models from high-resource languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07029v1","title":"Distilling Textual Priors from LLM to Efficient Image Fusion","summary":"Multi-modality image fusion aims to synthesize a single, comprehensive image\nfrom multiple source inputs. Traditional approaches, such as CNNs and GANs,\noffer efficiency but struggle to handle low-quality or complex inputs. Recent\nadvances in text-guided methods leverage large model priors to overcome these\nlimitations, but at the cost of significant computational overhead, both in\nmemory and inference time. To address this challenge, we propose a novel\nframework for distilling large model priors, eliminating the need for text\nguidance during inference while dramatically reducing model size. Our framework\nutilizes a teacher-student architecture, where the teacher network incorporates\nlarge model priors and transfers this knowledge to a smaller student network\nvia a tailored distillation process. Additionally, we introduce spatial-channel\ncross-fusion module to enhance the model's ability to leverage textual priors\nacross both spatial and channel dimensions. Our method achieves a favorable\ntrade-off between computational efficiency and fusion quality. The distilled\nnetwork, requiring only 10\\% of the parameters and inference time of the\nteacher network, retains 90\\% of its performance and outperforms existing SOTA\nmethods. Extensive experiments demonstrate the effectiveness of our approach.\nThe implementation will be made publicly available as an open-source resource.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T16:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07040v1","title":"Bounds on the number of squares in recurrence sequences: arbitrary $b$,\n  III","summary":"We generalise our earlier work on the number of squares in binary recurrence\nsequences, $\\left\\{ y_{k} \\right\\}_{k \\geq -\\infty}$. In the notation of our\nprevious papers, here we consider the case when $N_{\\alpha}$ is any negative\ninteger and $y_{0}=b^{2}$ for any positive integer, $b$. We show that there are\nat most $4$ distinct squares with $y_{k}$ sufficiently large. This allows us to\nalso show that there are at most $9$ distinct squares in such sequences when\n$b=1,2$ or $3$, or once $d$ is sufficiently large.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T16:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.07056v1","title":"The Lyman-alpha and Continuum Origins Survey I: Survey description and\n  Ly$α$ imaging","summary":"Understanding the mechanisms driving the escape of ionizing or Lyman\ncontinuum (LyC) emission from the interstellar medium of galaxies is necessary\nto constrain the evolution of Reionization, and the sources responsible for it.\nWhile progress has been made into identifying the global galaxy properties\nlinked to the escape fraction of ionizing radiation, f$_{esc}^{LyC}$, little is\ncurrently known about how spatially resolved galaxy properties impact this\nparameter. We present Hubble Space Telescope (HST) imaging data obtained as\npart of the Lyman $\\alpha$ and Continuum Origins Survey (LaCOS). LaCOS consists\nof HST imaging in 5 filters covering rest-frame optical and UV bands for a\nsubsample of 42 galaxies in the Low redshift Lyman Continuum Survey, 22 being\nLyman continuum emitters ($f_{esc}^{LyC}=0.01-0.49$). These data allow for\ninvestigations of the connection between sub-kpc stellar and nebular\nproperties, including Ly$\\alpha$ emission, and $f_{esc}^{LyC}$. Here, we\ndescribe the sample selection, observations and data reduction methods.\nAdditionally, we present results on the link between global and resolved\nLy$\\alpha$ photometry and $f_{esc}^{LyC}$. We find similar trends between\nglobal photometric observables ($L_{Ly\\alpha}$, $EW_{Ly\\alpha}$,\n$f_{esc}^{Ly\\alpha}$, $r_{50}$, $\\Sigma_{SFR}$) and $f_{esc}^{LyC}$ as\npreviously found with spectroscopy, but the correlations generally show a\nslightly smaller degree of correlations. However, we do find strong\ncorrelations between Ly$\\alpha$ observables ($L_{Ly\\alpha}$,$EW_{Ly\\alpha}$)\nand $f_{esc}^{LyC}$ when measured in a small aperture around the brightest UV\nsource in each galaxy. We interpret these results as evidence that LyC photons\nescaping on the line-of-sight are contributed by a small number of UV-bright\ncompact regions in most galaxies in our sample.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-09T17:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.07070v1","title":"A Survey on Personalized and Pluralistic Preference Alignment in Large\n  Language Models","summary":"Personalized preference alignment for large language models (LLMs), the\nprocess of tailoring LLMs to individual users' preferences, is an emerging\nresearch direction spanning the area of NLP and personalization. In this\nsurvey, we present an analysis of works on personalized alignment and modeling\nfor LLMs. We introduce a taxonomy of preference alignment techniques, including\ntraining time, inference time, and additionally, user-modeling based methods.\nWe provide analysis and discussion on the strengths and limitations of each\ngroup of techniques and then cover evaluation, benchmarks, as well as open\nproblems in the field.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:39:58Z"}
{"aid":"http://arxiv.org/abs/2504.07077v1","title":"Machine Learning Approach towards Quantum Error Mitigation for Accurate\n  Molecular Energetics","summary":"Despite significant efforts, the realization of the hybrid quantum-classical\nalgorithms has predominantly been confined to proof-of-principles, mainly due\nto the hardware noise. With fault-tolerant implementation being a long-term\ngoal, going beyond small molecules with existing error mitigation (EM)\ntechniques with current noisy intermediate scale quantum (NISQ) devices has\nbeen a challenge. That being said, statistical learning methods are promising\napproaches to learning the noise and its subsequent mitigation. We devise a\ngraph neural network and regression-based machine learning (ML) architecture\nfor practical realization of EM techniques for molecular Hamiltonian without\nthe requirement of the exponential overhead. Given the short coherence time of\nthe quantum hardware, the ML model is trained with either ideal or mitigated\nexpectation values over a judiciously chosen ensemble of shallow sub-circuits\nadhering to the native hardware architecture. The hardware connectivity network\nis mapped to a directed graph which encodes the information of the native gate\nnoise profile to generate the features for the neural network. The training\ndata is generated on-the-fly during ansatz construction thus removing the\ncomputational overhead. We demonstrate orders of magnitude improvements in\npredicted energy over a few strongly correlated molecules.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T17:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.07079v1","title":"SkillWeaver: Web Agents can Self-Improve by Discovering and Honing\n  Skills","summary":"To survive and thrive in complex environments, humans have evolved\nsophisticated self-improvement mechanisms through environment exploration,\nhierarchical abstraction of experiences into reuseable skills, and\ncollaborative construction of an ever-growing skill repertoire. Despite recent\nadvancements, autonomous web agents still lack crucial self-improvement\ncapabilities, struggling with procedural knowledge abstraction, refining\nskills, and skill composition. In this work, we introduce SkillWeaver, a\nskill-centric framework enabling agents to self-improve by autonomously\nsynthesizing reusable skills as APIs. Given a new website, the agent\nautonomously discovers skills, executes them for practice, and distills\npractice experiences into robust APIs. Iterative exploration continually\nexpands a library of lightweight, plug-and-play APIs, significantly enhancing\nthe agent's capabilities. Experiments on WebArena and real-world websites\ndemonstrate the efficacy of SkillWeaver, achieving relative success rate\nimprovements of 31.8% and 39.8%, respectively. Additionally, APIs synthesized\nby strong agents substantially enhance weaker agents through transferable\nskills, yielding improvements of up to 54.3% on WebArena. These results\ndemonstrate the effectiveness of honing diverse website interactions into APIs,\nwhich can be seamlessly shared among various web agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-09T17:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.07407v1","title":"Cech - de Rham Chern character on the stack of holomorphic vector\n  bundles","summary":"We provide a formula for the Chern character of a holomorphic vector bundle\nin the hyper-cohomology of the de Rham complex of holomorphic sheaves on a\ncomplex manifold. This Chern character can be thought of as a completion of the\nChern character in Hodge cohomology obtained as the trace of the exponential of\nthe Atiyah class, which is \\v{C}ech closed, to one that is \\v{C}ech-Del closed.\nSuch a completion is a key step toward lifting O'Brian-Toledo-Tong invariants\nof coherent sheaves from Hodge cohomology to de Rham cohomology. An alternate\napproach toward the same end goal, instead using simplicial differential forms\nand Green complexes, can be found in Hosgood's works [Ho1, Ho2]. In the\nalgebraic setting, and more generally for K\\\"{a}hler manifolds, where Hodge and\nde Rham cohomologies agree, such extensions are not necessary, whereas in the\nnon-K\\\"{a}hler, or equivariant settings the two theories differ. We provide our\nformulae as a map of simplicial presheaves, which readily extend the results to\nthe equivariant setting and beyond. This paper can be viewed as a sequel to\n[GMTZ1] which covered such a discussion in Hodge cohomology. As an aside, we\ngive a conceptual understanding of how formulas obtained by Bott and Tu for\nChern classes using transition functions and those from Chern-Weil theory using\nconnections, are part of a natural unifying story.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-10T03:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.07408v1","title":"AI Coding with Few-Shot Prompting for Thematic Analysis","summary":"This paper explores the use of large language models (LLMs), here represented\nby GPT 3.5-Turbo to perform coding for a thematic analysis. Coding is highly\nlabor intensive, making it infeasible for most researchers to conduct\nexhaustive thematic analyses of large corpora. We utilize few-shot prompting\nwith higher quality codes generated on semantically similar passages to enhance\nthe quality of the codes while utilizing a cheap, more easily scalable model.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:02:15Z"}
{"aid":"http://arxiv.org/abs/2504.07414v1","title":"Decomposition-Based Optimal Bounds for Privacy Amplification via\n  Shuffling","summary":"Shuffling has been shown to amplify differential privacy guarantees, offering\na stronger privacy-utility trade-off. To characterize and compute this\namplification, two fundamental analytical frameworks have been proposed: the\nprivacy blanket by Balle et al. (CRYPTO 2019) and the clone paradigm (including\nboth the standard clone and stronger clone) by Feldman et al. (FOCS 2021, SODA\n2023). All these methods rely on decomposing local randomizers.\n  In this work, we introduce a unified analysis framework--the general clone\nparadigm--which encompasses all possible decompositions. We identify the\noptimal decomposition within the general clone paradigm. Moreover, we develop a\nsimple and efficient algorithm to compute the exact value of the optimal\nprivacy amplification bounds via Fast Fourier Transform. Experimental results\ndemonstrate that the computed upper bounds for privacy amplification closely\napproximate the lower bounds, highlighting the tightness of our approach.\nFinally, using our algorithm, we conduct the first systematic analysis of the\njoint composition of LDP protocols in the shuffle model.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:11:17Z"}
{"aid":"http://arxiv.org/abs/2504.07416v1","title":"RadZero: Similarity-Based Cross-Attention for Explainable\n  Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability","summary":"Recent advancements in multi-modal models have significantly improved\nvision-language alignment in radiology. However, existing approaches struggle\nto effectively utilize complex radiology reports for learning, rely on\nlow-resolution images, and offer limited interpretability in attention\nmechanisms. To address these challenges, we introduce RadZero, a novel\nsimilarity-based cross-attention framework for vision-language alignment in\nradiology with zero-shot multi-task capability. RadZero leverages large\nlanguage models to extract minimal semantic sentences from radiology reports\nand employs a multi-positive contrastive learning strategy to effectively\ncapture relationships between images and multiple relevant textual\ndescriptions. It also utilizes a pre-trained vision encoder with additional\ntrainable Transformer layers, allowing efficient high-resolution image\nprocessing. By computing similarity between text embeddings and local image\npatch features, RadZero enables zero-shot inference with similarity probability\nfor classification and pixel-level cross-modal similarity maps for grounding\nand segmentation. Experimental results on public chest radiograph benchmarks\nshow that RadZero outperforms state-of-the-art methods in zero-shot\nclassification, grounding, and segmentation. Furthermore, cross-modal\nsimilarity map analysis highlights its potential for improving explainability\nin vision-language alignment. Additionally, qualitative evaluation demonstrates\nRadZero's capability for open-vocabulary semantic segmentation, further\nvalidating its effectiveness in medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.07421v1","title":"AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery","summary":"We introduce AgentAda, the first LLM-powered analytics agent that can learn\nand use new analytics skills to extract more specialized insights. Unlike\nexisting methods that require users to manually decide which data analytics\nmethod to apply, AgentAda automatically identifies the skill needed from a\nlibrary of analytical skills to perform the analysis. This also allows AgentAda\nto use skills that existing LLMs cannot perform out of the box. The library\ncovers a range of methods, including clustering, predictive modeling, and NLP\ntechniques like BERT, which allow AgentAda to handle complex analytics tasks\nbased on what the user needs. AgentAda's dataset-to-insight extraction strategy\nconsists of three key steps: (I) a question generator to generate queries\nrelevant to the user's goal and persona, (II) a hybrid Retrieval-Augmented\nGeneration (RAG)-based skill matcher to choose the best data analytics skill\nfrom the skill library, and (III) a code generator that produces executable\ncode based on the retrieved skill's documentation to extract key patterns. We\nalso introduce KaggleBench, a benchmark of curated notebooks across diverse\ndomains, to evaluate AgentAda's performance. We conducted a human evaluation\ndemonstrating that AgentAda provides more insightful analytics than existing\ntools, with 48.78% of evaluators preferring its analyses, compared to 27.67%\nfor the unskilled agent. We also propose a novel LLM-as-a-judge approach that\nwe show is aligned with human evaluation as a way to automate insight quality\nevaluation at larger scale.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07422v1","title":"The Role of Machine Learning in Reducing Healthcare Costs: The Impact of\n  Medication Adherence and Preventive Care on Hospitalization Expenses","summary":"This study reveals the important role of prevention care and medication\nadherence in reducing hospitalizations. By using a structured dataset of 1,171\npatients, four machine learning models Logistic Regression, Gradient Boosting,\nRandom Forest, and Artificial Neural Networks are applied to predict five-year\nhospitalization risk, with the Gradient Boosting model achieving the highest\naccuracy of 81.2%. The result demonstrated that patients with high medication\nadherence and consistent preventive care can reduce 38.3% and 37.7% in\nhospitalization risk. The finding also suggests that targeted preventive care\ncan have positive Return on Investment (ROI), and therefore ML models can\neffectively direct personalized interventions and contribute to long-term\nmedical savings.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY","published":"2025-04-10T03:28:42Z"}
{"aid":"http://arxiv.org/abs/2504.07435v1","title":"Opportunity-Cost-Driven Reward Mechanisms for Crowd-Sourced Computing\n  Platforms","summary":"This paper introduces a game-theoretic model tailored for reward distribution\non crowd-sourced computing platforms. It explores a repeated game framework\nwhere miners, as computation providers, decide their computation power\ncontribution in each round, guided by the platform's designed reward\ndistribution mechanism. The reward for each miner in every round is based on\nthe platform's randomized task payments and the miners' computation\ntranscripts. Specifically, it defines Opportunity-Cost-Driven Incentive\nCompatibility (OCD-IC) and Dynamic OCD-IC (DOCD-IC) for scenarios where\nstrategic miners might allocate some computation power to more profitable\nactivities, such as Bitcoin mining. The platform must also achieve Budget\nBalance (BB), aiming for a non-negative total income over the long term. This\npaper demonstrates that traditional Pay-Per-Share (PPS) reward schemes require\nassumptions about task demand and miners' opportunity costs to ensure OCD-IC\nand BB, yet they fail to satisfy DOCD-IC. The paper then introduces\nPay-Per-Share with Subsidy (PPSS), a new reward mechanism that allows the\nplatform to provide subsidies to miners, thus eliminating the need for\nassumptions on opportunity cost to achieve OCD-IC, DOCD-IC, and long-term BB.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-10T04:05:48Z"}
{"aid":"http://arxiv.org/abs/2504.07442v1","title":"RIS-Aided Integrated Sensing and Communication Waveform Design With\n  Tunable PAPR","summary":"Low peak-to-average power ratio (PAPR) transmission is an important and\nfavorable requirement prevalent in radar and communication systems, especially\nin transmission links integrated with high power amplifiers. Meanwhile,\nmotivated by the advantages of reconfigurable intelligent surface (RIS) in\nmitigating multi-user interference (MUI) to enhance the communication rate,\nthis paper investigates the design problem of joint waveform and passive\nbeamforming with PAPR constraint for integrated sensing and communication\n(ISAC) systems, where RIS is deployed for downlink communication. We first\nconstruct a trade-off optimization problem for the MUI and beampattern\nsimilarity under PAPR constraint. Then, in order to solve this multivariate\nproblem, an iterative optimization algorithm based on alternating direction\nmethod of multipliers (ADMM) and manifold optimization is proposed. Finally,\nthe simulation results show that the designed waveforms can well satisfy the\nPAPR requirement of the ISAC systems and achieve a trade-off between radar and\ncommunication performance. Under high signal-to-noise ratio (SNR) conditions,\ncompared to systems without RIS, RIS-aided ISAC systems have a performance\nimprovement of about 50\\% in communication rate and at least 1 dB in\nbeampatterning error.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T04:18:23Z"}
{"aid":"http://arxiv.org/abs/2504.07452v1","title":"Laboratory Three-dimensional X-ray Micro-beam Laue Diffraction","summary":"The development of three-dimensional (3D) non-destructive X-ray\ncharacterization techniques in home laboratories is essential for enabling many\nmore researchers to perform 3D characterization daily, overcoming the\nlimitations imposed by competitive and scarce access to synchrotron facilities.\nRecent efforts have focused on techniques such as laboratory diffraction\ncontrast tomography (LabDCT), which allows 3D characterization of\nrecrystallized grains with sizes larger than 15-20 $\\mu$m, offering a boundary\nresolution of approximately 5$\\mu$m using commercial X-ray computed tomography\n(CT) systems. To enhance the capabilities of laboratory instruments, we have\ndeveloped a new laboratory-based 3D X-ray micro-beam diffraction\n(Lab-3D$\\mu$XRD) technique. Lab-3D$\\mu$XRD combines the use of a focused\npolychromatic beam with a scanning-tomographic data acquisition routine to\nenable depth-resolved crystallographic orientation characterization. This work\npresents the first realization of Lab-3D$\\mu$XRD, including hardware\ndevelopment through the integration of a newly developed Pt-coated twin\nparaboloidal capillary X-ray focusing optics into a conventional X-ray $\\mu$CT\nsystem, as well as the development of data acquisition and processing software.\nThe results are validated through comparisons with LabDCT and synchrotron phase\ncontrast tomography. The findings clearly demonstrate the feasibility of\nLab-3D$\\mu$XRD, particularly in detecting smaller grains and providing\nintragranular information. Finally, we discuss future directions for developing\nLab-3D$\\mu$XRD into a versatile tool for studying materials with smaller grain\nsizes and high defect densities, including the potential of combining it with\nLabDCT and $\\mu$CT for multiscale and multimodal microstructural\ncharacterization.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.07453v1","title":"Probability Estimation and Scheduling Optimization for Battery Swap\n  Stations via LRU-Enhanced Genetic Algorithm and Dual-Factor Decision System","summary":"To address the challenges of limited Battery Swap Stations datasets, high\noperational costs, and fluctuating user charging demand, this research proposes\na probability estimation model based on charging pile data and constructs nine\nscenario-specific battery swap demand datasets. In addition, this study\ncombines Least Recently Used strategy with Genetic Algorithm and incorporates a\nguided search mechanism, which effectively enhances the global optimization\ncapability. Thus, a dual-factor decision-making based charging schedule\noptimization system is constructed. Experimental results show that the\nconstructed datasets exhibit stable trend characteristics, adhering to 24-hour\nand 168-hour periodicity patterns, with outlier ratios consistently below\n3.26%, confirming data validity. Compared to baseline, the improved algorithm\nachieves better fitness individuals in 80% of test regions under the same\niterations. When benchmarked against immediate swap-and-charge strategy, our\nalgorithm achieves a peak cost reduction of 13.96%. Moreover, peak user\nsatisfaction reaches 98.57%, while the average iteration time remains below 0.6\nseconds, demonstrating good computational efficiency. The complete datasets and\noptimization algorithm are open-sourced at\nhttps://github.com/qingshufan/GA-EVLRU.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T04:58:24Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07469v1","title":"Vortex droplets and lattice patterns in two-dimensional traps: A\n  photonic spin-orbit-coupling perspective","summary":"In the context of the mean-field exciton-polariton (EP) theory with balanced\nloss and pump, we investigate the formation of lattice structures built of\nindividual vortex-antivortex (VAV) bound states under the action of the\ntwo-dimensional harmonic-oscillator (HO) potential trap and effective\nspin-orbit coupling (SOC), produced by the TE-TM splitting in the polariton\nsystem. The number of VAV elements (pixels) building the structures grow with\nthe increase of self- and cross-interaction coefficients. Depending upon their\nvalues and the trapping frequency, stable ring-shaped, circular, square-shaped,\nrectangular, pentagonal, hexagonal, and triangular patterns are produced, with\nthe central site left vacant or occupied in the lattice patterns of different\ntypes. The results suggest the experimental creation of the new patterns and\ntheir possible use for the design of integrated circuits in EP setups,\ncontrolled by the strengths of the TE-TM splitting, nonlinearity, and HO trap.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T05:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.07473v1","title":"Standard $t$-structures","summary":"We provide a general construction of induced $t$-structures, that generalizes\nstandard $t$-structures for $\\infty$-categories of sheaves. More precisely,\ngiven a presentable $\\infty$-category $\\mathcal{X}$ and a presentable stable\n$\\infty$-category $\\mathcal{E}$ equipped with an accessible $t$-structure $\\tau\n= (\\mathcal{E}_{\\geq 0}, \\mathcal{E}_{\\leq 0})$, we show that $\\mathcal{X}\n\\otimes \\mathcal{E}$ is equipped with a canonical $t$-structure whose\ncoconnective part is given in $\\mathcal{X} \\otimes \\mathcal{E}_{\\leq 0}$. When\n$\\mathcal{X}$ is an $\\infty$-topos, we give a more explicit description of the\nconnective part as well.","main_category":"math.CT","categories":"math.CT,math.AT","published":"2025-04-10T05:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.07487v1","title":"Microscopic model for yields and total kinetic energy in nuclear fission","summary":"An extension of time-dependent density functional theory (TDDFT), the\ngeneralized time-dependent generator coordinate method (TDGCM), is applied to a\nstudy of induced nuclear fission dynamics. In the generalized TDGCM, the\ncorrelated nuclear wave function is represented as a coherent superposition of\ntime-dependent DFT trajectories. In the first realistic application, a large\nbasis of 25 TDDFT trajectories is employed to calculate the charge yields and\ntotal kinetic energy distribution for the fission of $^{240}$Pu. The results\nare compared with available data, and with those obtained using a standard\nTDDFT, that does not consider quantum fluctuations, and the adiabatic TDGCM+GOA\n(Gaussian overlap approximation). It is shown that fragment yields and kinetic\nenergies can simultaneously be described in a consistent microscopic framework\nthat includes fluctuations in the collective degrees of freedom and the\none-body dissipation mechanism.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-10T06:42:56Z"}
{"aid":"http://arxiv.org/abs/2504.07494v1","title":"Apt-Serve: Adaptive Request Scheduling on Hybrid Cache for Scalable LLM\n  Inference Serving","summary":"Large language model (LLM) inference serving systems are essential to various\nLLM-based applications. As demand for LLM services continues to grow, scaling\nthese systems to handle high request rates while meeting latency Service-Level\nObjectives (SLOs), referred to as effective throughput, becomes critical.\nHowever, existing systems often struggle to improve effective throughput,\nprimarily due to a significant decline in Time To First Token (TTFT) SLO\nattainment. We identify two major causes of this bottleneck: (1)\nmemory-intensive KV cache that limits batch size expansion under GPU memory\nconstraints, and (2) rigid batch composition enforced by the default\nFirst-Come-First-Serve scheduling policy. In this paper, we introduce\nApt-Serve, a scalable framework designed to enhance effective throughput in LLM\ninference serving. Apt-Serve features a new hybrid cache scheme that combines\nKV cache with a memory-efficient hidden cache for reusable input hidden state\nvectors, allowing large batch sizes and improving request concurrency. Based on\nthe hybrid cache, Apt-Serve employs an adaptive runtime scheduling mechanism\nthat dynamically optimizes batch composition. We formally define the adaptive\nscheduling optimization problem and propose an efficient algorithm with\ntheoretical guarantees. Extensive evaluations on three real-world datasets and\nLLMs ranging from 13B to 66B parameters demonstrate that Apt-Serve achieves up\nto 8.8x improvement in effective throughput compared to the state-of-the-art\ninference serving systems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T06:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.07496v1","title":"Modular Control of Discrete Event System for Modeling and Mitigating\n  Power System Cascading Failures","summary":"Cascading failures in power systems caused by sequential tripping of\ncomponents are a serious concern as they can lead to complete or partial\nshutdowns, disrupting vital services and causing damage and inconvenience. In\nprior work, we developed a new approach for identifying and preventing\ncascading failures in power systems. The approach uses supervisory control\ntechnique of discrete event systems (DES) by incorporating both on-line\nlookahead control and forcible events. In this paper, we use modular\nsupervisory control of DES to reduce computation complexity and increase the\nrobustness and reliability of control. Modular supervisory control allows us to\npredict and mitigate cascading failures in power systems more effectively. We\nimplemented the proposed control technique on a simulation platform developed\nin MATLAB and applied the proposed DES controller. The calculations of modular\nsupervisory control of DES are performed using an external tool and imported\ninto the MATLAB platform. We conduct simulation studies for the IEEE 30-bus,\n118-bus and 300-bus systems, and the results demonstrate the effectiveness of\nour proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T06:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.07499v1","title":"Digital quantum simulation of the Su-Schrieffer-Heeger model using a\n  parameterized quantum circuit","summary":"We perform digital quantum simulations of the noninteracting\nSu-Schrieffer-Heeger (SSH) model using a parameterized quantum circuit. The\ncircuit comprises two main components: the first prepares the initial state\nfrom the product state $|0\\rangle^{\\otimes L}$, where $L$ is the system size;\nthe second consists of $M$ layers of brick-wall unitaries simulating time\nevolution. The evolution times, encoded as the rotation angles of quantum gates\nin the second part, are optimized variationally to minimize the energy. The SSH\nmodel exhibits two distinct topological phases, depending on the relative\nstrengths of inter- and intra-cell hopping amplitudes. We investigate the\nevolution of the energy, entanglement entropy, and mutual information towards\ntopologically trivial and nontrivial ground states. Our results find the\nfollows: (i) When the initial and target ground states belong to the same\ntopological phase, the variational energy decreases exponentially, the\nentanglement entropy quickly saturates in a system-size-independent manner, and\nthe mutual information remains spatially localized, as the number of layers\nincreases. (ii) When the initial and target ground states belong to different\ntopological phases, the variational energy decreases polynomially, the\nentanglement entropy initially grows logarithmically before decreasing, and the\nmutual information spreads ballistically across the entire system, with\nincreasing the number of layers. Furthermore, by calculating the polarization,\nwe identify a topological phase transition occurring at an intermediate circuit\nlayer when the initial and final target states lie in different topological\ncharacters. Finally, we experimentally confirm this topological phase\ntransition in an 18-site system using 19 qubits on a trapped-ion quantum\ncomputer provided by Quantinuum.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T06:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07501v1","title":"Distance signless Laplacian spectral radius and tough graphs involving\n  minimun degree","summary":"Let $G=(V(G),E(G))$ be a simple graph, where $V(G)$ and $E(G)$ are the vertex\nset and the edge set of $G$, respectively. The number of components of $G$ is\ndenoted by $c(G)$. Let $t$ be a positive real number, and a connected graph $G$\nis $t$-tough if $t c(G-S)\\leq|S|$ for every vertex cut $S$ of $V(G)$. The\ntoughness of graph $G$, denoted by $\\tau(G)$, is the largest value of $t$ for\nwhich $G$ is $t$-tough. Recently, Fan, Lin and Lu [European J. Combin.\n110(2023), 103701] presented sufficient conditions based on the spectral radius\nfor graphs to be 1-tough with minimum degree $\\delta(G)$ and graphs to be\n$t$-tough with $t\\geq 1$ being an integer, respectively. In this paper, we\nestablish sufficient conditions in terms of the distance signless Laplacian\nspectral radius for graphs to be 1-tough with minimum degree $\\delta(G)$ and\ngraphs to be $t$-tough, where $\\frac{1}{t}$ is a positive integer. Moreover, we\nconsider the relationship between the distance signless Laplacian spectral\nradius and $t$-tough graphs in terms of the order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.07502v1","title":"Arithmetic and Geometric Langlands Program","summary":"We explain how the geometric Langlands program inspires some recent new\nprospectives of classical arithmetic Langlands program and leads to the\nsolutions of some problems in arithmetic geometry.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.07506v1","title":"Normalized solutions to mixed dispersion nonlinear Schrödinger system\n  with coupled nonlinearity","summary":"In this paper, we consider the existence of normalized solutions for the\nfollowing biharmonic nonlinear Schr\\\"{o}dinger system\n  \\[ \\begin{aligned}\n  \\begin{cases}\n  &\\Delta^2u+\\alpha_{1}\\Delta u+\\lambda u=\\beta r_{1}|u|^{r_{1}-2}|v|^{r_{2}} u\n&&\\text{ in } \\mathbb{R}^{N},\n  & \\Delta^2v+\\alpha_{2}\\Delta v+\\lambda v=\\beta r_{2}|u|^{r_{1}}|v|^{r_{2}-2}\nv && \\text{ in } \\mathbb{R}^{N},\\\\ & \\int_{\\mathbb{R}^{N}} (u^{2}+v^{2}){\\rm d}\nx=\\rho^{2},&&\n  \\end{cases} \\end{aligned}\n  \\]\n  where $\\Delta^2u=\\Delta(\\Delta u)$ is the biharmonic operator, $\\alpha_{1}$,\n$\\alpha_{2}$, $\\beta>0$, $r_{1}$, $r_{2}>1$, $N\\geq 1$. $\\rho^2$ stands for the\nprescribed mass, and $\\lambda\\in\\mathbb{R}$ arises as a Lagrange multiplier.\nSuch single constraint permits mass transformation in two materials. When\n$r_{1}+r_{2}\\in\\left(2,2+\\frac{8}{N}\\right]$, we obtain a dichotomy result for\nthe existence of nontrivial ground states. Especially when $\\alpha_1=\\alpha_2$,\nthe ground state exists for all $\\rho>0$ if and only if\n$r_1+r_2<\\min\\left\\{\\max\\left\\{4, 2+\\frac{8}{N+1}\\right\\},\n2+\\frac{8}{N}\\right\\}$. When $r_{1}+r_{2}\\in\\left(2+\\frac{8}{N},\n\\frac{2N}{(N-4)^{+}}\\right)$ and $N\\geq 2$, we obtain the existence of radial\nnontrivial mountain pass solution for small $\\rho>0$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:08:19Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07524v1","title":"DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy\n  Prediction","summary":"Monocular 3D occupancy prediction, aiming to predict the occupancy and\nsemantics within interesting regions of 3D scenes from only 2D images, has\ngarnered increasing attention recently for its vital role in 3D scene\nunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from\n2D images is ill-posed and resource-intensive. In this paper, we present\n\\textbf{DGOcc}, a \\textbf{D}epth-aware \\textbf{G}lobal query-based network for\nmonocular 3D \\textbf{Occ}upancy prediction. We first explore prior depth maps\nto extract depth context features that provide explicit geometric information\nfor the occupancy network. Then, in order to fully exploit the depth context\nfeatures, we propose a Global Query-based (GQ) Module. The cooperation of\nattention mechanisms and scale-aware operations facilitates the feature\ninteraction between images and 3D voxels. Moreover, a Hierarchical Supervision\nStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxel\nfeatures to full resolution, which mitigates GPU memory utilization and time\ncost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasets\ndemonstrate that the proposed method achieves the best performance on monocular\nsemantic occupancy prediction while reducing GPU and time overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:44:55Z"}
{"aid":"http://arxiv.org/abs/2504.07533v1","title":"Quantitative uniqueness of continuation for the Schrödinger equation :\n  explicit dependence on the potential","summary":"We demonstrate a quantitative version of the usual properties related to\nunique continuation from an interior datum for the Schr\\\"odinger equation with\nbounded or unbounded potential. The inequalities we establish have constants\nthat explicitly depend on the potential. We also indicate how the\nabove-mentioned inequalities can be extended to elliptic equations with bounded\nor unbounded first-order derivatives. The case of unique continuation from\nCauchy data is also considered.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.07536v1","title":"Criteria for finite injective dimension of modules over a local ring","summary":"Let $R$ be a commutative Noetherian local ring. We prove that the finiteness\nof the injective dimension of a finitely generated $R$-module $C$ is determined\nby the existence of a Cohen--Macaulay module $M$ that satisfies an inequality\nconcerning multiplicity and type, together with the vanishing of finitely many\nExt modules. As applications, we recover a result of Rahmani and Taherizadeh\nand provide sufficient conditions for a finitely generated $R$-module to have\nfinite injective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.07544v1","title":"SeparationPINN: Physics-Informed Neural Networks for Seismic P- and\n  S-Wave Mode Separation","summary":"Accurate separation of P- and S-waves is essential for multi-component\nseismic data processing, as it helps eliminate interference between wave modes\nduring imaging or inversion, which leads to high-accuracy results. Traditional\nmethods for separating P- and S-waves rely on the Christoffel equation to\ncompute the polarization direction of the waves in the wavenumber domain, which\nis computationally expensive. Although machine learning has been employed to\nimprove the computational efficiency of the separation process, most methods\nstill require supervised learning with labeled data, which is often unavailable\nfor field data. To address this limitation, we propose a wavefield separation\ntechnique based on the physics-informed neural network (PINN). This\nunsupervised machine learning approach is applicable to unlabeled data.\nFurthermore, the trained PINN model provides a mesh-free numerical solution\nthat effectively captures wavefield features at multiple scales. Numerical\ntests demonstrate that the proposed PINN-based separation method can accurately\nseparate P- and S-waves in both homogeneous and heterogeneous media.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.07557v1","title":"Using LLMs for Analyzing AIS Data","summary":"Recent research in Large Language Models (LLMs), has had a profound impact\nacross various fields, including mobility data science. This paper explores the\nand experiment with different approaches to using LLMs for analyzing AIS data.\nWe propose a set of carefully designed queries to assess the reasoning\ncapabilities of LLMs in this kind of tasks. Further, we experiment with four\ndifferent methods: (1) using LLMs as a natural language interface to a spatial\ndatabase, (2) reasoning on raw data, (3) reasoning on compressed trajectories,\nand (4) reasoning on semantic trajectories. We investigate the strengths and\nweaknesses for the four methods, and discuss the findings. The goal is to\nprovide valuable insights for both researchers and practitioners on selecting\nthe most appropriate LLM-based method depending on their specific data analysis\nobjectives.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T08:38:39Z"}
{"aid":"http://arxiv.org/abs/2504.07561v1","title":"Regular Black Hole Models in the Transition from Baryonic Matter to\n  Quark Matter","summary":"In this paper, we investigate gravitational collapse scenarios involving\nbaryonic matter transitioning into quark-gluon plasma under extreme\nastrophysical conditions, focusing on their implications for the formation of\nregular black holes. Standard gravitational collapse models inevitably predict\ncentral singularities, highlighting the limitations of classical general\nrelativity in extreme density regimes. By introducing a physically motivated,\ninhomogeneous transition rate between baryonic and quark matter, we demonstrate\nanalytically and numerically that it is possible to construct regular black\nhole solutions featuring a nonsingular de Sitter-like core. We further analyze\nthe observable consequences of these models, particularly emphasizing\nmodifications to the black hole shadow radius, which provide direct\nobservational constraints accessible through Event Horizon Telescope (EHT)\nmeasurements.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:46:40Z"}
{"aid":"http://arxiv.org/abs/2504.07563v1","title":"Post-Newtonian dynamics of compact binaries with mass transfer","summary":"Taking into account the mass transfer effect, we derive the equations of\nmotion of a compact binary system at the second-half post-Newtonian order.\nApplying such equations of motion to quasi-circular orbits, we obtain the time\nderivative of the orbital frequency, which is consistent with the angular\nmomentum balance equation. Numerical estimates of the phase of gravitational\nwaves are provided for typical mass transfer rates. Our result can be used to\nimprove the waveforms of gravitational waves emitted by compact binaries with\nmass transfer.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:49:57Z"}
{"aid":"http://arxiv.org/abs/2504.07567v1","title":"Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf\n  Foundation Models, Fine-Tuning Strategies and Practical Trade-offs","summary":"We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CE,cs.IR,cs.LG","published":"2025-04-10T08:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.07569v1","title":"Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple\n  modelling","summary":"We provide an updated test for modifications of gravity from a sample of\nwide-binary stars from GAIA DR3, and their sky-projected relative velocities.\nHere we extend on our earlier 2023 study, using several updated selection cuts\naimed at reducing contamination from triple systems with an undetected third\nstar. We also use improved mass estimates from FLAMES, and we add refinements\nto previous modelling of the triple and other populations and the\nmodel-fitting. We fit histograms of observed vs Newtonian velocity differences\nto a flexible mixture of binary + triple populations with realistic\neccentricity distributions, plus unbound flyby and random-chance populations.\nWe find as before that Newtonian models provide a significantly better fit than\nMOND, though improved understanding of the triple population is necessary to\nmake this fully decisive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-10T09:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.07578v1","title":"Privacy-Preserving Vertical K-Means Clustering","summary":"Clustering is a fundamental data processing task used for grouping records\nbased on one or more features. In the vertically partitioned setting, data is\ndistributed among entities, with each holding only a subset of those features.\nA key challenge in this scenario is that computing distances between records\nrequires access to all distributed features, which may be privacy-sensitive and\ncannot be directly shared with other parties. The goal is to compute the joint\nclusters while preserving the privacy of each entity's dataset. Existing\nsolutions using secret sharing or garbled circuits implement privacy-preserving\nvariants of Lloyd's algorithm but incur high communication costs, scaling as\nO(nkt), where n is the number of data points, k the number of clusters, and t\nthe number of rounds. These methods become impractical for large datasets or\nseveral parties, limiting their use to LAN settings only. On the other hand, a\ndifferent line of solutions rely on differential privacy (DP) to outsource the\nlocal features of the parties to a central server. However, they often\nsignificantly degrade the utility of the clustering outcome due to excessive\nnoise. In this work, we propose a novel solution based on homomorphic\nencryption and DP, reducing communication complexity to O(n+kt). In our method,\nparties securely outsource their features once, allowing a computing party to\nperform clustering operations under encryption. DP is applied only to the\nclusters' centroids, ensuring privacy with minimal impact on utility. Our\nsolution clusters 100,000 two-dimensional points into five clusters using only\n73MB of communication, compared to 101GB for existing works, and completes in\njust under 3 minutes on a 100Mbps network, whereas existing works take over 1\nday. This makes our solution practical even for WAN deployments, all while\nmaintaining accuracy comparable to plaintext k-means algorithms.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T09:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.07585v1","title":"High-Level Synthesis of Digital Circuits from Template Haskell and\n  SDF-AP","summary":"Functional languages as input specifications for High-Level Synthesis (HLS)\ntools allow to specify data dependencies but do not contain a notion of time\nnor execution order. In this paper, we propose a method to add this notion to\nthe functional description using the dataflow model SDF-AP. SDF-AP consists of\npatterns that express consumption and production that we can use to enforce\nresource usage. We created an HLS-tool that can synthesize parallel hardware,\nboth data and control path, based on the repetition, expressed in Higher-Order\nFunctions, combined with specified SDF-AP patterns.\n  Our HLS-tool, based on Template Haskell, generates an Abstract Syntax Tree\nbased on the given patterns and the functional description uses the\nClash-compiler to generate VHDL/Verilog.\n  Case studies show consistent resource consumption and temporal behavior for\nour HLS. A comparison with a commercially available HLS-tool shows that our HLS\ntool outperforms in terms of latency and sometimes in resource consumption.\n  The method and tool presented in this paper offer more transparency to the\ndeveloper and allow to specify more accurately the synthesized hardware\ncompared to what is possible with pragmas of the Vitis HLS-tool.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:25:47Z"}
{"aid":"http://arxiv.org/abs/2504.07591v1","title":"On the Cox rings of some hypersurfaces","summary":"We introduce a cohomological method to compute Cox rings of hypersurfaces in\nthe ambient space P^1 x P^n, which is more direct than existing methods. We\nprove that smooth hypersurfaces defined by regular sequences of coefficients\nare Mori dream spaces, generalizing a result of Ottem. We also compute Cox\nrings of certain specialized examples. In particular, we compute Cox rings in\nthe well-studied family of Calabi--Yau threefolds of bidegree (2,4) in P^1 x\nP^3, determining explicitly how the Cox ring can jump discontinuously in a\nsmooth family.","main_category":"math.AG","categories":"math.AG","published":"2025-04-10T09:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.07595v1","title":"High-Level Synthesis using SDF-AP, Template Haskell, QuasiQuotes, and\n  GADTs to Generate Circuits from Hierarchical Input Specification","summary":"FPGAs provide highly parallel and customizable hardware solutions but are\ntraditionally programmed using low-level Hardware Description Languages (HDLs)\nlike VHDL and Verilog. These languages have a low level of abstraction and\nrequire engineers to manage control and scheduling manually. High-Level\nSynthesis (HLS) tools attempt to lift this level of abstraction by translating\nC/C++ code into hardware descriptions, but their reliance on imperative\nparadigms leads to challenges in deriving parallelism due to pointer aliasing\nand sequential execution models.\n  Functional programming, with its inherent purity, immutability, and\nparallelism, presents a more natural abstraction for FPGA design. Existing\nfunctional hardware description tools such as Clash enable high-level circuit\ndescriptions but lack automated scheduling and control mechanisms. Prior work\nby Folmer introduced a framework integrating SDF-AP graphs into Haskell for\nautomatic hardware generation, but it lacked hierarchy and reusability.\n  This paper extends that framework by introducing hierarchical pattern\nspecification, enabling structured composition and scalable parallelism. Key\ncontributions include: (1) automatic hardware generation, where both data and\ncontrol paths are derived from functional specifications with hierarchical\npatterns, (2) parameterized buffers using GADTs, eliminating the need for\nmanual buffer definitions and facilitating component reuse, and (3) provision\nof a reference \"golden model\" that can be simulated in the integrated\nenvironment for validation.\n  The core focus of this paper is on methodology. But we also evaluate our\napproach against Vitis HLS, comparing both notation and resulting hardware\narchitectures. Experimental results demonstrate that our method provides\ngreater transparency in resource utilization and scheduling, often\noutperforming Vitis in both scheduling and predictability.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.07601v1","title":"Restricted Poisson algebras in characteristic 2","summary":"In this paper, we introduce restricted Poisson algebras in characteristic 2\nand their relationship with restricted Lie-Rinehart algebras, for which we\ndevelop a cohomology theory and investigate abelian extensions. We also\nconstruct a full cohomology complex for restricted Poisson algebras in\ncharacteristic 2 that captures formal deformations and prove that it is\nisomorphic to the cohomology complex of a suitable restricted Lie-Rinehart\nalgebra, under certain assumptions. A number of examples are provided in order\nto illustrate our constructions.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T09:54:29Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07615v1","title":"VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model","summary":"Recently DeepSeek R1 has shown that reinforcement learning (RL) can\nsubstantially improve the reasoning capabilities of Large Language Models\n(LLMs) through a simple yet effective design. The core of R1 lies in its\nrule-based reward formulation, which leverages tasks with deterministic\nground-truth answers to enable precise and stable reward computation. In the\nvisual domain, we similarly observe that a wide range of visual understanding\ntasks are inherently equipped with well-defined ground-truth annotations. This\nproperty makes them naturally compatible with rule-based reward mechanisms.\nMotivated by this observation, we investigate the extension of R1-style\nreinforcement learning to Vision-Language Models (VLMs), aiming to enhance\ntheir visual reasoning capabilities. To this end, we develop VLM-R1, a\ndedicated framework designed to harness RL for improving VLMs' performance on\ngeneral vision-language tasks. Using this framework, we further explore the\nfeasibility of applying RL to visual domain. Experimental results indicate that\nthe RL-based model not only delivers competitive performance on visual\nunderstanding tasks but also surpasses Supervised Fine-Tuning (SFT) in\ngeneralization ability. Furthermore, we conduct comprehensive ablation studies\nthat uncover a series of noteworthy insights, including the presence of reward\nhacking in object detection, the emergence of the \"OD aha moment\", the impact\nof training data quality, and the scaling behavior of RL across different model\nsizes. Through these analyses, we aim to deepen the understanding of how\nreinforcement learning enhances the capabilities of vision-language models, and\nwe hope our findings and open-source contributions will support continued\nprogress in the vision-language RL community. Our code and model are available\nat https://github.com/om-ai-lab/VLM-R1","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T10:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.07620v1","title":"Equivariant recollements and singular equivalences","summary":"In this paper we investigate equivariant recollements of abelian (resp.\ntriangulated) categories. We first characterize when a recollement of abelian\n(resp. triangulated) categories induces an equivariant recollement, i.e. a\nrecollement between the corresponding equivariant abelian (resp. triangulated)\ncategories. We further investigate singular equivalences in the context of\nequivariant abelian recollements. In particular, we characterize when a\nsingular equivalence induced by the quotient functor in an abelian recollement\nlift to a singular equivalence induced by the equivariant quotient functor. As\napplications of our results: (i) we construct equivariant recollements for the\nderived category of a quasi-compact, quasi-separated scheme where the action is\ncoming from a subgroup of the automorphism group of the scheme and (ii) we\nderive new singular equivalences between certain skew group algebras.","main_category":"math.RT","categories":"math.RT,math.AG,math.CT,math.RA","published":"2025-04-10T10:08:23Z"}
{"aid":"http://arxiv.org/abs/2504.07622v1","title":"A new quasar strongly-lensed candidate by the galaxy cluster WHJ0400-27\n  with a $18''$ image-separation","summary":"Time-delay cosmography (TDC) using multiply-lensed quasars (QSOs) by galaxies\nhas recently emerged as an independent and competitive tool to measure the\nvalue of the Hubble constant. Lens galaxy clusters hosting multiply-imaged\nQSOs, when coupled with an accurate and precise knowledge of their total mass\ndistribution, are equally powerful cosmological probes. However, less than ten\nsuch systems have been identified to date. Our study aims to expand the limited\nsample of cluster-lensed QSO systems by identifying new candidates within rich\ngalaxy clusters. Starting from a sample of ~$10^5$ galaxy cluster candidates\n(Wen & Han, 2022), built from Dark Energy Survey and Wide-field Infrared Survey\nExplorer imaging data, and a highly-pure catalogue of over one million QSOs,\nbased on Gaia DR3 data, we cross-correlate them to identify candidate lensed\nQSOs near the core of massive galaxy clusters. Our search yielded 3 lensed\ndouble candidates over an area of ~$5000$ sq. degree. In this work, we focus on\nthe best candidate consisting of a double QSO with Gaia-based redshift of 1.35,\nprojected behind a moderately rich cluster (WHJ0400-27) at $z_{phot}=0.65$.\nBased on a first spectroscopic follow-up study, we confirm the two QSOs at\n$z=1.345$, with indistinguishable spectra, and a brightest cluster galaxy at\n$z=0.626$. These observations seem to support the strong lensing nature of this\nsystem, although some tension emerges when the cluster mass from a preliminary\nlens model is compared with that from other mass proxies. We also discuss the\npossibility that such system is a rare physical association of two distinct\nQSOs with a projected physical distance of ~$150$ kpc. If further spectroscopic\nobservations confirm its lensing nature, such a rare lens system would exhibit\none of the largest image separations observed to date\n($\\Delta\\vartheta=17.8''$), opening interesting TDC applications.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-10T10:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.07623v1","title":"Joint Travel Route Optimization Framework for Platooning","summary":"Platooning represents an advanced driving technology designed to assist\ndrivers in traffic convoys of varying lengths, enhancing road safety, reducing\ndriver fatigue, and improving fuel efficiency. Sophisticated automated driving\nassistance systems have facilitated this innovation. Recent advancements in\nplatooning emphasize cooperative mechanisms within both centralized and\ndecentralized architectures enabled by vehicular communication technologies.\nThis study introduces a cooperative route planning optimization framework aimed\nat promoting the adoption of platooning through a centralized platoon formation\nstrategy at the system level. This approach is envisioned as a transitional\nphase from individual (ego) driving to fully collaborative driving.\nAdditionally, this research formulates and incorporates travel cost metrics\nrelated to fuel consumption, driver fatigue, and travel time, considering\nregulatory constraints on consecutive driving durations. The performance of\nthese cost metrics has been evaluated using Dijkstra's and A* shortest path\nalgorithms within a network graph framework. The results indicate that the\nproposed architecture achieves an average cost improvement of 14 % compared to\nindividual route planning for long road trips.","main_category":"cs.ET","categories":"cs.ET,cs.RO,cs.SY,eess.SY","published":"2025-04-10T10:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.07627v1","title":"Robustness of Online Identification-based Policy Iteration to Noisy Data","summary":"This article investigates the core mechanisms of indirect data-driven control\nfor unknown systems, focusing on the application of policy iteration (PI)\nwithin the context of the linear quadratic regulator (LQR) optimal control\nproblem. Specifically, we consider a setting where data is collected\nsequentially from a linear system subject to exogenous process noise, and is\nthen used to refine estimates of the optimal control policy. We integrate\nrecursive least squares (RLS) for online model estimation within a\ncertainty-equivalent framework, and employ PI to iteratively update the control\npolicy. In this work, we investigate first the convergence behavior of RLS\nunder two different models of adversarial noise, namely point-wise and energy\nbounded noise, and then we provide a closed-loop analysis of the combined model\nidentification and control design process. This iterative scheme is formulated\nas an algorithmic dynamical system consisting of the feedback interconnection\nbetween two algorithms expressed as discrete-time systems. This system\ntheoretic viewpoint on indirect data-driven control allows us to establish\nconvergence guarantees to the optimal controller in the face of uncertainty\ncaused by noisy data. Simulations illustrate the theoretical results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T10:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.07638v1","title":"Predicting the Lifespan of Industrial Printheads with Survival Analysis","summary":"Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.07657v1","title":"Single-Pixel Imaging Technology in Holographic Microscopy","summary":"We propose a holographic microscopy method based on single-pixel imaging\ntechnology (HM-SPI). We used a holographic microscopy method based on in-line\nGabor holography. In single-pixel imaging technology, cyclic binary masks and\namplitude-phase masks are used instead of cyclic Hadamard masks. These masks\nare generated using the quadratic residue and twin-prime techniques. Numerical\nresults are presented for both cases. Unlike the traditional approach of using\nDMD technology, our model considers a photodetector as a single-pixel detector.\nWe propose a method based on the fast Fourier transform (FFT) algorithm to\nreconstruct the original field, which has a computational complexity of\nO(NlogN). This approach opens up prospects for the development of compact\nholographic systems capable of operating across a wide spectral range and under\nlimited computational resources.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.07669v1","title":"Languages of Boundedly-Ambiguous Vector Addition Systems with States","summary":"The aim of this paper is to deliver broad understanding of a class of\nlanguages of boundedly-ambiguous VASS, that is k-ambiguous VASS for some\nnatural k. These are languages of Vector Addition Systems with States with the\nacceptance condition defined by the set of accepting states such that each\naccepted word has at most k accepting runs. We develop tools for proving that a\ngiven language is not accepted by any k-ambiguous VASS. Using them we show a\nfew negative results: lack of some closure properties of languages of\nk-ambiguous VASS and undecidability of the k-ambiguity problem, namely the\nquestion whether a given VASS language is a language of some k-ambiguous VASS.\nFinally, we show that the regularity problem is decidable for k-ambiguous VASS.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-10T11:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.07674v1","title":"Is the atmospheric river operating at a self-organized criticality\n  state?","summary":"Atmospheric rivers (ARs) are essential components of the global hydrological\ncycle, with profound implications for water resources, extreme weather events,\nand climate dynamics. Yet, the statistical organization and underlying physical\nmechanisms of AR intensity and evolution remain poorly understood. Here we\napply methods from statistical physics to analyze the full life cycle of ARs\nand identify universal signatures of self-organized criticality (SOC). We\ndemonstrate that AR morphology exhibits nontrivial fractal geometry, while AR\nevent sizes, quantified via integrated water vapor transport, follow robust\npower-law distributions, displaying finite-size scaling. These scaling\nbehaviors persist under warming scenarios, suggesting that ARs operate near a\ncritical state as emergent, self-regulating systems. Concurrently, we observe a\nsystematic poleward migration and intensification of ARs, linked to\nthermodynamic amplification and dynamical reorganization. Our findings\nestablish a statistical physics framework for ARs, linking critical phenomena\nto the spatiotemporal structure of extreme events in a warming climate.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T11:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.07675v1","title":"Low-Complexity Optimization of Antenna Switching Schemes for Dynamic\n  Channel Sounding","summary":"Understanding wireless channels is crucial for the design of wireless\nsystems. For mobile communication, sounders and antenna arrays with short\nmeasurement times are required to simultaneously capture the dynamic and\nspatial channel characteristics. Switched antenna arrays are an attractive\noption that can overcome the high cost of real arrays and the long measurement\ntimes of virtual arrays. Optimization of the switching sequences is then\nessential to avoid aliasing and increase the accuracy of channel parameter\nestimates. This paper provides a novel and comprehensive analysis of the design\nof switching sequences. We first review the conventional spatio-temporal\nambiguity function, extend it to dual-polarized antenna arrays, and analyze its\nprohibitive complexity when designing for ultra-massive antenna arrays. We thus\npropose a new method that uses the Fisher information matrix to tackle the\nestimation accuracy. We also propose to minimize the ambiguity by choosing a\nswitching sequence that minimizes side lobes in its Fourier spectrum. In this\nsense, we divide the sequence design problem into Fourier-based ambiguity\nreduction and Fisher-based accuracy improvement, and coin the resulting design\napproach as Fourier-Fisher. Simulations and measurements show that the\nFourier-Fisher approach achieves identical performance and significantly lower\ncomputational complexity than that of the conventional ambiguity-based\napproach.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:56:37Z"}
{"aid":"http://arxiv.org/abs/2504.07677v1","title":"Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal\n  Localization","summary":"Reliable localization is critical for robot navigation in complex indoor\nenvironments. In this paper, we propose an uncertainty-aware localization\nmethod that enhances the reliability of localization outputs without modifying\nthe prediction model itself. This study introduces a percentile-based rejection\nstrategy that filters out unreliable 3-DoF pose predictions based on aleatoric\nand epistemic uncertainties the network estimates. We apply this approach to a\nmulti-modal end-to-end localization that fuses RGB images and 2D LiDAR data,\nand we evaluate it across three real-world datasets collected using a\ncommercialized serving robot. Experimental results show that applying stricter\nuncertainty thresholds consistently improves pose accuracy. Specifically, the\nmean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean\norientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70%\nthresholds, respectively. Furthermore, the rejection strategy effectively\nremoves extreme outliers, resulting in better alignment with ground truth\ntrajectories. To the best of our knowledge, this is the first study to\nquantitatively demonstrate the benefits of percentile-based uncertainty\nrejection in multi-modal end-to-end localization tasks. Our approach provides a\npractical means to enhance the reliability and accuracy of localization systems\nin real-world deployments.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-10T12:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.07685v1","title":"Context-Aware Monolingual Human Evaluation of Machine Translation","summary":"This paper explores the potential of context-aware monolingual human\nevaluation for assessing machine translation (MT) when no source is given for\nreference. To this end, we compare monolingual with bilingual evaluations (with\nsource text), under two scenarios: the evaluation of a single MT system, and\nthe comparative evaluation of pairwise MT systems. Four professional\ntranslators performed both monolingual and bilingual evaluations by assigning\nratings and annotating errors, and providing feedback on their experience. Our\nfindings suggest that context-aware monolingual human evaluation achieves\ncomparable outcomes to human bilingual evaluations, and suggest the feasibility\nand potential of monolingual evaluation as an efficient approach to assessing\nMT.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-10T12:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.07686v1","title":"Measurements of Higgs boson production via gluon-gluon fusion and\n  vector-boson fusion using $H\\rightarrow WW^\\ast \\rightarrow \\ellν\\ellν$\n  decays in $pp$ collisions with the ATLAS detector and their effective field\n  theory interpretations","summary":"Higgs boson production cross-sections via gluon-gluon fusion and vector-boson\nfusion in proton-proton collisions are measured in the $H\\rightarrow WW^\\ast\n\\rightarrow \\ell\\nu\\ell\\nu$ decay channel. The Large Hadron Collider delivered\nproton-proton collisions at a centre-of-mass energy of $13\\,\\textrm{TeV}$\nbetween 2015 and 2018, which were recorded by the ATLAS detector, corresponding\nto an integrated luminosity of $140\\,\\textrm{fb}^{-1}$. The total\ncross-sections for Higgs boson production by gluon-gluon fusion and\nvector-boson fusion times the $H\\rightarrow WW^\\ast$ branching ratio are\nmeasured to be $12.4^{+1.3}_{-1.2}\\,\\textrm{pb}$ and\n$0.79^{+0.18}_{-0.16}\\,\\textrm{pb}$, respectively, in agreement with the\nStandard Model predictions. Higgs boson production is further characterised\nthrough measurements of Simplified Template Cross-Sections in a total of\nfifteen kinematic fiducial regions. A new scheme of kinematic fiducial regions\nhas been introduced to enhance the sensitivity to CP-violating effects in Higgs\nboson interactions. Both schemes are used to constrain CP-even and CP-odd\ndimension-six operators in the Standard Model effective field theory.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T12:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.07698v1","title":"Proactive User Information Acquisition via Chats on User-Favored Topics","summary":"Chat-oriented dialogue systems designed to provide tangible benefits, such as\nsharing the latest news or preventing frailty in senior citizens, often require\nProactive acquisition of specific user Information via chats on user-faVOred\nTopics (PIVOT). This study proposes the PIVOT task, designed to advance the\ntechnical foundation for these systems. In this task, a system needs to acquire\nthe answers of a user to predefined questions without making the user feel\nabrupt while engaging in a chat on a predefined topic. We found that even\nrecent large language models (LLMs) show a low success rate in the PIVOT task.\nWe constructed a dataset suitable for the analysis to develop more effective\nsystems. Finally, we developed a simple but effective system for this task by\nincorporating insights obtained through the analysis of this dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:32:16Z"}
{"aid":"http://arxiv.org/abs/2504.07705v1","title":"Electroweak baryogenesis in 2HDM without EDM cancellation","summary":"We study two Higgs doublet models with successful electroweak baryogenesis\nbut without cancellations of electric dipole moments (EDMs). For the\nbaryogenesis, additional scalar bosons are favored to couple mainly with the\ntop quark with CP violations. However, if they also couple to light fermions of\nthe Standard Model, the model is limited severely by EDMs, and additional CP\nphases irrelevant to the baryogenesis are often introduced to cancel the\ncontributions to the EDMs. Alternatively, we consider a scenario where the\nlight-fermion couplings are suppressed to avoid the constraints. In our\nscenario, it is found that the leading contributions arise in the top-quark\nEDMs at the two-loop level. They induce the electron, neutron, and proton EDMs\nvia radiative corrections. Since there is no additional CP-violating phase,\nthey are correlated with the baryon asymmetry. We show that our scenario is\ncompatible with the current experimental bounds and is within the scope of\nfuture EDM experiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T12:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.07724v1","title":"MRD-RAG: Enhancing Medical Diagnosis with Multi-Round\n  Retrieval-Augmented Generation","summary":"In recent years, accurately and quickly deploying medical large language\nmodels (LLMs) has become a significant trend. Among these, retrieval-augmented\ngeneration (RAG) has garnered significant attention due to its features of\nrapid deployment and privacy protection. However, existing medical RAG\nframeworks still have shortcomings. Most existing medical RAG frameworks are\ndesigned for single-round question answering tasks and are not suitable for\nmulti-round diagnostic dialogue. On the other hand, existing medical\nmulti-round RAG frameworks do not consider the interconnections between\npotential diseases to inquire precisely like a doctor. To address these issues,\nwe propose a Multi-Round Diagnostic RAG (MRD-RAG) framework that mimics the\ndoctor's diagnostic process. This RAG framework can analyze diagnosis\ninformation of potential diseases and accurately conduct multi-round diagnosis\nlike a doctor. To evaluate the effectiveness of our proposed frameworks, we\nconduct experiments on two modern medical datasets and two traditional Chinese\nmedicine datasets, with evaluations by GPT and human doctors on different\nmethods. The results indicate that our RAG framework can significantly enhance\nthe diagnostic performance of LLMs, highlighting the potential of our approach\nin medical diagnosis. The code and data can be found in our project website\nhttps://github.com/YixiangCh/MRD-RAG/tree/master.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T13:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.07731v1","title":"Adaptive Robust Unscented Kalman Filter for Dynamic State Estimation of\n  Power System","summary":"Non-Gaussian noise and the uncertainty of noise distribution are the common\nfactors that reduce accuracy in dynamic state estimation of power systems (PS).\nIn addition, the optimal value of the free coefficients in the unscented Kalman\nfilter (UKF) based on information theoretic criteria is also an urgent problem.\nIn this paper, a robust adaptive UKF (AUKF) under generalized minimum mixture\nerror entropy with fiducial points (GMMEEF) over improve Snow Geese algorithm\n(ISGA) (ISGA-GMMEEF-AUKF) is proposed to overcome the above difficulties. The\nestimation process of the proposed algorithm is based on several key steps\nincluding augmented regression error model (AREM) construction, adaptive state\nestimation, and free coefficients optimization. Specifically, an AREM\nconsisting of state prediction and measurement errors is established at the\nfirst step. Then, GMMEEF-AUKF is developed by solving the optimization problem\nbased on GMMEEF, which uses a generalized Gaussian kernel combined with mixture\ncorrentropy to enhance the flexibility further and resolve the data problem\nwith complex attributes and update the noise covariance matrix according to the\nAREM framework. Finally, the ISGA is designed to automatically calculate the\noptimal value of coefficients such as the shape coefficients of the kernel in\nthe GMMEEF criterion, the coefficients selection sigma points in unscented\ntransform, and the update coefficient of the noise covariance matrices fit with\nthe PS model. Simulation results on the IEEE 14, 30, and 57-bus test systems in\ncomplex scenarios have confirmed that the proposed algorithm outperforms the\nMEEF-UKF and UKF by an average efficiency of 26% and 65%, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T13:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.07735v1","title":"$q$-Differential Operators for $q$-Spinor Variables","summary":"In this paper we introduce the $q$-differential operator for $q$-spinor\nvariables. We establish the $q$-spinor chain rule , the new $q$-differential\noperator, the $q$-Dirac differential operators and the $q$-complex spinor\nintegrals. We also define the $q$-spinor differential equation. The suggestions\nfor further work at the end of the paper.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-10T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.07740v1","title":"Zero-Shot Cross-Domain Code Search without Fine-Tuning","summary":"Code search aims to retrieve semantically relevant code snippets for natural\nlanguage queries. While pre-trained language models (PLMs) have shown\nremarkable performance in this task, they struggle in cross-domain scenarios,\noften requiring costly fine-tuning or facing performance drops in zero-shot\nsettings. RAPID, which generates synthetic data for model fine-tuning, is\ncurrently the only effective method for zero-shot cross-domain code search.\nDespite its effectiveness, RAPID demands substantial computational resources\nfor fine-tuning and needs to maintain specialized models for each domain,\nunderscoring the need for a zero-shot, fine-tuning-free approach for\ncross-domain code search.\n  The key to tackling zero-shot cross-domain code search lies in bridging the\ngaps among domains. In this work, we propose to break the query-code matching\nprocess of code search into two simpler tasks: query-comment matching and\ncode-code matching. Our empirical study reveals the strong complementarity\namong the three matching schemas in zero-shot cross-domain settings, i.e.,\nquery-code, query-comment, and code-code matching. Based on the findings, we\npropose CodeBridge, a zero-shot, fine-tuning-free approach for cross-domain\ncode search. Specifically, CodeBridge uses Large Language Models (LLMs) to\ngenerate comments and pseudo-code, then combines query-code, query-comment, and\ncode-code matching via PLM-based similarity scoring and sampling-based fusion.\nExperimental results show that our approach outperforms the state-of-the-art\nPLM-based code search approaches, i.e., CoCoSoDa and UniXcoder, by an average\nof 21.4% and 24.9% in MRR, respectively, across three datasets. Our approach\nalso yields results that are better than or comparable to those of the\nzero-shot cross-domain code search approach RAPID, which requires costly\nfine-tuning.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-10T13:36:37Z"}
{"aid":"http://arxiv.org/abs/2504.07742v1","title":"Gradient-based Sample Selection for Faster Bayesian Optimization","summary":"Bayesian optimization (BO) is an effective technique for black-box\noptimization. However, its applicability is typically limited to\nmoderate-budget problems due to the cubic complexity in computing the Gaussian\nprocess (GP) surrogate model. In large-budget scenarios, directly employing the\nstandard GP model faces significant challenges in computational time and\nresource requirements. In this paper, we propose a novel approach,\ngradient-based sample selection Bayesian Optimization (GSSBO), to enhance the\ncomputational efficiency of BO. The GP model is constructed on a selected set\nof samples instead of the whole dataset. These samples are selected by\nleveraging gradient information to maintain diversity and representation. We\nprovide a theoretical analysis of the gradient-based sample selection strategy\nand obtain explicit sublinear regret bounds for our proposed framework.\nExtensive experiments on synthetic and real-world tasks demonstrate that our\napproach significantly reduces the computational cost of GP fitting in BO while\nmaintaining optimization performance comparable to baseline methods.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-10T13:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07744v1","title":"MMLA: Multi-Environment, Multi-Species, Low-Altitude Aerial Footage\n  Dataset","summary":"Real-time wildlife detection in drone imagery is critical for numerous\napplications, including animal ecology, conservation, and biodiversity\nmonitoring. Low-altitude drone missions are effective for collecting\nfine-grained animal movement and behavior data, particularly if missions are\nautomated for increased speed and consistency. However, little work exists on\nevaluating computer vision models on low-altitude aerial imagery and\ngeneralizability across different species and settings. To fill this gap, we\npresent a novel multi-environment, multi-species, low-altitude aerial footage\n(MMLA) dataset. MMLA consists of drone footage collected across three diverse\nenvironments: Ol Pejeta Conservancy and Mpala Research Centre in Kenya, and The\nWilds Conservation Center in Ohio, which includes five species: Plains zebras,\nGrevy's zebras, giraffes, onagers, and African Painted Dogs. We comprehensively\nevaluate three YOLO models (YOLOv5m, YOLOv8m, and YOLOv11m) for detecting\nanimals. Results demonstrate significant performance disparities across\nlocations and species-specific detection variations. Our work highlights the\nimportance of evaluating detection algorithms across different environments for\nrobust wildlife monitoring applications using drones.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.07752v1","title":"Linear relations between face numbers of levels in arrangements","summary":"We study linear relations between face numbers of levels in arrangements. Let\n$V = \\{ v_1, \\ldots, v_n \\} \\subset \\mathbf{R}^{r}$ be a vector configuration\nin general position, and let $\\mathcal{A}(V)$ be polar dual arrangement of\nhemispheres in the $d$-dimensional unit sphere $S^d$, where $d=r-1$. For $0\\leq\ns \\leq d$ and $0 \\leq t \\leq n$, let $f_{s,t}(V)$ denote the number of faces of\n\\emph{level} $t$ and dimension $d-s$ in the arrangement $\\mathcal{A}(V)$ (these\ncorrespond to partitions $V=V_-\\sqcup V_0 \\sqcup V_+$ by linear hyperplanes\nwith $|V_0|=s$ and $|V_-|=t$). We call the matrix $f(V):=[f_{s,t}(V)]$ the\n\\emph{$f$-matrix} of $V$.\n  Completing a long line of research on linear relations between face numbers\nof levels in arrangements, we determine, for every $n\\geq r \\geq 1$, the affine\nspace $\\mathfrak{F}_{n,r}$ spanned by the $f$-matrices of configurations of $n$\nvectors in general position in $\\mathbf{R}^r$; moreover, we determine the\nsubspace $\\mathfrak{F}^0_{n,r} \\subset \\mathfrak{F}_{n,r}$ spanned by all\n\\emph{pointed} vector configurations (i.e., such that $V$ is contained in some\nopen linear halfspace), which correspond to point sets in $\\mathbf{R}^d$. This\ngeneralizes the classical fact that the Dehn--Sommerville relations generate\nall linear relations between the face numbers of simple polytopes (the faces at\nlevel $0$) and answers a question posed by Andrzejak and Welzl in 2003.\n  The key notion for the statements and the proofs of our results is the\n$g$-matrix of a vector configuration, which determines the $f$-matrix and\ngeneralizes the classical $g$-vector of a polytope.\n  By Gale duality, we also obtain analogous results for partitions of vector\nconfigurations by sign patterns of nontrivial linear dependencies, and for\n\\emph{Radon partitions} of point sets in $\\mathbf{R}^d$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.07753v1","title":"Virtual-mask Informed Prior for Sparse-view Dual-Energy CT\n  Reconstruction","summary":"Sparse-view sampling in dual-energy computed tomography (DECT) significantly\nreduces radiation dose and increases imaging speed, yet is highly prone to\nartifacts. Although diffusion models have demonstrated potential in effectively\nhandling incomplete data, most existing methods in this field focus on the\nimage do-main and lack global constraints, which consequently leads to\ninsufficient reconstruction quality. In this study, we propose a dual-domain\nvirtual-mask in-formed diffusion model for sparse-view reconstruction by\nleveraging the high inter-channel correlation in DECT. Specifically, the study\ndesigns a virtual mask and applies it to the high-energy and low-energy data to\nperform perturbation operations, thus constructing high-dimensional tensors\nthat serve as the prior information of the diffusion model. In addition, a\ndual-domain collaboration strategy is adopted to integrate the information of\nthe randomly selected high-frequency components in the wavelet domain with the\ninformation in the projection domain, for the purpose of optimizing the global\nstruc-tures and local details. Experimental results indicated that the present\nmethod exhibits excellent performance across multiple datasets.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.07755v1","title":"Renormalization and blow ups for the nonlinear Schrödinger equation","summary":"Existence of finite-time blow ups in the classical one-dimensional nonlinear\nSchr\\\"odinger equation (NLS)\n  (1) i \\partial_t u + u_{x x} + |u|^{2r} u = 0, u(x,0) = u_0(x)\n  has been one of the central problems in the studies of the singularity\nformation in the PDEs.\n  We revisit this problem using an approach based on the ideas borrowed from\nDynamical Systems.\n  To that end, we reformulate the initial value problem for (1), with r \\in\n\\mathbb{N}, r \\ge 1, as a fixed point problem for a certain renormalization\noperator, and use the ideas of apriori bounds to prove existence of a\nrenormalization fixed point. Existence of such fixed points leads to existence\nof self-similar solutions of the form\n  u(x,t) = (T-t)^{-{1 \\over 2 r}} U((T-t)^{-{1 \\over 2}} x),\n  whose L^{2 r +2}-norms are bounded up-to a finite time T and whose energy\nblows up at T.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:55:08Z"}
{"aid":"http://arxiv.org/abs/2504.07764v1","title":"A note on extendable sets of colorings and rooted minors","summary":"DeVos and Seymour (2003) proved that for every set $C$ of 3-colorings of a\nset $X$ of vertices, there exists a plane graph $G$ with vertices of $X$\nincident with the outer face such that a 3-coloring of $X$ extends to a\n3-coloring of $G$ if and only if it belongs to $C$. We prove a generalization\nof this claim for $k$-colorings of $X$-rooted-$K_{k+1}$-minor-free\n$K_{k+2}$-minor-free graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T14:03:41Z"}
{"aid":"http://arxiv.org/abs/2504.07766v1","title":"Realigning Incentives to Build Better Software: a Holistic Approach to\n  Vendor Accountability","summary":"In this paper, we ask the question of why the quality of commercial software,\nin terms of security and safety, does not measure up to that of other (durable)\nconsumer goods we have come to expect. We examine this question through the\nlens of incentives. We argue that the challenge around better quality software\nis due in no small part to a sequence of misaligned incentives, the most\ncritical of which being that the harm caused by software problems is by and\nlarge shouldered by consumers, not developers. This lack of liability means\nsoftware vendors have every incentive to rush low-quality software onto the\nmarket and no incentive to enhance quality control. Within this context, this\npaper outlines a holistic technical and policy framework we believe is needed\nto incentivize better and more secure software development. At the heart of the\nincentive realignment is the concept of software liability. This framework\ntouches on various components, including legal, technical, and financial, that\nare needed for software liability to work in practice; some currently exist,\nsome will need to be re-imagined or established. This is primarily a\nmarket-driven approach that emphasizes voluntary participation but highlights\nthe role appropriate regulation can play. We connect and contrast this with the\nEU legal environment and discuss what this framework means for open-source\nsoftware (OSS) development and emerging AI risks. Moreover, we present a\nCrowdStrike case study complete with a what-if analysis had our proposed\nframework been in effect. Our intention is very much to stimulate a robust\nconversation among both researchers and practitioners.","main_category":"cs.CR","categories":"cs.CR,cs.SE,econ.TH","published":"2025-04-10T14:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.07769v1","title":"Inflection Point Inflation in Supergravity","summary":"In this paper, we study the inflection point inflation generated by a\npolynomial superpotential and a canonical K\\\"ahler potential under the\nsupergravity framework, where only one chiral superfield is needed. We find\nthat the special form of the scalar potential limits the inflationary Hubble\nparameter to values $\\lesssim 10^{10}\\, \\textrm{GeV}$ and the inflaton mass to\n$\\lesssim 10^{11} \\, \\textrm{GeV}$. We obtain analytic results for small field\ncases and present numerical results for large field ones. We find the\ntensor-to-scalar ratio $r<10^{-8}$ is always suppressed in these models, while\nthe running of spectral index $\\alpha\\approx \\mathcal{O}(-10^{-3})$ may be\ntestable in next-generation CMB experiments. We also discuss the possible\neffects of SUSY breaking Polonyi term presented in the superpotential where we\nfind a general upper bound for the SUSY breaking scale for a given value of the\nHubble parameter.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:08:14Z"}
{"aid":"http://arxiv.org/abs/2504.07772v1","title":"Extremum Seeking Boundary Control for Euler-Bernoulli Beam PDEs","summary":"This paper presents the design and analysis of an extremum seeking (ES)\ncontroller for scalar static maps in the context of infinite-dimensional\ndynamics governed by the 1D Euler-Bernoulli (EB) beam Partial Differential\nEquation (PDE). The beam is actuated at one end (using position and moment\nactuators). The map's input is the displacement at the beam's uncontrolled end,\nwhich is subject to a sliding boundary condition. Notably, ES for this class of\nPDEs remains unexplored in the existing literature. To compensate for PDE\nactuation dynamics, we employ a boundary control law via a backstepping\ntransformation and averaging-based estimates for the gradient and Hessian of\nthe static map to be optimized. This compensation controller leverages a\nSchr\\\"odinger equation representation of the EB beam and adapts existing\nbackstepping designs to stabilize the beam. Using the semigroup and averaging\ntheory in infinite dimensions, we prove local exponential convergence to a\nsmall neighborhood of the unknown optimal point. Finally, simulations\nillustrate the effectiveness of the design in optimizing the unknown static\nmap.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T14:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07776v1","title":"SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified\n  Flow","summary":"Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-10T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.07792v1","title":"Breaking the Barriers: Video Vision Transformers for Word-Level Sign\n  Language Recognition","summary":"Sign language is a fundamental means of communication for the deaf and\nhard-of-hearing (DHH) community, enabling nuanced expression through gestures,\nfacial expressions, and body movements. Despite its critical role in\nfacilitating interaction within the DHH population, significant barriers\npersist due to the limited fluency in sign language among the hearing\npopulation. Overcoming this communication gap through automatic sign language\nrecognition (SLR) remains a challenge, particularly at a dynamic word-level,\nwhere temporal and spatial dependencies must be effectively recognized. While\nConvolutional Neural Networks have shown potential in SLR, they are\ncomputationally intensive and have difficulties in capturing global temporal\ndependencies between video sequences. To address these limitations, we propose\na Video Vision Transformer (ViViT) model for word-level American Sign Language\n(ASL) recognition. Transformer models make use of self-attention mechanisms to\neffectively capture global relationships across spatial and temporal\ndimensions, which makes them suitable for complex gesture recognition tasks.\nThe VideoMAE model achieves a Top-1 accuracy of 75.58% on the WLASL100 dataset,\nhighlighting its strong performance compared to traditional CNNs with 65.89%.\nOur study demonstrates that transformer-based architectures have great\npotential to advance SLR, overcome communication barriers and promote the\ninclusion of DHH individuals.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07795v1","title":"Measurement of coincident photon-initiated processes in ultra-peripheral\n  Pb+Pb collisions with the ATLAS detector","summary":"The Lorentz-contracted electromagnetic fields of the ions in\nultra-relativistic heavy-ion collisions generate intense quasi-real photon\nfluxes. These lead to photon-induced interactions that are observed in\nultra-peripheral collisions (UPCs), such as vector meson and lepton-pair\nproduction. The high photon flux also enables the occurrence of multiple\nphoton-induced processes in a single collision. Presented is the first\nmeasurement of the coincident production of $\\gamma\\gamma \\rightarrow\n\\mu^{+}\\mu^{-}$ and $\\gamma+A\\rightarrow\\rho^{0}+A$ in UPC Pb+Pb collisions at\ncentre-of-mass energies of 5.02 TeV and 5.36 TeV with the ATLAS detector at the\nLarge Hadron Collider. The rate of the coincident process relative to the\nexclusive $\\gamma\\gamma \\rightarrow \\mu^{+}\\mu^{-}$ process is measured\ndifferentially in intervals of forward event activity, quantified by the Zero\nDegree Calorimeters. The relative rate, summed over forward event activity, for\nthe coincident $\\rho^{0}$ production is measured to be\n$(9.3\\,\\pm0.4\\,\\mathrm{(stat.)}\\,\\pm0.2\\,\\mathrm{(syst.)})\\times10^{-3}$.\nCorrelations between the dimuon kinematic properties, such as its mass, and the\ncoincident $\\rho^{0}$ meson production rate, are also presented. These\nmeasurements confirm the presence of multi photon-induced processes in UPC\ncollisions, and can provide new insight into the impact parameter dependence of\nphoton-induced vector meson production.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-10T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07809v1","title":"A Riemannian Gradient Descent Method for the Least Squares Inverse\n  Eigenvalue Problem","summary":"We address an algorithm for the least squares fitting of a subset of the\neigenvalues of an unknown Hermitian matrix lying an an affine subspace, called\nthe Lift and Projection (LP) method, due to Chen and Chu (SIAM Journal on\nNumerical Analysis, 33 (1996), pp.2417-2430). The LP method iteratively `lifts'\nthe current iterate onto the spectral constraint manifold then 'projects' onto\nthe solution's affine subspace. We prove that this is equivalent to a\nRiemannian Gradient Descent with respect to a natural Riemannian metric. This\ninsight allows us to derive a more efficient implementation, analyse more\nprecisely its global convergence properties, and naturally append additional\nconstraints to the problem. We provide several numerical experiments to\ndemonstrate the improvement in computation time, which can be more than an\norder of magnitude if the eigenvalue constraints are on the smallest\neigenvalues, the largest eigenvalues, or the eigenvalues closest to a given\nnumber. These experiments include an inverse eigenvalue problem arising in\nInelastic Neutron Scattering of Manganese-6, which requires the least squares\nfitting of 16 experimentally observed eigenvalues of a $32400\\times32400$\nsparse matrix from a 5-dimensional subspace of spin Hamiltonian matrices.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T14:47:16Z"}
{"aid":"http://arxiv.org/abs/2504.07811v1","title":"The ISC Creator: Human-Centered Design of Learning Analytics Interactive\n  Indicator Specification Cards","summary":"Emerging research on human-centered learning analytics (HCLA) has\ndemonstrated the importance of involving diverse stakeholders in co-designing\nlearning analytics (LA) systems. However, there is still a demand for effective\nand efficient methods to co-design LA dashboards and indicators. Indicator\nSpecification Cards (ISCs) have been introduced recently to facilitate the\nsystematic co-design of indicators by different LA stakeholders. In this paper,\nwe strive to enhance the user experience and usefulness of the ISC-based\nindicator design process. Towards this end, we present the systematic design,\nimplementation, and evaluation details of the ISC Creator, an interactive LA\ntool that allows low-cost and flexible design of LA indicators. Our findings\ndemonstrate the importance of carefully considered interactivity and\nrecommendations for orienting and supporting non-expert LA stakeholders to\ndesign custom LA indicators.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-10T14:49:47Z"}
{"aid":"http://arxiv.org/abs/2504.07820v1","title":"Smoothed Distance Kernels for MMDs and Applications in Wasserstein\n  Gradient Flows","summary":"Negative distance kernels $K(x,y) := - \\|x-y\\|$ were used in the definition\nof maximum mean discrepancies (MMDs) in statistics and lead to favorable\nnumerical results in various applications. In particular, so-called slicing\ntechniques for handling high-dimensional kernel summations profit from the\nsimple parameter-free structure of the distance kernel. However, due to its\nnon-smoothness in $x=y$, most of the classical theoretical results, e.g. on\nWasserstein gradient flows of the corresponding MMD functional do not longer\nhold true. In this paper, we propose a new kernel which keeps the favorable\nproperties of the negative distance kernel as being conditionally positive\ndefinite of order one with a nearly linear increase towards infinity and a\nsimple slicing structure, but is Lipschitz differentiable now. Our construction\nis based on a simple 1D smoothing procedure of the absolute value function\nfollowed by a Riemann-Liouville fractional integral transform. Numerical\nresults demonstrate that the new kernel performs similarly well as the negative\ndistance kernel in gradient descent methods, but now with theoretical\nguarantees.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.FA,math.PR","published":"2025-04-10T14:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07823v1","title":"A new look into the atmospheric composition of WASP-39 b","summary":"Being one of the first exoplanets observed by the James Webb Space Telescope\n(JWST), WASP-39 b has become an iconic target and many transit spectra recorded\nwith different instruments (NIRISS, NIRCAM, NIRSpec G395H, NIRSpec PRISM and\nMIRI) are currently available, allowing in-depth studies of its atmosphere. We\npresent here a novel approach to interpret WASP-39 b's transit spectroscopic\ndata, consisting of a multi-step process where ab initio equilibrium chemistry\nmodels and blind retrievals are used iteratively to find physically robust,\noptimal solutions. Following this approach, we have identified a new scenario\nto explain WASP-39 b's atmospheric composition, in which silicon-based\nchemistry plays a major role. In this scenario, SiO may explain the spectral\nabsorption at 4.1 $\\mu$m, currently interpreted as being due to SO$_2$. SiO and\nthe other gas species identified by the retrieval models, i.e. H$_2$O, CO$_2$,\nNa and K, are consistent with an atmosphere in chemical equilibrium with a\ntemperature-pressure profile constrained by H$_2$O and CO$_2$ absorption bands.\nIn addition, silicate clouds and hazes can produce the spectral features\nobserved by MIRI in the spectral window 5-12 $\\mu$m. While we advocate the need\nfor more data, possibly at higher spectral resolution, to confirm our results\nfor WASP-39 b's atmospheric composition, we highlight a refined atmospheric\nretrieval strategy with pre-selection and post-reconstruction to guide the next\ngeneration of transit spectroscopy.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-10T15:01:28Z"}
{"aid":"http://arxiv.org/abs/2504.07824v1","title":"Go Figure: Transparency in neuroscience images preserves context and\n  clarifies interpretation","summary":"Visualizations are vital for communicating scientific results. Historically,\nneuroimaging figures have only depicted regions that surpass a given\nstatistical threshold. This practice substantially biases interpretation of the\nresults and subsequent meta-analyses, particularly towards non-reproducibility.\nHere we advocate for a \"transparent thresholding\" approach that not only\nhighlights statistically significant regions but also includes subthreshold\nlocations, which provide key experimental context. This balances the dual needs\nof distilling modeling results and enabling informed interpretations for modern\nneuroimaging. We present four examples that demonstrate the many benefits of\ntransparent thresholding, including: removing ambiguity, decreasing\nhypersensitivity to non-physiological features, catching potential artifacts,\nimproving cross-study comparisons, reducing non-reproducibility biases, and\nclarifying interpretations. We also demonstrate the many software packages that\nimplement transparent thresholding, several of which were added or streamlined\nrecently as part of this work. A point-counterpoint discussion addresses issues\nwith thresholding raised in real conversations with researchers in the field.\nWe hope that by showing how transparent thresholding can drastically improve\nthe interpretation (and reproducibility) of neuroimaging findings, more\nresearchers will adopt this method.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-10T15:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.07826v1","title":"MuSaRoNews: A Multidomain, Multimodal Satire Dataset from Romanian News\n  Articles","summary":"Satire and fake news can both contribute to the spread of false information,\neven though both have different purposes (one if for amusement, the other is to\nmisinform). However, it is not enough to rely purely on text to detect the\nincongruity between the surface meaning and the actual meaning of the news\narticles, and, often, other sources of information (e.g., visual) provide an\nimportant clue for satire detection. This work introduces a multimodal corpus\nfor satire detection in Romanian news articles named MuSaRoNews. Specifically,\nwe gathered 117,834 public news articles from real and satirical news sources,\ncomposing the first multimodal corpus for satire detection in the Romanian\nlanguage. We conducted experiments and showed that the use of both modalities\nimproves performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T15:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07830v1","title":"MOSAIC: Modeling Social AI for Content Dissemination and Regulation in\n  Multi-Agent Simulations","summary":"We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SI","published":"2025-04-10T15:06:54Z"}
{"aid":"http://arxiv.org/abs/2504.07834v1","title":"Inverse Design of Block Polymer Materials with Desired Nanoscale\n  Structure and Macroscale Properties","summary":"The rational design of novel polymers with tailored material properties has\nbeen a long-standing challenge in the field due to the large number of possible\npolymer design variables. To accelerate this design process, there is a\ncritical need to develop novel tools to aid in the inverse design process and\nefficiently explore the high-dimensional polymer design space. Optimizing\nmacroscale material properties for polymeric systems is difficult as properties\nare dictated by features on a multitude of length scales, ranging from the\nchosen monomer chemistries to the chain level design to larger-scale domain\nstructures. In this work, we present an efficient high-throughput in-silico\nbased framework to effectively design high-performance polymers with desired\nmulti-scale nanostructure and macroscale properties, which we call RAPSIDY 2.0\n- Rapid Analysis of Polymer Structure and Inverse Design strategY 2.0. This new\nversion of RAPSIDY builds upon our previous work, RAPSIDY 1.0, which focused\npurely on identifying polymer designs that stabilized a desired nanoscale\nmorphology. In RAPSIDY 2.0 we use a combination of molecular dynamics\nsimulations and Bayesian optimization driven active learning to optimally query\nhigh-dimensional polymer design spaces and propose promising design candidates\nthat simultaneously stabilize a selected nanoscale morphology and exhibit\ndesired macroscale material properties. We utilize MD simulations with polymer\nchains preplaced into selected nanoscale morphologies and perform virtual\nexperiments to determine the stability of the chosen polymer design within the\ntarget morphology and calculate the desired macroscale material properties\n(e.g., thermal conductivity). Our methodology directly addresses the unique\nchallenge associated with copolymers, whose macroscale properties are a\nfunction of both their chain design and mesoscale morphology, which are\ncoupled.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.07836v1","title":"AerialVG: A Challenging Benchmark for Aerial Visual Grounding by\n  Exploring Positional Relations","summary":"Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T15:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.07840v1","title":"Understanding Learner-LLM Chatbot Interactions and the Impact of\n  Prompting Guidelines","summary":"Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CL","published":"2025-04-10T15:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07850v1","title":"Probabilistic Multi-Criteria Decision-Making for Circularity Performance\n  of Modern Methods of Construction Products","summary":"The construction industry faces increasingly more significant pressure to\nreduce resource consumption, minimise waste, and enhance environmental\nperformance. Towards the transition to a circular economy in the construction\nindustry, one of the challenges is the lack of a standardised assessment\nframework and methods to measure circularity at the product level. To support a\nmore sustainable and circular construction industry through robust and enhanced\nscenario analysis, this paper integrates probabilistic analysis into the\ncoupled assessment framework; this research addresses uncertainties associated\nwith multiple criteria and diverse stakeholders in the construction industry to\nenable more robust decision-making support on both circularity and\nsustainability performance. By demonstrating the application in three\nreal-world MMC products, the proposed framework offers a novel approach to\nsimultaneously assess the circularity and sustainability of MMC products with\nrobustness and objectiveness.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.AP","published":"2025-04-10T15:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.07860v1","title":"Conformally weighted Einstein manifolds: the uniqueness problem","summary":"We discuss smooth metric measure spaces admitting two weighted Einstein\nrepresentatives of the same weighted conformal class. First, we describe the\nlocal geometries of such manifolds in terms of certain Einstein and\nquasi-Einstein warped products. Secondly, a global classification result is\nobtained when one of the underlying metrics is complete, showing that either it\nis a weighted space form, a special Einstein warped product, or a specific\nfamily of quasi-Einstein warped products. As a consequence, it must be a\nweighted sphere in the compact case.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.07862v1","title":"Resummation of Universal Tails in Gravitational Waveforms","summary":"We present a formula for the universal anomalous scaling of the multipole\nmoments of a generic gravitating source in classical general relativity. We\nderive this formula in two independent ways using effective field theory\nmethods. First, we use the absorption of low frequency gravitational waves by a\nblack hole to identify the total multipole scaling dimension as the\nrenormalized angular momentum of black hole perturbation theory. More\ngenerally, we show that the anomalous dimension is determined by phase shifts\nof gravitational waves elastically scattering off generic source multipole\nmoments, which reproduces the renormalized angular momentum in the particular\ncase of black holes. The effective field theory approach thus clarifies the\nrole of the renormalized angular momentum in the multipole expansion. The\nuniversality of the point-particle effective description of compact gravitating\nsystems further allows us to extract the universal part of the anomalous\ndimension, which is the same for any object, including black holes, neutron\nstars, and binary systems. As an application, we propose a novel resummation of\nthe universal short-distance logarithms (``tails'') in the gravitational\nwaveform of binary systems, which may improve the modeling of signals from\ncurrent and future gravitational wave experiments.","main_category":"hep-th","categories":"hep-th,astro-ph.HE,gr-qc,hep-ph","published":"2025-04-10T15:39:05Z"}
{"aid":"http://arxiv.org/abs/2504.07865v1","title":"Equidistribution in 2-Nilpotent Polish Groups and triple restricted\n  sumsets","summary":"The aim of this paper is to establish a Ratner-type equidistribution theorem\nfor orbits on homogeneous spaces associated with \\(2\\)-nilpotent locally\ncompact Polish groups under the action of a countable discrete abelian group.\nWe apply this result to establish the existence of triple restricted sumsets in\nsubsets of positive density in arbitrary countable discrete abelian groups,\nsubject to a necessary finiteness condition.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-10T15:40:48Z"}
{"aid":"http://arxiv.org/abs/2504.07876v1","title":"Quintessence models in the late Universe","summary":"Scalar-tensor theories have shown great potential in inducing tailored\nmodifications compared to cosmic evolution in the $\\Lambda$CDM model. We\nreconsider quintessence models in this work in the context of three driving\npotentials. We center the action of these models in the late Universe which\nleaves early $\\Lambda$CDM cosmology unchanged. The effects show the potential\nof producing a faster expanding cosmology with a high Hubble constant. The\nmodels are constrained using the cosmic chronometer data, Pantheon plus, and\ntransversal baryonic acoustic oscillation data.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.07877v1","title":"Gauge and parametrization dependence of Quantum Einstein Gravity within\n  the Proper Time flow","summary":"Proper time functional flow equations have garnered significant attention in\nrecent years, as they are particularly suitable in analyzing non-perturbative\ncontexts. By resorting to this flow, we investigate the regulator and gauge\ndependence in quantum Einstein gravity within the asymptotic safety framework,\nconsidering various regularization schemes. Our findings indicate that some\ndetails of the regulator have minor influence on the critical properties of the\ntheory. In contrast, the selection between linear and exponential\nparametrizations appears to have a more substantial impact on the scaling\nbehavior of the renormalized flow near the non-Gaussian fixed point.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T15:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.07880v1","title":"Sculpting the outer edge of accretion disks in pre-circumbinary binary\n  black hole systems","summary":"Binary black hole systems (BBHs) have become a vivid reality in astrophysics\nas stellar-mass black hole mergers are now detected through their related\ngravitational wave emission during the merger stage. If many studies were\nrecently dedicated to the last stages of BBH where black holes are surrounded\nby a circumbinary disk (CBD), the structure of these systems prior to the\nformation of the CBD remains mostly unexplored. The aim of the present article\nis to investigate the potential modifications induced by the presence of a\nsecondary black hole onto the structure of the accretion disk surrounding the\nprimary black hole. We performed 2D classical hydrodynamical simulations of an\naccretion disk surrounding the primary black hole while taking into account all\ngravitational effects induced by both the primary black hole and the secondary\nblack hole orbiting on circular orbits around the center of mass of the\nsystem.We report three main effects of the presence of a secondary black hole\norbiting a circular orbit beyond the outer edge of the accretion disk: 1/ the\nouter radius of the accretion disk is significantly reduced and its ratio to\nthe black hole separation is directly linked to only the mass ratio of the\nblack holes; 2/ two spiral arms are visible in the gas density structure of the\ndisk and 3/ the outer edge of the accretion disk exhibits an elliptical shape\nthat mainly depends on the mass ratio of the black holes. Our results show that\nan accretion disk orbiting a primary black hole in a pre-CBD BBH exhibits\nspecific features induced by the gravitational force generated by the presence\nof a secondary black hole beyond its outer edge. Such features, directly linked\nto the binary separation and mass ratio, has therefore the potential to help in\nthe search and identification of BBH in the pre-CBD stage.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-10T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.07884v1","title":"CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and\n  Categorical Variables","summary":"This study focuses on mixed-variable black-box optimization (MV-BBO),\naddressing continuous, integer, and categorical variables. Many real-world\nMV-BBO problems involve dependencies among these different types of variables,\nrequiring efficient methods to optimize them simultaneously. Recently,\nstochastic optimization methods leveraging the mechanism of the covariance\nmatrix adaptation evolution strategy have shown promising results in\nmixed-integer or mixed-category optimization. However, such methods cannot\nhandle the three types of variables simultaneously. In this study, we propose\nCatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that\njointly optimizes continuous, integer, and categorical variables. CatCMAwM is\ndeveloped by incorporating a novel integer handling into CatCMA, a\nmixed-category black-box optimization method employing a joint distribution of\nmultivariate Gaussian and categorical distributions. The proposed integer\nhandling is carefully designed by reviewing existing integer handlings and\nfollowing the design principles of CatCMA. Even when applied to mixed-integer\nproblems, it stabilizes the marginal probability and improves the convergence\nperformance of continuous variables. Numerical experiments show that CatCMAwM\neffectively handles the three types of variables, outperforming\nstate-of-the-art Bayesian optimization methods and baselines that simply\nincorporate existing integer handlings into CatCMA.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T15:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.07885v1","title":"Self-Evaluated Expertise in experimental physics: a measure of students'\n  physics self-recognition","summary":"We introduce and theoretically justify a new measure of the self-recognition\ncomponent of student physics identity called Self-Evaluated Expertise (SEE).\nThis measure is constructed such that it can be extracted from existing\nresponses to the E-CLASS. In this work, we compare scores from SEE with the\ntraditional measure calculated from the E-CLASS, which probes student views\nabout experimental physics, to show that the SEE score is a quantitatively\ndifferent measure. Consequently, we show that student self-recognition\ndecreases from pre-instruction administration of the E-CLASS to the\npost-instruction administration when averaged across data from 494 courses\nhaving taken place between 2016--2019.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-10T15:59:27Z"}
{"aid":"http://arxiv.org/abs/2504.07888v1","title":"The Role of Buffer Gas in Shaping the D1 Line Spectrum of Potassium\n  Vapour","summary":"In this study, we investigate the effect of buffer gas and magnetic field on\nthe spectral line shapes of the potassium D1 transition using sealed vapour\ncells filled with varying amounts of neon as a buffer gas. Employing a\ndual-temperature control system, we independently manipulate the cell body and\nstem temperatures to explore Doppler and collisional effects on the spectrum.\nOur results show how the Voigt spectral profile changes from Gaussian- to\nLorentzian-dominated forms due to pressure broadening and shifts caused by\ncollisions between potassium atoms and neon. Our measurements are in excellent\nagreement with the literature values for potassium-neon collisions. For the\nfirst time we were able to incorporate the buffer-gas shift and broadening into\nthe modified Voigt profile via the ElecSus code, and found excellent agreement\nbetween the predicted and measured line profiles. We also analyse the potassium\nD1 spectral lines in the hyperfine Paschen-Back regime using strong magnetic\nfields, demonstrating how Zeeman splitting modifies the pressure-broadened line\nshape. This work provides valuable insights into collision-induced broadening\nand shifts, enhancing our understanding of potassium spectroscopy and its\napplication in the development of advanced magneto-optical filters for solar\nphysics and other applications.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.optics","published":"2025-04-10T16:01:57Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07891v1","title":"SpecReason: Fast and Accurate Inference-Time Compute via Speculative\n  Reasoning","summary":"Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves 1.5-2.5$\\times$ speedup over vanilla LRM inference while improving\naccuracy by 1.0-9.9\\%. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional 19.4-44.2\\% latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T16:05:19Z"}
{"aid":"http://arxiv.org/abs/2504.07892v1","title":"Orbit design for mitigating interstellar scattering effects in\n  Earth-space VLBI observations of Sgr A*","summary":"(abridged) The black hole Sagittarius A* (Sgr A*) is a prime target for\nnext-generation Earth-space very-long-baseline interferometry missions such as\nthe Black Hole Explorer (BHEX), which aims to probe baselines of the order of\n20 G$\\lambda$. At these baselines, Sgr A* observations will be affected by the\ndiffractive scattering effects from the interstellar medium (ISM). Therefore,\nwe study how different parameter choices for turbulence in the ISM affect\nBHEX's observational capabilities to probe strong lensing features of Sgr A*.\nBy using a simple geometric model of concentric Gaussian rings for Sgr A*'s\nphoton ring signal and observing at 320 GHz, we find that the BHEX-ALMA\nbaseline has the required sensitivity to observe Sgr A* for a broad range of\nvalues of the power-law index of density fluctuations in the ISM and the inner\nscale of turbulence. For other baselines with moderate sensitivities, a strong\nneed for observations at shorter scales of $\\approx$ 13.5 G$\\lambda$ is\nidentified. For this purpose, an orbit migration scheme is proposed. It is\nmodeled using both chemical propulsion (CP)-based Hohmann transfers and\nelectric propulsion (EP)-based orbit raising with the result that a CP-based\ntransfer can be performed in a matter of hours, but with a significantly higher\nfuel requirement as compared to EP, which however requires a transfer time of\naround 6 weeks. The consequences of these orbits for probing Sgr A*'s spacetime\nis studied by quantifying the spatial resolution, temporal resolution and the\nangular sampling of the photon ring signal in the Fourier coverage of each of\nthese orbits. We show that higher orbits isolate spacetime features while\nsacrificing both, signal lost to scattering and temporal resolution, but gain\ngreater access to the morphology of the photon ring.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-10T16:06:14Z"}
{"aid":"http://arxiv.org/abs/2504.07903v1","title":"Spectral delineation of Markov Generators: Classical vs Quantum","summary":"The celebrated theorem of Perron and Frobenius implies that spectra of\nclassical Markov operators, represented by stochastic matrices, are restricted\nto the unit disk. This property holds also for spectra of quantum stochastic\nmaps (quantum channels), which describe quantum Markovian evolution in discrete\ntime. Moreover, the spectra of stochastic $N \\times N$ matrices are\nadditionally restricted to a subset of the unit disk, called Karpelevi\\u{c}\nregion, the shape of which depends on $N$. We address the question of whether\nthe spectra of generators, which induce Markovian evolution in continuous time,\ncan be bound in a similar way. We propose a rescaling that allows us to answer\nthis question affirmatively. The eigenvalues of the rescaled classical\ngenerators are confined to the modified Karpelevi\\u{c} regions, whereas the\neigenvalues of the rescaled quantum generators fill the entire unit disk.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-10T16:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.07905v1","title":"From Winter Storm Thermodynamics to Wind Gust Extremes: Discovering\n  Interpretable Equations from Data","summary":"Reliably identifying and understanding temporal precursors to extreme wind\ngusts is crucial for early warning and mitigation. This study proposes a simple\ndata-driven approach to extract key predictors from a dataset of historical\nextreme European winter windstorms and derive simple equations linking these\nprecursors to extreme gusts over land. A major challenge is the limited\ntraining data for extreme events, increasing the risk of model overfitting.\nTesting various mitigation strategies, we find that combining dimensionality\nreduction, careful cross-validation, feature selection, and a nonlinear\ntransformation of maximum wind gusts informed by Generalized Extreme Value\ndistributions successfully reduces overfitting. These measures yield\ninterpretable equations that generalize across regions while maintaining\nsatisfactory predictive skill. The discovered equations reveal the association\nbetween a steady drying low-troposphere before landfall and wind gust intensity\nin Northwestern Europe.","main_category":"physics.ao-ph","categories":"physics.ao-ph,stat.AP","published":"2025-04-10T16:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.07908v1","title":"Majorization for probability distributions, column stochastic matrices\n  and their linear preservers","summary":"In this paper we investigate majorization for probability distributions and\ncolumn stochastic matrices. We show that majorizations in general can be\nreduced to these sets. We characterize linear operators that preserve\nmajorization for probability distributions, and show their equivalence to\noperators preserving vector majorization. Our main result provides a complete\ncharacterization of linear preservers of strong majorization for column\nstochastic matrices, revealing a richer structure of preservers, than in the\nstandard setting. As a prerequisite to this characterization, we solve the\nproblem of characterizing linear preservers of majorization for zero-sum\nvectors, which yields a new structural insight into the classical results of\nAndo and of Li and Poon.","main_category":"math.RA","categories":"math.RA","published":"2025-04-10T16:29:54Z"}
{"aid":"http://arxiv.org/abs/2504.07913v1","title":"Optimal Control For Anti-Abeta Treatment in Alzheimer's Disease using a\n  Reaction-Diffusion Model","summary":"Alzheimer's disease is a progressive neurodegenerative disorder that\nsignificantly impairs patient survival and quality of life. While current\npharmacological treatments aim to slow disease progression, they remain\ninsufficient in halting cognitive decline. Mathematical modeling has emerged as\na powerful tool for understanding the dynamics of AD and optimizing treatment\nstrategies. However, most existing models focus on temporal dynamics using\nordinary differential equation-based approaches, often neglecting the critical\nrole of spatial heterogeneity in disease progression.\n  In this study, we employ a spatially explicit reaction-diffusion model to\ndescribe amyloid-beta (A beta) dynamics in the brain, incorporating treatment\noptimization while accounting for potential side effects. Our objective is to\nminimize amyloid-beta plaque concentration while balancing therapeutic efficacy\nagainst adverse effects, such as amyloid-related imaging abnormalities (ARIA).\nUnder specific assumptions, we establish the well-posedness and uniqueness of\nthe optimal solution. We employ numerical methods based on the Finite Element\nMethod to compute personalized treatment strategies, leveraging real patient\namyloid-beta positron emission tomography (PET) scan data.\n  Our results demonstrate that optimal treatment strategies outperform constant\ndosing regimens, achieving significant reductions in amyloid burden while\nminimizing side effects. By integrating spatial dynamics and personalized\ntreatment planning, our framework offers a novel approach to refining\ntherapeutic interventions for Alzheimer's disease.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T17:22:09Z"}
{"aid":"http://arxiv.org/abs/2504.07914v1","title":"Scaling and Predictability in Surface Quasi-Geostrophic Turbulence","summary":"Turbulent flows are strongly chaotic and unpredictable, with a Lyapunov\nexponent that increases with the Reynolds number. Here, we study the chaoticity\nof the Surface Quasi-geostrophic system, a two-dimensional model for\ngeophysical flows that displays a direct cascade similar to that of\nthree-dimensional turbulence. Using high-resolution direct numerical\nsimulations, we investigate the dependence of the Lyapunov exponent on the\nReynolds number and find an anomalous scaling exponent larger than the one\npredicted by dimensional arguments. We also study the finite-time fluctuation\nof the Lyapunov exponent by computing the Cram\\'er function associated with its\nprobability distribution. We find that the Cram\\'er function attains a\nself-similar form at large Re.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-10T17:23:13Z"}
{"aid":"http://arxiv.org/abs/2504.07922v1","title":"Exploring Structure Constants in Planar $\\mathcal{N} = 4$ SYM: From\n  Small Spin to Strong Coupling","summary":"We study the structure constants of two conformal primary operators and one\nspinning operator in planar $\\mathcal{N} = 4$ Super-Yang-Mills theory using the\nhexagon formalism. By analytically continuing in the spin, we derive a formula\nfor computing these structure constants at any coupling in the small-spin\nlimit, up to a normalization factor. This formula allows us to explore their\nanalytical properties at strong coupling. In this regime, using classical\nstring calculations and a suitable ansatz, we extend our analysis to\nfinite-spin operators, verifying recent two-loop results for structure\nconstants in string theory and generalizing them to operators with arbitrary\nR-charges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.07928v1","title":"Riemann zeros and the KKR determinant","summary":"We transform the counting function for the Riemann zeros into a\nKorringa-Kohn-Rostoker (KKR) determinant, assisted by Krein's theorem. This is\nbased on our observation that the function derived from a few methods can all\nbe recast into two terms: one corresponds to the scattering phase, and the\nother is similar to structure constants related to the Green function. We also\ndiscuss the possible physical realizations. Our method provides a new physical\npathway towards the solution of the Riemann hypothesis.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.07929v1","title":"Market-Based Portfolio Selection","summary":"We show that Markowitz's (1952) decomposition of a portfolio variance as a\nquadratic form in the variables of the relative amounts invested into the\nsecurities, which has been the core of classical portfolio theory for more than\n70 years, is valid only in the approximation when all trade volumes with all\nsecurities of the portfolio are assumed constant. We derive the market-based\nportfolio variance and its decomposition by its securities, which accounts for\nthe impact of random trade volumes and is a polynomial of the 4th degree in the\nvariables of the relative amounts invested into the securities. To do that, we\ntransform the time series of market trades with the securities of the portfolio\nand obtain the time series of trades with the portfolio as a single market\nsecurity. The time series of market trades determine the market-based means and\nvariances of prices and returns of the portfolio in the same form as the means\nand variances of any market security. The decomposition of the market-based\nvariance of returns of the portfolio by its securities follows from the\nstructure of the time series of market trades of the portfolio as a single\nsecurity. The market-based decompositions of the portfolio's variances of\nprices and returns could help the managers of multi-billion portfolios and the\ndevelopers of large market and macroeconomic models like BlackRock's Aladdin,\nJP Morgan, and the U.S. Fed adjust their models and forecasts to the reality of\nrandom markets.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,q-fin.GN,q-fin.PM,q-fin.PR","published":"2025-04-10T17:44:57Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07935v1","title":"Stacking-induced ferroelectricity in tetralayer graphene","summary":"Recent studies have reported emergent ferroelectric behavior in twisted or\nmoir\\'e-engineered graphene-based van der Waals heterostructures, yet the\nmicroscopic origin of this effect remains under debate. Pristine mono- or\nfew-layer graphene lacks a permanent dipole due to its centrosymmetric lattice,\nmaking the emergence of ferroelectricity unlikely. However, mixed-stacked\ngraphene, such as the ABCB tetralayer configuration, breaks both inversion and\nmirror symmetry and has been theoretically predicted to support electrically\nswitchable dipoles. ABCB graphene represents the simplest natural graphene\npolytype exhibiting intrinsic out-of-plane polarization, arising from\nasymmetric charge carrier distribution across its layers. Here, we report\nrobust ferroelectric behavior in dual-gated, non-aligned ABCB tetralayer\ngraphene encapsulated in hexagonal boron nitride. The device exhibits\npronounced hysteresis in resistance under both top and bottom gate modulation,\nwith the effect persisting up to room temperature. This hysteresis originates\nfrom reversible layer-polarized charge reordering, driven by gate-induced\ntransitions between ABCB and BCBA stacking configurations -- without requiring\nmoir\\'e superlattices. Our findings establish stacking-order-induced symmetry\nbreaking as a fundamental route to electronic ferroelectricity in graphene and\nopen pathways for non-volatile memory applications based on naturally occurring\nmixed-stacked multilayer graphene.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T17:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.07941v1","title":"Quantum error correction via multi-particle discrete-time quantum walk","summary":"We propose a scheme of quantum error correction that employs a multi-particle\nquantum walk defined on nested squares, each hosting a single particle. In this\nmodel, each particle moves within its own distinct square through iterations of\nthree discrete-time steps. First, a particle updates its two-level internal\n{\\it coin} state. Next, it either moves to an adjacent vertex or stays put,\ndepending on the outcome. Finally, it interacts with another particle if these\nparticles arrive at the nearest-neighbor vertices of the two adjacent squares,\nacquiring a phase factor of $-1$. Because a single particle represents a\nthree-qubit state through its position and coin state, Shor's nine-qubit code\nis implemented using only three particles, with two additional particles for\nsyndrome measurement. Furthermore, by exploiting gauge symmetry, our scheme\nachieves redundant encoding, error correction, and arbitrary operations on the\nencoded information using only nearest-neighbor interactions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T17:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.07942v1","title":"MARS: a Multimodal Alignment and Ranking System for Few-Shot\n  Segmentation","summary":"Current Few Shot Segmentation literature lacks a mask selection method that\ngoes beyond visual similarity between the query and example images, leading to\nsuboptimal predictions. We present MARS, a plug-and-play ranking system that\nleverages multimodal cues to filter and merge mask proposals robustly. Starting\nfrom a set of mask predictions for a single query image, we score, filter, and\nmerge them to improve results. Proposals are evaluated using multimodal scores\ncomputed at local and global levels. Extensive experiments on COCO-20i,\nPascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring\ncomponents is crucial for robust ranking, validating our contribution. As MARS\ncan be effortlessly integrated with various mask proposal systems, we deploy it\nacross a wide range of top-performer methods and achieve new state-of-the-art\nresults on multiple existing benchmarks. Code will be available upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:53:23Z"}
{"aid":"http://arxiv.org/abs/2504.07949v1","title":"InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars\n  with Deformable Gaussians","summary":"With the rising interest from the community in digital avatars coupled with\nthe importance of expressions and gestures in communication, modeling natural\navatar behavior remains an important challenge across many industries such as\nteleconferencing, gaming, and AR/VR. Human hands are the primary tool for\ninteracting with the environment and essential for realistic human behavior\nmodeling, yet existing 3D hand and head avatar models often overlook the\ncrucial aspect of hand-body interactions, such as between hand and face. We\npresent InteracttAvatar, the first model to faithfully capture the\nphotorealistic appearance of dynamic hand and non-rigid hand-face interactions.\nOur novel Dynamic Gaussian Hand model, combining template model and 3D Gaussian\nSplatting as well as a dynamic refinement module, captures pose-dependent\nchange, e.g. the fine wrinkles and complex shadows that occur during\narticulation. Importantly, our hand-face interaction module models the subtle\ngeometry and appearance dynamics that underlie common gestures. Through\nexperiments of novel view synthesis, self reenactment and cross-identity\nreenactment, we demonstrate that InteracttAvatar can reconstruct hand and\nhand-face interactions from monocular or multiview videos with high-fidelity\ndetails and be animated with novel poses.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.07964v1","title":"C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization\n  for Test-Time Expert Re-Mixing","summary":"Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely\nsub-optimal expert pathways-our study reveals that naive expert selection\nlearned from pretraining leaves a surprising 10-20% accuracy gap for\nimprovement. Motivated by this observation, we develop a novel class of\ntest-time optimization methods to re-weight or \"re-mixing\" the experts in\ndifferent layers jointly for each test sample. Since the test sample's ground\ntruth is unknown, we propose to optimize a surrogate objective defined by the\nsample's \"successful neighbors\" from a reference set of samples. We introduce\nthree surrogates and algorithms based on mode-finding, kernel regression, and\nthe average loss of similar reference samples/tasks. To reduce the cost of\noptimizing whole pathways, we apply our algorithms merely to the core experts'\nmixing weights in critical layers, which enjoy similar performance but save\nsignificant computation. This leads to \"Critical-Layer, Core-Expert,\nCollaborative Pathway Optimization (C3PO)\". We apply C3PO to two recent MoE\nLLMs and examine it on six widely-used benchmarks. It consistently improves the\nbase model by 7-15% in accuracy and outperforms widely used test-time learning\nbaselines, e.g., in-context learning and prompt/prefix tuning, by a large\nmargin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to\noutperform LLMs of 7-9B parameters, hence improving MoE's advantages on\nefficiency. Our thorough ablation study further sheds novel insights on\nachieving test-time improvement on MoE.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09883v1","title":"Modelling & Steady State Compliance Testing of an Improved Time\n  Synchronized Phasor Measurement Unit Based on IEEE Standard C37.118.1","summary":"Synchrophasor technology is an emerging and developing technology for\nmonitoring and control of wide area measurement systems (WAMS). In an\nelementary WAMS, two identical phasors measured at two different locations have\ndifference in the phase angles measured since their reference waveforms are not\nsynchronized with each other. Phasor measurement units (PMUs) measure input\nphasors with respect to a common reference wave based on the atomic clock\npulses received from global positioning system (GPS) satellites, eliminating\nvariation in the measured phase angles due to distant locations of the\nmeasurement nodes. This has found tremendous applications in quick fault\ndetection, fault location analysis, accurate current, voltage, frequency and\nphase angle measurements in WAMS. Commercially available PMU models are often\nproven to be expensive for research and development as well as for grid\nintegration projects. This research article proposes an economic PMU model\noptimized for accurate steadystate performance based on recursive discrete\nFourier transform (DFT) and provides results and detailed analysis of the\nproposed PMU model as per the steady state compliance specifications of IEEE\nstandard C37.118.1. Results accurate up to 13 digits after decimal point are\nobtained through the developed PMU model for both nominal and off-nominal\nfrequency inputs in steady state.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,physics.soc-ph","published":"2025-04-14T05:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.09892v1","title":"Vermilion: A Traffic-Aware Reconfigurable Optical Interconnect with\n  Formal Throughput Guarantees","summary":"The increasing gap between datacenter traffic volume and the capacity of\nelectrical switches has driven the development of reconfigurable network\ndesigns utilizing optical circuit switching. Recent advancements, particularly\nthose featuring periodic fixed-duration reconfigurations, have achieved\npractical end-to-end delays of just a few microseconds. However, current\ndesigns rely on multi-hop routing to enhance utilization, which can lead to a\nsignificant reduction in worst-case throughput and added overhead from\ncongestion control and routing complexity. These factors pose significant\noperational challenges for the large-scale deployment of these technologies.\n  We present Vermilion, a reconfigurable optical interconnect that breaks the\nthroughput barrier of existing periodic reconfigurable networks, without the\nneed for multi-hop routing -- thus eliminating congestion control and\nsimplifying routing to direct communication. Vermilion adopts a traffic-aware\napproach while retaining the simplicity of periodic fixed-duration\nreconfigurations, similar to RotorNet. We formally establish throughput bounds\nfor Vermilion, demonstrating that it achieves at least $33\\%$ more throughput\nin the worst-case compared to existing designs. The key innovation of Vermilion\nis its short traffic-aware periodic schedule, derived using a matrix rounding\ntechnique. This schedule is then combined with a traffic-oblivious periodic\nschedule to efficiently manage any residual traffic. Our evaluation results\nsupport our theoretical findings, revealing significant performance gains for\ndatacenter workloads.","main_category":"cs.NI","categories":"cs.NI,cs.DS","published":"2025-04-14T05:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.09893v1","title":"LangPert: Detecting and Handling Task-level Perturbations for Robust\n  Object Rearrangement","summary":"Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T05:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.09898v1","title":"The Milky Way Project MOBStIRS: Parametrizing Infrared Stellar-Wind Bow\n  Shock Morphologies with Citizen Science","summary":"Mass-loss influences stellar evolution, especially for massive stars with\nstrong winds. Stellar wind bow shock nebulae driven by Galactic OB stars can be\nused to measure mass-loss rates ($\\dot{M}$). The standoff distance ($R_{0}$)\nbetween the star and the bow shock is set by momentum flux balance between the\nstellar wind and the surrounding interstellar medium (ISM). We created the\nMilky Way Project: MOBStIRS (Mass-loss rates for OB Stars driving IR bow\nShocks) using the online Zooniverse citizen science platform. We enlisted\nseveral hundred students to measure $R_0$ and two other projected shape\nparameters for 764 cataloged IR bow shocks. MOBStIRS incorporated 1528 JPEG\ncutout images produced from Spitzer GLIMPSE and MIPSGAL survey data.\nMeasurements were aggregated to compute shape parameters for each bow shock\nimage deemed high-quality by participants. The average statistical uncertainty\non $R_0$ is $12.5\\%$ but varies from ${<}5\\%$ to ${\\sim}40\\%$ among individual\nbow shocks, contributing significantly to the total error budget of $\\dot{M}$.\nThe derived nebular morphologies agree well with (magneto)hydrodynamic\nsimulations of bow shocks driven by the winds of OB stars moving at $V_a =\n10-40~km~s^{-1}$ with respect to the ambient interstellar medium (ISM). A\nsystematic correction to $R_0$ to account for viewing angle appears unnecessary\nfor computing $\\dot{M}$. Slightly more than half of MOBStIRS bow shocks are\nasymmetric, which could indicate anisotropic stellar winds, ISM clumping on\nsub-pc scales, time-dependent instabilities, and/or misalignments between the\nlocal ISM magnetic field and the star-bow shock axis.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-14T05:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.09903v1","title":"Refining Financial Consumer Complaints through Multi-Scale Model\n  Interaction","summary":"Legal writing demands clarity, formality, and domain-specific\nprecision-qualities often lacking in documents authored by individuals without\nlegal training. To bridge this gap, this paper explores the task of legal text\nrefinement that transforms informal, conversational inputs into persuasive\nlegal arguments. We introduce FinDR, a Chinese dataset of financial dispute\nrecords, annotated with official judgments on claim reasonableness. Our\nproposed method, Multi-Scale Model Interaction (MSMI), leverages a lightweight\nclassifier to evaluate outputs and guide iterative refinement by Large Language\nModels (LLMs). Experimental results demonstrate that MSMI significantly\noutperforms single-pass prompting strategies. Additionally, we validate the\ngeneralizability of MSMI on several short-text benchmarks, showing improved\nadversarial robustness. Our findings reveal the potential of multi-model\ncollaboration for enhancing legal document generation and broader text\nrefinement tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.09910v1","title":"Learning to Erase Private Knowledge from Multi-Documents for\n  Retrieval-Augmented Large Language Models","summary":"Retrieval-Augmented Generation (RAG) is a promising technique for applying\nLLMs to proprietary domains. However, retrieved documents may contain sensitive\nknowledge, posing risks of privacy leakage in generative results. Thus,\neffectively erasing private information from retrieved documents is a key\nchallenge for RAG. Unlike traditional text anonymization, RAG should consider:\n(1) the inherent multi-document reasoning may face de-anonymization attacks;\n(2) private knowledge varies by scenarios, so users should be allowed to\ncustomize which information to erase; (3) preserving sufficient publicly\navailable knowledge for generation tasks. This paper introduces the privacy\nerasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which\neffectively removes user-defined private knowledge from documents while\npreserving sufficient public knowledge for generation. Specifically, we first\nconstruct a global knowledge graph to identify potential knowledge across\ndocuments, aiming to defend against de-anonymization attacks. Then we randomly\nsplit it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite\nthe retrieved documents excluding private triples. Finally, PPO algorithm\noptimizes the rewriting model to minimize private triples and maximize public\ntriples retention. Experiments on four QA datasets demonstrate that Eraser4RAG\nachieves superior erase performance than GPT-4o.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.09917v1","title":"Creation of chaos for interacting Brownian particles","summary":"We consider a system of $N$ Brownian particles, with or without inertia,\ninteracting in the mean-field regime via a weak, smooth, long-range potential,\nand starting initially from an arbitrary exchangeable $N$-particle\ndistribution. In this model framework, we establish a fine version of the\nso-called creation-of-chaos phenomenon: in weak norms, the mean-field\napproximation for a typical particle is shown to hold with an accuracy\n$O(N^{-1})$ up to an error due solely to initial pair correlations, which is\ndamped exponentially over time. The novelty is that the initial information\nappears in our estimates only through pair correlations, which currently seems\ninaccessible to other methods. This is complemented by corresponding results on\nhigher-order creation of chaos in the form of higher-order correlation\nestimates.","main_category":"math.PR","categories":"math.PR,math-ph,math.AP,math.MP","published":"2025-04-14T06:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.09926v1","title":"Quotients of Poisson boundaries, entropy, and spectral gap","summary":"Poisson boundary is a measurable $\\Gamma$-space canonically associated with a\ngroup $\\Gamma$ and a probability measure $\\mu$ on it. The collection of all\nmeasurable $\\Gamma$-equivariant quotients, known as $\\mu$-boundaries, of the\nPoisson boundary forms a partially ordered set, equipped with a strictly\nmonotonic non-negative function, known as Furstenberg or differential entropy.\n  In this paper we demonstrate the richness and the complexity of this lattice\nof quotients for the case of free groups and surface groups and rather general\nmeasures. In particular, we show that there are continuum many unrelated\n$\\mu$-boundaries at each, sufficiently low, entropy level, and there are\ncontinuum many distinct order-theoretic cubes of $\\mu$-boundaries.\n  These $\\mu$-boundaries are constructed from dense linear representations\n$\\rho:\\Gamma\\to G$ to semi-simple Lie groups, like $\\PSL_2(\\bbC)^d$ with\nabsolutely continuous stationary measures on $\\hat\\bbC^d$.","main_category":"math.GR","categories":"math.GR,math.DS","published":"2025-04-14T06:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.09927v1","title":"Efficient Task-specific Conditional Diffusion Policies: Shortcut Model\n  Acceleration and SO(3) Optimization","summary":"Imitation learning, particularly Diffusion Policies based methods, has\nrecently gained significant traction in embodied AI as a powerful approach to\naction policy generation. These models efficiently generate action policies by\nlearning to predict noise. However, conventional Diffusion Policy methods rely\non iterative denoising, leading to inefficient inference and slow response\ntimes, which hinder real-time robot control. To address these limitations, we\npropose a Classifier-Free Shortcut Diffusion Policy (CF-SDP) that integrates\nclassifier-free guidance with shortcut-based acceleration, enabling efficient\ntask-specific action generation while significantly improving inference speed.\nFurthermore, we extend diffusion modeling to the SO(3) manifold in shortcut\nmodel, defining the forward and reverse processes in its tangent space with an\nisotropic Gaussian distribution. This ensures stable and accurate rotational\nestimation, enhancing the effectiveness of diffusion-based control. Our\napproach achieves nearly 5x acceleration in diffusion inference compared to\nDDIM-based Diffusion Policy while maintaining task performance. Evaluations\nboth on the RoboTwin simulation platform and real-world scenarios across\nvarious tasks demonstrate the superiority of our method.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T06:37:22Z"}
{"aid":"http://arxiv.org/abs/2504.09935v1","title":"Constrained Auto-Regressive Decoding Constrains Generative Retrieval","summary":"Generative retrieval seeks to replace traditional search index data\nstructures with a single large-scale neural network, offering the potential for\nimproved efficiency and seamless integration with generative large language\nmodels. As an end-to-end paradigm, generative retrieval adopts a learned\ndifferentiable search index to conduct retrieval by directly generating\ndocument identifiers through corpus-specific constrained decoding. The\ngeneralization capabilities of generative retrieval on out-of-distribution\ncorpora have gathered significant attention.\n  In this paper, we examine the inherent limitations of constrained\nauto-regressive generation from two essential perspectives: constraints and\nbeam search. We begin with the Bayes-optimal setting where the generative\nretrieval model exactly captures the underlying relevance distribution of all\npossible documents. Then we apply the model to specific corpora by simply\nadding corpus-specific constraints. Our main findings are two-fold: (i) For the\neffect of constraints, we derive a lower bound of the error, in terms of the KL\ndivergence between the ground-truth and the model-predicted step-wise marginal\ndistributions. (ii) For the beam search algorithm used during generation, we\nreveal that the usage of marginal distributions may not be an ideal approach.\nThis paper aims to improve our theoretical understanding of the generalization\ncapabilities of the auto-regressive decoding retrieval paradigm, laying a\nfoundation for its limitations and inspiring future advancements toward more\nrobust and generalizable generative retrieval.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T06:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.09936v1","title":"KeepKV: Eliminating Output Perturbation in KV Cache Compression for\n  Efficient LLMs Inference","summary":"Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-14T06:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.09942v1","title":"Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting\n  Loewner-State Model for EM Simulation of Multiport Systems","summary":"This paper employs a fully adaptive and semi-adaptive frequency sweep\nalgorithm using the Loewner matrix-based state model for the electromagnetic\nsimulation. The proposed algorithms use two Loewner matrix models with\ndifferent or the same orders with small frequency perturbation for adaptive\nfrequency selection. The error between the two models is calculated in each\niteration, and the next frequency points are selected to minimize maximum\nerror. With the help of memory, the algorithm terminates when the error between\nthe model and the simulation result is reached within the specified error\ntolerance. In the fully adaptive frequency sweep algorithm, the method starts\nwith the minimum and maximum frequency of simulation. In the semi-adaptive\nalgorithm, a novel approach has been proposed to determine the initial number\nof frequency points necessary for system interpolation based on the electrical\nsize of the structure. The proposed algorithms have been compared with the\nStoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for\nelectromagnetic simulation. Four examples are presented using MATLAB R2024b.\nThe results show that the proposed methods offer better performance in terms of\nspeed, accuracy and the requirement of the minimum number of frequency samples.\nThe proposed method shows remarkable consistency with full-wave simulation\ndata, and the algorithm can be effectively applicable to electromagnetic\nsimulations.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,G.1.1","published":"2025-04-14T07:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.09957v1","title":"Programmable time-frequency mode encoded quantum state generator for\n  silicon-on-insulator platform","summary":"We propose a method for the programmable generation of time-frequency mode\n(TFM) encoded quantum states of light on the silicon-on-insulator (SOI)\nplatform. The state generator consists of an N-tap finite impulse response\nfilter and a Mach-Zehnder interferometer (MZI)-based coupled-ring resonator.\nThrough numerical simulations, its capability of producing TFM-encoded\nmaximally entangled states in two, three, and four dimensions is theoretically\ndemonstrated, with fidelities of 0.950, 0.954, and 0.971, respectively.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T07:54:17Z"}
{"aid":"http://arxiv.org/abs/2504.09968v1","title":"Some memos on Stable Symplectic Structured Space","summary":"In these memos, we define a pregeometry $\\mathcal{T}_{\\mathbb{S}} ^{alg}$ and\na geometry $\\mathcal{G}_{\\mathbb{S}} ^{alg}$ which integrate symplectic\nmanifolds with $E_{\\infty}$-ring sheaves, enabling the construction of\n$\\mathcal{G}_{\\mathbb{S}} ^{alg}$-schemes as structured $\\infty$-topoi. Our\nframework and results establish a profound connection between algebraic\ninvariants and homological properties, opening new pathways for exploring\nsymplectic phenomena through the lens of higher category theory and derived\ngeometry.","main_category":"math.AG","categories":"math.AG,math.SG","published":"2025-04-14T08:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.09975v1","title":"OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape\n  Generation","summary":"Autoregressive models have achieved remarkable success across various\ndomains, yet their performance in 3D shape generation lags significantly behind\nthat of diffusion models. In this paper, we introduce OctGPT, a novel\nmultiscale autoregressive model for 3D shape generation that dramatically\nimproves the efficiency and performance of prior 3D autoregressive approaches,\nwhile rivaling or surpassing state-of-the-art diffusion models. Our method\nemploys a serialized octree representation to efficiently capture the\nhierarchical and spatial structures of 3D shapes. Coarse geometry is encoded\nvia octree structures, while fine-grained details are represented by binary\ntokens generated using a vector quantized variational autoencoder (VQVAE),\ntransforming 3D shapes into compact \\emph{multiscale binary sequences} suitable\nfor autoregressive prediction. To address the computational challenges of\nhandling long sequences, we incorporate octree-based transformers enhanced with\n3D rotary positional encodings, scale-specific embeddings, and token-parallel\ngeneration schemes. These innovations reduce training time by 13 folds and\ngeneration time by 69 folds, enabling the efficient training of high-resolution\n3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days.\nOctGPT showcases exceptional versatility across various tasks, including text-,\nsketch-, and image-conditioned generation, as well as scene-level synthesis\ninvolving multiple objects. Extensive experiments demonstrate that OctGPT\naccelerates convergence and improves generation quality over prior\nautoregressive methods, offering a new paradigm for high-quality, scalable 3D\ncontent creation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-14T08:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.09982v1","title":"The gravitational index of a small black ring","summary":"Certain supersymmetric elementary string states with angular momentum can be\nviewed as small black rings in a five-dimensional string theory. These black\nrings have zero area event horizon. The 4D-5D connection relates these small\nrings to small black holes without angular momentum in one less dimension.\nRecent works have proposed saddle solutions that compute the supersymmetric\nindex for small black holes using gravitational path integral. In this paper,\nwe propose an analogous saddle solution for a five-dimensional small black\nring. The dominant contribution comes from a black ring saddle that rotates in\nboth independent planes in five dimensions and has a finite area event horizon.\nWe also write the saddle solution as a three-center Bena-Warner solution.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T08:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.09996v1","title":"Nonlinear transport of Wigner solid phase surrounding the two-flux\n  composite fermion liquid","summary":"We have investigated the low temperature (T) transport properties of\nfractional quantum Hall (FQH) states in a high-mobility two-dimensional hole\ngas. According to the composite fermion (CF) model, FQH states stemming from a\nhalf-filled Landau level, specifically at filling factors ${\\nu}=p/(2p+1)\n(p=\\pm 1,\\pm 2,\\pm 3,...)$, can be associated with two-flux-attached CFs at the\ncorresponding Lambda filling factor p. The zero-resistance minima and Hall\nplateaus of these states exhibit unusual temperature dependencies,\ncharacterized by rapid increases in width below a threshold temperature around\n100 mK. Differential conductivity measurements from Corbino samples reveal that\nthe regimes surrounding the CF liquid display clear nonlinear transport\ncharacteristics. This nonlinearity implies that each CF liquid is surrounded by\nCF solid phase composed of dilute CF excitations. Quantitatively, the applied\nelectric field E influences the motion of CF solid in a way analogous to T,\nwhich is dubbed the \"E-T duality\". Our analysis indicates that this E-T duality\nis consistent with the Berezinskii-Kosterlitz-Thouless theory in\ntwo-dimensional phase transitions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T09:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.09998v1","title":"Metric-Guided Synthesis of Class Activation Mapping","summary":"Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.10008v1","title":"Time for Timed Monitorability","summary":"Monitoring is an important part of the verification toolbox, in particular in\nsituations where exhaustive verification using, e.g., model-checking, is\ninfeasible. The goal of online monitoring is to determine the satisfaction or\nviolation of a specification during runtime, i.e., based on finite execution\nprefixes. However, not every specification is amenable to monitoring, e.g.,\nproperties for which no finite execution can witness satisfaction or violation.\nMonitorability is the question whether a given specification is amenable to\nmonitoring, and has been extensively studied in discrete time.\n  Here, we study, for the first time, the monitorability problem for real-time\nspecifications. For specifications given by deterministic Timed Muller\nAutomata, we prove decidability while we show that the problem is undecidable\nfor specifications given by nondeterministic Timed B\\\"uchi automata.\nFurthermore, we refine monitorability to also determine bounds on the number of\nevents as well as the time that must pass before monitoring the property may\nyield an informative verdict. We prove that for deterministic Timed Muller\nautomata, such bounds can be effectively computed. In contrast we show that for\nnondeterministic Timed B\\\"uchi automata such bounds are not computable.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-14T09:12:58Z"}
{"aid":"http://arxiv.org/abs/2504.10013v1","title":"Training LLMs on HPC Systems: Best Practices from the OpenGPT-X Project","summary":"The training of large language models (LLMs) requires substantial\ncomputational resources, complex software stacks, and carefully designed\nworkflows to achieve scalability and efficiency. This report presents best\npractices and insights gained from the OpenGPT-X project, a German initiative\nfocused on developing open, multilingual LLMs optimized for European languages.\nWe detail the use of high-performance computing (HPC) systems, primarily JUWELS\nBooster at JSC, for training Teuken-7B, a 7-billion-parameter transformer\nmodel. The report covers system architecture, training infrastructure, software\nchoices, profiling and benchmarking tools, as well as engineering and\noperational challenges.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T09:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.10022v1","title":"Parameters estimation of a Threshold Chan-Karolyi-Longstaff-Sanders\n  process from continuous and discrete observations","summary":"We consider a continuous time process that is self-exciting and ergodic,\ncalled threshold Chan-Karolyi-Longstaff-Sanders (CKLS) process. This process is\na generalization of various models in econometrics, such as Vasicek model,\nCox-Ingersoll-Ross, and Black-Scholes, allowing for the presence of several\nthresholds which determine changes in the dynamics. We study the asymptotic\nbehavior of maximum-likelihood and quasi-maximum-likelihood estimators of the\ndrift parameters in the case of continuous time and discrete time observations.\nWe show that for high frequency observations and infinite horizon the\nestimators satisfy the same asymptotic normality property as in the case of\ncontinuous time observations. We also discuss diffusion coefficient estimation.\nFinally, we apply our estimators to simulated and real data to motivate\nconsidering (multiple) thresholds.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-14T09:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.10025v1","title":"Progressive Transfer Learning for Multi-Pass Fundus Image Restoration","summary":"Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-14T09:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.10050v1","title":"Emotional Strain and Frustration in LLM Interactions in Software\n  Engineering","summary":"Large Language Models (LLMs) are increasingly integrated into various daily\ntasks in Software Engineering such as coding and requirement elicitation.\nDespite their various capabilities and constant use, some interactions can lead\nto unexpected challenges (e.g. hallucinations or verbose answers) and, in turn,\ncause emotions that develop into frustration. Frustration can negatively impact\nengineers' productivity and well-being if they escalate into stress and\nburnout. In this paper, we assess the impact of LLM interactions on software\nengineers' emotional responses, specifically strains, and identify common\ncauses of frustration when interacting with LLMs at work. Based on 62 survey\nresponses from software engineers in industry and academia across various\ncompanies and universities, we found that a majority of our respondents\nexperience frustrations or other related emotions regardless of the nature of\ntheir work. Additionally, our results showed that frustration mainly stemmed\nfrom issues with correctness and less critical issues such as adaptability to\ncontext or specific format. While such issues may not cause frustration in\ngeneral, artefacts that do not follow certain preferences, standards, or best\npractices can make the output unusable without extensive modification, causing\nfrustration over time. In addition to the frustration triggers, our study\noffers guidelines to improve the software engineers' experience, aiming to\nminimise long-term consequences on mental health.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T09:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.10058v1","title":"Data Cooperatives: Democratic Models for Ethical Data Stewardship","summary":"Data cooperatives offer a new model for fair data governance, enabling\nindividuals to collectively control, manage, and benefit from their information\nwhile adhering to cooperative principles such as democratic member control,\neconomic participation, and community concern. This paper reviews data\ncooperatives, distinguishing them from models like data trusts, data commons,\nand data unions, and defines them based on member ownership, democratic\ngovernance, and data sovereignty. It explores applications in sectors like\nhealthcare, agriculture, and construction. Despite their potential, data\ncooperatives face challenges in coordination, scalability, and member\nengagement, requiring innovative governance strategies, robust technical\nsystems, and mechanisms to align member interests with cooperative goals. The\npaper concludes by advocating for data cooperatives as a sustainable,\ndemocratic, and ethical model for the future data economy.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T10:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.10060v1","title":"Learning to Beamform for Cooperative Localization and Communication: A\n  Link Heterogeneous GNN-Based Approach","summary":"Integrated sensing and communication (ISAC) has emerged as a key enabler for\nnext-generation wireless networks, supporting advanced applications such as\nhigh-precision localization and environment reconstruction. Cooperative ISAC\n(CoISAC) further enhances these capabilities by enabling multiple base stations\n(BSs) to jointly optimize communication and sensing performance through\ncoordination. However, CoISAC beamforming design faces significant challenges\ndue to system heterogeneity, large-scale problem complexity, and sensitivity to\nparameter estimation errors. Traditional deep learning-based techniques fail to\nexploit the unique structural characteristics of CoISAC systems, thereby\nlimiting their ability to enhance system performance. To address these\nchallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) for\njoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNN\nmodels communication and sensing links as heterogeneous nodes and their\ninteractions as edges, enabling the capture of the heterogeneous nature and\nintricate interactions of CoISAC systems. Furthermore, a graph attention\nmechanism is incorporated to dynamically adjust node and link importance,\nimproving robustness to channel and position estimation errors. Numerical\nresults demonstrate that the proposed attention-enhanced LHGNN achieves\nsuperior communication rates while maintaining sensing accuracy under power\nconstraints. The proposed method also exhibits strong robustness to\ncommunication channel and position estimation error.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:03:12Z"}
{"aid":"http://arxiv.org/abs/2504.10068v1","title":"Mavors: Multi-granularity Video Representation for Multimodal Large\n  Language Model","summary":"Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-14T10:14:44Z"}
{"aid":"http://arxiv.org/abs/2504.10077v1","title":"Towards Quantifying Commonsense Reasoning with Mechanistic Insights","summary":"Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T10:21:59Z"}
{"aid":"http://arxiv.org/abs/2504.10081v1","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning\n  Capability","summary":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-14T10:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.10089v1","title":"Convergence Analysis of a Stochastic Interacting Particle-Field\n  Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems","summary":"Chemotaxis models describe the movement of organisms in response to chemical\ngradients. In this paper, we present a stochastic interacting particle-field\nalgorithm with random batch approximation (SIPF-$r$) for the three-dimensional\n(3D) parabolic-parabolic Keller-Segel (KS) system, also known as the fully\nparabolic KS system. The SIPF-$r$ method approximates the KS system by coupling\nparticle-based representations of density with a smooth field variable computed\nusing spectral methods. By incorporating the random batch method (RBM), we\nbypass the mean-field limit and significantly reduce computational complexity.\nUnder mild assumptions on the regularity of the original KS system and the\nboundedness of numerical approximations, we prove that, with high probability,\nthe empirical measure of the SIPF-$r$ particle system converges to the exact\nmeasure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance.\nNumerical experiments validate the theoretical convergence rates and\ndemonstrate the robustness and accuracy of the SIPF-$r$ method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.10132v1","title":"Asymptotic Optimality of Projected Inventory Level Policies for Lost\n  Sales Inventory Systems with Large Leadtime and Penalty Cost","summary":"We study the canonical periodic review lost sales inventory system with\npositive leadtime and independent and identically distributed (i.i.d.) demand\nunder the average cost criterion. We demonstrate that the relative value\nfunction under the constant order policy satisfies the Wiener-Hopf equation. We\nemploy ladder processes associated with a random walk featuring i.i.d.\nincrements, to obtain an explicit solution for the relative value function.\nThis solution can be expressed as a quadratic form and a term that grows\nsublinearly. Then we perform an approximate policy iteration step on the\nconstant order policy and bound the approximation errors as a function of the\ncost of losing a sale. This leads to our main result that projected inventory\nlevel policies are asymptotically optimal as the leadtime grows when the cost\nof losing a sale is sufficiently large and demand has a finite second moment.\nUnder these conditions, we also show that the optimal cost rate approaches\ninfinity, proportional to the square root of the cost of losing a sale.","main_category":"math.PR","categories":"math.PR,math.OC,G.3","published":"2025-04-14T11:38:35Z"}
{"aid":"http://arxiv.org/abs/2504.10134v1","title":"Let's Talk About It: Making Scientific Computational Reproducibility\n  Easy","summary":"Computational reproducibility of scientific results, that is, the execution\nof a computational experiment (e.g., a script) using its original settings\n(data, code, etc.), should always be possible. However, reproducibility has\nbecome a significant challenge, as researchers often face difficulties in\naccurately replicating experiments due to inconsistencies in documentation,\nsetup configurations, and missing data. This lack of reproducibility may\nundermine the credibility of scientific results.\n  To address this issue, we propose a conversational, text-based tool that\nallows researchers to easily reproduce computational experiments (theirs or\nfrom others) and package them in a single file that can be re-executed with\njust a double click on any computer, requiring the installation of a single\nwidely-used software. Researchers interact with the platform in natural\nlanguage, which our tool processes to automatically create a computational\nenvironment able to execute the provided experiment/code.\n  We conducted two studies to evaluate our proposal. In the first study, we\ngathered qualitative data by executing 18 experiments from the literature.\nAlthough in some cases it was not possible to execute the experiment, in most\ninstances, it was necessary to have little or even no interaction for the tool\nto reproduce the results.\n  We also conducted a user study comparing our tool with an enterprise-level\none. During this study, we measured the usability of both tools using the\nSystem Usability Scale (SUS) and participants' workload using the NASA Task\nLoad Index (TLX). The results show a statistically significant difference\nbetween both tools in favor of our proposal, demonstrating that the usability\nand workload of our tool are superior to the current state of the art.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.10149v1","title":"BoTTA: Benchmarking on-device Test Time Adaptation","summary":"The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T12:00:00Z"}
{"aid":"http://arxiv.org/abs/2504.10154v1","title":"The energy content of Alfven waves in the stratified solar atmosphere","summary":"Alfven waves propagating in a vertically stratified plasma, such as those\ntravelling from the solar photosphere to the corona, are partially reflected\ndue to the gradient in the Alfven speed. Wave reflection naturally results in\nthe superposition of upward- and downward-propagating waves. A simple analytic\nmodel demonstrates that this superposition leads to the non-equipartition of\nkinetic and magnetic energies in the Alfven wave perturbations and slows down\nthe net energy transport. A numerical model of Alfven wave propagation in the\nlower solar atmosphere reveals significant wave reflection below the transition\nregion, leading to highly variable kinetic and magnetic energy content in the\nlower chromosphere. At higher altitudes, the kinetic energy eventually\ndominates, depending on the wave frequency. The velocity at which net energy\npropagates upward is significantly smaller than the local Alfven speed\nthroughout the chromosphere. Consequently, the commonly used expression for\nunidirectional Alfven waves in a uniform plasma, which relates the energy flux\nto the kinetic energy density, is not generally applicable in the stratified\nlower solar atmosphere and cannot be reliably used to estimate the energy\ncontent of observed waves. A generalized expression is given, incorporating\ncorrection factors that account for wave reflection and energy\nnon-equipartition. The applicability of the expression is discussed.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T12:07:51Z"}
{"aid":"http://arxiv.org/abs/2504.10157v1","title":"SocioVerse: A World Model for Social Simulation Powered by LLM Agents\n  and A Pool of 10 Million Real-World Users","summary":"Social simulation is transforming traditional social science research by\nmodeling human behavior through interactions between virtual individuals and\ntheir environments. With recent advances in large language models (LLMs), this\napproach has shown growing potential in capturing individual differences and\npredicting group behaviors. However, existing methods face alignment challenges\nrelated to the environment, target users, interaction mechanisms, and\nbehavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven\nworld model for social simulation. Our framework features four powerful\nalignment components and a user pool of 10 million real individuals. To\nvalidate its effectiveness, we conducted large-scale simulation experiments\nacross three distinct domains: politics, news, and economics. Results\ndemonstrate that SocioVerse can reflect large-scale population dynamics while\nensuring diversity, credibility, and representativeness through standardized\nprocedures and minimal manual adjustments.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-14T12:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.10162v1","title":"When Do We Feel Present in a Virtual Reality? Towards Sensitivity and\n  User Acceptance of Presence Questionnaires","summary":"Presence is an important and widely used metric to measure the quality of\nvirtual reality (VR) applications. Given the multifaceted and subjective nature\nof presence, the most common measures for presence are questionnaires. But\nthere is little research on their validity regarding specific presence\ndimensions and their responsiveness to differences in perception among users.\nWe investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their\nresponsiveness to intensity variations of known presence dimensions and asked\nusers about their consistency with their experience. Therefore, we created five\nVR scenarios that were designed to emphasize a specific presence dimension. Our\nfindings showed heterogeneous sensitivity of the questionnaires dependent on\nthe different dimensions of presence. This highlights a context-specific\nsuitability of presence questionnaires. The questionnaires' sensitivity was\nfurther stated as lower than actually perceived. Based on our findings, we\noffer guidance on selecting these questionnaires based on their suitability for\nparticular use cases.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.10163v1","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating\n  Scapulohumeral Rhythm for Frozen Shoulder","summary":"This paper presents a novel rehabilitation robot designed to address the\nchallenges of passive range of motion (PROM) exercises for frozen shoulder\npatients by integrating advanced scapulohumeral rhythm stabilization. Frozen\nshoulder is characterized by limited glenohumeral motion and disrupted\nscapulohumeral rhythm, with therapist-assisted interventions being highly\neffective for restoring normal shoulder function. While existing robotic\nsolutions replicate natural shoulder biomechanics, they lack the ability to\nstabilize compensatory movements, such as shoulder shrugging, which are\ncritical for effective rehabilitation. Our proposed device features a 6 degrees\nof freedom (DoF) mechanism, including 5 DoF for shoulder motion and an\ninnovative 1 DoF Joint press for scapular stabilization. The robot employs a\npersonalized two-phase operation: recording normal shoulder movement patterns\nfrom the unaffected side and applying them to guide the affected side.\nExperimental results demonstrated the robot's ability to replicate recorded\nmotion patterns with high precision, with root mean square error (RMSE) values\nconsistently below 1 degree. In simulated frozen shoulder conditions, the robot\neffectively suppressed scapular elevation, delaying the onset of compensatory\nmovements and guiding the affected shoulder to move more closely in alignment\nwith normal shoulder motion, particularly during arm elevation movements such\nas abduction and flexion. These findings confirm the robot's potential as a\nrehabilitation tool capable of automating PROM exercises while correcting\ncompensatory movements. The system provides a foundation for advanced,\npersonalized rehabilitation for patients with frozen shoulders.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T12:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.10167v1","title":"C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination\n  Evaluation","summary":"Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.10180v1","title":"ChartOptimiser: Task-driven Optimisation of Chart Designs","summary":"Effective chart design is essential for satisfying viewers' information\nneeds, such as retrieving values from a chart or comparing two values. However,\ncreating effective charts is challenging and time-consuming due to the large\ndesign space and the inter-dependencies between individual design parameters.\nTo address this challenge, we propose ChartOptimiser -- a Bayesian approach for\ntask-driven optimisation of charts, such as bar charts. At the core of\nChartOptimiser is a novel objective function to automatically optimise an\neight-dimensional design space combining four perceptual metrics: visual\nsaliency, text legibility, colour preference, and white space ratio. Through\nempirical evaluation on 12 bar charts and four common analytical tasks --\nfinding the extreme value, retrieving a value, comparing two values, and\ncomputing a derived value -- we show that ChartOptimiser outperforms existing\ndesign baselines concerning task-solving ease, visual aesthetics, and chart\nclarity. We also discuss two practical applications of ChartOptimiser:\ngenerating charts for accessibility and content localisation. Taken together,\nChartOptimiser opens up an exciting new research direction in automated chart\ndesign where charts are optimised for users' information needs, preferences,\nand contexts.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.10181v1","title":"A New Paradigm in IBR Modeling for Power Flow and Short Circuit Analysis","summary":"The fault characteristics of inverter-based resources (IBRs) are different\nfrom conventional synchronous generators. The fault response of IBRs is\nnon-linear due to saturation states and mainly determined by fault ride through\n(FRT) strategies of the associated voltage source converter (VSC). This results\nin prohibitively large solution times for power flows considering these short\ncircuit characteristics, especially when the power system states change fast\ndue to uncertainty in IBR generations. To overcome this, a phasor-domain steady\nstate (SS) short circuit (SC) solver for IBR dominated power systems is\nproposed in this paper, and subsequently the developed IBR models are\nincorporated with a novel Jacobian-based Power Flow (PF) solver. In this\nmultiphase PF solver, any power system components can be modeled by considering\ntheir original non-linear or linear mathematical representations. Moreover, two\nnovel FRT strategies are proposed to fully utilize the converter capacity and\nto comply with IEEE-2800 2022 std and German grid code. The results are\ncompared with the Electromagnetic Transient (EMT) simulation on the IEEE 34\ntest network and the 120 kV EPRI benchmark system. The developed IBR sequence\ndomain PF model demonstrates more accurate behavior compared to the classical\nIBR generator model. The error in calculating the short circuit current with\nthe proposed SC solver is less than 3%, while achieving significant speed\nimprovements of three order of magnitudes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T12:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.10194v1","title":"Black Hole Singularities from Holographic Complexity","summary":"Using a second law of complexity, we prove a black hole singularity theorem.\nBy introducing the notion of trapped extremal surfaces, we show that their\nexistence implies null geodesic incompleteness inside globally hyperbolic black\nholes. We also demonstrate that the vanishing of the growth rate of the volume\nof extremal surfaces provides a sharp diagnostic of the black hole singularity.\nIn static, uncharged, spherically symmetric spacetimes, this corresponds to the\ngrowth rate of spacelike extremal surfaces going to zero at the singularity. In\ncharged or rotating spacetimes, such as the Reissner-Nordstr\\\"om and Kerr black\nholes, we identify novel timelike extremal surfaces that exhibit the same\nbehavior at the timelike singularity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T12:56:04Z"}
{"aid":"http://arxiv.org/abs/2504.10208v1","title":"From Prompting to Alignment: A Generative Framework for Query\n  Recommendation","summary":"In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-14T13:21:29Z"}
{"aid":"http://arxiv.org/abs/2504.10209v1","title":"Continuity of differential operators for nonarchimedean Banach algebras","summary":"Given a nonarchimedean field $K$ and a commutative, noetherian, Banach\n$K$-algebra $A$, we study continuity of $K$-linear differential operators (in\nthe sense of Grothendieck) between finitely generated Banach $A$-modules. When\n$K$ is of characteristic zero we show that every such operator is continuous if\nand only if $A/\\mathfrak{m}$ is a finite extension of $K$ for every maximal\nideal $\\mathfrak{m}\\subset A$.","main_category":"math.AG","categories":"math.AG,math.FA","published":"2025-04-14T13:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.10215v1","title":"Public Health Insurance of Children and Maternal Labor Market Outcomes","summary":"This paper exploits variation resulting from a series of federal and state\nMedicaid expansions between 1977 and 2017 to estimate the effects of children's\nincreased access to public health insurance on the labor market outcomes of\ntheir mothers. The results imply that the extended Medicaid eligibility of\nchildren leads to positive labor supply responses at the extensive and\nintensive margins of single mothers and to negative labor supply responses at\nthe extensive margin of married mothers. The analysis of mechanisms suggests\nthat extended children's Medicaid eligibility positively affects take-up of\nMedicaid and health of children.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T13:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.10219v1","title":"Inverse design of multiresonance filters via quasi-normal mode theory","summary":"We present a practical methodology for inverse design of compact\nhigh-order/multiresonance filters in linear passive 2-port wave-scattering\nsystems, targeting any desired transmission spectrum (such as standard\npass/stop-band filters). Our formulation allows for both large-scale topology\noptimization and few-variable parametrized-geometry optimization. It is an\nextension of a quasi-normal mode theory and analytical filter-design criteria\n(on the system resonances and background response) derived in our previous\nwork. Our new optimization-oriented formulation relies solely on a scattering\nsolver and imposes these design criteria as equality constraints with easily\ncalculated (via the adjoint method) derivatives, so that our algorithm is\nnumerically tractable, robust, and well-suited for large-scale inverse design.\nWe demonstrate its effectiveness by designing 3rd- and 4th-order elliptic and\nChebyshev filters for photonic metasurfaces, multilayer films, and electrical\nLC-ladder circuits.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.optics","published":"2025-04-14T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.10222v1","title":"PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam\n  Annealing Search","summary":"Recent work increasingly focuses on improving the reasoning capabilities of\nMultimodal Large Language Models (MLLMs). Among existing methods, Process\nReward Models (PRMs) stand out for offering dense, step-wise supervision to\nguide intermediate reasoning. However, how to effectively integrate PRMs into\nsearch strategies remains an open question. In this paper, we introduce PRM-BAS\n(PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided\nreasoning that dynamically adjusts beam size -- starting with a broader search\nspace and gradually narrowing it as contextual information accumulates, thereby\nbalancing performance and efficiency. We further propose a unified framework\nfor data construction and PRM training. Specifically, we construct the\nPRM-BAS-300k dataset by selecting 300k questions from existing datasets and\nperforming rollouts at each step to estimate the probability of reaching a\ncorrect final answer. The PRM is then trained using a combination of value loss\nfor absolute action quality and rank loss for relative action quality.\nExtensive experiments on challenging multimodal reasoning benchmarks\ndemonstrate that PRM-BAS significantly improves reasoning performance while\nmaintaining low computational cost. Moreover, it generalizes well across\ndifferent model scales and architectures, showcasing strong robustness and\nplug-and-play capability.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T13:44:11Z"}
{"aid":"http://arxiv.org/abs/2504.10233v1","title":"Bingo: Radix-based Bias Factorization for Random Walk on Dynamic Graphs","summary":"Random walks are a primary means for extracting information from large-scale\ngraphs. While most real-world graphs are inherently dynamic, state-of-the-art\nrandom walk engines failed to efficiently support such a critical use case.\nThis paper takes the initiative to build a general random walk engine for\ndynamically changing graphs with two key principles: (i) This system should\nsupport both low-latency streaming updates and high-throughput batched updates.\n(ii) This system should achieve fast sampling speed while maintaining\nacceptable space consumption to support dynamic graph updates. Upholding both\nstandards, we introduce Bingo, a GPU-based random walk engine for dynamically\nchanging graphs. First, we propose a novel radix-based bias factorization\nalgorithm to support constant time sampling complexity while supporting fast\nstreaming updates. Second, we present a group-adaption design to reduce space\nconsumption dramatically. Third, we incorporate GPU-aware designs to support\nhigh-throughput batched graph updates on massively parallel platforms.\nTogether, Bingo outperforms existing efforts across various applications,\nsettings, and datasets, achieving up to a 271.11x speedup compared to the\nstate-of-the-art efforts.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T13:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10251v1","title":"Global stability of the Lengyel-Epstein systems","summary":"We study the global (asymptotic) stability of the Lengyel-Epstein\ndifferential systems, sometimes called Belousov-Zhabotinsky differential\nsystems. Such systems are topologically equivalent to a two-parameter family of\ncubic systems in the plane. We show that for each pair of admissible parameters\nthe unique equilibrium point of the corresponding system is not globally\n(asymptotically) stable. On the other hand, we provide explicit conditions for\nthis unique equilibrium point to be asymptotically stable and we study its\nbasin of attraction. We also study the generic and degenerate Hopf bifurcations\nand highlight a subset of the set of admissible parameters for which the phase\nportraits of the systems have two limit cycles.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10266v1","title":"Vision based driving agent for race car simulation environments","summary":"In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-14T14:29:37Z"}
{"aid":"http://arxiv.org/abs/2504.10269v1","title":"Multiple solutions to asymptotically linear problems driven by\n  superposition operators","summary":"In this paper, we investigate the existence and multiplicity of weak\nsolutions to problems involving a superposition operator of the type\n$$\\int_{[0, 1]}(- \\Delta)^s u d \\mu(s),$$ for a signed measure $\\mu$ on the\ninterval of fractional exponents $[0,1]$, when the nonlinearity is subcritical\nand asymptotically linear at infinity; thus, we deal with a perturbation of the\neigenvalue problem for the superposition operator. We use variational tools,\nextending to this setting well-known results for the classical and the\nfractional Laplace operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.10283v1","title":"$α$-Flow: A Unified Framework for Continuous-State Discrete Flow\n  Matching Models","summary":"Recent efforts have extended the flow-matching framework to discrete\ngenerative modeling. One strand of models directly works with the continuous\nprobabilities instead of discrete tokens, which we colloquially refer to as\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\nsignificantly in their representations and geometric assumptions. This work\npresents a unified framework for CS-DFM models, under which the existing\nvariants can be understood as operating on different $\\alpha$-representations\nof probabilities. Building upon the theory of information geometry, we\nintroduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the\ncanonical $\\alpha$-geometry of the statistical manifold, and demonstrate its\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\nthat the flow matching loss for $\\alpha$-flow establishes a unified variational\nbound for the discrete negative log-likelihood. We comprehensively evaluate\ndifferent instantiations of $\\alpha$-flow on various discrete generation\ndomains to demonstrate their effectiveness in discrete generative modeling,\nincluding intermediate values whose geometries have never been explored before.\n$\\alpha$-flow significantly outperforms its discrete-state counterpart in image\nand protein sequence generation and better captures the entropy in language\nmodeling.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.10286v1","title":"Characterizing LLM-driven Social Network: The Chirper.ai Case","summary":"Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-14T14:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.10293v1","title":"Gravity-induced emergence of the Fermi scale in quantum quadratic\n  gravity","summary":"In the framework of asymptotic safety, we study quantum quadratic gravity in\nthe presence of the Higgs field considered as non-separable from the vacuum.\nThe theory flows to a high energy fixed point where the Higgs field is strongly\ncoupled to gravity, its potential is symmetric, and the quadratic Weyl\ncurvature coupling is large. The latter renders the ghost graviton an unstable\nhigh mass resonance which renders unitarity in the spirit of Lee-Week type\ntheories. Furthermore, if the scalar graviton is tachyonic then there will be a\nlow energy fixed point where tachyonic condensation leads to a new stable\nvacuum. At this fixed point the symmetry breaks and the Fermi scale emerges,\nand the behavior of the Higgs field is classical (not influenced by\ngravitational interaction). Gravity at the UV scale is purely quadratic whereas\nat the Fermi scale it is linear, and in the intermediate region both\ncontributions are relevant. Thus, at the Fermi scale the quadratic curvature\nfields disappear through the ghost instability and tachyon condensation, giving\nrise to Einstein gravity and the electroweak phase transition.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-14T15:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.10299v1","title":"IRR-Based AS Type of Relationship Inference","summary":"The Internet comprises tens of thousands of autonomous systems (ASes) whose\ncommercial relationships are not publicly announced. The classification of the\nType of Relationship (ToR) between ASes has been extensively studied over the\npast two decades due to its relevance in network routing management and\nsecurity.\n  This paper presents a new approach to ToR classification, leveraging publicly\navailable BGP data from the Internet Routing Registry (IRR). We show how the\nIRR can be mined and the results refined to achieve a large and accurate ToR\ndatabase. Using a ground truth database with hundreds of entries we show that\nwe indeed manage to obtain high accuracy. About two-thirds of our ToRs are new,\nnamely, they were not obtained by previous works, which means that we enrich\nour ToR knowledge with links that are otherwise missed.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T15:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.10303v1","title":"Row completion of polynomial and rational matrices","summary":"We characterize the existence of a polynomial (rational) matrix when its\neigenstructure (complete structural data) and some of its rows are prescribed.\nFor polynomial matrices, this problem was solved in a previous work when the\npolynomial matrix has the same degree as the prescribed submatrix. In that\npaper, the following row completion problems were also solved arising when the\neigenstructure was partially prescribed, keeping the restriction on the degree:\nthe eigenstructure but the row (column) minimal indices, and the finite and/or\ninfinite structures. Here we remove the restriction on the degree, allowing it\nto be greater than or equal to that of the submatrix. We also generalize the\nresults to rational matrices. Obviously, the results obtained hold for the\ncorresponding column completion problems.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T15:11:19Z"}
{"aid":"http://arxiv.org/abs/2504.10321v1","title":"Indecomposable bundles on Cartesian products of odd projective spaces","summary":"In this paper we construct indecomposable vector bundles associated to monads\non Cartesian products of odd dimension projective spaces. Specifically we\nestablish the existence of monads on\n$(\\mathbb{P}^1)^{l_1}\\times\\cdots\\times(\\mathbb{P}^{2n+1})^{l_m}$. We prove\nstability of the kernel bundle and prove that the cohomology bundle is simple.\nWe also prove the same for monads on\n$(\\mathbb{P}^n)^2\\times(\\mathbb{P}^m)^2\\times(\\mathbb{P}^l)^2$ for an ample\nline bundle\n$\\mathscr{L}=\\mathcal{O}_X(\\alpha,\\alpha,\\beta,\\beta,\\gamma,\\gamma)$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.10339v1","title":"Gyroscopically stabilized quantum spin rotors","summary":"Recent experiments demonstrate all-electric spinning of levitated\nnanodiamonds with embedded nitrogen-vacancy spins. Here, we argue that such\ngyroscopically stabilized spin rotors offer a promising platform for probing\nand exploiting quantum spin-rotation coupling of particles hosting a single\nspin degree of freedom. Specifically, we derive the effective Hamiltonian\ndescribing how an embedded spin affects the rotation of rapidly revolving\nquantum rotors due to the Einstein-de Haas and Barnett effects, which we use to\ndevise experimental protocols for observing this coupling in state-of-the-art\nexperiments. This will open the door for future exploitations of quantum spin\nrotors for superposition experiments with massive objects.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.10345v1","title":"AraOS: Analyzing the Impact of Virtual Memory Management on Vector Unit\n  Performance","summary":"Vector processor architectures offer an efficient solution for accelerating\ndata-parallel workloads (e.g., ML, AI), reducing instruction count, and\nenhancing processing efficiency. This is evidenced by the increasing adoption\nof vector ISAs, such as Arm's SVE/SVE2 and RISC-V's RVV, not only in\nhigh-performance computers but also in embedded systems. The open-source nature\nof RVV has particularly encouraged the development of numerous vector processor\ndesigns across industry and academia. However, despite the growing number of\nopen-source RVV processors, there is a lack of published data on their\nperformance in a complex application environment hosted by a full-fledged\noperating system (Linux). In this work, we add OS support to the open-source\nbare-metal Ara2 vector processor (AraOS) by sharing the MMU of CVA6, the scalar\ncore used for instruction dispatch to Ara2, and integrate AraOS into the\nopen-source Cheshire SoC platform. We evaluate the performance overhead of\nvirtual-to-physical address translation by benchmarking matrix multiplication\nkernels across several problem sizes and translation lookaside buffer (TLB)\nconfigurations in CVA6's shared MMU, providing insights into vector performance\nin a full-system environment with virtual memory. With at least 16 TLB entries,\nthe virtual memory overhead remains below 3.5%. Finally, we benchmark a 2-lane\nAraOS instance with the open-source RiVEC benchmark suite for RVV\narchitectures, with peak average speedups of 3.2x against scalar-only\nexecution.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T15:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.10351v1","title":"Multimodal Representation Learning Techniques for Comprehensive Facial\n  State Analysis","summary":"Multimodal foundation models have significantly improved feature\nrepresentation by integrating information from multiple modalities, making them\nhighly suitable for a broader set of applications. However, the exploration of\nmultimodal facial representation for understanding perception has been limited.\nUnderstanding and analyzing facial states, such as Action Units (AUs) and\nemotions, require a comprehensive and robust framework that bridges visual and\nlinguistic modalities. In this paper, we present a comprehensive pipeline for\nmultimodal facial state analysis. First, we compile a new Multimodal Face\nDataset (MFA) by generating detailed multilevel language descriptions of face,\nincorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.\nSecond, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)\ntailored for Action Unit (AU) and emotion recognition. Our model incorporates\ncomprehensive visual feature modeling at both local and global levels of face\nimage, enhancing its ability to represent detailed facial appearances. This\ndesign aligns visual representations with structured AU and emotion\ndescriptions, ensuring effective cross-modal integration. Third, we develop a\nDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various\ntasks and datasets. This approach not only reduces computational overhead but\nalso broadens the applicability of the foundation model to diverse scenarios.\nExperimentation show superior performance for AU and emotion detection tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:57Z"}
{"aid":"http://arxiv.org/abs/2504.10352v1","title":"Pseudo-Autoregressive Neural Codec Language Models for Efficient\n  Zero-Shot Text-to-Speech Synthesis","summary":"Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://anonymous-palle.github.io.","main_category":"eess.AS","categories":"eess.AS,cs.CL","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10383v1","title":"A monotonicity formula for a semilinear fractional parabolic equation","summary":"By applying a high-dimensional parabolic-to-elliptic transformation, we\nestablish a monotonicity formula for the extension problem of the fractional\nparabolic semilinear equation $(\\partial_t -\\Delta)^s u = |u|^{p-1}u$, where\n$0<s<1$. This is an analogous result to the Giga-Kohn monotonicity formula for\nthe equation $\\partial_t u - \\Delta u = |u|^{p-1}u.$","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.10384v1","title":"A 10.8mW Mixed-Signal Simulated Bifurcation Ising Solver using SRAM\n  Compute-In-Memory with 0.6us Time-to-Solution","summary":"Combinatorial optimization problems are funda- mental for various fields\nranging from finance to wireless net- works. This work presents a simulated\nbifurcation (SB) Ising solver in CMOS for NP-hard optimization problems. Analog\ndomain computing led to a superior implementation of this algorithm as inherent\nand injected noise is required in SB Ising solvers. The architecture novelties\ninclude the use of SRAM compute-in-memory (CIM) to accelerate bifurcation as\nwell as the generation and injection of optimal decaying noise in the analog\ndomain. We propose a novel 10-T SRAM cell capable of performing ternary\nmultiplication. When measured with 60- node, 50% density, random, binary MAXCUT\ngraphs, this all- to-all connected Ising solver reliably achieves above 93% of\nthe ground state solution in 0.6us with 10.8mW average power in TSMC 180nm\nCMOS. Our chip achieves an order of magnitude improvement in time-to-solution\nand power compared to previously proposed Ising solvers in CMOS and other\nplatforms.","main_category":"eess.SY","categories":"eess.SY,cs.CL,cs.SY","published":"2025-04-14T16:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.10385v1","title":"Normalized solutions for Schrödinger-Bopp-Podolsky systems in bounded\n  domains","summary":"We consider an elliptic system of Schr\\\"odinger-Bopp-Podolsky type in a\nbounded and smooth domain of R3 with a non constant coupling factor. This kind\nof system has been introduced in the mathematical literature in [14] and in the\nlast years many contributions appeared. In particular here we present the\nresults in [2] and [34] which show existence of solutions by means of the\nLjusternik-Schnirelmann theory under different boundary conditions on the\nelectrostatic potential.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:31Z"}
{"aid":"http://arxiv.org/abs/2504.10391v1","title":"LLM-driven Constrained Copy Generation through Iterative Refinement","summary":"Crafting a marketing message (copy), or copywriting is a challenging\ngeneration task, as the copy must adhere to various constraints. Copy creation\nis inherently iterative for humans, starting with an initial draft followed by\nsuccessive refinements. However, manual copy creation is time-consuming and\nexpensive, resulting in only a few copies for each use case. This limitation\nrestricts our ability to personalize content to customers. Contrary to the\nmanual approach, LLMs can generate copies quickly, but the generated content\ndoes not consistently meet all the constraints on the first attempt (similar to\nhumans). While recent studies have shown promise in improving constrained\ngeneration through iterative refinement, they have primarily addressed tasks\nwith only a few simple constraints. Consequently, the effectiveness of\niterative refinement for tasks such as copy generation, which involves many\nintricate constraints, remains unclear. To address this gap, we propose an\nLLM-based end-to-end framework for scalable copy generation using iterative\nrefinement. To the best of our knowledge, this is the first study to address\nmultiple challenging constraints simultaneously in copy generation. Examples of\nthese constraints include length, topics, keywords, preferred lexical ordering,\nand tone of voice. We demonstrate the performance of our framework by creating\ncopies for e-commerce banners for three different use cases of varying\ncomplexity. Our results show that iterative refinement increases the copy\nsuccess rate by $16.25-35.91$% across use cases. Furthermore, the copies\ngenerated using our approach outperformed manually created content in multiple\npilot studies using a multi-armed bandit framework. The winning copy improved\nthe click-through rate by $38.5-45.21$%.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.10409v1","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for\n  Efficient Online Class-Incremental Learning","summary":"Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.10416v1","title":"Region Based SLAM-Aware Exploration: Efficient and Robust Autonomous\n  Mapping Strategy That Can Scale","summary":"Autonomous exploration for mapping unknown large scale environments is a\nfundamental challenge in robotics, with efficiency in time, stability against\nmap corruption and computational resources being crucial. This paper presents a\nnovel approach to indoor exploration that addresses these key issues in\nexisting methods. We introduce a Simultaneous Localization and Mapping\n(SLAM)-aware region-based exploration strategy that partitions the environment\ninto discrete regions, allowing the robot to incrementally explore and\nstabilize each region before moving to the next one. This approach\nsignificantly reduces redundant exploration and improves overall efficiency. As\nthe device finishes exploring a region and stabilizes it, we also perform SLAM\nkeyframe marginalization, a technique which reduces problem complexity by\neliminating variables, while preserving their essential information. To\nimproves robustness and further enhance efficiency, we develop a check- point\nsystem that enables the robot to resume exploration from the last stable region\nin case of failures, eliminating the need for complete re-exploration. Our\nmethod, tested in real homes, office and simulations, outperforms\nstate-of-the-art approaches. The improvements demonstrate substantial\nenhancements in various real world environments, with significant reductions in\nkeyframe usage (85%), submap usage (50% office, 32% home), pose graph\noptimization time (78-80%), and exploration duration (10-15%). This\nregion-based strategy with keyframe marginalization offers an efficient\nsolution for autonomous robotic mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.10417v1","title":"Silent Self-Stabilizing Ranking: Time Optimal and Space Efficient","summary":"We present a silent, self-stabilizing ranking protocol for the population\nprotocol model of distributed computing, where agents interact in randomly\nchosen pairs to solve a common task. We are given $n$ anonymous agents, and the\ngoal is to assign each agent a unique rank in $\\{1, \\dots, n\\}$. Given unique\nranks, it is straightforward to select a designated leader. Thus, our protocol\nis a self-stabilizing leader election protocol as well. Ranking requires at\nleast $n$ states per agent; hence, the goal is to minimize the additional\nnumber of states, called overhead states. The core of our protocol is a\nspace-efficient but non-self-stabilizing ranking protocol that requires only $n\n+ O(\\log n)$ states. Our protocol stabilizes in $O(n^2\\log n)$ interactions\nw.h.p.\\ and in expectation, using $n + O(\\log^2 n)$ states in total. Our\nstabilization time is asymptotically optimal (see Burman et al., PODC'21). In\ncomparison to the currently best known ranking protocol by Burman et al., which\nrequires $n + \\Omega(n)$ states, our result exponentially improves the number\nof overhead states.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T17:04:19Z"}
{"aid":"http://arxiv.org/abs/2504.10418v1","title":"CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical\n  Interview Dialogue Reconstruction and Evaluation","summary":"Large language models (LLMs) hold great promise for assisting clinical\ninterviews due to their fluent interactive capabilities and extensive medical\nknowledge. However, the lack of high-quality interview dialogue data and widely\naccepted evaluation methods has significantly impeded this process. So we\npropose CliniChat, a framework that integrates multi-source knowledge to enable\nLLMs to simulate real-world clinical interviews. It consists of two modules:\nClini-Recon and Clini-Eval, each responsible for reconstructing and evaluating\ninterview dialogues, respectively. By incorporating three sources of knowledge,\nClini-Recon transforms clinical notes into systematic, professional, and\nempathetic interview dialogues. Clini-Eval combines a comprehensive evaluation\nmetric system with a two-phase automatic evaluation approach, enabling LLMs to\nassess interview performance like experts. We contribute MedQA-Dialog, a\nhigh-quality synthetic interview dialogue dataset, and CliniChatGLM, a model\nspecialized for clinical interviews. Experimental results demonstrate that\nCliniChatGLM's interview capabilities undergo a comprehensive upgrade,\nparticularly in history-taking, achieving state-of-the-art performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.10426v1","title":"Spectral Mode Enhancement in Coherent-harmonic Dual-comb Spectroscopy\n  Enables Exceeding 300-fold Averaging Time Reduction","summary":"Dual-comb spectroscopy (DCS) is a novel Fourier-transform spectroscopy not\nrelying on mechanical scanning and capable of simultaneously achieving\nhigh-speed, high spectral resolution, and broad optical bandwidth. Despite\nthis, conventional DCS suffers from low signal-to-noise ratio (SNR) per single\nacquisition due to the dynamic range limitation of photodetectors imposed by\nthe high peak power of mode-locked pulses, necessitating coherent averaging.\nConsequently, averaging numerous interferograms compromises both the\nexceptional time resolution and places greater demands on long-term mutual\ncoherence and stability. In this study, we demonstrate a novel approach to\nenhance SNR by exploiting the spectral mode enhancement mechanism in\ncoherent-harmonic pulses. As a proof-of-concept, we employ two frequency combs\nwith mode spacing of $\\sim$12.5 MHz, operating at a 20th harmonic repetition\nrate of $\\sim$250 MHz. The result demonstrates a $>$300-fold reduction in\naveraging time while achieving comparable SNR in conventional DCS. This\nreduction is expected to be further enhancement through integration with\nultra-high repetition rate combs, such as microresonator combs. This approach\npromises both a recovery of the inherent high-speed capability and a mitigation\nof the coherence-time requirements, thereby making it possible to significantly\nfacilitate subsequent DCS investigations, as well as field-deployed\nimplementations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T17:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.10427v1","title":"On roots of normal operators and extensions of Ando's Theorem","summary":"In this paper, we extend Ando's theorem on paranormal operators, which states\nthat if $ T \\in \\mathfrak{B}(\\mathcal{H}) $ is a paranormal operator and there\nexists $ n \\in \\mathbb{N} $ such that $ T^n $ is normal, then $ T $ is normal.\nWe generalize this result to the broader classes of $ k $-paranormal operators\nand absolute-$ k $-paranormal operators. Furthermore, in the case of a\nseparable Hilbert space $\\mathcal{H}$, we show that if $ T \\in\n\\mathfrak{B}(\\mathcal{H}) $ is a $ k $-quasi-paranormal operator for some $ k\n\\in \\mathbb{N} $, and there exists $ n \\in \\mathbb{N} $ such that $ T^n $ is\nnormal, then $ T $ decomposes as $ T = T' \\oplus T'' $, where $ T' $ is normal\nand $ T'' $ is nilpotent of nil-index at most $ \\min\\{n,k+1\\} $, with either\nsummand potentially absent.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T17:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.10430v1","title":"LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety\n  in Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.HC","published":"2025-04-14T17:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.10434v1","title":"Anchor Token Matching: Implicit Structure Locking for Training-free AR\n  Image Editing","summary":"Text-to-image generation has seen groundbreaking advancements with diffusion\nmodels, enabling high-fidelity synthesis and precise image editing through\ncross-attention manipulation. Recently, autoregressive (AR) models have\nre-emerged as powerful alternatives, leveraging next-token generation to match\ndiffusion models. However, existing editing techniques designed for diffusion\nmodels fail to translate directly to AR models due to fundamental differences\nin structural control. Specifically, AR models suffer from spatial poverty of\nattention maps and sequential accumulation of structural errors during image\nediting, which disrupt object layouts and global consistency. In this work, we\nintroduce Implicit Structure Locking (ISLock), the first training-free editing\nstrategy for AR visual models. Rather than relying on explicit attention\nmanipulation or fine-tuning, ISLock preserves structural blueprints by\ndynamically aligning self-attention patterns with reference images through the\nAnchor Token Matching (ATM) protocol. By implicitly enforcing structural\nconsistency in latent space, our method ISLock enables structure-aware editing\nwhile maintaining generative autonomy. Extensive experiments demonstrate that\nISLock achieves high-quality, structure-consistent edits without additional\ntraining and is superior or comparable to conventional editing techniques. Our\nfindings pioneer the way for efficient and flexible AR-based image editing,\nfurther bridging the performance gap between diffusion and autoregressive\ngenerative models. The code will be publicly available at\nhttps://github.com/hutaiHang/ATM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.10439v1","title":"Bayesian Analysis of Interpretable Aging across Thousands of Lithium-ion\n  Battery Cycles","summary":"The Doyle-Fuller-Newman (DFN) model is a common mechanistic model for\nlithium-ion batteries. The reaction rate constant and diffusivity within the\nDFN model are key parameters that directly affect the movement of lithium ions,\nthereby offering explanations for cell aging. This work investigates the\nability to uniquely estimate each electrode's diffusion coefficients and\nreaction rate constants of 95 Tesla Model 3 cells with a nickel cobalt aluminum\noxide (NCA) cathode and silicon oxide--graphite\n(LiC$_\\text{6}$--SiO$_{\\text{x}}$) anode. The parameters are estimated at\nintermittent diagnostic cycles over the lifetime of each cell. The four\nparameters are estimated using Markov chain Monte Carlo (MCMC) for uncertainty\nquantification (UQ) for a total of 7776 cycles at discharge C-rates of C/5, 1C,\nand 2C. While one or more anode parameters are uniquely identifiable over every\ncell's lifetime, cathode parameters become identifiable at mid- to end-of-life,\nindicating measurable resistive growth in the cathode. The contribution of key\nparameters to the state of health (SOH) is expressed as a power law. This model\nfor SOH shows a high consistency with the MCMC results performed over the\noverall lifespan of each cell. Our approach suggests that effective diagnosis\nof aging can be achieved by predicting the trajectories of the parameters\ncontributing to cell aging. As such, extending our analysis with more\nphysically accurate models building on DFN may lead to more identifiable\nparameters and further improved aging predictions.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:31:16Z"}
{"aid":"http://arxiv.org/abs/2504.10440v1","title":"HybridCollab: Unifying In-Person and Remote Collaboration for\n  Cardiovascular Surgical Planning in Mobile Augmented Reality","summary":"Surgical planning for congenital heart disease traditionally relies on\ncollaborative group examinations of a patient's 3D-printed heart model, a\nprocess that lacks flexibility and accessibility. While mobile augmented\nreality (AR) offers a promising alternative with its portability and familiar\ninteraction gestures, existing solutions limit collaboration to users in the\nsame physical space. We developed HybridCollab, the first iOS AR application\nthat introduces a novel paradigm that enables both in-person and remote medical\nteams to interact with a shared AR heart model in a single surgical planning\nsession. For example, a team of two doctors in one hospital room can\ncollaborate in real time with another team in a different hospital.Our approach\nis the first to leverage Apple's GameKit service for surgical planning,\nensuring an identical collaborative experience for all participants, regardless\nof location. Additionally, co-located users can interact with the same anchored\nheart model in their shared physical space. By bridging the gap between remote\nand in-person collaboration across medical teams, HybridCollab has the\npotential for significant real-world impact, streamlining communication and\nenhancing the effectiveness of surgical planning. Watch the demo:\nhttps://youtu.be/hElqJYDuvLM.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T17:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10442v1","title":"Pinching-Antenna System (PASS) Enhanced Covert Communications","summary":"A Pinching-Antenna SyStem (PASS)-assisted convert communication framework is\nproposed. PASS utilizes dielectric waveguides with freely positioned pinching\nantennas (PAs) to establish strong line-of-sight links. Capitalizing on this\nhigh reconfigurable flexibility of antennas, the potential of PASS for covert\ncommunications is investigated. 1)~For the single-waveguide single-PA (SWSP)\nscenario, a closed-form optimal PA position that maximizes the covert rate is\nfirst derived. Subsequently, a one-dimensional power search is employed to\nenable low-complexity optimization for covert communications. With antenna\nmobility on a scale of meters, PASS can deal with the challenging situation of\nthe eavesdropper enjoying better channel conditions than the legal user. 2)~For\nthe multi-waveguide multi-PA (MWMP) scenario, the positions of multiple PAs are\noptimized to enable effective pinching beamforming, thereby enhancing the\ncovert rate. To address the resultant multimodal joint transmit and pinching\nbeamforming problem, a twin particle swarm optimization (TwinPSO) approach is\nproposed. Numerical results demonstrate that: i)~the proposed approaches can\neffectively resolve the optimization problems; ii)~PASS achieves a higher\ncovert rate than conventional fixed-position antenna architectures; and\niii)~with enhanced flexibility, the MWMP setup outperforms the SWSP\ncounterpart.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T17:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.10446v1","title":"Evolution equations on co-evolving graphs: long-time behaviour and the\n  graph continuity equation","summary":"We focus on evolution equations on co-evolving, infinite, graphs and\nestablish a rigorous link with a class of nonlinear continuity equations, whose\nvector fields depend on the graphs considered. More precisely, weak solutions\nof the so-called graph-continuity equation are shown to be the push-forward of\ntheir initial datum through the flow map solving the associated\ncharacteristics' equation, which depends on the co-evolving graph considered.\nThis connection can be used to prove contractions in a suitable distance,\nalthough the flow on the graphs requires a too limiting assumption on the\noverall flux. Therefore, we consider upwinding dynamics on graphs with\npointwise and monotonic velocity and prove long-time convergence of the\nsolutions towards the uniform mass distribution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T17:36:55Z"}
{"aid":"http://arxiv.org/abs/2504.10448v1","title":"A High-Precision, Fast, Robust, and Cost-Effective Muon Detector Concept\n  for the FCC-ee","summary":"We propose a high-precision, fast, robust and cost-effective muon detector\nconcept for an FCC-ee experiment. This design combines precision drift tubes\nwith fast plastic scintillator strips to enable both spatial and timing\nmeasurements. The drift tubes deliver two-dimensional position measurements\nperpendicular to the tubes with a resolution around 100~$\\mu$m. Meanwhile, the\nscintillator strips, read out with the wavelength-shifting fibers and silicon\nphotomultipliers, provide fast timing information with a precision of 200~ps or\nbetter and measure the third coordinate along the tubes with a resolution of\nabout 1~mm.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-14T17:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.10450v1","title":"AC Current-Driven Magnetization Switching and Nonlinear Hall\n  Rectification in a Magnetic Topological Insulator","summary":"Spin-orbit torque arising from the spin-orbit-coupled surface states of\ntopological insulators enables current-induced control of magnetization with\nhigh efficiency. Here, alternating-current (AC) driven magnetization reversal\nis demonstrated in a semi-magnetic topological insulator\n(Cr,Bi,Sb)2Te3/(Bi,Sb)2Te3, facilitated by a low threshold current density of\n1.5x10^9 A/m^2. Time-domain Hall voltage measurements using an oscilloscope\nreveal a strongly nonlinear and nonreciprocal Hall response during the\nmagnetization reversal process. Fourier analysis of the time-varying Hall\nvoltage identifies higher-harmonic signals and a rectified direct-current (DC)\ncomponent, highlighting the complex interplay among the applied current,\nexternal magnetic field, and magnetization dynamics. Furthermore, a hysteretic\nbehavior in the current-voltage characteristics gives rise to frequency mixing\nunder dual-frequency excitation. This effect, distinct from conventional\npolynomial-based nonlinearities, allows for selective extraction of specific\nfrequency components. The results demonstrate that AC excitation can not only\nswitch magnetization efficiently but also induce tunable nonlinear responses,\noffering a new pathway for multifunctional spintronic devices with potential\napplications in energy-efficient memory, signal processing, and frequency\nconversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T17:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.10459v1","title":"The Price of Competitive Information Disclosure","summary":"In many decision-making scenarios, individuals strategically choose what\ninformation to disclose to optimize their own outcomes. It is unclear whether\nsuch strategic information disclosure can lead to good societal outcomes. To\naddress this question, we consider a competitive Bayesian persuasion model in\nwhich multiple agents selectively disclose information about their qualities to\na principal, who aims to choose the candidates with the highest qualities.\nUsing the price-of-anarchy framework, we quantify the inefficiency of such\nstrategic disclosure. We show that the price of anarchy is at most a constant\nwhen the agents have independent quality distributions, even if their utility\nfunctions are heterogeneous. This result provides the first theoretical\nguarantee on the limits of inefficiency in Bayesian persuasion with competitive\ninformation disclosure.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-14T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.10463v1","title":"Influence of excitonic coupling, static disorder, and coherent dynamics\n  in action-2D electronic spectroscopy of a molecular dimer model","summary":"We investigate the spectral features of Action-2D Electronic Spectroscopy\n(A-2DES) in a molecular dimer model across different regimes of excitonic\ncoupling. By explicitly including a second-excited state for each chromophore,\nwe simulate A-2DES spectra ranging from the non-interacting limit to the\nstrong-coupling case, focusing on the significance of cross peaks. While for\nweak excitonic coupling, cross peaks can be understood as the incoherent mixing\nof linear signals of the two chromophores, these features reflect excitonic\ndelocalization as the coupling increases. We highlight that A-2DES offers\nenhanced sensitivity to coherent excited-state dynamics, particularly in the\nintermediate-coupling regime, where it provides higher contrast compared to its\ncoherent-detected counterpart. Finally, we show that static disorder reduces\nthe relative amplitude of cross peaks compared to diagonal features in a way\nthat depends on the excitonic coupling. Notably, the relative suppression of\ncross peaks decreases with the strength of the excitonic coupling, implying\nthat spectral features related to incoherent mixing are less prominent in\ninhomogeneous samples. These findings support the potential of A-2DES for\ninvestigating excitonic dynamics in small multi-chromophoric systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T17:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.10464v1","title":"Implications of distance duality violation for the $H_0$ tension and\n  evolving dark energy","summary":"We investigate whether a violation of the distance duality relation (DDR),\n$D_L(z) = (1+z)^2 D_A(z)$, connecting the angular diameter and luminosity\ndistances, can explain the Hubble tension and alter the evidence for dynamical\ndark energy in recent cosmological observations. We constrain five\nphenomenological parameterisations of DDR violation using Baryon Acoustic\nOscillation measurements from the DESI survey calibrated with the sound horizon\nderived from \\textit{Planck} Cosmic Microwave Background data and the Pantheon+\nType Ia supernova (SNIa) catalogue calibrated with the supernova absolute\nmagnitude from S$H_0$ES. We find that two toy models can resolve the tension: a\nconstant offset in the DDR (equivalent to a shift in the calibration of the\nSNIa data), $D_L(z)/D_A(z)\\simeq 0.925(1+z)^2$, which leaves the hint for\nevolving dark energy unaffected; or a change in the power-law\nredshift-dependence of the DDR, restricted to $z\\lesssim 1$,\n$D_L(z)/D_A(z)\\simeq(1+z)^{1.866}$, together with a {\\it constant} phantom dark\nenergy equation of state $w\\sim -1.155$. The Bayesian evidence slightly favours\nthe latter model. Our phenomenological approach motivates the investigation of\nphysical models of DDR violation as a novel way to explain the Hubble tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-14T17:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.10467v1","title":"De-excitation of $K$-shell hollow atoms with $12 \\le Z \\le 20$:\n  transition rates and branching ratios","summary":"Investigating $K$-shell hollow atom spectra enhances our understanding of\nfemtosecond phenomena in atomic physics, chemistry, and biology. Synchrotron\nmeasurements of two-electron one-photon (TEOP) transitions in low-$Z$ atoms\nhave revealed discrepancies between experimental results and theoretical\npredictions of TEOP relative intensities. These discrepancies appear to\noriginate from an incomplete description of an atom's response to the strong\nperturbation caused by $K$-shell double photoionization (DPI). The\nmulticonfiguration Dirac-Hartree-Fock relativistic configuration interaction\nmethod has been applied for studying the TEOP spectra of Mg, Al, Si, S, Ar, and\nCa atoms. The results show that branching ratios can be accurately reproduced\nby accounting for the effects of core and valence electron correlations, as\nwell as the outer-shell ionization and excitation processes following $K$-shell\nDPI.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-14T17:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10469v1","title":"Bounds as blueprints: towards optimal and accelerated photonic inverse\n  design","summary":"Our ability to structure materials at the nanoscale has, and continues to,\nenable key advances in optical control. In pursuit of optimal photonic designs,\nsubstantial progress has been made on two complementary fronts: bottom-up\nstructural optimizations (inverse design) discover complex high-performing\nstructures but offer no guarantees of optimality; top-down field optimizations\n(convex relaxations) reveal fundamental performance limits but offer no\nguarantees that structures meeting the limits exist. We bridge the gap between\nthese two parallel paradigms by introducing a ``verlan'' initialization method\nthat exploits the encoded local and global wave information in duality-based\nconvex relaxations to guide inverse design towards better-performing\nstructures. We illustrate this technique via the challenging problem of Purcell\nenhancement, maximizing the power extracted from a small emitter in the\nvicinity of a photonic structure, where ill-conditioning and the presence of\ncompeting local maxima lead to sub-optimal designs for adjoint optimization.\nStructures discovered by our verlan method outperform standard (random)\ninitializations by close to an order of magnitude and approach fundamental\nperformance limits within a factor of two, highlighting the possibility of\naccessing significant untapped performance improvements.","main_category":"physics.optics","categories":"physics.optics,math.OC","published":"2025-04-14T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.10470v1","title":"Online Advanced Labs in Physics","summary":"At Arizona State University we have built the first and only fully online\nBachelor of Science degree in Physics, with a complete curriculum, including\nlabs. The upper division Advanced Lab courses present a special challenge for\nonline delivery. We address that using a set of custom-built simulator modules\nthat replicate all the imperfections (noise, background, etc) inherent in\nreal-world data. The set of experiments duplicates those of the in-person\nclasses. In this paper, we present an overview of these labs and discuss the\nadvantages and challenges of delivering them online. We assert that these labs\nprovide a valid and rigorous component for the fully online degree. The entire\nset of labs is available as Open Source Supplemental Materials and is shared\nfor others to use in part or in whole, with suitable attribution.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-14T17:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10481v1","title":"xVerify: Efficient Answer Verifier for Reasoning Model Evaluations","summary":"With the release of the o1 model by OpenAI, reasoning models adopting slow\nthinking strategies have gradually emerged. As the responses generated by such\nmodels often include complex reasoning, intermediate steps, and\nself-reflection, existing evaluation methods are often inadequate. They\nstruggle to determine whether the LLM output is truly equivalent to the\nreference answer, and also have difficulty identifying and extracting the final\nanswer from long, complex responses. To address this issue, we propose xVerify,\nan efficient answer verifier for reasoning model evaluations. xVerify\ndemonstrates strong capability in equivalence judgment, enabling it to\neffectively determine whether the answers produced by reasoning models are\nequivalent to reference answers across various types of objective questions. To\ntrain and evaluate xVerify, we construct the VAR dataset by collecting\nquestion-answer pairs generated by multiple LLMs across various datasets,\nleveraging multiple reasoning models and challenging evaluation sets designed\nspecifically for reasoning model assessment. A multi-round annotation process\nis employed to ensure label accuracy. Based on the VAR dataset, we train\nmultiple xVerify models of different scales. In evaluation experiments\nconducted on both the test set and generalization set, all xVerify models\nachieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest\nvariant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o,\nwhile xVerify-3B-Ib surpasses GPT-4o in overall performance. These results\nvalidate the effectiveness and generalizability of xVerify.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10483v1","title":"REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion\n  Transformers","summary":"In this paper we tackle a fundamental question: \"Can we train latent\ndiffusion models together with the variational auto-encoder (VAE) tokenizer in\nan end-to-end manner?\" Traditional deep-learning wisdom dictates that\nend-to-end training is often preferable when possible. However, for latent\ndiffusion transformers, it is observed that end-to-end training both VAE and\ndiffusion-model using standard diffusion-loss is ineffective, even causing a\ndegradation in final performance. We show that while diffusion loss is\nineffective, end-to-end training can be unlocked through the\nrepresentation-alignment (REPA) loss -- allowing both VAE and diffusion model\nto be jointly tuned during the training process. Despite its simplicity, the\nproposed training recipe (REPA-E) shows remarkable performance; speeding up\ndiffusion model training by over 17x and 45x over REPA and vanilla training\nrecipes, respectively. Interestingly, we observe that end-to-end tuning with\nREPA-E also improves the VAE itself; leading to improved latent space structure\nand downstream generation performance. In terms of final performance, our\napproach sets a new state-of-the-art; achieving FID of 1.26 and 1.83 with and\nwithout classifier-free guidance on ImageNet 256 x 256. Code is available at\nhttps://end2end-diffusion.github.io.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.10484v1","title":"Generalized Symmetries of Non-SUSY and Discrete Torsion String\n  Backgrounds","summary":"String / M-theory backgrounds with degrees of freedom at a localized\nsingularity provide a general template for generating strongly correlated\nsystems decoupled from lower-dimensional gravity. There are by now several\ncomplementary procedures for extracting the associated generalized symmetry\ndata from orbifolds of the form $\\mathbb{R}^6 / \\Gamma$, including methods\nbased on the boundary topology of the asymptotic geometry, as well as the\nadjacency matrix for fermionic degrees of freedom in the quiver gauge theory of\nprobe branes. In this paper we show that this match between the two methods\nalso works in non-supersymmetric and discrete torsion backgrounds. In\nparticular, a refinement of geometric boundary data based on Chen-Ruan\ncohomology matches the expected answer based on quiver data. Additionally, we\nalso show that free (i.e., non-torsion) factors count the number of\nhigher-dimensional branes which couple to the localized singularity. We use\nthis to also extract quadratic pairing terms in the associated symmetry theory\n(SymTh) for these systems, and explain how these considerations generalize to a\nbroader class of backgrounds.","main_category":"hep-th","categories":"hep-th,math.AT,math.RT","published":"2025-04-14T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.10486v1","title":"DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar\n  Relighting","summary":"Creating relightable and animatable human avatars from monocular videos is a\nrising research topic with a range of applications, e.g. virtual reality,\nsports, and video games. Previous works utilize neural fields together with\nphysically based rendering (PBR), to estimate geometry and disentangle\nappearance properties of human avatars. However, one drawback of these methods\nis the slow rendering speed due to the expensive Monte Carlo ray tracing. To\ntackle this problem, we proposed to distill the knowledge from implicit neural\nfields (teacher) to explicit 2D Gaussian splatting (student) representation to\ntake advantage of the fast rasterization property of Gaussian splatting. To\navoid ray-tracing, we employ the split-sum approximation for PBR appearance. We\nalso propose novel part-wise ambient occlusion probes for shadow computation.\nShadow prediction is achieved by querying these probes only once per pixel,\nwhich paves the way for real-time relighting of avatars. These techniques\ncombined give high-quality relighting results with realistic shadow effects.\nOur experiments demonstrate that the proposed student model achieves comparable\nor even better relighting results with our teacher model while being 370 times\nfaster at inference time, achieving a 67 FPS rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:58Z"}
