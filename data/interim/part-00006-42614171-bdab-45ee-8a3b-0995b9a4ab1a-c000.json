{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21690v1","title":"CMED: A Child Micro-Expression Dataset","summary":"Micro-expressions are short bursts of emotion that are difficult to hide.\nTheir detection in children is an important cue to assist psychotherapists in\nconducting better therapy. However, existing research on the detection of\nmicro-expressions has focused on adults, whose expressions differ in their\ncharacteristics from those of children. The lack of research is a direct\nconsequence of the lack of a child-based micro-expressions dataset as it is\nmuch more challenging to capture children's facial expressions due to the lack\nof predictability and controllability. This study compiles a dataset of\nspontaneous child micro-expression videos, the first of its kind, to the best\nof the authors knowledge. The dataset is captured in the wild using video\nconferencing software. This dataset enables us to then explore key features and\ndifferences between adult and child micro-expressions. This study also\nestablishes a baseline for the automated spotting and recognition of\nmicro-expressions in children using three approaches comprising of hand-created\nand learning-based approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:55:32Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21706v1","title":"Flashlights: Prospects for constraining the Initial Mass Function around\n  cosmic noon with caustic-crossing events","summary":"The Flashlights program with the Hubble Space Telescope imaged the six Hubble\nFrontier Fields galaxy clusters in two epochs and detected twenty transients.\nThese are primarily expected to be caustic-crossing events (CCEs) where bright\nstars in distant lensed galaxies, typically at redshift $z\\approx1$--3, get\ntemporarily magnified close to cluster caustics. Since CCEs are generally\nbiased toward more massive and luminous stars, they offer a unique route for\nprobing the high end of the stellar mass function. We take advantage of the\nFlashlights event statistics to place preliminary constraints on the stellar\ninitial mass function (IMF) around cosmic noon. The photometry (along with\nspectral information) of lensed arcs is used to infer their various stellar\nproperties, and stellar synthesis models are used to evolve a recent stellar\npopulation in them. We estimate the microlens surface density near each arc\nand, together with existing lens models and simple formalism for CCEs,\ncalculate the expected rate for a given IMF. We find that, on average, a\nSalpeter-like IMF ($\\alpha=2.35$) underpredicts the number of observed CCEs by\na factor of ${\\sim}0.7$, and a top-heavy IMF ($\\alpha=1.00$) overpredicts by a\nfactor of ${\\sim}1.7$, suggesting that the average IMF slope may lie somewhere\nin between. However, given the large uncertainties associated with estimating\nthe stellar populations, these results are strongly model-dependent.\nNevertheless, we introduce a useful framework for constraining the IMF using\nCCEs. Observations with JWST are already yielding many more CCEs and will soon\nenable more stringent constraints on the IMF at a range of redshifts.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-27T17:20:35Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21732v1","title":"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling","summary":"Creating high-fidelity 3D meshes with arbitrary topology, including open\nsurfaces and complex interiors, remains a significant challenge. Existing\nimplicit field methods often require costly and detail-degrading watertight\nconversion, while other approaches struggle with high resolutions. This paper\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\nsectional voxel training strategy that activates only relevant voxels during\nrendering, dramatically reducing memory consumption and enabling\nhigh-resolution training. This also allows, for the first time, the\nreconstruction of mesh interiors using only rendering supervision. Building\nupon this, we demonstrate a complete shape modeling pipeline by training a\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\n3D shape generation. Our experiments show state-of-the-art reconstruction\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\nF-score compared to previous methods, and demonstrate the generation of\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\nhigh-resolution, differentiable mesh reconstruction and generation with\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\nshape representation and modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  Schrödinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21757v1","title":"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck","summary":"In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21759v1","title":"Large Scale Structure and the Cosmic Web","summary":"The formation and evolution of galaxies cannot be separated from large scale\nstructure growth. Dark matter halos (and, therefore, galaxies) form and grow\nwithin the cosmic web - the classification of large-scale structure as distinct\nenvironments, namely voids, walls, filaments and nodes. Thanks to the rapid\ndevelopment of extragalactic spectroscopic redshift surveys and cosmological\nsimulations over the last two decades, we are now able to measure the impact of\nthe cosmic web on galaxies and halos in observations and in simulations. In\nthis chapter we summarise the state of play in our understanding of the link\nbetween dark matter halos, galaxies, and the cosmic web.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:57:19Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.21778v1","title":"HS-SLAM: Hybrid Representation with Structural Supervision for Improved\n  Dense SLAM","summary":"NeRF-based SLAM has recently achieved promising results in tracking and\nreconstruction. However, existing methods face challenges in providing\nsufficient scene representation, capturing structural information, and\nmaintaining global consistency in scenes emerging significant movement or being\nforgotten. To this end, we present HS-SLAM to tackle these problems. To enhance\nscene representation capacity, we propose a hybrid encoding network that\ncombines the complementary strengths of hash-grid, tri-planes, and one-blob,\nimproving the completeness and smoothness of reconstruction. Additionally, we\nintroduce structural supervision by sampling patches of non-local pixels rather\nthan individual rays to better capture the scene structure. To ensure global\nconsistency, we implement an active global bundle adjustment (BA) to eliminate\ncamera drifts and mitigate accumulative errors. Experimental results\ndemonstrate that HS-SLAM outperforms the baselines in tracking and\nreconstruction accuracy while maintaining the efficiency required for robotics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2503.23719v1","title":"Compact orbital-angular-momentum multiplexing via laser-written glass\n  chips","summary":"Orbital angular momentum (OAM) modes have emerged as a promising solution for\nenhancing the capacity of optical multiplexing systems, leveraging their\ntheoretically unbounded set of orthogonal spatial modes. However, the\ngeneration and detection of OAM multiplexing signals are predominantly reliant\non bulky optical components within complex optical setups. We introduce a\ncompact solution for OAM information processing using laser-written glass\nchips, facilitating efficient multiplexing and demultiplexing of multiple OAM\ninformation channels. During the multiplexing process, OAM channels are managed\nvia laser-scribed single-mode waveguides within a glass chip, with their modes\nconverted using laser-written holograms on the side wall of the glass chip. The\nreverse optical process is employed for OAM demultiplexing. Our chips\nseamlessly interface with commercial optical fibers, ensuring compatibility\nwith existing fiber-optic communication infrastructure. This work not only\nestablishes a novel approach for OAM optical multiplexing but also underscores\nthe potential of laser-writing technology in advancing photonics and its\npractical applications in optical communications.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-03-31T04:40:57Z"}
{"aid":"http://arxiv.org/abs/2503.23729v1","title":"Integral regularization PINNs for evolution equations","summary":"Evolution equations, including both ordinary differential equations (ODEs)\nand partial differential equations (PDEs), play a pivotal role in modeling\ndynamic systems. However, achieving accurate long-time integration for these\nequations remains a significant challenge. While physics-informed neural\nnetworks (PINNs) provide a mesh-free framework for solving PDEs, they often\nsuffer from temporal error accumulation, which limits their effectiveness in\ncapturing long-time behaviors. To alleviate this issue, we propose integral\nregularization PINNs (IR-PINNs), a novel approach that enhances temporal\naccuracy by incorporating an integral-based residual term into the loss\nfunction. This method divides the entire time interval into smaller\nsub-intervals and enforces constraints over these sub-intervals, thereby\nimproving the resolution and correlation of temporal dynamics. Furthermore,\nIR-PINNs leverage adaptive sampling to dynamically refine the distribution of\ncollocation points based on the evolving solution, ensuring higher accuracy in\nregions with sharp gradients or rapid variations. Numerical experiments on\nbenchmark problems demonstrate that IR-PINNs outperform original PINNs and\nother state-of-the-art methods in capturing long-time behaviors, offering a\nrobust and accurate solution for evolution equations.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-03-31T05:02:59Z"}
{"aid":"http://arxiv.org/abs/2503.23734v1","title":"Semantic Packet Aggregation and Repeated Transmission for Text-to-Image\n  Generation","summary":"Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T05:14:40Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23758v1","title":"Exact Solution of the Frustrated Potts Model with Next-Nearest-Neighbor\n  Interactions in One Dimension: An AI-Aided Discovery","summary":"The one-dimensional $J_1$-$J_2$ $q$-state Potts model is solved exactly for\narbitrary $q$, based on using OpenAI's latest reasoning model o3-mini-high to\nexactly solve the $q=3$ case. The exact results provide insights to outstanding\nphysical problems such as the stacking of atomic or electronic orders in\nlayered materials and the formation of a $T_c$-dome-shaped phase often seen in\nunconventional superconductors. The work is anticipated to fuel both the\nresearch in one-dimensional frustrated magnets for recently discovered\nfinite-temperature application potentials and the fast moving topic area of AI\nfor sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-03-31T06:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.23770v1","title":"A new index transform with the square of Whittaker's function","summary":"An index transform, involving the square of Whittaker's function is\nintroduced and investigated. The corresponding inversion formula is\nestablished. Particular cases cover index transforms of the Lebedev type with\nproducts of the modified Bessel functions.","main_category":"math.CA","categories":"math.CA","published":"2025-03-31T06:40:58Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23808v1","title":"Why does tinnitus vary with naps? A polysomnographic prospective study\n  exploring the somatosensory hypothesis","summary":"Background: Tinnitus, defined as the conscious awareness of a noise without\nany identifiable corresponding external acoustic source, can be modulated by\nvarious factors. Among these factors, tinnitus patients commonly report drastic\nincreases of tinnitus loudness following nap sleep. Previous studies have\nsuggested that this clinical pattern could be attributed to a somatosensory\nmodulation of tinnitus. To our knowledge, no polysomnographic study has been\ncarried out to assess this hypothesis. Methods: For this observational\nprospective study, 37 participants reporting frequent increases of tinnitus\nfollowing naps were recruited. They participated to six full-polysomnography\nnap attempts over two days. Audiological and kinesiologic tests were conducted\nbefore and after each nap attempt. Results: 197 naps were collected. Each nap\nat each time of day elicited an overall significant increase in tinnitus\nminimum masking level (MML). Each inter nap period elicited an overall\nsignificant decrease. Tinnitus modulations were found significantly correlated\nwith nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p <\n0.05), with snoring duration (MML, p < 0.001), with snoring average sound level\n(VNS on tinnitus intrusiveness, VNS-I, p < 0.05) and with sleep apnea count\n(VNS-I, p < 0.001). Conclusions: This study confirms objectively that tinnitus\nmay increase following naps. No association was found between these modulations\nand somatosensory modulations involving the temporomandibular joint and\ncervical areas. However, it may be possible that nap-induced tinnitus\nmodulations are a hidden form of somatosensory modulation as snoring and sleep\napnea events are often related to tensor veli palatini muscle dysfunction.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-03-31T07:42:33Z"}
{"aid":"http://arxiv.org/abs/2503.23835v1","title":"Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as\n  Feedback Enables Pure Simulation Learning","summary":"Grasp-based manipulation tasks are fundamental to robots interacting with\ntheir environments, yet gripper state ambiguity significantly reduces the\nrobustness of imitation learning policies for these tasks. Data-driven\nsolutions face the challenge of high real-world data costs, while simulation\ndata, despite its low costs, is limited by the sim-to-real gap. We identify the\nroot cause of gripper state ambiguity as the lack of tactile feedback. To\naddress this, we propose a novel approach employing pseudo-tactile as feedback,\ninspired by the idea of using a force-controlled gripper as a tactile sensor.\nThis method enhances policy robustness without additional data collection and\nhardware involvement, while providing a noise-free binary gripper state\nobservation for the policy and thus facilitating pure simulation learning to\nunleash the power of simulation. Experimental results across three real-world\ngrasp-based tasks demonstrate the necessity, effectiveness, and efficiency of\nour approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T08:29:17Z"}
{"aid":"http://arxiv.org/abs/2503.23837v1","title":"Transmission resonances in scattering by $δ'$-like combs","summary":"We introduce a new exactly solvable model in quantum mechanics that describes\nthe propagation of particles through a potential field created by regularly\nspaced $\\delta'$-type point interactions, which model the localized dipoles\noften observed in crystal structures. We refer to the corresponding potentials\nas $\\delta'_\\theta$-combs, where the parameter $\\theta$ represents the contrast\nof the resonant wave at zero energy and determines the interface conditions in\nthe Hamiltonians. We explicitly calculate the scattering matrix for these\nsystems and prove that the transmission probability exhibits sharp resonance\npeaks while rapidly decaying at other frequencies. Consequently, Hamiltonians\nwith $\\delta'_\\theta$-comb potentials act as quantum filters, permitting\ntunnelling only for specific wave frequencies.","main_category":"math.SP","categories":"math.SP,math-ph,math.MP","published":"2025-03-31T08:33:37Z"}
{"aid":"http://arxiv.org/abs/2503.23858v1","title":"Incremental capacity-based multi-feature fusion model for predicting\n  state-of-health of lithium-ion batteries","summary":"Lithium-ion batteries have become an indispensable part of human industrial\nproduction and daily life. For the safe use, management and maintenance of\nlithium-ion batteries, the state of health (SOH) of lithium-ion batteries is an\nimportant indicator so that the SOH estimation is of significant practical\nvalue. In order to accurately predict SOH, this paper proposes a fusion\nprediction model which combines particle swarm optimization (PSO) algorithm,\nbi-directional long-short time memory network (BiLSTM) and adaptive boosting\n(AdaBoost) algorithm. In the proposed prediction model, indirect health\nindicators (HIs), which characterize battery degradation, are obtained with the\nhelp of incremental capacity analysis (ICA), and is fed into BiLSTM to extract\ntime-series features, whose parameters are optimized by employing PSO\nalgorithm. On this basis, the AdaBoost algorithm is applied to reduce the risk\nof overfitting the PSO-BiLSTM model. The study based on lithium-ion battery\ndata from Center for Advanced Life Cycle Engineering (CALCE) shows that the\nPSO-BiLSTM-AdaBoost model has higher accuracy, better robustness, and\ngeneralization ability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:05:56Z"}
{"aid":"http://arxiv.org/abs/2503.23864v1","title":"Hybrid Random Concentrated Optimization Without Convexity Assumption","summary":"We propose a method to minimize a continuous function over a subset\n$\\mathcal{S}$ of high-dimensional space $\\mathbb{R}^K$ without assuming\nconvexity. The method alternates between Global Search (GS) to identify\ncandidates and Concentrated Search (CS) regimes to improve an eligible\ncandidate in $\\mathcal{S}$.Beyond the alternation between regimes, the\noriginality of the method lies in leveraging high dimensionality. We\ndemonstrate concentration properties under the $CS$ regime. In parallel, we\nshow that $GS$ reaches any point in finite time. Finally, two applications are\nproposed. The first is the reduction of the $L_1$ norm in the Lasso to\ndemonstrate the relevance of the method. In a second application, we compress\nneural network by pruning weights while maintaining performance. Our approach\nachieves significant weight reduction with minimal performance loss, offering\nan effective solution for network optimization.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-03-31T09:11:34Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23883v1","title":"Algorithm Design and Prototype Validation for Reconfigurable Intelligent\n  Sensing Surface: Forward-Only Transmission","summary":"Sensing-assisted communication schemes have recently garnered significant\nresearch attention. In this work, we design a dual-function reconfigurable\nintelligent surface (RIS), integrating both active and passive elements,\nreferred to as the reconfigurable intelligent sensing surface (RISS), to\nenhance communication. By leveraging sensing results from the active elements,\nwe propose communication enhancement and robust interference suppression\nschemes for both near-field and far-field models, implemented through the\npassive elements. These schemes remove the need for base station (BS) feedback\nfor RISS control, simplifying the communication process by replacing\ntraditional channel state information (CSI) feedback with real-time sensing\nfrom the active elements. The proposed schemes are theoretically analyzed and\nthen validated using software-defined radio (SDR). Experimental results\ndemonstrate the effectiveness of the sensing algorithms in real-world\nscenarios, such as direction of arrival (DOA) estimation and radio frequency\n(RF) identification recognition. Moreover, the RISS-assisted communication\nsystem shows strong performance in communication enhancement and interference\nsuppression, particularly in near-field models.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T09:36:15Z"}
{"aid":"http://arxiv.org/abs/2503.23891v1","title":"Monodromy of Darboux transformations of polarised curves","summary":"We show that every finite type polarised curve in the conformal $2$-sphere\nwith a polynomial conserved quantity admits a resonance point, under a\nnon-orthogonality assumption on the conserved quantity. Using this fact, we\ndeduce that every finite type curve polarised by space form arc-length in the\nconformal $2$-sphere admits a resonance point, possibly on a multiple cover.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T09:42:15Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23959v1","title":"Local Information Matters: Inference Acceleration For Grounded\n  Conversation Generation Models Through Adaptive Local-Aware Token Pruning","summary":"Grounded Conversation Generation (GCG) is an emerging vision-language task\nthat requires models to generate natural language responses seamlessly\nintertwined with corresponding object segmentation masks. Recent models, such\nas GLaMM and OMG-LLaVA, achieve pixel-level grounding but incur significant\ncomputational costs due to processing a large number of visual tokens. Existing\ntoken pruning methods, like FastV and PyramidDrop, fail to preserve the local\nvisual features critical for accurate grounding, leading to substantial\nperformance drops in GCG tasks. To address this, we propose Adaptive\nLocal-Aware Token Pruning (ALTP), a simple yet effective framework that\naccelerates GCG models by prioritizing local object information. ALTP\nintroduces two key components: (1) Detail Density Capture (DDC), which uses\nsuperpixel segmentation to retain tokens in object-centric regions, preserving\nfine-grained details, and (2) Dynamic Density Formation (DDF), which\ndynamically allocates tokens based on information density, ensuring higher\nretention in semantically rich areas. Extensive experiments on the GranDf\ndataset demonstrate that ALTP significantly outperforms existing token pruning\nmethods, such as FastV and PyramidDrop, on both GLaMM and OMG-LLaVA models.\nNotably, when applied to GLaMM, ALTP achieves a 90% reduction in visual tokens\nwith a 4.9% improvement in AP50 and a 5.0% improvement in Recall compared to\nPyramidDrop. Similarly, on OMG-LLaVA, ALTP improves AP by 2.1% and mIOU by 3.0%\nat a 90% token reduction compared with PDrop.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:18:27Z"}
{"aid":"http://arxiv.org/abs/2503.23966v1","title":"Machine Learning-assisted High-speed Combinatorial Optimization with\n  Ising Machines for Dynamically Changing Problems","summary":"Quantum or quantum-inspired Ising machines have recently shown promise in\nsolving combinatorial optimization problems in a short time. Real-world\napplications, such as time division multiple access (TDMA) scheduling for\nwireless multi-hop networks and financial trading, require solving those\nproblems sequentially where the size and characteristics change dynamically.\nHowever, using Ising machines involves challenges to shorten system-wide\nlatency due to the transfer of large Ising model or the cloud access and to\ndetermine the parameters for each problem. Here we show a combinatorial\noptimization method using embedded Ising machines, which enables solving\ndiverse problems at high speed without runtime parameter tuning. We customize\nthe algorithm and circuit architecture of the simulated bifurcation-based Ising\nmachine to compress the Ising model and accelerate computation and then built a\nmachine learning model to estimate appropriate parameters using extensive\ntraining data. In TDMA scheduling for wireless multi-hop networks, our\ndemonstration has shown that the sophisticated system can adapt to changes in\nthe problem and showed that it has a speed advantage over conventional methods.","main_category":"cs.ET","categories":"cs.ET,cs.LG","published":"2025-03-31T11:31:36Z"}
{"aid":"http://arxiv.org/abs/2503.23974v1","title":"Revealing the Low Temperature Phase of FAPbI$_3$ using Machine-Learned\n  Potential","summary":"FAPbI$_3$ is a material of interest for its potential in solar cell\napplications, driven by its remarkable optoelectronic properties. However, the\nlow-temperature phase of FAPbI$_3$ remains poorly understood, with open\nquestions surrounding its crystal structure, octahedral tilting, and the\narrangement of formamidinium (FA) cations. Using our trained machine-learned\npotential in combination with large-scale molecular dynamics simulations, we\nprovide a detailed investigation of this phase, uncovering its structural\ncharacteristics and dynamical behavior. Our analysis reveals the octahedral\ntilt pattern and sheds light on the rotational dynamics of FA cations in the\nlow temperature phase. Strikingly, we find that the FA cations become frozen in\na metastable configuration, unable to reach the thermodynamic ground state. By\ncomparing our simulated results with experimental nuclear magnetic resonance\n(NMR) and inelastic neutron scattering (INS) spectra, we demonstrate good\nagreement, further validating our findings. This phenomenon mirrors\nexperimental observations and offers a compelling explanation for the\nexperimental challenges in accessing the true ground state. These findings\nprovide critical insights into the fundamental physics of FAPbI$_3$ and its\nlow-temperature behavior, advancing our understanding of this technologically\nimportant material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T11:36:16Z"}
{"aid":"http://arxiv.org/abs/2503.23977v1","title":"Directed treewidth is closed under taking butterfly minors","summary":"Butterfly minors are a generalisation of the minor containment relation for\nundirected graphs to directed graphs. Many results in directed structural graph\ntheory use this notion as a central tool next to directed treewidth, a\ngeneralisation of the width measure treewidth to directed graphs. Adler\n[JCTB'07] showed that the directed treewidth is not closed under taking\nbutterfly minors. Over the years, many alternative definitions for directed\ntreewidth appeared throughout the literature, equivalent to the original\ndefinition up to small functions. In this paper, we consider the major ones and\nshow that not all of them share the problem identified by Adler.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-31T11:40:22Z"}
{"aid":"http://arxiv.org/abs/2503.23985v1","title":"An Empirical Study of Rust-Specific Bugs in the rustc Compiler","summary":"Rust is gaining popularity for its well-known memory safety guarantees and\nhigh performance, distinguishing it from C/C++ and JVM-based languages. Its\ncompiler, rustc, enforces these guarantees through specialized mechanisms such\nas trait solving, borrow checking, and specific optimizations. However, Rust's\nunique language mechanisms introduce complexity to its compiler, leading to\nRust-specific compiler bugs that are less common in traditional compilers. With\nRust's increasing adoption in safety-critical domains, understanding these\nlanguage mechanisms and their impact on compiler bugs is essential for\nimproving the reliability of both rustc and Rust programs. Yet, we still lack a\nlarge-scale, detailed, and in-depth study of Rust-specific bugs in rustc.\n  To bridge this gap, this work conducts a comprehensive and systematic study\nof Rust-specific bugs in rustc, with a particular focus on the components that\nsupport its unique language features. Our analysis examines issues and fixes\nreported between 2022 and 2024, with a manual review of 301 valid issues. We\ncategorize these bugs based on their causes, symptoms, affected compilation\nstages, and test case characteristics. Additionally, we evaluate existing rustc\ntesting tools to assess their effectiveness and limitations. Our key findings\ninclude: (1) rustc bugs primarily arise from Rust's type system and lifetime\nmodel, with frequent errors in the High-Level Intermediate Representation (HIR)\nand Mid-Level Intermediate Representation (MIR) modules due to complex checkers\nand optimizations; (2) bug-revealing test cases often involve unstable\nfeatures, advanced trait usages, lifetime annotations, standard APIs, and\nspecific optimization levels; (3) while both valid and invalid programs can\ntrigger bugs, existing testing tools struggle to detect non-crash errors,\nunderscoring the need for further advancements in rustc testing.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T11:55:04Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24029v1","title":"Global Well-Posedness of the 3D Navier-Stokes Equations under\n  Multi-Level Logarithmically Improved Criteria","summary":"This paper extends our previous results on logarithmically improved\nregularity criteria for the three-dimensional Navier-Stokes equations by\nestablishing a comprehensive framework of multi-level logarithmic improvements.\nWe prove that if the initial data $u_0 \\in L^2(\\mathbb{R}^3)$ satisfies a\nnested logarithmically weakened condition\n$\\|(-\\Delta)^{s/2}u_0\\|_{L^q(\\mathbb{R}^3)} \\leq \\frac{C_0}{\\prod_{j=1}^{n} (1\n+ L_j(\\|u_0\\|_{\\dot{H}^s}))^{\\delta_j}}$ for some $s \\in (1/2, 1)$, where $L_j$\nrepresents $j$-fold nested logarithms, then the corresponding solution exists\nglobally in time and is unique. The proof introduces a novel sequence of\nincreasingly precise commutator estimates incorporating multiple layers of\nlogarithmic corrections. We establish the existence of a critical threshold\nfunction $\\Phi(s,q,\\{\\delta_j\\}_{j=1}^n)$ that completely characterizes the\nboundary between global regularity and potential singularity formation, with\nexplicit asymptotics as $s$ approaches the critical value $1/2$. This paper\nfurther provides a rigorous geometric characterization of potential singular\nstructures through refined multi-fractal analysis, showing that any singular\nset must have Hausdorff dimension bounded by $1 - \\sum_{j=1}^n\n\\frac{\\delta_j}{1+\\delta_j} \\cdot \\frac{1}{j+1}$. Our results constitute a\nsignificant advancement toward resolving the global regularity question for the\nNavier-Stokes equations, as we demonstrate that with properly calibrated\nsequences of nested logarithmic improvements, the gap to the critical case can\nbe systematically reduced.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T12:55:30Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24037v1","title":"Digital Nudges Using Emotion Regulation to Reduce Online Disinformation\n  Sharing","summary":"Online disinformation often provokes strong anger, driving social media users\nto spread it; however, few measures specifically target sharing behaviors\ndriven by this emotion to curb the spread of disinformation. This study aimed\nto evaluate whether digital nudges that encourage deliberation by drawing\nattention to emotional information can reduce sharing driven by strong anger\nassociated with online disinformation. We focused on emotion regulation, as a\nmethod for fostering deliberation, which is activated when individuals'\nattention is drawn to their current emotions. Digital nudges were designed to\ndisplay emotional information about disinformation and emotion regulation\nmessages. Among these, we found that distraction and perspective-taking nudges\nmay encourage deliberation in anger-driven sharing. To assess their\neffectiveness, existing nudges mimicking platform functions were used for\ncomparison. Participant responses were measured across four dimensions: sharing\nintentions, type of emotion, intensity of emotion, and authenticity. The\nresults showed that all digital nudges significantly reduced the sharing of\ndisinformation, with distraction nudges being the most effective. These\nfindings suggest that digital nudges addressing emotional responses can serve\nas an effective intervention against the spread disinformation driven by strong\nanger.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-03-31T13:01:05Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24056v1","title":"Moment polytopes of toric exponential families","summary":"We show that the moment polytope of a K\\\"ahler toric manifold, constructed as\nthe torification (in the sense of M. Molitor, K\\\"ahler toric manifolds from\ndually flat spaces, arXiv:2109.04839, 2021) of an exponential family defined on\na finite sample space, is the projection of a higher-dimensional simplex.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T13:17:20Z"}
{"aid":"http://arxiv.org/abs/2503.24057v1","title":"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\n  Micro-Expression Recognition","summary":"Micro-expressions are typically regarded as unconscious manifestations of a\nperson's genuine emotions. However, their short duration and subtle signals\npose significant challenges for downstream recognition. We propose a multi-task\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\nmicro-expressions through self-supervised subtle motion magnification, while\nthe sparse spatial selection Mamba architecture combines sparse activation with\nthe advanced Visual Mamba model to model key motion regions and their valuable\nrepresentations more effectively. Additionally, we employ evolutionary search\nto optimize the magnification factor and the sparsity ratios of spatial\nselection, followed by fine-tuning to improve performance further. Extensive\nexperiments on two standard datasets demonstrate that the proposed AMMSM\nachieves state-of-the-art (SOTA) accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:17:43Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24066v1","title":"Smooth and rough paths in mean derivative estimation for functional data","summary":"In this paper, in a multivariate setting we derive near optimal rates of\nconvergence in the minimax sense for estimating partial derivatives of the mean\nfunction for functional data observed under a fixed synchronous design over\nH\\\"older smoothness classes. We focus on the supremum norm since it corresponds\nto the visualisation of the estimation error, and is closely related to the\nconstruction of uniform confidence bands. In contrast to mean function\nestimation, for derivative estimation the smoothness of the paths of the\nprocesses is crucial for the rates of convergence. On the one hand, if the\npaths have higher-order smoothness than the order of the partial derivative to\nbe estimated, the parametric $\\sqrt n$ rate can be achieved under sufficiently\ndense design. On the other hand, for processes with rough paths of lower-order\nsmoothness, we show that the rates of convergence are necessarily slower than\nthe parametric rate, and determine a near-optimal rate at which estimation is\nstill possible. We implement a multivariate local polynomial derivative\nestimator and illustrate its finite-sample performance in a simulation as well\nas for two real-data sets. To assess the smoothness of the sample paths in the\napplications we further discuss a method based on comparing restricted\nestimates of the partial derivatives of the covariance kernel.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T13:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24081v1","title":"Cell-Free Massive MIMO Under Mobility: A Fairness-Differentiated\n  Handover Scheme","summary":"While cell-free massive MIMO (CF-mMIMO) offers both uniform and high\nnetwork-wide throughput in static networks, its performance in a mobile network\nis not yet fully addressed. In this paper, we evaluate the performance of a\nmobile CF-mMIMO network under a comprehensive throughput model and show that it\nsuffers from large performance degradation due to the combined effect of\nchannel aging and handover delay. To improve the performance of CF-mMIMO under\nmobility, we propose a fairness-differentiated handover scheme. Our scheme\ndifferentiates the handover policy for different users by their channel\nconditions compared to a threshold based on Jain's fairness index, in order to\nprioritize handovers for the poorly served users. We present an extensive\nevaluation of the mobile throughput performance of our handover scheme with\nrealistic urban network distributions and UE mobility patterns. Our results\nshow that our scheme significantly outperforms the existing literature\nbenchmarks when considering both channel aging and handover delay cost.\nImportantly, the advantage of UE-centric over network-centric CF-mMIMO, of\nuniformly good performance over the network, is uniquely preserved under\nmobility by our handover scheme. We thus show that CF-mMIMO can be a feasible\narchitecture for practical mobile networks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T13:35:41Z"}
{"aid":"http://arxiv.org/abs/2503.24091v1","title":"4D mmWave Radar in Adverse Environments for Autonomous Driving: A Survey","summary":"Autonomous driving systems require accurate and reliable perception. However,\nadverse environments, such as rain, snow, and fog, can significantly degrade\nthe performance of LiDAR and cameras. In contrast, 4D millimeter-wave (mmWave)\nradar not only provides 3D sensing and additional velocity measurements but\nalso maintains robustness in challenging conditions, making it increasingly\nvaluable for autonomous driving. Recently, research on 4D mmWave radar under\nadverse environments has been growing, but a comprehensive survey is still\nlacking. To bridge this gap, this survey comprehensively reviews the current\nresearch on 4D mmWave radar under adverse environments. First, we present an\noverview of existing 4D mmWave radar datasets encompassing diverse weather and\nlighting scenarios. Next, we analyze methods and models according to different\nadverse conditions. Finally, the challenges faced in current studies and\npotential future directions are discussed for advancing 4D mmWave radar\napplications in harsh environments. To the best of our knowledge, this is the\nfirst survey specifically focusing on 4D mmWave radar in adverse environments\nfor autonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:42:50Z"}
{"aid":"http://arxiv.org/abs/2503.24102v1","title":"Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?","summary":"Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T13:56:03Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24134v1","title":"Moving mesh FSI approach for VIV simulation based on DG method with AMR\n  technique","summary":"Vortex-induced vibration (VIV) remains a fundamental yet computationally\n  challenging problem in computational fluid dynamics (CFD). This study\ndevelops a moving mesh Fluid-structure interaction (FSI) algorithm within a\nRunge-Kutta\n  Discontinuous Galerkin (RKDG) adaptive mesh refinement (AMR) framework. The\nviscous term in the compressible Navier-Stokes (NS) equations is discretized\nusing\n  the high-order Interior Penalty Discontinuous Galerkin (IPDG)\n  method. In addition to the above, key numerical advancements encompass\n  the rigorous derivation of the Lax-Friedrichs (L-F) numerical flux\nformulation\n  tailored for moving meshes, an enhanced AMR-driven nodal correction\n  methodology designed for curved surface geometries,\n  and the implementation of a ghost-node boundary condition treatment scheme\n  to address dynamic mesh motion. Numerical validation proceeds through three\nphases:\n  First, Couette flow simulations confirm the IPDG method's spatial\n  convergence order. Subsequent analysis of unsteady flow past a cylinder\n  demonstrate the AMR framework's efficacy in resolving vortex-dominated flow.\n  Finally, six VIV benchmark cases are simulated using third-order IPDG\ndiscretization,\n  establishing the proposed FSI algorithm's accuracy. Furthermore, synthetic\njets (SJs) flow control is investigated through\n  four frequency-variant SJs configurations. The results reveal that SJs can\nachieve completely\n  VIV suppression at a low actuation frequency, while higher actuation\n  frequencies reduce suppression efficiency due\n  to the energy of the SJs is more in the form of acoustic wave.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T14:17:53Z"}
{"aid":"http://arxiv.org/abs/2503.24147v1","title":"Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and\n  DR8 with a CMOS 3 nm SerDes and TFLN Modulators","summary":"We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:33:17Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24164v1","title":"SVLA: A Unified Speech-Vision-Language Assistant with Multimodal\n  Reasoning and Speech Generation","summary":"Large vision and language models show strong performance in tasks like image\ncaptioning, visual question answering, and retrieval. However, challenges\nremain in integrating speech, text, and vision into a unified model, especially\nfor spoken tasks. Speech generation methods vary (some produce speech\ndirectly), others through text (but their impact on quality is unclear).\nEvaluation often relies on automatic speech recognition, which may introduce\nbias. We propose SVLA, a unified speech vision language model based on a\ntransformer architecture that handles multimodal inputs and outputs. We train\nit on 38.2 million speech text image examples, including 64.1 hours of\nsynthetic speech. We also introduce Speech VQA Accuracy, a new metric for\nevaluating spoken responses. SVLA improves multimodal understanding and\ngeneration by better combining speech, vision, and language.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:46:34Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24178v1","title":"Beijing Normal University 12 meter Interferometric kHz GW Detector\n  Prototype","summary":"Gravitational wave (GW) astronomy has opened a new window into the universe,\nenabling the study of extreme astrophysical phenomena that are otherwise\nobscured in traditional electromagnetic observations. While global efforts have\npredominantly focused on low- and mid-frequency GW detection, the\nhigh-frequency regime, particularly in the kilohertz (kHz) range, remains\nunderexplored despite its potential to reveal critical insights into compact\nbinary mergers, neutron star physics, and other exotic astrophysical sources.\nIn this context, the Beijing Normal University (BNU) prototype represents a\npioneering effort to develop a dedicated kHz GW detector. Featuring a 12-meter\nL-shaped resonator within a two-arm vacuum system, the BNU prototype is\ndesigned to test innovative configurations and address key technical challenges\nfor kHz GW detection. Beyond its primary focus on being a technology testbed\nand demonstrator for kHz detection, the prototype is also being evaluated for\nits own sensitivity in the megahertz (MHz) range, offering the potential to\nexplore even higher-frequency signals from e.g., primordial black holes and\ngeontropic fluctuations. This paper provides a comprehensive overview of the\nBNU prototype, detailing its design, key components, and scientific objectives.","main_category":"physics.optics","categories":"physics.optics,astro-ph.IM,gr-qc,physics.ins-det,quant-ph","published":"2025-03-31T14:54:53Z"}
{"aid":"http://arxiv.org/abs/2503.24187v1","title":"NeuRaLaTeX: A machine learning library written in pure LaTeX","summary":"In this paper, we introduce NeuRaLaTeX, which we believe to be the first deep\nlearning library written entirely in LaTeX. As part of your LaTeX document you\ncan specify the architecture of a neural network and its loss functions, define\nhow to generate or load training data, and specify training hyperparameters and\nexperiments. When the document is compiled, the LaTeX compiler will generate or\nload training data, train the network, run experiments, and generate figures.\nThis paper generates a random 100 point spiral dataset, trains a two layer MLP\non it, evaluates on a different random spiral dataset, produces plots and\ntables of results. The paper took 48 hours to compile and the entire source\ncode for NeuRaLaTeX is contained within the source code of the paper. We\npropose two new metrics: the Written In Latex (WIL) metric measures the\nproportion of a machine learning library that is written in pure LaTeX, while\nthe Source Code Of Method in Source Code of Paper (SCOMISCOP) metric measures\nthe proportion of a paper's implementation that is contained within the paper\nsource. We are state-of-the-art for both metrics, outperforming the ResNet and\nTransformer papers, as well as the PyTorch and Tensorflow libraries. Source\ncode, documentation, videos, crypto scams and an invitation to invest in the\ncommercialisation of NeuRaLaTeX are available at https://www.neuralatex.com","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:05:19Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24204v1","title":"Many-to-Many Matching via Sparsity Controlled Optimal Transport","summary":"Many-to-many matching seeks to match multiple points in one set and multiple\npoints in another set, which is a basis for a wide range of data mining\nproblems. It can be naturally recast in the framework of Optimal Transport\n(OT). However, existing OT methods either lack the ability to accomplish\nmany-to-many matching or necessitate careful tuning of a regularization\nparameter to achieve satisfactory results. This paper proposes a novel\nmany-to-many matching method to explicitly encode many-to-many constraints\nwhile preventing the degeneration into one-to-one matching. The proposed method\nconsists of the following two components. The first component is the matching\nbudget constraints on each row and column of a transport plan, which specify\nhow many points can be matched to a point at most. The second component is the\ndeformed $q$-entropy regularization, which encourages a point to meet the\nmatching budget maximally. While the deformed $q$-entropy was initially\nproposed to sparsify a transport plan, we employ it to avoid the degeneration\ninto one-to-one matching. We optimize the objective via a penalty algorithm,\nwhich is efficient and theoretically guaranteed to converge. Experimental\nresults on various tasks demonstrate that the proposed method achieves good\nperformance by gleaning meaningful many-to-many matchings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.24209v1","title":"Optimal low-rank approximations for linear Gaussian inverse problems on\n  Hilbert spaces, Part II: posterior mean approximation","summary":"In this work, we construct optimal low-rank approximations for the Gaussian\nposterior distribution in linear Gaussian inverse problems. The parameter space\nis a separable Hilbert space of possibly infinite dimension, and the data space\nis assumed to be finite-dimensional. We consider various types of approximation\nfamilies for the posterior. We first consider approximate posteriors in which\nthe means vary among a class of either structure-preserving or\nstructure-ignoring low-rank transformations of the data, and in which the\nposterior covariance is kept fixed. We give necessary and sufficient conditions\nfor these approximating posteriors to be equivalent to the exact posterior, for\nall possible realisations of the data simultaneously. For such approximations,\nwe measure approximation error with the Kullback-Leibler, R\\'enyi and Amari\n$\\alpha$-divergences for $\\alpha\\in(0,1)$, and with the Hellinger distance, all\naveraged over the data distribution. With these losses, we find the optimal\napproximations and formulate an equivalent condition for their uniqueness,\nextending the work in finite dimensions of Spantini et al. (SIAM J. Sci.\nComput. 2015). We then consider joint approximation of the mean and covariance,\nby also varying the posterior covariance over the low-rank updates considered\nin Part I of this work. For the reverse Kullback-Leibler divergence, we show\nthat the separate optimal approximations of the mean and of the covariance can\nbe combined to yield an optimal joint approximation of the mean and covariance.\nIn addition, we interpret the joint approximation with the optimal\nstructure-ignoring approximate mean in terms of an optimal projector in\nparameter space.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-03-31T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2503.24246v1","title":"Quantum phase diagram of the extended spin-3/2 Kitaev-Heisenberg model:\n  A DMRG study","summary":"Recently there has been considerable excitement surrounding the promising\nrealization of high-spin Kitaev material, such as the quasi-2D compound CrI$_3$\nand CrGeTe$_3$. However, the stability of quantum spin liquids (QSL) against\nsingle ion anisotropy (SIA) in these materials and the global quantum phase\ndiagram of the extended spin-3/2 Kitaev model with finite SIA remain unclear.\nIn this study, we perform large-scale density matrix renormalization group\n(DMRG) to explore the quantum phase diagram of the generalized spin-3/2\nKitaev-Heisenberg (K-H) model accompanied with SIA $A_c$. In the $A_c=0$ limit,\nthe spin-3/2 K-H model exhibits a quantum phase diagram similar to that of a\nspin-1/2 system, including two QSLs around antiferromagnetic and ferromagnetic\nKitaev models. For models with finite $A_c$, we map out the quantum phase\ndiagram around two Kitaev points and observe distinct types of in-plane vortex\norders developed from these two QSL phases. Interestingly, series of nearly\ndegenerate vortex configurations are discovered in each vortex phases. Using\nlinear spin-wave theory, we demonstrate that these vortex configurations can be\nunderstood as a consequence of the quantum correction on a continuous family of\ndegenerate classical states.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T15:58:20Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24252v1","title":"A BDG inequality for stochastic Volterra integrals","summary":"We establish Burkholder-Davis-Gundy-type inequalities for stochastic Volterra\nintegrals with a completely monotone convolution kernel, which may exhibit\nsingular behaviour at the origin. When the supremum is taken over a finite\ninterval, the upper bound depends linearly on the $L^\\gamma$-norm of the\nkernel, for any $\\gamma>2$. We demonstrate the utility of this inequality in\nquantifying the pathwise distance between two stochastic Volterra equations\nwith distinct kernels, with a particular emphasis on the multifactor Markovian\napproximation. For kernels that decay sufficiently fast, we derive an\nalternative inequality valid over an infinite time interval, providing\nuniform-in-time bounds for mean-reverting stochastic Volterra equations.\nFinally, we compare our findings with existing results in the literature.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T16:02:11Z"}
{"aid":"http://arxiv.org/abs/2503.24279v1","title":"Toward the effective 2-topos","summary":"A candidate for the effective 2-topos is proposed and shown to include the\neffective 1-topos as its subcategory of 0-types.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-03-31T16:23:47Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24298v1","title":"Order Matters: On Parameter-Efficient Image-to-Video Probing for\n  Recognizing Nearly Symmetric Actions","summary":"We study parameter-efficient image-to-video probing for the unaddressed\nchallenge of recognizing nearly symmetric actions - visually similar actions\nthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).\nExisting probing mechanisms for image-pretrained models, such as DinoV2 and\nCLIP, rely on attention mechanism for temporal modeling but are inherently\npermutation-invariant, leading to identical predictions regardless of frame\norder. To address this, we introduce Self-attentive Temporal Embedding Probing\n(STEP), a simple yet effective approach designed to enforce temporal\nsensitivity in parameter-efficient image-to-video transfer. STEP enhances\nself-attentive probing with three key modifications: (1) a learnable frame-wise\npositional encoding, explicitly encoding temporal order; (2) a single global\nCLS token, for sequence coherence; and (3) a simplified attention mechanism to\nimprove parameter efficiency. STEP outperforms existing image-to-video probing\nmechanisms by 3-15% across four activity recognition benchmarks with only 1/3\nof the learnable parameters. On two datasets, it surpasses all published\nmethods, including fully fine-tuned models. STEP shows a distinct advantage in\nrecognizing nearly symmetric actions, surpassing other probing mechanisms by\n9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code and\nmodels will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:42:38Z"}
{"aid":"http://arxiv.org/abs/2503.24314v1","title":"Impact of Synchronization Offsets and CSI Feedback Delay in Distributed\n  MIMO Systems","summary":"The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2503.24322v1","title":"NoProp: Training Neural Networks without Back-propagation or\n  Forward-propagation","summary":"The canonical deep learning approach for learning requires computing a\ngradient term at each layer by back-propagating the error signal from the\noutput towards each learnable parameter. Given the stacked structure of neural\nnetworks, where each layer builds on the representation of the layer below,\nthis approach leads to hierarchical representations. More abstract features\nlive on the top layers of the model, while features on lower layers are\nexpected to be less abstract. In contrast to this, we introduce a new learning\nmethod named NoProp, which does not rely on either forward or backwards\npropagation. Instead, NoProp takes inspiration from diffusion and flow matching\nmethods, where each layer independently learns to denoise a noisy target. We\nbelieve this work takes a first step towards introducing a new family of\ngradient-free learning methods, that does not learn hierarchical\nrepresentations -- at least not in the usual sense. NoProp needs to fix the\nrepresentation at each layer beforehand to a noised version of the target,\nlearning a local denoising process that can then be exploited at inference. We\ndemonstrate the effectiveness of our method on MNIST, CIFAR-10, and CIFAR-100\nimage classification benchmarks. Our results show that NoProp is a viable\nlearning algorithm which achieves superior accuracy, is easier to use and\ncomputationally more efficient compared to other existing back-propagation-free\nmethods. By departing from the traditional gradient based learning paradigm,\nNoProp alters how credit assignment is done within the network, enabling more\nefficient distributed learning as well as potentially impacting other\ncharacteristics of the learning process.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-03-31T17:08:57Z"}
{"aid":"http://arxiv.org/abs/2503.24330v1","title":"Quantum algorithms for cooling: a simple case study","summary":"Preparation of low-energy quantum many-body states has a wide range of\napplications in quantum information processing and condensed matter physics.\nQuantum cooling algorithms offer a promising alternative to other methods\nbased, for instance, on variational and adiabatic principles, or on dissipative\nstate preparation. In this work, we investigate a set of cooling algorithms in\na simple, solvable fermionic model which allows us to identify the mechanisms\nwhich underlie the cooling process and, also, those which prevent it. We derive\nanalytical expressions for the cooling dynamics, steady states, and cooling\nrates in the weak coupling limit. We find that multi-frequency and randomized\ncycle strategies can significantly enhance the performance of the quantum\nalgorithm and circumvent some of the obstacles. We also analyze the effects of\nnoise and evaluate the conditions under which cooling remains feasible.\nFurthermore, we present optimized cooling protocols that can significantly\nenhance cooling performance in the presence of noise. Additionally, we compare\ncooling and dissipative state preparation and show that, in the model analyzed\nhere, cooling generally achieves lower energies and is more resilient to noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:19:12Z"}
{"aid":"http://arxiv.org/abs/2503.24344v1","title":"Local basis for interacting topological bands","summary":"The discovery of correlated states in moire materials has challenged the\nestablished methods of projecting interactions into a local Wannier basis due\nto topological obstructions that manifest in extended interactions. This\ndifficulty can sometimes be evaded by decomposing the band into a basis of\nextended itinerant states and a lattice of local states, using the heavy\nfermion prescription. We revisit this framework by systematically identifying\nthe dominant interaction channels guided by the eigenvalues of the projected\ndensity operator. This approach can be applied both to tight-binding and\ncontinuum models, allowing us to identify a hierarchy in interaction scales\nthat can be universally used to reduce the Hilbert space dimension and\ndetermine an appropriate local basis for modeling electronic correlations in\ninteracting topological materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2503.24355v1","title":"Modified cosmology though spacetime thermodynamics and generalized\n  mass-to-horizon entropy","summary":"In this work we apply the gravity-thermodynamics approach for the case of\ngeneralized mass-to-horizon entropy, which is a two-parameter extension of\nBekenstein-Hawking entropy that arises from the extended mass-to-horizon\nrelation, that is in turn required in order to have consistency with the\nClausius relation. We extract the modified Friedmann equations and we obtain an\neffective dark energy sector arising from the novel terms. We derive analytical\nsolutions for the dark energy density parameter, the dark energy\nequation-of-state parameter, and the deceleration parameter, and we show that\nthe Universe exhibits the usual thermal history with the succession of matter\nand dark energy epochs. Additionally, depending on the value of the entropy\nparameters, the dark energy equation-of-state parameter can either lie in the\nphantom regime at high redshifts entering into the quintessence regime at small\nredshifts, or it can lie in the quintessence regime at high redshifts and\nexperience the phantom-divide crossing at small redshifts, while in the far\nfuture in all cases it asymptotically obtains the cosmological constant value\n$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\ndatasets, showing that the scenario is in agreement with observations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-03-31T17:35:35Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24390v1","title":"Intertwining bulk and surface: the case of UTe$_2$","summary":"UTe$_2$ has been the focus of numerous experimental and theoretical studies\nin recent years, as it is recognized as an odd-parity bulk superconductor. Its\nsurface has also been probed, revealing charge density wave (CDW), pair density\nwave (PDW), and time-reversal symmetry breaking (TRSB). In this work, we\npropose that the interplay between the order parameters observed on the surface\nand in the bulk of UTe$_2$ may be crucial in explaining some of the unusual\nfeatures detected by surface probes in this material. Through a\nphenomenological analysis, we can account for three distinctive experimental\nsignatures observed on the surface of UTe$_2$: i) the apparent suppression of\nCDW order at the upper critical field of the bulk superconducting state; ii)\nthe magnetic field-induced imbalance of the Fourier peaks associated with the\nCDW; iii) the onset of TRSB at the bulk superconducting critical temperature\nand its field-trainability. Furthermore, we propose specific experimental\nchecks to validate our conjecture, which we believe could be promptly achieved.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2503.24391v1","title":"Easi3R: Estimating Disentangled Motion from DUSt3R Without Training","summary":"Recent advances in DUSt3R have enabled robust estimation of dense point\nclouds and camera parameters of static scenes, leveraging Transformer network\narchitectures and direct supervision on large-scale 3D datasets. In contrast,\nthe limited scale and diversity of available 4D datasets present a major\nbottleneck for training a highly generalizable 4D model. This constraint has\ndriven conventional 4D methods to fine-tune 3D models on scalable dynamic video\ndata with additional geometric priors such as optical flow and depths. In this\nwork, we take an opposite path and introduce Easi3R, a simple yet efficient\ntraining-free method for 4D reconstruction. Our approach applies attention\nadaptation during inference, eliminating the need for from-scratch pre-training\nor network fine-tuning. We find that the attention layers in DUSt3R inherently\nencode rich information about camera and object motion. By carefully\ndisentangling these attention maps, we achieve accurate dynamic region\nsegmentation, camera pose estimation, and 4D dense point map reconstruction.\nExtensive experiments on real-world dynamic videos demonstrate that our\nlightweight attention adaptation significantly outperforms previous\nstate-of-the-art methods that are trained or finetuned on extensive dynamic\ndatasets. Our code is publicly available for research purpose at\nhttps://easi3r.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01320v1","title":"A link between covering and coefficient theorems for holomorphic\n  functions","summary":"Recently the author presented a new approach to solving the coefficient\nproblems for various classes of holomorphic functions $f(z) =\n\\sum\\limits_0^\\infty c_n z^n$, not necessarily univalent. This approach is\nbased on lifting the given polynomial coefficient functionals $J(f) =\nJ(c_{m_1}, \\dots, c_{m_s}), 2 < c_{m_1} < \\dots < c_{m_s} < \\infty$, onto the\nBers fiber space over universal Teichmuller space and applying the analytic and\ngeometric features of Teichm\\\"{u}ller spaces, especially the Bers isomorphism\ntheorem for Teichmuller spaces of punctured Riemann surfaces.\n  In this paper, we extend this approach to more general classes of functions.\nIn particular, this provides a strengthening of de Branges' theorem solving the\nBieberbach conjecture.","main_category":"math.CV","categories":"math.CV","published":"2025-04-02T03:12:22Z"}
{"aid":"http://arxiv.org/abs/2504.01321v1","title":"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\n  Tracking","summary":"Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T03:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.01324v1","title":"On Data Synthesis and Post-training for Visual Abstract Reasoning","summary":"This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T03:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01369v1","title":"LITE: LLM-Impelled efficient Taxonomy Evaluation","summary":"This paper presents LITE, an LLM-based evaluation method designed for\nefficient and flexible assessment of taxonomy quality. To address challenges in\nlarge-scale taxonomy evaluation, such as efficiency, fairness, and consistency,\nLITE adopts a top-down hierarchical evaluation strategy, breaking down the\ntaxonomy into manageable substructures and ensuring result reliability through\ncross-validation and standardized input formats. LITE also introduces a penalty\nmechanism to handle extreme cases and provides both quantitative performance\nanalysis and qualitative insights by integrating evaluation metrics closely\naligned with task objectives. Experimental results show that LITE demonstrates\nhigh reliability in complex evaluation tasks, effectively identifying semantic\nerrors, logical contradictions, and structural flaws in taxonomies, while\noffering directions for improvement. Code is available at\nhttps://github.com/Zhang-l-i-n/TAXONOMY_DETECT .","main_category":"cs.CL","categories":"cs.CL,cs.IR","published":"2025-04-02T05:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.01376v1","title":"On the dual structure of the Schrödinger dynamics","summary":"This paper elucidates the dual structure of the Schr\\\"{o}dinger dynamics in\ntwo correlated stages: (1) We first derive the real-valued Schr\\\"{o}dinger\nequation from scratch without referring to classical mechanics, wave mechanics,\nnor optics, and thereby attain a concrete and clear interpretation of the\nSchr\\\"{o}dinger (wave) function. Beginning with a factorization of the density\ndistribution function of the particles to two component vectors in\nconfiguration space, we impose very simple conditions on them such as\ntranslational invariance of space-time and the conservation of flux under a\ngiven potential function. A real-valued path-integral is formulated as a Green\nfunction for the real-valued Schr\\\"{o}dinger equation. (2) We then study a\nquantum stochastic path dynamics in a manner compatible with the\nSchr\\\"{o}dinger equation. The relation between them is like the Langevin\ndynamics with the diffusion equation. Each quantum path describes a\n\\textquotedblleft trajectory\\textquotedblright\\ in configuration space\nrepresenting, for instance, a singly launched electron in the double-slit\nexperiment that leaves a spot one by one at the measurement board, while\naccumulated spots give rise to the fringe pattern as predicted by the absolute\nsquare of the Schr\\\"{o}dinger function. We start from the relationship between\nthe Ito stochastic differential equation, the Feynman-Kac formula, and the\nassociated parabolic partial differential equations, to one of which\\ the\nSchr\\\"{o}dinger equation is transformed. The physical significance of the\nquantum intrinsic stochasticity and the indirect correlation among the quantum\npaths and so on are discussed. The self-referential nonlinear interrelationship\nbetween the Schr\\\"{o}dinger functions (regarded as a whole) and the quantum\npaths (as its parts) is identified as the ultimate mystery in quantum dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T05:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.01406v1","title":"A steady solution to the hydrodynamic equation and incommensurate\n  magnetization in a U(2) invariant superfluid","summary":"At the zero temperature limit, a one-dimensional steady solution to the\nhydrodynamic equation of a U(2) invariant superfluid is obtained. This solution\nreveals that the magnitude of magnetization is always directly proportional to\nthe particle number density. Furthermore, the problem can be interpreted as a\nparticle's motion in a central force field. It is demonstrated that the\nparticle's orbits are elliptical in shape, with a precession angle determined\nby a non-zero mass current. This suggests that the spatial periods of the three\ncomponent magnetizations are not commensurate. These findings indicate that the\ncoupling of mass superflow and magnetization distortions usually results in an\nincommensurate magnetization.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.01407v1","title":"TimeSearch: Hierarchical Video Search with Spotlight and Reflection for\n  Human-like Long Video Understanding","summary":"Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T06:47:19Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01470v1","title":"Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for\n  Analyzing Mouth Inconsistencies","summary":"Deepfakes are AI-generated media in which the original content is digitally\naltered to create convincing but manipulated images, videos, or audio. Among\nthe various types of deepfakes, lip-syncing deepfakes are one of the most\nchallenging deepfakes to detect. In these videos, a person's lip movements are\nsynthesized to match altered or entirely new audio using AI models. Therefore,\nunlike other types of deepfakes, the artifacts in lip-syncing deepfakes are\nconfined to the mouth region, making them more subtle and, thus harder to\ndiscern. In this paper, we propose LIPINC-V2, a novel detection framework that\nleverages a combination of vision temporal transformer with multihead\ncross-attention to detect lip-syncing deepfakes by identifying spatiotemporal\ninconsistencies in the mouth region. These inconsistencies appear across\nadjacent frames and persist throughout the video. Our model can successfully\ncapture both short-term and long-term variations in mouth movement, enhancing\nits ability to detect these inconsistencies. Additionally, we created a new\nlip-syncing deepfake dataset, LipSyncTIMIT, which was generated using five\nstate-of-the-art lip-syncing models to simulate real-world scenarios. Extensive\nexperiments on our proposed LipSyncTIMIT dataset and two other benchmark\ndeepfake datasets demonstrate that our model achieves state-of-the-art\nperformance. The code and the dataset are available at\nhttps://github.com/skrantidatta/LIPINC-V2 .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:06Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01485v1","title":"Diameter Shortcut Sets on Temporal Graphs","summary":"Shortcut sets are a vital instrument for reducing the diameter of a static\ngraph and, consequently, its shortest path complexity, which is relevant in\nnumerous subfields of graph theory. We explore the notion of shortcut sets in\ntemporal graphs, which incorporate a discrete time model into the graph,\nrendering each edge accessible exclusively at specific points in time. This not\nonly alters the underlying assumptions of regular graphs but also substantially\nincreases the complexity of path problems and reachability. In turn, a temporal\ngraph is often a much more realistic and accurate representation of a\nreal-world network. In this thesis we provide a definition for a shortcut set\nin a temporal graph and explore differences to classic shortcut sets. Utilizing\nthis definition, we show that temporal and regular shortcut sets yield the same\nresults on temporal paths, enabling the application of existing construction\nalgorithms for static shortcut sets on paths. The primary contribution of this\nthesis is a translation approach for general temporal graphs that utilizes the\nstatic expansion of a temporal graph, allowing the conversion of static\nshortcut sets into temporal shortcut sets, yielding similar results.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T08:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.01488v1","title":"A Novel Pilot Allocation Technique for Uplink OFDMA in ISAC Systems","summary":"In integrated sensing and communication (ISAC) systems, pilot signals play a\ncrucial role in enhancing sensing performance due to their strong\nautocorrelation properties and high transmission power. However, conventional\ninterleaved pilots inherently constrain the maximum unambiguous range and\nreduce the accuracy of channel impulse response (CIR) estimation compared to\ncontinuous orthogonal frequency-division multiple access (OFDMA) signals. To\naddress this challenge, we propose a novel overlapped block-pilot structure for\nuplink OFDMA-based ISAC systems, called phase-shifted ISAC (PS-ISAC) pilot\nallocation. The proposed method leverages a cyclic prefix (CP)-based\nphase-shifted pilot design, enabling efficient multi-transmitter pilot\nseparation at the receiver. Simulation results confirm that the proposed scheme\nenhances CIR separation, reduces computational complexity, and improves mean\nsquare error (MSE) performance under practical power constraints. Furthermore,\nwe demonstrate that utilizing continuous pilot resources maximizes the\nunambiguous range.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T08:39:28Z"}
{"aid":"http://arxiv.org/abs/2504.01490v1","title":"Deep Learning-Driven Protein Structure Prediction and Design: Key Model\n  Developments by Nobel Laureates and Multi-Domain Applications","summary":"This systematic review outlines pivotal advancements in deep learning-driven\nprotein structure prediction and design, focusing on four core\nmodels-AlphaFold, RoseTTAFold, RFDiffusion, and ProteinMPNN-developed by 2024\nNobel Laureates in Chemistry: David Baker, Demis Hassabis, and John Jumper. We\nanalyze their technological iterations and collaborative design paradigms,\nemphasizing breakthroughs in atomic-level structural accuracy, functional\nprotein engineering, and multi-component biomolecular interaction modeling. Key\ninnovations include AlphaFold3's diffusion-based framework for unified\nbiomolecular prediction, RoseTTAFold's three-track architecture integrating\nsequence and spatial constraints, RFDiffusion's denoising diffusion for de novo\nprotein generation, and ProteinMPNN's inverse folding for sequence-structure\nco-optimization. Despite transformative progress in applications such as binder\ndesign, nanomaterials, and enzyme engineering, challenges persist in dynamic\nconformational sampling, multimodal data integration, and generalization to\nnon-canonical targets. We propose future directions, including hybrid\nphysics-AI frameworks and multimodal learning, to bridge gaps between\ncomputational design and functional validation in cellular environments.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-02T08:44:10Z"}
{"aid":"http://arxiv.org/abs/2504.01492v1","title":"Nagaoka ferromagnetism in semiconductor artificial graphene","summary":"We present the emergence of Nagaoka ferromagnetism in semiconductor-based\nartificial graphene using high-precision variational and diffusion Monte Carlo\nmethods, complemented by exact diagonalization calculations of the extended\nHubbard model. Specifically, we analyze a realistic model of an armchair\nhexagonal geometry comprising $42$ lattice sites, nanopatterned on GaAs quantum\nwells with nearest-neighbor distance of $a = 50$ nm. Our results reveal a\ndistinct magnetic phase transition near $U/t \\approx 60$ driven by the\nabsence/addition of a single electron at half-filling where the ferromagnetic\nphase is further stabilized by Coulomb scattering terms.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-02T08:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.01506v1","title":"MLKV: Efficiently Scaling up Large Embedding Model Training with\n  Disk-based Key-Value Storage","summary":"Many modern machine learning (ML) methods rely on embedding models to learn\nvector representations (embeddings) for a set of entities (embedding tables).\nAs increasingly diverse ML applications utilize embedding models and embedding\ntables continue to grow in size and number, there has been a surge in the\nad-hoc development of specialized frameworks targeted to train large embedding\nmodels for specific tasks. Although the scalability issues that arise in\ndifferent embedding model training tasks are similar, each of these frameworks\nindependently reinvents and customizes storage components for specific tasks,\nleading to substantial duplicated engineering efforts in both development and\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\ndata storage framework designed to address the scalability challenges in\nembedding model training, specifically data stall and staleness. MLKV augments\ndisk-based key-value storage by democratizing optimizations that were\npreviously exclusive to individual specialized frameworks and provides\neasy-to-use interfaces for embedding model training tasks. Extensive\nexperiments on open-source workloads, as well as applications in eBay's payment\ntransaction risk detection and seller payment risk detection, show that MLKV\noutperforms offloading strategies built on top of industrial-strength key-value\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01518v1","title":"On 2-color partitions where one of the colors is multiples of $7^k$","summary":"In this work, we investigate the arithmetic properties of $p_{1,7^k}(n)$,\nwhich counts 2-color partitions of $n$ where one of the colors appears only in\nparts that are multiples of $7^k$. By constructing generating functions for\n$p_{1,7^k}(n)$ across specific arithmetic progressions, we establish a set of\nRamanujan-type infinite family of congruences modulo powers of $7$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01578v1","title":"Entanglement in the symmetric subspace: mapping multipartite to\n  bipartite states","summary":"We propose a technique to investigate multipartite entanglement in the\nsymmetric subspace. Our approach is to map an $N$-qubit symmetric state onto a\nbipartite symmetric state of higher local dimension. We show that this mapping\npreserves separability and allows to characterize the entanglement of the\noriginal multipartite state. In particular, we provide several bounds to\nestimate the symmetric tensor rank and geometric measure of entanglement.\nAdditionally, we identify multipartite symmetric states whose entanglement\noutperforms that of previously known candidates for maximally entangled\nsymmetric states. Finally, we reveal the existence of entangled symmetric\nsubspaces, where all bipartite states are entangled.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01593v1","title":"Integrating experimental feedback improves generative models for\n  biological sequences","summary":"Generative probabilistic models have shown promise in designing artificial\nRNA and protein sequences but often suffer from high rates of false positives,\nwhere sequences predicted as functional fail experimental validation. To\naddress this critical limitation, we explore the impact of reintegrating\nexperimental feedback into the model design process. We propose a\nlikelihood-based reintegration scheme, which we test through extensive\ncomputational experiments on both RNA and protein datasets, as well as through\nwet-lab experiments on the self-splicing ribozyme from the group I intron RNA\nfamily where our approach demonstrates particular efficacy. We show that\nintegrating recent experimental data enhances the model's capacity of\ngenerating functional sequences (e.g. from 6.7\\% to 63.7\\% of active designs at\n45 mutations). This feedback-driven approach thus provides a significant\nimprovement in the design of biomolecular sequences by directly tackling the\nfalse-positive challenge.","main_category":"q-bio.BM","categories":"q-bio.BM,physics.bio-ph,q-bio.QM","published":"2025-04-02T10:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01615v1","title":"The Mini-SiTian Array: A Pathfinder for the SiTian Project","summary":"The Mini-SiTian Array serves as a pathfinder for the SiTian project, which\naims to survey the entire sky in $gri$ bands every 30 minutes, reaching a\nlimiting magnitude of 21. This special issue features 11 papers covering the\ndesign, operation, data reduction, and early scientific results from two years\nof Mini-SiTian observations. The insights gained from these pathfinder\nexperiments represent a significant milestone toward the full realization of\nthe SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.01621v1","title":"Two-photon microscopy using picosecond pulses from four-wave mixing in a\n  Yb-doped photonic crystal fiber","summary":"Two-photon microscopy (TPM) enables deep tissue imaging but requires\nexcitation pulses that have a large product of average and peak power,\ntypically supplied by femtosecond solid-state lasers. However, these lasers are\nbulky and femtosecond pulses require careful dispersion management to avoid\npulse broadening, particularly when delivery fibers are used. Here we present a\ncompact, fiber-based picosecond laser source operating at 790 nm for TPM using\na ytterbium-doped photonic crystal fiber (Yb-doped PCF). The Yb-doped PCF\nsimultaneously amplifies 1064 nm input pulses and efficiently converts them to\n790 nm via four-wave mixing, generating pulses with a peak power of up to ~3.8\nkW. The source has a variable repetition rate (1.48 MHz-14.78 MHz), enabling\nthe two-photon excitation fluorescence signal to be maximized in the presence\nof excitation saturation. We benchmark our picosecond laser source against a\nfemtosecond Ti:Sapphire laser for TPM of stained Convallaria majalis samples\nand demonstrate comparable fluorescence signal when the two-photon excitation\nconditions are matched.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.01642v1","title":"Spanning clique subdivisions in pseudorandom graphs","summary":"In this paper, we study the appearance of a spanning subdivision of a clique\nin graphs satisfying certain pseudorandom conditions. Specifically, we show the\nfollowing three results. Firstly, that there are constants $C>0$ and $c\\in\n(0,1]$ such that, whenever $d/\\lambda\\ge C$, every $(n,d,\\lambda)$-graph\ncontains a spanning subdivision of $K_t$ for all $2\\le t \\le\n\\min\\{cd,c\\sqrt{\\frac{n}{\\log n}}\\}$. Secondly, that there are constants $C>0$\nand $c\\in (0,1]$ such that, whenever $d/\\lambda\\ge C\\log^3n$, every\n$(n,d,\\lambda)$-graph contains a spanning nearly-balanced subdivision of $K_t$\nfor all $2\\le t \\le \\min\\{cd,c\\sqrt{\\frac{n}{\\log^3n}}\\}$. Finally, we show\nthat for every $\\mu>0$, there are constants $c,\\varepsilon\\in (0,1]$ and\n$n_0\\in \\mathbb N$ such that, whenever $n\\ge n_0$, every $n$-vertex graph with\nminimum degree at least $\\mu n$ and no bipartite holes of size $\\varepsilon n$\ncontains a spanning nearly-balanced subdivision of $K_t$ for all $2\\le t \\le\nc\\sqrt{n}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T11:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.01666v1","title":"CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign\n  Language Recognition","summary":"Continuous sign language recognition (CSLR) focuses on interpreting and\ntranscribing sequences of sign language gestures in videos. In this work, we\npropose CLIP sign language adaptation (CLIP-SLA), a novel CSLR framework that\nleverages the powerful pre-trained visual encoder from the CLIP model to sign\nlanguage tasks through parameter-efficient fine-tuning (PEFT). We introduce two\nvariants, SLA-Adapter and SLA-LoRA, which integrate PEFT modules into the CLIP\nvisual encoder, enabling fine-tuning with minimal trainable parameters. The\neffectiveness of the proposed frameworks is validated on four datasets:\nPhoenix2014, Phoenix2014-T, CSL-Daily, and Isharah-500, where both CLIP-SLA\nvariants outperformed several SOTA models with fewer trainable parameters.\nExtensive ablation studies emphasize the effectiveness and flexibility of the\nproposed methods with different vision-language models for CSLR. These findings\nshowcase the potential of adapting large-scale pre-trained models for scalable\nand efficient CSLR, which pave the way for future advancements in sign language\nunderstanding.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01678v1","title":"Second-order cone programming for distributionally robust compliance\n  optimization of trusses considering input distribution uncertainty","summary":"Reliability-based design optimization (RBDO) is a methodology for designing\nstructures under the consideration for uncertainty with the assumption that the\ninput distribution is completely known. In practical engineering, the number of\ninput data is often limited, which can damage the validity of the optimal\nresults obtained by RBDO. Confidence-based design optimization (CBDO) has been\nproposed to account for the uncertainty of the input distribution. However,\nthis approach faces challenges, computational cost and accuracy when dealing\nwith highly nonlinear performance constraints. In this paper, we consider the\ncompliance minimization problem of truss structures with uncertain external\nforces. Armed with the advanced risk measure, conditional Value-at-Risk (CVaR),\nwe formulate a bi-objective optimization problem for the worst-case expected\nvalue and the worst-case CVaR of compliance, which allows us to account for the\ntail risk of performance functions not addressed in CBDO. Employing kernel\ndensity estimation for estimation of the input distribution allows us to\neliminate the need for modeling the input distribution. We show that this\nproblem reduces to a second-order cone programming when assigning either\nuniform kernel or triangular kernel. Finally, through numerical experiments, we\nobtain the Pareto front for the bi-objective optimization problem of the\nworst-case expected value and CVaR of compliance of truss structures, and\nconfirm the changes in the Pareto solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T12:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01733v1","title":"Epistemic Skills: Reasoning about Knowledge and Oblivion","summary":"This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.","main_category":"cs.AI","categories":"cs.AI,cs.CC,cs.LO","published":"2025-04-02T13:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.01742v1","title":"Doctor: Optimizing Container Rebuild Efficiency by Instruction\n  Re-Orchestration","summary":"Containerization has revolutionized software deployment, with Docker leading\nthe way due to its ease of use and consistent runtime environment. As Docker\nusage grows, optimizing Dockerfile performance, particularly by reducing\nrebuild time, has become essential for maintaining efficient CI/CD pipelines.\nHowever, existing optimization approaches primarily address single builds\nwithout considering the recurring rebuild costs associated with modifications\nand evolution, limiting long-term efficiency gains. To bridge this gap, we\npresent Doctor, a method for improving Dockerfile build efficiency through\ninstruction re-ordering that addresses key challenges: identifying instruction\ndependencies, predicting future modifications, ensuring behavioral equivalence,\nand managing the optimization computational complexity. We developed a\ncomprehensive dependency taxonomy based on Dockerfile syntax and a historical\nmodification analysis to prioritize frequently modified instructions. Using a\nweighted topological sorting algorithm, Doctor optimizes instruction order to\nminimize future rebuild time while maintaining functionality. Experiments on\n2,000 GitHub repositories show that Doctor improves 92.75% of Dockerfiles,\nreducing rebuild time by an average of 26.5%, with 12.82% of files achieving\nover a 50% reduction. Notably, 86.2% of cases preserve functional similarity.\nThese findings highlight best practices for Dockerfile management, enabling\ndevelopers to enhance Docker efficiency through informed optimization\nstrategies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T13:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.01752v1","title":"A Two-Timescale Approach for Wireless Federated Learning with Parameter\n  Freezing and Power Control","summary":"Federated learning (FL) enables distributed devices to train a shared machine\nlearning (ML) model collaboratively while protecting their data privacy.\nHowever, the resource-limited mobile devices suffer from intensive\ncomputation-and-communication costs of model parameters. In this paper, we\nobserve the phenomenon that the model parameters tend to be stabilized long\nbefore convergence during training process. Based on this observation, we\npropose a two-timescale FL framework by joint optimization of freezing\nstabilized parameters and controlling transmit power for the unstable\nparameters to balance the energy consumption and convergence. First, we analyze\nthe impact of model parameter freezing and unreliable transmission on the\nconvergence rate. Next, we formulate a two-timescale optimization problem of\nparameter freezing percentage and transmit power to minimize the model\nconvergence error subject to the energy budget. To solve this problem, we\ndecompose it into parallel sub-problems and decompose each sub-problem into two\ndifferent timescales problems using the Lyapunov optimization method. The\noptimal parameter freezing and power control strategies are derived in an\nonline fashion. Experimental results demonstrate the superiority of the\nproposed scheme compared with the benchmark schemes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T14:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.01767v1","title":"Leveraging Embedding Techniques in Multimodal Machine Learning for\n  Mental Illness Assessment","summary":"The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CV","published":"2025-04-02T14:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.01768v1","title":"Updating the Ephemeris and Physical Properties of Five Long-period\n  Transiting Exoplanets Using TESS and CHEOPS","summary":"The transiting long-period exoplanets are the most interesting follow-up\ntargets for the next-generation instruments, using the most sophisticated\nobservational techniques. However, the scarcity in their transit events often\nleads to larger uncertainties in their known ephemeris, also resulting in\nlarger biases in their known physical properties in many cases. In this work, I\nhave used the newer publicly available observations from TESS and CHEOPS for\nfive very interesting long-period transiting exoplanets, i.e., HD95338 b,\nTOI-2134 c, K2-290 c, TOI-1898 b, and TOI-813 b, combined with the previously\nreported observations, to reanalyze their transit properties and estimate the\nupdated ephemeris. The analyses also incorporated a critical noise treatment\nalgorithm, which uses well-tested techniques such as wavelet denoising and\nGaussian process regression, to effectively reduce the impact of various noise\ncomponents present in the lightcurves on the estimated parameters. The study\nhas resulted in a more precise estimation of ephemeris for all the targets,\nwith the precision in the estimated periods being better than 5 seconds, except\nfor TOI-813 b, for which the precision in the estimated period is better than\n21 seconds. The other transit parameters also got updated, with statistically\nsignificant improvements seen in most of the cases, the major notable\nimprovements being in the estimated value of the impact parameter of TOI-1898\nb, the orbital semi-major axis of TOI-2134 c, and the radius of HD95338 b.\nAlthough long-period exoplanets are expected to show more significant transit\ntiming variations in the presence of other undetected planetary mass objects,\nno such variations were recorded for these targets.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T14:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01787v1","title":"The Factors Influencing Well-Being in Software Engineers: A\n  Cross-Country Mixed-Method Study","summary":"The well-being of software engineers is increasingly under strain due to the\nhigh-stress nature of their roles, which involve complex problem-solving, tight\ndeadlines, and the pressures of rapidly evolving technologies.\n  Despite increasing recognition of mental health challenges in software\nengineering, few studies focus on the factors that sustain or undermine\nwell-being. Existing research often overlooks the interaction between personal,\ncollaborative, and organisational influences on this unique population. This\nstudy fills this gap by investigating the specific factors affecting the\nwell-being of software engineers. We conducted 15 qualitative interviews and\ncomplemented them with a confirmatory cross-country survey to validate and\nextend our findings to a broader population. Our mixed-methods approach\nprovides a robust framework to identify key factors influencing well-being,\nincluding personal perceptions of well-being, interpersonal and collaborative\ndynamics, workplace support and recognition, organisational culture, and\nspecific stressors inherent to software engineering.\n  By offering a detailed, context-specific exploration of these factors, our\nstudy builds on existing literature and provides actionable insights for\nimproving well-being in software engineering. We conclude with policy\nrecommendations to inform organisational strategies and develop targeted\ninterventions that address the specific challenges of this field, contributing\nto more sustainable and supportive work environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T14:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.01798v1","title":"A Novel Approach To Implementing Knowledge Distillation In Tsetlin\n  Machines","summary":"The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-02T15:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.01808v1","title":"Coloring of graphs without long odd holes","summary":"A {\\em hole} is an induced cycle of length at least 4, a $k$-hole is a hole\nof length $k$, and an {\\em odd hole} is a hole of odd length. Let $\\ell\\ge 2$\nbe an integer. Let ${\\cal A}_{\\ell}$ be the family of graphs of girth at least\n$2\\ell$ and having no odd holes of length at least $2\\ell+3$, let ${\\cal\nB}_{\\ell}$ be the triangle-free graphs which have no 5-holes and no odd holes\nof length at least $2\\ell+3$, and let ${\\cal G}_{\\ell}$ be the family of graphs\nof girth $2\\ell+1$ and have no odd hole of length at least $2\\ell+5$.\nChudnovsky {\\em et al.} \\cite{CSS2016} proved that every graph in ${\\cal\nA}_{2}$ is 58000-colorable, and every graph in ${\\cal B}_{\\ell}$ is\n$(\\ell+1)4^{\\ell-1}$-colorable. Lan and liu \\cite{LL2023} showed that for\n$\\ell\\geq3$, every graph in ${\\cal G}_{\\ell}$ is 4-colorable. It is not known\nwhether there exists a small constant $c$ such that graphs of ${\\cal G}_2$ are\n$c$-colorable. In this paper, we show that every graph in ${\\cal G}_2$ is\n1456-colorable, and every graph in ${\\cal A}_{3}$ is 4-colorable. We also show\nthat every 7-hole free graph in ${\\cal B}_{\\ell}$ is $(12\\ell+8)$-colorable.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T15:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.01817v1","title":"Multi-actuator lens systems for turbulence correction in free-space\n  optical communications","summary":"The implementation of efficient free-space channels is fundamental for both\nclassical and quantum Free-Space Optical (FSO) communication. This can be\nchallenging for fibre-coupled receivers, due to the time variant inhomogeneity\nof the refractive index that can cause strong fluctuations in the power coupled\ninto the Single-Mode Fiber (SMF), and requires the use of Adaptive Optics (AO)\nsystems to correct the atmospheric induced aberrations. In this work, we\npresent two adaptive optic systems, one using a Fast-Steering Prism (FSP) for\nthe correction of tip-tilt and a second one based on a Multi-Actuator\ndeformable Lens (MAL), capable of correcting up to the third order of Zernike's\npolynomials. We test both systems at telecom wavelength both with artificial\nturbulence in the laboratory and on a free-space channel, demonstrating their\neffectiveness in increasing the fibre coupling efficiency.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T15:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.01827v1","title":"What is AI, what is it not, how we use it in physics and how it\n  impacts... you","summary":"Artificial Intelligence (AI) and Machine Learning (ML) have been prevalent in\nparticle physics for over three decades, shaping many aspects of High Energy\nPhysics (HEP) analyses. As AI's influence grows, it is essential for physicists\n$\\unicode{x2013}$ as both researchers and informed citizens $\\unicode{x2013}$\nto critically examine its foundations, misconceptions, and impact. This paper\nexplores AI definitions, examines how ML differs from traditional programming,\nand provides a brief review of AI/ML applications in HEP, highlighting\npromising trends such as Simulation-Based Inference, uncertainty-aware machine\nlearning, and Fast ML for anomaly detection. Beyond physics, it also addresses\nthe broader societal harms of AI systems, underscoring the need for responsible\nengagement. Finally, it stresses the importance of adapting research practices\nto an evolving AI landscape, ensuring that physicists not only benefit from the\nlatest tools but also remain at the forefront of innovation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.LG,hep-ex","published":"2025-04-02T15:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $δ$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01842v1","title":"shapr: Explaining Machine Learning Models with Conditional Shapley\n  Values in R and Python","summary":"This paper introduces the shapr package, a versatile tool for generating\nShapley value explanations for machine learning and statistical regression\nmodels in both R and Python. The package emphasizes conditional Shapley value\nestimates, providing a comprehensive range of approaches for accurately\ncapturing feature dependencies, which is crucial for correct model\ninterpretation and lacking in similar software. In addition to regular tabular\ndata, the shapr R-package includes specialized functionality for explaining\ntime series forecasts. The package offers a minimal set of user functions with\nsensible defaults for most use cases while providing extensive flexibility for\nadvanced users to fine-tune computations. Additional features include\nparallelized computations, iterative estimation with convergence detection, and\nrich visualization tools. shapr also extends its functionality to compute\ncausal and asymmetric Shapley values when causal information is available. In\naddition, we introduce the shaprpy Python library, which brings core\ncapabilities of shapr to the Python ecosystem. Overall, the package aims to\nenhance the interpretability of predictive models within a powerful and\nuser-friendly framework.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-04-02T15:47:30Z"}
{"aid":"http://arxiv.org/abs/2504.01846v1","title":"Many neighbors little entanglement: A curious scaling in the\n  variable-range extended Ising model","summary":"We study the two-point correlation functions and the bipartite entanglement\nin the ground state of the exactly-solvable variable-range extended Ising model\nof qubits in the presence of a transverse field on a one-dimensional lattice.\nWe introduce the variation in the range of interaction by varying the\ncoordination number, $\\mathcal{Z}$, of each qubit, where the interaction\nstrength between a pair of qubits at a distance $r$ varies as $\\sim\nr^{-\\alpha}$. We show that the algebraic nature of the correlation functions is\npresent only up to $r=\\mathcal{Z}$, above which it exhibits short-range\nexponential scaling. We also show that at the critical point, the bipartite\nentanglement exhibits a power-law decrease ($\\sim\\mathcal{Z}^{-\\gamma}$) with\nincreasing coordination number irrespective of the partition size and the value\nof $\\alpha$ for $\\alpha>1$. We further consider a sudden quench of the system\nstarting from the ground state of the infinite-field limit of the system\nHamiltonian via turning on the critical Hamiltonian, and demonstrate that the\nlong-time averaged bipartite entanglement exhibits a qualitatively similar\nvariation ($\\sim\\mathcal{Z}^{-\\gamma}$) with $\\mathcal{Z}$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-02T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01868v1","title":"Focal Mechanism Uncertainty Quantification In Ground Motion Simulations\n  Of Le Teil Earthquake","summary":"Ensuring the seismic safety of nuclear power plants (NPPs) is essential,\nespecially for facilities that rely on base isolation to reduce earthquake\nimpacts. For understanding the seismic response, accurate models are key to\npredict the ground motions, which are generally sensitive to various factors,\nincluding earthquake source parameters like the focal mechanism, i.e., strike,\ndip, and rake angles. This study examines how uncertainties in these parameters\naffect ground motion predictions. The analysis is based on the SMATCH\nbenchmark, which provides a standardized approach for evaluating the seismic\nresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquake\nof 2019. A set of 27 3D high-fidelity numerical simulations was performed using\na spectral-element method, each incorporating different focal mechanism\nvariations. These simulations provide an effective approach for investigating\nthe factors behind the exceptional ground motion observed during this event. To\nquantify uncertainty, the simulated ground motions were compared to recorded\ndata using two well-established goodness-of-fit criteria: one assessing\ntime-frequency domain characteristics and another focusing on the\ncharacterization of the ground motion signals by intensity measures. Results\nhighlight the significant influence of focal mechanism variability on ground\nmotion predictions, especially on the rake angle, which showed the strongest\ncorrelation with wave and intensity measures.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01901v1","title":"Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness","summary":"The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.RO","published":"2025-04-02T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01909v1","title":"The Trinity of black hole correspondences: Shadows-quasinormal\n  modes-graybody factors and cautionary remarks","summary":"Correspondences between apparently distant concepts are ubiquitous in\ntheoretical physics. In the context of Black Holes (BHs), Quasi-Normal Modes\n(QNMs) were shown to be linked to both the shadows, in the so-called eikonal\nlimit, and Gray-Body Factors (GBFs), using the WKB approximation. We test the\naccuracy of the quasinormal modes-graybody factors correspondence's in the\ncontext of the Hawking spectra for static and rotating black hole\nconfigurations, with particular attention to the superradiant regime. Our\nanalysis reveals the correspondence failure to accurately reproduce the Hawking\nspectrum due to divergences. Furthermore, we bridge the gap between black\nshadows and graybody factors by drawing a correspondence between such\nquantities in the case of generic static and spherically symmetric spacetime\nconfigurations. The shadow-GBF correspondence is tested for some case studies,\nincluding regular BHs, and its limitations and applicability are thereof\ndiscussed. This study opens new perspectives, by introducing a new\ncorrespondence and remarking on the caution needed when considering these\nconnections.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-ph","published":"2025-04-02T17:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.01918v1","title":"Long-eared digraphs","summary":"Let $H$ be a subdigraph of a digraph $D$. An ear of $H$ in $D$ is a path or a\ncycle in $D$ whose ends lie in $H$ but whose internal vertices do not. An\n\\emph{ear decomposition} of a strong digraph $D$ is a nested sequence\n$(D_0,D_1,\\ldots , D_k)$ of strong subdigraphs of $D$ such that: 1) $D_0$ is a\ncycle, 2) $D_{i+1} = D_i\\cup P_i$, where $P_i$ is an ear of $D_i$ in $D$, for\nevery $i\\in \\{0,1,\\ldots,k-1\\}$, and 3) $D_k=D$.\n  In this work, the $\\mathcal{LE}_i$ is defined as the family of strong\ndigraphs, with an ear decomposition such that every ear has a length of at\nleast $i\\geq 1$. It is proved that Seymour's second Neighborhood Conjecture and\nthe Laborde, Payan, and Soung conjecture, are true in the family\n$\\mathcal{LE}_2$, and the Small quasi-kernel conjecture is true for digraphs in\n$\\mathcal{LE}_3$. Also, some sufficient conditions for a strong nonseparable\ndigraph in $\\mathcal{LE}_2$ with a kernel to imply that the previous\n(following) subdigraph in the ear decomposition has a kernel too, are\npresented. It is proved that digraphs in $\\mathcal{LE}_2$ have a chromatic\nnumber at most 3, and a dichromatic number 2 or 3. Finally, the oriented\nchromatic number of asymmetrical digraphs in $\\mathcal{LE}_3$ is bounded by 6,\nand it is shown that the oriented chromatic number of asymmetrical digraphs in\n$\\mathcal{LE}_2$ is not bounded.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T17:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.01927v1","title":"Characterisation of distributions through $δ$-records and\n  martingales","summary":"Given parameters $c>0, \\delta\\ne0$ and a sequence $(X_n)$ of real-valued,\nintegrable, independent and identically $F$-distributed random variables, we\ncharacterise distributions $F$ such that $(N_n-cM_n)$ is a martingale, where\n$N_n$ denotes the number of observations $X_k$ among $X_1,\\ldots,X_n$ such that\n$X_k>M_{k-1}+\\delta$, called $\\delta$-records, and $M_k=\\max\\{X_1,\\ldots,\nX_k\\}$.\n  The problem is recast as $1-F(x+\\delta)=c\\int_{x}^{\\infty}(1-F)(t)dt$, for\n$x\\in T$, with $F(T)=1$. Unlike standard functional equations, where the\nequality must hold for all $x$ in a fixed set, our problem involves a domain\nthat depends on $F$ itself, introducing complexity but allowing for more\npossibilities of solutions.\n  We find the explicit expressions of all solutions when $\\delta < 0$ and, when\n$\\delta > 0$, for distributions with bounded support. In the unbounded support\ncase, we focus attention on continuous and lattice distributions. In the\ncontinuous setting, with support $\\mathbb{R}_+$, we reduce the problem to a\ndelay differential equation, showing that, besides particular cases of the\nexponential distribution, mixtures of exponential and gamma distributions and\nmany others are solutions as well. The lattice case, with support\n$\\mathbb{Z}_+$ is treated analogously and reduced to the study of a difference\nequation. Analogous results are obtained; in particular, mixtures of geometric\nand negative binomial distributions are found to solve the problem.","main_category":"math.PR","categories":"math.PR","published":"2025-04-02T17:37:30Z"}
{"aid":"http://arxiv.org/abs/2504.01933v1","title":"Hessian-aware Training for Enhancing DNNs Resilience to Parameter\n  Corruptions","summary":"Deep neural networks are not resilient to parameter corruptions: even a\nsingle-bitwise error in their parameters in memory can cause an accuracy drop\nof over 10%, and in the worst cases, up to 99%. This susceptibility poses great\nchallenges in deploying models on computing platforms, where adversaries can\ninduce bit-flips through software or bitwise corruptions may occur naturally.\nMost prior work addresses this issue with hardware or system-level approaches,\nsuch as integrating additional hardware components to verify a model's\nintegrity at inference. However, these methods have not been widely deployed as\nthey require infrastructure or platform-wide modifications.\n  In this paper, we propose a new approach to addressing this issue: training\nmodels to be more resilient to bitwise corruptions to their parameters. Our\napproach, Hessian-aware training, promotes models with $flatter$ loss surfaces.\nWe show that, while there have been training methods, designed to improve\ngeneralization through Hessian-based approaches, they do not enhance resilience\nto parameter corruptions. In contrast, models trained with our method\ndemonstrate increased resilience to parameter corruptions, particularly with a\n20$-$50% reduction in the number of bits whose individual flipping leads to a\n90$-$100% accuracy drop. Moreover, we show the synergy between ours and\nexisting hardware and system-level defenses.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-02T17:42:31Z"}
{"aid":"http://arxiv.org/abs/2504.01940v1","title":"Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and\n  Communication Towards 6G","summary":"This paper presents field-tested use cases from Search and Rescue (SAR)\nmissions, highlighting the co-design of mobile robots and communication systems\nto support Edge-Cloud architectures based on 5G Standalone (SA). The main goal\nis to contribute to the effective cooperation of multiple robots and first\nresponders. Our field experience includes the development of Hybrid Wireless\nSensor Networks (H-WSNs) for risk and victim detection, smartphones integrated\ninto the Robot Operating System (ROS) as Edge devices for mission requests and\npath planning, real-time Simultaneous Localization and Mapping (SLAM) via\nMulti-Access Edge Computing (MEC), and implementation of Uncrewed Ground\nVehicles (UGVs) for victim evacuation in different navigation modes. These\nexperiments, conducted in collaboration with actual first responders,\nunderscore the need for intelligent network resource management, balancing\nlow-latency and high-bandwidth demands. Network slicing is key to ensuring\ncritical emergency services are performed despite challenging communication\nconditions. The paper identifies architectural needs, lessons learned, and\nchallenges to be addressed by 6G technologies to enhance emergency response\ncapabilities.","main_category":"cs.RO","categories":"cs.RO,cs.NI","published":"2025-04-02T17:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.01943v1","title":"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding","summary":"Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T17:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.01958v1","title":"Individual halo bias in models of $f(R)$ gravity","summary":"Halo bias links the statistical properties of the spatial distribution of\ndark matter halos to those of the underlying dark matter field, providing\ninsights into clustering properties in both general relativity (GR) and\nmodified-gravity scenarios such as $f(R)$ models. While the primary halo\nmass-dependent bias has been studied in detailed, the secondary bias, which\naccounts for the additional dependencies on other internal halo properties, can\noffer a sensitive probe for testing gravity beyond the $\\Lambda$CDM model. To\nquantify any potential deviations between $\\Lambda$CDM and $f(R)$ gravity\nmodels in halo clustering, at both the primary and secondary level, as well as\nin the distributions of halo properties in the cosmic web. Using $N$-body\nsimulations of $f(R)$ gravity models, we assess the scaling relations and the\nprimary and secondary bias signals of halo populations on the basis of a\nhalo-by-halo estimator of large-scale effective bias. Our analysis is performed\nusing halo number density as the independent variable. The relative difference\nin the effective bias between the $f(R)$ models and $\\Lambda$CDM is sensitive,\nalbeit slightly, to the power index of modified gravity. The largest deviations\nfrom GR are measured for low-mass halos, where the average bias at fixed number\ndensity decreases by up to 5\\% for fixed scaling indices. We also show that the\nscaling relations for some environmental properties, including neighbour\nstatistics, Mach number and local overdensity, exhibit small but non-negligible\ndeviations (~3-5\\%) from GR for a wide range of number densities. Our results\nalso suggests that the properties of halos in sheets and voids show the largest\ndepartures from GR (> 10\\% in some cases). In terms of secondary bias, we do\nnot find any statistically significant deviations with respect to $\\Lambda$CDM\nfor any of the properties explored in this work.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T17:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02222v1","title":"APSeg: Auto-Prompt Model with Acquired and Injected Knowledge for\n  Nuclear Instance Segmentation and Classification","summary":"Nuclear instance segmentation and classification provide critical\nquantitative foundations for digital pathology diagnosis. With the advent of\nthe foundational Segment Anything Model (SAM), the accuracy and efficiency of\nnuclear segmentation have improved significantly. However, SAM imposes a strong\nreliance on precise prompts, and its class-agnostic design renders its\nclassification results entirely dependent on the provided prompts. Therefore,\nwe focus on generating prompts with more accurate localization and\nclassification and propose \\textbf{APSeg}, \\textbf{A}uto-\\textbf{P}rompt model\nwith acquired and injected knowledge for nuclear instance \\textbf{Seg}mentation\nand classification. APSeg incorporates two knowledge-aware modules: (1)\nDistribution-Guided Proposal Offset Module (\\textbf{DG-POM}), which learns\ndistribution knowledge through density map guided, and (2) Category Knowledge\nSemantic Injection Module (\\textbf{CK-SIM}), which injects morphological\nknowledge derived from category descriptions. We conducted extensive\nexperiments on the PanNuke and CoNSeP datasets, demonstrating the effectiveness\nof our approach. The code will be released upon acceptance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T02:28:51Z"}
{"aid":"http://arxiv.org/abs/2504.02228v1","title":"Stochastic positivity-preserving symplectic splitting methods for\n  stochastic Lotka--Volterra predator-prey model","summary":"In this paper, we present two stochastic positive-preserving symplectic\nmethods for the stochastic Lotka-Volterra predator-prey model driven by a\nmultiplicative noise. To inherit the intrinsic characteristic of the original\nsystem, the stochastic Lie--Trotter splitting method and the stochastic Strang\nsplitting method are introduced, which are proved to preserve the positivity of\nthe numerical solution and possess the discrete stochastic symplectic\nconservation law as well. By deriving the uniform boundedness of the $p$-th\nmoment of the numerical solution, we prove that the strong convergence orders\nof these two methods are both one in the $L^2(\\Omega)$-norm. Finally, we\nvalidate the theoretical results through two and four dimensional numerical\nexamples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T02:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.02231v1","title":"AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image\n  Generation","summary":"Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T02:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.02240v1","title":"Measurement of charged hadron multiplicity in Au+Au collisions at\n  $\\sqrt{\\text{s}_{\\text{NN}}} = 200$ GeV with the sPHENIX detector","summary":"The pseudorapidity distribution of charged hadrons produced in Au+Au\ncollisions at a center-of-mass energy of $\\sqrt{s_\\mathrm{NN}} = 200$ GeV is\nmeasured using data collected by the sPHENIX detector. Charged hadron yields\nare extracted by counting cluster pairs in the inner and outer layers of the\nIntermediate Silicon Tracker, with corrections applied for detector acceptance,\nreconstruction efficiency, combinatorial pairs, and contributions from\nsecondary decays. The measured distributions cover $|\\eta| < 1.1$ across\nvarious centralities, and the average pseudorapidity density of charged hadrons\nat mid-rapidity is compared to predictions from Monte Carlo heavy-ion event\ngenerators. This result, featuring full azimuthal coverage at mid-rapidity, is\nconsistent with previous experimental measurements at the Relativistic Heavy\nIon Collider, thereby supporting the broader sPHENIX physics program.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-03T03:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.02242v1","title":"Measurement of the transverse energy density in Au+Au collisions at\n  $\\sqrt{s_{NN}} = 200$ GeV with the sPHENIX detector","summary":"This paper reports measurements of the transverse energy per unit\npseudorapidity ($dE_{T}/d\\eta$) produced in Au+Au collisions at $\\sqrt{s_{NN}}\n= 200$ GeV, performed with the sPHENIX detector at the Relativistic Heavy Ion\nCollider (RHIC). The results cover the pseudorapidity range $\\left|\\eta\\right|\n< 1.1$ and constitute the first such measurement performed using a hadronic\ncalorimeter at RHIC. Measurements of $dE_{T}/d\\eta$ are presented for a range\nof centrality intervals and the average $dE_{T}/d\\eta$ as a function of the\nnumber of participating nucleons, $N_{\\mathrm{part}}$, is compared to a variety\nof Monte Carlo heavy-ion event generators. The results are in agreement with\nprevious measurements at RHIC, and feature an improved granularity in $\\eta$\nand improved precision in low-$N_{\\mathrm{part}}$ events.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-03T03:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.02245v1","title":"Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and\n  Low-Rank Tensor Optimization","summary":"Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-03T03:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02283v1","title":"Ga$_2$O$_3$ TCAD Mobility Parameter Calibration using Simulation\n  Augmented Machine Learning with Physics Informed Neural Network","summary":"In this paper, we demonstrate the possibility of performing automatic\nTechnology Computer-Aided-Design (TCAD) parameter calibration using machine\nlearning, verified with experimental data. The machine only needs to be trained\nby TCAD data. Schottky Barrier Diode (SBD) fabricated with emerging\nultra-wide-bandgap material, Gallium Oxide (Ga$_2$O$_3$), is measured and its\ncurrent-voltage (IV) is used for Ga$_2$O$_3$ Philips Unified Mobility (PhuMob)\nmodel parameters, effective anode workfunction, and ambient temperature\nextraction (7 parameters). A machine comprised of an autoencoder (AE) and a\nneural network (NN) (AE-NN) is used. Ga$_2$O$_3$ PhuMob parameters are\nextracted from the noisy experimental curves. TCAD simulation with the\nextracted parameters shows that the quality of the parameters is as good as an\nexpert's calibration at the pre-turned-on regime but not in the on-state\nregime. By using a simple physics-informed neural network (PINN) (AE-PINN), the\nmachine performs as well as the human expert in all regimes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T05:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.02307v1","title":"Solving adhesive rough contact problems with Atomic Force Microscope\n  data","summary":"This study presents an advanced numerical framework that integrates\nexperimentally acquired Atomic Force Microscope (AFM) data into high-fidelity\nsimulations for adhesive rough contact problems, bridging the gap between\nexperimental physics and computational mechanics. The proposed approach extends\nthe eMbedded Profile for Joint Roughness (MPJR) interface finite element method\nto incorporate both surface topography and spatially varying adhesion\nproperties, imported directly from AFM measurements. The adhesion behavior is\nmodeled using a modified Lennard-Jones potential, which is locally\nparameterized based on the AFM-extracted adhesion peak force and energy\ndissipation data. The effectiveness of this method is demonstrated through 2D\nand 3D finite element simulations of a heterogeneous PS-LDPE (polystyrene\nmatrix with low-density polyethylene inclusions) sample, where the bulk elastic\nproperties are also experimentally characterized via AFM. The results highlight\nthe significance of accounting for both surface adhesion variability and\nmaterial bulk heterogeneity in accurately predicting contact responses.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T06:32:06Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02320v1","title":"$β$-decay properties of some astrophysically important Sc-isotopes","summary":"In the late progressive stages of heavy stars, electron capture and\n$\\beta^\\pm$-decay are the governing processes. The weak rates are essential\ninputs for modeling the stages of high-mass stars before supernova explosions.\nAs per results obtained from previous simulations, weak rates of Scandium\nisotopes contribute substantially in changing the lepton-to-baryon ratio\n($Y_e$) of the nuclear matter in the core. In the present analysis, we report\nimportant $\\beta^-$-decay properties of crucial Sc isotopes in an astrophysical\nenvironment with mass numbers $49 \\leq A \\leq 54$. The investigation includes\nGamow-Teller (GT) strength distributions, terrestrial half-lives, and stellar\nrates of electron capture (EC) and $\\beta^-$-decay reactions. The calculations\nare performed using the proton-neutron (pn) quasi-particle random phase\napproximation (QRPA) model over a wide temperature range ($10^7$-$3 \\times\n10^{10}$ K) and density range ($10^1 - 10^{11}$ g/cm$^3$). Additionally, we\ncompare our calculated results with available experimental and theoretical\ndata. A good agreement is observed between our calculated half-lives and\nexperimentally measured values. Our weak $\\beta^-$-decay and EC rates are\ncompared with those from the Independent-Particle Model (IPM) and Large-Scale\nShell Model (LSSM). At high stellar temperatures and densities, our calculated\n$\\beta^-$-decay rates are smaller than those from the other models.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.02325v1","title":"Surgeries between lens spaces of type $L(n,1)$ and the Heegaard Floer\n  $d$-invariant","summary":"We establish a $d$-invariant surgery formula for $L$-space knots that\nprovides an effective tool for studying surgeries between lens spaces. Using\nthis formula, we classify distance one surgeries between lens spaces of the\nform $L(n,1)$. This classification has direct applications to band surgeries\nbetween torus links $T(2,n)$, with connections to DNA topology. In particular,\nwe show that chirally cosmetic banding of torus links can possibly occur only\nwhen $n=1,5,9$ or $10$.","main_category":"math.GT","categories":"math.GT","published":"2025-04-03T06:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.02337v1","title":"LPA3D: 3D Room-Level Scene Generation from In-the-Wild Images","summary":"Generating realistic, room-level indoor scenes with semantically plausible\nand detailed appearances from in-the-wild images is crucial for various\napplications in VR, AR, and robotics. The success of NeRF-based generative\nmethods indicates a promising direction to address this challenge. However,\nunlike their success at the object level, existing scene-level generative\nmethods require additional information, such as multiple views, depth images,\nor semantic guidance, rather than relying solely on RGB images. This is because\nNeRF-based methods necessitate prior knowledge of camera poses, which is\nchallenging to approximate for indoor scenes due to the complexity of defining\nalignment and the difficulty of globally estimating poses from a single image,\ngiven the unseen parts behind the camera. To address this challenge, we\nredefine global poses within the framework of Local-Pose-Alignment (LPA) -- an\nanchor-based multi-local-coordinate system that uses a selected number of\nanchors as the roots of these coordinates. Building on this foundation, we\nintroduce LPA-GAN, a novel NeRF-based generative approach that incorporates\nspecific modifications to estimate the priors of camera poses under LPA. It\nalso co-optimizes the pose predictor and scene generation processes. Our\nablation study and comparisons with straightforward extensions of NeRF-based\nobject generative methods demonstrate the effectiveness of our approach.\nFurthermore, visual comparisons with other techniques reveal that our method\nachieves superior view-to-view consistency and semantic normality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02366v1","title":"Non-Koszulness in a family of properads","summary":"Proving Koszulness of a properad can be very hard, but sometimes one can look\nat its Koszul complex to look for obstructions for Koszulness. In this paper,\nwe present a method and tools to prove non-Koszulness of many properads in a\nfamily of quadratic properads. We illustrate this method on a family of\nassociative and coassociative properads with one quadratic compatibility\nrelation.","main_category":"math.AT","categories":"math.AT","published":"2025-04-03T07:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.02373v1","title":"HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image\n  Enhancement","summary":"In practical applications, conventional methods generate large volumes of\nlow-light images that require compression for efficient storage and\ntransmission. However, most existing methods either disregard the removal of\npotential compression artifacts during the enhancement process or fail to\nestablish a unified framework for joint task enhancement of images with varying\ncompression qualities. To solve this problem, we propose the hybrid\npriors-guided network (HPGN), which enhances compressed low-light images by\nintegrating both compression and illumination priors. Our approach fully\nutilizes the JPEG quality factor (QF) and DCT quantization matrix (QM) to guide\nthe design of efficient joint task plug-and-play modules. Additionally, we\nemploy a random QF generation strategy to guide model training, enabling a\nsingle model to enhance images across different compression levels.\nExperimental results confirm the superiority of our proposed method.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T08:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.02390v1","title":"Flag Hardy spaces and partial differential equations","summary":"After a quick introduction to flag geometry on the Heisenberg group, we\ndiscuss the problem of identifying flag atoms, which boils down to a question\nin PDE. We establish a conjecture of E.M.~Stein for the flag Hardy space on the\nHeisenberg group. The key result on which our arguments hinge is due to Baldi,\nFranchi and Pansu.","main_category":"math.CA","categories":"math.CA","published":"2025-04-03T08:31:34Z"}
{"aid":"http://arxiv.org/abs/2504.02402v1","title":"EvMic: Event-based Non-contact sound recovery from effective\n  spatial-temporal modeling","summary":"When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-03T08:51:17Z"}
{"aid":"http://arxiv.org/abs/2504.02419v1","title":"Numerical simulations of the pressure-driven flow of pairs of rigid\n  spheres in elastoviscoplastic fluids","summary":"We investigate through numerical simulations the hydrodynamic interactions\nbetween two rigid spherical particles suspended on the axis of a cylindrical\ntube filled with an elastoviscoplastic fluid subjected to pressure-driven flow.\nThe simulations are performed by the finite element method with the arbitrary\nLagrangian-Eulerian formulation. We carry out a parametric analysis to examine\nthe impact of the yield stress and relaxation time of the fluid and of particle\nconfinement on the dynamics of the system. We identify master curves of the\nparticle relative velocity as a function of the inter-particle distance. When\nthe yield stress of the suspending phase is much lower than the viscous stress,\nthose curves highlight short-range attractive interactions and long-range\nrepulsive interactions between particles, with the latter specifically\npromoting their alignment. As the yield stress increases, the attractive\ninteraction is replaced by stasis at short distance, characterized by a\nvanishing relative velocity and the formation of an unyielded region that\nconnects the two spheres, where the fluid behaves like a viscoelastic solid.\nAdditionally, the combined effects of plasticity and elasticity enhance the\nrepulsion between the particles, promoting their ordering. Also increasing the\nconfinement of the particles enhances repulsion, thus allowing to achieve\nordering within shorter lengths in the flow direction. Reducing shear thinning\namplifies peak relative velocities and expands the attractive region due to\nincreased viscoelastic stresses and stress gradients. While a stable\nequilibrium may appear at larger separations, its impact is limited by low\nrelative velocities.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T09:20:24Z"}
{"aid":"http://arxiv.org/abs/2504.02423v1","title":"Quantum effects in piezoelectric semiconductor plasmas : Solitons and\n  transmission feasibility","summary":"A study of the coupling between lattice ion vibrations and electron waves in\na piezoelectric semiconductor quantum plasma is presented. The nonlinearities\nhave been analyzed, and solitons have been studied. The theory is built using\nthe quantum hydrodynamic (QHD) model, incorporating the effects of Fermi\npressure, quantum Bohm potential, and exchange-correlation potentials. The\ndispersion relation for the coupling is established. A set of nonlinear\nevolution equations has been derived using the two-time scale theory, and a\nsoliton solution for the coupled nonlinear evolution equations is obtained\nusing the modified quantum Zakharov equations. The solitons are found to have a\ncusp profile. It is also found that the solitons' field amplitude increases\nsignificantly with particle density and coupling strength in piezoelectric\nsemiconductor quantum plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T09:24:38Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02436v1","title":"SkyReels-A2: Compose Anything in Video Diffusion Transformers","summary":"This paper presents SkyReels-A2, a controllable video generation framework\ncapable of assembling arbitrary visual elements (e.g., characters, objects,\nbackgrounds) into synthesized videos based on textual prompts while maintaining\nstrict consistency with reference images for each element. We term this task\nelements-to-video (E2V), whose primary challenges lie in preserving the\nfidelity of each reference element, ensuring coherent composition of the scene,\nand achieving natural outputs. To address these, we first design a\ncomprehensive data pipeline to construct prompt-reference-video triplets for\nmodel training. Next, we propose a novel image-text joint embedding model to\ninject multi-element representations into the generative process, balancing\nelement-specific consistency with global coherence and text alignment. We also\noptimize the inference pipeline for both speed and output stability. Moreover,\nwe introduce a carefully curated benchmark for systematic evaluation, i.e, A2\nBench. Experiments demonstrate that our framework can generate diverse,\nhigh-quality videos with precise element control. SkyReels-A2 is the first\nopen-source commercial grade model for the generation of E2V, performing\nfavorably against advanced closed-source commercial models. We anticipate\nSkyReels-A2 will advance creative applications such as drama and virtual\ne-commerce, pushing the boundaries of controllable video generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:50:50Z"}
{"aid":"http://arxiv.org/abs/2504.02439v1","title":"Estimating Scene Flow in Robot Surroundings with Distributed\n  Miniaturized Time-of-Flight Sensors","summary":"Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T09:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.02441v1","title":"Cognitive Memory in Large Language Models","summary":"This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.02449v1","title":"Strongly regular graphs with parameters (85,14,3,2) do not exist","summary":"We investigate the second smallest unresolved feasible set of parameters of\nstrongly regular graphs, $(v,k,\\lambda,\\mu)=(85,14,3,2)$. Using the\nclassification of cubic graphs of small degree, we restrict possible local\nstructure of such a graph $G$. After that, we exhaustively enumerate possible\nneighbourhoods of a maximal $3$-clique of $G$ and check them against a variety\nof conditions, including the combinatorial ones, coming from $\\lambda=3$ and\n$\\mu=2$, as well as the linear algebra ones, utilising the Euclidean\nrepresentation of $G$. These conditions yield contradiction in all cases, and\nhence, no $\\mathrm{srg}(85,14,3,2)$ exists.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T10:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02458v1","title":"Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation","summary":"Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-03T10:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.02468v1","title":"Enhancing Compton telescope imaging with maximum a posteriori\n  estimation: a modified Richardson-Lucy algorithm for the Compton Spectrometer\n  and Imager","summary":"We present a modified Richardson-Lucy (RL) algorithm tailored for image\nreconstruction in MeV gamma-ray observations, focusing on its application to\nthe upcoming Compton Spectrometer and Imager (COSI) mission. Our method\naddresses key challenges in MeV gamma-ray astronomy by incorporating Bayesian\npriors for sparseness and smoothness while optimizing background components\nsimultaneously. We introduce a novel sparsity term suitable for Poisson-sampled\ndata in addition to a smoothness prior, allowing for flexible reconstruction of\nboth point sources and extended emission. The performance of the algorithm is\nevaluated using simulated three-month COSI observations of gamma-ray lines of\n$^{44}$Ti (1.157 MeV), $^{26}$Al (1.809 MeV), and positron annihilation (0.511\nMeV), respectively, representing various spatial features. Our results\ndemonstrate significant improvements over conventional RL methods, particularly\nin suppressing artificial structures in point source reconstructions and\nretaining diffuse spatial structures. This work represents an important step\ntowards establishing a robust data analysis for studying nucleosynthesis,\npositron annihilation, and other high-energy phenomena in our Galaxy.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.HE","published":"2025-04-03T10:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.02477v1","title":"Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision","summary":"Robot vision has greatly benefited from advancements in multimodal fusion\ntechniques and vision-language models (VLMs). We systematically review the\napplications of multimodal fusion in key robotic vision tasks, including\nsemantic scene understanding, simultaneous localization and mapping (SLAM), 3D\nobject detection, navigation and localization, and robot manipulation. We\ncompare VLMs based on large language models (LLMs) with traditional multimodal\nfusion methods, analyzing their advantages, limitations, and synergies.\nAdditionally, we conduct an in-depth analysis of commonly used datasets,\nevaluating their applicability and challenges in real-world robotic scenarios.\nFurthermore, we identify critical research challenges such as cross-modal\nalignment, efficient fusion strategies, real-time deployment, and domain\nadaptation, and propose future research directions, including self-supervised\nlearning for robust multimodal representations, transformer-based fusion\narchitectures, and scalable multimodal frameworks. Through a comprehensive\nreview, comparative analysis, and forward-looking discussion, we provide a\nvaluable reference for advancing multimodal perception and interaction in\nrobotic vision. A comprehensive list of studies in this survey is available at\nhttps://github.com/Xiaofeng-Han-Res/MF-RV.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.02493v1","title":"On zero-divisor graph of the ring of Gaussian integers modulo $2^n$","summary":"For a commutative ring $R$, the zero-divisor graph of $R$ is a simple graph\nwith the vertex set as the set of all zero-divisors of $R$ and two distinct\nvertices $x$ and $y$ are adjacent if and only if $xy = 0$. This article\nattempts to predict the structure of the zero-divisor graph of the ring of\nGaussian integers modulo $2$ to the power $n$ and determine the size, chromatic\nnumber, clique number, independence number, and matching through associate\nclasses of divisors of $2^n$ in $\\mathbb{Z}_{2^n}[i]$. In addition, a few\ntopological indices of the corresponding zero-divisor graph, are obtained.","main_category":"math.AC","categories":"math.AC,math.CO,math.NT","published":"2025-04-03T11:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02503v1","title":"Direction switchable single-photon emitter using a Rydberg polariton","summary":"All-optical redirection or routing of single photons is essential for quantum\nnetworks. Although studied in various systems both in theory and experiment,\nthe redirection of single photons with many output ports, compatible with\nlarge-scale photonic circuits, still needs to be explored. Here, we demonstrate\na direction switchable single-photon emitter using a Rydberg polariton. The\nRydberg component of the stored photon is changed using a stimulated Raman\ntransition with a specific intermediate state. By adjusting the direction of\nthe retrieval laser, we can redirect the emitted photon into a rich variety of\nalternative modes. Building upon this scheme, we propose a quantum routing of\nsingle photons with \\textit{N} output channels and unity routing efficiency. In\naddition, the protocol reduces the effect of motional dephasing increasing the\nphoton lifetime to $>10~\\mu$s ($>20$ times photon processing time), enabling\nfunctional quantum devices based on Rydberg polaritons.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T11:35:36Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02507v1","title":"ZClip: Adaptive Spike Mitigation for LLM Pre-Training","summary":"Training large language models (LLMs) presents numerous challenges, including\ngradient instability and loss spikes. These phenomena can lead to catastrophic\ndivergence, requiring costly checkpoint restoration and data batch skipping.\nTraditional gradient clipping techniques, such as constant or norm-based\nmethods, fail to address these issues effectively due to their reliance on\nfixed thresholds or heuristics, leading to inefficient learning and requiring\nfrequent manual intervention. In this work, we propose ZClip, an adaptive\ngradient clipping algorithm that dynamically adjusts the clipping threshold\nbased on statistical properties of gradient norms over time. Unlike prior\nreactive strategies, ZClip proactively adapts to training dynamics without\nmaking any prior assumptions on the scale and the temporal evolution of\ngradient norms. At its core, it leverages z-score-based anomaly detection to\nidentify and mitigate large gradient spikes, preventing malignant loss spikes\nwhile not interfering with convergence otherwise. Our code is available at:\nhttps://github.com/bluorion-com/ZClip.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T11:41:55Z"}
{"aid":"http://arxiv.org/abs/2504.02532v1","title":"Polynomial Bounds for the Graph Minor Structure Theorem","summary":"The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T12:35:45Z"}
{"aid":"http://arxiv.org/abs/2504.02533v1","title":"ARCANE: Adaptive RISC-V Cache Architecture for Near-memory Extensions","summary":"Modern data-driven applications expose limitations of von Neumann\narchitectures - extensive data movement, low throughput, and poor energy\nefficiency. Accelerators improve performance but lack flexibility and require\ndata transfers. Existing compute in- and near-memory solutions mitigate these\nissues but face usability challenges due to data placement constraints. We\npropose a novel cache architecture that doubles as a tightly-coupled\ncompute-near-memory coprocessor. Our \\riscv cache controller executes custom\ninstructions from the host CPU using vector operations dispatched to\nnear-memory vector processing units within the cache memory subsystem. This\narchitecture abstracts memory synchronization and data mapping from application\nsoftware while offering software-based \\isa extensibility. Our implementation\nshows $30\\times$ to $84\\times$ performance improvement when operating on 8-bit\ndata over the same system with a traditional cache when executing a worst-case\n32-bit CNN workload, with only $41.3\\%$ area overhead.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-03T12:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.02541v1","title":"$Λ$CDM from broken diffeomorphisms","summary":"We present a simple field theory model with reduced invariance under\ndiffeomorphisms whose energy-momentum tensor is identical to the sum of\npressureless irrotational matter and a cosmological constant. The model action\nis built from a single scalar field with a canonical kinetic term without any\npotential or Lagrange multiplier terms. The coupling to gravity is realized\nthrough a particular transverse diffeomorphism invariant volume element. The\ncorresponding sound speed is exactly zero in any background geometry and the\nmodel is dynamically identical to $\\Lambda$CDM. By restoring the full\ndiffeomorphism invariance through the introduction of Stueckelberg-like fields,\nwe obtain an equivalent local scalar-vector theory.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-03T12:43:15Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02566v1","title":"Local Flow Estimation at the top of the Earth's Core using Physics\n  Informed Neural Networks","summary":"The Earth's main geomagnetic field arises from the constant motion of the\nfluid outer core. By assuming that the field changes are advection-dominated,\nthe fluid motion at the core surface can be related to the secular variation of\nthe geomagnetic field. The majority of existing core flow models are global,\nshowing features such as an eccentric planetary gyre, with some evidence of\nrapid regional changes. By construction, the flow defined at any location by\nsuch a model depends on all magnetic field variations across the entire\ncore-mantle boundary making it challenging to interpret local structures in the\nflow as due to specific local changes in magnetic field. Here we present an\nalternative strategy in which we construct regional flow models that rely only\non local secular changes. We use a novel technique based on machine learning\ntermed Physics-Informed Neural Networks (PINNs), in which we seek a regional\nflow model that simultaneously fits both the local magnetic field variation and\ndynamical conditions assumed satisfied by the flow. Although we present results\nusing the Tangentially Geostrophic flow constraint, we set out a modelling\nframework for which the physics constraint can be easily changed by altering a\nsingle line of code. After validating the PINN-based method on synthetic flows,\nwe apply our method to the CHAOS-8.1 geomagnetic field model, itself based on\ndata from Swarm. Constructing a global mosaic of regional flows, we reproduce\nthe planetary gyre, providing independent evidence that the strong secular\nchanges at high latitude and in equatorial regions are part of the same global\nfeature. Our models also corroborate regional changes in core flows over the\nlast decade. Furthermore, our models endorse the existence of a dynamic high\nlatitude jet, which began accelerating around 2005 but has been weakening since\n2017.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-03T13:27:45Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02576v1","title":"Derivation of the Landau-Zener formula via functional equations","summary":"The Landau-Zener formula describes the diabatic transition probability of a\ntwo-level system under linear driving. Its rigorous derivation typically relies\non sophisticated mathematical tools, such as special functions, Laplace\ntransforms, or contour integrals. In this work, we present a derivation of the\nLandau-Zener transition probability using a fundamentally different approach\nvia functional equations. By leveraging integrability, we prove that this\ntransition probability satisfies a functional equation, whose solutions\nestablish the exponential form of the formula. The coefficient in the exponent\nis then determined through a lowest-order perturbation calculation. This\nderivation is rigorous and mathematically simple. Our work provides new insight\ninto the origin of the exponential form of the Landau-Zener transition\nprobability.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.SI","published":"2025-04-03T13:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"Ramírez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02614v1","title":"Single-Particle Dispersion and Density of States of the Half-Filled 2D\n  Hubbard Model","summary":"Implementing an improved method for analytic continuation and working with\nimaginary-time correlation functions computed using quantum Monte Carlo\nsimulations, we resolve the single-particle dispersion relation and the density\nof states (DOS) of the two-dimensional Hubbard model at half-filling. At\nintermediate interactions of $U/t = 4,6$, we find quadratic dispersion around\nthe gap minimum at wave-vectors $\\mathbf{k} = (\\pm \\pi/2, \\pm \\pi/2)$ (the\n$\\Sigma$ points). We find saddle points at $\\mathbf{k} = (\\pm \\pi,0),(0,\\pm\n\\pi)$ (the X points) where the dispersion is quartic, leading to a sharp DOS\nmaximum above the almost flat ledge arising from the states close to $\\Sigma$.\nThe fraction of quasi-particle states within the ledge is $n_{\\rm ledge}\n\\approx 0.15$. Upon doping, within the rigid-band approximation, these results\nsupport Fermi pockets around the $\\Sigma$ points, with states around the X\npoints becoming filled only at doping fractions $x \\ge n_{\\rm ledge}$. The high\ndensity of states and the associated onset of $(\\pi,\\pi)$ scattering may be an\nimportant clue for a finite minimum doping level for superconductivity in the\ncuprates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-03T14:13:57Z"}
{"aid":"http://arxiv.org/abs/2504.02618v1","title":"Variational Online Mirror Descent for Robust Learning in Schrödinger\n  Bridge","summary":"Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\ngenerative models. In practice, however, estimated learning signals are often\nuncertain, and the reliability promised by existing methods is often based on\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\nalgorithm through mirror descent (MD) have gained attention, revealing\ngeometric insights into solution acquisition of the SB problems. In this paper,\nwe propose a variational online MD (OMD) framework for the SB problems, which\nprovides further stability to SB solvers. We formally prove convergence and a\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\npropose a simulation-free SB algorithm called Variational Mirrored\nSchr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\nthe Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\ndynamics that precisely approximate each OMD step. In experiments, we validate\nthe performance of the proposed VMSB algorithm across an extensive suite of\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\nSB problems, demonstrating the robustness predicted by our theory.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T14:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.02619v1","title":"Existence of solutions for time-dependent Signorini problems in\n  linearised viscoelasticity","summary":"In this paper, we establish the existence of solutions for time-dependent\nlinearly viscoelastic bodies confined to a specified half-space. The\nconfinement condition under consideration is of Signorini type, and is given\nover the boundary of the linearly viscoelastic body under consideration. In\norder to derive a suitable notion of solution that possesses a sufficient\ndegree of regularity, we introduce the concept of ``admissible'' applied body\nforce. In agreement with expectations, the variational problem that solutions\nmust satisfy is a system of hyperbolic variational inequalities, and the\ndisplacement acceleration is a vector-valued measure in the sense of\nDinculeanu.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T14:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.02622v1","title":"Exploring undercurrents of learning tensions in an LLM-enhanced\n  landscape: A student-centered qualitative perspective on LLM vs Search","summary":"Large language models (LLMs) are transforming how students learn by providing\nreadily available tools that can quickly augment or complete various learning\nactivities with non-trivial performance. Similar paradigm shifts have occurred\nin the past with the introduction of search engines and Wikipedia, which\nreplaced or supplemented traditional information sources such as libraries and\nbooks. This study investigates the potential for LLMs to represent the next\nshift in learning, focusing on their role in information discovery and\nsynthesis compared to existing technologies, such as search engines. Using a\nwithin-subjects, counterbalanced design, participants learned new topics using\na search engine (Google) and an LLM (ChatGPT). Post-task follow-up interviews\nexplored students' reflections, preferences, pain points, and overall\nperceptions. We present analysis of their responses that show nuanced insights\ninto when, why, and how students prefer LLMs over search engines, offering\nimplications for educators, policymakers, and technology developers navigating\nthe evolving educational landscape.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02672v1","title":"Certified Model Order Reduction for parametric Hermitian eigenproblems","summary":"This article deals with the efficient and certified numerical approximation\nof the smallest eigenvalue and the associated eigenspace of a large-scale\nparametric Hermitian matrix. For this aim, we rely on projection-based model\norder reduction (MOR), i.e., we approximate the large-scale problem by\nprojecting it onto a suitable subspace and reducing it to one of a much smaller\ndimension. Such a subspace is constructed by means of weak greedy-type\nstrategies. After detailing the connections with the reduced basis method for\nsource problems, we introduce a novel error estimate for the approximation\nerror related to the eigenspace associated with the smallest eigenvalue. Since\nthe difference between the second smallest and the smallest eigenvalue, the\nso-called spectral gap, is crucial for the reliability of the error estimate,\nwe propose efficiently computable upper and lower bounds for higher eigenvalues\nand for the spectral gap, which enable the assembly of a subspace for the MOR\napproximation of the spectral gap. Based on that, a second subspace is then\ngenerated for the MOR approximation of the eigenspace associated with the\nsmallest eigenvalue. We also provide efficiently computable conditions to\nensure that the multiplicity of the smallest eigenvalue is fully captured in\nthe reduced space. This work is motivated by a specific application: the\nrepeated identifications of the states with minimal energy, the so-called\nground states, of parametric quantum spin system models.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T15:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.02688v1","title":"Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication\n  using DRL","summary":"Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted\nnext-generation wireless networks is critical for mobility management and\nensuring UAV safety and ubiquitous connectivity, especially in dense urban\nenvironments with street canyons and tall buildings. Traditional statistical\nand model-based techniques have been successfully used for path optimization in\ncommunication networks. However, when dynamic channel propagation\ncharacteristics such as line-of-sight (LOS), interference, handover, and\nsignal-to-interference and noise ratio (SINR) are included in path\noptimization, statistical and model-based path planning solutions become\nobsolete since they cannot adapt to the dynamic and time-varying wireless\nchannels, especially in the mmWave bands. In this paper, we propose a novel\nmodel-free actor-critic deep reinforcement learning (AC-DRL) framework for path\noptimization in UAV-assisted 5G mmWave wireless networks, which combines four\nimportant aspects of UAV communication: \\textit{flight time, handover,\nconnectivity and SINR}. We train an AC-RL agent that enables a UAV connected to\na gNB to determine the optimal path to a desired destination in the shortest\npossible time with minimal gNB handover, while maintaining connectivity and the\nhighest possible SINR. We train our model with data from a powerful ray tracing\ntool called Wireless InSite, which uses 3D images of the propagation\nenvironment and provides data that closely resembles the real propagation\nenvironment. The simulation results show that our system has superior\nperformance in tracking high SINR compared to other selected RL algorithms.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-04-03T15:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.02695v1","title":"Mind the Gap? Not for SVP Hardness under ETH!","summary":"We prove new hardness results for fundamental lattice problems under the\nExponential Time Hypothesis (ETH). Building on a recent breakthrough by\nBitansky et al. [BHIRW24], who gave a polynomial-time reduction from\n$\\mathsf{3SAT}$ to the (gap) $\\mathsf{MAXLIN}$ problem-a class of CSPs with\nlinear equations over finite fields-we derive ETH-hardness for several lattice\nproblems.\n  First, we show that for any $p \\in [1, \\infty)$, there exists an explicit\nconstant $\\gamma > 1$ such that $\\mathsf{CVP}_{p,\\gamma}$ (the $\\ell_p$-norm\napproximate Closest Vector Problem) does not admit a $2^{o(n)}$-time algorithm\nunless ETH is false. Our reduction is deterministic and proceeds via a direct\nreduction from (gap) $\\mathsf{MAXLIN}$ to $\\mathsf{CVP}_{p,\\gamma}$.\n  Next, we prove a randomized ETH-hardness result for $\\mathsf{SVP}_{p,\\gamma}$\n(the $\\ell_p$-norm approximate Shortest Vector Problem) for all $p > 2$. This\nresult relies on a novel property of the integer lattice $\\mathbb{Z}^n$ in the\n$\\ell_p$ norm and a randomized reduction from $\\mathsf{CVP}_{p,\\gamma}$ to\n$\\mathsf{SVP}_{p,\\gamma'}$.\n  Finally, we improve over prior reductions from $\\mathsf{3SAT}$ to\n$\\mathsf{BDD}_{p, \\alpha}$ (the Bounded Distance Decoding problem), yielding\nbetter ETH-hardness results for $\\mathsf{BDD}_{p, \\alpha}$ for any $p \\in [1,\n\\infty)$ and $\\alpha > \\alpha_p^{\\ddagger}$, where $\\alpha_p^{\\ddagger}$ is an\nexplicit threshold depending on $p$.\n  We additionally observe that prior work implies ETH hardness for the gap\nminimum distance problem ($\\gamma$-$\\mathsf{MDP}$) in codes.","main_category":"cs.CC","categories":"cs.CC,cs.CR,cs.DS","published":"2025-04-03T15:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02711v1","title":"Anisotropy analysis of bamboo and tooth using 4-angle polarization\n  micro-spectroscopy","summary":"To investigate the anisotropic properties of biomaterials, two distinct\nclasses are considered: polymer-based (e.g., cellulose in plants) and\ncrystalline-based (e.g., enamel in teeth), each demonstrating distinct\nstructural and functional characteristics. Four-angle polarization (4-pol.)\nspectral mapping of sub-1 {\\mu}m bamboo slices was carried out in the mid-IR\nspectral range (2.5-20 {\\mu}m) to reveal the 3D organization of the chemical\nbonding of cellulose using the key characteristic absorption bands associated\nwith C-O-C and C-N vibrational modes. The longitudinal and transverse microtome\nslices revealed a switch between the presence and absence of dichroism in\nparenchyma cell walls and vascular bundles. The cell wall showed continuous\nalignment of the C-O-C stretching vibrational mode (8.6 {\\mu}m/1163 cm-1) down\nto the pixel resolution of ~ 4 {\\mu}m (the step size in imaging) in the\ntransverse slice; the cell wall thickness is ~ 1 {\\mu}m. Thin microtomed slices\nof a tooth were measured in transmission and reflection modes. The single-point\nreflection measurements, performed using two perpendicular orientations,\nrevealed orientational anisotropy in the enamel, which was absent in the dentin\nregion. High sub-diffraction limited lateral resolution was numerically\nvalidated using a simplified-model of a Gaussian beam reading out material\npixels with a defined orientation of absorption. It is shown that the\norientation of small ~ {\\lambda}/10 ~ 1 {\\mu}m objects can be revealed using a\nfocal spot of ~ {\\lambda}/NA ~ 20 {\\mu}m, defining the diffraction limit for\nthe objective lens with a numerical aperture NA ~ 0.5.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.med-ph","published":"2025-04-03T15:51:43Z"}
{"aid":"http://arxiv.org/abs/2504.02713v1","title":"Web3DB: Web 3.0 RDBMS for Individual Data Ownership","summary":"This paper introduces Web3DB, a decentralized relational database management\nsystem (RDBMS) designed to align with the principles of Web 3.0, addressing\ncritical shortcomings of traditional centralized DBMS, such as data privacy,\nsecurity vulnerabilities, and single points of failure. Several similar systems\nhave been proposed, but they are not compatible with the legacy systems based\non RDBMS. Motivated by the necessity for enhanced data sovereignty and the\ndecentralization of data control, Web3DB leverages blockchain technology for\nfine-grained access control and utilizes decentralized data storage. This\nsystem leverages a novel, modular architecture that contributes to enhanced\nflexibility, scalability, and user-centric functionality. Central to the Web3DB\ninnovation is its decentralized query execution, which uses cryptographic\nsortition and blockchain verification to ensure secure and fair query\nprocessing across network nodes. The motivation for integrating relational\ndatabases within decentralized DBMS primarily stems from the need to combine\nthe robustness and ease of use of relational database structures with the\nbenefits of decentralization. This paper outlines the architecture of Web3DB,\nits practical implementation, and the system's ability to support SQL-like\noperations on relational data, manage multi-tenancy, and facilitate open data\nsharing, setting new standards for decentralized databases in the Web 3.0 era.","main_category":"cs.DB","categories":"cs.DB,cs.DC","published":"2025-04-03T15:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02736v1","title":"Parity violation as enforced symmetry breaking in 3D fermionic\n  topological order","summary":"Symmetry can be intrinsically broken in topological phases due to inherent\nincompatibilities, a phenomenon known as enforced symmetry breaking (ESB) in\nthe framework of topological order. In our previous work, we developed a\nsystematic framework to understand ESB within 2D invertible topological order.\nMeanwhile, the origin of parity violation in the Standard Model remains one of\nthe most profound mysteries in physics, with no clear explanation to date. In\nthis study, we explore the ESB of parity symmetry by three-dimensional\nfermionic topological order (fTO), offering potential insights into the origins\nof parity violation. As the simplest example, here we consider an fTO related\nto the intrinsic interacting fermionic SPT phase protected by $Z_2^f\\times\nZ_2\\times Z_8$ symmetry in three dimensions. We show that time-reversal\nsymmetry (TRS) with ${T}^2=1$ on physical fermions is incompatible with such\nfTO; then, through the so-called crystalline equivalence principle, we show\nthat the parity symmetry is also incompatible with it. In comparison,\nconventional TRS with ${T}^2={P}_f$ remains compatible to this fTO. We also\ndiscuss a general framework to study the ESB phenomenon for 3D fTO.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-ph,hep-th","published":"2025-04-03T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02744v1","title":"The Ordering Principle and Dependent Choice","summary":"We introduce finite support iterations of symmetric systems, and use them to\nprovide a strongly modernized proof of David Pincus' classical result that the\naxiom of dependent choice is independent over ZF with the ordering principle\ntogether with a failure of the axiom of choice.","main_category":"math.LO","categories":"math.LO","published":"2025-04-03T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.02765v1","title":"Robot-Led Vision Language Model Wellbeing Assessment of Children","summary":"This study presents a novel robot-led approach to assessing children's mental\nwellbeing using a Vision Language Model (VLM). Inspired by the Child\nApperception Test (CAT), the social robot NAO presented children with pictorial\nstimuli to elicit their verbal narratives of the images, which were then\nevaluated by a VLM in accordance with CAT assessment guidelines. The VLM's\nassessments were systematically compared to those provided by a trained\npsychologist. The results reveal that while the VLM demonstrates moderate\nreliability in identifying cases with no wellbeing concerns, its ability to\naccurately classify assessments with clinical concern remains limited.\nMoreover, although the model's performance was generally consistent when\nprompted with varying demographic factors such as age and gender, a\nsignificantly higher false positive rate was observed for girls, indicating\npotential sensitivity to gender attribute. These findings highlight both the\npromise and the challenges of integrating VLMs into robot-led assessments of\nchildren's wellbeing.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-03T17:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.02770v1","title":"Efficient Algorithms for Cardinality Estimation and Conjunctive Query\n  Evaluation With Simple Degree Constraints","summary":"Cardinality estimation and conjunctive query evaluation are two of the most\nfundamental problems in database query processing. Recent work proposed,\nstudied, and implemented a robust and practical information-theoretic\ncardinality estimation framework. In this framework, the estimator is the\ncardinality upper bound of a conjunctive query subject to\n``degree-constraints'', which model a rich set of input data statistics. For\ngeneral degree constraints, computing this bound is computationally hard.\nResearchers have naturally sought efficiently computable relaxed upper bounds\nthat are as tight as possible. The polymatroid bound is the tightest among\nthose relaxed upper bounds. While it is an open question whether the\npolymatroid bound can be computed in polynomial-time in general, it is known to\nbe computable in polynomial-time for some classes of degree constraints.\n  Our focus is on a common class of degree constraints called simple degree\nconstraints. Researchers had not previously determined how to compute the\npolymatroid bound in polynomial time for this class of constraints. Our first\nmain result is a polynomial time algorithm to compute the polymatroid bound\ngiven simple degree constraints. Our second main result is a polynomial-time\nalgorithm to compute a ``proof sequence'' establishing this bound. This proof\nsequence can then be incorporated in the PANDA-framework to give a faster\nalgorithm to evaluate a conjunctive query. In addition, we show computational\nlimitations to extending our results to broader classes of degree constraints.\nFinally, our technique leads naturally to a new relaxed upper bound called the\n{\\em flow bound}, which is computationally tractable.","main_category":"cs.DB","categories":"cs.DB,cs.DS","published":"2025-04-03T17:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02790v1","title":"Dynamic Treewidth in Logarithmic Time","summary":"We present a dynamic data structure that maintains a tree decomposition of\nwidth at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is\nupdated by edge insertions and deletions. The amortized update time of our data\nstructure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data\nstructure also supports maintaining any ``dynamic programming scheme'' on the\ntree decomposition, providing, for example, a dynamic version of Courcelle's\ntheorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation\nhides factors that depend on $k$. This improves upon a result of Korhonen,\nMajewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar\ndata structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.\nFurthermore, our data structure is arguably simpler.\n  Our main novel idea is to maintain a tree decomposition that is ``downwards\nwell-linked'', which allows us to implement local rotations and analysis\nsimilar to those for splay trees.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-03T17:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02793v1","title":"A Framework for Situating Innovations, Opportunities, and Challenges in\n  Advancing Vertical Systems with Large AI Models","summary":"Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY,cs.HC","published":"2025-04-03T17:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.02794v1","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies\n  and Emotions","summary":"The need to improve geriatric care quality presents a challenge that requires\ninsights from stakeholders. While simulated trainings can boost competencies,\nextracting meaningful insights from these practices to enhance simulation\neffectiveness remains a challenge. In this study, we introduce Multimodal\nEpistemic Network Analysis (MENA), a novel framework for analyzing caregiver\nattitudes and emotions in an Augmented Reality setting and exploring how the\nawareness of a virtual geriatric patient (VGP) impacts these aspects. MENA\nenhances the capabilities of Epistemic Network Analysis by detecting positive\nemotions, enabling visualization and analysis of complex relationships between\ncaregiving competencies and emotions in dynamic caregiving practices. The\nframework provides visual representations that demonstrate how participants\nprovided more supportive care and engaged more effectively in person-centered\ncaregiving with aware VGP. This method could be applicable in any setting that\ndepends on dynamic interpersonal interactions, as it visualizes connections\nbetween key elements using network graphs and enables the direct comparison of\nmultiple networks, thereby broadening its implications across various fields.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T17:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.02808v1","title":"Quantum theory does not need complex numbers","summary":"The longstanding debate over whether quantum theory fundamentally requires\ncomplex numbers--or if their use is merely a convenient choice--has persisted\nfor decades. Until recently, this question was considered open. However, in\n[M.-O. Renou et al, Nature 600, 625-629, 2021], a decisive argument was\npresented asserting that quantum theory needs complex numbers. In this work, we\ndemonstrate that a formulation of quantum theory based solely on real numbers\nis indeed possible while retaining key features such as theory-representation\nlocality (i.e. local physical operations are represented by local changes to\nthe states) and the positive semi-definiteness of its states and effects. We\nobserve that the standard system combination rule--the tensor product--was\nderived after the development of single-system complex quantum theory. By\nstarting from a single-system quantum theory using only real numbers, we derive\na combination rule that produces a real quantum theory with properties\nanalogous to those of conventional complex quantum theory. We also prove that\nthe conventional tensor product rule can also lead to a real and\nrepresentation-local theory, albeit with a modified characterization of the\nstate space. We thus conclude that complex numbers are a mere convenience in\nquantum theory.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T17:53:19Z"}
{"aid":"http://arxiv.org/abs/2504.02811v1","title":"An Assessment of the CO2 Emission Reduction Potential of Residential\n  Load Management in Developing and Developed Countries","summary":"Intermittent renewable energies are increasingly dominating electricity grids\nand are forecasted to be the main force driving out fossil fuels from the grid\nin most major economies until 2040. However, grids based on intermittent\nrenewables are challenged by diurnal and seasonal mismatch between supply of\nsun and wind and demand for electricity, including for heat pumps and electric\ntwo and four wheelers. Load management and demand response measures promise to\nadjust for this mismatch, utilizing information- and price-based approaches to\nsteer demand towards times with high supply of intermittent renewables. Here,\nwe systematically review the literature estimating CO2 savings from residential\nload management in developing and developed nations. We find that load\nmanagement holds high potential, locally differentiated with energy mix\n(including the respective share of renewables and fossils), climate zone, and\nthe regulatory environment and price mechanism. Most identified studies suggest\na mitigation potential between 1 and 20%. Load management becomes more relevant\nwith higher shares of intermittent renewables, and when electricity prices are\nhigh. Importantly, load management aligns consumers' financial incentives with\nclimate change mitigation, thus rendering accompanying strategies politically\nfeasible. We summarize key regulatory steps to facilitate load management in\neconomies and to realize relevant consumer surplus and mitigation potential.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T17:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.02812v1","title":"BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose\n  Estimation","summary":"We present the evaluation methodology, datasets and results of the BOP\nChallenge 2024, the sixth in a series of public competitions organized to\ncapture the state of the art in 6D object pose estimation and related tasks. In\n2024, our goal was to transition BOP from lab-like setups to real-world\nscenarios. First, we introduced new model-free tasks, where no 3D object models\nare available and methods need to onboard objects just from provided reference\nvideos. Second, we defined a new, more practical 6D object detection task where\nidentities of objects visible in a test image are not provided as input. Third,\nwe introduced new BOP-H3 datasets recorded with high-resolution sensors and\nAR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D\nmodels and onboarding videos to support both model-based and model-free tasks.\nParticipants competed on seven challenge tracks, each defined by a task, object\nonboarding setup, and dataset group. Notably, the best 2024 method for\nmodel-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher\naccuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only\n4% behind the best 2023 method for seen objects (GPose2023) although being\nsignificantly slower (24.9 vs 2.7s per image). A more practical 2024 method for\nthis task is Co-op which takes only 0.8s per image and is 25X faster and 13%\nmore accurate than GenFlow. Methods have a similar ranking on 6D detection as\non 6D localization but higher run time. On model-based 2D detection of unseen\nobjects, the best 2024 method (MUSE) achieves 21% relative improvement compared\nto the best 2023 method (CNOS). However, the 2D detection accuracy for unseen\nobjects is still noticealy (-53%) behind the accuracy for seen objects\n(GDet2023). The online evaluation system stays open and is available at\nhttp://bop.felk.cvut.cz/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.02814v1","title":"Convergence of the Markovian iteration for coupled FBSDEs via a\n  differentiation approach","summary":"In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR,q-fin.CP","published":"2025-04-03T17:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.02818v1","title":"Universal Log-Optimality for General Classes of e-processes and\n  Sequential Hypothesis Tests","summary":"We consider the problem of sequential hypothesis testing by betting. For a\ngeneral class of composite testing problems -- which include bounded mean\ntesting, equal mean testing for bounded random tuples, and some key ingredients\nof two-sample and independence testing as special cases -- we show that any\n$e$-process satisfying a certain sublinear regret bound is adaptively,\nasymptotically, and almost surely log-optimal for a composite alternative. This\nis a strong notion of optimality that has not previously been established for\nthe aforementioned problems and we provide explicit test supermartingales and\n$e$-processes satisfying this notion in the more general case. Furthermore, we\nderive matching lower and upper bounds on the expected rejection time for the\nresulting sequential tests in all of these cases. The proofs of these results\nmake weak, algorithm-agnostic moment assumptions and rely on a general-purpose\nproof technique involving the aforementioned regret and a family of numeraire\nportfolios. Finally, we discuss how all of these theorems hold in a\ndistribution-uniform sense, a notion of log-optimality that is stronger still\nand seems to be new to the literature.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-04-03T17:58:10Z"}
{"aid":"http://arxiv.org/abs/2504.02824v1","title":"Observation of non-Hermitian dislocation bound states and dislocation\n  skin effects","summary":"The confluence of Non-Hermitian (NH) topology and crystal defects has\nculminated significant interest, yet its experimental exploration has been\nlimited due to the challenges involved in design and measurements. Here, we\nshowcase experimental observation of NH dislocation bound states (NHDS) and the\ndislocation-induced NH skin effect in two-dimensional acoustic NH Chern\nlattices. By embedding edge dislocations in such acoustic lattices and\nimplementing precision-controlled hopping and onsite gain/loss via active\nmeta-atoms, we reveal robust defect-bound states localized at dislocation cores\nwithin the line gap of the complex energy spectrum. These NHDS survive against\nmoderate NH perturbations but gradually delocalize and merge with the bulk\n(skin) states as the system arrives at the shore of fostering exceptional\npoints in the Brillouin zone under periodic (open) boundary conditions.\nFurthermore, our experiments demonstrate that the dislocation core can feature\nweak NH skin effects when its direction is perpendicular to the Burgers vector\nin periodic systems. Our findings pave an experimental pathway for probing NH\ntopology via lattice defects and open new avenues for defect-engineered\ntopological devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.class-ph,quant-ph","published":"2025-04-03T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.02826v1","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual\n  Editing","summary":"Large Multi-modality Models (LMMs) have made significant progress in visual\nunderstanding and generation, but they still face challenges in General Visual\nEditing, particularly in following complex instructions, preserving appearance\nconsistency, and supporting flexible input formats. To address this gap, we\nintroduce RISEBench, the first benchmark for evaluating Reasoning-Informed\nviSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal,\nCausal, Spatial, and Logical Reasoning. We curate high-quality test cases for\neach category and propose an evaluation framework that assesses Instruction\nReasoning, Appearance Consistency, and Visual Plausibility with both human\njudges and an LMM-as-a-judge approach. Our experiments reveal that while\nGPT-4o-Native significantly outperforms other open-source and proprietary\nmodels, even this state-of-the-art system struggles with logical reasoning\ntasks, highlighting an area that remains underexplored. As an initial effort,\nRISEBench aims to provide foundational insights into reasoning-aware visual\nediting and to catalyze future research. Though still in its early stages, we\nare committed to continuously expanding and refining the benchmark to support\nmore comprehensive, reliable, and scalable evaluations of next-generation\nmultimodal systems. Our code and data will be released at\nhttps://github.com/PhoenixZ810/RISEBench.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.04726v1","title":"Can LLM-Driven Hard Negative Sampling Empower Collaborative Filtering?\n  Findings and Potentials","summary":"Hard negative samples can accelerate model convergence and optimize decision\nboundaries, which is key to improving the performance of recommender systems.\nAlthough large language models (LLMs) possess strong semantic understanding and\ngeneration capabilities, systematic research has not yet been conducted on how\nto generate hard negative samples effectively. To fill this gap, this paper\nintroduces the concept of Semantic Negative Sampling and exploreshow to\noptimize LLMs for high-quality, hard negative sampling. Specifically, we design\nan experimental pipeline that includes three main modules, profile generation,\nsemantic negative sampling, and semantic alignment, to verify the potential of\nLLM-driven hard negative sampling in enhancing the accuracy of collaborative\nfiltering (CF). Experimental results indicate that hard negative samples\ngenerated based on LLMs, when semantically aligned and integrated into CF, can\nsignificantly improve CF performance, although there is still a certain gap\ncompared to traditional negative sampling methods. Further analysis reveals\nthat this gap primarily arises from two major challenges: noisy samples and\nlack of behavioral constraints. To address these challenges, we propose a\nframework called HNLMRec, based on fine-tuning LLMs supervised by collaborative\nsignals. Experimental results show that this framework outperforms traditional\nnegative sampling and other LLM-driven recommendation methods across multiple\ndatasets, providing new solutions for empowering traditional RS with LLMs.\nAdditionally, we validate the excellent generalization ability of the LLM-based\nsemantic negative sampling method on new datasets, demonstrating its potential\nin alleviating issues such as data sparsity, popularity bias, and the problem\nof false hard negative samples. Our implementation code is available at\nhttps://github.com/user683/HNLMRec.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T04:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.04737v1","title":"TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction\n  and Explanation in the Indian Legal Context","summary":"In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T05:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04743v1","title":"AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation","summary":"Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04769v1","title":"Scalable simulation of random quantum circuits using projected\n  entangled-pair states","summary":"Classical simulation of a programmable quantum processor is crucial in\nidentifying the threshold of a quantum advantage. We use the simple update of\nprojected entangled-pair states (PEPSs) in the Vidal gauge to simulate the\nstates of random quantum circuits (RQCs), which center around recent quantum\nadvantage claims. Applied to square lattices of qubits akin to state-of-the-art\nsuperconducting processors, our PEPS simulation is exact for circuit depths\nless than $D_\\mathrm{tr}$ = $\\beta\\log_2\\chi$, where $\\chi$ is the maximum bond\ndimension and $2 \\lesssim \\beta \\lesssim 4$ depends on the choice of two-qubit\ngates, independent of the qubit number $n$. We find the universal scaling\nbehaviors of the state fidelity by performing large-scale simulations for $n\n\\leq 10^{4}$ or $\\chi \\leq 128$ on a conventional CPU. Our method has\ncomputational cost scaling polynomially with $n$ for circuit depth $D =O(\\log\nn)$ and is more advantageous than matrix product state (MPS) approaches if $n$\nis large. This work underscores PEPSs as a scalable tool for benchmarking\nquantum algorithms, with future potential for sampling applications using\nadvanced contraction techniques.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-07T06:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04779v1","title":"Black hole destabilization via trapped quasi-normal modes","summary":"In the presence of non-minimal gravitational couplings, matter field\nperturbations on a static black hole spacetime may develop unphysical poles in\ntheir linearized equations. Physical solutions confined in the domain between\nthe event horizon and a pole satisfy a boundary value problem, although with\nboundary conditions which are different from standard quasi-normal modes. We\nrefer to them as \"trapped quasi-normal modes\". Focusing on a Schwarzschild\nblack hole in Einstein-Proca theory, we find that trapped quasi-normal modes\naccurately capture the behavior of perturbations under time evolution. In\nparticular, axial-vector modes are unstable, with a growth rate that increases\nwith multipole number. More interestingly, we uncover a new instability that\naffects monopole perturbations. These results confirm the existence of a novel\ndestabilization mechanism of black holes by non-minimally coupled vector\nfields, with potential implications to well-studied models of modified gravity\nand cosmology based on vector particles.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T07:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04787v1","title":"Dynamic Vision Mamba","summary":"Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T07:31:28Z"}
{"aid":"http://arxiv.org/abs/2504.04813v1","title":"Generalized Fermi-Dirac Distribution of Exclusive Fermions","summary":"A system of exclusive fermions occurs when two fermions of opposite spin are\nprohibited from occupying the same quantum level. We derive the distribution of\nexclusive fermions via the employment of the grand canonical ensemble. Salient\nfeatures of its statistical properties, compared to the free electron gases,\ninclude: larger Fermi energy, higher degeneracy pressure, but the same Pauli\nparamagnetism and Landau diamagnetism. In particular, higher degeneracy\npressure leads to an inflation of the Chandrasekhar limit to 1.6 times when\napplied to white dwarf stars and neutron stars.","main_category":"math-ph","categories":"math-ph,astro-ph.SR,cond-mat.stat-mech,math.MP","published":"2025-04-07T08:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.04842v1","title":"FantasyTalking: Realistic Talking Portrait Generation via Coherent\n  Motion Synthesis","summary":"Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04853v1","title":"Charmonium-nucleon femtoscopic correlation function","summary":"This study investigates the femtoscopic correlation functions of\ncharmonium-nucleon pairs, utilizing the lattice QCD phase shifts provided by\nthe HAL QCD Collaboration. A model-independent formalism is employed to\ntransform scattering phase shifts directly into momentum correlation functions,\nthereby circumventing the approximations inherent in traditional methods, such\nas the Lednick\\'y-Lyuboshits model. The $J/\\psi$-$p$ correlation functions,\nincluding spin-averaged and partial-wave results, are predicted using\nnear-physical pion mass lattice results. The $\\eta_c$-$p$ correlation function\nis calculated for the first time. The derived correlation functions provide\ncritical references for future experiments, such as those at the LHC, where\nhigh-precision measurements of charmonium-nucleon correlations could unveil\nvaluable insights into non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T09:10:58Z"}
{"aid":"http://arxiv.org/abs/2504.04854v1","title":"Traversable wormholes with multiple unstable critical curves","summary":"The number and position of unstable critical curves, as well as the nature of\nthe accretion disk around compact objects, play a fundamental role in their\noptical appearance. Identifying differences in the optical spectrum of various\nobserved compact objects can help classify them as black holes or black hole\nmimickers, such as traversable wormholes. Although multiple unstable critical\ncurves have been reported to appear in asymmetric traversable wormholes, in\nthis work we construct symmetric traversable wormholes with multiple unstable\ncritical curves. We propose a general rational redshift function that allows us\nto trace the number of critical points of the effective potential and determine\ntheir nature as maxima or minima. The ray tracing method is used to study the\ntrajectories of massless particles, particularly their behavior near the\nunstable critical points. Finally, a thin accretion disk model is implemented\nto analyze the optical appearance of the solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T09:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04883v1","title":"How Far do Lindbladians Go?","summary":"We investigate geometric aspects of the space of densities by analyzing\ntransport along paths generated by quantum Markovian semigroups and more\ngenerally locally Markovian, or time-dependent Lindbladian, dynamics. Motivated\nby practical constraints, we also consider a more realistic scenario in which\nonly a restricted set of Lindbladian generators is available. We study the\ncorresponding transitivity properties and characterize the set of states that\ncan be reached using such limited dynamical resources.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.FA,math.MP","published":"2025-04-07T09:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.04923v1","title":"Truncated sequential guaranteed estimation for the Cox-Ingersoll-Ross\n  models","summary":"The drift sequential parameter estimation problems for the Cox-Ingersoll-Ross\n(CIR) processes under the limited duration of observation are studied.\nTruncated sequential estimation methods for both scalar and {two}-dimensional\nparameter cases are proposed. In the non-asymptotic setting, for the proposed\ntruncated estimators, the properties of guaranteed mean-square estimation\naccuracy are established. In the asymptotic formulation, when the observation\ntime tends to infinity, it is shown that the proposed sequential procedures are\nasymptotically optimal among all possible sequential and non-sequential\nestimates with an average estimation time less than the fixed observation\nduration. It also turned out that asymptotically, without degrading the\nestimation quality, they significantly reduce the observation duration compared\nto classical non-sequential maximum likelihood estimations based on a fixed\nobservation duration.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T11:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.04928v1","title":"Advanced Codebook Design for SCMA-aided NTNs With Randomly Distributed\n  Users","summary":"In this letter, a novel class of sparse codebooks is proposed for sparse code\nmultiple access (SCMA) aided non-terrestrial networks (NTN) with randomly\ndistributed users characterized by Rician fading channels. Specifically, we\nfirst exploit the upper bound of bit error probability (BEP) of an SCMA-aided\nNTN with large-scale fading of different users under Rician fading channels.\nThen, the codebook is designed by employing pulse-amplitude modulation\nconstellation, user-specific rotation and power factors. To further reduce the\noptimization complexity while maintaining the power diversity of different\nusers, an orthogonal layer-assisted joint layer and power assignment strategy\nis proposed. Finally, unlike existing SCMA codebook designs that treat all\nusers as one super-user, we propose to minimize the BEP of the worst user to\nensure user fairness. The simulation results show that the proposed scheme is\ncapable of providing a substantial performance gain over conventional\ncodebooks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T11:10:44Z"}
{"aid":"http://arxiv.org/abs/2504.04931v1","title":"The $L_{p}$ dual Christoffel-Minkowski problem for $1<p<q\\leq k+1$ with\n  $1\\leq k\\leq n$","summary":"In this paper, we investigate an $L_{p}$ Christoffel-Minkowski-type problem\nthat prescribes a class of $L_p$ geometric measures, which are mixtures of the\n$k$-th area measure and the $q$-th dual curvature measure. By establishing a\ngradient estimate, we obtain the existence of an even, smooth, strictly convex\nsolution to this problem for $1 < p < q \\leq k + 1$, where $1 \\leq k \\leq n$\nand $n \\geq 1$.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-07T11:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.04935v1","title":"RCCFormer: A Robust Crowd Counting Network Based on Transformer","summary":"Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T11:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.04937v1","title":"Hybrid Control Barrier Functions for Nonholonomic Multi-Agent Systems","summary":"This paper addresses the problem of guaranteeing safety of multiple\ncoordinated agents moving in dynamic environments. It has recently been shown\nthat this problem can be efficiently solved through the notion of Control\nBarrier Functions (CBFs). However, for nonholonomic vehicles that are required\nto keep positive speeds, existing CBFs lose their validity. To overcome this\nlimitation, we propose a hybrid formulation based on synergistic CBFs (SCBFs),\nwhich leverages a discrete switching mechanism to avoid configurations that\nwould render the CBF invalid. Unlike existing approaches, our method ensures\nsafety in the presence of moving obstacles and inter-agent interactions while\nrespecting nonzero speed restrictions. We formally analyze the feasibility of\nthe constraints with respect to actuation limits, and the efficacy of the\nsolution is demonstrated in simulation of a multi-agent coordination problem in\nthe presence of moving obstacles.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2504.04940v1","title":"Fine tuning generative adversarial networks with universal force fields:\n  application to two-dimensional topological insulators","summary":"Despite rapid growth in use cases for generative artificial intelligence, its\nability to design purpose built crystalline materials remains in a nascent\nphase. At the moment inverse design is generally accomplished by either\nconstraining the training data set or producing a vast number of samples from a\ngenerator network and constraining the output via post-processing. We show that\na general adversarial network trained to produce crystal structures from a\nlatent space can be fine tuned through the introduction of advanced graph\nneural networks as discriminators, including a universal force field, to\nintrinsically bias the network towards generation of target materials. This is\nexemplified utilizing two-dimensional topological insulators as a sample target\nspace. While a number of two-dimensional topological insulators have been\npredicted, the size of the band-gap, a measure of topological protection,\nremains a concern in most candidate compounds. The resulting generative network\nis shown to yield novel topological insulators.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T11:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04943v1","title":"Emergence of microbial host dormancy during a persistent virus epidemic","summary":"We study a minimal stochastic individual-based model for a microbial\npopulation challenged by a persistent (lytic) virus epidemic. We focus on the\nsituation in which the resident microbial host population and the virus\npopulation are in stable coexistence upon arrival of a single new ``mutant''\nhost individual. We assume that this mutant is capable of switching to a\nreversible state of dormancy upon contact with virions as a means of avoiding\ninfection by the virus. At the same time, we assume that this new dormancy\ntrait comes with a cost, namely a reduced individual reproduction rate. We\nprove that there is a non-trivial range of parameters where the mutants can\nnevertheless invade the resident population with strictly positive probability\n(bounded away from 0) in the large population limit. Given the reduced\nreproductive rate, such an invasion would be impossible in the absence of\neither the dormancy trait or the virus epidemic. We explicitly characterize the\nparameter regime where this emergence of a (costly) host dormancy trait is\npossible, determine the success probability of a single invader and the typical\namount of time it takes the successful mutants to reach a macroscopic\npopulation size. We conclude this study by an investigation of the fate of the\npopulation after the successful emergence of a dormancy trait. Heuristic\narguments and simulations suggest that after successful invasion, either both\nhost types and the virus will reach coexistence, or the mutants will drive the\nresident hosts to extinction while the virus will stay in the system.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05010v1","title":"Some analogues of isoperimetric inequality","summary":"The discrete isoperimetric inequality states that among all n -gons with a\nfixed area, the regular n -gon has the least perimeter. We prove analogues of\nthe discrete isoperimetric inequality (involving circumradius or inradius) for\ncyclic and tangential polygons in hyperbolic geometry, considering both single\nand multiple polygons. Furthermore, we establish two versions of the\nisoperimetric inequality for multiple polygons in hyperbolic geometry with some\nrestriction on their area or perimeter.","main_category":"math.GT","categories":"math.GT","published":"2025-04-07T12:37:48Z"}
{"aid":"http://arxiv.org/abs/2504.05012v1","title":"Descriptive Complexity of Sensitivity of Cellular Automata","summary":"We study the computational complexity of determining whether a cellular\nautomaton is sensitive to initial conditions. We show that this problem is\n$\\Pi^0_2$-complete in dimension 1 and $\\Sigma^0_3$-complete in dimension 2 and\nhigher. This solves a question posed by Sablik and Theyssier.","main_category":"math.DS","categories":"math.DS,cs.CC,math.LO","published":"2025-04-07T12:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05019v1","title":"Mixture-of-Personas Language Models for Population Simulation","summary":"Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-07T12:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05058v1","title":"Not All Data Are Unlearned Equally","summary":"Machine unlearning is concerned with the task of removing knowledge learned\nfrom particular data points from a trained model. In the context of large\nlanguage models (LLMs), unlearning has recently received increased attention,\nparticularly for removing knowledge about named entities from models for\nprivacy purposes. While various approaches have been proposed to address the\nunlearning problem, most existing approaches treat all data points to be\nunlearned equally, i.e., unlearning that Montreal is a city in Canada is\ntreated exactly the same as unlearning the phone number of the first author of\nthis paper. In this work, we show that this all data is equal assumption does\nnot hold for LLM unlearning. We study how the success of unlearning depends on\nthe frequency of the knowledge we want to unlearn in the pre-training data of a\nmodel and find that frequency strongly affects unlearning, i.e., more frequent\nknowledge is harder to unlearn. Additionally, we uncover a misalignment between\nprobability and generation-based evaluations of unlearning and show that this\nproblem worsens as models become larger. Overall, our experiments highlight the\nneed for better evaluation practices and novel methods for LLM unlearning that\ntake the training data of models into account.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:29:02Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05068v1","title":"Global approximations to the error function of real argument for\n  vectorized computation","summary":"The error function of real argument can be uniformly approximated to a given\naccuracy by a single closed-form expression for the whole variable range either\nin terms of addition, multiplication, division, and square root operations\nonly, or also using the exponential function. The coefficients have been\ntabulated for up to 128-bit precision. Tests of a computer code implementation\nusing the standard single- and double-precision floating-point arithmetic show\ngood performance and vectorizability.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-07T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.05074v1","title":"On the Performance of an Explainable Language Model on PubMedQA","summary":"Large language models (LLMs) have shown significant abilities in retrieving\nmedical knowledge, reasoning over it and answering medical questions comparably\nto physicians. However, these models are not interpretable, hallucinate, are\ndifficult to maintain and require enormous compute resources for training and\ninference. In this paper, we report results from Gyan, an explainable language\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\nLLM is a compositional language model and the model is decoupled from\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\nrequire significant training or compute resources. Gyan is easily transferable\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\nDeepMind). We will be reporting results for other medical data sets - MedQA,\nMedMCQA, MMLU - Medicine in the future.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.05077v1","title":"Transforming Ridesharing: Harnessing Role Flexibility and HOV\n  Integration for Enhanced Mobility Solutions","summary":"While dynamic ridesharing has been extensively studied, there remains a\nsignificant research gap in exploring role flexibility within the many-to-many\nridesharing scheme, where the system allows for several pickups for drivers and\nmultiple transfers for riders. Previous works have predominantly assumed that\nall participants own a car and have focused on one-to-one arrangements.\nAdditionally, there is a scarcity of research on integrating High Occupancy\nVehicle (HOV) lanes and mathematical modelling. This study addresses these gaps\nby presenting a novel Mixed Integer Linear Programming (MILP) model that allows\nfor role flexibility irrespective of car ownership and considers the\nimplications of HOV lanes. Computational analysis highlights the benefits of\nincorporating role flexibility and accommodating non-car-owning participants in\nmany-to-many ridesharing systems. Yet, excessive role shifts may create\nimbalances, impacting service to non-car owners. Further research should\nexplore these correlations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T13:45:19Z"}
{"aid":"http://arxiv.org/abs/2504.05089v1","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","summary":"Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05138v1","title":"Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated\n  Learning","summary":"Federated learning (FL) allows edge devices to collaboratively train models\nwithout sharing local data. As FL gains popularity, clients may need to train\nmultiple unrelated FL models, but communication constraints limit their ability\nto train all models simultaneously. While clients could train FL models\nsequentially, opportunistically having FL clients concurrently train different\nmodels -- termed multi-model federated learning (MMFL) -- can reduce the\noverall training time. Prior work uses simple client-to-model assignments that\ndo not optimize the contribution of each client to each model over the course\nof its training. Prior work on single-model FL shows that intelligent client\nselection can greatly accelerate convergence, but na\\\"ive extensions to MMFL\ncan violate heterogeneous resource constraints at both the server and the\nclients. In this work, we develop a novel convergence analysis of MMFL with\narbitrary client sampling methods, theoretically demonstrating the strengths\nand limitations of previous well-established gradient-based methods. Motivated\nby this analysis, we propose MMFL-LVR, a loss-based sampling method that\nminimizes training variance while explicitly respecting communication limits at\nthe server and reducing computational costs at the clients. We extend this to\nMMFL-StaleVR, which incorporates stale updates for improved efficiency and\nstability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead\ndeployment. Experiments show our methods improve average accuracy by up to\n19.1% over random sampling, with only a 5.4% gap from the theoretical optimum\n(full client participation).","main_category":"cs.LG","categories":"cs.LG,cs.DC,I.2.11","published":"2025-04-07T14:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05158v1","title":"Leveraging Label Potential for Enhanced Multimodal Emotion Recognition","summary":"Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-07T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05201v1","title":"3D Universal Lesion Detection and Tagging in CT with Self-Training","summary":"Radiologists routinely perform the tedious task of lesion localization,\nclassification, and size measurement in computed tomography (CT) studies.\nUniversal lesion detection and tagging (ULDT) can simultaneously help alleviate\nthe cumbersome nature of lesion measurement and enable tumor burden assessment.\nPrevious ULDT approaches utilize the publicly available DeepLesion dataset,\nhowever it does not provide the full volumetric (3D) extent of lesions and also\ndisplays a severe class imbalance. In this work, we propose a self-training\npipeline to detect 3D lesions and tag them according to the body part they\noccur in. We used a significantly limited 30\\% subset of DeepLesion to train a\nVFNet model for 2D lesion detection and tagging. Next, the 2D lesion context\nwas expanded into 3D, and the mined 3D lesion proposals were integrated back\ninto the baseline training data in order to retrain the model over multiple\nrounds. Through the self-training procedure, our VFNet model learned from its\nown predictions, detected lesions in 3D, and tagged them. Our results indicated\nthat our VFNet model achieved an average sensitivity of 46.9\\% at [0.125:8]\nfalse positives (FP) with a limited 30\\% data subset in comparison to the\n46.8\\% of an existing approach that used the entire DeepLesion dataset. To our\nknowledge, we are the first to jointly detect lesions in 3D and tag them\naccording to the body part label.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05221v1","title":"Apparent fractional charge signatures in PbTe quantum dots due to\n  capacitively coupled charge trap dynamics","summary":"We report the observation of fractional shifts in the experimental stability\ndiagrams of PbTe nanowire quantum dots. Although this behavior may appear to\nsuggest fractional charge transport, akin to that reported in the fractional\nquantum Hall regime, the quasi-one-dimensionality of the system and absence of\nan applied magnetic field indicate that the presence of fractional charges is\nhighly unlikely. We instead attribute these effects to the presence of one or\nmore spurious dots, or charge traps, capacitively coupled to the primary dot.\nOur findings illustrate how signatures of fractional charge transport may be\nreplicated through trivial mesoscopic Coulombic effects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-07T16:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05234v1","title":"Precision DIS thrust predictions for HERA and EIC","summary":"We present predictions for the DIS 1-jettiness event shape $\\tau_1^b$, or DIS\nthrust, using the framework of Soft Collinear Effective Theory (SCET) for\nfactorization, resummation of large logarithms, and rigorous treatment of\nnonperturbative power corrections, matched to fixed-order QCD away from the\nresummation region. Our predictions reach\nnext-to-next-to-next-to-leading-logarithmic (N$^3$LL) accuracy in resummed\nperturbation theory, matched to $O(\\alpha_s^2)$ fixed-order QCD calculations\nobtained using the program NLOJet++. We include a rigorous treatment of\nhadronization corrections, which are universal across different event shapes\nand kinematic variables $x$ and $Q$ at leading power, and supplement them with\na systematic scheme to remove $O(\\Lambda_\\textrm{QCD})$ renormalon ambiguities\nin their definition. The framework of SCET allows us to connect smoothly the\nnonperturbative, resummation, and fixed-order regions, whose relative\nimportance varies with $x$ and $Q$, and to rigorously estimate theoretical\nuncertainties, across a broad range of $x$ and $Q$ covering existing\nexperimental results from HERA as well as expected new measurements from the\nupcoming Electron-Ion-Collider (EIC). Our predictions will serve as an\nimportant benchmark for the EIC program, enabling the precise determination of\nthe QCD strong coupling $\\alpha_s$ and the universal nonperturbative first\nmoment parameter $\\Omega_1$.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T16:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.05237v1","title":"Measuring Rényi entropy using a projected Loschmidt echo","summary":"We present efficient and practical protocols to measure the second R\\'enyi\nentropy (RE), whose exponential is known as the purity. We achieve this by\nestablishing a direct connection to a Loschmidt echo (LE) type measurement\nsequence, applicable to quantum many-body systems. Notably, our approach does\nnot rely on random-noise averaging, a feature that can be extended to protocols\nto measure out-of-time-order correlation functions (OTOCs), as we demonstrate.\nBy way of example, we show that our protocols can be practically implemented in\nsuperconducting qubit-based platforms, as well as in cavity-QED trapped\nultra-cold gases.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,cond-mat.stat-mech,hep-th","published":"2025-04-07T16:21:53Z"}
{"aid":"http://arxiv.org/abs/2504.05243v1","title":"Boundedness of polarized log Calabi-Yau fibrations with bounded bases","summary":"We investigate the boundedness problem for log Calabi-Yau fibrations whose\nbases and general fibers are bounded. We prove that the total spaces of log\nCalabi-Yau fibrations are bounded in codimension one after fixing some natural\ninvariants. We also prove that the total spaces are bounded if, in addition,\nthe irregularity of the general fibers vanishes. Then we apply our results to\nthe boundedness problem for stable minimal models and fibered Calabi-Yau\nvarieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T16:28:38Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05260v1","title":"Manipulating phases in many-body interacting systems with subsystem\n  resetting","summary":"Stabilizing thermodynamically unstable phases in many-body systems -- such as\nsuppressing pathological neuronal synchronization in Parkinson's disease or\nmaintaining magnetic order across broad temperature ranges -- remains a\npersistent challenge. In traditional approaches, such phases are stabilized\nthrough intervening in the dynamics of all system constituents or introducing\nadditional interactions. Here, we offer a hitherto-unexplored alternative --\nsubsystem resetting, whereby intervention in the dynamics of only a part of the\nsystem, and that too only occasionally in time, is implemented through\nresetting its state to a reset configuration. Just playing with a few\nparameters, e.g., the nature of the reset configuration and the size of the\nreset subsystem, one achieves a remarkable and robust control over the phase\ndiagram of the bare dynamics. We demonstrate that these universal effects span\na wide variety of scenarios, including equilibrium and non-equilibrium,\nmean-field and non-mean-field dynamics, with and without quenched disorder.\nDespite the challenges posed by memory effects, we obtain explicit analytical\npredictions, validated by simulations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,nlin.AO","published":"2025-04-07T16:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.05271v1","title":"AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point\n  Detection for Accurate Characterization of Anomalous Diffusion in Video Data","summary":"Anomalous diffusion occurs in a wide range of systems, including protein\ntransport within cells, animal movement in complex habitats, pollutant\ndispersion in groundwater, and nanoparticle motion in synthetic materials.\nAccurately estimating the anomalous diffusion exponent and the diffusion\ncoefficient from the particle trajectories is essential to distinguish between\nsub-diffusive, super-diffusive, or normal diffusion regimes. These estimates\nprovide a deeper insight into the underlying dynamics of the system,\nfacilitating the identification of particle behaviors and the detection of\nchanges in diffusion states. However, analyzing short and noisy video data,\nwhich often yield incomplete and heterogeneous trajectories, poses a\nsignificant challenge for traditional statistical approaches. We introduce a\ndata-driven method that integrates particle tracking, an attention\n  U-Net architecture, and a change-point detection algorithm to address these\nissues. This approach not only infers the anomalous diffusion parameters with\nhigh accuracy but also identifies temporal transitions between different\nstates, even in the presence of noise and limited temporal resolution. Our\nmethodology demonstrated strong performance in the 2nd Anomalous Diffusion\n(AnDi) Challenge benchmark within the top submissions for video tasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T17:08:17Z"}
{"aid":"http://arxiv.org/abs/2504.05274v1","title":"Aggregating time-series and image data: functors and double functors","summary":"Aggregation of time-series or image data over subsets of the domain is a\nfundamental task in data science. We show that many known aggregation\noperations can be interpreted as (double) functors on appropriate (double)\ncategories. Such functorial aggregations are amenable to parallel\nimplementation via straightforward extensions of Blelloch's parallel scan\nalgorithm. In addition to providing a unified viewpoint on existing operations,\nit allows us to propose new aggregation operations for time-series and image\ndata.","main_category":"math.CT","categories":"math.CT,cs.LG","published":"2025-04-07T17:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05276v1","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\n  Generation","summary":"Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05278v1","title":"The challenge of uncertainty quantification of large language models in\n  medicine","summary":"This study investigates uncertainty quantification in large language models\n(LLMs) for medical applications, emphasizing both technical innovations and\nphilosophical implications. As LLMs become integral to clinical\ndecision-making, accurately communicating uncertainty is crucial for ensuring\nreliable, safe, and ethical AI-assisted healthcare. Our research frames\nuncertainty not as a barrier but as an essential part of knowledge that invites\na dynamic and reflective approach to AI design. By integrating advanced\nprobabilistic methods such as Bayesian inference, deep ensembles, and Monte\nCarlo dropout with linguistic analysis that computes predictive and semantic\nentropy, we propose a comprehensive framework that manages both epistemic and\naleatoric uncertainties. The framework incorporates surrogate modeling to\naddress limitations of proprietary APIs, multi-source data integration for\nbetter context, and dynamic calibration via continual and meta-learning.\nExplainability is embedded through uncertainty maps and confidence metrics to\nsupport user trust and clinical interpretability. Our approach supports\ntransparent and ethical decision-making aligned with Responsible and Reflective\nAI principles. Philosophically, we advocate accepting controlled ambiguity\ninstead of striving for absolute predictability, recognizing the inherent\nprovisionality of medical knowledge.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T17:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05630v1","title":"A new discrimination measure for assessing predictive performance of\n  non-linear survival models","summary":"Non-linear survival models are flexible models in which the proportional\nhazard assumption is not required. This poses difficulties in their evaluation.\nWe introduce a new discrimination measure, time-dependent Uno's C-index, to\nassess the discrimination performance of non-linear survival models. This is an\nunbiased version of Antolini's time-dependent concordance. We prove convergence\nof both measures employing Nolan and Pollard's results on U-statistics. We\nexplore the relationship between these measures and, in particular, the bias of\nAntolini's concordance in the presence of censoring using simulated data. We\ndemonstrate the value of time-dependent Uno's C-index for the evaluation of\nmodels trained on censored real data and for model tuning.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05645v1","title":"A Study of Multiple Molecular Lines at the 3 mm Band toward Gas\n  Infalling Sources","summary":"The study of multiple molecular spectral lines in gas infalling sources can\nprovide the physical and chemical properties of these sources and help us\nestimate their evolutionary stages. We report line detections within the 3 mm\nband using the FTS wide-sideband mode of the IRAM 30 m telescope toward 20\ngas-infalling sources. Using XCLASS, we identify the emission lines of up to 22\nmolecular species (including a few isotopologues) and one hydrogen radio\nrecombination line in these sources. H$^{13}$CO$^+$, HCO$^+$, HCN, HNC,\nc-C$_3$H$_2$, and CCH lines are detected in 15 sources. We estimate the\nrotation temperatures and column densities of these molecular species using the\nLTE radiative transfer model, and compare the molecular abundances of these\nsources with those from nine high-mass star-forming regions reported in\nprevious studies and with those from the chemical model. Our results suggest\nthat G012.79-0.20, G012.87-0.22 clump A and B, and G012.96-0.23 clump A may be\nin the high-mass protostellar object stage, while sources with fewer detected\nspecies may be in the earlier evolutionary stage. Additionally, the CCH and\nc-C$_3$H$_2$ column densities in our sources reveal a linear correlation, with\na ratio of N(CCH)/N(c-C$_3$H$_2$) = 89.2$\\pm$5.6, which is higher than the\nratios reported in the literature. When considering only sources with lower\ncolumn densities, this ratio decreases to 29.0$\\pm$6.1, consistent with those\nof diffuse clouds. Furthermore, a comparison between the N(CCH)/N(c-C$_3$H$_2$)\nratio and the sources' physical parameters reveals a correlation, with sources\nexhibiting higher ratios tending to have higher kinetic temperatures and H$_2$\ncolumn densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T03:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05719v1","title":"Mental Geometry","summary":"This article illustrates pedagogy through training in the handling of\nabstractions. Mental arithmetic is not limited to numerical calculation; one\ncan mentally calculate primitives and simplify analytical expressions. Even if\nthere is software that does this very well, this training retains its\npedagogical value. Can we go further and consider geometric mental arithmetic:\nmentally proceeding with transformations of simple figures allowing the\ncalculation of areas or volumes? It turns out that the intuition that allowed\nArchimedes to obtain his main geometric results, if we take only the ideas\nwithout the old-fashioned style, provides the opportunity for a pleasant and\nquite rich mental game that I present here in the form of a short narrative\ndialogue, not a philosophical tale because it does not bring any thesis, simply\na story to be classified among the invitations to exercise the mind. It starts\nwith the area of a triangle and ends with Guldin's two theorems.","main_category":"math.HO","categories":"math.HO,math.MG","published":"2025-04-08T06:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.05721v1","title":"Graph product and the stability of circulant graphs","summary":"A graph $\\Gamma$ is said to be stable if $\\mathrm{Aut}(\\Gamma\\times\nK_2)\\cong\\mathrm{Aut}(\\Gamma)\\times \\mathbb{Z}_{2}$ and unstable otherwise. If\nan unstable graph is connected, non-bipartite and any two of its distinct\nvertices have different neighborhoods, then it is called nontrivially unstable.\nWe establish conditions guaranteeing the instability of various graph products,\nincluding direct products, direct product bundles, Cartesian products, strong\nproducts, semi-strong products, and lexicographic products. Inspired by a\ncondition for the instability of direct product bundles, we propose a new\nsufficient condition for circulant graphs to be unstable. This condition yields\ninfinitely many nontrivially unstable circulant graphs that do not satisfy any\npreviously established instability conditions for circulant graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T06:42:11Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05745v1","title":"Reflections on Chiral Symmetry within QCD","summary":"That chiral symmetry is a crucial feature of the strong force was realized\nbefore the discovery of Quantum Chromodynamics. However, the full power it\nexerts on the structure of the nucleon became apparent only afterwards. We\npresent a high-level and somewhat personal overview of its role in almost every\naspect of proton structure, from its mass and spin to the asymmetry of its\nantimatter content and its strange quark content. The lessons learned from\nstudying the proton are also vital with respect to the modern challenge of the\nnature of baryon excited states.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-08T07:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05765v1","title":"Probabilistic Process Discovery with Stochastic Process Trees","summary":"In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.05780v1","title":"Magnetic Memory Driven by Orbital Current","summary":"Spin-orbitronics, based on both spin and orbital angular momentum, presents a\npromising pathway for energy-efficient memory and logic devices. Recent studies\nhave demonstrated the emergence of orbital currents in light transition metals\nsuch as Ti, Cr, and Zr, broadening the scope of spin-orbit torque (SOT). In\nparticular, the orbital Hall effect, which arises independently of spin-obit\ncoupling, has shown potential for enhancing torque efficiency in spintronic\ndevices. However, the direct integration of orbital current into magnetic\nrandom-access memory (MRAM) remains unexplored. In this work, we design a light\nmetal/heavy metal/ferromagnet multilayer structure and experimentally\ndemonstrate magnetization switching by orbital current. Furthermore, we have\nrealized a robust SOT-MRAM cell by incorporating a reference layer that is\npinned by a synthetic antiferromagnetic structure. We observed a tunnel\nmagnetoresistance of 66%, evident in both magnetic field and current-driven\nswitching processes. Our findings underscore the potential for employing\norbital current in designing next-generation spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T08:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.05787v1","title":"Finiteness properties of asymptotically rigid handlebody groups","summary":"We introduce asymptotically rigid mapping class groups of handlebodies and\ndetermine their finiteness properties, which vary depending on the space of\nends of the underlying handlebody. As it turns out, in some cases, the homology\nof these groups coincides with the stable homology of handlebody groups, as\nstudied by Hatcher and Wahl.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-08T08:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.05794v1","title":"DefMamba: Deformable Visual State Space Model","summary":"Recently, state space models (SSM), particularly Mamba, have attracted\nsignificant attention from scholars due to their ability to effectively balance\ncomputational efficiency and performance. However, most existing visual Mamba\nmethods flatten images into 1D sequences using predefined scan orders, which\nresults the model being less capable of utilizing the spatial structural\ninformation of the image during the feature extraction process. To address this\nissue, we proposed a novel visual foundation model called DefMamba. This model\nincludes a multi-scale backbone structure and deformable mamba (DM) blocks,\nwhich dynamically adjust the scanning path to prioritize important information,\nthus enhancing the capture and processing of relevant input features. By\ncombining a deformable scanning(DS) strategy, this model significantly improves\nits ability to learn image structures and detects changes in object details.\nNumerous experiments have shown that DefMamba achieves state-of-the-art\nperformance in various visual tasks, including image classification, object\ndetection, instance segmentation, and semantic segmentation. The code is open\nsource on DefMamba.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:54Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05800v1","title":"Storybooth: Training-free Multi-Subject Consistency for Improved Visual\n  Storytelling","summary":"Training-free consistent text-to-image generation depicting the same subjects\nacross different images is a topic of widespread recent interest. Existing\nworks in this direction predominantly rely on cross-frame self-attention; which\nimproves subject-consistency by allowing tokens in each frame to pay attention\nto tokens in other frames during self-attention computation. While useful for\nsingle subjects, we find that it struggles when scaling to multiple characters.\nIn this work, we first analyze the reason for these limitations. Our\nexploration reveals that the primary-issue stems from self-attention-leakage,\nwhich is exacerbated when trying to ensure consistency across\nmultiple-characters. This happens when tokens from one subject pay attention to\nother characters, causing them to appear like each other (e.g., a dog appearing\nlike a duck). Motivated by these findings, we propose StoryBooth: a\ntraining-free approach for improving multi-character consistency. In\nparticular, we first leverage multi-modal chain-of-thought reasoning and\nregion-based generation to apriori localize the different subjects across the\ndesired story outputs. The final outputs are then generated using a modified\ndiffusion model which consists of two novel layers: 1) a bounded cross-frame\nself-attention layer for reducing inter-character attention leakage, and 2)\ntoken-merging layer for improving consistency of fine-grain subject details.\nThrough both qualitative and quantitative results we find that the proposed\napproach surpasses prior state-of-the-art, exhibiting improved consistency\nacross both multiple-characters and fine-grain subject details.","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.MM","published":"2025-04-08T08:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05856v1","title":"Analyzing type Ia supernovae near-infrared light curves with Principal\n  Component Analysis","summary":"Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf\nstars in binary systems, are phenomena that remain poorly understood. The\ncomplexity of their progenitor systems, explosion physics and intrinsic\ndiversity poses not only challenges for their understanding as astrophysical\nobjects, but also for their standardization and use as cosmological probes.\nNear-infrared (NIR) observations offer a promising avenue for studying the\nphysics of SNeIa and for reducing systematic uncertainties in distance\nestimations, as they exhibit lower dust extinction and smaller dispersion in\npeak luminosity than optical bands. Here, Principal Component Analysis (PCA) is\napplied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to\nidentify the dominant components of their variability and constrain physical\nunderlying properties. The theoretical models of Kasen2006 are used for the\nphysical interpretation of the PCA components, where we found the 56Ni mass to\ndescribe the dominant variability. Other factors, such as mixing and\nmetallicity, were found to contribute significantly as well. However, some\ndifferences are found between the components of the NIR bands which may be\nattributed to differences in the explosion aspects they each trace.\nAdditionally, the PCA components are compared to various light-curve\nparameters, identifying strong correlations between some components and peak\nbrightness in both the NIR and optical bands, particularly in the Y band. When\napplying PCA to NIR color curves, we found interesting correlations with the\nhost-galaxy mass, where SNeIa with redder NIR colors are predominantly found in\nless massive galaxies. We also investigate the potential for improved\nstandardization in the Y band by incorporating PCA coefficients as correction\nparameters, leading to a reduction in the scatter of the intrinsic luminosity\nof SNeIa.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T09:35:33Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05887v1","title":"Jointly-optimized Trajectory Generation and Camera Control for 3D\n  Coverage Planning","summary":"This work proposes a jointly optimized trajectory generation and camera\ncontrol approach, enabling an autonomous agent, such as an unmanned aerial\nvehicle (UAV) operating in 3D environments, to plan and execute coverage\ntrajectories that maximally cover the surface area of a 3D object of interest.\nSpecifically, the UAV's kinematic and camera control inputs are jointly\noptimized over a rolling planning horizon to achieve complete 3D coverage of\nthe object. The proposed controller incorporates ray-tracing into the planning\nprocess to simulate the propagation of light rays, thereby determining the\nvisible parts of the object through the UAV's camera. This integration enables\nthe generation of precise look-ahead coverage trajectories. The coverage\nplanning problem is formulated as a rolling finite-horizon optimal control\nproblem and solved using mixed-integer programming techniques. Extensive\nreal-world and synthetic experiments validate the performance of the proposed\napproach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05922v1","title":"Thawed Gaussian Ehrenfest dynamics at conical intersections: When can a\n  single mean-field trajectory capture internal conversion?","summary":"The thawed Gaussian Ehrenfest dynamics is a single-trajectory method that\npartially includes both nuclear quantum and electronically nonadiabatic effects\nby combining the thawed Gaussian wavepacket dynamics with Ehrenfest dynamics.\nFirst, we demonstrate the improvement over the parent methods in a\nmultidimensional system consisting of vertically displaced harmonic potentials\nwith constant diabatic couplings, for which the thawed Gaussian Ehrenfest\ndynamics is exact. Then, we show that single-trajectory mean-field methods\ncompletely fail to capture electronic population transfer in the vicinity of\nconical intersections between potential energy surfaces associated with\nelectronic states of different symmetry (i.e., belonging to different\nirreducible representations of the molecular point group). The underlying cause\nof this limitation suggests that the thawed Gaussian Ehrenfest dynamics can be\nuseful for studying nonadiabatic dynamics close to conical intersections of\nelectronic states of the same symmetry, which have been understudied owing to\nthe difficulty in locating them. Using a model of this type of intersection, we\ncompare the thawed Gaussian Ehrenfest dynamics with exact quantum dynamics and\nfind that the approximate mean-field approach yields a molecular wavefunction\nthat remains qualitatively similar to the exact one even after crossing and\nrecrossing the conical intersection.","main_category":"physics.chem-ph","categories":"physics.chem-ph,quant-ph","published":"2025-04-08T11:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.05924v1","title":"A Control-Oriented Simplified Single Particle Model with Grouped\n  Parameter and Sensitivity Analysis for Lithium-Ion Batteries","summary":"Lithium-ion batteries are widely used in transportation, energy storage, and\nconsumer electronics, driving the need for reliable battery management systems\n(BMS) for state estimation and control. The Single Particle Model (SPM)\nbalances computational efficiency and accuracy but faces challenges in\nparameter estimation due to numerous parameters. Current SPM models using\nparabolic approximation introduce intermediate variables and hard to do\nparameter grouping. This study presents a control-oriented SPM reformulation\nthat employs parameter grouping and parabolic approximation to simplify model\nparameters while using average and surface lithium-ion concentrations as model\noutput. By parameter grouping, the original 17 parameters were reduced to 9\ngrouped parameters. The reformulated model achieves a reduced-order ordinary\ndifferential equation form while maintaining mathematical accuracy equivalent\nto the pre-grouped discretized SPM. Through Sobol sensitivity analysis under\nvarious current profiles, the grouped parameters were reduced from 9 to 6\nhighly sensitive parameters. Results demonstrate that estimating these 6\nparameters achieves comparable practical accuracy to estimating all 9\nparameters, with faster convergence. This control-oriented SPM enhances BMS\napplications by facilitating state estimation and control while reducing\nparameter estimation requirements.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.05930v1","title":"Totally equimodular matrices: decomposition and triangulation","summary":"Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-08T11:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05956v1","title":"Temporal Alignment-Free Video Matching for Few-shot Action Recognition","summary":"Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T12:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05969v1","title":"Extension of derivations to forms","summary":"The problem of extending derivations of a field $F$ to an $F-$algebra $B$ is\nwidely studied in commutative algebra and non-commutative ring theory. For\nexample, every derivation of $F$ extends to $B$ if $B$ is a separable algebraic\nextension or a central simple algebra over $F.$ We unify and generalize these\nresults by showing that a derivation $d$ of $F$ with the field of constants $C$\nextends to a finite dimensional algebra $B$ if $B$ is a form of some\n$C-$algebra having a smooth automorphism scheme $\\rm G$. Furthermore, we show\nthat the set of derivations of $B$ that extend the derivation $d$ of $F$ is in\nbijection with the set of derivations $\\delta$ such that $(Y,\\delta)$ is a\ndifferential $\\rm G_F-$torsor where $Y$ is the $\\rm G_F-$torsor corresponding\nto $B$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-08T12:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06028v1","title":"A Mean-Reverting Model of Exchange Rate Risk Premium Using\n  Ornstein-Uhlenbeck Dynamics","summary":"This paper examines the empirical failure of uncovered interest parity (UIP)\nand proposes a structural explanation based on a mean-reverting risk premium.\nWe define a realized premium as the deviation between observed exchange rate\nreturns and the interest rate differential, and demonstrate its strong\nmean-reverting behavior across multiple horizons. Motivated by this pattern, we\nmodel the risk premium using an Ornstein-Uhlenbeck (OU) process embedded within\na stochastic differential equation for the exchange rate.\n  Our model yields closed-form approximations for future exchange rate\ndistributions, which we evaluate using coverage-based backtesting. Applied to\nUSD/KRW data from 2010 to 2025, the model shows strong predictive performance\nat both short-term and long-term horizons, while underperforming at\nintermediate (3-month) horizons and showing conservative behavior in the tails\nof long-term forecasts. These results suggest that exchange rate deviations\nfrom UIP may reflect structured, forecastable dynamics rather than pure noise,\nand point to future modeling improvements via regime-switching or time-varying\nvolatility.","main_category":"q-fin.CP","categories":"q-fin.CP,q-fin.ST","published":"2025-04-08T13:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.06031v1","title":"Virtual Agent Tutors in Sheltered Workshops: A Feasibility Study on\n  Attention Training for Individuals with Intellectual Disabilities","summary":"In this work, we evaluate the feasibility of socially assistive virtual\nagent-based cognitive training for people with intellectual disabilities (ID)\nin a sheltered workshop. The Robo- Camp system, originally developed for\nchildren with Attention Deficit Hyperactivity Disorder (ADHD), is adapted based\non the results of a pilot study in which we identified barriers and collected\nfeedback from workshop staff. In a subsequent study, we investigate the aspects\nof usability, technical reliability, attention training capabilities and\nnovelty effect in the feasibility of integrating the RoboCamp system.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T13:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06049v1","title":"Directed LS category and directed parametrized topological complexity","summary":"We introduce and study a parametrized analogue of the directed topological\ncomplexity, originally developed by Goubault, Farber, and Sagnier. We establish\nthe fibrewise basic dihomotopy invariance of directed parametrized topological\ncomplexity and explore its relationship with the parametrized topological\ncomplexity. In addition, we introduce the concept of the directed\nLusternik$-$Schnirelmann (LS) category, prove its basic dihomotopy invariance,\nand investigate its connections with both directed topological complexity and\ndirected parametrized topological complexity. As an application, we show that\nthe directed LS category of the directed spheres is equal to two.","main_category":"math.AT","categories":"math.AT","published":"2025-04-08T13:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.06054v1","title":"Thermodynamic formalism for Quasi-Morphisms: Bounded Cohomology and\n  Statistics","summary":"For a compact negatively curved space, we develop a notion of thermodynamic\nformalism and apply it to study the space of quasi-morphisms of its fundamental\ngroup modulo boundedness. We prove that this space is Banach isomorphic to the\nspace of Bowen functions corresponding to the associated Gromov geodesic flow,\nmodulo a weak notion of Livsic cohomology.\n  The results include that each such unbounded quasi-morphism is associated\nwith a unique invariant measure for the flow, and this measure uniquely\ncharacterizes the cohomology class. As a consequence, we establish the Central\nLimit Theorem for any unbounded quasi-morphism with respect to Markov measures,\nthe invariance principle, and the Bernoulli property of the associated\nequilibrium state.","main_category":"math.DS","categories":"math.DS,math.GT","published":"2025-04-08T13:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.06062v1","title":"A characterization of quasi-homogeneity in terms of liftable vector\n  fields","summary":"We prove under certain conditions that any stable unfolding of a\nquasi-homogeneous map-germ with finite singularity type is substantial. We then\nprove that if an equidimensional map-germ is finitely determined, of corank 1,\nand either it admits a minimal stable unfolding or it is of multipliticy 3,\nthen it admits a substantial unfolding if and only if it is quasi-homogeneous.\nBased on this we pose the following conjecture: a finitely determined map-germ\nis quasi-homogeneous if and only if it admits a substantial unfolding.","main_category":"math.AG","categories":"math.AG,math.DS","published":"2025-04-08T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.06083v1","title":"Security Analysis of Thumbnail-Preserving Image Encryption and a New\n  Framework","summary":"As a primary encryption primitive balancing the privacy and searchability of\ncloud storage images, thumbnail preserving encryption (TPE) enables users to\nquickly identify the privacy personal image on the cloud and request this image\nfrom the owner through a secure channel. In this paper, we have found that two\ndifferent plaintext images may produce the same thumbnail. It results in the\nfailure of search strategy because the collision of thumbnail occurs. To\naddress this serious security issues, we conduct an in-depth analysis on the\ncollision probabilities of thumbnails, and then propose a new TPE framework,\ncalled multi-factor thumbnail preserving encryption (MFTPE). It starts from the\ncollision probability of two blocks, extend to the probabilities of two images\nand ultimately to N images. Then, we in detail describe three specific MFTPE\nconstructions preserving different combinations of factors, i.e., the sum and\nthe geometric mean, the sum and the range, and the sum and the weighted mean.\nThe theoretical and experimental results demonstrate that the proposed MFTPE\nreduces the probability of thumbnails, exhibits strong robustness, and also\neffectively resists face detection and noise attacks.","main_category":"cs.CR","categories":"cs.CR,cs.MM","published":"2025-04-08T14:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.06123v1","title":"Equating quantum imaginary time evolution, Riemannian gradient flows,\n  and stochastic implementations","summary":"We identify quantum imaginary time evolution as a Riemannian gradient flow on\nthe unitary group. We develop an upper bound for the error between the two\nevolutions that can be controlled through the step size of the Riemannian\ngradient descent which minimizes the energy of the system. We discuss\nimplementations through adaptive quantum algorithms and present a stochastic\nRiemannian gradient descent algorithm in which each step is efficiently\nimplementable on a quantum computer. We prove that for a sufficiently small\nstep size, the stochastic evolution concentrates around the imaginary time\nevolution, thereby providing performance guarantees for cooling the system\nthrough stochastic Riemannian gradient descent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T15:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.06126v1","title":"Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms","summary":"Vehicle Routing Problems (VRP) are an extension of the Traveling Salesperson\nProblem and are a fundamental NP-hard challenge in combinatorial optimization.\nSolving VRP in real-time at large scale has become critical in numerous\napplications, from growing markets like last-mile delivery to emerging\nuse-cases like interactive logistics planning. Such applications involve\nsolving similar problem instances repeatedly, yet current state-of-the-art\nsolvers treat each instance on its own without leveraging previous examples. We\nintroduce a novel optimization framework that uses a reinforcement learning\nagent - trained on prior instances - to quickly generate initial solutions,\nwhich are then further optimized by genetic algorithms. Our framework,\nEvolutionary Algorithm with Reinforcement Learning Initialization (EARLI),\nconsistently outperforms current state-of-the-art solvers across various time\nscales. For example, EARLI handles vehicle routing with 500 locations within\n1s, 10x faster than current solvers for the same solution quality, enabling\napplications like real-time and interactive routing. EARLI can generalize to\nnew data, as demonstrated on real e-commerce delivery data of a previously\nunseen city. Our hybrid framework presents a new way to combine reinforcement\nlearning and genetic algorithms, paving the road for closer interdisciplinary\ncollaboration between AI and optimization communities towards real-time\noptimization in diverse domains.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T15:21:01Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06162v1","title":"A distributional approach to nonlocal curvature flows","summary":"In \\cite{CMP17} a novel distributional approach has been introduced to\nprovide a well-posed formulation of a class of crystalline mean curvature\nflows. In this paper, such an approach is extended to the nonlocal setting.\nApplications include the fractional mean curvature flow and the Minkowski flow;\ni.e., the geometric flow generated by the $(N-1)$-dimensional Minkowski\npre-content.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06195v1","title":"Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum\n  Machine Learning Modeling","summary":"We present a full-spectrum machine learning framework for refractive index\nsensing using simulated absorption spectra from meta-grating structures\ncomposed of titanium or silicon nanorods under TE and TM polarizations. Linear\nregression was applied to 80 principal components extracted from each spectrum,\nand model performance was assessed using five-fold cross-validation, simulating\nreal-world biosensing scenarios where unknown patient samples are predicted\nbased on standard calibration data. Titanium-based structures, dominated by\nbroadband intensity changes, yielded the lowest mean squared errors and the\nhighest accuracy improvements: up to a 6065-fold reduction compared to the best\nsingle-feature model. In contrast, silicon-based structures, governed by narrow\nresonances, showed more modest gains due to spectral nonlinearity that limits\nthe effectiveness of global linear models. We also show that even the best\nsingle-wavelength predictor is identified through data-driven analysis, not\nvisual selection, highlighting the value of automated feature preselection.\nThese findings demonstrate that spectral shape plays a key role in modeling\nperformance and that full-spectrum linear approaches are especially effective\nfor intensity-modulated index sensors.","main_category":"physics.optics","categories":"physics.optics,physics.med-ph,q-bio.QM","published":"2025-04-08T16:37:53Z"}
{"aid":"http://arxiv.org/abs/2504.06201v1","title":"Quantum Annealing for Combinatorial Optimization: A Benchmarking Study","summary":"Quantum annealing (QA) has the potential to significantly improve solution\nquality and reduce time complexity in solving combinatorial optimization\nproblems compared to classical optimization methods. However, due to the\nlimited number of qubits and their connectivity, the QA hardware did not show\nsuch an advantage over classical methods in past benchmarking studies. Recent\nadvancements in QA with more than 5,000 qubits, enhanced qubit connectivity,\nand the hybrid architecture promise to realize the quantum advantage. Here, we\nuse a quantum annealer with state-of-the-art techniques and benchmark its\nperformance against classical solvers. To compare their performance, we solve\nover 50 optimization problem instances represented by large and dense\nHamiltonian matrices using quantum and classical solvers. The results\ndemonstrate that a state-of-the-art quantum solver has higher accuracy\n(~0.013%) and a significantly faster problem-solving time (~6,561x) than the\nbest classical solver. Our results highlight the advantages of leveraging QA\nover classical counterparts, particularly in hybrid configurations, for\nachieving high accuracy and substantially reduced problem solving time in\nlarge-scale real-world optimization problems.","main_category":"quant-ph","categories":"quant-ph,cs.CE","published":"2025-04-08T16:43:24Z"}
{"aid":"http://arxiv.org/abs/2504.06219v1","title":"Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling\n  Opt-Outs","summary":"The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T17:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.06220v1","title":"Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of\n  Frequency Adaptation","summary":"Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt\npowerful Foundation Models (FMs) to diverse downstream tasks while preserving\nand unleashing their inherent capabilities. However, we have observed that\nexisting PEFT methods, which are often designed with natural imagery in mind,\nstruggle when applied to Remote Sensing (RS) scenarios. This is primarily due\nto their inability to handle artifact influences, a problem particularly severe\nin RS image features. To tackle this challenge, we introduce Earth-Adapter, the\nfirst PEFT method specifically designed for RS artifacts conquering.\nEarth-Adapter introduces a novel Mixture of Frequency Adaptation process that\ncombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).\nBy utilizing DFT, Earth-Adapter can decompose features into different frequency\ncomponents, precisely separating artifacts from original features. The MoA then\ndynamically assigns weights to each adapter expert, allowing for the\ncombination of features across various frequency domains. These\nsimple-yet-effective approaches enable Earth-Adapter to more efficiently\novercome the disturbances caused by artifacts than previous PEFT methods,\nsignificantly enhancing the FMs' performance on RS scenarios. Experiments on\nDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentation\nbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline\nRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG\nbenchmarks. Our code will be released at\nhttps://github.com/VisionXLab/Earth-Adapter.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06554v1","title":"Experimental Implementation of a Qubit-Efficient Variational Quantum\n  Eigensolver with Analog Error Mitigation on a Superconducting Quantum\n  Processor","summary":"We experimentally demonstrate a qubit-efficient variational quantum\neigensolver (VQE) algorithm using a superconducting quantum processor,\nemploying minimal quantum resources with only a transmon qubit coupled to a\nhigh-coherence photonic qubit. By leveraging matrix product states to compress\nthe quantum state representation, we simulate an N + 1-spin circular Ising\nmodel with a transverse field. Furthermore, we develop an analog error\nmitigation approach through zero-noise extrapolation by introducing a precise\nnoise injection technique for the transmon qubit. As a validation, we apply our\nerror-mitigated qubit-efficient VQE in determining the ground state energies of\na 4-spin Ising model. Our results demonstrate the feasibility of performing\nquantum algorithms with minimal quantum resources while effectively mitigating\nthe impact of noise, offering a promising pathway to bridge the gap between\ntheoretical advances and practical implementations on current noisy\nintermediate-scale quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T03:23:26Z"}
{"aid":"http://arxiv.org/abs/2504.06560v1","title":"NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables","summary":"Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06594v1","title":"Machine Learning for Extrapolating No-Core Shell Model Results to\n  Infinite Basis","summary":"We utilize the machine learning to extrapolate to the infinite model space\nthe no-core shell model (NCSM) results for the energies and rms radii of the\n6He ground state and 6Li lowest states. The extrapolated energies and rms radii\nconverge as the NCSM results from larger model spaces are included in the\ntraining dataset for ensemble of artificial neural networks thus enabling an\naccurate predictions for these observables.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T05:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.06598v1","title":"Stochastic Ray Tracing of 3D Transparent Gaussians","summary":"3D Gaussian splatting has recently been widely adopted as a 3D representation\nfor novel-view synthesis, relighting, and text-to-3D generation tasks, offering\nrealistic and detailed results through a collection of explicit 3D Gaussians\ncarrying opacities and view-dependent colors. However, efficient rendering of\nmany transparent primitives remains a significant challenge. Existing\napproaches either rasterize the 3D Gaussians with approximate sorting per view\nor rely on high-end RTX GPUs to exhaustively process all ray-Gaussian\nintersections (bounding Gaussians by meshes). This paper proposes a stochastic\nray tracing method to render 3D clouds of transparent primitives. Instead of\nprocessing all ray-Gaussian intersections in sequential order, each ray\ntraverses the acceleration structure only once, randomly accepting and shading\na single intersection (or N intersections, using a simple extension). This\napproach minimizes shading time and avoids sorting the Gaussians along the ray\nwhile minimizing the register usage and maximizing parallelism even on low-end\nGPUs. The cost of rays through the Gaussian asset is comparable to that of\nstandard mesh-intersection rays. While our method introduces noise, the shading\nis unbiased, and the variance is slight, as stochastic acceptance is\nimportance-sampled based on accumulated opacity. The alignment with the Monte\nCarlo philosophy simplifies implementation and easily integrates our method\ninto a conventional path-tracing framework.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-09T05:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.06600v1","title":"Automated Business Process Analysis: An LLM-Based Approach to Value\n  Assessment","summary":"Business processes are fundamental to organizational operations, yet their\noptimization remains challenging due to the timeconsuming nature of manual\nprocess analysis. Our paper harnesses Large Language Models (LLMs) to automate\nvalue-added analysis, a qualitative process analysis technique that aims to\nidentify steps in the process that do not deliver value. To date, this\ntechnique is predominantly manual, time-consuming, and subjective. Our method\noffers a more principled approach which operates in two phases: first,\ndecomposing high-level activities into detailed steps to enable granular\nanalysis, and second, performing a value-added analysis to classify each step\naccording to Lean principles. This approach enables systematic identification\nof waste while maintaining the semantic understanding necessary for qualitative\nanalysis. We develop our approach using 50 business process models, for which\nwe collect and publish manual ground-truth labels. Our evaluation, comparing\nzero-shot baselines with more structured prompts reveals (a) a consistent\nbenefit of structured prompting and (b) promising performance for both tasks.\nWe discuss the potential for LLMs to augment human expertise in qualitative\nprocess analysis while reducing the time and subjectivity inherent in manual\napproaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SE","published":"2025-04-09T05:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06617v1","title":"Spectrum radii of trees","summary":"For any positive integer $r$ and positive number $\\alpha$, let ${\\mathscr\nW}_r(\\alpha)$ denote the set of positive numbers defined recursively:\n$\\alpha\\in {\\mathscr W}_r(\\alpha)$, and for any multi-set $\\{q_i\\in {\\mathscr\nW}_r(\\alpha): 1\\le i\\le s\\}$, where $1\\le s<r$,\n$\\beta:=\\alpha-\\sum\\limits_{i=1}^sq_i^{-1}$ belongs to ${\\mathscr W}_r(\\alpha)$\nas long as $\\beta>0$. We first show that there exists a tree $T$ such that its\nmaximum degree $\\Delta(T)$ is at most $r$ and its spectrum radius $\\lambda(T)$\nis equal to $\\alpha$ if and only if $\\alpha^{-1}\\in {\\mathscr W}_r(\\alpha)$. It\nfollows that the set of spectrum radii of non-trivial trees is exactly the set\nof positive numbers $\\alpha$ such that $\\alpha^{-1}\\in {\\mathscr\nW}_{\\lfloor\\alpha^2\\rfloor}(\\alpha)$. Applying this conclusion, we then prove\nthat for any positive integers $r$ and $k$, there exists a tree $T$ with\n$\\Delta(T)=r$ and $\\lambda(T)=\\sqrt k$ if and only if $\\frac 14 k+1<r\\le k$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.06621v1","title":"Computation of shape Taylor expansions","summary":"Shape derivative is an important analytical tool for studying scattering\nproblems involving perturbations in scatterers. Many applications, including\ninverse scattering, optimal design, and uncertainty quantification, are based\non shape derivatives. However, computing high order shape derivatives is\nchallenging due to the complexity of shape calculus. This work introduces a\ncomprehensive method for computing shape Taylor expansions in two dimensions\nusing recurrence formulas. The approach is developed under sound-soft,\nsound-hard, impedance, and transmission boundary conditions. Additionally, we\napply the shape Taylor expansion to uncertainty quantification in wave\nscattering, enabling high order moment estimation for the scattered field under\nrandom boundary perturbations. Numerical examples are provided to illustrate\nthe effectiveness of the shape Taylor expansion in achieving high order\napproximations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T06:42:21Z"}
{"aid":"http://arxiv.org/abs/2504.06624v1","title":"An inverse problem for a nonlinear biharmonic operator","summary":"An inverse problem for a nonlinear biharmonic operator is under consideration\nin the spirit of Isakov (1993) and Johansson-Nurminen-Salo (2023). We prove\nthat a general nonlinear term of the $Q= Q(x,u, \\nabla u, \\Delta u)$ associated\nto a nonlinear biharmonic operator can be recovered from the local Cauchy data\nset. The proof uses first order linearization method, Runge approximation, and\nuniqueness results for the linearized inverse problem.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T06:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.06654v1","title":"Finiteness of projective pluricanonical representation for automorphisms\n  of complex manifolds","summary":"We study the action of the group of bimeromorphic automorphisms\n$\\mathrm{Bim}(X)$ of a compact complex manifold $X$ on the image of the\npluricanonical map, which we call the projective pluricanonical representation\nof this group. If $X$ is a Moishezon variety, then the image of\n$\\mathrm{Bim}(X)$ via such a representation is a finite group by a classical\nresult due to Deligne and Ueno. We prove that this image is a finite group\nunder the assumption that for the Kodaira dimension $\\kappa(X)$ of $X$ we have\n$\\kappa(X)=\\dim X-1$. To this aim, we prove a version of the canonical bundle\nformula in relative dimension $1$ which works for a proper morphism from a\ncomplex variety to a projective variety. In particular, this establishes the\nanalytic version of Prokhorov--Shokurov conjecture in relative dimension $1$.\nAlso, we observe that the analytic version of this conjecture does not hold in\nrelative dimension $2$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-09T07:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.06659v1","title":"Bridging the Gap Between Preference Alignment and Machine Unlearning","summary":"Despite advances in Preference Alignment (PA) for Large Language Models\n(LLMs), mainstream methods like Reinforcement Learning with Human Feedback\n(RLHF) face notable challenges. These approaches require high-quality datasets\nof positive preference examples, which are costly to obtain and computationally\nintensive due to training instability, limiting their use in low-resource\nscenarios. LLM unlearning technique presents a promising alternative, by\ndirectly removing the influence of negative examples. However, current research\nhas primarily focused on empirical validation, lacking systematic quantitative\nanalysis. To bridge this gap, we propose a framework to explore the\nrelationship between PA and LLM unlearning. Specifically, we introduce a\nbi-level optimization-based method to quantify the impact of unlearning\nspecific negative examples on PA performance. Our analysis reveals that not all\nnegative examples contribute equally to alignment improvement when unlearned,\nand the effect varies significantly across examples. Building on this insight,\nwe pose a crucial question: how can we optimally select and weight negative\nexamples for unlearning to maximize PA performance? To answer this, we propose\na framework called Unlearning to Align (U2A), which leverages bi-level\noptimization to efficiently select and unlearn examples for optimal PA\nperformance. We validate the proposed method through extensive experiments,\nwith results confirming its effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T07:49:08Z"}
{"aid":"http://arxiv.org/abs/2504.06669v1","title":"NLP Security and Ethics, in the Wild","summary":"As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T08:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06704v1","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-09T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06718v1","title":"Ice-Breakers, Turn-Takers and Fun-Makers: Exploring Robots for Groups\n  with Teenagers","summary":"Successful, enjoyable group interactions are important in public and personal\ncontexts, especially for teenagers whose peer groups are important for\nself-identity and self-esteem. Social robots seemingly have the potential to\npositively shape group interactions, but it seems difficult to effect such\nimpact by designing robot behaviors solely based on related (human interaction)\nliterature. In this article, we take a user-centered approach to explore how\nteenagers envisage a social robot \"group assistant\". We engaged 16 teenagers in\nfocus groups, interviews, and robot testing to capture their views and\nreflections about robots for groups. Over the course of a two-week summer\nschool, participants co-designed the action space for such a robot and\nexperienced working with/wizarding it for 10+ hours. This experience further\naltered and deepened their insights into using robots as group assistants. We\nreport results regarding teenagers' views on the applicability and use of a\nrobot group assistant, how these expectations evolved throughout the study, and\ntheir repeat interactions with the robot. Our results indicate that each group\nmoves on a spectrum of need for the robot, reflected in use of the robot more\n(or less) for ice-breaking, turn-taking, and fun-making as the situation\ndemanded.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T09:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.06720v1","title":"Revealing the ages of metal-rich RR Lyrae via kinematic label transfer","summary":"RR Lyrae stars have long been considered reliable tracers of old, metal-poor\npopulations, primarily due to their prevalence in globular clusters and the\nGalactic halo. However, the discovery of a metal-rich subpopulation in the\nGalactic disc, kinematically colder and more rotationally supported, challenges\nthis classical view. Understanding the age of these metal-rich RR Lyrae stars\nis crucial for constraining their formation pathways and assessing what\nGalactic populations they are tracing. In this work, we leverage the\nunprecedented astrometric precision of Gaia DR3 to infer the age distribution\nof metal-rich RR Lyrae stars through a kinematic comparison with O-rich Mira\nvariables. Mira variables, with their well-established period-age relation,\nserve as a natural clock, allowing us to transfer age information to RR Lyrae\nstars via their phase-space properties. By applying this approach across\ndifferent metallicity bins, we find that the most metal-rich RR Lyrae stars\n($[\\rm Fe/H] > -0.5$) exhibit kinematics consistent with a population\nsignificantly younger ($\\approx 6-7$ Gyr) than typically assumed for RR Lyrae\nstars. In contrast, those with $-1 < [\\rm Fe/H] < -0.5$ show properties more\naligned with older ($\\approx 9-11$ Gyr) populations. Interestingly, we also\nfind evidence of a possible double age populations for the most metal-rich RR\nLyrae, one younger with ages between 3 and 6 Gyr, and another one older ranging\nfrom 8 to 11 Gyr. These results provide strong evidence that metal-rich RR\nLyrae stars in the Galactic field do not exclusively trace ancient populations.\nThis finding challenges the current model of RR Lyrae formation and supports\nalternative formation scenarios, such as binary evolution.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T09:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.06729v1","title":"Optimal Duration of Reserve Capacity Ancillary Services for Distributed\n  Energy Resources","summary":"The increasing integration of distributed energy resources (DERs) into power\nsystems presents opportunities and challenges for ancillary services (AS)\nprovision. Technical requirements of existing AS (i.e., duration, reliability,\nramp rate, and lead time) have been designed for traditional generating units,\nmaking their provision by DER aggregates particularly challenging. This paper\nproposes a method to design the duration of reserve capacity AS products\nconsidering the operational constraints of DERs and the temporal dynamics of\nsystem imbalances. The optimal product duration is determined by maximizing\nproduct availability and aligning the supply profile with the system's\nbalancing needs. We apply the methodology to a realistic Swiss low-voltage\nnetwork with a diverse DER portfolio. The results reveal that (i) shorter\nproduct durations maximize average availability and (ii) long product durations\nimprove the alignment with system balancing needs. This paper offers valuable\ninsights for system operators to design AS products tailored for DER\nparticipation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T09:37:24Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06746v1","title":"Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning","summary":"Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.","main_category":"cs.MA","categories":"cs.MA,cs.RO","published":"2025-04-09T10:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06770v1","title":"Measuring and predicting galaxy assembly bias across galaxy samples","summary":"One of the most important effects shaping small-scale galaxy clustering is\ngalaxy assembly bias, which refers to the dependence of galaxy clustering on\nhalo properties. We investigate this effect using galaxy samples selected\naccording to stellar mass, r-band magnitude, and broad-band colors from the\nlargest hydrodynamical simulation of the IllustrisTNG suite. We find that\ngalaxy assembly bias depends strongly upon the selection criteria, number\ndensity, and redshift of the sample, increasing or decreasing the clustering by\nas much as 25%. Interestingly, no single secondary halo property fully captures\nthe strength of this effect for any galaxy population. Therefore, empirical\napproaches modeling galaxy assembly bias as a function of a single halo\nproperty cannot reproduce predictions from hydrodynamical simulations. We then\nstudy how galaxy assembly bias emerges from the interplay of halo assembly bias\n-- the dependence of halo clustering on properties other than mass -- and\noccupancy variation -- the correlation between galaxy occupation and secondary\nhalo properties -- and provide an analytical expression that predicts the\namount of galaxy assembly bias caused by any halo property. This expression\nfacilitates understanding the dependence of galaxy assembly bias on halo\nproperties and enables the straightforward incorporation of this effect into\nhalo model approaches.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-09T10:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.06772v1","title":"Towards Efficient Roadside LiDAR Deployment: A Fast Surrogate Metric\n  Based on Entropy-Guided Visibility","summary":"The deployment of roadside LiDAR sensors plays a crucial role in the\ndevelopment of Cooperative Intelligent Transport Systems (C-ITS). However, the\nhigh cost of LiDAR sensors necessitates efficient placement strategies to\nmaximize detection performance. Traditional roadside LiDAR deployment methods\nrely on expert insight, making them time-consuming. Automating this process,\nhowever, demands extensive computation, as it requires not only visibility\nevaluation but also assessing detection performance across different LiDAR\nplacements. To address this challenge, we propose a fast surrogate metric, the\nEntropy-Guided Visibility Score (EGVS), based on information gain to evaluate\nobject detection performance in roadside LiDAR configurations. EGVS leverages\nTraffic Probabilistic Occupancy Grids (TPOG) to prioritize critical areas and\nemploys entropy-based calculations to quantify the information captured by\nLiDAR beams. This eliminates the need for direct detection performance\nevaluation, which typically requires extensive labeling and computational\nresources. By integrating EGVS into the optimization process, we significantly\naccelerate the search for optimal LiDAR configurations. Experimental results\nusing the AWSIM simulator demonstrate that EGVS strongly correlates with\nAverage Precision (AP) scores and effectively predicts object detection\nperformance. This approach offers a computationally efficient solution for\nroadside LiDAR deployment, facilitating scalable smart infrastructure\ndevelopment.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T10:53:03Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06801v1","title":"MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular\n  Detection","summary":"Current monocular 3D detectors are held back by the limited diversity and\nscale of real-world datasets. While data augmentation certainly helps, it's\nparticularly difficult to generate realistic scene-aware augmented data for\noutdoor settings. Most current approaches to synthetic data generation focus on\nrealistic object appearance through improved rendering techniques. However, we\nshow that where and how objects are positioned is just as crucial for training\neffective 3D monocular detectors. The key obstacle lies in automatically\ndetermining realistic object placement parameters - including position,\ndimensions, and directional alignment when introducing synthetic objects into\nactual scenes. To address this, we introduce MonoPlace3D, a novel system that\nconsiders the 3D scene content to create realistic augmentations. Specifically,\ngiven a background scene, MonoPlace3D learns a distribution over plausible 3D\nbounding boxes. Subsequently, we render realistic objects and place them\naccording to the locations sampled from the learned distribution. Our\ncomprehensive evaluation on two standard datasets KITTI and NuScenes,\ndemonstrates that MonoPlace3D significantly improves the accuracy of multiple\nexisting monocular 3D detectors while being highly data efficient.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.06812v1","title":"Semi-classical geometric tensor in multiparameter quantum information","summary":"The quantum geometric tensor (QGT) captures the variations of quantum states\nwith parameters, serving as a central concept in modern quantum physics. Its\nreal part, the quantum Fisher information matrix (QFIM), has a\nmeasurement-dependent counterpart that links statistics to distinguishability.\nHowever, an analogous extension for the QGT is hindered by the fundamental\ninaccessibility of its imaginary part through measurement probabilities. Here\nwe introduce a counterpart to the QGT that includes measurement operators,\ntermed the \\textit{semi-classical} geometric tensor (SCGT). We show that the\nSCGT provides a lower bound to the QGT that is tight for pure states. Moreover,\nwe use the SCGT to derive sharp multiparameter information bounds and discuss\nextensions of the Berry phase.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-09T12:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.06819v1","title":"Developing Modular Grasping and Manipulation Pipeline Infrastructure to\n  Streamline Performance Benchmarking","summary":"The robot manipulation ecosystem currently faces issues with integrating\nopen-source components and reproducing results. This limits the ability of the\ncommunity to benchmark and compare the performance of different solutions to\none another in an effective manner, instead relying on largely holistic\nevaluations. As part of the COMPARE Ecosystem project, we are developing\nmodular grasping and manipulation pipeline infrastructure in order to\nstreamline performance benchmarking. The infrastructure will be used towards\nthe establishment of standards and guidelines for modularity and improved\nopen-source development and benchmarking. This paper provides a high-level\noverview of the architecture of the pipeline infrastructure, experiments\nconducted to exercise it during development, and future work to expand its\nmodularity.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T12:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06843v1","title":"Integrating Cognitive Processing Signals into Language Models: A Review\n  of Advances, Applications and Future Directions","summary":"Recently, the integration of cognitive neuroscience in Natural Language\nProcessing (NLP) has gained significant attention. This article provides a\ncritical and timely overview of recent advancements in leveraging cognitive\nsignals, particularly Eye-tracking (ET) signals, to enhance Language Models\n(LMs) and Multimodal Large Language Models (MLLMs). By incorporating\nuser-centric cognitive signals, these approaches address key challenges,\nincluding data scarcity and the environmental costs of training large-scale\nmodels. Cognitive signals enable efficient data augmentation, faster\nconvergence, and improved human alignment. The review emphasises the potential\nof ET data in tasks like Visual Question Answering (VQA) and mitigating\nhallucinations in MLLMs, and concludes by discussing emerging challenges and\nresearch trends.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06888v1","title":"The Singular CR Yamabe Problem and Hausdorff Dimension","summary":"We consider a compact pseudo-hermitian manifold (M,\\theta, J), that is a\nmanifold equipped with a contact form \\theta and CR structure J. We consider a\nconformal deformation of the contact form to obtain a complete, singular\ncontact form and a corresponding Yamabe problem. We estimate then the Hausdorff\ndimension of the singular set. The conformal geometry analog of this result is\ndue to R. Schoen and S. -T. Yau. Results of this type have their origin in work\nby Huber for Riemann surfaces. In the second part of our paper we investigate\nthe CR developing map for three dimensional CR manifolds. We establish the\ninjectivity of the developing map essentially using the same strategy as Schoen\nand Yau for the conformal case which is based on the positive mass theorem.\nHigher dimensional analogs of Huber's theorem in the conformal case for Q\ncurvature are due to Alice Chang, Jie Qing and P. Yang.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T13:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06897v1","title":"MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs","summary":"This paper presents MedSegFactory, a versatile medical synthesis framework\nthat generates high-quality paired medical images and segmentation masks across\nmodalities and tasks. It aims to serve as an unlimited data repository,\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\nmedical images and the other generates corresponding segmentation masks. To\nensure precise alignment between image-mask pairs, we introduce Joint\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\ncross-conditioning between streams. This bidirectional interaction allows both\nrepresentations to guide each other's generation, enhancing consistency between\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\nimages and segmentation masks through user-defined prompts that specify the\ntarget labels, imaging modalities, anatomical regions, and pathological\nconditions, facilitating scalable and high-quality data generation. This new\nparadigm of medical image synthesis enables seamless integration into diverse\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\nexperiments show that MedSegFactory generates data of superior quality and\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\nsegmentation tasks while addressing data scarcity and regulatory constraints.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T13:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06929v1","title":"Minimal rational graphs admitting a QHD smoothing","summary":"Using the picture deformation technique of De Jong-Van Straten we show that\nno singularity whose resolution graph has 3 or 4 large nodes, i.e., nodes\nsatisfying d(v)+e(v)\\leq -2, has a QHD smoothing. This is achieved by providing\na general reduction algorithm for graphs with QHD smoothings, and enumeration.\nNew examples and families are presented, which admit a combinatorial QHD\nsmoothing, i.e. the incidence relations for a sandwich presentation can be\nsatisfied. We also give a new proof of the Bhupal-Stipsicz theorem on the\nclassification of weighted homogeneous singularities admitting QHD smoothings\nwith this method by using cusp singularities.","main_category":"math.GT","categories":"math.GT,math.AG","published":"2025-04-09T14:36:41Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06946v1","title":"Uniqueness of Lp Minkowski problem in the supercritical range","summary":"The uniqueness of the $L_p$-Minkowski problem has been a long standing\nproblem in convex geometry. In the groundbreaking paper by\nBrendle-Choi-Daskalopoulos (Acta Math, {\\bf219}, 2017), a full uniqueness\nresult was shown for the subcritical exponents $p\\in(-n-1,1]$. In the\nsupercritical range, the uniqueness problem is much more complicated, even in\nthe planar case $n=1$. One of the famous results was shown by Andrews (J. Amer.\nMath. Soc., {\\bf16}, 2003), where he established that the uniqueness holds in\nthe range $p\\in(-7,-2)$ and fails to hold for the other supercritical exponents\n$p\\in(-\\infty,-7)$. In this paper, we study the same uniqueness problem in the\nfull supercritical range $p\\in(-2n-5,-n-1)$ for all higher dimensional cases\n$n\\geq2$. We will prove that for $p\\in(-2n-5,-n-1)$, the unique strongly\nsymmetric solution is given by the unit sphere ${\\mathbb{S}}^n$. The uniqueness\nrange $(-2n-5,-n-1)$ is optimal due to our recent preprint (arXiv: 2104.07426)\njoint with J. Lu and Y.N. Liu, where we have constructed non-spherical strongly\nsymmetric solutions for all $p\\in(-\\infty,-2n-5)$. When considering general\nsolutions without symmetricity assumption, the uniqueness set $\\Gamma$ of $p$\nfor which the uniqueness holds, is shown to be both relatively open and closed\nin the full interval $(-2n-5,-n-1)$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.06948v1","title":"An improved quantum algorithm for linear autonomous differential\n  equations via Padé approximation","summary":"We propose a novel quantum algorithm for solving linear autonomous ordinary\ndifferential equations (ODEs) using the Pad\\'e approximation. For linear\nautonomous ODEs, the discretized solution can be represented by a product of\nmatrix exponentials. The proposed algorithm approximates the matrix exponential\nby the diagonal Pad\\'e approximation, which is then encoded into a large,\nblock-sparse linear system and solved via quantum linear system algorithms\n(QLSA). The detailed quantum circuit is given based on quantum oracle access to\nthe matrix, the inhomogeneous term, and the initial state. The complexity of\nthe proposed algorithm is analyzed. Compared to the method based on Taylor\napproximation, which approximates the matrix exponential using a $k$-th order\nTaylor series, the proposed algorithm improves the approximation order $k$ from\ntwo perspectives: 1) the explicit complexity dependency on $k$ is improved, and\n2) a smaller $k$ suffices for the same precision. Numerical experiments\ndemonstrate the advantages of the proposed algorithm comparing to other related\nalgorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.06984v1","title":"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\n  Theory","summary":"The masses of data now available have opened up the prospect of discovering\nweak signals using machine-learning algorithms, with a view to predictive or\ninterpretation tasks. As this survey of recent results attempts to show,\nbringing multivariate extreme value theory and statistical learning theory\ntogether in a common, non-parametric and non-asymptotic framework makes it\npossible to design and analyze new methods for exploiting the scarce\ninformation located in distribution tails in these purposes. This article\nreviews recently proved theoretical tools for establishing guarantees for\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\nThese are mainly exponential maximal deviation inequalities tailored to\nlow-probability regions and concentration results for stochastic processes\nempirically describing the behavior of extreme observations, their dependence\nstructure in particular. Under appropriate assumptions of regular variation,\nseveral illustrative applications are then examined: classification,\nregression, anomaly detection, model selection via cross-validation. For these,\ngeneralization results are established inspired by the classical bounds in\nstatistical learning theory. In the same spirit, it is also shown how to adapt\nthe popular high-dimensional lasso technique in the context of extreme values\nfor the covariates with generalization guarantees.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T15:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.06986v1","title":"Solving \"pseudo-injective\" polynomial equations over finite dynamical\n  systems","summary":"We consider the semiring of abstract finite dynamical systems up to\nisomorphism, with the operations of alternative and synchronous execution. We\ncontinue searching for efficient algorithms for solving polynomial equations of\nthe form $P(X) = B$, with a constant side B, with the goal of decomposing\ncomplex behaviors into simpler systems. Taking inspiration from the\ncharacterization of injective polynomials P over dynamical systems, which is\nbased on a condition on the lengths of limit cycles of their coefficients, we\nintroduce a more general notion of pseudo-injectivity by relaxing this\nconstraint. We prove that the associated equations can be solved efficiently,\neven in certain cases where the input is encoded in an exponentially more\ncompact way.","main_category":"cs.DM","categories":"cs.DM,math.DS","published":"2025-04-09T15:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07020v1","title":"Computably discrete represented spaces","summary":"In computable topology, a represented space is called computably discrete if\nits equality predicate is semidecidable. While any such space is classically\nisomorphic to an initial segment of the natural numbers, the\ncomputable-isomorphism types of computably discrete represented spaces exhibit\na rich structure. We show that the widely studied class of computably\nenumerable equivalence relations (ceers) corresponds precisely to the\ncomputably Quasi-Polish computably discrete spaces. We employ computably\ndiscrete spaces to exhibit several separating examples in computable topology.\nWe construct a computably discrete computably Quasi-Polish space admitting no\ndecidable properties, a computably discrete and computably Hausdorff\nprecomputably Quasi-Polish space admitting no computable injection into the\nnatural numbers, a two-point space which is computably Hausdorff but not\ncomputably discrete, and a two-point space which is computably discrete but not\ncomputably Hausdorff. We further expand an example due to Weihrauch that\nseparates computably regular spaces from computably normal spaces.","main_category":"math.LO","categories":"math.LO,cs.LO,math.GN","published":"2025-04-09T16:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07031v1","title":"Identifying Key Challenges of Hardness-Based Resampling","summary":"Performance gap across classes remains a persistent challenge in machine\nlearning, often attributed to variations in class hardness. One way to quantify\nclass hardness is through sample complexity - the minimum number of samples\nrequired to effectively learn a given class. Sample complexity theory suggests\nthat class hardness is driven by differences in the amount of data required for\ngeneralization. That is, harder classes need substantially more samples to\nachieve generalization. Therefore, hardness-based resampling is a promising\napproach to mitigate these performance disparities. While resampling has been\nstudied extensively in data-imbalanced settings, its impact on balanced\ndatasets remains unexplored.\n  This raises the fundamental question whether resampling is effective because\nit addresses data imbalance or hardness imbalance. We begin addressing this\nquestion by introducing class imbalance into balanced datasets and evaluate its\neffect on performance disparities. We oversample hard classes and undersample\neasy classes to bring hard classes closer to their sample complexity\nrequirements while maintaining a constant dataset size for fairness. We\nestimate class-level hardness using the Area Under the Margin (AUM) hardness\nestimator and leverage it to compute resampling ratios. Using these ratios, we\nperform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100\ndatasets.\n  Contrary to theoretical expectations, our results show that hardness-based\nresampling does not meaningfully affect class-wise performance disparities. To\nexplain this discrepancy, we conduct detailed analyses to identify key\nchallenges unique to hardness-based imbalance, distinguishing it from\ntraditional data-based imbalance. Our insights help explain why theoretical\nsample complexity expectations fail to translate into practical performance\ngains and we provide guidelines for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.07035v1","title":"Classification results for totally real surfaces of nearly Kähler\n  $\\mathbb{C}P^3$","summary":"Totally real surfaces in the nearly K\\\"ahler $\\mathbb{C}P^3$ are investigated\nand are completely classified under various additional assumptions, resulting\nin multiple new examples. Among others, the classification includes totally\nreal surfaces that are extrinsically homogeneous; or minimal; or totally\numbilical; or Codazzi-like (including parallel and non-parallel examples).","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T16:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.07042v1","title":"Towards a Higher Roofline for Matrix-Vector Multiplication in\n  Matrix-Free HOSFEM","summary":"The high-order/spectral finite element method (HOSFEM) is a widely used\nnumerical method for solving PDEs, with its performance primarily relying on\naxhelm, a matrix-free kernel for element-local matrix-vector multiplications.\nIn axhelm, geometric factors account for over half of memory access but\nminimally contribute to computational workload. This imbalance significantly\nconstrains the performance roofline, indicating that further optimization of\ntensor contraction, the core computation in axhelm, yields only minimal\nimprovements. To overcome this bottleneck, we propose a low-cost on-the-fly\nrecalculation of geometric factors for trilinear elements, thereby unlocking\nsubstantial potential for optimizing tensor contraction. The proposed approach\nis implemented in Nekbone, a standard HOSFEM benchmark. With optimizations such\nas merging scalar factors, partial recalculation, Tensor Core acceleration, and\nconstant memory utilization, performance reaches 85%-100% of the higher\nroofline. The optimized kernels achieve speedups of 1.74x-4.10x on NVIDIA A100\nand 1.99x-3.77x on DCU K100. This leads to a 1.12x-1.40x speedup for Nekbone.","main_category":"cs.PF","categories":"cs.PF,cs.MS","published":"2025-04-09T17:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Π$-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07069v1","title":"HalluciNot: Hallucination Detection Through Context and Common Knowledge\n  Verification","summary":"This paper introduces a comprehensive system for detecting hallucinations in\nlarge language model (LLM) outputs in enterprise settings. We present a novel\ntaxonomy of LLM responses specific to hallucination in enterprise applications,\ncategorizing them into context-based, common knowledge, enterprise-specific,\nand innocuous statements. Our hallucination detection model HDM-2 validates LLM\nresponses with respect to both context and generally known facts (common\nknowledge). It provides both hallucination scores and word-level annotations,\nenabling precise identification of problematic content. To evaluate it on\ncontext-based and common-knowledge hallucinations, we introduce a new dataset\nHDMBench. Experimental results demonstrate that HDM-2 out-performs existing\napproaches across RagTruth, TruthfulQA, and HDMBench datasets. This work\naddresses the specific challenges of enterprise deployment, including\ncomputational efficiency, domain specialization, and fine-grained error\nidentification. Our evaluation dataset, model weights, and inference code are\npublicly available.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T17:39:41Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07083v1","title":"GenDoP: Auto-regressive Camera Trajectory Generation as a Director of\n  Photography","summary":"Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07417v1","title":"Secure Directional Modulation with Movable Antenna Array Aided by RIS","summary":"In this paper, to fully exploit the performance gains from moveable antennas\n(MAs) and reconfigurable intelligent surface (RIS), a RIS-aided directional\nmodulation \\textcolor{blue}{(DM)} network with movable antenna at base station\n(BS) is established Based on the principle of DM, a BS equipped with MAs\ntransmits legitimate information to a single-antenna user (Bob) while\nexploiting artificial noise (AN) to degrade signal reception at the\neavesdropper (Eve). The combination of AN and transmission beamforming vectors\nis modeled as joint beamforming vector (JBV) to achieve optimal power\nallocation. The objective is to maximize the achievable secrecy rate (SR) by\noptimizing MAs antenna position, phase shift matrix (PSM) of RIS, and JBV. The\nlimited movable range (MR) and discrete candidate positions of the MAs at the\nBS are considered, which renders the optimization problem non-convex. To\naddress these challenges, an optimization method under perfect channel state\ninformation (CSI) is firstly designed, in which the MAs antenna positions are\nobtained using compressive sensing (CS) technology, and JBV and PSM are\niteratively optimized. Then, the design method and SR performance under\nimperfect CSI is investigated. The proposed algorithms have fewer iterations\nand lower complexity. Simulation results demonstrate that MAs outperform\nfixed-position antennas in SR performance when there is an adequately large MR\navailable.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T03:14:30Z"}
{"aid":"http://arxiv.org/abs/2504.07430v1","title":"Nonlinear Optimal Guidance for Intercepting Moving Targets","summary":"This paper introduces a nonlinear optimal guidance framework for guiding a\npursuer to intercept a moving target, with an emphasis on real-time generation\nof optimal feedback control for a nonlinear optimal control problem. Initially,\nconsidering the target moves without maneuvering, we derive the necessary\noptimality conditions using Pontryagin's Maximum Principle. These conditions\nreveal that each extremal trajectory is uniquely determined by two scalar\nparameters. Analyzing the geometric property of the parameterized extremal\ntrajectories not only leads to an additional necessary condition but also\nallows to establish a sufficient condition for local optimality. This enables\nthe generation of a dataset containing at least locally optimal trajectories.\nBy studying the properties of the optimal feedback control, the size of the\ndataset is reduced significantly, allowing training a lightweight neural\nnetwork to predict the optimal guidance command in real time. Furthermore, the\nperformance of the neural network is enhanced by incorporating the target's\nacceleration, making it suitable for intercepting both uniformly moving and\nmaneuvering targets. Finally, numerical simulations validate the proposed\nnonlinear optimal guidance framework, demonstrating its better performance over\nexisting guidance laws.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T03:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.07443v1","title":"Optoelectronic properties of self-trapped holes in orthorhombic Ga2O3\n  and its alloys","summary":"We investigated the influence of valence band holes on the optoelectronic\nproperties of orthorhombic k-Ga2O3 and its alloys with Al and In. Our hybrid\ndensity functional theory calculations show that self-trapped holes (STHs)\nlocalize on oxygen atoms within a single unit cell and exhibit \\emph{p}-orbital\ncharacteristics. The inclusion of isoelectronic dopants such as Al and In\nreduces but does not remove the absorption of visible light due to STH\nformation. The combination of a positive STH formation energy, large lattice\ndistortions, and emergent acceptor levels, coupled with the observed\nred-shifted, visible spectrum, emergent absorption peaks, implies that\nalternative doping/alloying strategies are necessary to achieve effective\np-type conductivity in orthorhombic k-Ga2O3.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07466v1","title":"Personalized and Demand-Based Education Concept: Practical Tools for\n  Control Engineers","summary":"This paper presents a personalized lecture concept using educational blocks\nand its demonstrative application in a new university lecture. Higher education\nfaces daily challenges: deep and specialized knowledge is available from\neverywhere and accessible to almost everyone. University lecturers of\nspecialized master courses confront the problem that their lectures are either\ntoo boring or too complex for the attending students. Additionally, curricula\nare changing more rapidly than they have in the past 10-30 years. The German\neducation system comprises different educational forms, with universities\nproviding less practical content. Consequently, many university students do not\nobtain the practical skills they should ideally gain through university\nlectures. Therefore, in this work, a new lecture concept is proposed based on\nthe extension of the just-in-time teaching paradigm: Personalized and\nDemand-Based Education. This concept includes: 1) an initial assessment of\nstudents' backgrounds, 2) selecting the appropriate educational blocks, and 3)\ncollecting ongoing feedback during the semester. The feedback was gathered via\nPingo, ensuring anonymity for the students. Our concept was exemplarily tested\nin the new lecture \"Practical Tools for Control Engineers\" at the Karlsruhe\nInstitute of Technology. The initial results indicate that our proposed concept\ncould be beneficial in addressing the current challenges in higher education.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,K.3.1","published":"2025-04-10T05:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.07468v1","title":"Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from\n  Imbalanced Chest X-Ray Datasets","summary":"This paper proposes a novel pooling-based VGG-Lite model in order to mitigate\nclass imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia\ndetection from CXR images by deep learning model has emerged as a prominent and\ndynamic area of research, since the inception of the new Covid-19 variant in\n2020. However, the standard Convolutional Neural Network (CNN) models encounter\nchallenges associated with class imbalance, a prevalent issue found in many\nmedical datasets. The innovations introduced in the proposed model architecture\ninclude: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base\nmodel, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this\nbase model, we leverage an ``Edge Enhanced Module (EEM)\" through a parallel\nbranch, consisting of a ``negative image layer\", and a novel custom pooling\nlayer ``2Max-Min Pooling\". This 2Max-Min Pooling layer is entirely novel in\nthis investigation, providing more attention to edge components within\npneumonia CXR images. Thus, it works as an efficient spatial attention module\n(SAM). We have implemented the proposed framework on two separate CXR datasets.\nThe first dataset is obtained from a readily available source on the internet,\nand the second dataset is a more challenging CXR dataset, assembled by our\nresearch team from three different sources. Experimental results reveal that\nour proposed framework has outperformed pre-trained CNN models, and three\nrecent trend existing models ``Vision Transformer\", ``Pooling-based Vision\nTransformer (PiT)'' and ``PneuNet\", by substantial margins on both datasets.\nThe proposed framework VGG-Lite with EEM, has achieved a macro average of 95%\naccuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia\nImbalance CXR dataset\", without employing any pre-processing technique.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T05:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.07471v1","title":"Traversal Learning Coordination For Lossless And Efficient Distributed\n  Learning","summary":"In this paper, we introduce Traversal Learning (TL), a novel approach\ndesigned to address the problem of decreased quality encountered in popular\ndistributed learning (DL) paradigms such as Federated Learning (FL), Split\nLearning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an\naccuracy drop during aggregation due to its averaging function, while SL and\nSFL face increased loss due to the independent gradient updates on each split\nnetwork. TL adopts a unique strategy where the model traverses the nodes during\nforward propagation (FP) and performs backward propagation (BP) on the\norchestrator, effectively implementing centralized learning (CL) principles\nwithin a distributed environment. The orchestrator is tasked with generating\nvirtual batches and planning the sequential node visits of the model during FP,\naligning them with the ordered index of the data within these batches. We\nconducted experiments on six datasets representing diverse characteristics\nacross various domains. Our evaluation demonstrates that TL is on par with\nclassic CL approaches in terms of accurate inference, thereby offering a viable\nand robust solution for DL tasks. TL outperformed other DL methods and improved\naccuracy by 7.85% for independent and identically distributed (IID) datasets,\nmacro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text\nclassification, and AUC by 3.88% and 4.54% for medical and financial datasets,\nrespectively. By effectively preserving data privacy while maintaining\nperformance, TL represents a significant advancement in DL methodologies.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-10T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.07488v1","title":"Mass-subcritical Half-Wave Equation with mixed nonlinearities: existence\n  and non-existence of ground states","summary":"We consider the problem of existence of constrained minimizers for the\nfocusing mass-subcritical Half-Wave equation with a defocusing mass-subcritical\nperturbation. We show the existence of a critical mass such that minimizers do\nexist for any mass larger than or equal to the critical one, and do not exist\nbelow it. At the dynamical level, in the one dimensional case, we show that the\nground states are orbitally stable.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-10T06:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.07497v1","title":"Quantum Determinant Estimation","summary":"A quantum algorithm for computing the determinant of a unitary matrix $U\\in\nU(N)$ is given. The algorithm requires no preparation of eigenstates of $U$ and\nestimates the phase of the determinant to $t$ binary digits accuracy with\n$\\mathcal{O}(N\\log^2 N+t^2)$ operations and $tN$ controlled applications of\n$U^{2^m}$ with $m=0,\\ldots,t-1$. For an orthogonal matrix $O\\in O(N)$ the\nalgorithm can determine with certainty the sign of the determinant using\n$\\mathcal{O}(N\\log^2 N)$ operations and $N$ controlled applications of $O$. An\nextension of the algorithm to contractions is discussed.","main_category":"quant-ph","categories":"quant-ph,hep-lat","published":"2025-04-10T06:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07521v1","title":"Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal\n  Large Language Models","summary":"Most existing emotion analysis emphasizes which emotion arises (e.g., happy,\nsad, angry) but neglects the deeper why. We propose Emotion Interpretation\n(EI), focusing on causal factors-whether explicit (e.g., observable objects,\ninterpersonal interactions) or implicit (e.g., cultural context, off-screen\nevents)-that drive emotional responses. Unlike traditional emotion recognition,\nEI tasks require reasoning about triggers instead of mere labeling. To\nfacilitate EI research, we present EIBench, a large-scale benchmark\nencompassing 1,615 basic EI samples and 50 complex EI samples featuring\nmultifaceted emotions. Each instance demands rationale-based explanations\nrather than straightforward categorization. We further propose a Coarse-to-Fine\nSelf-Ask (CFSA) annotation pipeline, which guides Vision-Language Models\n(VLLMs) through iterative question-answer rounds to yield high-quality labels\nat scale. Extensive evaluations on open-source and proprietary large language\nmodels under four experimental settings reveal consistent performance\ngaps-especially for more intricate scenarios-underscoring EI's potential to\nenrich empathetic, context-aware AI applications. Our benchmark and methods are\npublicly available at: https://github.com/Lum1104/EIBench, offering a\nfoundation for advanced multimodal causal analysis and next-generation\naffective computing.","main_category":"cs.AI","categories":"cs.AI,cs.MM","published":"2025-04-10T07:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.07525v1","title":"Non triviality of the percolation threshold and Gumbel fluctuations for\n  Branching Interlacements","summary":"We consider the model of Branching Interlacements, introduced by Zhu, which\nis a natural analogue of Sznitman's Random Interlacements model, where the\nrandom walk trajectories are replaced by ranges of some suitable tree-indexed\nrandom walks. We first prove a basic decorrelation inequality for events\ndepending on the state of the field on distinct boxes. We then show that in all\nrelevant dimensions, the vacant set undergoes a nontrivial phase transition\nregarding the existence of an infinite connected component. Finally we obtain\nthe Gumbel fluctuations for the cover level of finite sets, which is analogous\nto Belius' result in the setting of Random Interlacements.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T07:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07527v1","title":"Supervised Optimism Correction: Be Confident When LLMs Are Sure","summary":"In this work, we establish a novel theoretical connection between supervised\nfine-tuning and offline reinforcement learning under the token-level Markov\ndecision process, revealing that large language models indeed learn an implicit\n$Q$-function for inference. Through this theoretical lens, we demonstrate that\nthe widely used beam search method suffers from unacceptable over-optimism,\nwhere inference errors are inevitably amplified due to inflated $Q$-value\nestimations of suboptimal steps. To address this limitation, we propose\nSupervised Optimism Correction(SOC), which introduces a simple yet effective\nauxiliary loss for token-level $Q$-value estimations during supervised\nfine-tuning. Specifically, the auxiliary loss employs implicit value\nregularization to boost model confidence in expert-demonstrated responses,\nthereby suppressing over-optimism toward insufficiently supervised responses.\nExtensive experiments on mathematical reasoning benchmarks, including GSM8K,\nMATH, and GAOKAO, showcase the superiority of the proposed SOC with beam search\nacross a series of open-source models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T07:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.07531v1","title":"A taxonomy of epistemic injustice in the context of AI and the case for\n  generative hermeneutical erasure","summary":"Whether related to machine learning models' epistemic opacity, algorithmic\nclassification systems' discriminatory automation of testimonial prejudice, the\ndistortion of human beliefs via the 'hallucinations' of generative AI, the\ninclusion of the global South in global AI governance, the execution of\nbureaucratic violence via algorithmic systems, or located in the interaction\nwith conversational artificial agents epistemic injustice related to AI is a\ngrowing concern. Based on a proposed general taxonomy of epistemic injustice,\nthis paper first sketches a taxonomy of the types of epistemic injustice in the\ncontext of AI, relying on the work of scholars from the fields of philosophy of\ntechnology, political philosophy and social epistemology. Secondly, an\nadditional perspective on epistemic injustice in the context of AI: generative\nhermeneutical erasure. I argue that this injustice that can come about through\nthe application of Large Language Models (LLMs) and contend that generative AI,\nwhen being deployed outside of its Western space of conception, can have\neffects of conceptual erasure, particularly in the epistemic domain, followed\nby forms of conceptual disruption caused by a mismatch between AI system and\nthe interlocutor in terms of conceptual frameworks. AI systems' 'view from\nnowhere' epistemically inferiorizes non-Western epistemologies and thereby\ncontributes to the erosion of their epistemic particulars, gradually\ncontributing to hermeneutical erasure. This work's relevance lies in proposal\nof a taxonomy that allows epistemic injustices to be mapped in the AI domain\nand the proposal of a novel form of AI-related epistemic injustice.","main_category":"cs.AI","categories":"cs.AI,cs.CY,K.4","published":"2025-04-10T07:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07562v1","title":"ReXCL: A Tool for Requirement Document Extraction and Classification","summary":"This paper presents the ReXCL tool, which automates the extraction and\nclassification processes in requirement engineering, enhancing the software\ndevelopment lifecycle. The tool features two main modules: Extraction, which\nprocesses raw requirement documents into a predefined schema using heuristics\nand predictive modeling, and Classification, which assigns class labels to\nrequirements using adaptive fine-tuning of encoder-based models. The final\noutput can be exported to external requirement engineering tools. Performance\nevaluations indicate that ReXCL significantly improves efficiency and accuracy\nin managing requirements, marking a novel approach to automating the\nschematization of semi-structured requirement documents.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-10T08:46:54Z"}
{"aid":"http://arxiv.org/abs/2504.07573v1","title":"Additive diameters of group representations","summary":"We explore the concept of additive diameters in the context of group\nrepresentations, unifying various noncommutative Waring-type problems. Given a\nfinite-dimensional representation $\\rho \\colon G \\to \\mathrm{GL}(V)$ and a\nsubspace $U \\leq V$ that generates $V$ as a $G$-module, we define the\n$G$-additive diameter of $V$ with respect to $U$ as the minimal number of\ntranslates of $U$ under the representation $\\rho$ needed to cover $V$. We\ndemonstrate that every irreducible representation of\n$\\mathrm{SL}_2(\\mathbf{C})$ exhibits optimal additive diameters and establish\nsharp bounds for the conjugation representation of $\\mathrm{SL}_n(\\mathbf{C})$\non its Lie algebra $\\mathfrak{sl}_n(\\mathbf{C})$. Additionally, we investigate\nanalogous notions for additive diameters in Lie representations. We provide\napplications to additive diameters with respect to images of equivariant\nalgebraic morphisms, linking them to the corresponding $G$-additive diameters\nof images of their differentials.","main_category":"math.RT","categories":"math.RT,math.AG,math.GR,math.RA","published":"2025-04-10T09:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.07576v1","title":"An exceptional story: Symmetries and dualities between Maximal\n  supergravity and General relativity","summary":"We present the historical path from General relativity to the construction of\nMaximal $\\mathcal{N}_4 = 8$ Supergravity with a detour in D=10 and 11\ndimensions. The supergravities obtained by toric dimensional reduction and/or\nby reducing the number of supersymmetry generators have large exceptional\nduality symmetry groups and exhibit a remarkably uniform pattern across all\nvalues of $\\mathcal{N}_D$ and D. In particular (bosonic) General relativity\nfits in as the simplest case and anchors us to the Real world. Dimensional\nreduction to 2 dimensions brings us to affine Kac-Moody groups and their\nsemi-direct products with a real form of the Witt algebra: there is \"integrable\nMagics\". Integrability of 4D Gravity and of its reduction to 2D is considered\nwith their \"Twisted self-duality\". Hyperbolic Kac-Moody symmetries appear after\nreduction to 1D: this leads to \"chaotic Magics\". We then discover\n\"Borcherds\"-Kac-Moody symmetries that allow us to rewrite in any dimension all\nmatter equations of motion as Twisted self-duality: \"Algebraic geometric\nMagics\". Finally a \"BF\" metasymmetry $\\Sigma$ exchanges negative quartets of\nFermionic dimensions with Bosonic ones inside two Magic triangles. A third\nubiquitous triangle of symmetries from Invariant theory resists unification\ndespite its strong resemblance to the others. The prospective remarks include\nseven Challenges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T09:20:24Z"}
{"aid":"http://arxiv.org/abs/2504.07586v1","title":"A perspective on totally geodesic submanifolds of the symmetric space\n  $G_2/SO(4)$","summary":"We provide an independent proof of the classification of the maximal totally\ngeodesic submanifolds of the symmetric spaces $G_2$ and $G_2/SO(4)$, jointly\nwith very natural descriptions of all of these submanifolds. The description of\nthe totally geodesic submanifolds of $G_2$ is in terms of (1) principal\nsubalgebras of $\\mathfrak{g}_2$; (2) stabilizers of nonzero points of\n$\\mathbb{R}^7$; (3) stabilizers of associative subalgebras; (4) the set of\norder two elements in $G_2$ (and its translations). The space $G_2/SO(4)$ is\nidentified with the set of associative subalgebras of $\\mathbb{R}^7$ and its\nmaximal totally geodesic submanifolds can be described as the associative\nsubalgebras adapted to a fixed principal subalgebra, the associative\nsubalgebras orthogonal to a fixed nonzero vector, the associative subalgebras\ncontaining a fixed nonzero vector, and the associative subalgebras intersecting\nboth a fixed associative subalgebra and its orthogonal. A second description is\nincluded in terms of Grassmannians, the advantage of which is that the\nassociated Lie triple systems are easily described in matrix form.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T09:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.07592v1","title":"Hardness of 4-Colourings G-Colourable Graphs","summary":"We study the complexity of a class of promise graph homomorphism problems.\nFor a fixed graph H, the H-colouring problem is to decide whether a given graph\nhas a homomorphism to H. By a result of Hell and Ne\\v{s}et\\v{r}il, this problem\nis NP-hard for any non-bipartite loop-less graph H. Brakensiek and Guruswami\n[SODA 2018] conjectured the hardness extends to promise graph homomorphism\nproblems as follows: fix a pair of non-bipartite loop-less graphs G, H such\nthat there is a homomorphism from G to H, it is NP-hard to distinguish between\ngraphs that are G-colourable and those that are not H-colourable. We confirm\nthis conjecture in the cases when both G and H are 4-colourable. This is a\ncommon generalisation of previous results of Khanna, Linial, and Safra [Comb.\n20(3): 393-415 (2000)] and of Krokhin and Opr\\v{s}al [FOCS 2019]. The result is\nobtained by combining the algebraic approach to promise constraint satisfaction\nwith methods of topological combinatorics and equivariant obstruction theory.","main_category":"cs.CC","categories":"cs.CC,math.AT,math.CO","published":"2025-04-10T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07626v1","title":"Upper bounds of focusing light through multimode fibers","summary":"Wavefront shaping enables precise control of light propagation through\nmultimode fibers, facilitating diffraction-limited focusing for applications\nsuch as high-resolution single-fiber imaging and high-power fiber amplifiers.\nWhile the theoretical intensity enhancement at the focal point is dictated by\nthe number of input degrees of freedom, practical constraints such as\nphase-only modulation and experimental noise impose significant limitations.\nDespite its importance, the upper bounds of enhancement under these constraints\nremain largely unexplored. In this work, we establish a theoretical framework\nto predict the fundamental limits of intensity enhancement with phase-only\nmodulation in the presence of noise-induced phase errors, and we experimentally\ndemonstrate wavefront shaping that approaches these limits. Our experimental\nresults confirm an enhancement factor of 5,000 in a large-core multimode fiber,\napproaching the theoretical upper bound, enabled by noise-tolerant wavefront\nshaping. These findings provide key insights into the limits of phase-only\ncontrol in multimode fibers, with profound implications for single-fiber\nimaging, optical communication, high-power broad-area fiber amplification, and\nbeyond.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-10T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.07635v1","title":"Generative Artificial Intelligence for Internet of Things Computing: A\n  Systematic Survey","summary":"The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T10:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.07652v1","title":"Categorical Unsupervised Variational Acoustic Clustering","summary":"We propose a categorical approach for unsupervised variational acoustic\nclustering of audio data in the time-frequency domain. The consideration of a\ncategorical distribution enforces sharper clustering even when data points\nstrongly overlap in time and frequency, which is the case for most datasets of\nurban acoustic scenes. To this end, we use a Gumbel-Softmax distribution as a\nsoft approximation to the categorical distribution, allowing for training via\nbackpropagation. In this settings, the softmax temperature serves as the main\nmechanism to tune clustering performance. The results show that the proposed\nmodel can obtain impressive clustering performance for all considered datasets,\neven when data points strongly overlap in time and frequency.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-10T11:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.07654v1","title":"ms-Mamba: Multi-scale Mamba for Time-Series Forecasting","summary":"The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T11:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.07661v1","title":"Unveiling the Impact of Multimodal Features on Chinese Spelling\n  Correction: From Analysis to Design","summary":"The Chinese Spelling Correction (CSC) task focuses on detecting and\ncorrecting spelling errors in sentences. Current research primarily explores\ntwo approaches: traditional multimodal pre-trained models and large language\nmodels (LLMs). However, LLMs face limitations in CSC, particularly\nover-correction, making them suboptimal for this task. While existing studies\nhave investigated the use of phonetic and graphemic information in multimodal\nCSC models, effectively leveraging these features to enhance correction\nperformance remains a challenge. To address this, we propose the Multimodal\nAnalysis for Character Usage (\\textbf{MACU}) experiment, identifying potential\nimprovements for multimodal correctison. Based on empirical findings, we\nintroduce \\textbf{NamBert}, a novel multimodal model for Chinese spelling\ncorrection. Experiments on benchmark datasets demonstrate NamBert's superiority\nover SOTA methods. We also conduct a comprehensive comparison between NamBert\nand LLMs, systematically evaluating their strengths and limitations in CSC. Our\ncode and model are available at https://github.com/iioSnail/NamBert.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T11:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.07667v1","title":"S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion","summary":"The generalization of learning-based high dynamic range (HDR) fusion is often\nlimited by the availability of training data, as collecting large-scale HDR\nimages from dynamic scenes is both costly and technically challenging. To\naddress these challenges, we propose S2R-HDR, the first large-scale\nhigh-quality synthetic dataset for HDR fusion, with 24,000 HDR samples. Using\nUnreal Engine 5, we design a diverse set of realistic HDR scenes that encompass\nvarious dynamic elements, motion types, high dynamic range scenes, and\nlighting. Additionally, we develop an efficient rendering pipeline to generate\nrealistic HDR images. To further mitigate the domain gap between synthetic and\nreal-world data, we introduce S2R-Adapter, a domain adaptation designed to\nbridge this gap and enhance the generalization ability of models. Experimental\nresults on real-world datasets demonstrate that our approach achieves\nstate-of-the-art HDR reconstruction performance. Dataset and code will be\navailable at https://openimaginglab.github.io/S2R-HDR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T11:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07714v1","title":"Quasi-Periodic Pulsations in Ionospheric TEC Synchronized with Solar\n  Flare EUV Emission","summary":"The extreme ultraviolet (EUV) and X-ray radiation emitted during solar flares\nhas been shown to significantly increase the electron density of the Earth's\nionosphere. During flares, quasi-periodic pulsations (QPPs) in X-ray flux\noriginating in the corona have previously been linked to subsequent pulsations\nin the Earth's ionospheric D-region. Similar pulsations have been detected in\nchromospheric EUV emission, although their impact on the Earth's ionosphere has\nnot previously been investigated. Here, for the first time, synchronous\npulsations were detected in solar EUV emission and ionospheric Total Electron\nContent (TEC) measurements. Using wavelet and periodogram analysis, we detect\nQPPs with approximately 85 second periods in chromospheric EUV emission lines\n(He II 304 \\AA{}, C III 977 \\AA{} and H I 972 \\AA{}) from the Solar Dynamics\nObservatory Extreme Ultraviolet Variability Experiment (SDO/EVE) during the\nimpulsive phase of an X5.4 flare on March 7, 2012. These lines contribute to\nionization in the ionospheric E- and F-regions, resulting in subsequent\nvariations of electron density with the same periodicity, which was detected in\nTEC measurements. This work demonstrates that the Earth's ionosphere is\nresponsive to fine-scale fluctuations in EUV emission during flares, with a\ntime delay of approximately 30 seconds found. These findings may have\napplications in atmospheric modelling and solar-terrestrial studies, including\nthe calculation of ionospheric recombination rates.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-10T13:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.07725v1","title":"Approximation Algorithms for Connected Maximum Coverage, Minimum\n  Connected Set Cover, and Node-Weighted Group Steiner Tree","summary":"In the Connected Budgeted maximum Coverage problem (CBC), we are given a\ncollection of subsets $\\mathcal{S}$, defined over a ground set $X$, and an\nundirected graph $G=(V,E)$, where each node is associated with a set of\n$\\mathcal{S}$. Each set in $\\mathcal{S}$ has a different cost and each element\nof $X$ gives a different prize. The goal is to find a subcollection\n$\\mathcal{S}'\\subseteq \\mathcal{S}$ such that $\\mathcal{S}'$ induces a\nconnected subgraph in $G$, the total cost of the sets in $\\mathcal{S}'$ does\nnot exceed a budget $B$, and the total prize of the elements covered by\n$\\mathcal{S}'$ is maximized. The Directed rooted Connected Budgeted maximum\nCoverage problem (DCBC) is a generalization of CBC where the underlying graph\n$G$ is directed and in the subgraph induced by $\\mathcal{S}'$ in $G$ must be an\nout-tree rooted at a given node.\n  The current best algorithms achieve approximation ratios that are linear in\nthe size of $G$ or depend on $B$. In this paper, we provide two algorithms for\nCBC and DCBC that guarantee approximation ratios of\n$O\\left(\\frac{\\log^2|X|}{\\epsilon^2}\\right)$ and\n$O\\left(\\frac{\\sqrt{|V|}\\log^2|X|}{\\epsilon^2}\\right)$, resp., with a budget\nviolation of a factor $1+\\epsilon$, where $\\epsilon\\in (0,1]$.\n  Our algorithms imply improved approximation factors of other related\nproblems. For the particular case of DCBC where the prize function is additive,\nwe improve from $O\\left(\\frac{1}{\\epsilon^2}|V|^{2/3}\\log|V|\\right)$ to\n$O\\left(\\frac{1}{\\epsilon^2}|V|^{1/2}\\log^2|V|\\right)$. For the minimum\nconnected set cover, a minimization version of CBC, and its directed variant,\nwe obtain approximation factors of $O(\\log^3|X|)$ and $O(\\sqrt{|V|}\\log^3|X|)$,\nresp. For the Node-Weighted Group Steiner Tree and and its directed variant, we\nobtain approximation factors of $O(\\log^3k)$ and $O(\\sqrt{|V|}\\log^3k)$, resp.,\nwhere $k$ is the number of groups.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-10T13:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07730v1","title":"Thermodynamics of Reissner-nordstorm black bounce black hole","summary":"Our study focuses on the thermodynamics of Reissner-nordstorm black bounce\nblack hole,we have determined the thermodynamic parameters including entropy,\nmass, temperature, heat capacity and free energies and investigated how those\nparameters are related to entropy and for some insights we additionally focused\non the P V isotherm and the logarithmic correction to the entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.07737v1","title":"Statistics of power and efficiency for collisional Brownian engines","summary":"Collisional Brownian engines have attracted significant attention due to\ntheir simplicity, experimental accessibility, and amenability to exact\nanalytical solutions. While previous research has predominantly focused on\noptimizing mean values of power and efficiency, the joint statistical\nproperties of these performance metrics remain largely unexplored. Using\nstochastic thermodynamics, we investigate the joint probability distributions\nof power and efficiency for collisional Brownian engines, revealing how\nthermodynamic fluctuations influence the probability of observing values\nexceeding their respective mean maxima. Our conditional probability analysis\ndemonstrates that when power fluctuates above its maximum mean value, the\nprobability of achieving high efficiency increases substantially, suggesting\nfluctuation regimes where the classical power-efficiency trade-off can be\nprobabilistically overcome. Notably, our framework extends to a broader class\nof engines, as the essential features of the statistics of the system are fully\ndetermined by the Onsager coefficients. Our results contribute to a deeper\nunderstanding of the role of fluctuations in Brownian engines, highlighting how\nstochastic behavior can enable performance beyond traditional thermodynamic\nbounds.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-10T13:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07746v1","title":"Upper semi-continuity of metric entropy for $\\mathcal{C}^{1,α}$\n  diffeomorphisms","summary":"We prove that for $\\mathcal{C}^{1,\\alpha}$ diffeomorphisms on a compact\nmanifold $M$ with ${\\rm dim} M\\leq 3$, if an invariant measure $\\mu$ is a\ncontinuity point of the sum of positive Lyapunov exponents, then $\\mu$ is an\nupper semi-continuity point of the entropy map. This gives several\nconsequences, such as the upper-semi continuity of dimensions of measures for\nsurface diffeomorphisms. Furthermore, we know the continuity of dimensions for\nmeasures of maximal entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07774v1","title":"Bondi Mass, Memory Effect And Balance Law of Polyhomogeneous Spacetime","summary":"Spacetimes with metrics admitting an expansion in terms of a combination of\npowers of 1/r and ln r are known as polyhomogeneous spacetimes. The asymptotic\nbehaviour of the Newman-Penrose quantities for these spacetimes is presented\nunder certain gauges. The Bondi mass is revisited via the Iyer-Wald formalism.\nThe memory effect of the gravitational radiation in the polyhomogeneous\nspacetimes is also discussed. It is found that the appearance of the\nlogarithmic terms does not affect the balance law and it remains unchanged as\nthe one of spacetimes with metrics admitting an expansion in terms of powers of\n1/r.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07810v1","title":"Nonlocal Retinex-Based Variational Model and its Deep Unfolding Twin for\n  Low-Light Image Enhancement","summary":"Images captured under low-light conditions present significant limitations in\nmany applications, as poor lighting can obscure details, reduce contrast, and\nhide noise. Removing the illumination effects and enhancing the quality of such\nimages is crucial for many tasks, such as image segmentation and object\ndetection. In this paper, we propose a variational method for low-light image\nenhancement based on the Retinex decomposition into illumination, reflectance,\nand noise components. A color correction pre-processing step is applied to the\nlow-light image, which is then used as the observed input in the decomposition.\nMoreover, our model integrates a novel nonlocal gradient-type fidelity term\ndesigned to preserve structural details. Additionally, we propose an automatic\ngamma correction module. Building on the proposed variational approach, we\nextend the model by introducing its deep unfolding counterpart, in which the\nproximal operators are replaced with learnable networks. We propose\ncross-attention mechanisms to capture long-range dependencies in both the\nnonlocal prior of the reflectance and the nonlocal gradient-based constraint.\nExperimental results demonstrate that both methods compare favorably with\nseveral recent and state-of-the-art techniques across different datasets. In\nparticular, despite not relying on learning strategies, the variational model\noutperforms most deep learning approaches both visually and in terms of quality\nmetrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07873v1","title":"Spectral Periodic Differential Operators of Odd Order","summary":"In this paper, we establish a condition on the coefficients of the\ndifferential operators L generated by an ordinary differential expression of\nodd order with periodic, complex-valued coefficients, under which the operator\nL is a spectral operator.","main_category":"math.SP","categories":"math.SP","published":"2025-04-10T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07899v1","title":"Dislocation Patterning as a Mechanism for Flat Band Formation","summary":"We compute the second-order correction to the electronic dispersion relation\nof a free electron gas interacting with an effective electron-dislocation\npotential, derived from a modern quantized theory of dislocations. Our results\ndemonstrate that dislocation patterning induces anisotropic flat bands in the\nelectronic dispersion under specific strain fields and directions, referred to\nas ``magic'' parameters. These flat bands acquire non-zero curvature as the\nstrain or direction deviates from these magic parameters.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-10T16:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07927v1","title":"Zero-Shot Low-dose CT Denoising via Sinogram Flicking","summary":"Many low-dose CT imaging methods rely on supervised learning, which requires\na large number of paired noisy and clean images. However, obtaining paired\nimages in clinical practice is challenging. To address this issue, zero-shot\nself-supervised methods train denoising networks using only the information\nwithin a single image, such as ZS-N2N. However, these methods often employ\ndownsampling operations that degrade image resolution. Additionally, the\ntraining dataset is inherently constrained to the image itself. In this paper,\nwe propose a zero-shot low-dose CT imaging method based on sinogram flicking,\nwhich operates within a single image but generates many copies via random\nconjugate ray matching. Specifically, two conjugate X-ray pencil beams measure\nthe same path; their expected values should be identical, while their noise\nlevels vary during measurements. By randomly swapping portions of the conjugate\nX-rays in the sinogram domain, we generate a large set of sinograms with\nconsistent content but varying noise patterns. When displayed dynamically,\nthese sinograms exhibit a flickering effect due to their identical structural\ncontent but differing noise patterns-hence the term sinogram flicking. We train\nthe network on pairs of sinograms with the same content but different noise\ndistributions using a lightweight model adapted from ZS-NSN. This process is\nrepeated to obtain the final results. A simulation study demonstrates that our\nmethod outperforms state-of-the-art approaches such as ZS-N2N.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T17:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.07931v1","title":"Quantum Speed Limit in Driven-dissipative Systems","summary":"Every quantum operation that takes a system from one state to another is\nknown to have bounds on operation time, due to Heisenberg uncertainty\nprinciple. In open quantum systems (OQS), such bounds have been principally\naffected by system environment coupling. In the recent past, drives on OQS have\nshown to give rise to drive-induced dissipation (DID). In this work, we\ninvestigate how DID affects the quantum speed limits. To this end, we use a\nrecently-reported quantum master equation that takes into account environment\nfluctuations and provide a closed form estimate of drive-induced dissipation.\nOn such a system, we use Gradient Ascent Pulse Engineering (GRAPE) to find\noptimal route to move from an initial state to a desired final state. Our key\nresult is that there exists an optimal evolution time that maximizes fidelity.\nThis work enables robust quantum control in open systems, addressing a key\nchallenge in scaling quantum technologies. By improving fidelity and\nefficiency, our method advances practical quantum computing under realistic\ndissipative conditions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07960v1","title":"VisualCloze: A Universal Image Generation Framework via Visual\n  In-Context Learning","summary":"Recent progress in diffusion models significantly advances various image\ngeneration tasks. However, the current mainstream approach remains focused on\nbuilding task-specific models, which have limited efficiency when supporting a\nwide range of different needs. While universal models attempt to address this\nlimitation, they face critical challenges, including generalizable task\ninstruction, appropriate task distributions, and unified architectural design.\nTo tackle these challenges, we propose VisualCloze, a universal image\ngeneration framework, which supports a wide range of in-domain tasks,\ngeneralization to unseen ones, unseen unification of multiple tasks, and\nreverse generation. Unlike existing methods that rely on language-based task\ninstruction, leading to task ambiguity and weak generalization, we integrate\nvisual in-context learning, allowing models to identify tasks from visual\ndemonstrations. Meanwhile, the inherent sparsity of visual task distributions\nhampers the learning of transferable knowledge across tasks. To this end, we\nintroduce Graph200K, a graph-structured dataset that establishes various\ninterrelated tasks, enhancing task density and transferable knowledge.\nFurthermore, we uncover that our unified image generation formulation shared a\nconsistent objective with image infilling, enabling us to leverage the strong\ngenerative priors of pre-trained infilling models without modifying the\narchitectures.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.09912v1","title":"Parameter Convergence Detector Based on VAMP Deep Unfolding: A Novel\n  Radar Constant False Alarm Rate Detection Algorithm","summary":"The sub-Nyquist radar framework exploits the sparsity of signals, which\neffectively alleviates the pressure on system storage and transmission\nbandwidth. Compressed sensing (CS) algorithms, such as the VAMP algorithm, are\nused for sparse signal processing in the sub-Nyquist radar framework. By\ncombining deep unfolding techniques with VAMP, faster convergence and higher\naccuracy than traditional CS algorithms are achieved. However, deep unfolding\ndisrupts the parameter constrains in traditional VAMP algorithm, leading to the\ndistribution of non-sparse noisy estimation in VAMP deep unfolding unknown, and\nits distribution parameter unable to be obtained directly using method of\ntraditional VAMP, which prevents the application of VAMP deep unfolding in\nradar constant false alarm rate (CFAR) detection. To address this problem, we\nexplore the distribution of the non-sparse noisy estimation and propose a\nparameter convergence detector (PCD) to achieve CFAR detection based on VAMP\ndeep unfolding. Compared to the state-of-the-art methods, PCD leverages not\nonly the sparse solution, but also the non-sparse noisy estimation, which is\nused to iteratively estimate the distribution parameter and served as the test\nstatistic in detection process. In this way, the proposed algorithm takes\nadvantage of both the enhanced sparse recovery accuracy from deep unfolding and\nthe distribution property of VAMP, thereby achieving superior CFAR detection\nperformance. Additionally, the PCD requires no information about the power of\nAWGN in the environment, which is more suitable for practical application. The\nconvergence performance and effectiveness of the proposed PCD are analyzed\nbased on the Banach Fixed-Point Theorem. Numerical simulations and practical\ndata experiments demonstrate that PCD can achieve better false alarm control\nand target detection performance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.09925v1","title":"FUSION: Fully Integration of Vision-Language Representations for Deep\n  Cross-Modal Understanding","summary":"We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09966v1","title":"SemiETS: Integrating Spatial and Content Consistencies for\n  Semi-Supervised End-to-end Text Spotting","summary":"Most previous scene text spotting methods rely on high-quality manual\nannotations to achieve promising performance. To reduce their expensive costs,\nwe study semi-supervised text spotting (SSTS) to exploit useful information\nfrom unlabeled images. However, directly applying existing semi-supervised\nmethods of general scenes to SSTS will face new challenges: 1) inconsistent\npseudo labels between detection and recognition tasks, and 2) sub-optimal\nsupervisions caused by inconsistency between teacher/student. Thus, we propose\na new Semi-supervised framework for End-to-end Text Spotting, namely SemiETS\nthat leverages the complementarity of text detection and recognition.\nSpecifically, it gradually generates reliable hierarchical pseudo labels for\neach task, thereby reducing noisy labels. Meanwhile, it extracts important\ninformation in locations and transcriptions from bidirectional flows to improve\nconsistency. Extensive experiments on three datasets under various settings\ndemonstrate the effectiveness of SemiETS on arbitrary-shaped text. For example,\nit outperforms previous state-of-the-art SSL methods by a large margin on\nend-to-end spotting (+8.7%, +5.6%, and +2.6% H-mean under 0.5%, 1%, and 2%\nlabeled data settings on Total-Text, respectively). More importantly, it still\nimproves upon a strongly supervised text spotter trained with plenty of labeled\ndata by 2.0%. Compelling domain adaptation ability shows practical potential.\nMoreover, our method demonstrates consistent improvement on different text\nspotters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.09983v1","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\n  Learning Training","summary":"The increasing scale of deep learning models has led to the development of\nvarious parallelization strategies for distributed training across\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\nFSDP partition the parameters of each layer across multiple GPUs and gather\nthem through communication when needed. These methods rely on optimizations\nsuch as prefetching, which initiates communication early to overlap it with\ncomputation and reduce communication overhead, and unsharding, which retains as\nmany parameters in their unsharded form as possible to reduce communication\nvolume. Although the timing of prefetching should be adjusted in response to\ndynamic memory usage during execution, these systems lack the flexibility to\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\nanticipate how memory usage will change after prefetching is applied, making it\ndifficult to combine it effectively with other optimizations such as\nunsharding. We present DeepCompile, which compiles user-defined models into\ncomputation graphs and applies a sequence of profiling-guided optimization\npasses for distributed training. Taking dynamic memory usage into account,\nthese passes flexibly insert, reorder, or remove operations to improve\ncommunication-computation overlap, reduce memory pressure, and coordinate\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\ntop of DeepCompile, along with three optimizations: proactive prefetching,\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\nusing offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10035v1","title":"TT3D: Table Tennis 3D Reconstruction","summary":"Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:37:47Z"}
{"aid":"http://arxiv.org/abs/2504.10047v1","title":"Vibrational structure and symmetry in $^{110-116}$Cd","summary":"We show that a vibrational interpretation and good U(5) symmetry are\nmaintained for the majority of low-lying normal states in\n$^{110,112,114,116}$Cd isotopes, consistent with the empirical data. The\nobserved deviations from this paradigm are properly treated by an interacting\nboson model Hamiltonian which breaks the U(5) symmetry in selected non-yrast\nstates, while securing a weak mixing with coexisting SO(6)-like intruder\nstates. The results demonstrate the relevance of the U(5) partial dynamical\nsymmetry notion to this series of isotopes.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T09:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.10048v1","title":"Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers","summary":"Multi-object grounding in 3D scenes involves localizing multiple objects\nbased on natural language input. While previous work has primarily focused on\nsingle-object grounding, real-world scenarios often demand the localization of\nseveral objects. To tackle this challenge, we propose Hierarchical Contrastive\nSiamese Transformers (H-COST), which employs a Hierarchical Processing strategy\nto progressively refine object localization, enhancing the understanding of\ncomplex language instructions. Additionally, we introduce a Contrastive Siamese\nTransformer framework, where two networks with the identical structure are\nused: one auxiliary network processes robust object relations from ground-truth\nlabels to guide and enhance the second network, the reference network, which\noperates on segmented point-cloud data. This contrastive mechanism strengthens\nthe model' s semantic understanding and significantly enhances its ability to\nprocess complex point-cloud data. Our approach outperforms previous\nstate-of-the-art methods by 9.5% on challenging multi-object grounding\nbenchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10066v1","title":"A Framework for Adaptive Load Redistribution in Human-Exoskeleton-Cobot\n  Systems","summary":"Wearable devices like exoskeletons are designed to reduce excessive loads on\nspecific joints of the body. Specifically, single- or two-degrees-of-freedom\n(DOF) upper-body industrial exoskeletons typically focus on compensating for\nthe strain on the elbow and shoulder joints. However, during daily activities,\nthere is no assurance that external loads are correctly aligned with the\nsupported joints. Optimizing work processes to ensure that external loads are\nprimarily (to the extent that they can be compensated by the exoskeleton)\ndirected onto the supported joints can significantly enhance the overall\nusability of these devices and the ergonomics of their users. Collaborative\nrobots (cobots) can play a role in this optimization, complementing the\ncollaborative aspects of human work. In this study, we propose an adaptive and\ncoordinated control system for the human-cobot-exoskeleton interaction. This\nsystem adjusts the task coordinates to maximize the utilization of the\nsupported joints. When the torque limits of the exoskeleton are exceeded, the\nframework continuously adapts the task frame, redistributing excessive loads to\nnon-supported body joints to prevent overloading the supported ones. We\nvalidated our approach in an equivalent industrial painting task involving a\nsingle-DOF elbow exoskeleton, a cobot, and four subjects, each tested in four\ndifferent initial arm configurations with five distinct optimisation weight\nmatrices and two different payloads.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T10:09:00Z"}
{"aid":"http://arxiv.org/abs/2504.10067v1","title":"Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph\n  Auto-Encoders","summary":"EdgeIoT represents an approach that brings together mobile edge computing\nwith Internet of Things (IoT) devices, allowing for data processing close to\nthe data source. Sending source data to a server is bandwidth-intensive and may\ncompromise privacy. Instead, federated learning allows each device to upload a\nshared machine-learning model update with locally processed data. However, this\ntechnique, which depends on aggregating model updates from various IoT devices,\nis vulnerable to attacks from malicious entities that may inject harmful data\ninto the learning process. This paper introduces a new attack method targeting\nfederated learning in EdgeIoT, known as data-independent model manipulation\nattack. This attack does not rely on training data from the IoT devices but\ninstead uses an adversarial variational graph auto-encoder (AV-GAE) to create\nmalicious model updates by analyzing benign model updates intercepted during\ncommunication. AV-GAE identifies and exploits structural relationships between\nbenign models and their training data features. By manipulating these\nstructural correlations, the attack maximizes the training loss of the\nfederated learning system, compromising its overall effectiveness.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T10:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.10087v1","title":"Joint Localization and Synchronization in Downlink Distributed MIMO","summary":"We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.10099v1","title":"Regularization of Functional Determinants of Radial Operators via Heat\n  Kernel Coefficients","summary":"We propose an efficient regularization method for functional determinants of\nradial operators using heat kernel coefficients. Our key finding is a\nsystematic way to identify heat kernel coefficients in the angular momentum\nspace. We explicitly obtain the formulas up to sixth order in the heat kernel\nexpansion, which suffice to regularize functional determinants in up to 13\ndimensions. We find that the heat kernel coefficients accurately approximate\nthe large angular momentum dependence of functional determinants, and make\nnumerical computations more efficient. In the limit of a large angular\nmomentum, our formulas reduce to the WKB formulas in previous studies, but\nextended to higher orders. All the results are available in both the zeta\nfunction regularization and the dimensional regularization.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-14T11:06:21Z"}
{"aid":"http://arxiv.org/abs/2504.10103v1","title":"Numerical approach for solving problems arising from polynomial analysis","summary":"This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.","main_category":"math.NA","categories":"math.NA,cs.NA,math.CA","published":"2025-04-14T11:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.10104v1","title":"Automated next-to-leading order QCD and electroweak predictions of\n  photon-photon processes in ultraperipheral collisions","summary":"We present automated next-to-leading order QCD and/or electroweak (EW)\npredictions for photon-photon processes in ultraperipheral high-energy\ncollisions of protons and ions, extending the capabilities of the\n\\textsc{MadGraph5\\_aMC@NLO} framework together in combination with the\n\\ttt{gamma-UPC} code. Key aspects of this extension are discussed. We compute\nQCD and/or EW quantum corrections for several phenomenologically interesting\nprocesses at LHC and FCC-hh energies.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-14T11:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.10108v1","title":"A Photometric Comparison of B and Be stars using Gaia DR3","summary":"Previous studies have observed significant photometric differences between\nnon-emission B-type and classical Be stars, however the precise mechanism\nresponsible for these differences is unclear. This study combines the Bright\nStar Catalogue with Tycho and Gaia photometry to create a homogeneous sample of\n1015 of the closest and brightest B and Be-type field stars with 90 per cent of\nobjects at distances < 500pc. Due to their proximity, the extinction towards\nthese objects is very low, ensuring we minimise any obfuscation in the\nreddening correction and final photometry. We present our findings in both\nTycho and Gaia photometry through colour magnitude diagrams and present\nintrinsic colours and absolute magnitudes for each spectral type. We find Be\nstars are on average ~0.5 magnitudes brighter in both Gaia $G$ and Tycho V$_T$\ncompared to non-emission B stars of the same spectral type. Additionally, we\nfind tentative evidence that Be stars are redder in Gaia B$_P$$-$R$_P$,\nparticularly for the earlier types, but have similar Tycho B$_T$$-$V$_T$\ncolours. We test the effects of gravitational darkening due to rapid rotation\nand binarity on the photometry of our sample and find both to be insufficient\nto explain the observed photometric differences between B and Be stars. We\nconclude that the most likely mechanism responsible for the observed\nphotometric differences is the combined effect of the circumstellar disc and\nstellar evolution up the Main Sequence, with the disc dominating early-types\nand evolution dominating late type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T11:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.10109v1","title":"Lightweight Trustworthy Distributed Clustering","summary":"Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-14T11:16:07Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10118v1","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","summary":"We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-14T11:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.10125v1","title":"An initial-boundary corrected splitting method for diffusion-reaction\n  problems","summary":"Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T11:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.10138v1","title":"$k$-Fibonacci numbers that are palindromic concatenations of two\n  distinct Repdigits","summary":"Let $k\\ge 2$ and $\\{F_n^{(k)}\\}_{n\\geq 2-k}$ be the sequence of\n$k$--generalized Fibonacci numbers whose first $k$ terms are $0,\\ldots,0,0,1$\nand each term afterwards is the sum of the preceding $k$ terms. In this paper,\nwe determine all $k$-Fibonacci numbers that are palindromic concatenations of\ntwo distinct repdigits.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T11:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.10156v1","title":"The missing elements in the telegraph equations","summary":"The conventional modeling of transmission lines relies on the classical\ntelegraph equations, originally formulated over 150 years ago. These equations\nare typically derived by representing the line as an assembly of infinitesimal\ninductive, capacitive, and resistive elements. However, this formulation is\nfundamentally flawed, as a transmission line cannot be accurately described\nthrough a discretized model of infinitesimal lumped components. Instead, a more\nrigorous approach should derive the governing equations directly from Maxwells\nequations in conjunction with Ohms law. This paper presents such a derivation\nand introduces a corrected formulation, herein referred to as the Trump\nEquations.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-04-14T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.10160v1","title":"MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like\n  Reinforcement Learning","summary":"Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.10166v1","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented\n  LLMs for Social Media Analysis","summary":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with\nExplanation); a novel framework that integrates retrieval-augmented Large\nLanguage Models (LLMs) with clustering techniques to address fact-checking\nchallenges on social media. CRAVE automatically retrieves multimodal evidence\nfrom diverse, often contradictory, sources. Evidence is clustered into coherent\nnarratives, and evaluated via an LLM-based judge to deliver fact-checking\nverdicts explained by evidence summaries. By synthesizing evidence from both\ntext and image modalities and incorporating agent-based refinement, CRAVE\nensures consistency and diversity in evidence representation. Comprehensive\nexperiments demonstrate CRAVE's efficacy in retrieval precision, clustering\nquality, and judgment accuracy, showcasing its potential as a robust\ndecision-support tool for fact-checkers.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T12:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.10171v1","title":"Kullback-Leibler excess risk bounds for exponential weighted aggregation\n  in Generalized linear models","summary":"Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-14T12:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10185v1","title":"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in\n  Current Benchmarks","summary":"Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.10195v1","title":"Simulation of TOPCon/PERC Hybrid Bottom Structure for Perovskite/Silicon\n  Tandem Solar Cells using Quokka3","summary":"This work emphasizes the potential of perovskite/silicon tandem solar cells\nfor increased power conversion efficiencies. By employing crystalline silicon\n(c-Si) as the bottom cell, particularly with p-type PERC technology, there are\ncost-effective and advantageous physical properties. However, traditional\nphosphorus-doped emitters in PERC Si bottom cells are hindered by high surface\nrecombination, which limits their performance. This research introduces a novel\nhybrid PERC/TOPCon structure that integrates a phosphorus-doped poly-Si (n+\nTOPCon) layer as the front emitter to address these challenges. Numerical\nsimulations using Quokka3 confirmed the feasibility of the design, focusing on\noptimizing the rear side metallization to enhance implied open-circuit voltage\n(Voc) and fill factor (FF). A two-step process systematically varied local\ncontact openings to examine their impact on performance metrics. Results\nhighlighted optimal rear metallization parameters, achieving optimal metal\nfractions approximately 2%. This innovative approach demonstrates the\neffectiveness of combining TOPCon and PERC technologies for bottom cells in\ntandem structures, providing valuable insights into their development and\noptimization. The study underscores the potential of the hybrid PERC/TOPCon\nstructure in enhancing the functionality and efficiency of perovskite/silicon\ntandem solar cells.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-14T12:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10212v1","title":"WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients","summary":"Partial Differential Equations (PDEs) identification is a data-driven method\nfor mathematical modeling, and has received a lot of attentions recently. The\nstability and precision in identifying PDE from heavily noisy spatiotemporal\ndata present significant difficulties. This problem becomes even more complex\nwhen the coefficients of the PDEs are subject to spatial variation. In this\npaper, we propose a Weak formulation of Group-sparsity-based framework for\nIDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this\nchallenge. Our approach utilizes the weak formulation of PDEs to reduce the\nimpact of noise. We represent test functions and unknown PDE coefficients using\nB-splines, where the knot vectors of test functions are optimally selected\nbased on spectral analysis of the noisy data. To facilitate feature selection,\nwe propose to integrate group sparse regression with a newly designed group\nfeature trimming technique, called GF-trim, to eliminate unimportant features.\nExtensive and comparative ablation studies are conducted to validate our\nproposed method. The proposed method not only demonstrates greater robustness\nto high noise levels compared to state-of-the-art algorithms but also achieves\nsuperior performance while exhibiting reduced sensitivity to hyperparameter\nselection.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T13:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10253v1","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for\n  Genetic Programming","summary":"Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.","main_category":"cs.NE","categories":"cs.NE,cs.LG,cs.SC","published":"2025-04-14T14:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10268v1","title":"Theoretical Model of Microparticle-Assisted Super-Resolution Microscopy","summary":"This work presents the development of a three-dimensional model of\nsuper-resolution imaging, which may help resolve the longstanding debate about\nthe nature of this phenomenon and the methods used to describe it. We discuss\nthe approaches that enable an efficient and accurate theoretical description. A\ncomparison between theoretical predictions and experimental results is\npresented for both conventional and confocal microscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T14:33:51Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10282v1","title":"Optimal Execution in Intraday Energy Markets under Hawkes Processes with\n  Transient Impact","summary":"This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-14T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.10294v1","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into\n  Biomechanics and Human-Robot Interaction","summary":"Background: Lower limb exoskeletons can enhance quality of life, but\nwidespread adoption is limited by the lack of frameworks to assess their\nbiomechanical and human-robot interaction effects, which are essential for\ndeveloping adaptive and personalized control strategies. Understanding impacts\non kinematics, muscle activity, and HRI dynamics is key to achieve improved\nusability of wearable robots. Objectives: We propose a systematic methodology\nevaluate an ankle exoskeleton's effects on human movement during walking and\nload-carrying (10 kg front pack), focusing on joint kinematics, muscle\nactivity, and HRI torque signals. Materials and Methods: Using Xsens MVN\n(inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three\nexperiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait\nanalysis (two subjects, passive/active modes); and (3) load-carrying under\nassistance. Results and Conclusions: The first experiment confirmed that the\nHRI sensor captured both voluntary and involuntary torques, providing\ndirectional torque insights. The second experiment showed that the device\nslightly restricted ankle range of motion (RoM) but supported normal gait\npatterns across all assistance modes. The exoskeleton reduced muscle activity,\nparticularly in active mode. HRI torque varied according to gait phases and\nhighlighted reduced synchronization, suggesting a need for improved support.\nThe third experiment revealed that load-carrying increased GM and TA muscle\nactivity, but the device partially mitigated user effort by reducing muscle\nactivity compared to unassisted walking. HRI increased during load-carrying,\nproviding insights into user-device dynamics. These results demonstrate the\nimportance of tailoring exoskeleton evaluation methods to specific devices and\nusers, while offering a framework for future studies on exoskeleton\nbiomechanics and HRI.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10310v1","title":"Existence of Nonequilibrium Glasses in the Degenerate Stealthy\n  Hyperuniform Ground-State Manifold","summary":"Stealthy interactions are an emerging class of nontrivial, bounded\nlong-ranged oscillatory pair potentials with classical ground states that can\nbe disordered, hyperuniform, and infinitely degenerate. Their hybrid\ncrystal-liquid nature endows them with novel physical properties with\nadvantages over their crystalline counterparts. Here, we show the existence of\nnonequilibrium hard-sphere glasses within this unusual ground-state manifold as\nthe stealthiness parameter $\\chi$ tends to zero that are remarkably\nconfigurationally extremely close to hyperuniform 3D maximally random jammed\n(MRJ) sphere packings. The latter are prototypical glasses since they are\nmaximally disordered, perfectly rigid, and perfectly nonergodic. Our\noptimization procedure, which leverages the maximum cardinality of the infinite\nground-state set, not only guarantees that our packings are hyperuniform with\nthe same structure-factor scaling exponent as the MRJ state, but they share\nother salient structural attributes, including a packing fraction of $0.638$, a\nmean contact number per particle of 6, gap exponent of $0.44(1)$, and pair\ncorrelation functions $g_2(r)$ and structures factors $S(k)$ that are virtually\nidentical to one another for all $r$ and $k$, respectively. Moreover, we\ndemonstrate that stealthy hyperuniform packings can be created within the\ndisordered regime ($0 < \\chi <1/2$) with heretofore unattained maximal packing\nfractions. As $\\chi$ increases from zero, they always form interparticle\ncontacts, albeit with sparser contact networks as $\\chi$ increases from zero,\nresulting in linear polymer-like chains of contacting particles with\nincreasingly shorter chain lengths. The capacity to generate ultradense\nstealthy hyperuniform packings for all $\\chi$ opens up new materials\napplications in optics and acoustics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-14T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.10314v1","title":"Universal Algebra and Effectful Computation","summary":"Abstract clones serve as an algebraic presentation of the syntax of a simple\ntype theory. From the perspective of universal algebra, they define algebraic\ntheories like those of groups, monoids and rings. This link allows one to study\nthe language of simple type theory from the viewpoint of universal algebra.\n  Programming languages, however, are much more complicated than simple type\ntheory. Many useful features like reading, writing, and exception handling\ninvolve interacting with the environment; these are called side-effects.\nAlgebraic presentations for languages with the appropriate syntax for handling\neffects are given by premulticategories and effectful multicategories. We study\nthese structures with the aim of defining a suitable notion of an algebra.\n  To achieve this goal, we proceed in two steps. First, we define a tensor on\n$[\\to,\\category{Set}]$, and show that this tensor along with the cartesian\nproduct gives the category a duoidal structure. Secondly, we introduce the\nnovel notion of a multicategory enriched in a duoidal category which generalize\nthe traditional notion of a multicategory. Further, we prove that an effectful\nmulticategory is the same as a multicategory enriched in the duoidal category\n$[\\to,\\category{Set}]$. This result places multicategories and effectful\nmulticategories on a similar footing, and provides a mechanism for transporting\nconcepts from the theory of multicategories (which model pure computation) to\nthe theory of effectful multicategories (which model effectful computation). As\nan example of this, we generalize the definition of a 2-morphism for\nmulticategories to the duoidally enriched case. Our equivalence result then\ngives a natural definition of a 2-morphism for effectful multicategories, which\nwe then use to define the notion of an algebra.","main_category":"cs.PL","categories":"cs.PL,math.CT","published":"2025-04-14T15:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10354v1","title":"The diagonal and Hadamard grade of hypergeometric functions","summary":"Diagonals of rational functions are an important class of functions arising\nin number theory, algebraic geometry, combinatorics, and physics. In this paper\nwe study the diagonal grade of a function $f$, which is defined to be the\nsmallest $n$ such that $f$ is the diagonal of a rational function in variables\n$x_0,\\dots, x_n$. We relate the diagonal grade of a function to the nilpotence\nof the associated differential equation. This allows us to determine the\ndiagonal grade of many hypergeometric functions and answer affirmatively the\noutstanding question on the existence of functions with diagonal grade greater\nthan $2$. In particular, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\ndiagonal grade $n$ for each $n\\geq 1$. Our method also applies to the\ngenerating function of the Ap\\'ery sequence, which we find to have diagonal\ngrade $3$. We also answer related questions on Hadamard grades posed by\nAllouche and Mend\\`es France. For example, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\nHadamard grade $n$ for all $n\\geq 1$.","main_category":"math.CO","categories":"math.CO,math-ph,math.AG,math.MP,math.NT","published":"2025-04-14T16:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.10358v1","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for\n  AI-Generated Videos","summary":"Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T16:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.10364v1","title":"Widely FSR tunable high Q-factor microresonators formed at the\n  intersection of straight optical fibers","summary":"We present a new class of high-Q tunable microresonators formed at the\nintersection of two straight silica optical fibers, whose free spectral range\n(FSR) can be widely tuned by fiber rotation. The proposed configuration avoids\nthe limitations of traditional monolithic microresonators that lack FSR\ntunability required for a wide range of photonic applications. Using small\nrotation angles (1-15 mrad), we demonstrate a tunability of the FSR from 2 pm\nto 10 pm, enabled by microscale fiber displacements that reshape the resonator\nprofile over millimeter scales. The proposed approach minimizes mechanical\nstress, supports miniaturization, and is suitable for integration with MEMS. It\npaves the way for the fabrication of tunable delay lines, ultralow repetition\nrate broadband frequency comb generators, and nonlocal optofluidic sensors on a\nchip.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T16:10:08Z"}
{"aid":"http://arxiv.org/abs/2504.10371v1","title":"Brain-Machine Interfaces & Information Retrieval Challenges and\n  Opportunities","summary":"The fundamental goal of Information Retrieval (IR) systems lies in their\ncapacity to effectively satisfy human information needs - a challenge that\nencompasses not just the technical delivery of information, but the nuanced\nunderstanding of human cognition during information seeking. Contemporary IR\nplatforms rely primarily on observable interaction signals, creating a\nfundamental gap between system capabilities and users' cognitive processes.\nBrain-Machine Interface (BMI) technologies now offer unprecedented potential to\nbridge this gap through direct measurement of previously inaccessible aspects\nof information-seeking behaviour. This perspective paper offers a broad\nexamination of the IR landscape, providing a comprehensive analysis of how BMI\ntechnology could transform IR systems, drawing from advances at the\nintersection of both neuroscience and IR research. We present our analysis\nthrough three identified fundamental vertices: (1) understanding the neural\ncorrelates of core IR concepts to advance theoretical models of search\nbehaviour, (2) enhancing existing IR systems through contextual integration of\nneurophysiological signals, and (3) developing proactive IR capabilities\nthrough direct neurophysiological measurement. For each vertex, we identify\nspecific research opportunities and propose concrete directions for developing\nBMI-enhanced IR systems. We conclude by examining critical technical and\nethical challenges in implementing these advances, providing a structured\nroadmap for future research at the intersection of neuroscience and IR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T16:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10390v1","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10402v1","title":"Can spacetime torsion source an extremely red-tilted cosmological GW\n  background?","summary":"In the presence of spacetime torsion, any generic $f(R)$ model of gravity is\nconformally dual to a scalar-tensor theory augmented with a second rank\nantisymmetric massless degree of freedom. We investigate the stochastic\ngravitational wave background (SGWB) that may be sourced directly at the second\norder by such a torsional field, treated perturbatively during an epoch of\ncanonical, single-field, slow-roll inflation. The resulting second-order\ninduced SGWB, which dominates over the primary inflationary GW background at\nall scales, peaks only at ultra-low frequencies, and is found to be extremely\nred-tilted with an effective tensor spectral index $\\alpha_{\\rm T}\\sim-6$ on\nmatter-dominated scales. The signal is potentially within the reach of upcoming\nindirect GW probes on very large scales $k\\lesssim10^{-2}\\:\\textrm{Mpc}^{-1}$,\ni.e., next-generation CMB experiments like the LiteBIRD. In the near future,\nobservation of such a markedly red-tilted SGWB on CMB scales could hence\nprovide a novel and unique clue in favour of torsional gravity during the\ninflationary era.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-14T16:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10403v1","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI","published":"2025-04-14T16:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10414v1","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","summary":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.10420v1","title":"Role of Coulomb-nuclear breakup of 6,7Li projectiles with heavy deformed\n  232Th target","summary":"The significance of both Coulomb and nuclear couplings and their interference\neffects in the breakup processes of 6,7Li with a non-spherical nucleus 232Th\nhas been evaluated. The continuum discretized coupled channel(CDCC)\ncalculations are carried out in a nonstandard way, using short-range imaginary\npotentials for the fragment-target interaction at energies close to the Coulomb\nbarrier. The present calculations employing short-range imaginary potentials\nexhibit better agreement with the experimental elastic scattering angular\ndistributions than those using standard systematic value (0.78xWSPP ) used to\ndescribe elastic scattering. Including the excitation of the 232Th inelastic\nshows significant coupling effects on the elastic scattering below the barrier\nenergies compared to higher incident energies. Subsequently, the CDCC framework\nwas used to analyze the nuclear, Coulomb, and total breakup predictions\nseparately. The breakup cross sections for the 6Li+232Th system are greater\nthan those for the 7Li+232Th system across various energies. The present study\npredicts destructive Coulomb-nuclear interference in the breakup processes\ninvolving both 6Li and 7Li projectile nuclei with the deformed 232Th target.\nAdditionally, the breakup reaction cross-sections are compared with\nexperimentally measured fusion cross-sections near the barrier energies for\nboth 6,7Li+232Th systems.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T17:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.10421v1","title":"Can We Edit LLMs for Long-Tail Biomedical Knowledge?","summary":"Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T17:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10438v1","title":"Streaming Democratized: Ease Across the Latency Spectrum with Delayed\n  View Semantics and Snowflake Dynamic Tables","summary":"Streaming data pipelines remain challenging and expensive to build and\nmaintain, despite significant advancements in stronger consistency, event time\nsemantics, and SQL support over the last decade. Persistent obstacles continue\nto hinder usability, such as the need for manual incrementalization, semantic\ndiscrepancies across SQL implementations, and the lack of enterprise-grade\noperational features. While the rise of incremental view maintenance (IVM) as a\nway to integrate streaming with databases has been a huge step forward,\ntransaction isolation in the presence of IVM remains underspecified, leaving\nthe maintenance of application-level invariants as a painful exercise for the\nuser. Meanwhile, most streaming systems optimize for latencies of 100 ms to 3\nsec, whereas many practical use cases are well-served by latencies ranging from\nseconds to tens of minutes.\n  We present delayed view semantics (DVS), a conceptual foundation that bridges\nthe semantic gap between streaming and databases, and introduce Dynamic Tables,\nSnowflake's declarative streaming transformation primitive designed to\ndemocratize analytical stream processing. DVS formalizes the intuition that\nstream processing is primarily a technique to eagerly compute derived results\nasynchronously, while also addressing the need to reason about the resulting\nsystem end to end. Dynamic Tables then offer two key advantages: ease of use\nthrough DVS, enterprise-grade features, and simplicity; as well as scalable\ncost efficiency via IVM with an architecture designed for diverse latency\nrequirements.\n  We first develop extensions to transaction isolation that permit the\npreservation of invariants in streaming applications. We then detail the\nimplementation challenges of Dynamic Tables and our experience operating it at\nscale. Finally, we share insights into user adoption and discuss our vision for\nthe future of stream processing.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-14T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10472v1","title":"False and genuine decoherence in the early universe: a local observer\n  and time-averaged observables","summary":"We study quantum decoherence of curvature perturbations at superhorizon\nscales caused by the gravitational nonlinearities. We show that cubic\ngravitational couplings, constrained by the spatial diffeomorphism invariance,\nlead to infrared (IR) and ultraviolet (UV) divergences in the decoherence rate\nat one loop. These divergences arise from fluctuations of deep IR modes which\nlook like a background mode for a local observer and violent zero-point\nfluctuations in the deep UV, respectively. We argue that these divergences are\nunobservable, as they vanish when considering proper observables. We consider\ncorrelators defined using the geodesic distance for IR divergences and\ntime-averaged correlators for UV divergences. To account for these observer's\nperspectives, we propose to consider an effective quantum state, defined in\nterms of actual observables, as a more appropriate probe of the quantum\ncoherence of the system measured by an observer. We then evaluate the finite\ndecoherence rate induced by superhorizon environment during inflation and at\nlate universe.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc,hep-ph","published":"2025-04-14T17:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.10830v1","title":"Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint\n  BS Activation and Beamforming Coordination","summary":"Coordinated beamforming across distributed base stations (BSs) in cell-free\narchitectures can efficiently support integrated sensing and communication\n(ISAC) users by improving resource sharing and reducing conflicts in the\nspatial domain. However, coordinating numerous BSs within the ISAC network\nposes risks of generating substantial interference for other networks sharing\nthe spectrum, while also increasing operational costs from power consumption\nand signaling overhead. Therefore, in this paper, we propose an\ninterference-suppressed and cost-optimized cell-free ISAC network by\nopportunistically and cooperatively orchestrating distributed radio resources\nto address competing sensing and communication (S\\&C) demands. Specifically, we\nconceive a radiation footprint control mechanism that autonomously suppresses\ninterference across the entire signal propagation space to safeguard other\nnetworks without exchanging signaling. Then, we propose joint BS activation and\nbeamforming coordination to dynamically activate appropriate BSs and\norchestrate their spatial beams for service provisioning. Building upon this\nframework, we formulate a cost-efficient utility maximization problem that\nconsiders individual S\\&C demands and location-dependent radiation footprint\nconstraints. Since this results in a non-convex optimization problem, we\ndevelop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm\nto find the optimal solution. Additionally, we apply a low-complexity iterative\nmethod to obtain near-optimal solutions. Finally, simulation results validate\nthe effectiveness of the proposed algorithms.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T03:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.10837v1","title":"Elastocaloric signature of the excitonic instability in Ta$_2$NiSe$_5$","summary":"On cooling through a temperature $T_S$ of around 324 K, Ta$_2$NiSe$_5$\nundergoes a transition from a semimetallic state to one with a gapped\nelectronic spectrum which is suspected to be an excitonic insulator. However,\nat this transition the structure also changes, from orthorhombic to monoclinic,\nleaving open the question of whether it is driven primarily by excitonic\nordering or by a lattice instability. A lattice instability of this symmetry\nwould correspond to softening of a B$_{2g}$ optical or acoustic phonon mode.\nHere, we report that elastocaloric measurements of Ta$_2$NiSe$_5$ with induced\nB$_{2g}$ strain reveal a thermodynamic susceptibility described by a\nCurie-Weiss law with a Curie temperature $T^*$ of 298 K. The fact that $T^*$ is\nclose to $T_S$ rules out the possibility that the B$_{2g}$ acoustic mode is\nresponsible for the transition. Since prior Raman measurements have shown\nminimal softening of the B$_{2g}$ optical mode as well, our finding strengthens\nthe case that the transition is largely excitonic in nature. Our work\nunderscores the potential of using strain as a tool for separating electronic\nand lattice contributions in phase transitions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T03:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.10846v1","title":"Mosaic: Client-driven Account Allocation Framework in Sharded\n  Blockchains","summary":"Recent account allocation studies in sharded blockchains are typically\nminer-driven, requiring miners to perform global optimizations for all accounts\nto enhance system-wide performance. This forces each miner to maintain a\ncomplete copy of the entire ledger, resulting in significant storage,\ncommunication, and computation overhead.\n  In this work, we explore an alternative research direction by proposing\nMosaic, the first client-driven framework for distributed, lightweight local\noptimization. Rather than relying on miners to allocate all accounts, Mosaic\nenables clients to independently execute a local algorithm to determine their\nresiding shards. Clients can submit migration requests to a beacon chain when\nrelocation is necessary. Mosaic naturally addresses key limitations of\nminer-driven approaches, including the lack of miner incentives and the\nsignificant overhead. While clients are flexible to adopt any algorithm for\nshard allocation, we design and implement a reference algorithm, Pilot, to\nguide them. Clients execute Pilot to maximize their own benefits, such as\nreduced transaction fees and confirmation latency.\n  On a real-world Ethereum dataset, we implement and evaluate Pilot against\nstate-of-the-art miner-driven global optimization solutions. The results\ndemonstrate that Mosaic significantly enhances computational efficiency,\nachieving a four-order-of-magnitude reduction in computation time, with the\nreduced input data size from 1.44 GB to an average of 228.66 bytes per account.\nDespite these efficiency gains, Pilot introduces only about a 5% increase in\nthe cross-shard ratio and maintains approximately 98% of the system throughput,\ndemonstrating a minimal trade-off in overall effectiveness.","main_category":"cs.DC","categories":"cs.DC,cs.DB,cs.GT","published":"2025-04-15T04:07:09Z"}
{"aid":"http://arxiv.org/abs/2504.10847v1","title":"Cosmic-Ray Constraints on the Flux of Ultra-High-Energy Neutrino Event\n  KM3-230213A","summary":"The detection of a $\\simeq220$~PeV muon neutrino by the KM3NeT neutrino\ntelescope offers an unprecedented opportunity to probe the Universe at extreme\nenergies. We analyze the origin of this event under three scenarios, viz., a\ntransient point source, a diffuse astrophysical emission, and line-of-sight\ninteraction of ultrahigh-energy cosmic rays (UHECR; $E \\gtrsim 0.1$~EeV). Our\nanalysis includes the flux from both a KM3NeT-only fit and a joint fit,\nincorporating data from KM3NeT, IceCube, and Pierre Auger Observatory. If the\nneutrino event originates from transients, it requires a new population of\ntransient that is energetic, gamma-ray dark, and more abundant than known ones.\nIn the framework of diffuse astrophysical emission, we compare the required\nlocal UHECR energy injection rate at $\\gtrsim4$ EeV, assuming a proton primary,\nwith the rate derived from the flux measurements by Auger. This disfavors the\nKM3NeT-only fit at all redshifts, while the joint fit remains viable for\n$z\\gtrsim 1$, based on redshift evolution models of known source populations.\nFor cosmogenic origin from point sources, our results suggest that the\nluminosity obtained at redshifts $z \\lesssim 1$ from the joint fit is\ncompatible with the Eddington luminosity of supermassive black holes in active\ngalactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.10854v1","title":"LVLM_CSP: Accelerating Large Vision Language Models via Clustering,\n  Scattering, and Pruning for Reasoning Segmentation","summary":"Large Vision Language Models (LVLMs) have been widely adopted to guide vision\nfoundation models in performing reasoning segmentation tasks, achieving\nimpressive performance. However, the substantial computational overhead\nassociated with LVLMs presents a new challenge. The primary source of this\ncomputational cost arises from processing hundreds of image tokens. Therefore,\nan effective strategy to mitigate such overhead is to reduce the number of\nimage tokens, a process known as image token pruning. Previous studies on image\ntoken pruning for LVLMs have primarily focused on high level visual\nunderstanding tasks, such as visual question answering and image captioning. In\ncontrast, guiding vision foundation models to generate accurate visual masks\nbased on textual queries demands precise semantic and spatial reasoning\ncapabilities. Consequently, pruning methods must carefully control individual\nimage tokens throughout the LVLM reasoning process. Our empirical analysis\nreveals that existing methods struggle to adequately balance reductions in\ncomputational overhead with the necessity to maintain high segmentation\naccuracy. In this work, we propose LVLM_CSP, a novel training free visual token\npruning method specifically designed for LVLM based reasoning segmentation\ntasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.\nInitially, the LVLM performs coarse-grained visual reasoning using a subset of\nselected image tokens. Next, fine grained reasoning is conducted, and finally,\nmost visual tokens are pruned in the last stage. Extensive experiments\ndemonstrate that LVLM_CSP achieves a 65% reduction in image token inference\nFLOPs with virtually no accuracy degradation, and a 70% reduction with only a\nminor 1% drop in accuracy on the 7B LVLM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10859v1","title":"A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles","summary":"The problem of finding a path between two points while avoiding obstacles is\ncritical in robotic path planning. We focus on the feasibility problem:\ndetermining whether such a path exists. We model the robot as a query-specific\nrectangular object capable of moving parallel to its sides. The obstacles are\naxis-aligned, rectangular, and may overlap. Most previous works only consider\nnondisjoint rectangular objects and point-sized or statically sized robots. Our\napproach introduces a novel technique leveraging generalized Gabriel graphs and\nconstructs a data structure to facilitate online queries regarding path\nfeasibility with varying robot sizes in sublinear time. To efficiently handle\nfeasibility queries, we propose an online algorithm utilizing sweep line to\nconstruct a generalized Gabriel graph under the $L_\\infty$ norm, capturing key\ngap constraints between obstacles. We utilize a persistent disjoint-set union\ndata structure to efficiently determine feasibility queries in\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ total space.","main_category":"cs.CG","categories":"cs.CG,cs.RO","published":"2025-04-15T04:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.10875v1","title":"Emergence of Creativity and Individuality in Music: Insights from\n  Brain's Statistical Learning and its Embodied Mechanisms","summary":"Music is a universal feature of human culture, linked to embodied cognitive\nfunctions that drive learning, action, and the emergence of creativity and\nindividuality. Evidence highlights the critical role of statistical learning an\nimplicit cognitive process of the brain in musical creativity and\nindividuality. Despite its significance, the precise neural and computational\nmechanisms underpinning these dynamic and embodied cognitive processes re-main\npoorly understood. This paper discusses how individuality and creativity emerge\nwithin the framework of the brain's statistical learning, drawing on a series\nof neural and computational studies. This work offers perspectives on the\nmechanisms driving the heterogeneous nature of statistical learning abilities\nand embodied mechanisms and provides a framework to explain the paradoxical\nphenomenon where individuals with specific cognitive traits that limit certain\nperceptual abilities excel in creative domains.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-15T05:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.10877v1","title":"Weather-Aware Object Detection Transformer for Domain Adaptation","summary":"RT-DETRs have shown strong performance across various computer vision tasks\nbut are known to degrade under challenging weather conditions such as fog. In\nthis work, we investigate three novel approaches to enhance RT-DETR robustness\nin foggy environments: (1) Domain Adaptation via Perceptual Loss, which\ndistills domain-invariant features from a teacher network to a student using\nperceptual supervision; (2) Weather Adaptive Attention, which augments the\nattention mechanism with fog-sensitive scaling by introducing an auxiliary\nfoggy image stream; and (3) Weather Fusion Encoder, which integrates a\ndual-stream encoder architecture that fuses clear and foggy image features via\nmulti-head self and cross-attention. Despite the architectural innovations,\nnone of the proposed methods consistently outperform the baseline RT-DETR. We\nanalyze the limitations and potential causes, offering insights for future\nresearch in weather-aware object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T05:11:18Z"}
{"aid":"http://arxiv.org/abs/2504.10878v1","title":"Large Language Model-Informed Feature Discovery Improves Prediction and\n  Interpretation of Credibility Perceptions of Visual Content","summary":"In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-15T05:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.10912v1","title":"Superconducting quantum oscillations and anomalous negative\n  magnetoresistance in a honeycomb nanopatterned oxide interface superconductor","summary":"The extremely low superfluid density and unprecedented tunability of oxide\ninterface superconductors provide an ideal platform for studying fluctuations\nin two-dimensional superconductors. In this work, we have fabricated a\nLaAlO3/KTaO3 interface superconductor patterned with a nanohoneycomb array of\ninsulating islands. Little-Parks-like magnetoresistance oscillations have been\nobserved, which are dictated by the superconducting flux quantum h/2e.\nMoreover, an anomalous negative magnetoresistance (ANMR) appears under a weak\nmagnetic field, suggesting magnetic-field-enhanced superconductivity. By\nexamining their dependences on temperature, measurement current, and electrical\ngating, we conclude that both phenomena are associated with superconducting\norder parameter: The h/2e oscillations provide direct evidence of Cooper pair\ntransport; the ANMR is interpreted as a consequence of multiple connected\nnarrow superconducting paths with strong fluctuations.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-15T06:49:00Z"}
{"aid":"http://arxiv.org/abs/2504.10943v1","title":"Drivers and barriers of adopting shared micromobility: a latent class\n  clustering model on the attitudes towards shared micromobility as part of\n  public transport trips in the Netherlands","summary":"Shared micromobility (SMM) is often cited as a solution to the first/last\nmile problem of public transport (train) travel, yet when implemented, they\noften do not get adopted by a broader travelling public. A large part of\nbehavioural adoption is related to peoples' attitudes and perceptions. In this\npaper, we develop an adjusted behavioural framework, based on the UTAUT2\ntechnology acceptance framework. We carry out an exploratory factor analysis\n(EFA) to obtain attitudinal factors which we then use to perform a latent class\ncluster analysis (LCCA), with the goal of studying the potential adoption of\nSMM and to assess the various drivers and barriers as perceived by different\nuser groups. Our findings suggest there are six distinct user groups with\nvarying intention to use shared micromobility: Progressives, Conservatives,\nHesitant participants, Bold innovators, Anxious observers and Skilled sceptics.\nBold innovators and Progressives tend to be the most open to adopting SMM and\nare also able to do so. Hesitant participants would like to, but find it\ndifficult or dangerous to use, while Skilled sceptics are capable and\nconfident, but have limited intention of using it. Conservatives and Anxious\nobservers are most negative about SMM, finding it difficult to use and\ndangerous. In general, factors relating to technological savviness,\nease-of-use, physical safety and societal perception seem to be the biggest\nbarriers to wider adoption. Younger, highly educated males are the group most\nlikely and open to using shared micromobility, while older individuals with\nlower incomes and a lower level of education tend to be the least likely.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-15T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10949v1","title":"A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)","summary":"As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T07:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.10950v1","title":"Unveiling Challenges for LLMs in Enterprise Data Engineering","summary":"Large Language Models (LLMs) have demonstrated significant potential for\nautomating data engineering tasks on tabular data, giving enterprises a\nvaluable opportunity to reduce the high costs associated with manual data\nhandling. However, the enterprise domain introduces unique challenges that\nexisting LLM-based approaches for data engineering often overlook, such as\nlarge table sizes, more complex tasks, and the need for internal knowledge. To\nbridge these gaps, we identify key enterprise-specific challenges related to\ndata, tasks, and background knowledge and conduct a comprehensive study of\ntheir impact on recent LLMs for data engineering. Our analysis reveals that\nLLMs face substantial limitations in real-world enterprise scenarios, resulting\nin significant accuracy drops. Our findings contribute to a systematic\nunderstanding of LLMs for enterprise data engineering to support their adoption\nin industry.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.10957v1","title":"When is Task Vector Provably Effective for Model Editing? A\n  Generalization Analysis of Nonlinear Transformers","summary":"Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.10973v1","title":"Early Detection of Cognitive Impairment in Elderly using a Passive\n  FPVS-EEG BCI and Machine Learning -- Extended Version","summary":"Early dementia diagnosis requires biomarkers sensitive to both structural and\nfunctional brain changes. While structural neuroimaging biomarkers have\nprogressed significantly, objective functional biomarkers of early cognitive\ndecline remain a critical unmet need. Current cognitive assessments often rely\non behavioral responses, making them susceptible to factors like effort,\npractice effects, and educational background, thereby hindering early and\naccurate detection. This work introduces a novel approach, leveraging a\nlightweight convolutional neural network (CNN) to infer cognitive impairment\nlevels directly from electroencephalography (EEG) data. Critically, this method\nemploys a passive fast periodic visual stimulation (FPVS) paradigm, eliminating\nthe need for explicit behavioral responses or task comprehension from the\nparticipant. This passive approach provides an objective measure of working\nmemory function, independent of confounding factors inherent in active\ncognitive tasks, and offers a promising new avenue for early and unbiased\ndetection of cognitive decline.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.HC,cs.LG,J.3","published":"2025-04-15T08:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10980v1","title":"Planar Hall effect in ultrathin topological insulator films","summary":"The planar Hall effect (PHE), previously observed in Weyl and Dirac\nsemimetals due to the chiral anomaly, emerges with a different origin in\ntopological insulators (TIs), where in-plane magnetic fields induce resistivity\nanisotropy. In strictly two-dimensional TIs, PHE is generally suppressed due to\nthe inability of the out-of-plane Berry curvature to couple to the in-plane\nband velocity of the charge carriers. Here, we demonstrate that in ultrathin TI\nfilms, a quasi-two-dimensional system, intersurface tunneling coupling with\nin-plane magnetization induces electronic anisotropy, enabling a finite PHE. In\naddition, we reveal that strong in-plane magnetization can stabilize the\nthickness-dependent quantum anomalous Hall effect, typically associated with\nout-of-plane magnetization. These insights advance the understanding of\nmagnetic topological phases, paving the way for next-generation spintronic\ndevices and magnetic sensing technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T08:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.10987v1","title":"Leveraging Vertical Public-Private Split for Improved Synthetic Data\n  Generation","summary":"Differentially Private Synthetic Data Generation (DP-SDG) is a key enabler of\nprivate and secure tabular-data sharing, producing artificial data that carries\nthrough the underlying statistical properties of the input data. This typically\ninvolves adding carefully calibrated statistical noise to guarantee individual\nprivacy, at the cost of synthetic data quality. Recent literature has explored\nscenarios where a small amount of public data is used to help enhance the\nquality of synthetic data. These methods study a horizontal public-private\npartitioning which assumes access to a small number of public rows that can be\nused for model initialization, providing a small utility gain. However,\nrealistic datasets often naturally consist of public and private attributes,\nmaking a vertical public-private partitioning relevant for practical synthetic\ndata deployments. We propose a novel framework that adapts horizontal\npublic-assisted methods into the vertical setting. We compare this framework\nagainst our alternative approach that uses conditional generation, highlighting\ninitial limitations of public-data assisted methods and proposing future\nresearch directions to address these challenges.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-15T08:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.10990v1","title":"Mathematical Analysis of the PDE Model for the Consensus-based\n  Optimization","summary":"In this paper, we develop an analytical framework for the partial\ndifferential equation underlying the consensus-based optimization model. The\nmain challenge arises from the nonlinear, nonlocal nature of the consensus\npoint, coupled with a diffusion term that is both singular and degenerate. By\nemploying a regularization procedure in combination with a compactness\nargument, we establish the global existence and uniqueness of weak solutions in\n$L^\\infty(0,T;L^1\\cap L^\\infty(\\mathbb{R}^d))$. Furthermore, we show that the\nweak solutions exhibit improved $H^2$-regularity when the initial data is\nregular.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-15T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.10994v1","title":"Near-room-temperature zero-dimensional polariton lasers with sub-10 GHz\n  linewidths","summary":"Narrow and brilliant spectral lines are essential assets for high-resolution\nspectroscopy as well as for precision sensing and optomechanics. In\nsemiconductor structures and, in particular, in the well-established (Al,Ga)As\nmaterial system, strong emission lines with nanosecond coherence times can be\nprovided by the opto-electronic resonances of microcavity exciton-polariton\ncondensates. The temporal coherence of these resonances, however, normally\nrapidly deteriorates as the temperature increases beyond a few tens of kelvins\ndue to exciton dissociation. Here, we demonstrate that the temperature\nstability of polariton condensates in (Al,Ga)As can be significantly improved\nby confinement within micrometer-sized intracavity traps. We show that trapped\ncondensates can survive up to ~200 K while maintaining a light-matter character\nwith decoherence rates below 10 GHz (i.e., $< 40 {\\mu}$eV linewidths). These\nlinewidths are by an order of magnitude smaller than those so far reported for\nother solid-state systems at these temperatures. Confinement thus provides a\npathway towards room-temperature polariton condensation using the\nwell-established (Al,Ga)As material system with prospects for application in\nscalable on-chip photonic devices for optical processing, sensing, and\ncomputing.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.quant-gas,physics.optics","published":"2025-04-15T09:11:45Z"}
{"aid":"http://arxiv.org/abs/2504.11013v1","title":"Effective Theory of Ultrafast Skyrmion Nucleation","summary":"Laser-induced ultrafast skyrmion nucleation has been experimentally\ndemonstrated in several materials. So far, atomistic models have been used to\ncorroborate experimental results. However, such simulations do not provide a\nsimple intuitive understanding of the underlying physics. Here, we propose a\ncoarse-grained effective theory where skyrmions can be nucleated or annihilated\nby thermal activation over energy barriers. Evaluating these two processes\nduring a heat pulse shows good agreement with atomistic spin dynamics\nsimulations and experiments while drastically reducing computational\ncomplexity. Furthermore, the effective theory provides a direct guide for\nexperimentally optimizing the number of nucleated skyrmions. Interestingly, the\nmodel also predicts a novel pathway for ultrafast annihilation of skyrmions.\nOur results pave the way for a deeper understanding of ultrafast nanomagnetism\nand the role of non-equilibrium physics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T09:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.11016v1","title":"Heating reduction as collective action: Impact on attitudes, behavior\n  and energy consumption in a Polish field experiment","summary":"Heating and hot water usage account for nearly 80% of household energy\nconsumption in the European Union. In order to reach the EU New Deal goals, new\npolicies to reduce heat energy consumption are indispensable. However, research\ntargeting reductions concentrates either on technical building interventions\nwithout considerations of people's behavior, or psychological interventions\nwith no technical interference. Such interventions can be promising, but their\ntrue potential for scaling up can only be realized by testing approaches that\nintegrate behavioral and technical solutions in tandem rather than in\nisolation. In this research, we study a mix of psychological and technical\ninterventions targeting heating and hot water demand among students in Polish\nuniversity dormitories. We evaluate effects on building energy consumption,\nbehavioral spillovers and on social beliefs and attitudes in a pre-post\nquasi-experimental mixed-method field study in three student dormitories. Our\nfindings reveal that the most effective approaches to yield energy savings were\na direct, collectively framed request to students to reduce thermostat settings\nfor the environment, and an automated technical adjustment of the heating curve\ntemperature. Conversely, interventions targeting domestic hot water had\nunintended effects, including increased energy use and negative spillovers,\nsuch as higher water consumption. Further, we find that informing students\nabout their active, collective participation had a positive impact on perceived\nsocial norms. Our findings highlight the importance of trialing interventions\nin controlled real-world settings to understand the interplay between technical\nsystems, behaviors, and social impacts to enable scalable, evidence-based\npolicies driving an effective and sustainable energy transition.","main_category":"cs.ET","categories":"cs.ET,cs.CY","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11047v1","title":"Hints for a Geon from Causal Dynamic Triangulations","summary":"The existence of geons, physical states of self-bound gravitons, has long\nbeen proposed. In the context of four-dimensional causal dynamical\ntriangulation simulations we investigate this possibility by measuring\ncurvature-curvature correlators of different gravitational operators. We find a\nbehavior consistent with a massive state, independent of the operators\nconsidered, over a certain distance window. While at most a hint, this is\ntantalizing due to its possible implications for dark matter or (primordial)\nblack holes. We also find indications that the phase of rapid expansion of the\nobtained de Sitter universe impacts the mass, and relates to quantum\nfluctuations of space-time.","main_category":"hep-lat","categories":"hep-lat,gr-qc,hep-ph,hep-th","published":"2025-04-15T10:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.11052v1","title":"Weyl-mediated Ruderman-Kittel-Kasuya-Yosida interaction revisited:\n  imaginary-time formalism and finite temperature effects","summary":"Noncentrosymmetric magnetic Weyl semimetals provide a platform for\ninvestigating the interplay among magnetism, inversion symmetry breaking, and\ntopologically nontrivial Weyl fermions. The Weyl-mediated\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction may be related to the magnetic\norders observed in rare-earth magnetic Weyl semimetals. Previous studies of\nRKKY interaction between magnetic impurities in Weyl semimetals found\nHeisenberg, Ising-like, and Dzyaloshinskii-Moriya (DM) types of interactions.\nHowever, different range functions are obtained in the literature. In this\nwork, we calculate the Weyl-mediated RKKY interaction by using the\ndivergence-free imaginary-time formalism and obtain exact analytical results at\nfinite temperature. The discrepancies among zero temperature range functions in\nthe literature are resolved. At nonzero temperature, the interaction strength\ndecays exponentially in the long distance limit. But in the short distance\nlimit, the DM interaction shows a thermal enhancement, an effect persists up to\nhigher temperature for shorter distance. This provides a mechanism stabilizing\nthe helical order observed in rare-earth magnetic Weyl semimetals.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T10:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.11055v1","title":"Crane: Context-Guided Prompt Learning and Attention Refinement for\n  Zero-Shot Anomaly Detections","summary":"Anomaly Detection (AD) involves identifying deviations from normal data\ndistributions and is critical in fields such as medical diagnostics and\nindustrial defect detection. Traditional AD methods typically require the\navailability of normal training samples; however, this assumption is not always\nfeasible, as collecting such data can be impractical. Additionally, these\nmethods often struggle to generalize across different domains. Recent\nadvancements, such as AnomalyCLIP and AdaCLIP, utilize the zero-shot\ngeneralization capabilities of CLIP but still face a performance gap between\nimage-level and pixel-level anomaly detection. To address this gap, we propose\na novel approach that conditions the prompts of the text encoder based on image\ncontext extracted from the vision encoder. Also, to capture fine-grained\nvariations more effectively, we have modified the CLIP vision encoder and\naltered the extraction of dense features. These changes ensure that the\nfeatures retain richer spatial and structural information for both normal and\nanomalous prompts. Our method achieves state-of-the-art performance, improving\nperformance by 2% to 29% across different metrics on 14 datasets. This\ndemonstrates its effectiveness in both image-level and pixel-level anomaly\ndetection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:42:25Z"}
{"aid":"http://arxiv.org/abs/2504.11060v1","title":"Goos-Hänchen Shift and Photonic Spin Hall Effect in Semi-Dirac\n  Material Heterostructures","summary":"We investigate the photonic spin Hall effect (PSHE) and the Goos-H\\\"anchen\nshift (GH shift) in semi-Dirac\n  materials. Through theoretical modeling, we demonstrate that the anisotropic\ndielectric function in semi-Dirac\n  materials play a critical role in determining the magnitude and polarity of\nthese optical displacements. Further more, by utilizing the unidirectional\ndrift of massless Dirac electrons in Semi-Dirac materials, we systematically\n  reveal how the drift velocity and direction modulate the behavior of optical\ndisplacements. The results indicate\n  that semi-Dirac materials provide a versatile platform for controlling\nspin-dependent photonic phenomena with\n  their material anisotropy and carrier transport. This work opens a new avenue\nfor designing advanced photonic\n  devices with tunable optical responses, particularly with significant\napplication potential in quantum information\n  processing and topological photonics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.11061v1","title":"Synthesis and characterization of gold-coated nanodiamonds through green\n  chemistry as potential radiosensitizers for proton therapy","summary":"In this work the synthesis and characterization of novel gold-nanodiamond\nnanoparticles was performed. The synthesis was based on the reduction of gold\nonto the different types of nanodiamond (annealed or annealed and oxidized, 50\nor 230 nm) using root extracts of Nympheaea alba as a reducing agent. These\ngold-coated nanodiamonds were characterized by UV-Vis, PXRD, DLS,\nzeta-potential, PIXE, Raman, SEM, and TEM, assessing particle size, stability,\nand gold coating effectiveness. Cellular studies in the A549 and Panc1 cancer\ncell lines assessed uptake, cytotoxicity, and colony formation to evaluate\nNDAu's biological activity. NDAu demonstrated strong cellular uptake and\ncytotoxic effects in A549 and Panc1 cell lines, reducing cell survival in\nclonogenic assay. Futher research in the capabilites of these nanoparticles for\nproton therapy will be performed.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-15T10:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11075v1","title":"Emergence of Goal-Directed Behaviors via Active Inference with\n  Self-Prior","summary":"Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T11:16:27Z"}
{"aid":"http://arxiv.org/abs/2504.11085v1","title":"TD-Suite: All Batteries Included Framework for Technical Debt\n  Classification","summary":"Recognizing that technical debt is a persistent and significant challenge\nrequiring sophisticated management tools, TD-Suite offers a comprehensive\nsoftware framework specifically engineered to automate the complex task of its\nclassification within software projects. It leverages the advanced natural\nlanguage understanding of state-of-the-art transformer models to analyze\ntextual artifacts, such as developer discussions in issue reports, where subtle\nindicators of debt often lie hidden.\n  TD-Suite provides a seamless end-to-end pipeline, managing everything from\ninitial data ingestion and rigorous preprocessing to model training, thorough\nevaluation, and final inference. This allows it to support both straightforward\nbinary classification (debt or no debt) and more valuable, identifying specific\ncategories like code, design, or documentation debt, thus enabling more\ntargeted management strategies.\n  To ensure the generated models are robust and perform reliably on real-world,\noften imbalanced, datasets, TD-Suite incorporates critical training\nmethodologies: k-fold cross-validation assesses generalization capability,\nearly stopping mechanisms prevent overfitting to the training data, and class\nweighting strategies effectively address skewed data distributions. Beyond core\nfunctionality, and acknowledging the growing importance of sustainability, the\nframework integrates tracking and reporting of carbon emissions associated with\nthe computationally intensive model training process.\n  It also features a user-friendly Gradio web interface in a Docker container\nsetup, simplifying model interaction, evaluation, and inference.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.11090v1","title":"Towards global equity in political polarization research","summary":"With a folk understanding that political polarization refers to\nsocio-political divisions within a society, many have proclaimed that we are\nmore divided than ever. In this account, polarization has been blamed for\npopulism, the erosion of social cohesion, the loss of trust in the institutions\nof democracy, legislative dysfunction, and the collective failure to address\nexistential risks such as Covid-19 or climate change. However, at a global\nscale there is surprisingly little academic literature which conclusively\nsupports these claims, with half of all studies being U.S.-focused. Here, we\nprovide an overview of the global state of research on polarization,\nhighlighting insights that are robust across countries, those unique to\nspecific contexts, and key gaps in the literature. We argue that addressing\nthese gaps is urgent, but has been hindered thus far by systemic and cultural\nbarriers, such as regionally stratified restrictions on data access and\nmisaligned research incentives. If continued cross-disciplinary inertia means\nthat these disparities are left unaddressed, we see a substantial risk that\ncountries will adopt policies to tackle polarization based on inappropriate\nevidence, risking flawed decision-making and the weakening of democratic\ninstitutions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-15T11:34:12Z"}
{"aid":"http://arxiv.org/abs/2504.11092v1","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\n  Inpainting","summary":"Reconstructing 4D dynamic scenes from casually captured monocular videos is\nvaluable but highly challenging, as each timestamp is observed from a single\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\nvideo synthesis by augmenting observation views - synthesizing multi-view\nvideos from a monocular input. Unlike existing methods that either solely\nleverage geometric priors for supervision or use generative priors while\noverlooking geometry, we integrate both. This reformulates view augmentation as\na video inpainting task, where observed views are warped into new viewpoints\nbased on monocular depth priors. To achieve this, we train a video inpainting\nmodel on unposed web videos with synthetically generated masks that mimic\nwarping occlusions, ensuring spatially and temporally consistent completion of\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\nintroduce an iterative view augmentation strategy and a robust reconstruction\nloss. Experiments demonstrate that our method effectively improves monocular 4D\nscene reconstruction and completion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11095v1","title":"Magnetotransport and activation energy of the surface states in Cd3As2\n  thin films","summary":"Recent experiments performed the magnetotransport measurements in\n(001)-oriented Cd$_3$As$_2$ thin films and attributed the magnetotransport\nproperties to the surface states. In this paper, by using an effective model to\ndescribe the surface states, we analyze the Landau bands and then calculate the\nmagnetoconductivities and magnetoresistivities. From these results, the\nfeatures of two-dimensional quantum Hall effect of the surface states can be\ncaptured. More importantly, we reveal that the activation energy is determined\nby the Hall plateau width, which can explain the experimental observations that\nthe activation energies at odd plateaus are larger than those at even plateaus.\nWe also analyze the roles played by the structural inversion symmetry breaking\nand impurity scatterings in the magnetotransport, and suggest that their\ncombined effects would lead to the absence of some Hall plateaus.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T11:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11111v1","title":"S$^2$Teacher: Step-by-step Teacher for Sparsely Annotated Oriented\n  Object Detection","summary":"Although fully-supervised oriented object detection has made significant\nprogress in multimodal remote sensing image understanding, it comes at the cost\nof labor-intensive annotation. Recent studies have explored weakly and\nsemi-supervised learning to alleviate this burden. However, these methods\noverlook the difficulties posed by dense annotations in complex remote sensing\nscenes. In this paper, we introduce a novel setting called sparsely annotated\noriented object detection (SAOOD), which only labels partial instances, and\npropose a solution to address its challenges. Specifically, we focus on two key\nissues in the setting: (1) sparse labeling leading to overfitting on limited\nforeground representations, and (2) unlabeled objects (false negatives)\nconfusing feature learning. To this end, we propose the S$^2$Teacher, a novel\nmethod that progressively mines pseudo-labels for unlabeled objects, from easy\nto hard, to enhance foreground representations. Additionally, it reweights the\nloss of unlabeled objects to mitigate their impact during training. Extensive\nexperiments demonstrate that S$^2$Teacher not only significantly improves\ndetector performance across different sparse annotation levels but also\nachieves near-fully-supervised performance on the DOTA dataset with only 10%\nannotation instances, effectively balancing detection accuracy with annotation\nefficiency. The code will be public.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.11139v1","title":"Non-stabilizerness in open XXZ spin chains: Universal scaling and\n  dynamics","summary":"Magic, or non-stabilizerness, is a crucial quantum resource, yet its dynamics\nin open quantum systems remain largely unexplored. We investigate magic in the\nopen XXZ spin chain under either boundary gain and loss, or bulk dephasing\nusing the stabilizer R\\'enyi entropy $M_2$. To enable scalable simulations of\nlarge systems, we develop a novel, highly efficient algorithm for computing\n$M_2$ within the matrix product states formalism while maintaining constant\nbond dimension--an advancement over existing methods. For boundary driving, we\nuncover universal scaling laws, $M_2(t) \\sim t^{1/z}$, linked to the dynamical\nexponent $z$ for several distinct universality classes. We also disentangle\nclassical and quantum contributions to magic by introducing a mean-field\napproximation for magic, thus emphasizing the prominent role of quantum\ncritical fluctuations in non-stabilizerness. For bulk dephasing, dissipation\ncan transiently enhance magic before suppressing it, and drive it to a\nnontrivial steady-state value. These findings position magic as a powerful\ndiagnostic tool for probing universality and dynamics in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-15T12:41:52Z"}
{"aid":"http://arxiv.org/abs/2504.11143v1","title":"Taming Consistency Distillation for Accelerated Human Image Animation","summary":"Recent advancements in human image animation have been propelled by video\ndiffusion models, yet their reliance on numerous iterative denoising steps\nresults in high inference costs and slow speeds. An intuitive solution involves\nadopting consistency models, which serve as an effective acceleration paradigm\nthrough consistency distillation. However, simply employing this strategy in\nhuman image animation often leads to quality decline, including visual\nblurring, motion degradation, and facial distortion, particularly in dynamic\nregions. In this paper, we propose the DanceLCM approach complemented by\nseveral enhancements to improve visual quality and motion continuity at\nlow-step regime: (1) segmented consistency distillation with an auxiliary\nlight-weight head to incorporate supervision from real video latents,\nmitigating cumulative errors resulting from single full-trajectory generation;\n(2) a motion-focused loss to centre on motion regions, and explicit injection\nof facial fidelity features to improve face authenticity. Extensive qualitative\nand quantitative experiments demonstrate that DanceLCM achieves results\ncomparable to state-of-the-art video diffusion models with a mere 2-4 inference\nsteps, significantly reducing the inference burden without compromising video\nquality. The code and models will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.11156v1","title":"A preliminary cosmological analysis of stellar population synthesis of\n  galaxies released by LAMOST LRS DR11","summary":"The evolution of the universe together with the galaxies is one of the\nfundamental issues that we humans are most interested in. Both the observations\nof tidal streams from SDSS and the theory of $\\Lambda$CDM support the\nhierarchical merging theory. The study of high redshift celestial bodies\ncontributes to a more in-depth study of cosmology. The LAMOST low resolution\nsearch catalog DR11 v1.0 has released 11,939,296 spectra, including 11,581,542\nstars, 275,302 galaxies, and 82,452 quasars, and so on. The data of 28,780\nstellar population synthesis of galaxies and some high redshift quasars are\nused to do a preliminary statistical research. We selected the data with small\nerrors for analysis and obtained some basic statistical conclusions. Older\ngalaxies have relatively larger stellar velocity dispersions. The larger the\nmetallicity, the greater the stellar velocity dispersion. These statistical\nresults are reasonable and consistent with previous work. Because the stellar\nvelocity dispersion is driven by the total mass of a galaxy at the first order\nand more massive galaxies have older ages and greater metallicities. The\nspectra of high redshift quasars show clear Gunn-Peterson trough and\nLyman-$\\alpha$ forest. The identified emission lines and high redshift\ncelestial spectra released by LAMOST can be used for cosmological research.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.11157v1","title":"Similarity Constrained CC2 for Efficient Coupled Cluster Nonadiabatic\n  Dynamics","summary":"Despite their high accuracy, standard coupled cluster models cannot be used\nfor nonadiabatic molecular dynamics simulations because they yield unphysical\ncomplex excitation energies at conical intersections between same-symmetry\nexcited states. On the other hand, similarity constrained coupled cluster\ntheory has enabled the application of coupled cluster theory in such dynamics\nsimulations. Here, we present a similarity constrained perturbative doubles\n(SCC2) model with same-symmetry excited-state conical intersections that\nexhibit correct topography, topology, and real excitation energies. This is\nachieved while retaining the favorable computational scaling of the standard\nCC2 model. We illustrate the model for conical intersections in hypofluorous\nacid and thymine, and compare its performance with other methods. The results\ndemonstrate that conical intersections between excited states can be described\ncorrectly and efficiently at the SCC2 level. We therefore expect that the SCC2\nmodel will enable coupled cluster nonadiabatic dynamics simulations for large\nmolecular systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-15T13:04:06Z"}
{"aid":"http://arxiv.org/abs/2504.11162v1","title":"Scalable Transceiver Design for Multi-User Communication in FDD Massive\n  MIMO Systems via Deep Learning","summary":"This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.11165v1","title":"YOLO-RS: Remote Sensing Enhanced Crop Detection Methods","summary":"With the rapid development of remote sensing technology, crop classification\nand health detection based on deep learning have gradually become a research\nhotspot. However, the existing target detection methods show poor performance\nwhen dealing with small targets in remote sensing images, especially in the\ncase of complex background and image mixing, which is difficult to meet the\npractical application requirementsite. To address this problem, a novel target\ndetection model YOLO-RS is proposed in this paper. The model is based on the\nlatest Yolov11 which significantly enhances the detection of small targets by\nintroducing the Context Anchor Attention (CAA) mechanism and an efficient\nmulti-field multi-scale feature fusion network. YOLO-RS adopts a bidirectional\nfeature fusion strategy in the feature fusion process, which effectively\nenhances the model's performance in the detection of small targets. Small\ntarget detection. Meanwhile, the ACmix module at the end of the model backbone\nnetwork solves the category imbalance problem by adaptively adjusting the\ncontrast and sample mixing, thus enhancing the detection accuracy in complex\nscenes. In the experiments on the PDT remote sensing crop health detection\ndataset and the CWC crop classification dataset, YOLO-RS improves both the\nrecall and the mean average precision (mAP) by about 2-3\\% or so compared with\nthe existing state-of-the-art methods, while the F1-score is also significantly\nimproved. Moreover, the computational complexity of the model only increases by\nabout 5.2 GFLOPs, indicating its significant advantages in both performance and\nefficiency. The experimental results validate the effectiveness and application\npotential of YOLO-RS in the task of detecting small targets in remote sensing\nimages.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.11174v1","title":"Algorithmic thresholds in combinatorial optimization depend on the time\n  scaling","summary":"In the last decades, many efforts have focused on analyzing typical-case\nhardness in optimization and inference problems. Some recent work has pointed\nout that polynomial algorithms exist, running with a time that grows more than\nlinearly with the system size, which can do better than linear algorithms,\nfinding solutions to random problems in a wider range of parameters. However, a\ntheory for polynomial and superlinear algorithms is in general lacking. In this\npaper, we examine the performance of the Simulated Annealing algorithm, a\nstandard, versatile, and robust choice for solving optimization and inference\nproblems, in the prototypical random $K$-Sat problem. For the first time, we\nshow that the algorithmic thresholds depend on the time scaling of the\nalgorithm with the size of the system. Indeed, one can identify not just one,\nbut different thresholds for linear, quadratic, cubic regimes (and so on). This\nobservation opens new directions in studying the typical case hardness in\noptimization problems.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-15T13:27:57Z"}
{"aid":"http://arxiv.org/abs/2504.11184v1","title":"A simple, robust and cost-effective method to achieve dispersion\n  matching in swept source OCT","summary":"Optical path length and dispersion matching in both measurement and reference\narms of an OCT system is critical for achieving bandwidth-limited axial\nresolution. To minimize or eliminate dispersion mismatch, most, if not all,\nfiber-based OCT realisations employ a reference arm configuration that is as\nclosely identical to the measurement arm as possible. This typically includes a\ncollimator, dispersion compensating material (or sometimes a set of lenses), as\nwell as a mirror (or retro-reflector) mounted on a translation stage. However,\nthis solution makes the total instrument cost higher and the setup bulkier than\nnecessary and it also renders the reference arm mechanically unstable. Here, a\nsimple yet robust, low-cost reference arm setup is presented and its ability to\ncompensate for measurement arm dispersion is demonstrated. We use a single-mode\nfiber cleaved and polished perpendicular to the fiber axis to construct the\nreference arm. The length and material of the fibre is determined by\nconsidering the optical path length and dispersion of the measurement arm.\nExperimental images demonstrate the operation of the novel reference arm in our\nSwept-source Optical Coherence Tomography.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T13:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.11186v1","title":"Benchmarking Next-Generation Reasoning-Focused Large Language Models in\n  Ophthalmology: A Head-to-Head Evaluation on 5,888 Items","summary":"Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T13:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.11210v1","title":"Differentiating Formation Models with New Dynamical Masses for the PDS\n  70 Protoplanets","summary":"Hot- and cold-start planet formation models predict differing luminosities\nfor the young, bright planets that direct imaging surveys are most sensitive\nto. However, precise mass estimates are required to distinguish between these\nmodels observationally. The presence of two directly imaged planets, PDS 70 b\nand c, in the PDS 70 protoplanetary disk provides us a unique opportunity for\ndynamical mass measurements, since the masses for these planets are currently\npoorly constrained. Fitting orbital parameters to new astrometry of these\nplanets, taken with VLTI/GRAVITY in the $K$~band, we find $2\\sigma$ dynamical\nupper mass limits of 4.9 $M_{\\rm Jup}$ for b and 13.6 $M_{\\rm Jup}$ for c.\nAdding astrometry from the newly proposed planet candidate PDS 70 d into our\nmodel, we determine $2\\sigma$ dynamical upper mass limits of 5.3 $M_{\\rm Jup}$,\n7.5 $M_{\\rm Jup}$ and 2.2 $M_{\\rm Jup}$ for b, c, and the candidate d\nrespectively. However, $N$-body analysis of the orbits fit in this case suggest\nthat the inclusion of $d$ makes the system unstable. Using the upper mass\nlimits for b and c we rule out the coldest-start formation models for both\nplanets, calculating minimum post-formation entropies ($S_i$) of 9.5 $k_{\\rm\nB}/{\\rm baryon}$ and 8.4 $k_{\\rm B}/{\\rm baryon}$ respectively. This places PDS\n70 b and c on the growing list of directly-imaged planets inconsistent with\ncold-start formation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.11212v1","title":"SDFs from Unoriented Point Clouds using Neural Variational Heat\n  Distances","summary":"We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-15T14:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.11226v1","title":"Ab initio Maxwell-Bloch Approach for X-Ray Excitations in\n  Two-Dimensional Materials","summary":"The combination of Maxwell and X-ray Bloch equations forms an appropriate\nframework to describe ultrafast time-resolved X-ray experiments on attosecond\ntime scale in crystalline solids. However, broadband experiments such as X-ray\nabsorption near edge spectroscopy or resonant inelastic X-ray scattering\nrequire a detailed knowledge of the electronic structure and transition matrix\nelements. Here, we show how to fill this gap by combining the Maxwell-X-ray\nBloch formalism with first-principles calculations treating explicitly the core\nstates. The resulting X-ray absorption spectrum recovers key spectral\nsignatures which were missing in our previous work relying on a semi-empirical\ntight-binding approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.11235v1","title":"Guided Wave-Based Structural Awareness Under Varying Operating States\n  via Manifold Representations","summary":"Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.11246v1","title":"Respiratory Inhaler Sound Event Classification Using Self-Supervised\n  Learning","summary":"Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.LG","published":"2025-04-15T14:44:47Z"}
{"aid":"http://arxiv.org/abs/2504.11254v1","title":"Model Consistency of Iterative Regularization for Low-Complexity\n  Regularization","summary":"Regularization is a core component of modern inverse problems as it allows to\nestablish well-posedness to the solution of interests. Popular regularization\napproaches include variational regularization and iterative regularization. The\nformer one can be tackled by solving a variational optimization problem, which\nis the sum of a regularization term and a data-fidelity term balanced by a\nproper weight, while the latter one chooses a proper stopping time to avoid\noverfitting to the noise. In the study of regularization, an important topic is\nthe relation between the solution obtained by regularization and the original\nground truth. When the ground truth has low-complexity structure which is\nencoded as the \"model\", a sensitivity property shows that the solution obtained\nfrom proper regularization that promotes the same structure is robust to small\nperturbations, this is called \"model consistency\". For variational\nregularization, model consistency of linear inverse problem is studied in [1].\nWhile, for iterative regularization, the existence of model consistency is an\nopen problem. In this paper, based on a recent development of partial\nsmoothness which is also considered in [1], we show that if the noise level is\nsufficiently small and a proper stopping time is chosen, the solution by\niterative regularization also achieves model consistency and more exhibit local\nlinear convergence behavior. Numerical simulations are provided to verify our\ntheoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.11260v1","title":"$QQ$-systems and tropical geometry","summary":"We investigate the system of polynomial equations, known as $QQ$-systems,\nwhich are closely related to the so-called Bethe ansatz equations of the XXZ\nspin chain, using the methods of tropical geometry.","main_category":"math.AG","categories":"math.AG,hep-th,math-ph,math.MP,math.QA,math.RT","published":"2025-04-15T14:59:26Z"}
{"aid":"http://arxiv.org/abs/2504.11339v1","title":"Optimal and Scalable Augmented Lagrangian preconditioners for Fictitious\n  Domain problems","summary":"We present optimal and scalable preconditioning techniques to solve linear\nsystems of equations with a block two-by-two and three-by-three structure\narising from fictitious domain problems and from finite element discretizations\nof immersed boundary methods. In particular, we propose two augmented\nLagrangian-based preconditioners to accelerate the convergence of iterative\nsolvers for these two classes of linear. We consider two relevant examples to\nillustrate the performance of these preconditioners when used in conjunction\nwith flexible GMRES: the Poisson and the Stokes fictitious domain problems. A\nspectral analysis is established for both exact and inexact versions of these\npreconditioners. We show the effectiveness of the proposed approach and the\nrobustness of our preconditioning strategy through extensive numerical tests in\nboth two and three dimensions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.11343v1","title":"A Minimalist Approach to LLM Reasoning: from Rejection Sampling to\n  Reinforce","summary":"Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,stat.ML","published":"2025-04-15T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.11348v1","title":"Circuit metaconstruction in logspace for Rice-like complexity lower\n  bounds in ANs and SGRs","summary":"A new proof technique combining finite model theory and dynamical systems has\nrecently been introduced to obtain general complexity lower bounds on any\nquestion one may formulate on the dynamics (seen as a graph) of a given\nautomata network (AN). ANs are abstract finite dynamical systems of interacting\nentities whose evolution rules are encoded as circuits, hence the study also\napplies to succinct graph representations (SGRs). In this article, we detail\nthe construction of circuits to obtain general complexity lower bounds\n(metareduction) and show that the reduction is feasible in logarithmic space.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T16:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.11355v1","title":"Neural Networks for on-chip Model Predictive Control: a Method to Build\n  Optimized Training Datasets and its application to Type-1 Diabetes","summary":"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.11356v1","title":"Dimension preserving set-valued approximation and decomposition via\n  metric sum","summary":"In the literature, the Minkowski-sum and the metric-sum of compact sets are\nhighlighted. While the first is associative, the latter is not. But the major\ndrawback of the Minkowski combination is that, by increasing the number of\nsummands, this leads to convexification. The present article is uncovered in\ntwo folds: The initial segment presents a novel approach to approximate a\ncontinuous set-valued function with compact images via a fractal approach using\nthe metric linear combination of sets. The other segment contains the dimension\nanalysis of the distance set of graph of set-valued function and solving the\ncelebrated distance set conjecture. In the end, a decomposition of any\ncontinuous convex compact set-valued function is exhibited that preserves the\nHausdorff dimension, so this will serve as a method for dealing with\ncomplicated set-valued functions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T16:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.11381v1","title":"RankAlign: A Ranking View of the Generator-Validator Gap in Large\n  Language Models","summary":"Although large language models (LLMs) have become generally more capable and\naccurate across many tasks, some fundamental sources of unreliability remain in\ntheir behavior. One key limitation is their inconsistency at reporting the the\nsame information when prompts are changed. In this paper, we consider the\ndiscrepancy between a model's generated answer and their own verification of\nthat answer, the generator-validator gap. We define this gap in a more\nstringent way than prior work: we expect correlation of scores from a generator\nand a validator over the entire set of candidate answers. We show that\naccording to this measure, a large gap exists in various settings, including\nquestion answering, lexical semantics tasks, and next-word prediction. We then\npropose RankAlign, a ranking-based training method, and show that it\nsignificantly closes the gap by 31.8% on average, surpassing all baseline\nmethods. Moreover, this approach generalizes well to out-of-domain tasks and\nlexical items.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.11396v1","title":"Property Inheritance for Subtensors in Tensor Train Decompositions","summary":"Tensor dimensionality reduction is one of the fundamental tools for modern\ndata science. To address the high computational overhead, fiber-wise sampled\nsubtensors that preserve the original tensor rank are often used in designing\nefficient and scalable tensor dimensionality reduction. However, the theory of\nproperty inheritance for subtensors is still underdevelopment, that is, how the\nessential properties of the original tensor will be passed to its subtensors.\nThis paper theoretically studies the property inheritance of the two key tensor\nproperties, namely incoherence and condition number, under the tensor train\nsetting. We also show how tensor train rank is preserved through fiber-wise\nsampling. The key parameters introduced in theorems are numerically evaluated\nunder various settings. The results show that the properties of interest can be\nwell preserved to the subtensors formed via fiber-wise sampling. Overall, this\npaper provides several handy analytic tools for developing efficient tensor\nanalysis","main_category":"cs.IT","categories":"cs.IT,math.IT,stat.ML","published":"2025-04-15T17:10:38Z"}
{"aid":"http://arxiv.org/abs/2504.11405v1","title":"Size-Frequency Distribution of Terrestrial Leftover Planetesimals and\n  S-complex Implanted Asteroids","summary":"The isotopic composition of meteorites linked to S-complex asteroids has been\nused to suggest that these asteroids originated in the terrestrial planet's\nregion, i.e., within 1.5 au, and later got implanted into the main asteroid\nbelt (MAB). Dynamical models of planet formation support this view. Yet, it\nremains to be demonstrated whether the currently observed size-frequency\ndistribution (SFD) of S-complex bodies in the MAB can be reproduced via this\nimplantation process. Here we studied the evolution of the SFD of planetesimals\nduring the accretion of terrestrial planets with the code LIPAD\nself-consistently accounting for growth and fragmentation of planetesimals. In\nour simulations we vary the initial surface density of planetesimals, the\ngaseous disk lifetime, and the power slope of the initial planetesimals' SFD.\nWe compared the final SFDs of leftover planetesimals in the terrestrial planet\nregion with the SFD of observed S-complex MAB objects (D $>$ 100km). We found\nthat the SFDs of our planetesimal populations and that of S-complex MAB objects\nshow very similar cumulative power index (i.e., q $\\approx$ 3.15 in\nN($>$D)$~\\propto$ D$^{-q}$) for slopes in the diameter range 100 km $<$ D $<$\n400 km by the end of our simulations. Our results support the hypothesis of\nS-complex MAB implantation from the terrestrial planet forming region, assuming\nimplantation is size-independent, and implies that implantation efficiency is\nsmaller than $\\mathcal{O}$(10$^{\\rm -2}$--10$^{\\rm -4}$) to avoid\nover-implantation of (4) Vesta-sized objects or larger.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.11406v1","title":"Multi-level Cellular Automata for FLIM networks","summary":"The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.11408v1","title":"Five dimensional rotating and Quintessence black hole and their shadows","summary":"We present a new five-dimensional rotating quintessence black hole solution.\nTo obtain this, we employ the $5D$ version of the Janis Newman algorithm, which\nincorporates the Hopf bifurcation. The variation of the quintessence parameter\n$w_q$ causes the geometry to transition from a regular rotating universe\nsurrounded by a cosmological horizon to a singular rotating geometry, which can\nrepresent a naked singularity, a singular extremal black hole, or a singular\nblack hole with both an inner and an outer (event) horizon. We have also\ndetermined the properties of the ergosphere. For the study of the shadow, we\nfollowed a novel approach in which the $2D$ shadow observed by humans\ncorresponds to cross-sections of the $3D$ shadow. We analyzed how quintessence\naffects both the size and shape of the black hole shadow, showing that\nincreasing the quintessence strength reduces the shadow radius, contrary to the\nknown results in $4D$. We also propose a speculative methodology to test the\nshadow behavior in five-dimensional scenarios, in light of the constraints\nprovided by the Event Horizon Telescope (EHT) concerning the shadow of the\nfour-dimensional supermassive black hole M87. We identify scenarios in which\nthe theoretical $5D$ results could be consistent with these observational\nconstraints. Finally, we determine the energy conditions required to support\nthe solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.11426v1","title":"A Dual-Space Framework for General Knowledge Distillation of Large\n  Language Models","summary":"Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-15T17:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.11431v1","title":"Masculine Defaults via Gendered Discourse in Podcasts and Large Language\n  Models","summary":"Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-15T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.11442v1","title":"TextArena","summary":"TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG,cs.MA","published":"2025-04-15T17:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.11447v1","title":"Diffusion Distillation With Direct Preference Optimization For Efficient\n  3D LiDAR Scene Completion","summary":"The application of diffusion models in 3D LiDAR scene completion is limited\ndue to diffusion's slow sampling speed. Score distillation accelerates\ndiffusion sampling but with performance degradation, while post-training with\ndirect policy optimization (DPO) boosts performance using preference data. This\npaper proposes Distillation-DPO, a novel diffusion distillation framework for\nLiDAR scene completion with preference aligment. First, the student model\ngenerates paired completion scenes with different initial noises. Second, using\nLiDAR scene evaluation metrics as preference, we construct winning and losing\nsample pairs. Such construction is reasonable, since most LiDAR scene metrics\nare informative but non-differentiable to be optimized directly. Third,\nDistillation-DPO optimizes the student model by exploiting the difference in\nscore functions between the teacher and student models on the paired completion\nscenes. Such procedure is repeated until convergence. Extensive experiments\ndemonstrate that, compared to state-of-the-art LiDAR scene completion diffusion\nmodels, Distillation-DPO achieves higher-quality scene completion while\naccelerating the completion speed by more than 5-fold. Our method is the first\nto explore adopting preference learning in distillation to the best of our\nknowledge and provide insights into preference-aligned distillation. Our code\nis public available on https://github.com/happyw1nd/DistillationDPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:57:13Z"}
{"aid":"http://arxiv.org/abs/2504.11454v1","title":"Elucidating the Design Space of Multimodal Protein Language Models","summary":"Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-04-15T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.11756v1","title":"AQETuner: Reliable Query-level Configuration Tuning for Analytical Query\n  Engines","summary":"Modern analytical query engines (AQEs) are essential for large-scale data\nanalysis and processing. These systems usually provide numerous query-level\ntunable knobs that significantly affect individual query performance. While\nseveral studies have explored automatic DBMS configuration tuning, they have\nseveral limitations to handle query-level tuning. Firstly, they fail to capture\nhow knobs influence query plans, which directly affect query performance.\nSecondly, they overlook query failures during the tuning processing, resulting\nin low tuning efficiency. Thirdly, they struggle with cold-start problems for\nnew queries, leading to prolonged tuning time. To address these challenges, we\npropose AQETuner, a novel Bayesian Optimization-based system tailored for\nreliable query-level knob tuning in AQEs. AQETuner first applies the attention\nmechanisms to jointly encode the knobs and plan query, effectively identifying\nthe impact of knobs on plan nodes. Then, AQETuner employs a dual-task Neural\nProcess to predict both query performance and failures, leveraging their\ninteractions to guide the tuning process. Furthermore, AQETuner utilizes\nParticle Swarm Optimization to efficiently generate high-quality samples in\nparallel during the initial tuning stage for the new queries. Experimental\nresults show that AQETuner significantly outperforms existing methods, reducing\nquery latency by up to 23.7% and query failures by up to 51.2%.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T04:18:25Z"}
{"aid":"http://arxiv.org/abs/2504.11759v1","title":"Bringing closure to FDR control: beating the e-Benjamini-Hochberg\n  procedure","summary":"False discovery rate (FDR) has been a key metric for error control in\nmultiple hypothesis testing, and many methods have developed for FDR control\nacross a diverse cross-section of settings and applications. We develop a\nclosure principle for all FDR controlling procedures, i.e., we provide a\ncharacterization based on e-values for all admissible FDR controlling\nprocedures. We leverage this idea to formulate the closed eBH procedure, a\n(usually strict) improvement over the eBH procedure for FDR control when\nprovided with e-values. We demonstrate the practical performance of closed eBH\nin simulations.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-16T04:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.11763v1","title":"Extended Short- and Long-Range Mesh Learning for Fast and Generalized\n  Garment Simulation","summary":"3D garment simulation is a critical component for producing cloth-based\ngraphics. Recent advancements in graph neural networks (GNNs) offer a promising\napproach for efficient garment simulation. However, GNNs require extensive\nmessage-passing to propagate information such as physical forces and maintain\ncontact awareness across the entire garment mesh, which becomes computationally\ninefficient at higher resolutions. To address this, we devise a novel GNN-based\nmesh learning framework with two key components to extend the message-passing\nrange with minimal overhead, namely the Laplacian-Smoothed Dual Message-Passing\n(LSDMP) and the Geodesic Self-Attention (GSA) modules. LSDMP enhances\nmessage-passing with a Laplacian features smoothing process, which efficiently\npropagates the impact of each vertex to nearby vertices. Concurrently, GSA\nintroduces geodesic distance embeddings to represent the spatial relationship\nbetween vertices and utilises attention mechanisms to capture global mesh\ninformation. The two modules operate in parallel to ensure both short- and\nlong-range mesh modelling. Extensive experiments demonstrate the\nstate-of-the-art performance of our method, requiring fewer layers and lower\ninference latency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T04:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.11769v1","title":"Sliding Block Martingale based Multi-hop Delay QoS Analysis","summary":"With the growing density of wireless networks and demand for multi-hop\ntransmissions, precise delay Quality of Service (QoS) analysis has become a\ncritical challenge. This paper introduces a multi-hop delay QoS analysis\nframework based on the sliding block martingale, addressing the loose boundary\nissue of prior methods that rely on service process martingales and min-plus\ntransformations. By constructing a sliding block martingale with a window, we\ncapture both long-term trends and short-term fluctuations in the backlog,\neliminating the reliance on the generalized incremental property. The framework\nredefines delay unreliability events using cascading attributes, deriving a\nmore compact Delay Unreliability Probability Boundary (DUPB). To improve the\nefficiency of solving the key parameter $\\theta$, we propose a Micrometric\nIntervals based Supermartingale Upcrossing Estimate Theorem, quantifying the\nupper bound of event occurrence frequency to constrain the solution space of\n$\\theta$. Simulations based on the 3GPP UMa/UMi channel model validate the\nframework's effectiveness. Results show that in 2-7 hop scenarios, the maximum\ndeviation between theoretical boundaries and Monte Carlo simulations is $4.116\n\\times 10^{-5}$, with a lower RMSE than existing methods. Iteration count and\nCPU time for solving $\\theta$ are reduced by $59\\%-72\\%$ and $60.6\\%-70.5\\%$,\nrespectively, improving analysis efficiency. Furthermore, the derived minimum\nservice rate for multi-hop queues offers a valuable reference for resource\nallocation. The framework demonstrates high accuracy, scalability, and\npracticality in complex multi-hop networks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11779v1","title":"Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video\n  Object Detection","summary":"RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of\ntraditional RGB-based VOD in challenging lighting conditions, making it more\npractical and effective in many applications.\n  However, similar to most RGBT fusion tasks, it still mainly relies on\nmanually aligned multimodal image pairs.\n  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning\nNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust\ngraph representation learning model.\n  Specifically, we first design an Adaptive Partitioning Layer (APL) to\nestimate the corresponding regions of the Thermal image within the RGB image\n(high-resolution), achieving a preliminary inexact alignment.\n  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which\nemploys a sparse information passing mechanism on the estimated inexact\nalignment to achieve reliable information interaction between different\nmodalities.\n  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we\nintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal\nSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM\naims to filter out some redundant information between adjacent frames by\nemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,\nTSB is dedicated to achieving the complementary learning of local spatial\nrelationships.\n  Extensive comparative experiments conducted on both the aligned dataset\nVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness\nand superiority of our proposed method. Our project will be made available on\nour website for free public access.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.11788v1","title":"Enhancing Web Agents with Explicit Rollback Mechanisms","summary":"With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11793v1","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency\n  for Clinical Text Classification","summary":"Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.11828v1","title":"Semiclassical causal geodesics: Minkowski spacetime case","summary":"We use an integral quantization model based on the Heisenberg-Weyl group to\ndescribe the motion of a spinless particle in the Minkowski background\nspacetime. This work is a sequel to a previous paper, devoted to mathematical\naspects of our model: construction of the space of coherent states and\nproperties of elementary observables. We compute transition amplitudes\ncorresponding to a free motion of a particle between two coherent states. These\namplitudes are then used to model quantum random walks of free relativistic\nparticles. Our quantization scheme allows us to recover interference patterns\noccurring in a standard double-slit experiment, known from the classical\napproach. This result is obtained by modeling the slits in terms of eigenstates\nof the position operator and computing transition amplitudes between position\nand coherent states. We design our model in a way which allows for a future\ngeneralization to a semi-classical quantization of the geodesic motion in\ncurved spacetimes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T07:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.11833v1","title":"Could Thinking Multilingually Empower LLM Reasoning?","summary":"Previous work indicates that large language models exhibit a significant\n\"English bias\", i.e. they often perform better when tasks are presented in\nEnglish. Interestingly, we have observed that using certain other languages in\nreasoning tasks can yield better performance than English. However, this\nphenomenon remains under-explored. In this paper, we explore the upper bound of\nharnessing multilingualism in reasoning tasks, suggesting that multilingual\nreasoning promises significantly (by nearly 10 Acc@$k$ points) and robustly\n(tolerance for variations in translation quality and language choice) higher\nupper bounds than English-only reasoning. Besides analyzing the reason behind\nthe upper bound and challenges in reaching it, we also find that common answer\nselection methods cannot achieve this upper bound, due to their limitations and\nbiases. These insights could pave the way for future research aimed at fully\nharnessing the potential of multilingual reasoning in LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T07:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.11865v1","title":"Asymptotic normality of coefficients of P-recursive polynomial sequences","summary":"In recent years, the asymptotic normality of some famous combinatorial\nsequences has been the subject of extensive study. However, the methods used to\nprove the asymptotic normality of various combinatorial sequences differ\nsignificantly. In this paper, we present a sufficient condition for\nestablishing the asymptotic normality of the coefficients of a general\nP-recursive polynomial sequence. Additionally, we provide two examples that\nillustrate the application of this sufficient condition.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T08:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.11874v1","title":"Factor-MCLS: Multi-agent learning system with reward factor matrix and\n  multi-critic framework for dynamic portfolio optimization","summary":"Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T08:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.11891v1","title":"Towards a Refined Understanding of Non-holomorphic Soft SUSY-Breaking\n  Effects on the Higgs Boson Mass Spectra","summary":"We study the impact of the non-holomorphic (NH) soft supersymmetry-breaking\nterms $ T_{33}^{\\prime D} $ and $ \\mu^\\prime $, which introduce additional\nSUSY-breaking effects beyond the holomorphic structure of the superpotential,\non the Higgs boson mass spectrum in the NH Minimal Supersymmetric Standard\nModel (NHSSM). The term $ T_{33}^{\\prime D} $ modifies the scalar bottom-quark\nmass matrix and Higgs couplings, while $ \\mu^\\prime $ affects the mass matrices\nof charginos and neutralinos. In our analysis, we incorporate constraints from\ncharge- and color-breaking (CCB) minima where we find that a portion of the\nparameter space is excluded by these constraints. Focusing on the allowed\nparameter space, the NH contributions to the light $\\cal CP$-even Higgs boson\nmass, $ M_h $, from $ \\mu^\\prime $ and $ T_{33}^{\\prime D} $ can reach up to $\n1.4 \\,\\, \\mathrm{GeV} $ and $ 90 \\,\\, \\mathrm{MeV} $, respectively. For the\nheavy $\\cal CP$-even Higgs boson mass, $ M_H $, and the charged Higgs boson\nmass, $ M_{H^{\\pm}} $, these contributions can be substantially larger in\ncertain regions of the parameter space, reaching up to $ 44 \\,\\, \\mathrm{GeV} $\nfor $ M_H $ and $ 42 \\,\\, \\mathrm{GeV} $ for $ M_{H^{\\pm}} $ due to $\n\\mu^\\prime $, and up to $ 60 \\,\\, \\mathrm{GeV} $ due to $ T_{33}^{\\prime D} $\nfor both $ M_H $ and $ M_{H^{\\pm}} $. These corrections are significantly\nlarger than the expected future experimental precision for Higgs boson masses\nand should therefore be considered in precision analyses for future\nexperiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T09:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.11921v1","title":"On 5-point conformal block with level 2 degenerate field insertion and\n  its AGT dual","summary":"In this paper, we develop and explore recursive methods to investigate the 2d\nCFT 5-point conformal block with a level 2 degenerate insertion, as well as its\nAGT dual, by solving the BPZ differential equation. First, we represent the\nsolution of the differential equation as a double series expansion. On the\n2-node quiver gauge theory side, this corresponds to the instanton series. We\nthen demonstrate that the expansion coefficients are uniquely determined by a\nrecursion relation. Inspired by the approach initiated in a paper by D. Gaiotto\nand J. Teschner, we partially resum this series and show that the result can be\nelegantly expressed in terms of a single hypergeometric function and its\nderivative. This new representation makes it straightforward to relate\ndifferent asymptotic regions. As a by-product, this provides us a simple\nderivation of fusion and braiding coefficients.\n  We describe the subtle procedure of merging the degenerate field with the\noutgoing state, thereby obtaining a generic 4-point block, which on the gauge\ntheory side corresponds to the partition function of $SU(2)$ gauge theory with\nfour massive hypermultiplets in the $\\Omega$-background.\n  Finally, we performed several nontrivial checks, which confirm our results.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11946v1","title":"R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh\n  Reconstruction with Diffusion Priors","summary":"Mesh reconstruction from multi-view images is a fundamental problem in\ncomputer vision, but its performance degrades significantly under sparse-view\nconditions, especially in unseen regions where no ground-truth observations are\navailable. While recent advances in diffusion models have demonstrated strong\ncapabilities in synthesizing novel views from limited inputs, their outputs\noften suffer from visual artifacts and lack 3D consistency, posing challenges\nfor reliable mesh optimization. In this paper, we propose a novel framework\nthat leverages diffusion models to enhance sparse-view mesh reconstruction in a\nprincipled and reliable manner. To address the instability of diffusion\noutputs, we propose a Consensus Diffusion Module that filters unreliable\ngenerations via interquartile range (IQR) analysis and performs variance-aware\nimage fusion to produce robust pseudo-supervision. Building on this, we design\nan online reinforcement learning strategy based on the Upper Confidence Bound\n(UCB) to adaptively select the most informative viewpoints for enhancement,\nguided by diffusion loss. Finally, the fused images are used to jointly\nsupervise a NeRF-based model alongside sparse-view ground truth, ensuring\nconsistency across both geometry and appearance. Extensive experiments\ndemonstrate that our method achieves significant improvements in both geometric\nquality and rendering quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.11949v1","title":"Flow Intelligence: Robust Feature Matching via Temporal Signature\n  Correlation","summary":"Feature matching across video streams remains a cornerstone challenge in\ncomputer vision. Increasingly, robust multimodal matching has garnered interest\nin robotics, surveillance, remote sensing, and medical imaging. While\ntraditional rely on detecting and matching spatial features, they break down\nwhen faced with noisy, misaligned, or cross-modal data. Recent deep learning\nmethods have improved robustness through learned representations, but remain\nconstrained by their dependence on extensive training data and computational\ndemands. We present Flow Intelligence, a paradigm-shifting approach that moves\nbeyond spatial features by focusing on temporal motion patterns exclusively.\nInstead of detecting traditional keypoints, our method extracts motion\nsignatures from pixel blocks across consecutive frames and extract temporal\nmotion signatures between videos. These motion-based descriptors achieve\nnatural invariance to translation, rotation, and scale variations while\nremaining robust across different imaging modalities. This novel approach also\nrequires no pretraining data, eliminates the need for spatial feature\ndetection, enables cross-modal matching using only temporal motion, and it\noutperforms existing methods in challenging scenarios where traditional\napproaches fail. By leveraging motion rather than appearance, Flow Intelligence\nenables robust, real-time video feature matching in diverse environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.11953v1","title":"Novel-view X-ray Projection Synthesis through Geometry-Integrated Deep\n  Learning","summary":"X-ray imaging plays a crucial role in the medical field, providing essential\ninsights into the internal anatomy of patients for diagnostics, image-guided\nprocedures, and clinical decision-making. Traditional techniques often require\nmultiple X-ray projections from various angles to obtain a comprehensive view,\nleading to increased radiation exposure and more complex clinical processes.\nThis paper explores an innovative approach using the DL-GIPS model, which\nsynthesizes X-ray projections from new viewpoints by leveraging a single\nexisting projection. The model strategically manipulates geometry and texture\nfeatures extracted from an initial projection to match new viewing angles. It\nthen synthesizes the final projection by merging these modified geometry\nfeatures with consistent texture information through an advanced image\ngeneration process. We demonstrate the effectiveness and broad applicability of\nthe DL-GIPS framework through lung imaging examples, highlighting its potential\nto revolutionize stereoscopic and volumetric imaging by minimizing the need for\nextensive data acquisition.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T10:30:08Z"}
{"aid":"http://arxiv.org/abs/2504.11955v1","title":"Revisiting Unimodular Quantum Cosmology","summary":"The quantization of unimodular gravity in minisuperspace leads to a time\nevolution of states generated by the Hamiltonian, as in usual quantum\nmechanics. We revisit the analysis made in Ref. \\cite{unruh}, extending it to\nphantom scalar fields. It is argued that only in this case a non-trivial\nevolution for the scalar field can be obtained. The behavior of the scale\nfactor presents a bounce followed by a de Sitter expansion, reproducing the\nquantum cosmological scenario in General Relativity when the source is given by\na cosmological term described by the Schutz variable. The analysis is extended\nto the Brans-Dicke scalar tensor theory.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T10:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.11956v1","title":"The Conserved Effective Stress Tensor of Gravitational Wave","summary":"We present a detailed study of the effective stress tensor of gravitational\nwave (GW) as the source for the background Einstein equation and examine three\ncandidates in literature. The second order perturbed Einstein tensor\n$G^{(2)}_{\\mu\\nu}$, up to a coefficient, proposed by Brill, Hartle, and\nIsaacson, has long been known to be covariantly nonconserved with respect to\nthe background spacetime. We observe that $G^{(2)}_{\\mu\\nu}$ is not a true\ntensor on the background spacetime. More importantly, we find that, by\nexpressing $G^{(2)}_{\\mu\\nu}$ in terms of the perturbed Hilbert-Einstein\nactions,\n  the nonconserved part of $G^{(2)}_{\\mu\\nu}$ is actually canceled out by the\nperturbed fluid stress tensors in the back-reaction equation, or is vanishing\nin absence of fluid. The remaining part of $G^{(2)}_{\\mu\\nu}$ is just the\nconserved effective stress tensor $\\tau_{\\mu\\nu}$ proposed by Ford and Parker.\nAs the main result, we derive $\\tau_{\\mu\\nu}$ for a general curved spacetime by\nvarying the GW action and show its conservation using the equation of GW. The\nstress tensor $T_{\\text{MT}}^{\\mu\\nu}$ proposed by MacCallum and Taub was based\non an action $J_2$. We derive $T_{\\text{MT}}^{\\mu\\nu}$ and find that it is\nnonconserved, and that $J_2$ does not give the correct GW equation in presence\nof matter. The difficulty with $J_2$ is due to a background Ricci tensor term,\nwhich should be also canceled out by the fluid term or vanishing in absence of\nfluid. We also demonstrate these three candidates in a flat Robertson-Walker\nspacetime. The conserved $\\tau_{\\mu\\nu}$ has a positive energy density\nspectrum, and is adequate for the back-reaction in a perturbation scheme, while\nthe two nonconserved stress tensors have a negative spectrum at long\nwavelengths and are unphysical.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T10:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.11967v1","title":"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods,\n  Benchmarking, and Future Directions","summary":"Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-16T10:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.11978v1","title":"On the Intersection and Composition properties of conditional\n  independence","summary":"Compositional graphoids are fundamental discrete structures which appear in\nprobabilistic reasoning, particularly in the area of graphical models. They are\nsemigraphoids which satisfy the Intersection and Composition properties. These\nimportant properties, however, are not enjoyed by general probability\ndistributions. We survey what is known in terms of sufficient conditions for\nIntersection and Composition and derive a set of new sufficient conditions in\nthe context of discrete random variables based on conditional information\ninequalities for Shannon entropies.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.ST,stat.TH","published":"2025-04-16T11:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.11983v1","title":"Non-orientable Exceptional Points in Twisted Boundary Systems","summary":"Non-orientable manifolds, such as the M\\\"obius strip and the Klein bottle,\ndefy conventional geometric intuition through their twisted boundary\nconditions. As a result, topological defects on non-orientable manifolds give\nrise to novel physical phenomena. We study the adiabatic transport of\nexceptional points (EPs) along non-orientable closed loops and uncover distinct\ntopological responses arising from the lack of global orientation. Notably, we\ndemonstrate that the cyclic permutation of eigenstates across an EP depends\nsensitively on the loop orientation, yielding inequivalent braid\nrepresentations for clockwise and counterclockwise encirclement; this is a\nfeature unique to non-orientable geometries. Orientation-dependent geometric\nquantities, such as the winding number, cannot be consistently defined due to\nthe absence of a global orientation. However, when a boundary is introduced,\nsuch quantities become well defined within the local interior, even though the\nglobal manifold remains non-orientable. We further demonstrate the adiabatic\nevolution of EPs and the emergence of orientation-sensitive observables in a\nKlein Brillouin zone, described by an effective non-Hermitian Hamiltonian that\npreserves momentum-space glide symmetry. Finally, we numerically implement\nthese ideas in a microdisk cavity with embedded scatterers using synthetic\nmomenta.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,quant-ph","published":"2025-04-16T11:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.11995v1","title":"A Review of YOLOv12: Attention-Based Enhancements vs. Previous Versions","summary":"The YOLO (You Only Look Once) series has been a leading framework in\nreal-time object detection, consistently improving the balance between speed\nand accuracy. However, integrating attention mechanisms into YOLO has been\nchallenging due to their high computational overhead. YOLOv12 introduces a\nnovel approach that successfully incorporates attention-based enhancements\nwhile preserving real-time performance. This paper provides a comprehensive\nreview of YOLOv12's architectural innovations, including Area Attention for\ncomputationally efficient self-attention, Residual Efficient Layer Aggregation\nNetworks for improved feature aggregation, and FlashAttention for optimized\nmemory access. Additionally, we benchmark YOLOv12 against prior YOLO versions\nand competing object detectors, analyzing its improvements in accuracy,\ninference speed, and computational efficiency. Through this analysis, we\ndemonstrate how YOLOv12 advances real-time object detection by refining the\nlatency-accuracy trade-off and optimizing computational resources.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T11:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.11997v1","title":"A Computationally Efficient Algorithm for Infinite-Horizon\n  Average-Reward Linear MDPs","summary":"We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T11:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.12003v1","title":"Inclusion of an Inverse Magnetic Hysteresis Model into the Space-Time\n  Finite Element Method for Magnetoquasistatics","summary":"In this note we discuss the numerical solution of the eddy current\napproximation of the Maxwell equations using the simple Pragmatic Algebraic\nModel to include hysteresis effects. In addition to the more standard\ntime-stepping approach we propose a space-time finite element method which\nallows both for parallelization and adaptivity simultaneously in space and\ntime. Numerical experiments confirm both approaches yield the same numerical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.12016v1","title":"Active Human Feedback Collection via Neural Contextual Dueling Bandits","summary":"Collecting human preference feedback is often expensive, leading recent works\nto develop principled algorithms to select them more efficiently. However,\nthese works assume that the underlying reward function is linear, an assumption\nthat does not hold in many real-life applications, such as online\nrecommendation and LLM alignment. To address this limitation, we propose\nNeural-ADB, an algorithm based on the neural contextual dueling bandit\nframework that provides a principled and practical method for collecting human\npreference feedback when the underlying latent reward function is non-linear.\nWe theoretically show that when preference feedback follows the\nBradley-Terry-Luce model, the worst sub-optimality gap of the policy learned by\nNeural-ADB decreases at a sub-linear rate as the preference dataset increases.\nOur experimental results on problem instances derived from synthetic preference\ndatasets further validate the effectiveness of Neural-ADB.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T12:16:10Z"}
{"aid":"http://arxiv.org/abs/2504.12028v1","title":"Magnetic and Mechanical Analysis of Bi-2212 Rutherford Cable in a\n  Cos-Theta Sub-Scale Dipole Coil","summary":"The U.S. Magnet Development Program (US-MDP) explores high-field accelerator\nmagnets compatible with operational conditions beyond the limits of Nb$_3$Sn\ntechnology. The ongoing R\\&D High-Temperature Superconductors (HTS) suggests\nusing Bi$_2$Sr$_2$CaCu$_2$O$_{8-x}$ (Bi-2212) as superconducting element.\nBi-2212 Rutherford cables maintain a high critical current (I$_C$) when exposed\nto a large external magnetic field. However, Bi-2212 exhibits an oversensitive\nstress-strain response when subject to large Lorentz forces. This paper reports\non the magnetic and mechanical analysis of the Bi-2212 cosine-theta insert\nbeing developed at Fermilab for a hybrid magnet composed of two external layers\nof Nb$_3$Sn and two internal layers of Bi-2212. We performed a FEM analysis of\nthe insert to estimate the HTS stress state in the coil's strands under\nmagnetic and mechanical loads.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-16T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.12042v1","title":"Diverse regular spacetimes using a parametrised density profile","summary":"We explore the construction of diverse regular spacetimes (black holes and\ndefects) in General Relativity (GR) using a generic parametrised density\nprofile (the Dekel-Zhao profile), which includes, for specific parameter\nchoices, various well-known examples usually studied in the context of dark\nmatter halos. Our solutions, in the Schwarzschild gauge, include new regular\nblack holes as well as non-singular solutions representing spacetime defects.\nFor a sub-class of metrics, a TOV equation approach with a chosen equation of\nstate works. The status of the energy conditions and the issue of geodesic\ncompleteness are explored in detail. We also provide possible Lagrangian\ndensity constructions for the matter energy-momentum tensors. Further, we study\nthe shadow radius of the new regular black holes, and compare our findings with\navailable observational results from the EHT collaboration. Finally, for the\ndefect solution, we present a model for a stable star (a gravastar) by explicit\nuse of the junction conditions and obtain relevant consequences highlighting\nits characteristic features.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T12:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12067v1","title":"LO2: Microservice API Anomaly Dataset of Logs and Metrics","summary":"Context. Microservice-based systems have gained significant attention over\nthe past years. A critical factor for understanding and analyzing the behavior\nof these systems is the collection of monitoring data such as logs, metrics,\nand traces. These data modalities can be used for anomaly detection and root\ncause analysis of failures. In particular, multi-modal methods utilizing\nseveral types of this data at once have gained traction in the research\ncommunity since these three modalities capture different dimensions of system\nbehavior. Aim. We provide a dataset that supports research on anomaly detection\nand architectural degradation in microservice systems. We generate a\ncomprehensive dataset of logs, metrics, and traces from a production\nmicroservice system to enable the exploration of multi-modal fusion methods\nthat integrate multiple data modalities. Method. We dynamically tested the\nvarious APIs of the MS-based system, implementing the OAuth2.0 protocol using\nthe Locust tool. For each execution of the prepared test suite, we collect logs\nand performance metrics for correct and erroneous calls with data labeled\naccording to the error triggered during the call. Contributions. We collected\napproximately 657,000 individual log files, totaling over two billion log\nlines. In addition, we collected more than 45 million individual metric files\nthat contain 485 unique metrics. We provide an initial analysis of logs,\nidentify key metrics through PCA, and discuss challenges in collecting traces\nfor this system. Moreover, we highlight the possibilities for making a more\nfine-grained version of the data set. This work advances anomaly detection in\nmicroservice systems using multiple data sources.","main_category":"cs.SE","categories":"cs.SE,cs.DC,cs.NI","published":"2025-04-16T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2504.12075v1","title":"Generative Deep Learning Framework for Inverse Design of Fuels","summary":"In the present work, a generative deep learning framework combining a\nCo-optimized Variational Autoencoder (Co-VAE) architecture with quantitative\nstructure-property relationship (QSPR) techniques is developed to enable\naccelerated inverse design of fuels. The Co-VAE integrates a property\nprediction component coupled with the VAE latent space, enhancing molecular\nreconstruction and accurate estimation of Research Octane Number (RON) (chosen\nas the fuel property of interest). A subset of the GDB-13 database, enriched\nwith a curated RON database, is used for model training. Hyperparameter tuning\nis further utilized to optimize the balance among reconstruction fidelity,\nchemical validity, and RON prediction. An independent regression model is then\nused to refine RON prediction, while a differential evolution algorithm is\nemployed to efficiently navigate the VAE latent space and identify promising\nfuel molecule candidates with high RON. This methodology addresses the\nlimitations of traditional fuel screening approaches by capturing complex\nstructure-property relationships within a comprehensive latent representation.\nThe generative model provides a flexible tool for systematically exploring vast\nchemical spaces, paving the way for discovering fuels with superior anti-knock\nproperties. The demonstrated approach can be readily extended to incorporate\nadditional fuel properties and synthesizability criteria to enhance\napplicability and reliability for de novo design of new fuels.","main_category":"cs.LG","categories":"cs.LG,physics.chem-ph","published":"2025-04-16T13:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.12081v1","title":"QCD$_2$ 't Hooft model: 2-flavour mesons spectrum","summary":"We continue analytical study of the meson mass spectrum in the large-$N_c$\ntwo-dimensional QCD, known as the 't Hooft model, by addressing the most\ngeneral case of quarks with unequal masses. Based on our previous work, we\ndevelop non-perturbative methods to compute spectral sums and systematically\nderive large-$n$ WKB expansion of the spectrum. Furthermore, we examine the\nbehavior of these results in various asymptotic regimes, including the chiral,\nheavy quark, and heavy-light limits, and establish a precise coincidence with\nknown analytical and numerical results obtained through alternative approaches.","main_category":"hep-th","categories":"hep-th,hep-ph,math-ph,math.MP","published":"2025-04-16T13:42:10Z"}
{"aid":"http://arxiv.org/abs/2504.12086v1","title":"Neural Contextual Bandits Under Delayed Feedback Constraints","summary":"This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T13:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.12092v1","title":"Virtually structured illumination for terahertz super-resolution imaging","summary":"We demonstrate structured illumination super-resolution imaging in the\nTerahertz (THz) frequency band using the Virtually Structured Detection (VSD)\nmethod. Leveraging our previously reported high-speed, high-sensitivity\natomic-based THz imager, we achieve a resolution enhancement of 74(3)% at 0.55\nTHz, without the aid of deconvolution methods. We show a high-speed THz imaging\nsystem is compatible with the use of advanced optical techniques, with\npotential disruptive effects on applications requiring both high speed and high\nspatial resolution imaging in the THz range.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph","published":"2025-04-16T13:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.12093v1","title":"The Tripod High-Speed Quantum Memory As a Beam Splitter with Arbitrary\n  Splitting Ratios","summary":"The utilisation of a quantum memory cell as a beam splitter with arbitrary\ncoefficients is demonstrated theoretically. For such a beam splitter, an\ninput-output matrix is derived. We investigate the high-speed quantum memory\nbased on the tripod-type atomic levels and transitions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.12109v1","title":"Self-Supervised Traversability Learning with Online Prototype Adaptation\n  for Off-Road Autonomous Driving","summary":"Achieving reliable and safe autonomous driving in off-road environments\nrequires accurate and efficient terrain traversability analysis. However, this\ntask faces several challenges, including the scarcity of large-scale datasets\ntailored for off-road scenarios, the high cost and potential errors of manual\nannotation, the stringent real-time requirements of motion planning, and the\nlimited computational power of onboard units. To address these challenges, this\npaper proposes a novel traversability learning method that leverages\nself-supervised learning, eliminating the need for manual annotation. For the\nfirst time, a Birds-Eye View (BEV) representation is used as input, reducing\ncomputational burden and improving adaptability to downstream motion planning.\nDuring vehicle operation, the proposed method conducts online analysis of\ntraversed regions and dynamically updates prototypes to adaptively assess the\ntraversability of the current environment, effectively handling dynamic scene\nchanges. We evaluate our approach against state-of-the-art benchmarks on both\npublic datasets and our own dataset, covering diverse seasons and geographical\nlocations. Experimental results demonstrate that our method significantly\noutperforms recent approaches. Additionally, real-world vehicle experiments\nshow that our method operates at 10 Hz, meeting real-time requirements, while a\n5.5 km autonomous driving experiment further validates the generated\ntraversability cost maps compatibility with downstream motion planning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:17:31Z"}
{"aid":"http://arxiv.org/abs/2504.12115v1","title":"GripMap: An Efficient, Spatially Resolved Constraint Framework for\n  Offline and Online Trajectory Planning in Autonomous Racing","summary":"Conventional trajectory planning approaches for autonomous vehicles often\nassume a fixed vehicle model that remains constant regardless of the vehicle's\nlocation. This overlooks the critical fact that the tires and the surface are\nthe two force-transmitting partners in vehicle dynamics; while the tires stay\nwith the vehicle, surface conditions vary with location. Recognizing these\nchallenges, this paper presents a novel framework for spatially resolving\ndynamic constraints in both offline and online planning algorithms applied to\nautonomous racing. We introduce the GripMap concept, which provides a spatial\nresolution of vehicle dynamic constraints in the Frenet frame, allowing\nadaptation to locally varying grip conditions. This enables compensation for\nlocation-specific effects, more efficient vehicle behavior, and increased\nsafety, unattainable with spatially invariant vehicle models. The focus is on\nlow storage demand and quick access through perfect hashing. This framework\nproved advantageous in real-world applications in the presented form.\nExperiments inspired by autonomous racing demonstrate its effectiveness. In\nfuture work, this framework can serve as a foundational layer for developing\nfuture interpretable learning algorithms that adjust to varying grip conditions\nin real-time.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.12130v1","title":"Dynamics of localized states in the stochastic discrete nonlinear\n  Schrödinger equation","summary":"We reconsider the dynamics of localized states in the deterministic and\nstochastic discrete nonlinear Schr\\\"odinger equation. Localized initial\nconditions disperse if the strength of the nonlinear part drops below a\nthreshold. Localized states are unstable in a noisy environment. As expected,\nan infinite temperature state emerges when multiplicative noise is applied,\nwhile additive noise yields unbounded dynamics since conservation of\nnormalization is violated.","main_category":"nlin.PS","categories":"nlin.PS,cond-mat.stat-mech","published":"2025-04-16T14:44:40Z"}
{"aid":"http://arxiv.org/abs/2504.12144v1","title":"PINNs for Solving Unsteady Maxwell's Equations: Convergence Issues and\n  Comparative Assessment with Compact Schemes","summary":"Physics-Informed Neural Networks (PINNs) have recently emerged as a promising\nalternative for solving partial differential equations, offering a mesh-free\nframework that incorporates physical laws directly into the learning process.\nIn this study, we explore the application of PINNs for solving unsteady\nMaxwell's equations and compare their performance with two established\nnumerical methods: the Finite-Difference Time-Domain (FDTD) method and a\ncompact Pade scheme with filtering. Three benchmark problems are considered,\nranging from 1D free-space wave propagation to 2D Gaussian pulses in periodic\nand dielectric media. We assess the effectiveness of convergence-enhancing\nstrategies for PINNs, including random Fourier features, spatio-temporal\nperiodicity, and temporal causality training. An ablation study highlights that\narchitectural choices must align with the underlying physics. Additionally, we\nemploy a Neural Tangent Kernel framework to examine the spatio-temporal\nconvergence behavior of PINNs. Results show that convergence rates correlate\nwith error over time but not in space, revealing a limitation in how training\ndynamics allocate learning effort. Overall, this study demonstrates that PINNs,\nwhen properly configured, can match or surpass traditional solvers in accuracy\nand flexibility, though challenges remain in addressing spatial inhomogeneity\nand adapting training to localized complexity.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-16T14:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.12158v1","title":"What is a monoid?","summary":"In many situations one encounters a notion that resembles that of a monoid.\nIt consists of a carrier and two operations that resemble a unit and a\nmultiplication, subject to three equations that resemble associativity and left\nand right unital laws. The question then arises whether this notion in fact\nthat of a monoid in a suitable sense. Category theorists have answered this\nquestion by providing a notion of monoid in a monoidal category, or more\ngenerally in a multicategory. While this encompasses many examples, it is\nunsuitable in other cases, such as the notion of relative monad, and the\nmodelling of call-by-push-value sequencing. In each of these examples, the\nleftmost and/or the rightmost factor of a multiplication or associativity law\nseems to be distinguished. To include such examples, we generalize the\nmulticategorical framework in two stages. Firstly, we move to the framework of\na left-skew multicategory (due to Bourke and Lack), which generalizes both\nmulticategory and left-skew monoidal category. The notion of monoid in this\nframework encompasses examples where only the leftmost factor is distinguished,\nsuch as the notion of relative monad. Secondly, we consider monoids in the\nnovel framework of a bi-skew multicategory. This encompasses examples where\nboth the leftmost and the rightmost factor are distinguished, such as the\nnotion of a category on a span, and the modelling of call-by-push-value\nsequencing. In the bi-skew framework (which is the most general), we give a\ncoherence result saying that a monoid corresponds to an unbiased monoid, i.e. a\nmap from the unit bi-skew multicategory.","main_category":"math.CT","categories":"math.CT,cs.PL,F.3.2","published":"2025-04-16T15:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.12173v1","title":"Computational Exploration of Inclined Magnetic Fields and Variable\n  Thermal Flux Effects on the Flow of Dusty Hybrid Nanofluid around\n  Stretching/Shrinking Wedge","summary":"This extensive investigation explores the influence of inclined magnetic\nfields and radiative non-linear heat flux on the behavior of dusty hybrid\nnanofluids over stretching/shrinking wedges. Employing $Cu$-$SiO_2$ as a hybrid\nnanoparticle composition and ethylene glycol $(EG)$ as the base liquid, the\nstudy investigates the fluid's response to a uniform magnetic field. The\ngoverning partial differential equations and associated boundary conditions are\nadeptly transformed into ordinary differential equations using appropriate\ntransformations and then non-dimensionalized. Numerical simulations are\nexecuted using MATLAB and the bvp-4c solver. The outcomes offer a profound\ninsight into thermofluid dynamics in industrial applications featuring\nintricate fluid flows, evaluating the influence of magnetic parameters on\ndiverse fluid types, including nanofluids and dusty hybrid nanofluids.\nFurthermore, the investigation analyzes the impact of heat production and\nabsorption on both vertical and horizontal plates, studying the significance of\nthe velocity ratio factor in relation to the drag coefficient and local Nusselt\nnumber under thermal conditions of generation and absorption.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-16T15:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.12203v1","title":"Modality-Independent Explainable Detection of Inaccurate Organ\n  Segmentations Using Denoising Autoencoders","summary":"In radiation therapy planning, inaccurate segmentations of organs at risk can\nresult in suboptimal treatment delivery, if left undetected by the clinician.\nTo address this challenge, we developed a denoising autoencoder-based method to\ndetect inaccurate organ segmentations. We applied noise to ground truth organ\nsegmentations, and the autoencoders were tasked to denoise them. Through the\napplication of our method to organ segmentations generated on both MR and CT\nscans, we demonstrated that the method is independent of imaging modality. By\nproviding reconstructions, our method offers visual information about\ninaccurate regions of the organ segmentations, leading to more explainable\ndetection of suboptimal segmentations. We compared our method to existing\napproaches in the literature and demonstrated that it achieved superior\nperformance for the majority of organs.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T15:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.12220v1","title":"Interacting Object-Enabled Clustering and Characterization of\n  Distributed MIMO Channels","summary":"Distributed multiple-input multiple-output (MIMO), also known as cell-free\nmassive MIMO, emerges as a promising technology for sixth-generation (6G)\nsystems to support uniform coverage and reliable communication. For the design\nand optimization of such systems, measurement-based investigations of\nreal-world distributed MIMO channels are essential. In this paper, we present\nan indoor channel measurement campaign, featuring eight distributed antenna\narrays with 128 elements in total. Multi-link channels are measured at 50\npositions along a 12-meter user route. A clustering algorithm enabled by\ninteracting objects is proposed to identify clusters in the measured channels.\nThe algorithm jointly clusters the multipath components for all links,\neffectively capturing the dynamic contributions of common clusters to different\nlinks. In addition, a Kalman filter-based tracking framework is introduced for\ncluster prediction, tracking, and updating along the user movement. Using the\nclustering and tracking results, cluster-level characterization of the measured\nchannels is performed. First, the number of clusters and their visibility at\nboth link ends are analyzed. Next, a maximum-likelihood estimator is utilized\nto determine the entire cluster visibility region length. Finally, key\ncluster-level properties, including the common cluster ratio, cluster power,\nshadowing, spread, among others, are statistically investigated. The results\nprovide valuable insights into cluster behavior in typical multi-link channels,\nnecessary for accurate modeling of distributed MIMO channels.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T16:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.12223v1","title":"Superspecial representations of Weyl groups","summary":"We define a subset of the set of special representations of a Weyl group.\nThis subset contains at most one representation.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T16:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.12239v1","title":"The Discovery of Two Quadruple Star Systems with the Second and Third\n  Shortest Outer Periods","summary":"We present the discovery of two quadruple star systems -- TIC 285853156 and\nTIC 392229331 -- each consisting of two bound eclipsing binary stars. Among the\nmost compact quadruples known, TIC 392229331 and TIC 285853156 have the second\nand third shortest outer orbital periods (145 days and 152 days, respectively)\nafter BU Canis Minoris (122 days, Pribulla et al. 2023). We demonstrate that\nboth systems are long-term dynamically stable despite substantial outer orbital\neccentricities (0.33 for TIC 285853156 and 0.56 for TIC 392229331). We\npreviously reported these systems in Kostov et al. (2022) and Kostov et al.\n(2024) as 2+2 hierarchical quadruple candidates producing two sets of primary\nand secondary eclipses in TESS data, as well as prominent eclipse timing\nvariations on both binary components. We combine all available TESS data and\nnew spectroscopic observations into a comprehensive photodynamical model,\nproving that the component binary stars are gravitationally bound in both\nsystems and finding accurate stellar and orbital parameters for both systems,\nincluding very precise determinations of the outer periods. TIC 285853156 and\nTIC 392229331 represent the latest addition to the small population of\nwell-characterized proven quadruple systems dynamically interacting on\ndetectable timescales.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-16T16:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.12244v1","title":"Mobile Distributed MIMO (MD-MIMO) for NextG: Mobility Meets Cooperation\n  in Distributed Arrays","summary":"Distributed multiple-input multiple-output (D\\mbox{-}MIMO) is a promising\ntechnology to realize the promise of massive MIMO gains by fiber-connecting the\ndistributed antenna arrays, thereby overcoming the form factor limitations of\nco-located MIMO. In this paper, we introduce the concept of mobile D-MIMO\n(MD-MIMO) network, a further extension of the D-MIMO technology where\ndistributed antenna arrays are connected to the base station with a wireless\nlink allowing all radio network nodes to be mobile. This approach significantly\nimproves deployment flexibility and reduces operating costs, enabling the\nnetwork to adapt to the highly dynamic nature of next-generation (NextG)\nnetworks. We discuss use cases, system design, network architecture, and the\nkey enabling technologies for MD-MIMO. Furthermore, we investigate a case study\nof MD-MIMO for vehicular networks, presenting detailed performance evaluations\nfor both downlink and uplink. The results show that an MD-MIMO network can\nprovide substantial improvements in network throughput and reliability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T16:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.12256v1","title":"FLIP Reasoning Challenge","summary":"Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T17:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.12278v1","title":"Wormholes with Ends of the World","summary":"We study classical wormhole solutions in 3D gravity with end-of-the-world\n(EOW) branes, conical defects, kinks, and punctures. These solutions compute\nstatistical averages of an ensemble of boundary conformal field theories\n(BCFTs) related to universal asymptotics of OPE data extracted from 2D\nconformal bootstrap. Conical defects connect BCFT bulk operators; branes join\nBCFT boundary intervals with identical boundary conditions; kinks (1D defects\nalong branes) link BCFT boundary operators; and punctures (0D defects) are\nendpoints where conical defects terminate on branes. We provide evidence for a\ncorrespondence between the gravity theory and the ensemble. In particular, the\nagreement of $g$-function dependence results from an underlying topological\naspect of the on-shell EOW brane action, from which a BCFT analogue of the\nSchlenker-Witten theorem also follows.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T17:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.12284v1","title":"How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday\n  Interactions","summary":"We tackle the novel problem of predicting 3D hand motion and contact maps (or\nInteraction Trajectories) given a single RGB view, action text, and a 3D\ncontact point on the object as input. Our approach consists of (1) Interaction\nCodebook: a VQVAE model to learn a latent codebook of hand poses and contact\npoints, effectively tokenizing interaction trajectories, (2) Interaction\nPredictor: a transformer-decoder module to predict the interaction trajectory\nfrom test time inputs by using an indexer module to retrieve a latent\naffordance from the learned codebook. To train our model, we develop a data\nengine that extracts 3D hand poses and contact trajectories from the diverse\nHoloAssist dataset. We evaluate our model on a benchmark that is 2.5-10X larger\nthan existing works, in terms of diversity of objects and interactions\nobserved, and test for generalization of the model across object categories,\naction categories, tasks, and scenes. Experimental results show the\neffectiveness of our approach over transformer & diffusion baselines across all\nsettings.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T17:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.12293v1","title":"Exceptional times when bigeodesics exist in dynamical last passage\n  percolation","summary":"It is believed that, under very general conditions, doubly infinite geodesics\n(or bigeodesics) do not exist for planar first and last passage percolation\n(LPP) models. However, if one endows the model with a natural dynamics, thereby\ngradually perturbing the geometry, then it is plausible that there could exist\na non-trivial set of exceptional times $\\mathscr{T}$ at which such bigeodesics\nexist, and the objective of this paper is to investigate this set. For\ndynamical exponential LPP, we obtain an $\\Omega( 1/\\log n)$ lower bound on the\nprobability that there exists a random time $t\\in [0,1]$ at which a geodesic of\nlength $n$ passes through the origin at its midpoint -- note that this is\nslightly short of proving the non-triviality of the set $\\mathscr{T}$ which\nwould instead require an $\\Omega(1)$ lower bound. In the other direction,\nworking with a dynamical version of Brownian LPP, we show that the average\ntotal number of changes that a geodesic of length $n$ accumulates in unit time\nis at most $n^{5/3+o(1)}$; using this, we establish that the Hausdorff\ndimension of $\\mathscr{T}$ is a.s. upper bounded by $1/2$. Further, for a fixed\nangle $\\theta$, we show that the set $\\mathscr{T}^\\theta\\subseteq \\mathscr{T}$\nof exceptional times at which a $\\theta$-directed bigeodesic exists a.s. has\nHausdorff dimension zero. We provide a list of open questions.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12620v1","title":"Fractional balanced chromatic number of signed subcubic graphs","summary":"A signed graph is a pair $(G,\\sigma)$, where $G$ is a graph and $\\sigma:\nE(G)\\rightarrow \\{-, +\\}$, called signature, is an assignment of signs to the\nedges. Given a signed graph $(G,\\sigma)$ with no negative loops, a balanced\n$(p,q)$-coloring of $(G,\\sigma)$ is an assignment $f$ of $q$ colors to each\nvertex from a pool of $p$ colors such that each color class induces a balanced\nsubgraph, i.e., no negative cycles. Let $(K_4,-)$ be the signed graph on $K_4$\nwith all edges being negative. In this work, we show that every signed (simple)\nsubcubic graph admits a balanced $(5,3)$-coloring except for $(K_4,-)$ and\nsigned graphs switching equivalent to it. For this particular signed graph the\nbest balanced colorings are $(2p,p)$-colorings.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T03:51:29Z"}
{"aid":"http://arxiv.org/abs/2504.12631v1","title":"Geometry-preserving Numerical Scheme for Riemannian Stochastic\n  Differential Equations","summary":"Stochastic differential equations (SDEs) on Riemannian manifolds have\nnumerous applications in system identification and control. However,\ngeometry-preserving numerical methods for simulating Riemannian SDEs remain\nrelatively underdeveloped. In this paper, we propose the Exponential\nEuler-Maruyama (Exp-EM) scheme for approximating solutions of SDEs on\nRiemannian manifolds. The Exp-EM scheme is both geometry-preserving and\ncomputationally tractable. We establish a strong convergence rate of\n$\\mathcal{O}(\\delta^{\\frac{1 - \\epsilon}{2}})$ for the Exp-EM scheme, which\nextends previous results obtained for specific manifolds to a more general\nsetting. Numerical simulations are provided to illustrate our theoretical\nfindings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T04:14:00Z"}
{"aid":"http://arxiv.org/abs/2504.12641v1","title":"Hodge Dual Gauge Symmetry in Minimal Einstein-Aether Theory","summary":"Einstein-aether gravity is a theory that breaks the local Lorentz symmetry by\nintroducing a preferred direction via a vector field, which is considered to\nplay the role of an aether. The theory is identified by four coupling constants\nbetween the aether and gravity. Minimal Einstein-aether is the special case in\nwhich only one of the couplings is non-zero. We show that the aether vector\nfield in its minimal version is Hodge dual to a gauge field. The gauge symmetry\nin the dual description has been known for decades and has been used to\nimplement a cosmological constant into the Lagrangian. As a result, solutions\nto the well-established gauge theory can be transferred into the minimal\nEinstein-aether theory straightforwardly. On the other hand, some of the\nproposed solutions to the minimal Einstein-aether theory could be discarded as\npure gauges of the vanishing aether. We prove as a theorem that this holds true\nfor all divergence-less aether fields.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T04:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.12664v1","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","summary":"This paper presents a novel autonomous drone-based smoke plume tracking\nsystem capable of navigating and tracking plumes in highly unsteady atmospheric\nconditions. The system integrates advanced hardware and software and a\ncomprehensive simulation environment to ensure robust performance in controlled\nand real-world settings. The quadrotor, equipped with a high-resolution imaging\nsystem and an advanced onboard computing unit, performs precise maneuvers while\naccurately detecting and tracking dynamic smoke plumes under fluctuating\nconditions. Our software implements a two-phase flight operation, i.e.,\ndescending into the smoke plume upon detection and continuously monitoring the\nsmoke movement during in-plume tracking. Leveraging Proportional\nIntegral-Derivative (PID) control and a Proximal Policy Optimization based Deep\nReinforcement Learning (DRL) controller enables adaptation to plume dynamics.\nUnreal Engine simulation evaluates performance under various smoke-wind\nscenarios, from steady flow to complex, unsteady fluctuations, showing that\nwhile the PID controller performs adequately in simpler scenarios, the\nDRL-based controller excels in more challenging environments. Field tests\ncorroborate these findings. This system opens new possibilities for drone-based\nmonitoring in areas like wildfire management and air quality assessment. The\nsuccessful integration of DRL for real-time decision-making advances autonomous\ndrone control for dynamic environments.","main_category":"cs.RO","categories":"cs.RO,physics.flu-dyn","published":"2025-04-17T05:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.12678v1","title":"A Genetic Approach to Gradient-Free Kinodynamic Planning in Uneven\n  Terrains","summary":"This paper proposes a genetic algorithm-based kinodynamic planning algorithm\n(GAKD) for car-like vehicles navigating uneven terrains modeled as triangular\nmeshes. The algorithm's distinct feature is trajectory optimization over a\nfixed-length receding horizon using a genetic algorithm with heuristic-based\nmutation, ensuring the vehicle's controls remain within its valid operational\nrange. By addressing challenges posed by uneven terrain meshes, such as\nchanging face normals, GAKD offers a practical solution for path planning in\ncomplex environments. Comparative evaluations against Model Predictive Path\nIntegral (MPPI) and log-MPPI methods show that GAKD achieves up to 20 percent\nimprovement in traversability cost while maintaining comparable path length.\nThese results demonstrate GAKD's potential in improving vehicle navigation on\nchallenging terrains.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T06:11:31Z"}
{"aid":"http://arxiv.org/abs/2504.12689v1","title":"HSS-IAD: A Heterogeneous Same-Sort Industrial Anomaly Detection Dataset","summary":"Multi-class Unsupervised Anomaly Detection algorithms (MUAD) are receiving\nincreasing attention due to their relatively low deployment costs and improved\ntraining efficiency. However, the real-world effectiveness of MUAD methods is\nquestioned due to limitations in current Industrial Anomaly Detection (IAD)\ndatasets. These datasets contain numerous classes that are unlikely to be\nproduced by the same factory and fail to cover multiple structures or\nappearances. Additionally, the defects do not reflect real-world\ncharacteristics. Therefore, we introduce the Heterogeneous Same-Sort Industrial\nAnomaly Detection (HSS-IAD) dataset, which contains 8,580 images of\nmetallic-like industrial parts and precise anomaly annotations. These parts\nexhibit variations in structure and appearance, with subtle defects that\nclosely resemble the base materials. We also provide foreground images for\nsynthetic anomaly generation. Finally, we evaluate popular IAD methods on this\ndataset under multi-class and class-separated settings, demonstrating its\npotential to bridge the gap between existing datasets and real factory\nconditions. The dataset is available at\nhttps://github.com/Qiqigeww/HSS-IAD-Dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.12699v1","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via\n  Pseudo-Label-Guided Global Transforms","summary":"Existing 3D human pose estimation methods often suffer in performance, when\napplied to cross-scenario inference, due to domain shifts in characteristics\nsuch as camera viewpoint, position, posture, and body size. Among these\nfactors, camera viewpoints and locations {have been shown} to contribute\nsignificantly to the domain gap by influencing the global positions of human\nposes. To address this, we propose a novel framework that explicitly conducts\nglobal transformations between pose positions in the camera coordinate systems\nof source and target domains. We start with a Pseudo-Label Generation Module\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\nposes. Then, a Global Transformation Module leverages a human-centered\ncoordinate system as a novel bridging mechanism to seamlessly align the\npositional orientations of poses across disparate domains, ensuring consistent\nspatial referencing. To further enhance generalization, a Pose Augmentor is\nincorporated to address variations in human posture and body size. This process\nis iterative, allowing refined pseudo-labels to progressively improve guidance\nfor domain adaptation. Our method is evaluated on various cross-dataset\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\noutperforms state-of-the-art approaches and even outperforms the target-trained\nmodel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12713v1","title":"Efficient Primal-dual Forward-backward Splitting Method for\n  Wasserstein-like Gradient Flows with General Nonlinear Mobilities","summary":"We construct an efficient primal-dual forward-backward (PDFB) splitting\nmethod for computing a class of minimizing movement schemes with nonlinear\nmobility transport distances, and apply it to computing Wasserstein-like\ngradient flows. This approach introduces a novel saddle point formulation for\nthe minimizing movement schemes, leveraging a support function form from the\nBenamou-Brenier dynamical formulation of optimal transport. The resulting\nframework allows for flexible computation of Wasserstein-like gradient flows by\nsolving the corresponding saddle point problem at the fully discrete level, and\ncan be easily extended to handle general nonlinear mobilities. We also provide\na detailed convergence analysis of the PDFB splitting method, along with\npractical remarks on its implementation and application. The effectiveness of\nthe method is demonstrated through several challenging numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-17T07:37:08Z"}
{"aid":"http://arxiv.org/abs/2504.12718v1","title":"TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole\n  Slide Images of Histology","summary":"Digital pathology, augmented by artificial intelligence (AI), holds\nsignificant promise for improving the workflow of pathologists. However,\nchallenges such as the labor-intensive annotation of whole slide images (WSIs),\nhigh computational demands, and trust concerns arising from the absence of\nuncertainty estimation in predictions hinder the practical application of\ncurrent AI methodologies in histopathology. To address these issues, we present\na novel trustful fully unsupervised multi-level segmentation methodology\n(TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to\nidentify the different tissue types within low-resolution training data. It\nselects representative patches from each identified group based on an\nuncertainty measure and then does unsupervised nuclei segmentation in their\nrespective higher-resolution space without using any ML algorithms. Crucially,\nthis solution integrates seamlessly into clinicians workflows, transforming the\nexamination of a whole WSI into a review of concise, interpretable cross-level\ninsights. This integration significantly enhances and accelerates the workflow\nwhile ensuring transparency. We evaluated our approach using the UPENN-GBM\ndataset, where the AE achieved a mean squared error (MSE) of 0.0016.\nAdditionally, nucleus segmentation is assessed on the MoNuSeg dataset,\noutperforming all unsupervised approaches with an F1 score of 77.46% and a\nJaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in\nadvancing the field of digital pathology.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T07:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.12764v1","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large\n  Language Models on Graph-theoretic Tasks","summary":"In this paper, we presented GraphOmni, a comprehensive benchmark framework\nfor systematically evaluating the graph reasoning capabilities of LLMs. By\nanalyzing critical dimensions, including graph types, serialization formats,\nand prompt schemes, we provided extensive insights into the strengths and\nlimitations of current LLMs. Our empirical findings emphasize that no single\nserialization or prompting strategy consistently outperforms others. Motivated\nby these insights, we propose a reinforcement learning-based approach that\ndynamically selects the best serialization-prompt pairings, resulting in\nsignificant accuracy improvements. GraphOmni's modular and extensible design\nestablishes a robust foundation for future research, facilitating advancements\ntoward general-purpose graph reasoning models.","main_category":"cs.LG","categories":"cs.LG,cs.DM","published":"2025-04-17T09:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.12776v1","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets\n  and Multi-Dimensional Discrete Data","summary":"We propose a method for visualizing uncertain set systems, which differs from\nprevious set visualization approaches that are based on certainty (an element\neither belongs to a set or not). Our method is inspired by storyline\nvisualizations and parallel coordinate plots: (a) each element is represented\nby a vertical glyph, subdivided into bins that represent different levels of\nuncertainty; (b) each set is represented by an x-monotone curve that traverses\nelement glyphs through the bins representing the level of uncertainty of their\nmembership. Our implementation also includes optimizations to reduce visual\ncomplexity captured by the number of turns for the set curves and the number of\ncrossings. Although several of the natural underlying optimization problems are\nNP-hard in theory (e.g., optimal element order, optimal set order), in\npractice, we can compute near-optimal solutions with respect to curve crossings\nwith the help of a new exact algorithm for optimally ordering set curves within\neach element's bins. With these optimizations, the proposed method makes it\neasy to see set containment (the smaller set's curve is strictly below the\nlarger set's curve). A brief design-space exploration using uncertain\nset-membership data, as well as multi-dimensional discrete data, shows the\nflexibility of the proposed approach.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-17T09:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12785v1","title":"New developments in MatCont: delay equation importer and Lyapunov\n  exponents","summary":"MatCont is a powerful toolbox for numerical bifurcation analysis focussing on\nsmooth ODEs. A user can study equilibria, periodic and connecting orbits, and\ntheir stability and bifurcations. Here, we report on additional features in\nversion 7p6. The first is a delay equation importer enabling MatCont users to\nstudy a much larger class of models, namely delay equations with finite delay\n(including delay differential and renewal equations). This importer translates\nthe delay equation into a system of ODEs using a pseudospectral approximation\nwith an order specified by the user. We also implemented Lyapunov exponent\ncomputations, event functions for Poincar\\'e maps, and enhanced homoclinic\ncontinuation. We demonstrate these features with test cases, such as the\nMackey-Glass equation and a renewal equation, and provide additional examples\nin online tutorials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T09:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.12786v1","title":"Magnetized black holes in Kaluza-Klein theory and the Kerr/CFT\n  correspondence","summary":"In this work, we examine the Kerr/CFT correspondence for magnetized black\nholes arising from Kaluza--Klein theory, demonstrating that Kerr/CFT holography\npersists beyond the traditional Einstein--Maxwell framework. Notably, unlike in\nthe Einstein--Maxwell case, the massless neutral scalar field equation here is\nfully separable into radial and angular parts. This separability reveals a\nhidden conformal symmetry in the near--horizon, low--frequency regime,\nproviding further support for the robustness of Kerr/CFT dualities in extended\ngravitational theories.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-17T09:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.12788v1","title":"ARAP-GS: Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing\n  with Diffusion Prior","summary":"Drag-driven editing has become popular among designers for its ability to\nmodify complex geometric structures through simple and intuitive manipulation,\nallowing users to adjust and reshape content with minimal technical skill. This\ndrag operation has been incorporated into numerous methods to facilitate the\nediting of 2D images and 3D meshes in design. However, few studies have\nexplored drag-driven editing for the widely-used 3D Gaussian Splatting (3DGS)\nrepresentation, as deforming 3DGS while preserving shape coherence and visual\ncontinuity remains challenging. In this paper, we introduce ARAP-GS, a\ndrag-driven 3DGS editing framework based on As-Rigid-As-Possible (ARAP)\ndeformation. Unlike previous 3DGS editing methods, we are the first to apply\nARAP deformation directly to 3D Gaussians, enabling flexible, drag-driven\ngeometric transformations. To preserve scene appearance after deformation, we\nincorporate an advanced diffusion prior for image super-resolution within our\niterative optimization process. This approach enhances visual quality while\nmaintaining multi-view consistency in the edited results. Experiments show that\nARAP-GS outperforms current methods across diverse 3D scenes, demonstrating its\neffectiveness and superiority for drag-driven 3DGS editing. Additionally, our\nmethod is highly efficient, requiring only 10 to 20 minutes to edit a scene on\na single RTX 3090 GPU.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T09:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.12790v1","title":"Empirically Evaluating the Use of Bytecode for Diversity-Based Test Case\n  Prioritisation","summary":"Regression testing assures software correctness after changes but is\nresource-intensive. Test Case Prioritisation (TCP) mitigates this by ordering\ntests to maximise early fault detection. Diversity-based TCP prioritises\ndissimilar tests, assuming they exercise different system parts and uncover\nmore faults. Traditional static diversity-based TCP approaches (i.e., methods\nthat utilise the dissimilarity of tests), like the state-of-the-art FAST\napproach, rely on textual diversity from test source code, which is effective\nbut inefficient due to its relative verbosity and redundancies affecting\nsimilarity calculations. This paper is the first to study bytecode as the basis\nof diversity in TCP, leveraging its compactness for improved efficiency and\naccuracy. An empirical study on seven Defects4J projects shows that bytecode\ndiversity improves fault detection by 2.3-7.8% over text-based TCP. It is also\n2-3 orders of magnitude faster in one TCP approach and 2.5-6 times faster in\nFAST-based TCP. Filtering specific bytecode instructions improves efficiency up\nto fourfold while maintaining effectiveness, making bytecode diversity a\nsuperior static approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T09:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.12791v1","title":"Probing the topological protection of edge states in multilayer tungsten\n  ditelluride with the superconducting proximity effect","summary":"The topology of WTe2, a transition metal dichalcogenide with large spin-orbit\ninteractions, is thought to combine type II Weyl semimetal and second-order\ntopological insulator (SOTI) character. The SOTI character should endow WTe2\nmultilayer crystals with topologically protected helical states at its hinges,\nand, indeed, 1D states have been detected thanks to Josephson interferometry.\nHowever, the immunity to backscattering conferred to those states by their\nhelical nature has so far not been tested. To probe the topological protection\nof WTe2 edge states, we have fabricated Superconducting Quantum Interference\nDevices (SQUIDs) in which the supercurrent through a junction on the crystal\nedge interferes with the supercurrent through a junction in the bulk of the\ncrystal. We find behaviors ranging from a Symmetric SQUID pattern to asymmetric\nSQUID patterns, including one in which the modulation by magnetic field reveals\na sawtooth-like supercurrent versus phase relation for the edge junction,\ndemonstrating that the supercurrent at the edge is carried by ballistic\nchannels over 600 nm, a tell-tale sign of the SOTI character of WTe2.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.12817v1","title":"Explainable Scene Understanding with Qualitative Representations and\n  Graph Neural Networks","summary":"This paper investigates the integration of graph neural networks (GNNs) with\nQualitative Explainable Graphs (QXGs) for scene understanding in automated\ndriving. Scene understanding is the basis for any further reactive or proactive\ndecision-making. Scene understanding and related reasoning is inherently an\nexplanation task: why is another traffic participant doing something, what or\nwho caused their actions? While previous work demonstrated QXGs' effectiveness\nusing shallow machine learning models, these approaches were limited to\nanalysing single relation chains between object pairs, disregarding the broader\nscene context. We propose a novel GNN architecture that processes entire graph\nstructures to identify relevant objects in traffic scenes. We evaluate our\nmethod on the nuScenes dataset enriched with DriveLM's human-annotated\nrelevance labels. Experimental results show that our GNN-based approach\nachieves superior performance compared to baseline methods. The model\neffectively handles the inherent class imbalance in relevant object\nidentification tasks while considering the complete spatial-temporal\nrelationships between all objects in the scene. Our work demonstrates the\npotential of combining qualitative representations with deep learning\napproaches for explainable scene understanding in autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-17T10:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.12822v1","title":"Miura transformation in bidifferential calculus and a vectorial Darboux\n  transformation for the Fokas-Lenells equation","summary":"Using a general result of bidifferential calculus and recent results of other\nauthors, a vectorial binary Darboux transformation is derived for the first\nmember of the \"negative\" part of the potential Kaup-Newell hierarchy, which is\na system of two coupled Fokas-Lenells equations. Miura transformations are\nfound from the latter to the first member of the negative part of the AKNS\nhierarchy and also to its \"pseudodual\". The reduction to the Fokas-Lenells\nequation is implemented and exact solutions with a plane wave seed generated.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-17T10:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.12832v1","title":"Physics of an AMOC Overshoot in a Box Model","summary":"Recently the global average temperature has temporarily exceeded the\n1.5{\\deg}C goal of the Paris Agreement, and so an overshoot of various climate\ntipping elements becomes increasingly likely. In this study we analyze the\nphysical processes of an overshoot of the Atlantic Meridional Overturning\nCirculation (AMOC), one of the major tipping elements, using a conceptual box\nmodel. Here either the atmospheric temperature above the North Atlantic, or the\nfreshwater forcing into the North Atlantic overshoot their respective critical\nboundaries. In both cases a higher forcing rate can prevent a collapse of the\nAMOC, since a higher rate of forcing causes initially a fresher North Atlantic,\nwhich in turn results in a higher northward transport by the subtropical gyre\nsupplementing the salinity loss in time. For small exceedance amplitudes the\nAMOC is still resilient as the forcing rates can be low and so other state\nvariables outside of the North Atlantic can adjust. Contrarily, for larger\novershoots the trajectories are dynamically similar and we find a lower limit\nin volume and exceedance time for respectively freshwater and temperature\nforcing in order to prevent a collapse. Moreover, for a large overshoot an\nincreased air-sea temperature coupling has a destabilizing effect, while the\nreverse holds for an overshoot close to the tipping point. The understanding of\nthe physics of the AMOC overshoot behavior is important for interpreting\nresults of Earth System Models and for evaluating the effects of mitigation and\nintervention strategies.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-17T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.12835v1","title":"Kinetic simulated annealing optimization with entropy-based cooling rate","summary":"We present a modified simulated annealing method with a dynamical choice of\nthe cooling temperature. The latter is determined via a closed-loop control and\nis proven to yield exponential decay of the entropy of the particle system. The\nanalysis is carried out through kinetic equations for interacting particle\nsystems describing the simulated annealing method in an extended phase space.\nDecay estimates are derived under the quasi-invariant scaling of the resulting\nsystem of Boltzmann-type equations to assess the consistency with their\nmean-field limit. Numerical results are provided to illustrate and support the\ntheoretical findings.","main_category":"math.OC","categories":"math.OC,nlin.AO","published":"2025-04-17T10:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.12841v1","title":"ALT: A Python Package for Lightweight Feature Representation in Time\n  Series Classification","summary":"We introduce ALT, an open-source Python package created for efficient and\naccurate time series classification (TSC). The package implements the adaptive\nlaw-based transformation (ALT) algorithm, which transforms raw time series data\ninto a linearly separable feature space using variable-length shifted time\nwindows. This adaptive approach enhances its predecessor, the linear law-based\ntransformation (LLT), by effectively capturing patterns of varying temporal\nscales. The software is implemented for scalability, interpretability, and ease\nof use, achieving state-of-the-art performance with minimal computational\noverhead. Extensive benchmarking on real-world datasets demonstrates the\nutility of ALT for diverse TSC tasks in physics and related domains.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.MS,stat.ML","published":"2025-04-17T10:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12843v1","title":"Quadratic subproduct systems, free products, and their C*-algebras","summary":"Motivated by the interplay between quadratic algebras, noncommutative\ngeometry, and operator theory, we introduce the notion of quadratic subproduct\nsystems of Hilbert spaces. Specifically, we study the subproduct systems\ninduced by a finite number of complex quadratic polynomials in noncommuting\nvariables, and describe their Toeplitz and Cuntz--Pimsner algebras. Inspired by\nthe theory of graded associative algebras, we define a free product operation\nin the category of subproduct systems and show that this corresponds to the\nreduced free product of the Toeplitz algebras. Finally, we obtain results about\nthe K-theory of the Toeplitz and Cuntz--Pimsner algebras of a large class of\nquadratic subproduct systems.","main_category":"math.OA","categories":"math.OA","published":"2025-04-17T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.12846v1","title":"Timing via Pinwheel Double Categories","summary":"We discuss string diagrams for timed process theories -- represented by\nduoidally-graded symmetric strict monoidal categories -- built upon the string\ndiagrams of pinwheel double categories.","main_category":"math.CT","categories":"math.CT,cs.LO","published":"2025-04-17T11:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.12848v1","title":"Scattering of a Dirac particle by a Berry phase domain wall","summary":"Massless Dirac particles are characterized by an effective\npseudospin-momentum locking, which is the origin of the peculiar scattering\nproperties of Dirac particles through potential barriers. This\npseudospin-momentum locking also governs the quantum geometric properties (such\nas the Berry phase and Berry curvature) of Dirac particles. In the present\nwork, we demonstrate that a domain wall separating two regions with distinct\nquantum geometric properties can serve as an alternative to potential barriers.\nSpecifically, using the three-band $\\alpha-T_3$ model of two-dimensional Dirac\nparticles, we show that a Berry phase domain wall results in partial reflection\nand transmission of the Dirac particles, despite the fact that the incident and\nrefracted momenta are identical.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T11:08:30Z"}
{"aid":"http://arxiv.org/abs/2504.12867v1","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\n  Prompting","summary":"Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\nwill be released.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CL","published":"2025-04-17T11:50:04Z"}
{"aid":"http://arxiv.org/abs/2504.12873v1","title":"On a category of extensions whose endomorphism rings have at most four\n  maximal ideals","summary":"We describe the endomorphism ring of a short exact sequences $0 \\to A_R \\to\nB_R \\to C_R \\to 0$ with $A_R$ and $C_R$ uniserial modules and the behavior of\nthese short exact sequences as far as their direct sums are concerned.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T12:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.12880v1","title":"Can Masked Autoencoders Also Listen to Birds?","summary":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the\nfine-grained acoustic characteristics of specialized domains such as\nbioacoustic monitoring. Bird sound classification is critical for assessing\nenvironmental health, yet general-purpose models inadequately address its\nunique acoustic challenges. To address this, we introduce Bird-MAE, a\ndomain-specialized MAE pretrained on the large-scale BirdSet dataset. We\nexplore adjustments to pretraining, fine-tuning and utilizing frozen\nrepresentations. Bird-MAE achieves state-of-the-art results across all BirdSet\ndownstream tasks, substantially improving multi-label classification\nperformance compared to the general-purpose Audio-MAE baseline. Additionally,\nwe propose prototypical probing, a parameter-efficient method for leveraging\nMAEs' frozen representations. Bird-MAE's prototypical probes outperform linear\nprobing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately\n3\\% on average on BirdSet.","main_category":"cs.LG","categories":"cs.LG,cs.SD,eess.AS","published":"2025-04-17T12:13:25Z"}
{"aid":"http://arxiv.org/abs/2504.12916v1","title":"Exact Learning Dynamics of In-Context Learning in Linear Transformers\n  and Its Application to Non-Linear Transformers","summary":"Transformer models exhibit remarkable in-context learning (ICL), adapting to\nnovel tasks from examples within their context, yet the underlying mechanisms\nremain largely mysterious. Here, we provide an exact analytical\ncharacterization of ICL emergence by deriving the closed-form stochastic\ngradient descent (SGD) dynamics for a simplified linear transformer performing\nregression tasks. Our analysis reveals key properties: (1) a natural separation\nof timescales directly governed by the input data's covariance structure,\nleading to staged learning; (2) an exact description of how ICL develops,\nincluding fixed points corresponding to learned algorithms and conservation\nlaws constraining the dynamics; and (3) surprisingly nonlinear learning\nbehavior despite the model's linearity. We hypothesize this phenomenology\nextends to non-linear models. To test this, we introduce theory-inspired\nmacroscopic measures (spectral rank dynamics, subspace stability) and use them\nto provide mechanistic explanations for (1) the sudden emergence of ICL in\nattention-only networks and (2) delayed generalization (grokking) in modular\narithmetic models. Our work offers an exact dynamical model for ICL and\ntheoretically grounded tools for analyzing complex transformer training.","main_category":"cs.LG","categories":"cs.LG,cond-mat.dis-nn","published":"2025-04-17T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12934v1","title":"Quantifying walkable accessibility to urban services: An application to\n  Florence, Italy","summary":"The concept of quality of life in urban settings is increasingly associated\nto the accessibility of amenities within a short walking distance for\nresidents. However, this narrative still requires thorough empirical\ninvestigation to evaluate the practical implications, benefits, and challenges.\nIn this work, we propose a novel methodology for evaluating urban accessibility\nto services, with an application to the city of Florence, Italy. Our approach\ninvolves identifying the accessibility of essential services from residential\nbuildings within a 10-minute walking distance, employing a rigorous spatial\nanalysis process and open-source geospatial data. As a second contribution, we\nextend the concept of 10-minute accessibility within a network theory framework\nand apply a clustering algorithm to identify urban communities based on shared\naccess to essential services. Finally, we explore the dimension of functional\nredundancy. Our proposed metrics represent a step forward towards an accurate\nassessment of the adherence to the 10-minute city model and offer a valuable\ntool for place-based policies aimed at addressing spatial disparities in urban\ndevelopment.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-17T13:28:21Z"}
{"aid":"http://arxiv.org/abs/2504.12940v1","title":"A study of Andromeda to improve our knowledge on the evolution and dust\n  production by AGB stars","summary":"We study the AGB population of the galaxy M31, based on available HST and\nSpitzer data,\n  to characterize the individual sources in terms of mass, metallicity and\nformation epoch\n  of the progenitors. Particular attention is dedicated to the derivation of\nthe dust\n  production rate of the stars, in the attempt of determining the global\ncurrent dust production\n  rate of the galaxy, divided between the silicates and the carbonaceous dust\ncontributions.\n  We use results from stellar evolution modelling complemented by the\ndescription of the\n  dust formation process in the wind, to be used in a population synthesis\napproach, based on\n  the star formation history and age-metallicity relationship obtained in\nprevious investigations.\n  The comparison between the results from synthetic modelling and the data\navailable are used\n  for the characterization of AGB stars in M31.\n  We find that the bulk of the AGB population of M31 is composed by low-mass\nstars of\n  different metallicity formed between 6 Gyr and 14 Gyr ago, with an\nadditional, significant\n  contribution from the progeny of 1.7-2.5Msun stars formed during the\nsecondary peak\n  in the star formation, which occurred between 1 and 2 Gyr ago. The dust\nproduction rate of the\n  galaxy is mostly provided by carbon stars, whose contribution is of the order\nof\n  4x10^{-4} Msun/yr, completed by silicates production from massive AGB stars,\n  occurring at a rate of 6x10^{-5} Msun/yr. The implications of the present\n  results on the reliability of AGB modelling are also commented.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-17T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.12944v1","title":"A Bi-Objective MDP Design approach to redundancy allocation with dynamic\n  maintenance for a parallel system","summary":"The reliability of a system can be improved by the addition of redundant\nelements, giving rise to the well-known redundancy allocation problem (RAP),\nwhich can be seen as a design problem. We propose a novel extension to the RAP\ncalled the Bi-Objective Integrated Design and Dynamic Maintenance Problem\n(BO-IDDMP) which allows for future dynamic maintenance decisions to be\nincorporated. This leads to a problem with first-stage redundancy design\ndecisions and a second-stage sequential decision problem. To the best of our\nknowledge, this is the first use of a continuous-time Markov Decision Process\nDesign framework to formulate a problem with non-trivial dynamics, as well as\nits first use alongside bi-objective optimization. A general heuristic\noptimization methodology for two-stage bi-objective programmes is developed,\nwhich is then applied to the BO-IDDMP. The efficiency and accuracy of our\nmethodology are demonstrated against an exact optimization formulation. The\nheuristic is shown to be orders of magnitude faster, and in only 2 out of 42\ncases fails to find one of the Pareto-optimal solutions found by the exact\nmethod. The inclusion of dynamic maintenance policies is shown to yield\nstronger and better-populated Pareto fronts, allowing more flexibility for the\ndecision-maker. The impacts of varying parameters unique to our problem are\nalso investigated.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T13:45:14Z"}
{"aid":"http://arxiv.org/abs/2504.12955v1","title":"Systemic risk mitigation in supply chains through network rewiring","summary":"The networked nature of supply chains makes them susceptible to systemic\nrisk, where local firm failures can propagate through firm interdependencies\nthat can lead to cascading supply chain disruptions. The systemic risk of\nsupply chains can be quantified and is closely related to the topology and\ndynamics of supply chain networks (SCN). How different network properties\ncontribute to this risk remains unclear. Here, we ask whether systemic risk can\nbe significantly reduced by strategically rewiring supplier-customer links. In\ndoing so, we understand the role of specific endogenously emerged network\nstructures and to what extent the observed systemic risk is a result of\nfundamental properties of the dynamical system. We minimize systemic risk\nthrough rewiring by employing a method from statistical physics that respects\nfirm-level constraints to production. Analyzing six specific subnetworks of the\nnational SCNs of Ecuador and Hungary, we demonstrate that systemic risk can be\nconsiderably mitigated by 16-50% without reducing the production output of\nfirms. A comparison of network properties before and after rewiring reveals\nthat this risk reduction is achieved by changing the connectivity in\nnon-trivial ways. These results suggest that actual SCN topologies carry\nunnecessarily high levels of systemic risk. We discuss the possibility of\ndevising policies to reduce systemic risk through minimal, targeted\ninterventions in supply chain networks through market-based incentives.","main_category":"econ.GN","categories":"econ.GN,physics.soc-ph,q-fin.EC","published":"2025-04-17T13:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.12967v1","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic\n  End-Effector for Robotic Learning and Dexterous Manipulation","summary":"This paper presents the Krysalis Hand, a five-finger robotic end-effector\nthat combines a lightweight design, high payload capacity, and a high number of\ndegrees of freedom (DoF) to enable dexterous manipulation in both industrial\nand research settings. This design integrates the actuators within the hand\nwhile maintaining an anthropomorphic form. Each finger joint features a\nself-locking mechanism that allows the hand to sustain large external forces\nwithout active motor engagement. This approach shifts the payload limitation\nfrom the motor strength to the mechanical strength of the hand, allowing the\nuse of smaller, more cost-effective motors. With 18 DoF and weighing only 790\ngrams, the Krysalis Hand delivers an active squeezing force of 10 N per finger\nand supports a passive payload capacity exceeding 10 lbs. These characteristics\nmake Krysalis Hand one of the lightest, strongest, and most dexterous robotic\nend-effectors of its kind. Experimental evaluations validate its ability to\nperform intricate manipulation tasks and handle heavy payloads, underscoring\nits potential for industrial applications as well as academic research. All\ncode related to the Krysalis Hand, including control and teleoperation, is\navailable on the project GitHub repository:\nhttps://github.com/Soltanilara/Krysalis_Hand","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T14:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.12974v1","title":"L-systems with Multiplication Operator and c-Entropy","summary":"In this note, we utilize the concepts of c-entropy and the dissipation\ncoefficient in connection with canonical L-systems based on the multiplication\n(by a scalar) operator. Additionally, we examine the coupling of such L-systems\nand derive explicit formulas for the associated c-entropy and dissipation\ncoefficient. In this context, we also introduce the concept of a skew-adjoint\nL-system and analyze its coupling with the original L-system.","main_category":"math.SP","categories":"math.SP","published":"2025-04-17T14:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.12977v1","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems\n  Using Heidegger's Fundamental Ontology","summary":"This paper presents a novel research analytical IT system grounded in Martin\nHeidegger's Fundamental Ontology, distinguishing between beings (das Seiende)\nand Being (das Sein). The system employs two modally distinct, descriptively\ncomplete languages: a categorical language of beings for processing user inputs\nand an existential language of Being for internal analysis. These languages are\nbridged via a phenomenological reduction module, enabling the system to analyze\nuser queries (including questions, answers, and dialogues among IT\nspecialists), identify recursive and self-referential structures, and provide\nactionable insights in categorical terms. Unlike contemporary systems limited\nto categorical analysis, this approach leverages Heidegger's phenomenological\nexistential analysis to uncover deeper ontological patterns in query\nprocessing, aiding in resolving logical traps in complex interactions, such as\nmetaphor usage in IT contexts. The path to full realization involves\nformalizing the language of Being by a research team based on Heidegger's\nFundamental Ontology; given the existing completeness of the language of\nbeings, this reduces the system's computability to completeness, paving the way\nfor a universal query analysis tool. The paper presents the system's\narchitecture, operational principles, technical implementation, use\ncases--including a case based on real IT specialist dialogues--comparative\nevaluation with existing tools, and its advantages and limitations.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.HC","published":"2025-04-17T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.12978v1","title":"X-ray linear dichroic orientation tomography: reconstruction of\n  nanoscale three-dimensional orientation fields","summary":"Properties in crystalline and ordered materials tend to be anisotropic, with\ntheir orientation affecting the macroscopic behavior and functionality of\nmaterials. The ability to image the orientation of anisotropic material\nproperties in three dimensions (3D) is fundamental for the understanding and\nfunctionality-driven development of novel materials. With the development of X\nray linear dichroic orientation tomography (XL DOT), it is now possible to\nnon-destructively map three-dimensional (3D) orientation fields in\nmicrometer-sized samples. In this work, we present the iterative,\ngradient-based reconstruction algorithm behind XL DOT that can be used to map\norientations based on linear dichroism in 3D. As linear dichroism can be\nexhibited by a broad spectrum of materials, XL DOT can be used to map, for\nexample, crystal orientations as well as ferroic alignment, such as\nferroelectric and antiferromagnetic order. We demonstrate the robustness of\nthis technique for orientation fields that exhibit smoothly varying and\ngranular configurations, and subsequently identify and discuss optimal\ngeometries for experimental data acquisition and optimal conditions for the\nreconstruction. We anticipate that this technique will be instrumental in\nenabling a deeper understanding of the relationship between material structures\nand their functionality, quantifying, for example, the orientation of charge\ndistributions and magnetic anisotropies at the nanoscale in a wide variety of\nsystems - from functional to energy materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T14:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.12987v1","title":"Global regularity for the Dirichlet problem of Monge-Ampère equation\n  in convex polytopes","summary":"We study the Dirichlet problem for Monge-Amp\\`ere equation in bounded convex\npolytopes. We give sharp conditions for the existence of global $C^2$ and\n$C^{2,\\alpha}$ convex solutions provided that a global $C^2$, convex\nsubsolution exists.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T14:50:08Z"}
{"aid":"http://arxiv.org/abs/2504.12998v1","title":"Automated Generation of Commit Messages in Software Repositories","summary":"Commit messages are crucial for documenting software changes, aiding in\nprogram comprehension and maintenance. However, creating effective commit\nmessages is often overlooked by developers due to time constraints and varying\nlevels of documentation skills. Our research presents an automated approach to\ngenerate commit messages using Machine Learning (ML) and Natural Language\nProcessing (NLP) by developing models that use techniques such as Logistic\nRegression with TF-IDF and Word2Vec, as well as more sophisticated methods like\nLSTM. We used the dataset of code changes and corresponding commit messages\nthat was used by Liu et al., which we used to train and evaluate ML/NLP models\nand was chosen because it is extensively used in previous research, also for\ncomparability in our study. The objective was to explore which ML/NLP\ntechniques generate the most effective, clear, and concise commit messages that\naccurately reflect the code changes. We split the dataset into training,\nvalidation, and testing sets and used these sets to evaluate the performance of\neach model using qualitative and quantitative evaluation methods. Our results\nreveal a spectrum of effectiveness among these models, with the highest BLEU\nscore achieved being 16.82, showcasing the models' capability in automating a\nclear and concise commit message generation. Our paper offers insights into the\ncomparative effectiveness of different machine learning models for automating\ncommit message generation in software development, aiming to enhance the\noverall practice of code documentation. The source code is available at\nhttps://doi.org/10.5281/zenodo.10888106.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.13000v1","title":"Tree-Line graphs and their quantum walks","summary":"For a simple graph $\\Gamma$, a (bipartite)tree-line graph and a tree-graph of\n$\\Gamma$ can be defined. With a (bipartite)tree-line graph constructed by the\nfunction $(b)\\ell$, we study the continuous quantum walk on $(b)\\ell ^n\n\\Gamma$. An equitable partition of a bipartite tree-line graph is obtained by\nits corresponding derived tree graph. This paper also examines quantum walks on\nderived graphs, whose vertices represent their basis state.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T15:10:49Z"}
{"aid":"http://arxiv.org/abs/2504.13005v1","title":"Knot Floer homology of positive braids","summary":"We compute the next-to-top term of knot Floer homology for positive braid\nlinks. The rank is 1 for any prime positive braid knot. We give some examples\nof fibered positive links that are not positive braids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-17T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.13006v1","title":"Mathematical programs with complementarity constraints and application\n  to hyperparameter tuning for nonlinear support vector machines","summary":"We consider the Mathematical Program with Complementarity Constraints (MPCC).\nOne of the main challenges in solving this problem is the systematic failure of\nstandard Constraint Qualifications (CQs). Carefully accounting for the\ncombinatorial nature of the complementarity constraints, tractable versions of\nthe Mangasarian Fromovitz Constraint Qualification (MFCQ) have been designed\nand widely studied in the literature. This paper looks closely at two such\nMPCC-MFCQs and their influence on MPCC algorithms. As a key contribution, we\nprove the convergence of the sequential penalisation and Scholtes relaxation\nalgorithms under a relaxed MPCC-MFCQ that is much weaker than the CQs currently\nused in the literature. We then form the problem of tuning hyperparameters of a\nnonlinear Support Vector Machine (SVM), a fundamental machine learning problem\nfor classification, as a MPCC. For this application, we establish that the\naforementioned relaxed MPCC-MFCQ holds under a very mild assumption. Moreover,\nwe program robust implementations and comprehensive numerical experimentation\non real-world data sets, where we show that the sequential penalisation method\napplied to the MPCC formulation for tuning SVM hyperparameters can outperform\nboth the Scholtes relaxation technique and the state-of-the-art derivative-free\nmethods from the machine learning literature.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T15:15:34Z"}
{"aid":"http://arxiv.org/abs/2504.13009v1","title":"Sequential ejections of plasma blobs due to unbraiding of tangled loops\n  in the solar atmosphere","summary":"Nanoflares, which are consequences of braids in tangled magnetic fields, are\nan important candidate to heat the solar corona to million degrees. However,\ntheir observational evidence is sparse and many of their observational\ncharacteristics are yet to be discovered. With the high-resolution observations\ntaken by the Extreme Ultraviolet Imager onboard the Solar Orbiter, here we\nstudy a series of ejections of plasma blobs resulted from a braided magnetic\nloops in the upper transition region and reveal some critical characteristics\nof such processes. The cores of these ejections have a size of about 700\\,km, a\nduration less than 1 minute and a speed of about 90\\,\\kms. An important\ncharacteristic is that these plasma blobs are apparently constrained by the\npost-reconnection magnetic loops, along which they show an extension of up to\nabout 2\\,000\\,km. The propagation of unbraiding nodes along the main axis of\nthe tangled loops has a speed of about 45\\,\\kms. The separation angles between\nthe post-reconnection loops and the main axis of the tangled loops are about\n30\\degree. The observations from the Atmospheric Imaging Assembly reveal that\nthe braiding loops are upper transition region structures. Based on these\nobservations, the typical magnetic free energy producing a blob is estimated to\nbe about $3.4\\times10^{23}$\\,erg, well in the nano-flare regime, while the\nkinematic energy of a blob is about $2.3\\times10^{23}$\\,erg, suggesting that a\nmajority of magnetic free energy in a magnetic braid is likely transferred into\nkinematic energy.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T15:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.13012v1","title":"Hopf Exceptional Points","summary":"Exceptional points at which eigenvalues and eigenvectors of non-Hermitian\nmatrices coalesce are ubiquitous in the description of a wide range of\nplatforms from photonic or mechanical metamaterials to open quantum systems.\nHere, we introduce a class of Hopf exceptional points (HEPs) that are protected\nby the Hopf invariants (including the higher-dimensional generalizations) and\nwhich exhibit phenomenology sharply distinct from conventional exceptional\npoints. Saliently, owing to their $\\mathbb{Z}_2$ topological invariant related\nto the Witten anomaly, three-fold HEPs and symmetry-protected five-fold HEPs\nact as their own ``antiparticles\". Furthermore, based on higher homotopy groups\nof spheres, we predict the existence of multifold HEPs and symmetry-protected\nHEPs with non-Hermitian topology captured by a range of finite groups (such as\n$\\mathbb{Z}_3$, $\\mathbb{Z}_{12}$, or $\\mathbb{Z}_{24}$) beyond the periodic\ntable of Bernard-LeClair symmetry classes.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.optics,quant-ph","published":"2025-04-17T15:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.13016v1","title":"ORIS allocation to minimize the outage probability in a multi-user VLC\n  scenario","summary":"Visible Light Communication (VLC) is a promising solution to address the\ngrowing demand for wireless data, leveraging the widespread use of\nlight-emitting diodes (LEDs) as transmitters. However, its deployment is\nchallenged by link blockages that cause connectivity outages. Optical\nreconfigurable intelligent surfaces (ORISs) have recently emerged as a solution\nto mitigate these disruptions. This work considers a multi-user VLC system and\ninvestigates the optimal association of ORISs to LEDs and users to minimize the\noutage probability while limiting the number of ORISs used. Numerical results\nfrom our proposed optimization algorithm demonstrate that using ORISs can\nreduce the outage probability by up to 85% compared to a no-ORIS scenario.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.13021v1","title":"Pose and Facial Expression Transfer by using StyleGAN","summary":"We propose a method to transfer pose and expression between face images.\nGiven a source and target face portrait, the model produces an output image in\nwhich the pose and expression of the source face image are transferred onto the\ntarget identity. The architecture consists of two encoders and a mapping\nnetwork that projects the two inputs into the latent space of StyleGAN2, which\nfinally generates the output. The training is self-supervised from video\nsequences of many individuals. Manual labeling is not required. Our model\nenables the synthesis of random identities with controllable pose and\nexpression. Close-to-real-time performance is achieved.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T15:29:41Z"}
{"aid":"http://arxiv.org/abs/2504.13027v1","title":"Competing Bosonic Reactions: Insight from Exactly Solvable\n  Time-Dependent Models","summary":"We discuss the progress on exactly solvable multistate Landau-Zener models\nfrom a perspective of their application to competing reactions of particle\ncreation from a false vacuum. Such models generally predict that, even with\nidentical initial conditions, and for nearly the same other particle\nparameters, a quantum coherent evolution results in a final particle\ndistribution with significant asymmetry. We use an exact solution of the driven\nbosonic Tavis-Cummings model for two reaction pathways in order to quantify\nthis effect, reveal a corresponding phase transition, and identify its\nuniversality class.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,gr-qc,hep-th","published":"2025-04-17T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2504.13029v1","title":"Three-dimensional canonical quantum plasmonics for finite media: exact\n  solution in terms of the classical Green tensor","summary":"This article presents a comprehensive three-dimensional canonical\nquantization to treat quantum plasmonics for finite metallic or dielectric\nmedia of arbitrary shape. We use a microscopic model for the dissipative and\ndispersive medium coupled with the electromagnetic field, which is justified by\nthe fact that if one integrates the degrees of freedom of the medium, one\nobtains the macroscopic Maxwell equations. Its quantization features a\nHamiltonian formulation having the form of two infinite harmonic oscillators\ncharacterized by a double continuum. The diagonalized Hamiltonian is quantized\nby the correspondence principle, introducing creation-annihilation operators in\na bosonic Fock space. The diagonal quantum Hamiltonian is the sum of two terms\ncorresponding to the two continua. The physical observables, like, e.g., the\nelectric field, are also the sum of two terms corresponding to the two\ncontinua, one of which had been omitted in the literature geared for an\ninfinite bulk medium. In a second step, we show that the electric field\noperator can by written as linear combinations of the creation-annihilation\noperators with coefficients that satisfy integral equations of Fredholm type.\nWe show that the solution of these equations can be expressed in terms of the\nclassical Green tensor of the medium satisfying the Sommerfeld radiation\ncondition. Finally, we consider the Purcell effect for the spontaneous emission\nof an atom close to the medium. We show that through an exact compensation of\nsome terms, the Purcell factor for the system with the double continuum is\nproportional to the imaginary part of the Green tensor, which defines the local\ndensity of states. This result has the same form as the one obtained in the\nliterature for bulk systems that involve a single continuum and a small\ndissipative background extending to infinity, and can be seen as a\njustification of this approach.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.13032v1","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\n  Graphs for LLM-Based Task Planning","summary":"Recent advancements in large language models (LLMs) have enabled their use as\nagents for planning complex tasks. Existing methods typically rely on a\nthought-action-observation (TAO) process to enhance LLM performance, but these\napproaches are often constrained by the LLMs' limited knowledge of complex\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\nleveraging external databases to ground generation in retrieved information. In\nthis paper, we identify two key challenges (enlargability and transferability)\nin applying RAG to task planning. We propose InstructRAG, a novel solution\nwithin a multi-agent meta-reinforcement learning framework, to address these\nchallenges. InstructRAG includes a graph to organize past instruction paths\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\nimprove task generalization for transferability. The two agents are trained\nend-to-end to optimize overall planning performance. Our experiments on four\nwidely used task planning datasets demonstrate that InstructRAG significantly\nenhances performance and adapts efficiently to new tasks, achieving up to a\n19.2% improvement over the best existing approach.","main_category":"cs.AI","categories":"cs.AI,cs.IR","published":"2025-04-17T15:41:39Z"}
{"aid":"http://arxiv.org/abs/2504.13033v1","title":"Practical Application of the Quantum Carleman Lattice Boltzmann Method\n  in Industrial CFD Simulations","summary":"Computational Fluid Dynamics simulations are crucial in industrial\napplications but require extensive computational resources, particularly for\nextreme turbulent regimes. While classical digital approaches remain the\nstandard, quantum computing promises a breakthrough by enabling a more\nefficient encoding of large-scale simulations with a limited number of qubits.\n  This work presents a practical numerical assessment of a hybrid\nquantum-classical approach to CFD based on the Lattice Boltzmann Method (LBM).\nThe inherently non-linear LBM equations are linearized via a Carleman expansion\nand solved using the quantum Harrow Hassidim Lloyd algorithm (HHL). We evaluate\nthis method on three benchmark cases featuring different boundary conditions,\nperiodic, bounceback, and moving wall, using statevector emulation on\nhigh-performance computing resources.\n  Our results confirm the validity of the approach, achieving median error\nfidelities on the order of $10^{-3}$ and success probabilities sufficient for\npractical quantum state sampling. Notably, the spectral properties of small\nlattice systems closely approximate those of larger ones, suggesting a pathway\nto mitigate one of HHL's bottlenecks: eigenvalue pre-evaluation.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph,physics.flu-dyn","published":"2025-04-17T15:41:48Z"}
{"aid":"http://arxiv.org/abs/2504.13035v1","title":"Prototypes are Balanced Units for Efficient and Effective Partially\n  Relevant Video Retrieval","summary":"In a retrieval system, simultaneously achieving search accuracy and\nefficiency is inherently challenging. This challenge is particularly pronounced\nin partially relevant video retrieval (PRVR), where incorporating more diverse\ncontext representations at varying temporal scales for each video enhances\naccuracy but increases computational and memory costs. To address this\ndichotomy, we propose a prototypical PRVR framework that encodes diverse\ncontexts within a video into a fixed number of prototypes. We then introduce\nseveral strategies to enhance text association and video understanding within\nthe prototypes, along with an orthogonal objective to ensure that the\nprototypes capture a diverse range of content. To keep the prototypes\nsearchable via text queries while accurately encoding video contexts, we\nimplement cross- and uni-modal reconstruction tasks. The cross-modal\nreconstruction task aligns the prototypes with textual features within a shared\nspace, while the uni-modal reconstruction task preserves all video contexts\nduring encoding. Additionally, we employ a video mixing technique to provide\nweak guidance to further align prototypes and associated textual\nrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, and\nQVHighlights validate the effectiveness of our approach without sacrificing\nefficiency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T15:43:29Z"}
{"aid":"http://arxiv.org/abs/2504.13045v1","title":"Expert Kernel Generation Network Driven by Contextual Mapping for\n  Hyperspectral Image Classification","summary":"Deep neural networks face several challenges in hyperspectral image\nclassification, including high-dimensional data, sparse distribution of ground\nobjects, and spectral redundancy, which often lead to classification\noverfitting and limited generalization capability. To more efficiently adapt to\nground object distributions while extracting image features without introducing\nexcessive parameters and skipping redundant information, this paper proposes\nEKGNet based on an improved 3D-DenseNet model, consisting of a context-aware\nmapping network and a dynamic kernel generation module. The context-aware\nmapping module translates global contextual information of hyperspectral inputs\ninto instructions for combining base convolutional kernels, while the dynamic\nkernels are composed of K groups of base convolutions, analogous to K different\ntypes of experts specializing in fundamental patterns across various\ndimensions. The mapping module and dynamic kernel generation mechanism form a\ntightly coupled system - the former generates meaningful combination weights\nbased on inputs, while the latter constructs an adaptive expert convolution\nsystem using these weights. This dynamic approach enables the model to focus\nmore flexibly on key spatial structures when processing different regions,\nrather than relying on the fixed receptive field of a single static\nconvolutional kernel. EKGNet enhances model representation capability through a\n3D dynamic expert convolution system without increasing network depth or width.\nThe proposed method demonstrates superior performance on IN, UP, and KSC\ndatasets, outperforming mainstream hyperspectral image classification\napproaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:00:06Z"}
{"aid":"http://arxiv.org/abs/2504.13057v1","title":"Covariate balancing estimation and model selection for\n  difference-in-differences approach","summary":"In causal inference, remarkable progress has been made in\ndifference-in-differences (DID) approaches to estimate the average effect of\ntreatment on the treated (ATT). Of these, the semiparametric DID (SDID)\napproach incorporates a propensity score analysis into the DID setup. Supposing\nthat the ATT is a function of covariates, we estimate it by weighting the\ninverse of the propensity score. As one method to make the estimation robust to\nthe propensity score modeling, we incorporate covariate balancing. Then, by\nattentively constructing the moment conditions used in the covariate balancing,\nwe show that the proposed estimator has doubly robustness. In addition to the\nestimation, model selection is also addressed. In practice, covariate selection\nis an essential task in statistical analysis, but even in the basic setting of\nthe SDID approach, there are no reasonable information criteria. Therefore, we\nderive a model selection criterion as an asymptotically bias-corrected\nestimator of risk based on the loss function used in the SDID estimation. As a\nresult, we show that a penalty term is derived that is considerably different\nfrom almost twice the number of parameters that often appears in AIC-type\ninformation criteria. Numerical experiments show that the proposed method\nestimates the ATT robustly compared to the method using propensity scores given\nby the maximum likelihood estimation (MLE), and that the proposed criterion\nclearly reduces the risk targeted in the SDID approach compared to the\nintuitive generalization of the existing information criterion. In addition,\nreal data analysis confirms that there is a large difference between the\nresults of the proposed method and the existing method.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T16:11:42Z"}
{"aid":"http://arxiv.org/abs/2504.13070v1","title":"A quadratic estimator view of the transfer function correction in\n  intensity mapping surveys","summary":"In single dish neutral hydrogen (HI) intensity mapping, signal separation\nmethods such as Principal Component Analysis (PCA) are used to clean the\nastrophysical foregrounds. PCA induces a signal loss in the estimated power\nspectrum, which can be corrected by a transfer function (TF). By injecting mock\nsignals of HI into the data and performing the PCA cleaning, we can use the\ncleaned mock HI signal to cross-correlate with the original mock, and estimate\nthe signal loss as a TF, $T(\\vec{k})$. As expected, a correction of\n${T}(\\vec{k})^{-1}$ restores the cross-power between the HI and optical\ngalaxies. However, contrary to intuition, the HI auto-power also requires a\n${T}(\\vec{k})^{-1}$ correction, not ${T}(\\vec{k})^{-2}$. The\n${T}(\\vec{k})^{-1}$ correction is only known empirically through simulations.\nIn this Letter, we show that the ${T}(\\vec{k})^{-1}$ correction in auto-power\nis universal, and can be analytically proven using the quadratic estimator\nformalism through window function normalisation. The normalisation can also be\nused to determine the TF correction for any type of linear process. Using the\nwindow function, we demonstrate that PCA induces mode-mixing in the power\nspectrum estimation, which may lead to biases in the model inference.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T16:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.13073v1","title":"Topological defect engineering enables size and shape control in\n  self-assembly","summary":"The self-assembly of complex structures from engineered subunits is a major\ngoal of nanotechnology, but controlling their size becomes increasingly\ndifficult in larger assemblies. Existing strategies present significant\nchallenges, among which are the use of multiple subunit types or the precise\ncontrol of their shape and mechanics. Here we introduce an alternative approach\nbased on identical subunits whose interactions promote crystals, but also favor\ncrystalline defects. We theoretically show that topological restrictions on the\nscope of these defects in large assemblies imply that the assembly size is\ncontrolled by the magnitude of the defect-inducing interaction. Using DNA\norigami, we experimentally demonstrate both size and shape control in\ntwo-dimensional disk- and fiber-like assemblies. Our basic concept of defect\nengineering could be generalized well beyond these simple examples, and thus\nprovide a broadly applicable scheme to control self-assembly.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T16:35:44Z"}
{"aid":"http://arxiv.org/abs/2504.13084v1","title":"Proca theory of four-dimensional regularized Gauss-Bonnet gravity and\n  black holes with primary hair","summary":"We introduce a novel, well-defined four-dimensional regularized Gauss-Bonnet\ntheory of gravity by applying a dimensional regularization procedure. The\nresulting theory is a vector-tensor theory within the generalized Proca class.\nWe then consider the static spherically symmetric solutions of this theory and\nfind black hole solutions that acquire primary hair. Notably, one of the\nintegration constants associated with the Proca field is not manifest in the\noriginal metric, but under a disformal transformation of the seed solution, it\nemerges as a second, independent primary hair. This additional hair acts as an\neffective cosmological constant in the disformed geometry, even in the absence\nof a bare cosmological constant term. We further generalize these black hole\nsolutions to include electromagnetic charges and effects related to the\nscalar-tensor counterparts of the regularized Gauss-Bonnet theory. We discuss\nthe implications of our findings to observations.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.13093v1","title":"A lattice point counting approach for the study of the number of\n  self-avoiding walks on $\\mathbb{Z}^{d}$","summary":"We reduce the problem of counting self-avoiding walks in the square lattice\nto a problem of counting the number of integral points in multidimensional\ndomains. We obtain an asymptotic estimate of the number of self-avoiding walks\nof length $n$ in the square lattice. This new formalism gives a natural and\nunified setting in order to study the properties the number of self-avoidings\nwalks in the lattice $\\mathbb{Z}^{d}$ of any dimension $d\\geq 2$.","main_category":"math.PR","categories":"math.PR,math.CO,math.NT","published":"2025-04-17T16:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.13096v1","title":"Tight and overtwisted contact structures","summary":"The tight versus overtwisted dichotomy has been an essential organizing\nprinciple and driving force in 3-dimensional contact geometry since its\ninception around 1990. In this article, we will discuss the genesis of this\ndichotomy in Eliashberg's seminal work and his influential contributions to the\ntheory.","main_category":"math.SG","categories":"math.SG,math.GT","published":"2025-04-17T17:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.13106v1","title":"Intersection of non-degenerate Hermitian variety and cubic hypersurface","summary":"Edoukou, Ling and Xing in 2010, conjectured that in\n\\mathbb{P}^n(\\mathbb{F}_{q^2}), n \\geq 3, the maximum number of common points\nof a non-degenerate Hermitian variety \\mathcal{U}_n and a hypersurface of\ndegree d is achieved only when the hypersurface is a union of d distinct\nhyperplanes meeting in a common linear space \\Pi_{n-2} of codimension 2 such\nthat \\Pi_{n-2} \\cap \\mathcal{U}_n is a non-degenerate Hermitian variety.\nFurthermore, these d hyperplanes are tangent to \\mathcal{U}_n if n is odd and\nnon-tangent if n is even. In this paper, we show that the conjecture is true\nfor d = 3 and q \\geq 7.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T17:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.13113v1","title":"Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum\n  Autoencoders","summary":"Detecting mission-critical anomalous events and data is a crucial challenge\nacross various industries, including finance, healthcare, and energy. Quantum\ncomputing has recently emerged as a powerful tool for tackling several machine\nlearning tasks, but training quantum machine learning models remains\nchallenging, particularly due to the difficulty of gradient calculation. The\nchallenge is even greater for anomaly detection, where unsupervised learning\nmethods are essential to ensure practical applicability. To address these\nissues, we propose Quorum, the first quantum anomaly detection framework\ndesigned for unsupervised learning that operates without requiring any\ntraining.","main_category":"cs.LG","categories":"cs.LG,cs.ET","published":"2025-04-17T17:27:39Z"}
{"aid":"http://arxiv.org/abs/2504.13127v1","title":"Force and Speed in a Soft Stewart Platform","summary":"Many soft robots struggle to produce dynamic motions with fast, large\ndisplacements. We develop a parallel 6 degree-of-freedom (DoF) Stewart-Gough\nmechanism using Handed Shearing Auxetic (HSA) actuators. By using soft\nactuators, we are able to use one third as many mechatronic components as a\nrigid Stewart platform, while retaining a working payload of 2kg and an\nopen-loop bandwidth greater than 16Hx. We show that the platform is capable of\nboth precise tracing and dynamic disturbance rejection when controlling a ball\nand sliding puck using a Proportional Integral Derivative (PID) controller. We\ndevelop a machine-learning-based kinematics model and demonstrate a functional\nworkspace of roughly 10cm in each translation direction and 28 degrees in each\norientation. This 6DoF device has many of the characteristics associated with\nrigid components - power, speed, and total workspace - while capturing the\nadvantages of soft mechanisms.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T17:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.13137v1","title":"Integral formulas for hypersurfaces in cones and related questions","summary":"We discuss the validity of Minkowski integral identities for hypersurfaces\ninside a cone, intersecting the boundary of the cone orthogonally. In doing so\nwe correct a formula provided in [3]. Then we study rigidity results for\nconstant mean curvature graphs proving the precise statement of a result given\nin [9] and [10]. Finally we provide an integral estimate for stable constant\nmean curvature hypersurfaces in cones.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T17:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.13151v1","title":"MIB: A Mechanistic Interpretability Benchmark","summary":"How can we know whether new mechanistic interpretability methods achieve real\nimprovements? In pursuit of meaningful and lasting evaluation standards, we\npropose MIB, a benchmark with two tracks spanning four tasks and five models.\nMIB favors methods that precisely and concisely recover relevant causal\npathways or specific causal variables in neural language models. The circuit\nlocalization track compares methods that locate the model components - and\nconnections between them - most important for performing a task (e.g.,\nattribution patching or information flow routes). The causal variable\nlocalization track compares methods that featurize a hidden vector, e.g.,\nsparse autoencoders (SAEs) or distributed alignment search (DAS), and locate\nmodel features for a causal variable relevant to the task. Using MIB, we find\nthat attribution and mask optimization methods perform best on circuit\nlocalization. For causal variable localization, we find that the supervised DAS\nmethod performs best, while SAE features are not better than neurons, i.e.,\nstandard dimensions of hidden vectors. These findings illustrate that MIB\nenables meaningful comparisons of methods, and increases our confidence that\nthere has been real progress in the field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-17T17:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.13156v1","title":"Gravitational wave anisotropies from axion inflation","summary":"An important prediction of inflation is the production of a primordial\nstochastic gravitational wave background. Observing this background is\nchallenging due to the weakness of the signal and the simultaneous presence of\nan astrophysical background generated by many unresolved late-time sources. One\npossible way to distinguish between the two is to examine their anisotropies.\nIn this paper we calculate the primordial correlation function of gravitational\nwave anisotropies in the cosmological background generated by axion inflation,\nwhere the inflaton is a pseudo-Nambu-Goldstone boson coupled to gauge fields.\nIn this scenario, tensor modes arise not only from the standard amplification\nof vacuum fluctuations present in any inflationary model, but also from the\ninverse decay process of the produced gauge fields. The correlator of\ngravitational wave anisotropies consists therefore of two main components: the\ncontribution from vacuum tensor modes and the contribution from tensor modes\nsourced by the gauge fields. Our analysis shows that, while the former,\npreviously studied in the literature, is negligible, the one arising from the\nsourced tensor modes, normalized by the fractional energy density at\ninterferometer frequencies, can reach values as large as\n$\\mathcal{O}(10^{-1})$. This result shows that axion inflation can generate\nlarge anisotropies with the potential to be observed by gravitational wave\ndetectors within a reasonable time frame.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-17T17:56:58Z"}
{"aid":"http://arxiv.org/abs/2504.13161v1","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for\n  Language Model Pre-training","summary":"Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.13178v1","title":"Aligning Constraint Generation with Design Intent in Parametric CAD","summary":"We adapt alignment techniques from reasoning LLMs to the task of generating\nengineering sketch constraints found in computer-aided design (CAD) models.\nEngineering sketches consist of geometric primitives (e.g. points, lines)\nconnected by constraints (e.g. perpendicular, tangent) that define the\nrelationships between them. For a design to be easily editable, the constraints\nmust effectively capture design intent, ensuring the geometry updates\npredictably when parameters change. Although current approaches can generate\nCAD designs, an open challenge remains to align model outputs with design\nintent, we label this problem `design alignment'. A critical first step towards\naligning generative CAD models is to generate constraints which fully-constrain\nall geometric primitives, without over-constraining or distorting sketch\ngeometry. Using alignment techniques to train an existing constraint generation\nmodel with feedback from a constraint solver, we are able to fully-constrain\n93% of sketches compared to 34% when using a na\\\"ive supervised fine-tuning\n(SFT) baseline and only 8.9% without alignment. Our approach can be applied to\nany existing constraint generation model and sets the stage for further\nresearch bridging alignment strategies between the language and design domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:59:54Z"}
