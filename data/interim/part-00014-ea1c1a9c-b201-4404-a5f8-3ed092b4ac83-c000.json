{"aid":"http://arxiv.org/abs/2503.21661v1","title":"From conceptualization to operationalized meaning via ontological\n  components","summary":"Ontologies enable knowledge sharing and interdisciplinary collaboration by\nproviding standardized, structured vocabularies for diverse communities. While\nlogical axioms are a cornerstone of ontology design, natural language elements\nsuch as annotations are equally critical for conveying intended meaning and\nensuring consistent term usage. This paper explores how meaning is represented\nin ontologies and how it can be effectively represented and communicated,\naddressing challenges such as indeterminacy of reference and meaning holism. To\nthis end, it proposes an approach founded on the use of a new structure, named\n'ontological component' and defined by: a term-centered design; enhanced\ncharacterization of both formal and natural language statements; an\noperationalizable definition of communicated meaning based on general\nassertions; and the integration of natural language elements into the logical\ntheory. By formalizing the meaning of ontological components, this work seeks\nto enhance the semantic robustness of terms, improving their clarity and\naccessibility across domains. Furthermore, it aims to address practical\nchallenges in applied ontologies, such as facilitating reuse and managing\nversioning, thereby strengthening their role in diverse applications.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-27T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2503.21687v1","title":"Exploiting synergies between JWST and cosmic 21-cm observations to\n  uncover star formation in the early Universe","summary":"In the current era of JWST, we continue to uncover a wealth of information\nabout the Universe deep into the Epoch of Reionization. In this work, we run a\nsuite of simulations using the code 21cmSPACE, to explore the astrophysical\nproperties of galaxies in the early Universe, and their impact on high-redshift\nobservables. We use multi-wavelength observational data including the global\n21-cm signal and power spectrum limits from SARAS~3 and HERA respectively,\npresent-day diffuse X-ray and radio backgrounds, and UV luminosity functions\n(UVLFs) from HST and JWST in the range $z=6-14.5$ to derive our constraints. We\nconstrain a flexible model of halo-mass and redshift dependent star-formation\nefficiency (SFE), defined as the gas fraction converted into stars, and find\nthat it is best described by little to no redshift evolution at $z\\approx6-10$\nand rapid evolution at $z\\approx10-15$. We derive Bayesian functional posterior\ndistributions for the SFE across this redshift range, inferring that a halo of\nmass $M_h=10^{10}\\text{M}_\\odot$ has an efficiency of $2-3\\%$ at $z\\lesssim10$,\n$12\\%$ at $z=12$ and $26\\%$ at $z=15$. We also find, through synergy between\nSARAS~3 and UVLFs, that the minimum circular velocity for star-formation in\nhalos is $V_c = 16.9^{+25.7}_{-9.5}\\text{km s}^{-1}$ or equivalently\n$\\log_{10}(M_\\text{crit}/\\text{M}_\\odot) = 8.29^{+1.21}_{-1.08}$ at $z=6$.\nAlongside these star-formation constraints, we find the X-ray and radio\nefficiencies of early galaxies to be $f_X = 0.5^{+6.3}_{-0.3}$ and $f_r\n\\lesssim 11.7$ respectively, improving upon existing works that do not use UVLF\ndata. Our results demonstrate the critical role of UVLFs in constraining the\nearly Universe, and its synergies with 21-cm observations, alongside other\nmulti-wavelength observational datasets.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-27T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2503.21700v1","title":"Normalized solutions of one-dimensional defocusing NLS equations with\n  nonlinear point interactions","summary":"We investigate normalized solutions for doubly nonlinear Schr\\\"odinger\nequations on the real line with a defocusing standard nonlinearity and a\nfocusing nonlinear point interaction of $\\delta$--type at the origin. We\nprovide a complete characterization of existence and uniqueness for normalized\nsolutions and for energy ground states for every value of the nonlinearity\npowers. We show that the interplay between a defocusing standard and a focusing\npoint nonlinearity gives rise to new phenomena with respect to those observed\nwith single nonlinearities, standard combined nonlinearities, and combined\nfocusing standard and pointwise nonlinearities.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-03-27T17:04:43Z"}
{"aid":"http://arxiv.org/abs/2503.21704v1","title":"Learning to Represent Individual Differences for Choice Decision Making","summary":"Human decision making can be challenging to predict because decisions are\naffected by a number of complex factors. Adding to this complexity,\ndecision-making processes can differ considerably between individuals, and\nmethods aimed at predicting human decisions need to take individual differences\ninto account. Behavioral science offers methods by which to measure individual\ndifferences (e.g., questionnaires, behavioral models), but these are often\nnarrowed down to low dimensions and not tailored to specific prediction tasks.\nThis paper investigates the use of representation learning to measure\nindividual differences from behavioral experiment data. Representation learning\noffers a flexible approach to create individual embeddings from data that are\nboth structured (e.g., demographic information) and unstructured (e.g., free\ntext), where the flexibility provides more options for individual difference\nmeasures for personalization, e.g., free text responses may allow for\nopen-ended questions that are less privacy-sensitive. In the current paper we\nuse representation learning to characterize individual differences in human\nperformance on an economic decision-making task. We demonstrate that models\nusing representation learning to capture individual differences consistently\nimprove decision predictions over models without representation learning, and\neven outperform well-known theory-based behavioral models used in these\nenvironments. Our results propose that representation learning offers a useful\nand flexible tool to capture individual differences.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-27T17:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.21709v1","title":"Redefining Network Topology in Complex Systems: Merging Centrality\n  Metrics, Spectral Theory, and Diffusion Dynamics","summary":"This paper introduces a novel framework that combines traditional centrality\nmeasures with eigenvalue spectra and diffusion processes for a more\ncomprehensive analysis of complex networks. While centrality measures such as\ndegree, closeness, and betweenness have been commonly used to assess nodal\nimportance, they provide limited insight into dynamic network behaviors. By\nincorporating eigenvalue analysis, which evaluates network robustness and\nconnectivity through spectral properties, and diffusion processes that model\ninformation flow, this framework offers a deeper understanding of how networks\nfunction under dynamic conditions. Applied to synthetic networks, the approach\nidentifies key nodes not only by centrality but also by their role in diffusion\ndynamics and vulnerability points, offering a multi-dimensional view that\ntraditional methods alone cannot. This integrated analysis enables a more\nprecise identification of critical nodes and potential weaknesses, with\nimplications for improving network resilience in fields ranging from\nepidemiology to cybersecurity. Keywords: Centrality measures, eigenvalue\nspectra, diffusion processes, network analysis, network robustness, information\nflow, synthetic networks.","main_category":"cs.OH","categories":"cs.OH","published":"2025-03-27T17:21:46Z"}
{"aid":"http://arxiv.org/abs/2503.21721v1","title":"Evaluating Text-to-Image Synthesis with a Conditional FrÃ©chet\n  Distance","summary":"Evaluating text-to-image synthesis is challenging due to misalignment between\nestablished metrics and human preferences. We propose cFreD, a metric based on\nthe notion of Conditional Fr\\'echet Distance that explicitly accounts for both\nvisual fidelity and text-prompt alignment. Existing metrics such as Inception\nScore (IS), Fr\\'echet Inception Distance (FID) and CLIPScore assess either\nimage quality or image-text alignment but not both which limits their\ncorrelation with human preferences. Scoring models explicitly trained to\nreplicate human preferences require constant updates and may not generalize to\nnovel generation techniques or out-of-domain inputs. Through extensive\nexperiments across multiple recently proposed text-to-image models and diverse\nprompt datasets, we demonstrate that cFreD exhibits a higher correlation with\nhuman judgments compared to statistical metrics, including metrics trained with\nhuman preferences. Our findings validate cFreD as a robust, future-proof metric\nfor the systematic evaluation of text-to-image models, standardizing\nbenchmarking in this rapidly evolving field. We release our evaluation toolkit\nand benchmark in the appendix.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2503.21753v1","title":"Quantum enhanced parameter estimation with monitored quantum\n  nonequilibrium systems using inefficient photo detection","summary":"Many-body quantum systems hosting emergent collective behavior bear the\npromise to enable quantum enhanced parameter estimation. Formally this means\nthat the variance of the parameter to be estimated decreases faster than\n$N^{-1}$, where $N$ is the number of particles forming the quantum system. In\npractice such scaling is challenging to achieve as the underlying many-body\ncorrelations are fragile. Moreover, devising the optimal measurements that\nindeed tap the quantum enhancement is often rather involved. Here we show that\nthe inefficient detection of the photo emission from a dissipative quantum\nmany-body system is sufficient to reach quantum enhanced parameter estimation\neven when some loss channels remain completely unmonitored. We illustrate our\napproach by considering the so-called boundary time-crystal, which is a\nnonequilibrium many-body system that has been realized recently experimentally\nin cold atomic gases. By analyzing the structure of the temporal correlations\nof its emission field, we are able to construct a family of near optimal\nparameter estimation measurements with a simple interferometric setup.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2503.21755v1","title":"VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic\n  Faithfulness","summary":"Video generation has advanced significantly, evolving from producing\nunrealistic outputs to generating videos that appear visually convincing and\ntemporally coherent. To evaluate these video generative models, benchmarks such\nas VBench have been developed to assess their faithfulness, measuring factors\nlike per-frame aesthetics, temporal consistency, and basic prompt adherence.\nHowever, these aspects mainly represent superficial faithfulness, which focus\non whether the video appears visually convincing rather than whether it adheres\nto real-world principles. While recent models perform increasingly well on\nthese metrics, they still struggle to generate videos that are not just\nvisually plausible but fundamentally realistic. To achieve real \"world models\"\nthrough video generation, the next frontier lies in intrinsic faithfulness to\nensure that generated videos adhere to physical laws, commonsense reasoning,\nanatomical correctness, and compositional integrity. Achieving this level of\nrealism is essential for applications such as AI-assisted filmmaking and\nsimulated world modeling. To bridge this gap, we introduce VBench-2.0, a\nnext-generation benchmark designed to automatically evaluate video generative\nmodels for their intrinsic faithfulness. VBench-2.0 assesses five key\ndimensions: Human Fidelity, Controllability, Creativity, Physics, and\nCommonsense, each further broken down into fine-grained capabilities. Tailored\nfor individual dimensions, our evaluation framework integrates generalists such\nas state-of-the-art VLMs and LLMs, and specialists, including anomaly detection\nmethods proposed for video generation. We conduct extensive annotations to\nensure alignment with human judgment. By pushing beyond superficial\nfaithfulness toward intrinsic faithfulness, VBench-2.0 aims to set a new\nstandard for the next generation of video generative models in pursuit of\nintrinsic faithfulness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2503.21763v1","title":"Identification and estimation of treatment effects in a linear factor\n  model with fixed number of time periods","summary":"This paper provides a new approach for identifying and estimating the Average\nTreatment Effect on the Treated under a linear factor model that allows for\nmultiple time-varying unobservables. Unlike the majority of the literature on\ntreatment effects in linear factor models, our approach does not require the\nnumber of pre-treatment periods to go to infinity to obtain a valid estimator.\nOur identification approach employs a certain nonlinear transformations of the\ntime invariant observed covariates that are sufficiently correlated with the\nunobserved variables. This relevance condition can be checked with the\navailable data on pre-treatment periods by validating the correlation of the\ntransformed covariates and the pre-treatment outcomes. Based on our\nidentification approach, we provide an asymptotically unbiased estimator of the\neffect of participating in the treatment when there is only one treated unit\nand the number of control units is large.","main_category":"econ.EM","categories":"econ.EM","published":"2025-03-27T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2503.21771v1","title":"A Unified Image-Dense Annotation Generation Model for Underwater Scenes","summary":"Underwater dense prediction, especially depth estimation and semantic\nsegmentation, is crucial for gaining a comprehensive understanding of\nunderwater scenes. Nevertheless, high-quality and large-scale underwater\ndatasets with dense annotations remain scarce because of the complex\nenvironment and the exorbitant data collection costs. This paper proposes a\nunified Text-to-Image and DEnse annotation generation method (TIDE) for\nunderwater scenes. It relies solely on text as input to simultaneously generate\nrealistic underwater images and multiple highly consistent dense annotations.\nSpecifically, we unify the generation of text-to-image and text-to-dense\nannotations within a single model. The Implicit Layout Sharing mechanism (ILS)\nand cross-modal interaction method called Time Adaptive Normalization (TAN) are\nintroduced to jointly optimize the consistency between image and dense\nannotations. We synthesize a large-scale underwater dataset using TIDE to\nvalidate the effectiveness of our method in underwater dense prediction tasks.\nThe results demonstrate that our method effectively improves the performance of\nexisting underwater dense prediction models and mitigates the scarcity of\nunderwater data with dense annotations. We hope our method can offer new\nperspectives on alleviating data scarcity issues in other fields. The code is\navailable at https: //github.com/HongkLin/TIDE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2503.21773v1","title":"Simulating quantum circuits with restricted quantum computers","summary":"It is one of the most fundamental objectives in quantum information science\nto understand the boundary between the computational power of classical and\nquantum computers. One possible avenue to explore this boundary is to identify\nclasses of quantum circuits that can be efficiently simulated on a classical\ncomputer. Instead of simulating a general quantum circuit with a classical\ndevice, new schemes have recently emerged to simulate them on a quantum device\nthat is restricted in some manner. As such, these techniques allow us to study\nhow the restrictions impact the computational power of the device. One such\ntechnique is called quasiprobability simulation (QPS) and it estimates the\nresult of a quantum circuit with a Monte Carlo procedure that randomly replaces\ncircuit elements with ones that can be executed on the restricted quantum\ndevice.\n  The main focus of this thesis is dedicated to the QPS-based simulation of\nnonlocal quantum computation using local quantum operations. On the practical\nside, this enables the simulation of large quantum circuits using multiple\nsmaller quantum devices - a procedure that is sometimes called circuit\nknitting. We uncover a rich mathematical formalism with many connections to the\nresource theory of entanglement. We characterize the optimal simulation\noverhead for a broad range of practically relevant nonlocal states and channels\nand we explicitly provide achieving protocols. Moreover, we also investigate\nthe utility of classical communication between the local parties. Our results\naddress both the single-shot and asymptotic regime.\n  We frame QPS in a quantum resource theoretic framework, which highlights\nsimilarities that arise in the different instantiations of the technique.\nFurthermore, we study the importance of classical side information in the QPS\nprocedure and how it impacts the overhead and expressibility of QPS.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2503.21776v1","title":"Video-R1: Reinforcing Video Reasoning in MLLMs","summary":"Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for eliciting video reasoning\nwithin multimodal large language models (MLLMs). However, directly applying RL\ntraining with the GRPO algorithm to video reasoning presents two primary\nchallenges: (i) a lack of temporal modeling for video reasoning, and (ii) the\nscarcity of high-quality video-reasoning data. To address these issues, we\nfirst propose the T-GRPO algorithm, which encourages models to utilize temporal\ninformation in videos for reasoning. Additionally, instead of relying solely on\nvideo data, we incorporate high-quality image-reasoning data into the training\nprocess. We have constructed two datasets: Video-R1-COT-165k for SFT cold start\nand Video-R1-260k for RL training, both comprising image and video data.\nExperimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncodes, models, data are released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.23710v1","title":"Formation of the Little Red Dots from the Core-collapse of\n  Self-interacting Dark Matter Halos","summary":"We present a statistical study on the formation and growth of black holes\n(BHs) seeded by gravothermal core-collapse of self-interacting dark matter\n(SIDM) halos at high redshifts, using a semi-analytical framework based on\nMonte-Carlo merger trees. We demonstrate that BH formation via gravothermal\ncollapse naturally occurs in high-concentration halos at a characteristic mass\nscale determined by the SIDM cross section, and only during the early Universe.\nThis mechanism is particularly promising for explaining the abundance of little\nred dots (LRDs) -- a population of early, apparently galaxy-less active\ngalactic nuclei hosting supermassive BHs. By incorporating this seeding process\nwith simplified models of BH growth and mergers, we successfully reproduce the\nobserved LRD mass function for moderately large cross sections of $\\sigma_{0m}\n\\sim 30 \\mathrm{cm^2\\,g^{-1}}$ and $\\omega \\sim 80\\,\\mathrm{km\\,s^{-1}}$,\nintriguingly consistent with independent local constraints derived from galaxy\nrotation curves. Our results highlight the potential of high-redshift BH\nstatistics as a complementary probe for constraining SIDM models.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-31T04:15:20Z"}
{"aid":"http://arxiv.org/abs/2503.23741v1","title":"Classification of Modular Symmetries in Non-Supersymmetric Heterotic\n  String theories","summary":"We study modular symmetries in non-supersymmetric heterotic string theories\non toroidal backgrounds with Wilson line modulus, constructed by stringy\nScherk-Schwartz compactification. In particular, we focus on a subgroup of the\nT-duality group $O(D+16,D,\\mathbb{Z})$ with $D=2$ given by an outer\nautomorphism of the Narain lattice, which can be mapped to the Siegel modular\ngroup $\\mathrm{Sp}(4,\\mathbb{Z})$. We classify the modular symmetries and a\n$CP$-like symmetry on $T^2$ and its orbifolds with symmetric and asymmetric\norbifold twists. It turns out that the non-supersymmetric heterotic string\ntheories only enjoy a part of modular symmetries in contrast to supersymmetric\nones. Furthermore, the gauge symmetry is maximally enhanced at fixed points of\nmodular symmetries on $T^2$ on which we analyze the vacuum structure of\neight-dimensional tachyon-free vacua.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T05:42:06Z"}
{"aid":"http://arxiv.org/abs/2503.23751v1","title":"Decoupled Distillation to Erase: A General Unlearning Method for Any\n  Class-centric Tasks","summary":"In this work, we present DEcoupLEd Distillation To Erase (DELETE), a general\nand strong unlearning method for any class-centric tasks. To derive this, we\nfirst propose a theoretical framework to analyze the general form of unlearning\nloss and decompose it into forgetting and retention terms. Through the\ntheoretical framework, we point out that a class of previous methods could be\nmainly formulated as a loss that implicitly optimizes the forgetting term while\nlacking supervision for the retention term, disturbing the distribution of\npre-trained model and struggling to adequately preserve knowledge of the\nremaining classes. To address it, we refine the retention term using \"dark\nknowledge\" and propose a mask distillation unlearning method. By applying a\nmask to separate forgetting logits from retention logits, our approach\noptimizes both the forgetting and refined retention components simultaneously,\nretaining knowledge of the remaining classes while ensuring thorough forgetting\nof the target class. Without access to the remaining data or intervention\n(i.e., used in some works), we achieve state-of-the-art performance across\nvarious benchmarks. What's more, DELETE is a general solution that can be\napplied to various downstream tasks, including face recognition, backdoor\ndefense, and semantic segmentation with great performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:02:27Z"}
{"aid":"http://arxiv.org/abs/2503.23775v1","title":"Evaluation of (Un-)Supervised Machine Learning Methods for GNSS\n  Interference Classification with Real-World Data Discrepancies","summary":"The accuracy and reliability of vehicle localization on roads are crucial for\napplications such as self-driving cars, toll systems, and digital tachographs.\nTo achieve accurate positioning, vehicles typically use global navigation\nsatellite system (GNSS) receivers to validate their absolute positions.\nHowever, GNSS-based positioning can be compromised by interference signals,\nnecessitating the identification, classification, determination of purpose, and\nlocalization of such interference to mitigate or eliminate it. Recent\napproaches based on machine learning (ML) have shown superior performance in\nmonitoring interference. However, their feasibility in real-world applications\nand environments has yet to be assessed. Effective implementation of ML\ntechniques requires training datasets that incorporate realistic interference\nsignals, including real-world noise and potential multipath effects that may\noccur between transmitter, receiver, and satellite in the operational area.\nAdditionally, these datasets require reference labels. Creating such datasets\nis often challenging due to legal restrictions, as causing interference to GNSS\nsources is strictly prohibited. Consequently, the performance of ML-based\nmethods in practical applications remains unclear. To address this gap, we\ndescribe a series of large-scale measurement campaigns conducted in real-world\nsettings at two highway locations in Germany and the Seetal Alps in Austria,\nand in large-scale controlled indoor environments. We evaluate the latest\nsupervised ML-based methods to report on their performance in real-world\nsettings and present the applicability of pseudo-labeling for unsupervised\nlearning. We demonstrate the challenges of combining datasets due to data\ndiscrepancies and evaluate outlier detection, domain adaptation, and data\naugmentation techniques to present the models' capabilities to adapt to changes\nin the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T06:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.23797v1","title":"Kiloparsec-Scale Alignment of a Radio Jet with Cool Gas and Dust in a\n  z~6 Quasar","summary":"We present high-angular resolution (0.068\", ~400pc) ALMA imaging of the [CII]\nline and dust continuum emission of PSO J352.4034-15.3373, a radio-loud quasar\nat z=5.83. The observations reveal a remarkably close match between the\norientation of the [CII] and thermal dust emission mapped by ALMA, and radio\nsynchrotron emission of a radio jet previously mapped by the VLBA. This narrow\nalignment extends over ~4kpc, reminiscent of the well-studied 'alignment\neffect' in lower-redshift radio galaxies. The [CII] kinematics show a linear\nincrease in velocity with galactocentric radii up to ~200 km/s at r=2kpc,\nconsistent with bulk motions within the galaxy potential, and not relativistic\njet motions. The kinematics and respective morphologies are consistent with a\npicture in which the relativistic jet injects energy into the interstellar\nmedium (potentially leading to subsequent star formation), giving rise to the\nobserved alignment and significant (> 100 km/s) [CII] velocity dispersion\nwithin the host galaxy on kiloparsec scales. Indeed, the astonishingly close\nalignment and narrow linearity of the radio jet with the [CII] and dust\nemission are hard to conceive without some fundamental relationship between the\ntwo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T07:19:54Z"}
{"aid":"http://arxiv.org/abs/2503.23804v1","title":"Get the Agents Drunk: Memory Perturbations in Autonomous Agent-based\n  Recommender Systems","summary":"Large language model-based agents are increasingly used in recommender\nsystems (Agent4RSs) to achieve personalized behavior modeling. Specifically,\nAgent4RSs introduces memory mechanisms that enable the agents to autonomously\nlearn and self-evolve from real-world interactions. However, to the best of our\nknowledge, how robust Agent4RSs are remains unexplored. As such, in this paper,\nwe propose the first work to attack Agent4RSs by perturbing agents' memories,\nnot only to uncover their limitations but also to enhance their security and\nrobustness, ensuring the development of safer and more reliable AI agents.\n  Given the security and privacy concerns, it is more practical to launch\nattacks under a black-box setting, where the accurate knowledge of the victim\nmodels cannot be easily obtained. Moreover, the practical attacks are often\nstealthy to maximize the impact. To this end, we propose a novel practical\nattack framework named DrunkAgent. DrunkAgent consists of a generation module,\na strategy module, and a surrogate module. The generation module aims to\nproduce effective and coherent adversarial textual triggers, which can be used\nto achieve attack objectives such as promoting the target items. The strategy\nmodule is designed to `get the target agents drunk' so that their memories\ncannot be effectively updated during the interaction process. As such, the\ntriggers can play the best role. Both of the modules are optimized on the\nsurrogate module to improve the transferability and imperceptibility of the\nattacks. By identifying and analyzing the vulnerabilities, our work provides\ncritical insights that pave the way for building safer and more resilient\nAgent4RSs. Extensive experiments across various real-world datasets demonstrate\nthe effectiveness of DrunkAgent.","main_category":"cs.CR","categories":"cs.CR,cs.CL,cs.IR,cs.MA","published":"2025-03-31T07:35:40Z"}
{"aid":"http://arxiv.org/abs/2503.23818v1","title":"Free Parametrization of L2-bounded State Space Models","summary":"Structured state-space models (SSMs) have emerged as a powerful architecture\nin machine learning and control, featuring stacked layers where each consists\nof a linear time-invariant (LTI) discrete-time system followed by a\nnonlinearity. While SSMs offer computational efficiency and excel in\nlong-sequence predictions, their widespread adoption in applications like\nsystem identification and optimal control is hindered by the challenge of\nensuring their stability and robustness properties. We introduce L2RU, a novel\nparametrization of SSMs that guarantees input-output stability and robustness\nby enforcing a prescribed L-bound for all parameter values. This design\neliminates the need for complex constraints, allowing unconstrained\noptimization over L2RUs by using standard methods such as gradient descent.\nLeveraging tools from system theory and convex optimization, we derive a\nnon-conservative parametrization of square discrete-time LTI systems with a\nspecified L2-bound, forming the foundation of the L2RU architecture.\nAdditionally, we enhance its performance with a bespoke initialization strategy\noptimized for long input sequences. Through a system identification task, we\nvalidate L2RU's superior performance, showcasing its potential in learning and\ncontrol applications.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-03-31T07:56:17Z"}
{"aid":"http://arxiv.org/abs/2503.23838v1","title":"A MeerKAT survey of nearby dwarf novae: I. New detections","summary":"A program to search for radio emission from dwarf-novae-type cataclysmic\nvariables was conducted with the South African MeerKAT radio telescope. The\ndwarf novae RU Pegasi, V426 Ophiuchi and IP Pegasi were detected during\noutburst at L-band (1284 MHz central frequency). Previously, only one\ncataclysmic variable was radio-detected at a frequency this low. We now bring\nthe number to four. With these three newly found radio-emitters, the population\nof dwarf novae confirmed to be radio-emitting at any frequency reaches 10\nsystems. We found that the radio luminosity is correlated with the optical\nluminosity. For V426 Ophiuchi and RU Pegasi we found a radio decline\ncontemporary with the outburst's optical decline. The peak radio luminosity of\ndwarf novae in outburst is very similar to that of novalike Cataclysmic\nVariables and no correlation with orbital period is seen.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23845v1","title":"On the depth of subgroups of simple groups","summary":"The depth of a subgroup $H$ of a finite group $G$ is a positive integer\ndefined with respect to the inclusion of the corresponding complex group\nalgebras $\\mathbb{C}H \\subseteq \\mathbb{C}G$. This notion was originally\nintroduced by Boltje, Danz and K\\\"{u}lshammer in 2011, and it has been the\nsubject of numerous papers in recent years. In this paper, we study the depth\nof core-free subgroups, which allows us to apply powerful computational and\nprobabilistic techniques that were originally designed for studying bases for\npermutation groups. We use these methods to prove a wide range of new results\non the depth of subgroups of almost simple groups, significantly extending the\nscope of earlier work in this direction. For example, we establish best\npossible bounds on the depth of irreducible subgroups of classical groups and\nprimitive subgroups of symmetric groups. And with the exception of a handful of\nopen cases involving the Baby Monster, we calculate the exact depth of every\nsubgroup of every almost simple sporadic group. We also present a number of\nopen problems and conjectures.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-03-31T08:46:46Z"}
{"aid":"http://arxiv.org/abs/2503.23846v1","title":"Exchange cross-talk mitigation in dense quantum dot arrays","summary":"Coupled spins in semiconductor quantum dots are a versatile platform for\nquantum computing and simulations of complex many-body phenomena. However, on\nthe path of scale-up, cross-talk from densely packed electrodes poses a severe\nchallenge. While cross-talk onto the dot potentials is nowadays routinely\ncompensated for, cross-talk on the exchange interaction is much more difficult\nto tackle because it is not always directly measurable. Here we propose and\nimplement a way of characterizing and compensating cross-talk on adjacent\nexchange interactions by following the singlet-triplet avoided crossing in Ge.\nWe show that we can easily identify the barrier-to-barrier cross-talk element\nwithout knowledge of the particular exchange value in a 2x4 quantum dot array.\nWe uncover striking differences among these cross-talk elements which can be\nlinked to the geometry of the device and the barrier gate fan-out. We validate\nthe methodology by tuning up four-spin Heisenberg chains. The same methodology\nshould be applicable to longer chains of spins and to other semiconductor\nplatforms in which mixing of the singlet and the lowest-energy triplet is\npresent or can be engineered. Additionally, this procedure is well suited for\nautomated tuning routines as we obtain a stand-out feature that can be easily\ntracked and directly returns the magnitude of the cross-talk.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T08:50:43Z"}
{"aid":"http://arxiv.org/abs/2503.23852v1","title":"Multispacecraft Observations of the 2024 September 9 Backside Solar\n  Eruption that Resulted in a Sustained Gamma Ray Emission Event","summary":"We report on the 2024 September 9 sustained gamma ray emission (SGRE) event\nobserved by the Large Area Telescope onboard the Fermi satellite. The event was\nassociated with a backside solar eruption observed by multiple spacecraft such\nas the Solar and Heliospheric Observatory (SOHO), Solar Terrestrial Relations\nObservatory (STEREO), Parker Solar Probe (PSP), Solar Orbiter (SolO), Solar\nDynamics Observatory (SDO), Wind, and GOES, and by ground based radio\ntelescopes. SolO Spectrometer Telescope for Imaging X rays (STIX) imaged an\nintense flare, which occurred about 41 deg behind the east limb, from\nheliographic coordinates S13E131. Forward modeling of the CME flux rope\nrevealed that it impulsively accelerated (3.54 km s^{-2}) to attain a peak\nspeed of 2162 km s^{-1}. SolO energetic particle detectors (EPD) observed\nprotons up to about 1 GeV from the extended shock and electrons that produced a\ncomplex type II burst and possibly type III bursts. The durations of SGRE and\ntype II burst are consistent with the linear relation between these quantities\nobtained from longer duration (exceeding 3 hours) SGRE events. All these\nobservations are consistent with an extended shock surrounding the CME flux\nrope, which is the likely source of high energy protons required for the SGRE\nevent. We compare this event with six other BTL SGRE eruptions and find that\nthey are all consistent with energetic shock driving CMEs. We also find a\nsignificant east west asymmetry in the BTL source locations.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23855v1","title":"Physics case for low-$\\sqrt{s}$ QCD studies at FCC-ee","summary":"Measurements of hadronic final states in $e^{+}e^{-}$ collisions at\ncentre-of-mass (CM) energies below the Z peak can notably extend the FCC-ee\nphysics reach in terms of precision quantum chromodynamics (QCD) studies.\nHadronic final states can be studied over a range of hadronic energies\n$\\sqrt{s_\\mathrm{had}} \\approx 20\\mbox{--}80\\,\\mathrm{GeV}$ by exploiting\nevents with hard initial- and final-state QED radiation (ISR/FSR) during the\nhigh-luminosity Z-pole run, as well as in dedicated short (about one month\nlong) $e^{+}e^{-}$ runs at CM energies $\\sqrt{s} \\approx 40\\,\\mathrm{GeV}$ and\n$60\\,\\mathrm{GeV}$. Using realistic estimates and fast detector simulations, we\nshow that data samples of about $10^{9}$ hadronic events can be collected at\nthe FCC-ee at each of the low-CM-energy points. Such datasets can be exploited\nin a variety of precision QCD measurements, including studies of light-,\nheavy-quark and gluon jet properties, hadronic event shapes, fragmentation\nfunctions, and nonperturbative dynamics. This will offer valuable insights into\nstrong interaction physics, complementing data from nominal FCC-ee runs at\nhigher center-of-mass energies, $\\sqrt{s} \\approx 91, 160, 240,$ and\n$365\\,\\mathrm{GeV}$.","main_category":"hep-ex","categories":"hep-ex,hep-ph,hep-th","published":"2025-03-31T09:03:46Z"}
{"aid":"http://arxiv.org/abs/2503.23874v1","title":"He-Mg compounds and helium-driven nonmetal transition in metallic\n  magnesium","summary":"The polymorphism and mechanism of helium compounds is crucial for\nunderstanding the physical and chemical nature of He-bearing materials under\npressures. Here, we predict two new types of He-bearing compounds, MgHe and\nMgnHe (n = 6, 8, 10, 15, 18), being formed above 750 GPa by unbiased ab initio\nstructure search. An unexpected bandgap is opened up in MgHe at as low as\naround 200 GPa. This is the first case of noble gas driven metal-nonmetal\ntransition in all elements. The same mechanism is demonstrated also being\napplicable to other metallic elements, and making beryllium transform into a\nnon-metallic state, a triumph that is impossible otherwise. Furthermore, the\nstability of the simple cubic phase of Mg (Mg-sc) is greatly enhanced by mixing\nwith He, which lowers the critical pressure of pure Mg-sc from about 1.1 TPa\ndown to 750 GPa to form ordered substitutional alloying phase of MgnHe on a\nsimple cubic lattice of Mg. This is the first report on Mg-based noble gas\nsubstitutional alloy, in sharp contrast to the conventional wisdom that He\npreferring interstitial sites. The observed striking influences of He\ndemonstrate the rich physics and chemistry of He-bearing compounds under\nultra-high pressures.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,physics.chem-ph,physics.comp-ph","published":"2025-03-31T09:25:09Z"}
{"aid":"http://arxiv.org/abs/2503.23893v1","title":"DiffScale: Continuous Downscaling and Bias Correction of Subseasonal\n  Wind Speed Forecasts using Diffusion Models","summary":"Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,eess.IV","published":"2025-03-31T09:44:28Z"}
{"aid":"http://arxiv.org/abs/2503.23898v1","title":"An Explainable Neural Radiomic Sequence Model with Spatiotemporal\n  Continuity for Quantifying 4DCT-based Pulmonary Ventilation","summary":"Accurate evaluation of regional lung ventilation is essential for the\nmanagement and treatment of lung cancer patients, supporting assessments of\npulmonary function, optimization of therapeutic strategies, and monitoring of\ntreatment response. Currently, ventilation scintigraphy using nuclear medicine\ntechniques is widely employed in clinical practice; however, it is often\ntime-consuming, costly, and entails additional radiation exposure. In this\nstudy, we propose an explainable neural radiomic sequence model to identify\nregions of compromised pulmonary ventilation based on four-dimensional computed\ntomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset\nwas analyzed. For each patient, lung volumes were segmented from 4DCT, and\nvoxel-wise radiomic features (56-dimensional) were extracted across the\nrespiratory cycle to capture local intensity and texture dynamics, forming\ntemporal radiomic sequences. Ground truth ventilation defects were delineated\nvoxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions,\nwe developed a temporal saliency-enhanced explainable long short-term memory\n(LSTM) network trained on the radiomic sequences. Temporal saliency maps were\ngenerated to highlight key features contributing to the model's predictions.\nThe proposed model demonstrated robust performance, achieving average (range)\nDice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78\n(0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key\nradiomic sequences in ventilation quantification: during lung exhalation,\ncompromised pulmonary function region typically exhibits (1) an increasing\ntrend of intensity and (2) a decreasing trend of homogeneity, in contrast to\nhealthy lung tissue.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-03-31T09:47:03Z"}
{"aid":"http://arxiv.org/abs/2503.23903v1","title":"Privacy Preservation for Statistical Input in Dynamical Systems","summary":"This paper addresses the challenge of privacy preservation for statistical\ninputs in dynamical systems. Motivated by an autonomous building application,\nwe formulate a privacy preservation problem for statistical inputs in linear\ntime-invariant systems. What makes this problem widely applicable is that the\ninputs, rather than being assumed to be deterministic, follow a probability\ndistribution, inherently embedding privacy-sensitive information that requires\nprotection. This formulation also presents a technical challenge as\nconventional differential privacy mechanisms are not directly applicable.\nThrough rigorous analysis, we develop strategy to achieve $(0, \\delta)$\ndifferential privacy through adding noise. Finally, the effectiveness of our\nmethods is demonstrated by revisiting the autonomous building application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:54:09Z"}
{"aid":"http://arxiv.org/abs/2503.23906v1","title":"Topologizability and related properties of the iterates of composition\n  operators in Gelfand-Shilov classes","summary":"We analyse the behaviour of the iterates of composition operators defined by\npolynomials acting on global classes of ultradifferentiable functions of\nBeurling type which are invariant under the Fourier transform. In particular,\nwe determine the polynomials $\\psi$ for which the sequence of iterates of the\ncomposition operator $C_\\psi$ is topologizable (m-topologizable) acting on\ncertain Gelfand-Shilov spaces defined by mean of Braun-Meise-Taylor weights. We\nprove that the composition operators $C_\\psi$ with $\\psi$ a polynomial of\ndegree greater than one are always topologizable in certain settings involving\nGelfand-Shilov spaces, just like in the Schwartz space. Unlike in the Schwartz\nspace setting, composition operators $C_\\psi$ associated with polynomials\n$\\psi$ are not always $m-$topologizable. We also deal with the composition\noperators $C_\\psi$ with $\\psi$ being an affine function acting on\n$\\mathcal{S}_{\\omega}(\\mathbb{R})$ and find a complete characterization of\ntopologizability and m-topologizability","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-03-31T09:57:29Z"}
{"aid":"http://arxiv.org/abs/2503.23934v1","title":"Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in\n  Discriminative and Generative AI Operations","summary":"This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T10:28:04Z"}
{"aid":"http://arxiv.org/abs/2503.23967v1","title":"Note on $q=2$ paraparticle SYK model","summary":"We investigate the $q=2$ SYK model with paraparticles (PSYK$_2$), analyzing\nits thermodynamics and spectral form factor (SFF) using random matrix theory.\nThe Hamiltonian is quadratic, with coupling coefficients randomly drawn from\nthe Gaussian Unitary Ensemble (GUE). The model exhibits self-averaging behavior\nand shows a striking transition in SFF dynamics: while the fermionic SYK$_2$\ndisplays a ramp behavior $\\mathcal{K}(t) \\sim e^{C_0 t}$ with $C_0 \\sim \\ln N$,\nthe paraparticle cases exhibit $C_0 \\sim \\mathcal{O}(1)$. These findings offer\nnew insights into quantum systems with exotic statistics.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T11:32:06Z"}
{"aid":"http://arxiv.org/abs/2503.24000v1","title":"Rethinking Key-Value Cache Compression Techniques for Large Language\n  Model Serving","summary":"Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:23:31Z"}
{"aid":"http://arxiv.org/abs/2503.24003v1","title":"A Robust Extrinsic Single-index Model for Spherical Data","summary":"Regression with a spherical response is challenging due to the absence of\nlinear structure, making standard regression models inadequate. Existing\nmethods, mainly parametric, lack the flexibility to capture the complex\nrelationship induced by spherical curvature, while methods based on techniques\nfrom Riemannian geometry often suffer from computational difficulties. The\nnon-Euclidean structure further complicates robust estimation, with very\nlimited work addressing this issue, despite the common presence of outliers in\ndirectional data. This article introduces a new semi-parametric approach, the\nextrinsic single-index model (ESIM) and its robust estimation, to address these\nlimitations. We establish large-sample properties of the proposed estimator\nwith a wide range of loss functions and assess their robustness using the\ninfluence function and standardized influence function. Specifically, we focus\non the robustness of the exponential squared loss (ESL), demonstrating\ncomparable efficiency and superior robustness over least squares loss under\nhigh concentration. We also examine how the tuning parameter for the ESL\nbalances efficiency and robustness, providing guidance on its optimal choice.\nThe computational efficiency and robustness of our methods are further\nillustrated via simulations and applications to geochemical compositional data.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T12:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.24089v1","title":"Initial State Privacy of Nonlinear Systems on Riemannian Manifolds","summary":"In this paper, we investigate initial state privacy protection for\ndiscrete-time nonlinear closed systems. By capturing Riemannian geometric\nstructures inherent in such privacy challenges, we refine the concept of\ndifferential privacy through the introduction of an initial state adjacency set\nbased on Riemannian distances. A new differential privacy condition is\nformulated using incremental output boundedness, enabling the design of\ntime-varying Laplacian noise to achieve specified privacy guarantees. The\nproposed framework extends beyond initial state protection to also cover system\nparameter privacy, which is demonstrated as a special application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2503.24096v1","title":"DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description","summary":"Audio Description is a narrated commentary designed to aid vision-impaired\naudiences in perceiving key visual elements in a video. While short-form video\nunderstanding has advanced rapidly, a solution for maintaining coherent\nlong-term visual storytelling remains unresolved. Existing methods rely solely\non frame-level embeddings, effectively describing object-based content but\nlacking contextual information across scenes. We introduce DANTE-AD, an\nenhanced video description model leveraging a dual-vision Transformer-based\narchitecture to address this gap. DANTE-AD sequentially fuses both frame and\nscene level embeddings to improve long-term contextual understanding. We\npropose a novel, state-of-the-art method for sequential cross-attention to\nachieve contextual grounding for fine-grained audio description generation.\nEvaluated on a broad range of key scenes from well-known movie clips, DANTE-AD\noutperforms existing methods across traditional NLP metrics and LLM-based\nevaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:49:43Z"}
{"aid":"http://arxiv.org/abs/2503.24112v1","title":"Characterization of norm and quasi-norm forms in S-adic setting","summary":"The goal of the present paper is to characterize the norm and quasi-norm\nforms defined over an arbitrary number field F in terms of their values at the\nS-integer points, where S is a finite set of valuations of F containing the\narchimedean ones. In this way we generalize the main result of the recent paper\n[T5], where the notion of a quasi-norm form is introduced when F = Q and S is a\nsingleton. In complement, we exhibit some relations with problems and results\nin this area of research.","main_category":"math.NT","categories":"math.NT","published":"2025-03-31T14:04:51Z"}
{"aid":"http://arxiv.org/abs/2503.24127v1","title":"Compression Metadata-assisted RoI Extraction and Adaptive Inference for\n  Efficient Video Analytics","summary":"Video analytics demand substantial computing resources, posing significant\nchallenges in computing resource-constrained environment. In this paper, to\nachieve high accuracy with acceptable computational workload, we propose a\ncost-effective regions of interest (RoIs) extraction and adaptive inference\nscheme based on the informative encoding metadata. Specifically, to achieve\nefficient RoI-based analytics, we explore motion vectors from encoding metadata\nto identify RoIs in non-reference frames through morphological opening\noperation. Furthermore, considering the content variation of RoIs, which calls\nfor inference by models with distinct size, we measure RoI complexity based on\nthe bitrate allocation information from encoding metadata. Finally, we design\nan algorithm that prioritizes scheduling RoIs to models of the appropriate\ncomplexity, balancing accuracy and latency. Extensive experimental results show\nthat our proposed scheme reduces latency by nearly 40% and improves 2.2% on\naverage in accuracy, outperforming the latest benchmarks.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:12:02Z"}
{"aid":"http://arxiv.org/abs/2503.24137v1","title":"Half-life and precision shape measurement of 2Î½Î²Î² decay\n  of $^{130}$Te","summary":"We present a new measurement of the 2nbb half-life of 130Te (T1/2) using the\nfirst complete model of the CUORE data, based on 1038 kg yr of collected\nexposure. Thanks to optimized data selection, we achieve a factor of two\nimprovement in precision, obtaining T1/2 = (9.32 +0.05 -0.04 (stat.) +0.07\n-0.07 (syst.)) x10^20 yr. The signal-to-background ratio is increased by 70%\ncompared to our previous results, enabling the first application of the\nimproved 2nbb formalism to 130Te. Within this framework, we determine a\ncredibility interval for the effective axial coupling in the nuclear medium as\na function of nuclear matrix elements. We also extract values for the\nhigher-order nuclear matrix element ratios: second-to-first and third-to-first.\nThe second-to-first ratio agrees with nuclear model predictions, while the\nthird-to-first ratio deviates from theoretical expectations. These findings\nprovide essential tests of nuclear models and key inputs for future 0nbb\nsearches.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:19:33Z"}
{"aid":"http://arxiv.org/abs/2503.24163v1","title":"First-principles design of stable spin qubits in monolayer MoS2 with\n  elemental defect engineering","summary":"Quantum information science (QIS), encompassing technologies such as quantum\ncomputing, sensing, and communication, relies on the development and\nmanipulation of quantum bits (qubits). Recently, two-dimensional (2D) materials\n- characterized by their atomic thinness and external controllability - have\nemerged as promising candidates for qubit fabrication and manipulation at room\ntemperature. In this study, we propose that antisite defects (MX) in 2D\ntransition metal disulfides (TMDs) can serve as tunable quantum defects with\ncontrolled positioning. Using first-principles atomic structure simulations, we\nidentify six thermodynamically stable neutral antisite defects (MX, where M =\nMg, Ca, Sr, Ba, Zn, Cd; X = S) in monolayer 1H-MoS2. These defects exhibit\npotential as spin-defected qubits with stable triplet ground states.\nAdditionally, we demonstrate that the reduction of the bandgap leads to\nsignificant fluctuations in the absorption coefficient within the low-energy\nrange, resulting in the optical response within the desired telecommunication\nband, which is advantageous for quantum communication applications. The\nzero-phonon line (ZPL) associated with these qubits can serve as an effective\nidentifier. This work presents the novel, tunable approach to exploiting\ndefects in 2D materials, opening new possibilities for the development of qubit\nplatforms in quantum information technology.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-03-31T14:46:16Z"}
{"aid":"http://arxiv.org/abs/2503.24197v1","title":"Asymptotically distribution-free goodness-of-fit testing for point\n  processes","summary":"Consider an observation of a multivariate temporal point process $N$ with law\n$\\mathcal P$ on the time interval $[0,T]$. To test the null hypothesis that\n$\\mathcal P$ belongs to a given parametric family, we construct a convergent\ncompensated counting process to which we apply an innovation martingale\ntransformation. We prove that the resulting process converges weakly to a\nstandard Wiener process. Consequently, taking a suitable functional of this\nprocess yields an asymptotically distribution-free goodness-of-fit test for\npoint processes. For several standard tests based on the increments of this\ntransformed process, we establish consistency under alternative hypotheses.\nFinally, we assess the performance of the proposed testing procedure through a\nMonte Carlo simulation study and illustrate its practical utility with two\nreal-data examples.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2503.24211v1","title":"A Quantum Walk Inspired Qubit Lattice Algorithm for Simulating\n  Electromagnetic Wave Propagation and Scattering in Conservative and\n  Dissipative Magnetized Plasmas","summary":"Based on the Dirac representation of Maxwell equations we present an\nexplicit, discrete space-time, quantum walk-inspired algorithm suitable for\nsimulating the electromagnetic wave propagation and scattering from\ninhomogeneities within magnetized plasmas. The quantum walk is implemented on a\nlattice with an internal space of $n_q=4$--qubits, used to encode the classical\nfield amplitudes. Unitary rotation gates operate within this internal space to\ngenerate the non-trivial dynamics of the free plasma-Dirac equation. To\nincorporate the contributions from the cyclotron and plasma density\nterms--manifesting as inhomogeneous potential terms--in the plasma-Dirac\nequation, the walk process is complemented with unitary potential operators.\nThis leads to a unitary qubit lattice sequence that recovers the plasma-Dirac\nequation under a second-order accurate discretization scheme. The proposed\nalgorithm is explicit and demonstrates, in the worst case, a polynomial quantum\nadvantage compared to the Finite Difference Time Domain (FDTD) classical method\nin terms of resource requirements and error complexity. In addition, we extend\nthe algorithm to include dissipative effects by introducing a phenomenological\ncollision frequency between plasma species. Then, a post-selective\ntime-marching implementation scheme is delineated, featuring a non-vanishing\noverall success probability and, subsequently, eliminating the need for\namplitude amplification of the output state while preserving the quantum\nadvantage.","main_category":"quant-ph","categories":"quant-ph,physics.plasm-ph","published":"2025-03-31T15:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.24214v1","title":"Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach","summary":"We study an edge demand response problem where, based on historical edge\nworkload demands, an edge provider needs to dispatch moving computing units,\ne.g. truck-carried modular data centers, in response to emerging hotspots\nwithin service area. The goal of edge provider is to maximize the expected\nrevenue brought by serving congested users with satisfactory performance, while\nminimizing the costs of moving units and the potential service-level agreement\nviolation penalty for interrupted services. The challenge is to make robust\npredictions for future demands, as well as optimized moving unit dispatching\ndecisions. We propose a learning-based, uncertain-aware moving unit scheduling\nframework, URANUS, to address this problem. Our framework novelly combines\nBayesian deep learning and distributionally robust approximation to make\npredictions that are robust to data, model and distributional uncertainties in\ndeep learning-based prediction models. Based on the robust prediction outputs,\nwe further propose an efficient planning algorithm to optimize moving unit\nscheduling in an online manner. Simulation experiments show that URANUS can\nsignificantly improve robustness in decision making, and achieve superior\nperformance compared to state-of-the-art reinforcement learning,\nuncertainty-agnostic learning-based methods, and other baselines.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2503.24215v1","title":"All You Need is Sally-Anne: ToM in AI Strongly Supported After\n  Surpassing Tests for 3-Year-Olds","summary":"Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T15:32:10Z"}
{"aid":"http://arxiv.org/abs/2503.24241v1","title":"Asymmetry in Distributions of Accumulated Gains and Losses in Stock\n  Returns","summary":"We study decades-long historic distributions of accumulated S\\&P500 returns,\nfrom daily returns to those over several weeks. The time series of the returns\nemphasize major upheavals in the markets -- Black Monday, Tech Bubble,\nFinancial Crisis and Covid Pandemic -- which are reflected in the tail ends of\nthe distributions. De-trending the overall gain, we concentrate on comparing\ndistributions of gains and losses. Specifically, we compare the tails of the\ndistributions, which are believed to exhibit power-law behavior and possibly\ncontain outliers. Towards this end we find confidence intervals of the linear\nfits of the tails of the complementary cumulative distribution functions on a\nlog-log scale, as well as conduct a statistical U-test in order to detect\noutliers. We also study probability density functions of the full distributions\nof the returns with the emphasis on their asymmetry. The key empirical\nobservations are that the mean of de-trended distributions increases\nnear-linearly with the number of days of accumulation while the overall skew is\nnegative -- consistent with the heavier tails of losses -- and depends little\non the number of days of accumulation. At the same time the variance of the\ndistributions exhibits near-perfect linear dependence on the number of days of\naccumulation, that is it remains constant if scaled to the latter. Finally, we\ndiscuss the theoretical framework for understanding accumulated returns. Our\nmain conclusion is that the current state of theory, which predicts symmetric\nor near-symmetric distributions of returns cannot explain the aggregate of\nempirical results.","main_category":"q-fin.ST","categories":"q-fin.ST,econ.TH,physics.data-an","published":"2025-03-31T15:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24251v1","title":"Combining Query Performance Predictors: A Reproducibility Study","summary":"A large number of approaches to Query Performance Prediction (QPP) have been\nproposed over the last two decades. As early as 2009, Hauff et al. [28]\nexplored whether different QPP methods may be combined to improve prediction\nquality. Since then, significant research has been done both on QPP approaches,\nas well as their evaluation. This study revisits Hauff et al.s work to assess\nthe reproducibility of their findings in the light of new prediction methods,\nevaluation metrics, and datasets. We expand the scope of the earlier\ninvestigation by: (i) considering post-retrieval methods, including supervised\nneural techniques (only pre-retrieval techniques were studied in [28]); (ii)\nusing sMARE for evaluation, in addition to the traditional correlation\ncoefficients and RMSE; and (iii) experimenting with additional datasets\n(Clueweb09B and TREC DL). Our results largely support previous claims, but we\nalso present several interesting findings. We interpret these findings by\ntaking a more nuanced look at the correlation between QPP methods, examining\nwhether they capture diverse information or rely on overlapping factors.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T16:01:58Z"}
{"aid":"http://arxiv.org/abs/2503.24316v1","title":"Structure and Fragmentation Scale of a Massive Star-Forming Filament in\n  NGC6334: High-Resolution Mid-Infrared Absorption Imaging with JWST","summary":"Dense filaments are believed to be representative of the initial conditions\nof star formation in molecular clouds. We have used the MIRI instrument on JWST\nto image the massive filament NGC6334M at d~1.3 kpc with unprecedented\nresolution and dynamic range at 7.7 and 25.5 microns. Our observations reveal\nthe fine structure of the filament in absorption against mid-infrared\nbackground emission. From the absorption data, we derive high-resolution column\ndensity maps and perform a detailed analysis of the filament structure. We find\na median filament width of 0.12+/-0.02 pc at both wavelengths, resolved by\nalmost two orders of magnitude by MIRI, and consistent with the typical\nhalf-power width of Herschel filaments in nearby (d<0.5 kpc) clouds. The JWST\ndata also reveal the presence of a quasi-periodic series of side filaments with\na similar projected spacing of 0.125+/-0.015 pc. Combining our JWST results\nwith Spitzer and APEX/Herschel data, we perform a study of cloud structure over\nfour orders of magnitude in linear scale. A convergence test shows that our\nwidth estimates for NGC6334M are robust and reflect the presence of a true\ncharacteristic scale. While there is evidence of a Kolmogorov-like spectrum of\nsmall-scale fluctuations down the 1.6x10^-3 pc resolution of the JWST\nobservations, we identify a break in the power spectrum of column density\nfluctuations at a scale ~0.1-0.4 pc comparable to the width of NGC6334M and its\nside filaments. This characteristic scale ~0.1pc has important implications for\nthe origin of the star formation efficiency in dense gas and the IMF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:06:35Z"}
{"aid":"http://arxiv.org/abs/2503.24350v1","title":"Large CP violation in $Î^0_b \\to pK^-Ï^+Ï^-$ and its U-spin\n  partner decays","summary":"The LHCb Collaboration has recently found a large CP-violating rate asymmetry\nin the $b$-baryon decay $\\Lambda^0_b \\to pK^-\\pi^+\\pi^-$. This is the first\nobservation of CP violation in baryon processes, opening a new window to test\nits standard model (SM) origin. Many more baryon decays are expected to exhibit\nobservable signals of CP violation. We show that there also exists large CP\nviolation in the U-spin partner decay mode, $\\Xi^0_b \\to \\Sigma^+\\pi^- K^+K^-$,\nwith rate asymmetry $$A_{CP}(\\Xi^0_b \\to \\Sigma^+\\pi^- K^+ K^-) = -\nA_{CP}(\\Lambda^0_b \\to p K^- \\pi^+ \\pi^-)~ \\frac{Br(\\Lambda^0_b \\to p K^- \\pi^+\n\\pi^-)}{Br(\\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-)}~\n\\frac{\\tau^{\\Xi_b}}{\\tau^{\\Lambda_b}}$$ in the U-spin symmetry limit.\nNeglecting small annihilation contributions, we obtain $$A_{CP}(\\Lambda^0_b \\to\np \\pi^+ \\pi^- \\pi^-) =A_{CP}( \\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-) = -(12 \\pm 3)\n\\%.$$ These predictions provide crucial tests for the SM.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-03-31T17:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.24370v1","title":"Effectively Controlling Reasoning Models through Thinking Intervention","summary":"Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-31T17:50:13Z"}
{"aid":"http://arxiv.org/abs/2503.24382v1","title":"Free360: Layered Gaussian Splatting for Unbounded 360-Degree View\n  Synthesis from Extremely Sparse and Unposed Views","summary":"Neural rendering has demonstrated remarkable success in high-quality 3D\nneural reconstruction and novel view synthesis with dense input views and\naccurate poses. However, applying it to extremely sparse, unposed views in\nunbounded 360{\\deg} scenes remains a challenging problem. In this paper, we\npropose a novel neural rendering framework to accomplish the unposed and\nextremely sparse-view 3D reconstruction in unbounded 360{\\deg} scenes. To\nresolve the spatial ambiguity inherent in unbounded scenes with sparse input\nviews, we propose a layered Gaussian-based representation to effectively model\nthe scene with distinct spatial layers. By employing a dense stereo\nreconstruction model to recover coarse geometry, we introduce a layer-specific\nbootstrap optimization to refine the noise and fill occluded regions in the\nreconstruction. Furthermore, we propose an iterative fusion of reconstruction\nand generation alongside an uncertainty-aware training approach to facilitate\nmutual conditioning and enhancement between these two processes. Comprehensive\nexperiments show that our approach outperforms existing state-of-the-art\nmethods in terms of rendering quality and surface reconstruction accuracy.\nProject page: https://zju3dv.github.io/free360/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.01365v1","title":"Inflation with Gauss-Bonnet correction: beyond slow-roll","summary":"If a coupling between the inflaton and the Gauss-Bonnet term is introduced,\nmany models of inflation that were ruled out by the most recent Planck data can\nbe made viable again. The predictions for the scalar spectral index and\ntensor-to-scalar ratio are typically computed using the slow-roll\napproximation. In this paper we instead study the full equations of motion and\ndetermine the necessary initial conditions for reasonable inflation epoch. We\nderive the conditions under which the Friedmann equation admits positive\nsolutions for the Hubble parameter. Then we study the possibility of the\ninflaton becoming trapped in a local potential minimum induced by the\nGauss-Bonnet term. Finally we demonstrate the results on monomial potential\nmodels with a quadratic and a quartic potential and show that the slow-roll\napproximation becomes imprecise in the quartic case.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-02T05:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.01378v1","title":"A Control Barrier Function Approach to Constrained Resource Allocation\n  Problems in a Maximum Entropy Principle Framework","summary":"This paper presents a novel approach to solve capacitated facility location\nproblems (FLP) that encompass various resource allocation problems. FLPs are a\nclass of NP-hard combinatorial optimization problems, involving optimal\nplacement and assignment of a small number of facilities over a large number of\ndemand points, with each facility subject to upper and lower bounds on its\nresource utilization (e.g., the number of demand points it can serve). To\naddress the challenges posed by inequality constraints and the combinatorial\nnature of the solution space, we reformulate the problem as a dynamic control\ndesign problem, enabling structured constraint handling and enhanced solution\nefficiency. Our method integrates a Control Barrier Function (CBF) and Control\nLyapunov Function (CLF)-based framework with a maximum-entropy principle-based\nframework to ensure feasibility, optimality, and improved exploration of\nsolutions. Numerical experiments demonstrate that this approach significantly\nenhances computational efficiency, yielding better solutions and showing\nnegligible growth in computation time with problem size as compared to existing\nsolvers. These results highlight the potential of control-theoretic and\nentropy-based methods for large-scale facility location problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T05:47:57Z"}
{"aid":"http://arxiv.org/abs/2504.01381v1","title":"Interstellar extinction toward MWC 148","summary":"We analyse high resolution optical spectra of MWC148 (optical counterpart of\nthe gamma-ray source HESS J0632+057) obtained at Observatoire de Haute Provence\nand Rozhen Observatory. We measure equivalent widths of 7 diffuse interstellar\nbands and estimate the interstellar extinction E_{B-V}=0.85 +/- 0.08.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-04-02T05:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01397v1","title":"Can the poltergeist mechanism produce observable GWs?","summary":"The enhancement of induced gravitational waves (GWs) occurs due to a sudden\ntransition from an early matter-dominated era to the radiation-dominated era.\nWe analyze the impact of the transition rate on the scalar potential. We find\nthat the finite transition duration suppresses the oscillation amplitude of the\nscalar potential, consequently suppressing the amplitude of the GW energy\nspectrum. By numerically solving the background and perturbation equations, we\ndemonstrate that the physically motivated models, such as the evaporation of\nprimordial black holes and the decay of Q-balls, cannot produce an observable\nGW signal.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T06:37:17Z"}
{"aid":"http://arxiv.org/abs/2504.01411v1","title":"General channel capacities from quantum channel-state duality","summary":"The quantum channel-state duality permits the characterization of a quantum\nprocess through a quantum state, referred to as a Choi state. This\ncharacteristic serves as the impetus for the quantum computing paradigm that\nutilizes Choi states as information sources. In this work, the fundamental\ntheorems regarding quantum channel capacity are proven when Choi states are\nconsidered as sources. This achievement enriches the set of capacities\nassociated with quantum channels. Moreover, it gives rise to novel\nopportunities for the comprehension of superadditivity phenomena and the\ndiscovery of new classes of quantum error-correction codes.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T06:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01430v1","title":"Asymptotic Error Bounds and Fractional-Bit Design for Fixed-Point\n  Grover's Quantum Algorithm Emulation","summary":"Quantum computing (QC) emulators, which simulate quantum algorithms on\nclassical hardware, are indispensable platforms for testing quantum algorithms\nbefore scalable quantum computers become widely available. A critical challenge\nin QC emulation is managing numerical errors from finite arithmetic precision,\nespecially truncation errors in resource-efficient fixed-point arithmetic.\nDespite its importance, systematic studies quantifying how truncation errors\nimpact quantum algorithm accuracy are limited. In this paper, we propose a\nrigorous quantitative framework analyzing truncation error propagation in\nfixed-point QC emulation, focusing on Grover's quantum search algorithm. First,\nwe introduce a simplified two-value amplitude representation of quantum states\nduring Grover's iterations and prove its theoretical validity. Using this\nrepresentation, we derive explicit mathematical expressions characterizing\ntruncation error accumulation across quantum gate operations. We quantify the\noverall emulation error by the $\\ell_2$ distance between ideal and emulated\nprobability distributions, obtaining asymptotic bounds scaling as $O(2^{n-f})$,\nwhere $n$ is the number of qubits and $f$ is fractional-bit precision.\nExtensive numerical simulations and empirical experiments on a practical\nfixed-point QC emulator confirm that observed errors precisely match our\ntheoretical predictions. Finally, we provide a closed-form formula to determine\nthe minimal fractional-bit precision required to achieve a specified error\nthreshold, offering clear guidelines for emulator designers balancing accuracy\nand resource utilization.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-02T07:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.01431v1","title":"Multi-convex Programming for Discrete Latent Factor Models Prototyping","summary":"Discrete latent factor models (DLFMs) are widely used in various domains such\nas machine learning, economics, neuroscience, psychology, etc. Currently,\nfitting a DLFM to some dataset relies on a customized solver for individual\nmodels, which requires lots of effort to implement and is limited to the\ntargeted specific instance of DLFMs. In this paper, we propose a generic\nframework based on CVXPY, which allows users to specify and solve the fitting\nproblem of a wide range of DLFMs, including both regression and classification\nmodels, within a very short script. Our framework is flexible and inherently\nsupports the integration of regularization terms and constraints on the DLFM\nparameters and latent factors, such that the users can easily prototype the\nDLFM structure according to their dataset and application scenario. We\nintroduce our open-source Python implementation and illustrate the framework in\nseveral examples.","main_category":"math.OC","categories":"math.OC,cs.CE,cs.LG","published":"2025-04-02T07:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.01433v1","title":"Reaction and interaction nucleus-nucleus cross sections in the complete\n  Glauber theory","summary":"The straightforward calculations of the reaction and interaction cross\nsections of the nuclear scattering are carried out in Glauber approach using\nthe generating function method. It allows for the resummation of all orders of\nGlauber theory. The results are obtained for $^4$He, $^{11}$Li, $^{12}$C\nscattering on $^{12}$C target. The difference between the reaction and the\ndifferential cross section is shown to be not exceeding several percents","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-02T07:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.01441v1","title":"Locally- but not Globally-identified SVARs","summary":"This paper analyzes Structural Vector Autoregressions (SVARs) where\nidentification of structural parameters holds locally but not globally. In this\ncase there exists a set of isolated structural parameter points that are\nobservationally equivalent under the imposed restrictions. Although the data do\nnot inform us which observationally equivalent point should be selected, the\ncommon frequentist practice is to obtain one as a maximum likelihood estimate\nand perform impulse response analysis accordingly. For Bayesians, the lack of\nglobal identification translates to non-vanishing sensitivity of the posterior\nto the prior, and the multi-modal likelihood gives rise to computational\nchallenges as posterior sampling algorithms can fail to explore all the modes.\nThis paper overcomes these challenges by proposing novel estimation and\ninference procedures. We characterize a class of identifying restrictions and\ncircumstances that deliver local but non-global identification, and the\nresulting number of observationally equivalent parameter values. We propose\nalgorithms to exhaustively compute all admissible structural parameters given\nreduced-form parameters and utilize them to sample from the multi-modal\nposterior. In addition, viewing the set of observationally equivalent parameter\npoints as the identified set, we develop Bayesian and frequentist procedures\nfor inference on the corresponding set of impulse responses. An empirical\nexample illustrates our proposal.","main_category":"econ.EM","categories":"econ.EM","published":"2025-04-02T07:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.01443v1","title":"Split Federated Learning for UAV-Enabled Integrated Sensing,\n  Computation, and Communication","summary":"Unmanned aerial vehicles (UAVs) with integrated sensing, computation, and\ncommunication (ISCC) capabilities have become key enablers of next-generation\nwireless networks. Federated edge learning (FEL) leverages UAVs as mobile\nlearning agents to collect data, perform local model updates, and contribute to\nglobal model aggregation. However, existing UAV-assisted FEL systems face\ncritical challenges, including excessive computational demands, privacy risks,\nand inefficient communication, primarily due to the requirement for full-model\ntraining on resource-constrained UAVs. To deal with aforementioned challenges,\nwe propose Split Federated Learning for UAV-Enabled ISCC (SFLSCC), a novel\nframework that integrates split federated learning (SFL) into UAV-assisted FEL.\nSFLSCC optimally partitions model training between UAVs and edge servers,\nsignificantly reducing UAVs' computational burden while preserving data\nprivacy. We conduct a theoretical analysis of UAV deployment, split point\nselection, data sensing volume, and client-side aggregation frequency, deriving\nclosed-form upper bounds for the convergence gap. Based on these insights, we\nconceive a joint optimization problem to minimize the energy consumption\nrequired to achieve a target model accuracy. Given the non-convex nature of the\nproblem, we develop a low-complexity algorithm to efficiently determine UAV\ndeployment, split point selection, and communication frequency. Extensive\nsimulations on a target motion recognition task validate the effectiveness of\nSFLSCC, demonstrating superior convergence performance and energy efficiency\ncompared to baseline methods.","main_category":"cs.DC","categories":"cs.DC,cs.ET","published":"2025-04-02T07:53:24Z"}
{"aid":"http://arxiv.org/abs/2504.01452v1","title":"BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting\n  Binary Segmentation in Segment Anything Models","summary":"Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-02T08:04:37Z"}
{"aid":"http://arxiv.org/abs/2504.01454v1","title":"Quantum Key Distribution with Efficient Post-Quantum\n  Cryptography-Secured Trusted Node on a Quantum Network","summary":"Quantum Key Distribution (QKD) enables two distant users to exchange a secret\nkey with information-theoretic security, based on the fundamental laws of\nquantum physics. While it is arguably the most mature application of quantum\ncryptography, it has inherent limitations in the achievable distance and the\nscalability to large-scale infrastructures. While the applicability of QKD can\nbe readily increased with the use of intermediary trusted nodes, this adds\nadditional privacy requirements on third parties. In this work, we present an\nefficient scheme leveraging a trusted node with lower privacy requirements\nthanks to the use of post-quantum cryptographic techniques, and implement it on\na deployed fiber optic quantum communication network in the Paris area.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2504.01455v1","title":"Atmospheric dynamics of first steps toward terraforming Mars","summary":"Warming Mars' surface could be a step toward making it suitable for life, but\nwould represent a major science and engineering challenge. To warm Mars using\nengineered aerosol, particles released locally must disperse globally. The\nwinds that transport aerosol respond to the aerosol's radiative forcing,\nimplying strong radiative-dynamical feedbacks. Using a plume-tracking climate\nmodel without a water cycle, we investigate radiative-dynamical feedback from\nsurface release of two particle compositions: graphene (which attenuates UV)\nand aluminum. Both compositions can give fast global warming of ~30 K. We infer\nthat 2 liters/second release rate of graphene made from Mars' atmosphere via\nCO2-electrolysis could double Mars' greenhouse effect (+5 K). Self-lofting\nhelps particles rise and spread. The Hadley cell strengthens under warming,\naiding mixing. Warming can be focused in latitude by tuning particle size.\nWithin our model, Mars radiative-dynamical feedbacks enable engineered-aerosol\nwarming. Challenges remain, including functionalization, agglomeration,\ndry-deposition experiments, and modeling water cycle feedbacks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.geo-ph","published":"2025-04-02T08:06:35Z"}
{"aid":"http://arxiv.org/abs/2504.01499v1","title":"The de Rham cohomology of covers with cyclic $p$-Sylow subgroup","summary":"Let $X$ be a smooth projective curve over a field $k$ with an action of a\nfinite group $G$. A well-known result of Chevalley and Weil describes the\n$k[G]$-module structure of cohomologies of $X$ in the case when the\ncharacteristic of $k$ does not divide $\\# G$. It is unlikely that such a\nformula can be derived in the general case, since the representation theory of\ngroups with non-cyclic $p$-Sylow subgroups is wild in characteristic $p$. The\ngoal of this article is to show that when $G$ has a cyclic $p$-Sylow subgroup,\nthe $G$-structure of the de Rham cohomology of $X$ is completely determined by\nthe ramification data. In principle, this leads to new formulas in the spirit\nof Chevalley and Weil for such curves. We provide such an explicit description\nof the de Rham cohomology in the cases when $G = \\mathbb Z/p^n$ and when the\n$p$-Sylow subgroup of $G$ is normal of order $p$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-02T08:51:33Z"}
{"aid":"http://arxiv.org/abs/2504.01507v1","title":"Grasping by Spiraling: Reproducing Elephant Movements with Rigid-Soft\n  Robot Synergy","summary":"The logarithmic spiral is observed as a common pattern in several living\nbeings across kingdoms and species. Some examples include fern shoots,\nprehensile tails, and soft limbs like octopus arms and elephant trunks. In the\nlatter cases, spiraling is also used for grasping. Motivated by how this\nstrategy simplifies behavior into kinematic primitives and combines them to\ndevelop smart grasping movements, this work focuses on the elephant trunk,\nwhich is more deeply investigated in the literature. We present a soft arm\ncombined with a rigid robotic system to replicate elephant grasping\ncapabilities based on the combination of a soft trunk with a solid body. In our\nsystem, the rigid arm ensures positioning and orientation, mimicking the role\nof the elephant's head, while the soft manipulator reproduces trunk motion\nprimitives of bending and twisting under proper actuation patterns. This\nsynergy replicates 9 distinct elephant grasping strategies reported in the\nliterature, accommodating objects of varying shapes and sizes. The synergistic\ninteraction between the rigid and soft components of the system minimizes the\ncontrol complexity while maintaining a high degree of adaptability.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T08:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.01521v1","title":"Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion\n  Model","summary":"Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-02T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.01560v1","title":"Optimizing Package Delivery with Quantum Annealers: Addressing\n  Time-Windows and Simultaneous Pickup and Delivery","summary":"Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.","main_category":"cs.ET","categories":"cs.ET,cs.AI","published":"2025-04-02T10:01:34Z"}
{"aid":"http://arxiv.org/abs/2504.01561v1","title":"STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation","summary":"Accurate segmentation of lesions plays a critical role in medical image\nanalysis and diagnosis. Traditional segmentation approaches that rely solely on\nvisual features often struggle with the inherent uncertainty in lesion\ndistribution and size. To address these issues, we propose STPNet, a\nScale-aware Text Prompt Network that leverages vision-language modeling to\nenhance medical image segmentation. Our approach utilizes multi-scale textual\ndescriptions to guide lesion localization and employs retrieval-segmentation\njoint learning to bridge the semantic gap between visual and linguistic\nmodalities. Crucially, STPNet retrieves relevant textual information from a\nspecialized medical text repository during training, eliminating the need for\ntext input during inference while retaining the benefits of cross-modal\nlearning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and\nKvasir-SEG. Experimental results show that our vision-language approach\noutperforms state-of-the-art segmentation methods, demonstrating the\neffectiveness of incorporating textual semantic knowledge into medical image\nanalysis. The code has been made publicly on\nhttps://github.com/HUANGLIZI/STPNet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.01567v1","title":"Quantum Computing for Optimizing Aircraft Loading","summary":"The aircraft loading optimization problem is a computationally hard problem\nwith the best known classical algorithm scaling exponentially with the number\nof objects. We propose a quantum approach based on a multi-angle variant of the\nQAOA algorithm (Multi-Angle Layered Variational Quantum Algorithm (MAL-VQA))\ndesigned to utilize a smaller number of two qubit gates in the quantum circuit\nas compared to the standard QAOA algorithm so that the quantum optimization\nalgorithm can be run on near-term ion-trap quantum processing units (QPU). We\nalso describe a novel cost function implementation that can handle many\ndifferent types of inequality constraints without the overhead of introducing\nslack variables in the quantum circuit so that larger problems with complex\nconstraints may be represented on near-term QPUs which have low qubit counts.\nWe demonstrate the performance of the algorithm on different instances of the\naircraft loading problem by execution on IonQ QPUs Aria and Forte. Our\nexperiments obtain the optimal solutions for all the problem instances studied\nranging from 12 qubits to 28 qubits. This shows the potential scalability of\nthe method to significantly larger problem sizes with the improvement of\nquantum hardware in the near future as well as the robustness of the quantum\nalgorithm against varying initial guesses and varying constraints of different\nproblem instances.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-02T10:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.01577v1","title":"Instance Migration Diffusion for Nuclear Instance Segmentation in\n  Pathology","summary":"Nuclear instance segmentation plays a vital role in disease diagnosis within\ndigital pathology. However, limited labeled data in pathological images\nrestricts the overall performance of nuclear instance segmentation. To tackle\nthis challenge, we propose a novel data augmentation framework Instance\nMigration Diffusion Model (IM-Diffusion), IM-Diffusion designed to generate\nmore varied pathological images by constructing diverse nuclear layouts and\ninternuclear spatial relationships. In detail, we introduce a Nuclear Migration\nModule (NMM) which constructs diverse nuclear layouts by simulating the process\nof nuclear migration. Building on this, we further present an\nInternuclear-regions Inpainting Module (IIM) to generate diverse internuclear\nspatial relationships by structure-aware inpainting. On the basis of the above,\nIM-Diffusion generates more diverse pathological images with different layouts\nand internuclear spatial relationships, thereby facilitating downstream tasks.\nEvaluation on the CoNSeP and GLySAC datasets demonstrate that the images\ngenerated by IM-Diffusion effectively enhance overall instance segmentation\nperformance. Code will be made public later.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.01584v1","title":"Higher-order topological phases for time-reversal-symmetry breaking\n  superconductivity in UTe$_2$","summary":"The recent discovery of heavy-fermion superconductor UTe$_2$ has broadened\nthe possibility of realizing exotic time-reversal-symmetry-breaking\nsuperconductivity. However, a comprehensive understanding of the topological\nphases in the superconducting states of UTe$_2$ is still lacking. Here, we\npresent an exhaustive classification of topological phases for all\ntime-reversal symmetry breaking pairing symmetries of UTe$_2$. Using the K\ntheoretical classification approach, we uncover that 25 out of 36 possible\npairing states are classified as higher-order topological phases, with some\ndemonstrating hybrid-order topology through an intricate interplay of hinge and\ncorner states. Furthermore, under the weak-coupling condition of the pair\npotentials, the possible pairing symmetries are constrained to $B_{ju} + i\nB_{ku}$, $A_{u} + i B_{j u}$, and $B_{j g} + iA_u$ ($j,k = 1,2,3$; $j \\neq k$),\nwhere these symbols denote the irreducible representations of the point group\n$D_{2h}$. For these pairing states, the topological invariants are related to\nthe Fermi surface topology via the Fermi-surface formula, enabling us to\nsystematically diagnose higher-order topological phases. Using a tight-binding\nmodel, we demonstrate the higher-order topological phases of the mixed-parity\n$A_u + iB_{1g}$ superconductors, where the second-order and hybrid-order\ntopological phases emerge as the number of Fermi surfaces enclosing the\ntime-reversal invariant momentum evolves from two to four. The findings suggest\nthat UTe$_2$ serves as a compelling platform for exploring higher-order\ntopological superconductors with diverse topological surface states.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T10:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.01652v1","title":"Market-Oriented Flow Allocation for Thermal Solar Plants: An\n  Auction-Based Methodology with Artificial Intelligence","summary":"This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-02T12:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.01671v1","title":"Anomaly Detection for Hybrid Butterfly Subspecies via Probability\n  Filtering","summary":"Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.","main_category":"cs.CE","categories":"cs.CE,cs.AI","published":"2025-04-02T12:18:44Z"}
{"aid":"http://arxiv.org/abs/2504.01677v1","title":"System Level Synthesis for Affine Control Policies: Model Based and\n  Data-Driven Settings","summary":"There is an increasing need for effective control of systems with complex\ndynamics, particularly through data-driven approaches. System Level Synthesis\n(SLS) has emerged as a powerful framework that facilitates the control of\nlarge-scale systems while accounting for model uncertainties. SLS approaches\nare currently limited to linear systems and time-varying linear control\npolicies, thus limiting the class of achievable control strategies. We\nintroduce a novel closed-loop parameterization for time-varying affine control\npolicies, extending the SLS framework to a broader class of systems and\npolicies. We show that the closed-loop behavior under affine policies can be\nequivalently characterized using past system trajectories, enabling a fully\ndata-driven formulation. This parameterization seamlessly integrates affine\npolicies into optimal control problems, allowing for a closed-loop formulation\nof general Model Predictive Control (MPC) problems. To the best of our\nknowledge, this is the first work to extend SLS to affine policies in both\nmodel-based and data-driven settings, enabling an equivalent formulation of MPC\nproblems using closed-loop maps. We validate our approach through numerical\nexperiments, demonstrating that our model-based and data-driven affine SLS\nformulations achieve performance on par with traditional model-based MPC.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T12:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.01731v1","title":"The protein escape process at the ribosomal exit tunnel has conserved\n  mechanisms across the domains of life","summary":"The ribosomal exit tunnel is the primary structure affecting the release of\nnascent proteins at the ribosome. The ribosomal exit tunnels from different\nspecies have elements of conservation and differentiation in structural and\nphysico-chemical properties. In this study, by simulating the elongation and\nescape processes of nascent proteins at the ribosomal exit tunnels of four\ndifferent organisms, we show that the escape process has conserved mechanisms\nacross the domains of life. Specifically, it is found that the escape process\nof proteins follows the diffusion mechanism given by a simple diffusion model\nand the median escape time positively correlates with the number of hydrophobic\nresidues and the net charge of a protein for all the exit tunnels considered.\nThese properties hold for twelve distinct proteins considered in two slightly\ndifferent and improved G\\=o-like models. It is also found that the differences\nin physico-chemical properties of the tunnels lead to quantitative differences\nin the protein escape times. In particular, the relatively strong\nhydrophobicity of the E. coli's tunnel and the unusually high number of\nnegatively charged amino acids on the tunnel's surface of H. marismortui lead\nto substantially slower escapes of proteins at these tunnels than at those of\nS. cerevisisae and H. sapiens.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T13:40:58Z"}
{"aid":"http://arxiv.org/abs/2504.01783v1","title":"CLaP -- State Detection from Time Series","summary":"The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB","published":"2025-04-02T14:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.01788v1","title":"Projections from Furstenberg boundaries onto maximal flats and\n  barycenter maps","summary":"Let $G$ be a semisimple connected Lie group of non-compact type with finite\ncenter. Let $K<G$ be a maximal compact subgroup and $P<G$ be a minimal\nparabolic subgroup. For any pair $(F,x)$, where $F$ is a maximal flat in $G/K$\nand $x \\in G/P$ is opposite to the Weyl chambers determined by $F$, we define a\nprojection $\\Phi(F, x) \\in F$ which is continuous and $G$-equivariant.\nFurthermore, if $q \\geq 3$, we exhibit a $G$-equivariant continuous map defined\non an open subset of full measure of the space of $q$-tuples of $(G/P)^q$ with\nimage in $G/K$. When $G$ is the orientation preserving isometries of real\nhyperbolic space and $q = 3$, we recover the geometric barycenter of the\ncorresponding ideal triangle. All our proofs are constructive.","main_category":"math.GR","categories":"math.GR,math.DG","published":"2025-04-02T14:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.01812v1","title":"Non-collocated vibration absorption using delayed resonator for spectral\n  and spacial tuning -- analysis and experimental validation","summary":"Non-collocated vibration absorption (NCVA) concept using delayed resonator\nfor in-situ tuning is analyzed and experimentally validated. There are two\ncritical contributions of this work. One is on the scalable analytical pathway\nfor verifying the concept of resonant substructure as the basis of the ideal\nvibration absorption. The second is to experimentally validate the spatial and\nspectral tunability of NCVA structures for the first time. For both novelties\narbitrarily large dimensions of interconnected mass-spring-damper chains are\nconsidered. Following the state of the art on NCVA, control synthesis is\nperformed over the resonant substructure comprising the delayed resonator and a\npart of the primary structure involved in the vibration absorption. The\nexperimental validation of the proposed NCVA concept is performed on a\nmechatronic setup with three interconnected cart-bodies. Based on the spectral\nanalysis, an excitation frequency is selected for which a stable vibration\nsuppression can be achieved sequentially for all the three bodies, one\ncollocated and two non-collocated. The experimental results closely match the\nsimulations for complete vibration suppression at the targeted bodies, and thus\nvalidating the crucial spatial tunability characteristic as well as the\ntraditional spectral tuning.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T15:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.01814v1","title":"Energy Density Functional of Confined Quarks: an Improved Ansatz","summary":"Density Functional Theory (DFT) is a robust framework for modeling\ninteracting many-body systems, including the equation of state (EoS) of dense\nmatter. Many models, however, rely on energy functionals based on assumptions\nthat have not been rigorously validated. We critically analyze a commonly used\nansatz for confinement, where the energy functional scales with density as $U\n\\propto n^{\\frac{2}{3}}$ . Our findings, derived from a systematic non-local\nenergy functional, reveal that this scaling does not capture the dynamics of\nconfinement. Instead, the energy functional evolves from $n^2$ at low densities\nto $n$ at high densities, governed by an infrared cutoff. These results suggest\nthat models relying on such assumptions should be revisited to ensure more\nreliable EoS construction.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE,hep-ph,hep-th","published":"2025-04-02T15:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.01837v1","title":"CramÃ©r--Rao Inequalities for Several Generalized Fisher Information","summary":"The de Bruijn identity states that Fisher information is the half of the\nderivative of Shannon differential entropy along heat flow. In the same spirit,\nin this paper we introduce a generalized version of Fisher information, named\nas the R\\'enyi--Fisher information, which is the half of the derivative of\nR\\'enyi information along heat flow. Based on this R\\'enyi--Fisher information,\nwe establish sharp R\\'enyi-entropic isoperimetric inequalities, which\ngeneralize the classic entropic isoperimetric inequality to the R\\'enyi\nsetting. Utilizing these isoperimetric inequalities, we extend the classical\nCram\\'er--Rao inequality from Fisher information to R\\'enyi--Fisher\ninformation. Lastly, we use these generalized Cram\\'er--Rao inequalities to\ndetermine the signs of derivatives of entropy along heat flow, strengthening\nexisting results on the complete monotonicity of entropy.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.PR,math.ST,stat.TH","published":"2025-04-02T15:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.01840v1","title":"LARGE: Legal Retrieval Augmented Generation Evaluation Tool","summary":"Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T15:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.01852v1","title":"Deciphering the Nature of Virgil: An Obscured AGN Lurking Within an\n  Apparently Normal Lyman-Î± Emitter During Cosmic Reionization","summary":"We present a comprehensive analysis of the MIRI Extremely Red Object Virgil,\na Lyman-$\\alpha$ emitter at $z_{spec} = 6.6379 \\pm 0.0035$ with the photometric\nproperties of a Little Red Dot. Leveraging new JWST/MIRI imaging from the MIDIS\nand PAHSPECS programs, we confirm Virgil's extraordinary nature among galaxies\nin JADES/GOODS-South, exhibiting a strikingly red NIRCam-to-MIRI color (F444W\n$-$ F1500W = $2.84\\pm0.04$~mag). Deep NIRSpec/PRISM spectroscopy from the OASIS\nprogram offers key insights into the host galaxy, revealing properties of an\naverage star-forming galaxy during Cosmic Reionization, such as a subsolar\nmetallicity, low-to-moderate dust content, and a relatively high ionization\nparameter and electron temperature. By estimating the star formation rate of\nVirgil from UV and H$\\alpha$, we find evidence that the galaxy is either\nentering or fading out of a bursty episode. Although line-ratio diagnostics\nemployed at high-$z$ would classify Virgil as an Active Galactic Nucleus (AGN),\nthis classification becomes ambiguous once redshift evolution is considered.\nNonetheless, Virgil occupies the same parameter space as recently confirmed\nAGNs at similar redshifts. The new deep MIRI data at 15~$\\mu$m reinforce the\nAGN nature of Virgil, as inferred from multiple spectral energy distribution\n(SED) fitting codes. Virgil's rising infrared SED and UV excess resemble those\nof Dust-Obscured Galaxies (DOGs) studied with Spitzer at Cosmic Noon,\nparticularly blue-excess HotDOGs. Our results highlight the need for a\nmulti-wavelength approach incorporating MIRI to uncover such extreme sources at\n$z\\gtrsim6$ and to shed light on the interplay between galaxy evolution and\nearly black hole growth during Cosmic Reionization.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-02T16:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.01853v1","title":"Implications of recent LHCb data on CPV in b-baryon four body decays","summary":"Motivated by the recent CPV observation, we investigate the CPV of b-baryon\ncharmless four body decays under the U-spin symmetry. However, we find that\nonly U-spin symmetry cannot provide effective predictions, particularly for\n$\\Lambda_b$ decays. For giving more useful predictions, we also give a simple\ndynamic analysis. By counting the\npower($\\lambda=\\sqrt{\\frac{\\Lambda_{QCD}}{m_b}}$) of each topological diagram,\nwe find that for the specific decay $B_b^2\\to R(B_1^2 M^2 M^{\\bar 2})M^2$, only\none U-spin amplitude can contribute in the leading power. Then the effective\nprediction can be given as \\begin{align}\n  A_{CP}^{dir}(\\Lambda_b^0 \\to R( p \\pi^- \\pi^+ )\\pi^-) = (-12.98 \\pm\n2.85)\\%.\\notag \\end{align} Considering the $\\Lambda_b$ can effectively produced\nin LHCb, we strongly encourage a more precise experimental investigation of it.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T16:05:00Z"}
{"aid":"http://arxiv.org/abs/2504.01883v1","title":"CoRAG: Collaborative Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-02T16:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.01894v1","title":"Multi-fidelity Parameter Estimation Using Conditional Diffusion Models","summary":"We present a multi-fidelity method for uncertainty quantification of\nparameter estimates in complex systems, leveraging generative models trained to\nsample the target conditional distribution. In the Bayesian inference setting,\ntraditional parameter estimation methods rely on repeated simulations of\npotentially expensive forward models to determine the posterior distribution of\nthe parameter values, which may result in computationally intractable\nworkflows. Furthermore, methods such as Markov Chain Monte Carlo (MCMC)\nnecessitate rerunning the entire algorithm for each new data observation,\nfurther increasing the computational burden. Hence, we propose a novel method\nfor efficiently obtaining posterior distributions of parameter estimates for\nhigh-fidelity models given data observations of interest. The method first\nconstructs a low-fidelity, conditional generative model capable of amortized\nBayesian inference and hence rapid posterior density approximation over a\nwide-range of data observations. When higher accuracy is needed for a specific\ndata observation, the method employs adaptive refinement of the density\napproximation. It uses outputs from the low-fidelity generative model to refine\nthe parameter sampling space, ensuring efficient use of the computationally\nexpensive high-fidelity solver. Subsequently, a high-fidelity, unconditional\ngenerative model is trained to achieve greater accuracy in the target posterior\ndistribution. Both low- and high- fidelity generative models enable efficient\nsampling from the target posterior and do not require repeated simulation of\nthe high-fidelity forward model. We demonstrate the effectiveness of the\nproposed method on several numerical examples, including cases with multi-modal\ndensities, as well as an application in plasma physics for a runaway electron\nsimulation model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.01951v1","title":"The LLM Wears Prada: Analysing Gender Bias and Stereotypes through\n  Online Shopping Data","summary":"With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY","published":"2025-04-02T17:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.01960v1","title":"Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D\n  Reconstruction and Novel View Synthesis","summary":"Recent advancements in 3D Gaussian Splatting (3DGS) and Neural Radiance\nFields (NeRF) have achieved impressive results in real-time 3D reconstruction\nand novel view synthesis. However, these methods struggle in large-scale,\nunconstrained environments where sparse and uneven input coverage, transient\nocclusions, appearance variability, and inconsistent camera settings lead to\ndegraded quality. We propose GS-Diff, a novel 3DGS framework guided by a\nmulti-view diffusion model to address these limitations. By generating\npseudo-observations conditioned on multi-view inputs, our method transforms\nunder-constrained 3D reconstruction problems into well-posed ones, enabling\nrobust optimization even with sparse data. GS-Diff further integrates several\nenhancements, including appearance embedding, monocular depth priors, dynamic\nobject modeling, anisotropy regularization, and advanced rasterization\ntechniques, to tackle geometric and photometric challenges in real-world\nsettings. Experiments on four benchmarks demonstrate that GS-Diff consistently\noutperforms state-of-the-art baselines by significant margins.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-02T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.02260v1","title":"Implicit Neural Differential Model for Spatiotemporal Dynamics","summary":"Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T04:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.02270v1","title":"MinkOcc: Towards real-time label-efficient semantic occupancy prediction","summary":"Developing 3D semantic occupancy prediction models often relies on dense 3D\nannotations for supervised learning, a process that is both labor and\nresource-intensive, underscoring the need for label-efficient or even\nlabel-free approaches. To address this, we introduce MinkOcc, a multi-modal 3D\nsemantic occupancy prediction framework for cameras and LiDARs that proposes a\ntwo-step semi-supervised training procedure. Here, a small dataset of\nexplicitly 3D annotations warm-starts the training process; then, the\nsupervision is continued by simpler-to-annotate accumulated LiDAR sweeps and\nimages -- semantically labelled through vision foundational models. MinkOcc\neffectively utilizes these sensor-rich supervisory cues and reduces reliance on\nmanual labeling by 90\\% while maintaining competitive accuracy. In addition,\nthe proposed model incorporates information from LiDAR and camera data through\nearly fusion and leverages sparse convolution networks for real-time\nprediction. With its efficiency in both supervision and computation, we aim to\nextend MinkOcc beyond curated datasets, enabling broader real-world deployment\nof 3D semantic occupancy prediction in autonomous driving.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T04:31:56Z"}
{"aid":"http://arxiv.org/abs/2504.02303v1","title":"Diversifying halo structures in two-component self-interacting dark\n  matter models via mass segregation","summary":"Self-interacting dark matter (SIDM), through gravothermal evolution driven by\nelastic self-scatterings, offers a compelling explanation for the observed\ndiversity of inner halo densities. In this work, we investigate SIDM dynamics\nin a two-component dark matter model with mass ratios of order unity, motivated\nby an asymmetric dark matter framework that naturally evades constraints from\nrelic abundance and mediator decay, while enabling strong, velocity-dependent\nself-interactions. We show that cross-component scatterings significantly\nenhance mass segregation, driving the formation of dense, core collapsed-like\nhalos. This effect couples naturally to SIDM-induced diversity, introducing a\nnew mechanism for generating structural variations beyond those arising from\ngravothermal evolution alone. Our results reveal a novel mechanism for\nreconciling SIDM with small-scale observational tensions by enabling shifts in\ncentral densities while preserving the flexibility to generate diverse halo\nstructures. We further highlight that halo structural diversity may serve as a\ndiagnostic of dark sector composition, opening a new observational window into\nthe particle nature of SIDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-03T06:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.02322v1","title":"Distributed Log-driven Anomaly Detection System based on Evolving\n  Decision Making","summary":"Effective anomaly detection from logs is crucial for enhancing cybersecurity\ndefenses by enabling the early identification of threats. Despite advances in\nanomaly detection, existing systems often fall short in areas such as\npost-detection validation, scalability, and effective maintenance. These\nlimitations not only hinder the detection of new threats but also impair\noverall system performance. To address these challenges, we propose CEDLog, a\nnovel practical framework that integrates Elastic Weight Consolidation (EWC)\nfor continual learning and implements distributed computing for scalable\nprocessing by integrating Apache Airflow and Dask. In CEDLog, anomalies are\ndetected through the synthesis of Multi-layer Perceptron (MLP) and Graph\nConvolutional Networks (GCNs) using critical features present in event logs.\nThrough comparisons with update strategies on large-scale datasets, we\ndemonstrate the strengths of CEDLog, showcasing efficient updates and low false\npositives","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T06:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.02334v1","title":"Determining Sphere Radius through Pairwise Distances","summary":"We propose a novel method for determining the radius of a spherical surface\nbased on the distances measured between points on this surface. We consider the\nmost general case of determining the radius when the distances are measured\nwith errors and the sphere has random deviations from its ideal shape. For the\nsolution, we used the minimally necessary four points and an arbitrary N number\nof points. We provide a new closed form solution for the radius of the sphere\nthrough the matrix of pairwise distances. We also determine the standard\ndeviation of the radius estimate caused by measurement errors and deviations of\nthe sphere from its ideal shape. We found optimal configurations of points on\nthe sphere that provide the minimum standard deviation of the radius estimate.\nThis paper describes our solution and provides all the mathematical\nderivations. We share the implementation of our method as open source code at\nhttps://github.com/boris-sukhovilov/Sphere_Radius.","main_category":"cs.CG","categories":"cs.CG,cs.CV","published":"2025-04-03T07:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.02369v1","title":"Finding Diverse Solutions in Combinatorial Problems with a Distributive\n  Lattice Structure","summary":"We generalize the polynomial-time solvability of $k$-\\textsc{Diverse Minimum\ns-t Cuts} (De Berg et al., ISAAC'23) to a wider class of combinatorial problems\nwhose solution sets have a distributive lattice structure. We identify three\nstructural conditions that, when met by a problem, ensure that a $k$-sized\nmultiset of maximally-diverse solutions -- measured by the sum of pairwise\nHamming distances -- can be found in polynomial time. We apply this framework\nto obtain polynomial time algorithms for finding diverse minimum $s$-$t$ cuts\nand diverse stable matchings. Moreover, we show that the framework extends to\ntwo other natural measures of diversity. Lastly, we present a simpler\nalgorithmic framework for finding a largest set of pairwise disjoint solutions\nin problems that meet these structural conditions.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-03T08:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.02372v1","title":"Quantum Key Distribution over Complex Networks","summary":"There exist several initiatives worldwide to deploy quantum key distribution\n(QKD) over existing fibre networks and achieve quantum-safe security at large\nscales. To understand the overall QKD network performance, it is required to\ntransition from the analysis of individual links, as done so far, to the\ncharacterization of the network as a whole. In this work, we undertake this\nstudy by embedding QKD protocols on complex networks, which correctly model the\nexisting fiber networks. We focus on networks with trusted nodes and on\ncontinuous-variable (CV) schemes, which have much higher key rates than their\ndiscrete-variable (DV) counterparts. In the effective CV network, however, many\nof the unique properties of complex networks, such as small-worldness and the\npresence of hubs, are lost due to the fast decay of the key rate with physical\ndistance for CV systems. These properties can be restored when considering a\nhybrid network consisting of both CV and DV protocols, achieving at the same\ntime high average rate and inter-connectivity. Our work opens the path to the\nstudy of QKD complex networks in existing infrastructures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,physics.soc-ph","published":"2025-04-03T08:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.02382v1","title":"Benchmark of Segmentation Techniques for Pelvic Fracture in CT and\n  X-ray: Summary of the PENGWIN 2024 Challenge","summary":"The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-03T08:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.02422v1","title":"Applying Space-Group Symmetry to Speed up Hybrid-Functional-Based\n  Calculations with Numerical Atomic Orbitals","summary":"Building upon the efficient implementation of hybrid density functionals\n(HDFs) for large-scale periodic systems within the framework of numerical\natomic orbital bases using the localized resolution of identity (RI) technique,\nwe have developed an algorithm that exploits the space group symmetry in key\noperation steps of HDF calculations, leading to further improvements in two\nways. First, the reduction of $\\mathbf{k}$-points in the Brillouin zone can\nreduce the number of Kohn-Sham equations to be solved. This necessitates the\ncorrect implementation of the rotation relation between the density matrices of\nequivalent $\\mathbf{k}$-points within the representation of atomic orbitals.\nSecond, the reduction of the real-space sector can accelerate the construction\nof the exact-exchange part of the Hamiltonian in real space. We have\nimplemented this algorithm in the ABACUS software interfaced with LibRI, and\ntested its performance for several types of crystal systems with different\nsymmetries. The expected speed-up is achieved in both aspects: the time of\nsolving the Kohn-Sham equations decreases in proportion with the reduction of\n$\\mathbf{k}$-points, while the construction of the Hamiltonian in real space is\nsped up by several times, with the degree of acceleration depending on the size\nand symmetry of the system.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-03T09:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.02435v1","title":"Poisson-Voronoi percolation in higher rank","summary":"We show that the uniqueness thresholds for Poisson-Voronoi percolation in\nsymmetric spaces of connected higher rank semisimple Lie groups with property\n(T) converge to zero in the low-intensity limit. This phenomenon is\nfundamentally different from situations in which Poisson-Voronoi percolation\nhas previously been studied.\n  Our approach builds on a recent breakthrough of Fraczyk, Mellick and Wilkens\n(arXiv:2307.01194) and provides an alternative proof strategy for Gaboriau's\nfixed price problem. As a further application of our result, we give a new\nclass of examples of non-amenable Cayley graphs that admit factor of iid bond\npercolations with a unique infinite cluster and arbitrarily small expected\ndegree, answering a question inspired by Hutchcroft-Pete (Invent. math. 221\n(2020)).}","main_category":"math.PR","categories":"math.PR,math.GR","published":"2025-04-03T09:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.02460v1","title":"Finite steady-state current defies non-Hermitian many-body localization","summary":"Non-Hermitian many-body localization (NH MBL) has emerged as a possible\nscenario for stable localization in open systems, as suggested by spectral\nindicators identifying a putative transition for finite system sizes.\n  In this work, we shift the focus to dynamical probes, specifically the\nsteady-state spin current, to investigate transport properties in a disordered,\nnon-Hermitian XXZ spin chain. Through exact diagonalization for small systems\nand tensor-network methods for larger chains, we demonstrate that the\nsteady-state current remains finite and decays exponentially with disorder\nstrength, showing no evidence of a transition up to disorder values far beyond\nthe previously claimed critical point. Our results reveal a stark discrepancy\nbetween spectral indicators, which suggest localization, and transport\nbehavior, which indicates delocalization. This highlights the importance of\ndynamical observables in characterizing NH MBL and suggests that traditional\nspectral measures may not fully capture the physics of non-Hermitian systems.\n  Additionally, we observe a non-commutativity of limits in system size and\ntime, further complicating the interpretation of finite-size studies. These\nfindings challenge the existence of NH MBL in the studied model and underscore\nthe need for alternative approaches to understand localization in non-Hermitian\nsettings.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,quant-ph","published":"2025-04-03T10:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.02461v1","title":"Am I Being Treated Fairly? A Conceptual Framework for Individuals to\n  Ascertain Fairness","summary":"Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG,cs.MA","published":"2025-04-03T10:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.02466v1","title":"Optimal first-passage times of active Brownian particles under\n  stochastic resetting","summary":"We study the first-passage-time (FPT) properties of an active Brownian\nparticle under stochastic resetting to its initial configuration, comprising\nits position and orientation, to reach an absorbing wall in two dimensions.\nCoupling a perturbative approach for low P\\'eclet numbers, measuring the\nrelative importance of self-propulsion with respect to diffusion, with the\nrenewal framework for the stochastic resetting process, we derive analytical\nexpressions for the survival probability, the FPT probability density, and the\nassociated low-order moments. Depending on their initial orientation, the\nminimal mean FPT for active particles to reach the boundary can both decrease\nand increase relative to the passive counterpart. The associated optimal\nresetting rates depend non-trivially on the initial distance to the boundary\ndue to the intricate interplay of resetting, rotational Brownian noise, and\nactive motion.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-03T10:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.02474v1","title":"Rigid m-percolation in limited-valence gels","summary":"Determining the onset of rigidity in gels is a fundamental challenge with\nsignificant practical implications across different applications.\nLimited-valence, or patchy-particle systems have proven to be a valuable model\nto study the relationship between microscopic interactions and macroscopic\nmechanical properties. It has been suggested that the emergence of rigidity\ncoincides with the formation of an infinitely spanning cluster of particles\nwith at least three bonds. This work explores this hypothesis, its\nimplications, and its broader applicability across a range of system\nparameters, by associating the emergence of rigidity with m-percolation\ntransition for m=3. The properties of m-percolation are developed using a\nmean-field theoretical approach validated with numerical simulations, and used\nto build phase and rigidity diagrams for different particle valences of both\nsingle-component systems and binary mixtures of patchy particles. The\ndifference between connectivity and rigidity percolation thresholds is found to\nreduce with increasing valence, providing an explanation for the challenges\nencountered in experimental attempts to distinguish isotropic connectivity\npercolation from the onset of rigidity. For binary mixtures, we found a robust\nminimum average valence, below which the gel is never rigid.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T10:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.02476v1","title":"Globular cluster distributions as a dynamical probe of dark matter","summary":"Globular clusters (GCs) act as massive probe particles traversing the dark\nmatter halos of their host galaxies. Gravitational dynamical friction due to\nhalo particles causes GC orbits to contract over time, providing a beyond-mean\nfield test of the cold dark matter paradigm. We explore the information content\nof such systems, using N-body and semianalytic simulations and scanning over a\nrange of initial conditions. We consider data from the ultradiffuse galaxies\nNGC5846-UDG1 and UDG-DF44, and from the Fornax dwarf spheroidal galaxy. The GC\nsystems of UDG1 and Fornax indicate the presence of dark matter halos,\nindependent of (but consistent with) stellar kinematics data. UDG-DF44 is too\ndiffuse for dynamical friction to give strong constraints. Our analysis can be\nextended to many additional galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,hep-ph","published":"2025-04-03T10:53:02Z"}
{"aid":"http://arxiv.org/abs/2504.02479v1","title":"Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent\n  Shepherding Control of Non-Cohesive Targets","summary":"We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.MA,cs.SY,eess.SY,stat.ML","published":"2025-04-03T10:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.02504v1","title":"Ethics of Blockchain Technologies","summary":"This chapter explores three key questions in blockchain ethics. First, it\nsituates blockchain ethics within the broader field of technology ethics,\noutlining its goals and guiding principles. Second, it examines the unique\nethical challenges of blockchain applications, including permissionless\nsystems, incentive mechanisms, and privacy concerns. Key obstacles, such as\nconceptual modeling and information asymmetries, are identified as critical\nissues. Finally, the chapter argues that blockchain ethics should be approached\nas an engineering discipline, emphasizing the analysis and design of trade-offs\nin complex systems.","main_category":"cs.CY","categories":"cs.CY,cs.DC","published":"2025-04-03T11:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.02511v1","title":"Analytical Discovery of Manifold with Machine Learning","summary":"Understanding low-dimensional structures within high-dimensional data is\ncrucial for visualization, interpretation, and denoising in complex datasets.\nDespite the advancements in manifold learning techniques, key challenges-such\nas limited global insight and the lack of interpretable analytical\ndescriptions-remain unresolved. In this work, we introduce a novel framework,\nGAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs\na two-round training process within an auto-encoding framework to derive both\ncharacter and complementary representations for the underlying manifold. With\nthe character representation, the manifold is represented by a parametric\nfunction which unfold the manifold to provide a global coordinate. While with\nthe complementary representation, an approximate explicit manifold description\nis developed, offering a global and analytical representation of smooth\nmanifolds underlying high-dimensional datasets. This enables the analytical\nderivation of geometric properties such as curvature and normal vectors.\nMoreover, we find the two representations together decompose the whole latent\nspace and can thus characterize the local spatial structure surrounding the\nmanifold, proving particularly effective in anomaly detection and\ncategorization. Through extensive experiments on benchmark datasets and\nreal-world applications, GAMLA demonstrates its ability to achieve\ncomputational efficiency and interpretability while providing precise geometric\nand structural insights. This framework bridges the gap between data-driven\nmanifold learning and analytical geometry, presenting a versatile tool for\nexploring the intrinsic properties of complex data sets.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T11:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.02519v1","title":"Data-Driven Object Tracking: Integrating Modular Neural Networks into a\n  Kalman Framework","summary":"This paper presents novel Machine Learning (ML) methodologies for\nMulti-Object Tracking (MOT), specifically designed to meet the increasing\ncomplexity and precision demands of Advanced Driver Assistance Systems (ADAS).\nWe introduce three Neural Network (NN) models that address key challenges in\nMOT: (i) the Single-Prediction Network (SPENT) for trajectory prediction, (ii)\nthe Single-Association Network (SANT) for mapping individual Sensor Object (SO)\nto existing tracks, and (iii) the Multi-Association Network (MANTa) for\nassociating multiple SOs to multiple tracks. These models are seamlessly\nintegrated into a traditional Kalman Filter (KF) framework, maintaining the\nsystem's modularity by replacing relevant components without disrupting the\noverall architecture. Importantly, all three networks are designed to be run in\na realtime, embedded environment. Each network contains less than 50k trainable\nparameters. Our evaluation, conducted on the public KITTI tracking dataset,\ndemonstrates significant improvements in tracking performance. SPENT reduces\nthe Root Mean Square Error (RMSE) by 50% compared to a standard KF, while SANT\nand MANTa achieve up to 95% accuracy in sensor object-to-track assignments.\nThese results underscore the effectiveness of incorporating task-specific NNs\ninto traditional tracking systems, boosting performance and robustness while\npreserving modularity, maintainability, and interpretability.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T12:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.02540v1","title":"A 3D-1D-0D Multiscale Model of the Neuro-Glial-Vascular Unit for\n  Synaptic and Vascular Dynamics in the Dorsal Vagal Complex","summary":"Cerebral blood flow regulation is critical for brain function, and its\ndisruption is implicated in various neurological disorders. Many existing\nmodels do not fully capture the complex, multiscale interactions among neuronal\nactivity, astrocytic signaling, and vascular dynamics--especially in key\nbrainstem regions. In this work, we present a 3D-1D-0D multiscale computational\nframework for modeling the neuro-glial-vascular unit (NGVU) in the dorsal vagal\ncomplex (DVC). Our approach integrates a quadripartite synapse model--which\nrepresents the interplay among excitatory and inhibitory neurons, astrocytes,\nand vascular smooth muscle cells--with a hierarchical description of vascular\ndynamics that couples a three-dimensional microcirculatory network with a\none-dimensional macrocirculatory representation and a zero-dimensional synaptic\ncomponent. By linking neuronal spiking, astrocytic calcium and gliotransmitter\nsignaling, and vascular tone regulation, our model reproduces key features of\nfunctional hyperemia and elucidates the feedback loops that help maintain\ncerebral blood flow. Simulation results demonstrate that neurotransmitter\nrelease triggers astrocytic responses that modulate vessel radius to optimize\noxygen and nutrient delivery. This integrated framework, to our knowledge the\nfirst model to combine these elements for the NGVU in the DVC, provides a\nrobust and modular platform for future investigations into the pathophysiology\nof cerebral blood flow regulation and its role in autonomic control, including\nthe regulation of stomach function.","main_category":"q-bio.TO","categories":"q-bio.TO","published":"2025-04-03T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.02568v1","title":"Enhanced coherent terahertz emission from critical superconducting\n  fluctuations in YBa$_2$Cu$_3$O$_{6.6}$","summary":"Coherent terahertz (THz) emission is emerging as a powerful new tool to probe\nsymmetry breakings in quantum materials. This method relies on second order\noptical nonlinearities and is complementary to second harmonic generation\nspectroscopy. Here, we report coherent THz emission from Josephson plasmons in\nunderdoped YBa$_2$Cu$_3$O$_{6+x}$, and find that the amplitude of the emitted\nfield increases dramatically close to the superconducting transition\ntemperature, $T_C$. We show theoretically how emission is enhanced by critical\nsuperconducting fluctuations, a nonlinear analogue of critical opalescence.\nThis observation is expected to be of general importance for the study of many\nthermal and quantum phase transitions.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-03T13:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.02582v1","title":"Ambiguity Function Analysis of Affine Frequency Division Multiplexing\n  for Integrated Sensing and Communication","summary":"Affine frequency division multiplexing (AFDM) is a chirp-based multicarrier\nwaveform that was recently proposed for communication over doubly dispersive\nchannels. Given its chirp nature, AFDM is expected to have superior sensing\ncapabilities compared to orthogonal frequency division multiplexing (OFDM) and\nis thus a promising candidate for integrated sensing and communication (ISAC)\napplications. In this paper, we derive a closed-form expression for the\nambiguity function of AFDM waveforms modulated with $M$-ary quadrature\namplitude modulation (QAM) data symbols. We determine the condition on the\nchirp rate of the AFDM waveform that minimizes the sidelobes in the delay/range\ndomain in the presence of random $M$-ary QAM symbols, thereby improving overall\nsensing performance. Additionally, we find an approximate statistical\ndistribution for the magnitude of the derived ambiguity function. Simulation\nresults are presented to evaluate the sensing performance of the AFDM waveform\nfor various system parameters and to compare its peak-to-sidelobe ratio (PSLR)\nand integrated sidelobe ratio (ISLR) with those of OFDM.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T13:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.02598v1","title":"Graphs are everywhere -- Psst! In Music Recommendation too","summary":"In recent years, graphs have gained prominence across various domains,\nespecially in recommendation systems. Within the realm of music recommendation,\ngraphs play a crucial role in enhancing genre-based recommendations by\nintegrating Mel-Frequency Cepstral Coefficients (MFCC) with advanced graph\nembeddings. This study explores the efficacy of Graph Convolutional Networks\n(GCN), GraphSAGE, and Graph Transformer (GT) models in learning embeddings that\neffectively capture intricate relationships between music items and genres\nrepresented within graph structures. Through comprehensive empirical\nevaluations on diverse real-world music datasets, our findings consistently\ndemonstrate that these graph-based approaches outperform traditional methods\nthat rely solely on MFCC features or collaborative filtering techniques.\nSpecifically, the graph-enhanced models achieve notably higher accuracy in\npredicting genre-specific preferences and offering relevant music suggestions\nto users. These results underscore the effectiveness of utilizing graph\nembeddings to enrich feature representations and exploit latent associations\nwithin music data, thereby illustrating their potential to advance the\ncapabilities of personalized and context-aware music recommendation systems.\nKeywords: graphs, recommendation systems, neural networks, MFCC","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T14:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.02602v1","title":"Leveraging Sparse Annotations for Leukemia Diagnosis on the Large\n  Leukemia Dataset","summary":"Leukemia is 10th most frequently diagnosed cancer and one of the leading\ncauses of cancer related deaths worldwide. Realistic analysis of Leukemia\nrequires White Blook Cells (WBC) localization, classification, and\nmorphological assessment. Despite deep learning advances in medical imaging,\nleukemia analysis lacks a large, diverse multi-task dataset, while existing\nsmall datasets lack domain diversity, limiting real world applicability. To\novercome dataset challenges, we present a large scale WBC dataset named Large\nLeukemia Dataset (LLD) and novel methods for detecting WBC with their\nattributes. Our contribution here is threefold. First, we present a large-scale\nLeukemia dataset collected through Peripheral Blood Films (PBF) from several\npatients, through multiple microscopes, multi cameras, and multi magnification.\nTo enhance diagnosis explainability and medical expert acceptance, each\nleukemia cell is annotated at 100x with 7 morphological attributes, ranging\nfrom Cell Size to Nuclear Shape. Secondly, we propose a multi task model that\nnot only detects WBCs but also predicts their attributes, providing an\ninterpretable and clinically meaningful solution. Third, we propose a method\nfor WBC detection with attribute analysis using sparse annotations. This\napproach reduces the annotation burden on hematologists, requiring them to mark\nonly a small area within the field of view. Our method enables the model to\nleverage the entire field of view rather than just the annotated regions,\nenhancing learning efficiency and diagnostic accuracy. From diagnosis\nexplainability to overcoming domain shift challenges, presented datasets could\nbe used for many challenging aspects of microscopic image analysis. The\ndatasets, code, and demo are available at:\nhttps://im.itu.edu.pk/sparse-leukemiaattri/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.02608v1","title":"Input to the European Strategy for Particle Physics: Strong-Field\n  Quantum Electrodynamics","summary":"This document sets out the intention of the strong-field QED community to\ncarry out, both experimentally and numerically, high-statistics parametric\nstudies of quantum electrodynamics in the non-perturbative regime, at fields\napproaching and exceeding the critical or `Schwinger' field of QED. In this\nregime, several exotic and fascinating phenomena are predicted to occur that\nhave never been directly observed in the laboratory. These include\nBreit-Wheeler pair production, vacuum birefringence, and quantum radiation\nreaction. This experimental program will also serve as a stepping stone towards\nstudies of elusive phenomena such as elastic scattering of real photons and the\nconjectured perturbative breakdown of QED at extreme fields. State-of-the-art\nhigh-power laser facilities in Europe and beyond are starting to offer unique\nopportunities to study this uncharted regime at the intensity frontier, which\nis highly relevant also for the design of future multi-TeV lepton colliders.\nHowever, a transition from qualitative observational experiments to\nquantitative and high-statistics measurements can only be performed with\nlarge-scale collaborations and with systematic experimental programs devoted to\nthe optimisation of several aspects of these complex experiments, including\ndetector developments, stability and tolerances studies, and laser technology.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T14:10:23Z"}
{"aid":"http://arxiv.org/abs/2504.02610v1","title":"Do evidence-based active-engagement courses reduce the gender gap in\n  introductory physics?","summary":"Prior research suggests that using evidence-based pedagogies can not only\nimprove learning for all students, it can also reduce the gender gap. We\ndescribe the impact of physics education research based pedagogical techniques\nin flipped and active-engagement non-flipped courses on the gender gap observed\nwith validated conceptual surveys. We compare male and female students'\nperformance in courses which make significant use of evidence-based active\nengagement (EBAE) strategies with courses that primarily use lecture-based (LB)\ninstruction. The analysis presented here includes data from two-semester\nsequences of introductory algebra-based and calculus-based introductory physics\ncourses. The surveys used to assess student learning in the first and second\nsemester courses were the Force Concept Inventory and the Conceptual Survey of\nElectricity and Magnetism, respectively. The performance of male and female\nstudents in EBAE courses at a particular level is compared with LB courses in\ntwo situations: (I) the same instructor taught two courses, one of which was an\nEBAE course and the other an LB course, while the homework, recitations and\nfinal exams were kept the same, (II) student performance in all of the EBAE\ncourses taught by different instructors was averaged and compared with LB\ncourses of the same type also averaged over different instructors. In all\ncases, we find that students in courses which make significant use of EBAE\nstrategies, on average, outperformed students in courses of the same type using\nprimarily LB instruction even though there was no statistically significant\ndifference on the pretest before instruction. However, the gender gap persisted\neven in courses using EBAE methods. We also discuss correlations between the\nperformance of male and female students on the validated conceptual surveys and\nthe final exam, which had a heavy weight on quantitative problem solving.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.02639v1","title":"Reservoir Computing: A New Paradigm for Neural Networks","summary":"A Literature Review of Reservoir Computing.\n  Even before Artificial Intelligence was its own field of computational\nscience, humanity has tried to mimic the activity of the human brain. In the\nearly 1940s the first artificial neuron models were created as purely\nmathematical concepts. Over the years, ideas from neuroscience and computer\nscience were used to develop the modern Neural Network. The interest in these\nmodels rose quickly but fell when they failed to be successfully applied to\npractical applications, and rose again in the late 2000s with the drastic\nincrease in computing power, notably in the field of natural language\nprocessing, for example with the state-of-the-art speech recognizer making\nheavy use of deep neural networks.\n  Recurrent Neural Networks (RNNs), a class of neural networks with cycles in\nthe network, exacerbates the difficulties of traditional neural nets. Slow\nconvergence limiting the use to small networks, and difficulty to train through\ngradient-descent methods because of the recurrent dynamics have hindered\nresearch on RNNs, yet their biological plausibility and their capability to\nmodel dynamical systems over simple functions makes then interesting for\ncomputational researchers.\n  Reservoir Computing emerges as a solution to these problems that RNNs\ntraditionally face. Promising to be both theoretically sound and\ncomputationally fast, Reservoir Computing has already been applied successfully\nto numerous fields: natural language processing, computational biology and\nneuroscience, robotics, even physics. This survey will explore the history and\nappeal of both traditional feed-forward and recurrent neural networks, before\ndescribing the theory and models of this new reservoir computing paradigm.\nFinally recent papers using reservoir computing in a variety of scientific\nfields will be reviewed.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.02646v1","title":"Prompt Optimization with Logged Bandit Data","summary":"We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-03T14:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.02681v1","title":"Convergence of permuted products of exponentials","summary":"Let $\\{A_{i,n}\\}$ be a triangular array of elements in a Banach algebra,\nwhose norms do not grow too fast, and whose row averages converge to $A$. Let\n$\\sigma \\in S(n)$ be a permutation drawn uniformly at random. If the array only\ncontains $o(n / \\log n)$ distinct elements, then almost surely, for all $0 < s\n< t < 1$, the permuted product of their exponentials $\\prod_{i = [s n]}^{[t n]}\ne^{A_{\\sigma(i),n}/n}$ converges in norm to $e^{(t - s) A}$. For an array of\nfinite-dimensional matrices, convergence holds without this restriction. The\nproof of the latter result consists of an estimate valid in a general Banach\nalgebra, and an application of a matrix concentration inequality.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-03T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02684v1","title":"High Chern numbers and topological flat bands in high-field polarized\n  Kitaev magnets on the star lattice","summary":"The geometrically frustrated Kitaev magnets are demonstrated to be fertile\nplaygrounds that allow for the occurrence of exotic phenomena, including\ntopological phases and the thermal Hall effect. Notwithstanding the established\nconsensus that the field-polarized phase in the honeycomb-lattice Kitaev magnet\nhosts topological magnons exhibiting Chern numbers $C = \\pm1$, the nature of\nmagnon excitations in Kitaev magnets on the star lattice, a triangle-decorated\nhoneycomb lattice, has rarely been explored primarily due to its complicated\ngeometry. To this end, we study the band topology of magnons on the star\nlattice in the presence of a strong out-of-plane magnetic field using linear\nspin-wave theory. By calculating the Chern numbers of magnon bands, we find\nthat topological phase diagrams are predominantly composed of two distinct\ntopological phases whose Chern numbers are different by a sign in inverse\norder. Remarkably, each phase is characterized by a high Chern number of either\n$+2$ or $-2$. In addition, several topological flat bands with large flatness\nare identified. The two phases are separated by a dozen narrow topological\nhigh-Chern-number segments, whose region shrinks as the magnetic field\nincreases and vanishes eventually. We also find that the thermal Hall\nconductivity approaches zero at certain parameters, and it changes (keeps) its\nsign when crossing the topological phase-transition points (flat-band points).","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T15:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.02741v1","title":"A Complete Classification of Fourier Summation Formulas on the real line","summary":"We completely classify Fourier summation formulas of the form $$\n  \\int_{\\mathbb{R}} \\widehat{\\varphi}(t) d\\mu(t)=\\sum_{n=0}^{\\infty}\na(\\lambda_n)\\varphi(\\lambda_n), $$ that hold for any test function $\\varphi$,\nwhere $\\widehat\\varphi$ is the Fourier transform of $\\varphi$, $\\mu$ is a fixed\ncomplex measure on $\\mathbb{R}$ and $a:\\{\\lambda_n\\}_{n\\geq 0}\\to\\mathbb{C}$ is\na fixed function. We only assume the decay condition $$ \\int_{\\mathbb{R}}\n\\frac{d |\\mu|(t)}{(1+t^2)^{c_1}} + \\sum_{n\\geq 0} |a(\\lambda_n)|e^{-c_2\n|\\lambda_n|}<\\infty, $$ for some $c_1,c_2>0$. This completes the work initiated\nby the first author previously, where the condition $c_1\\leq 1$ was required.\nWe prove that any such pair $(\\mu,a)$ can be uniquely associated with a\nholomorphic map $F(z)$ in the upper-half space that is both almost periodic and\nbelongs to a certain higher index Nevanlinna class. The converse is also true:\nFor any such function $F$ it is possible to generate a Fourier summation pair\n$(\\mu,a)$. We provide important examples of such summation formulas not\ncontemplated by the previous results, such as Selberg's trace formula.","main_category":"math.CA","categories":"math.CA,math.MG,math.NT","published":"2025-04-03T16:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.02747v1","title":"GEOPARD: Geometric Pretraining for Articulation Prediction in 3D Shapes","summary":"We present GEOPARD, a transformer-based architecture for predicting\narticulation from a single static snapshot of a 3D shape. The key idea of our\nmethod is a pretraining strategy that allows our transformer to learn plausible\ncandidate articulations for 3D shapes based on a geometric-driven search\nwithout manual articulation annotation. The search automatically discovers\nphysically valid part motions that do not cause detachments or collisions with\nother shape parts. Our experiments indicate that this geometric pretraining\nstrategy, along with carefully designed choices in our transformer\narchitecture, yields state-of-the-art results in articulation inference in the\nPartNet-Mobility dataset.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-03T16:35:17Z"}
{"aid":"http://arxiv.org/abs/2504.02753v1","title":"Robust entangled photon generation by Floquet-engineered two-colour\n  pulses","summary":"Quantum emitters driven by resonant two-photon excitation are a leading\nsource for deterministically generated entangled photon pairs, essential for\nscalable photonic quantum technologies. However, conventional resonant schemes\nare highly sensitive to laser power fluctuations and pose additional\nexperimental challenges for emitters with small biexciton binding energies.\nHere, we demonstrate how biexciton preparation schemes with significantly\nimproved robustness and reduced laser filtering requirements can be identified\nusing a novel design principle beyond resonant and adiabatic driving: ultrafast\nall-optical Floquet engineering. This is achieved by employing two strongly and\nsymmetrically detuned dichromatic pulses, whose superposition generates a\nstroboscopic Hamiltonian that enables direct coupling between ground and\nbiexciton states. Moreover, a pulse delay serves as a tuning knob, introducing\nan effective magnetic field that concentrates the Bloch sphere trajectory at\nthe biexciton state for a wide range of parameters, making biexciton\npreparation particularly robust. Experimentally, we achieve a biexciton\noccupation exceeding 96% and preserve photon-pair entanglement with a fidelity\nof 93.4%. Our scheme highlights the great impact of Floquet-engineered\nmulticolour excitation protocols for on-demand quantum light sources.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-03T16:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.02757v1","title":"Echoes of the hidden: Uncovering coordination beyond network structure","summary":"The study of connectivity and coordination has drawn increasing attention in\nrecent decades due to their central role in driving markets, shaping societal\ndynamics, and influencing biological systems. Traditionally, observable\nconnections, such as phone calls, financial transactions, or social media\nconnections, have been used to infer coordination and connectivity. However,\nincomplete, encrypted, or fragmented data, alongside the ubiquity of\ncommunication platforms and deliberate obfuscation, often leave many real-world\nconnections hidden. In this study, we demonstrate that coordinating individuals\nexhibit shared bursty activity patterns, enabling their detection even when\nobservable links between them are sparse or entirely absent. We further propose\na generative model based on the network of networks formalism to account for\nthe mechanisms driving this collaborative burstiness, attributing it to shock\npropagation across networks rather than isolated individual behavior. Model\nsimulations demonstrate that when observable connection density is below 70\\%,\nburstiness significantly improves coordination detection compared to\nstate-of-the-art temporal and structural methods. This work provides a new\nperspective on community and coordination dynamics, advancing both theoretical\nunderstanding and practical detection. By laying the foundation for identifying\nhidden connections beyond observable network structures, it enables detection\nacross different platforms, alongside enhancing system behavior understanding,\ninformed decision-making, and risk mitigation.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-03T16:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.02785v1","title":"Beating full state tomography for unentangled spectrum estimation","summary":"How many copies of a mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$ are\nneeded to learn its spectrum? To date, the best known algorithms for spectrum\nestimation require as many copies as full state tomography, suggesting the\npossibility that learning a state's spectrum might be as difficult as learning\nthe entire state. We show that this is not the case in the setting of\nunentangled measurements, by giving a spectrum estimation algorithm that uses\n$n = O(d^3\\cdot (\\log\\log(d) / \\log(d))^4 )$ copies of $\\rho$, which is\nasymptotically fewer than the $n = \\Omega(d^3)$ copies necessary for full state\ntomography. Our algorithm is inspired by the technique of local moment matching\nfrom classical statistics, and shows how it can be applied in the quantum\nsetting.\n  As an important subroutine in our spectrum estimation algorithm, we give an\nestimator of the $k$-th moment $\\operatorname{tr}(\\rho^k)$ which performs\nunentangled measurements and uses $O(d^{3-2/k})$ copies of $\\rho$ in order to\nachieve a constant multiplicative error. This directly translates to an\nadditive-error estimator of quantum Renyi entropy of order $k$ with the same\nnumber of copies.\n  Finally, we present numerical evidence that the sample complexity of spectrum\nestimation can only improve over full state tomography by a sub-polynomial\nfactor. Specifically, for spectrum learning with fully entangled measurements,\nwe run simulations which suggest a lower bound of $\\Omega(d^{2 - \\gamma})$\ncopies for any constant $\\gamma > 0$. From this, we conclude the current best\nlower bound of $\\Omega(d)$ is likely not tight.","main_category":"quant-ph","categories":"quant-ph,cs.CC,cs.DS","published":"2025-04-03T17:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.02796v1","title":"Suppression of decoherence dynamics by a dissipative bath at strong\n  coupling","summary":"Control of decoherence in open quantum systems has become a topic of great\ninterest due to the emergence of quantum technologies that depend on quantum\ncoherent effects. In this work, we investigate the decoherence dynamics of\nsystems coupled to multiple baths through noncommuting systems' operators, and\nbeyond the weak system-bath coupling limit. By building on cooperative effects\nbetween baths, we propose a novel strategy to mitigate rapid decoherence.\nConcretely, we study the dynamics of a qubit coupled to multiple environments\nwith arbitrary interaction strengths, and along different coordinates. Based on\ninsights gained on the decoherence dynamics from the analytical Effective\nHamiltonian method, we carry out numerical simulations using the Reaction\nCoordinate quantum master equation method. In contrast to standard\nexpectations, we show that when the system strongly interacts with a decohering\nbath, increasing its coupling to a second, dissipative bath slows down the\ndecoherence dynamics. Our work offers insights into the preservation of quantum\ncoherences in open quantum systems based on frustration effects, by utilizing\ncooperative effects between different heat baths.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T17:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.02803v1","title":"Beyond Discretization: A Continuous-Time Framework for Event Generation\n  in Neuromorphic Pixels","summary":"A novel continuous-time framework is proposed for modeling neuromorphic image\nsensors in the form of an initial canonical representation with analytical\ntractability. Exact simulation algorithms are developed in parallel with\nclosed-form expressions that characterize the model's dynamics. This framework\nenables the generation of synthetic event streams in genuine continuous-time,\nwhich combined with the analytical results, reveal the underlying mechanisms\ndriving the oscillatory behavior of event data presented in the literature.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T17:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.02804v1","title":"Convergence of Ricci flow and long-time existence of Harmonic map heat\n  flow","summary":"For an ancient Ricci flow asymptotic to a compact integrable shrinker, or a\nRicci flow developing a finite-time singularity modelled on the shrinker, we\nestablish the long-time existence of a harmonic map heat flow between the Ricci\nflow and the shrinker for all times. This provides a global parabolic gauge for\nthe Ricci flow and implies the uniqueness of the tangent flow without modulo\nany diffeomorphisms.\n  We present two main applications: First, we construct and classify all\nancient Ricci flows asymptotic to any compact integrable shrinker, showing that\nthey converge exponentially. Second, we obtain the optimal convergence rate at\nsingularities modelled on the shrinker, characterized by the first negative\neigenvalue of the stability operator for the entropy. In particular, we show\nthat any Ricci flow developing a round $\\mathbb S^n$ singularity converges at\nleast at the rate $(-t)^{\\frac{n+1}{n-1}}$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-03T17:50:14Z"}
{"aid":"http://arxiv.org/abs/2504.04747v1","title":"Two is Better than One: Efficient Ensemble Defense for Robust and\n  Compact Models","summary":"Deep learning-based computer vision systems adopt complex and large\narchitectures to improve performance, yet they face challenges in deployment on\nresource-constrained mobile and edge devices. To address this issue, model\ncompression techniques such as pruning, quantization, and matrix factorization\nhave been proposed; however, these compressed models are often highly\nvulnerable to adversarial attacks. We introduce the \\textbf{Efficient Ensemble\nDefense (EED)} technique, which diversifies the compression of a single base\nmodel based on different pruning importance scores and enhances ensemble\ndiversity to achieve high adversarial robustness and resource efficiency. EED\ndynamically determines the number of necessary sub-models during the inference\nstage, minimizing unnecessary computations while maintaining high robustness.\nOn the CIFAR-10 and SVHN datasets, EED demonstrated state-of-the-art robustness\nperformance compared to existing adversarial pruning techniques, along with an\ninference speed improvement of up to 1.86 times. This proves that EED is a\npowerful defense solution in resource-constrained environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.04774v1","title":"BayesCPF: Enabling Collective Perception in Robot Swarms with Degrading\n  Sensors","summary":"The collective perception problem -- where a group of robots perceives its\nsurroundings and comes to a consensus on an environmental state -- is a\nfundamental problem in swarm robotics. Past works studying collective\nperception use either an entire robot swarm with perfect sensing or a swarm\nwith only a handful of malfunctioning members. A related study proposed an\nalgorithm that does account for an entire swarm of unreliable robots but\nassumes that the sensor faults are known and remain constant over time. To that\nend, we build on that study by proposing the Bayes Collective Perception Filter\n(BayesCPF) that enables robots with continuously degrading sensors to\naccurately estimate the fill ratio -- the rate at which an environmental\nfeature occurs. Our main contribution is the Extended Kalman Filter within the\nBayesCPF, which helps swarm robots calibrate for their time-varying sensor\ndegradation. We validate our method across different degradation models,\ninitial conditions, and environments in simulated and physical experiments. Our\nfindings show that, regardless of degradation model assumptions, fill ratio\nestimation using the BayesCPF is competitive to the case if the true sensor\naccuracy is known, especially when assumptions regarding the model and initial\nsensor accuracy levels are preserved.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T07:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.04820v1","title":"Dark energy under a gauge symmetry: A review of gauged quintessence and\n  its implications","summary":"We review the gauged quintessence scenario, wherein the quintessence scalar\nfield responsible for dark energy is promoted to a complex field charged under\na dark $U(1)$ gauge symmetry. This construction leads to new and potentially\nrich cosmological phenomenology. After a concise recap of the standard\nquintessence scenario, we highlight how a $U(1)$ gauge invariance alters the\ndynamics of the scalar and the associated dark gauge boson. We survey the\nevolution of both fields across cosmic history, discuss their possible\nproduction via a misalignment mechanism, and examine implications for the\nHubble tension. We also comment on potential non-gravitational signals of\ngauged quintessence through kinetic mixing (the dark photon vector portal).","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-07T08:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.04822v1","title":"How to build transfer matrices, one wave at a time","summary":"We show how to build the closed-form expression of transfer matrices for wave\npropagation in layered media. The key is to represent the propagation across\nthe piece-wise constant medium as a superposition of a finite number of paths\n($2^{N-1}$ paths for a medium with $N$ layers), each one of them contributing a\ncertain phase change (corresponding to signed sums of the phase change in each\nindividual layer) and amplitude change (corresponding to the pattern of\ntransmission and/or reflection associated to each path). The outlined technique\nis combinatorial in nature: it begins with the linear governing equations in\nfrequency domain, whose fundamental solution is known, then it enumerates the\nfinite number of paths across the overall system, then computes their\nassociated phase and amplitude change, and finally adds all the possible paths\nto find the final result. Beyond providing physical insight, this\n``path-by-path'' construction can also circumvent the need for transfer matrix\nnumerical multiplication in many practical applications, potentially enabling\nsubstantial computational savings.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cond-mat.other","published":"2025-04-07T08:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.04830v1","title":"X-ray particle tracking velocimetry for rheological characterization:\n  Application to material extrusion additive manufacturing","summary":"We introduce X-ray Particle Tracking Velocimetry (XPTV) as a promising method\nto quantitatively resolve the velocity field and associated rheological\nquantities of polymer melt flow within the nozzle of a fused filament\nfabrication (FFF) printer. Employing tungsten powder as tracer particles\nembedded within a polymer filament, we investigate melt flow dynamics through\nan aluminum nozzle in a custom-designed experimental setup, based on commercial\ndesigns. The velocity profiles obtained via XPTV reveal significant deviations\nfrom classical Newtonian flow, highlighting complex heterogeneous and\nnon-isothermal behavior within the melt. From these measurements, we determine\nthe local infinitesimal strain rate tensor and correlate flow-induced\nnon-Newtonian effects to spatially varying temperature distributions,\nreflecting incomplete thermal homogenization within the nozzle. Our findings\ndemonstrate the capability of XPTV to quantify both velocity fields and\nrheological properties, underscoring its potential as a future tool for\ninvestigating opaque polymer melt flows in additive manufacturing, industrial\nprocessing, and rheology. To our knowledge, this represents the first reported\napplication of XPTV in polymer melt rheology, offering a new approach to\naddress measurement challenges previously inaccessible to conventional optical\nmethods.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-07T08:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.04838v1","title":"Palatable pellets -- a fundamental framework to produce sustainable\n  pellets via extrusion","summary":"In pellet manufacturing various ingredients in powder or particle form are\npressed together into a dense product, a pellet, with better nutritional,\ncalorific, and handling properties than the individual input ingredients\nthemselves. For this reason, pellet manufacturing is applied to up-convert\nindustrial co-products from various sectors like agriculture, forestry, human\nfood, or bio-energy production, to valorize their waste-streams into more\nvaluable products. However, processing such diverse ingredient streams presents\nan industrial challenge and raises the important scientific question: \"Under\nwhich process conditions do loose pellet ingredients bind together to form a\nmechanically rigid and durable pellet?\" In this work we provide new answers to\nthis old research question by determining the causal relationships between\nprocessing parameters and physical pellet quality. Systematic pelleting\nexperiments reveal that the interplay of typical process parameters such as\nsteam conditioning temperature, production rate, and die geometry, can be\nunderstood in an overarching framework of process interactions. We introduce\nthe concept of the \"stickiness temperature,\" $\\mathrm{T^*}$, marking the onset\nof critical enthalpic reactions necessary for pellet agglomeration, the\nboundary condition for bond formation within a pellet. Our framework\ndemonstrates how $T^*$ is achieved through a combination of steam conditioning\nand friction, and how these conditions can be controlled by adjusting process\nparameters. Our findings underscore the significance of pellet temperature in\nconjunction with die residence time, for optimizing physical pellet quality\nwhile reducing energy consumption per kilogram of product. Validating our\nresults in a trial and leveraging existing literature data, our framework\nprovides handles to intelligently enhance the efficiency and sustainability of\npelleting processes.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T08:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.04840v1","title":"Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning\n  via Gaze Consensus Adaptation","summary":"Even from an early age, humans naturally adapt between exocentric (Exo) and\negocentric (Ego) perspectives to understand daily procedural activities.\nInspired by this cognitive ability, in this paper, we propose a novel\nUnsupervised Ego-Exo Adaptation for Dense Video Captioning (UEA-DVC) task,\nwhich aims to predict the time segments and descriptions for target view\nvideos, while only the source view data are labeled during training. Despite\nprevious works endeavoring to address the fully-supervised single-view or\ncross-view dense video captioning, they lapse in the proposed unsupervised task\ndue to the significant inter-view gap caused by temporal misalignment and\nirrelevant object interference. Hence, we propose a Gaze Consensus-guided\nEgo-Exo Adaptation Network (GCEAN) that injects the gaze information into the\nlearned representations for the fine-grained alignment between the Ego and Exo\nviews. Specifically, the Score-based Adversarial Learning Module (SALM)\nincorporates a discriminative scoring network to learn unified view-invariant\nrepresentations for bridging distinct views from a global level. Then, the Gaze\nConsensus Construction Module (GCCM) utilizes gaze representations to\nprogressively calibrate the learned global view-invariant representations for\nextracting the video temporal contexts based on focusing regions. Moreover, the\ngaze consensus is constructed via hierarchical gaze-guided consistency losses\nto spatially and temporally align the source and target views. To support our\nresearch, we propose a new EgoMe-UEA-DVC benchmark and experiments demonstrate\nthe effectiveness of our method, which outperforms many related methods by a\nlarge margin. The code will be released.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-07T08:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.04856v1","title":"Approach to optimal quantum transport via states over time","summary":"We approach the problem of constructing a quantum analogue of the immensely\nfruitful classical transport cost theory of Monge from a new angle. Going back\nto the original motivations, by which the transport is a bilinear function of a\nmass distribution (without loss of generality a probability density) and a\ntransport plan (a stochastic kernel), we explore the quantum version where the\nmass distribution is generalised to a density matrix, and the transport plan to\na completely positive and trace preserving map.\n  These two data are naturally integrated into their Jordan product, which is\ncalled state over time (``stote''), and the transport cost is postulated to be\na linear function of it.\n  We explore the properties of this transport cost, as well as the optimal\ntransport cost between two given states (simply the minimum cost over all\nsuitable transport plans). After that, we analyse in considerable detail the\ncase of unitary invariant cost, for which we can calculate many costs\nanalytically. These findings suggest that our quantum transport cost is\nqualitatively different from Monge's classical transport.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-07T09:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.04891v1","title":"Leveraging Large Language Models for Cost-Effective, Multilingual\n  Depression Detection and Severity Assessment","summary":"Depression is a prevalent mental health disorder that is difficult to detect\nearly due to subjective symptom assessments. Recent advancements in large\nlanguage models have offered efficient and cost-effective approaches for this\nobjective. In this study, we evaluated the performance of four LLMs in\ndepression detection using clinical interview data. We selected the best\nperforming model and further tested it in the severity evaluation scenario and\nknowledge enhanced scenario. The robustness was evaluated in complex diagnostic\nscenarios using a dataset comprising 51074 statements from six different mental\ndisorders. We found that DeepSeek V3 is the most reliable and cost-effective\nmodel for depression detection, performing well in both zero-shot and few-shot\nscenarios, with zero-shot being the most efficient choice. The evaluation of\nseverity showed low agreement with the human evaluator, particularly for mild\ndepression. The model maintains stably high AUCs for detecting depression in\ncomplex diagnostic scenarios. These findings highlight DeepSeek V3s strong\npotential for text-based depression detection in real-world clinical\napplications. However, they also underscore the need for further refinement in\nseverity assessment and the mitigation of potential biases to enhance clinical\nreliability.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.04893v1","title":"SCAM: A Real-World Typographic Robustness Evaluation for Multimodal\n  Foundation Models","summary":"Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.04904v1","title":"A kinetic CMA diagram","summary":"We present a kinetic Clemmow-Mullaly-Allis (CMA) diagram by systematically\nanalysing the kinetic effects on the wave propagation in a homogeneous thermal\nplasma. The differences between the cold and kinetic CMA diagrams are outlined.\nIt is found that new boundaries for weakly damped left- and right-handed\ncircularly polarized waves are located above the ion and electron cyclotron\nfrequency lines in the kinetic CMA diagram. Additionally, Langmuir waves in the\nkinetic CMA diagram occupy a specific region between the new Langmuir wave\nboundary and the plasma frequency line, while in the cold CMA diagram, they\nexist on the plasma frequency line. The extraordinary-Bernstein mode\ntransformation frequency lines in the kinetic CMA diagram replace the hybrid\nresonant frequency lines of the cold CMA diagram, with discontinuities between\ndifferent cyclotron harmonics. These new boundaries partition the parameter\nspace in the kinetic CMA diagram differently, leading to new inverse wave\nnormal surfaces in the regions bounded by new boundaries. The kinetic CMA\ndiagram not only contributes to a basic understanding of wave properties in\nthermal plasmas, but also can provide a powerful tool to explore new possible\npropagation paths.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T10:22:29Z"}
{"aid":"http://arxiv.org/abs/2504.04915v1","title":"Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question\n  Answering via White-Box and Black-Box LLM Collaboration","summary":"Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T10:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.04925v1","title":"Scaling regimes in slow quenches within a gapped phase","summary":"We consider the finite-time quench dynamics in the quantum transverse field\nIsing model which exhibits a second order phase transition from a paramagnetic\nto a ferromagnetic phase, as the transverse magnetic field is decreased. These\ndynamics have been thoroughly investigated in previous studies when the\ncritical point is crossed during the quench; here, we quench the system from\ndeep in the paramagnetic phase to just above the critical field so that the\nsystem remains in the gapped phase throughout the quench duration. On linearly\nquenching the infinitely large system, we find that the behavior of mean\nlongitudinal defect density and mean transverse magnetization at the end of the\nquench falls into three distinct scaling regimes as the quench time is\nincreased. For sufficiently small quench times, these observables remain\nroughly constant, but for larger quench times, a crossover occurs from the\nKibble-Zurek scaling law to the quadratic quench rate law when the Kibble-Zurek\ntime is of the order of relaxation time at the final quench field. These\nresults are shown analytically using power series and uniform asymptotic\nexpansions of the exact solution of the model, and also compared with an\nadiabatic perturbation theory in the third regime. We find that the above\nmentioned scaling regimes hold for quenches within the ferromagnetic phase\nalso, and provide a general scaling argument for crossover from the\nKibble-Zurek regime to an adiabatic regime for slow quenches within a gapped\nphase.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T11:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.04936v1","title":"Constrained Gaussian Process Motion Planning via Stein Variational\n  Newton Inference","summary":"Gaussian Process Motion Planning (GPMP) is a widely used framework for\ngenerating smooth trajectories within a limited compute time--an essential\nrequirement in many robotic applications. However, traditional GPMP approaches\noften struggle with enforcing hard nonlinear constraints and rely on Maximum a\nPosteriori (MAP) solutions that disregard the full Bayesian posterior. This\nlimits planning diversity and ultimately hampers decision-making. Recent\nefforts to integrate Stein Variational Gradient Descent (SVGD) into motion\nplanning have shown promise in handling complex constraints. Nonetheless, these\nmethods still face persistent challenges, such as difficulties in strictly\nenforcing constraints and inefficiencies when the probabilistic inference\nproblem is poorly conditioned. To address these issues, we propose a novel\nconstrained Stein Variational Gaussian Process Motion Planning (cSGPMP)\nframework, incorporating a GPMP prior specifically designed for trajectory\noptimization under hard constraints. Our approach improves the efficiency of\nparticle-based inference while explicitly handling nonlinear constraints. This\nadvancement significantly broadens the applicability of GPMP to motion planning\nscenarios demanding robust Bayesian inference, strict constraint adherence, and\ncomputational efficiency within a limited time. We validate our method on\nstandard benchmarks, achieving an average success rate of 98.57% across 350\nplanning tasks, significantly outperforming competitive baselines. This\ndemonstrates the ability of our method to discover and use diverse trajectory\nmodes, enhancing flexibility and adaptability in complex environments, and\ndelivering significant improvements over standard baselines without incurring\nmajor computational costs.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-07T11:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.04978v1","title":"The eigenvalue one property of finite groups, I","summary":"We prove a conjecture of Dekimpe, De Rock and Penninckx concerning the\nexistence of eigenvalues one in certain elements of finite groups acting\nirreducibly on a real vector space of odd dimension. This yields a sufficient\ncondition for a closed flat manifold to be an $R_{\\infty}$-manifold.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T12:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.04984v1","title":"Finding large $k$-colorable induced subgraphs in (bull, chair)-free and\n  (bull,E)-free graphs","summary":"We study the Max Partial $k$-Coloring problem, where we are given a\nvertex-weighted graph, and we ask for a maximum-weight induced subgraph that\nadmits a proper $k$-coloring. For $k=1$ this problem coincides with Maximum\nWeight Independent Set, and for $k=2$ the problem is equivalent (by\ncomplementation) to Minimum Odd Cycle Transversal. Furthermore, it generalizes\n$k$-Coloring. We show that Max Partial $k$-Coloring on $n$-vertex instances\nwith clique number $\\omega$ can be solved in time\n  * $n^{\\mathcal{O}(k\\omega)}$ if the input graph excludes the bull and the\nchair as an induced subgraph,\n  * $n^{\\mathcal{O}(k\\omega \\log n)}$ if the input graph excludes the bull and\nE as an induced subgraph.\n  This implies that $k$-Coloring can be solved in polynomial time in the former\nclass, and in quasipolynomial-time in the latter one.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-07T12:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.05040v1","title":"InstructionBench: An Instructional Video Understanding Benchmark","summary":"Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ\\&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42\\% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q\\&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.05071v1","title":"AI-Driven Tactical Communications and Networking for Defense: A Survey\n  and Emerging Trends","summary":"The integration of Artificial Intelligence (AI) in military communications\nand networking is reshaping modern defense strategies, enhancing secure data\nexchange, real-time situational awareness, and autonomous decision-making. This\nsurvey explores how AI-driven technologies improve tactical communication\nnetworks, radar-based data transmission, UAV-assisted relay systems, and\nelectronic warfare resilience. The study highlights AI applications in adaptive\nsignal processing, multi-agent coordination for network optimization,\nradar-assisted target tracking, and AI-driven electronic countermeasures. Our\nwork introduces a novel three-criteria evaluation methodology. It\nsystematically assesses AI applications based on general system objectives,\ncommunications constraints in the military domain, and critical tactical\nenvironmental factors. We analyze key AI techniques for different types of\nlearning applied to multi-domain network interoperability and distributed data\ninformation fusion in military operations. We also address challenges such as\nadversarial AI threats, the real-time adaptability of autonomous communication\nnetworks, and the limitations of current AI models under battlefield\nconditions. Finally, we discuss emerging trends in self-healing networks,\nAI-augmented decision support systems, and intelligent spectrum allocation. We\nprovide a structured roadmap for future AI-driven defense communications and\nnetworking research.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-07T13:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.05073v1","title":"The Drinfeld-Grinberg-Kazhdan theorem and embedding codimension of the\n  arc space","summary":"We prove an extension of the theorem of Drinfeld, Grinberg and Kazhdan to\narcs with arbitrary residue field. As an application we show that the embedding\ncodimension is generically constant on each irreducible subset of the arc space\nwhich is not contained in the singular locus. In the case of maximal divisorial\nsets, this relates the corresponding finite formal models with invariants of\nsingularities of the underlying variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T13:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.05085v1","title":"Characterisation of conserved and reacting moieties in chemical reaction\n  networks","summary":"A detailed understanding of biochemical networks at the molecular level is\nessential for studying complex cellular processes. In this paper, we provide a\ncomprehensive description of biochemical networks by considering individual\natoms and chemical bonds. To address combinatorial complexity, we introduce a\nwell-established approach to group similar types of information within\nbiochemical networks. A conserved moiety is a set of atoms whose association is\ninvariant across all reactions in a network. A reacting moiety is a set of\nbonds that are either broken, formed, or undergo a change in bond order in at\nleast one reaction in the network. By mathematically identifying these\nmoieties, we establish the biological significance of conserved and reacting\nmoieties according to the mathematical properties of the stoichiometric matrix.\nWe also present a novel decomposition of the stoichiometric matrix based on\nconserved moieties. This approach bridges the gap between graph theory, linear\nalgebra, and biological interpretation, thus opening up new horizons in the\nstudy of chemical reaction networks.","main_category":"q-bio.MN","categories":"q-bio.MN","published":"2025-04-07T13:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.05094v1","title":"Hollow Victory: How Malicious Proposers Exploit Validator Incentives in\n  Optimistic Rollup Dispute Games","summary":"Blockchain systems, such as Ethereum, are increasingly adopting layer-2\nscaling solutions to improve transaction throughput and reduce fees. One\npopular layer-2 approach is the Optimistic Rollup, which relies on a mechanism\nknown as a dispute game for block proposals. In these systems, validators can\nchallenge blocks that they believe contain errors, and a successful challenge\nresults in the transfer of a portion of the proposer's deposit as a reward. In\nthis paper, we reveal a structural vulnerability in the mechanism: validators\nmay not be awarded a proper profit despite winning a dispute challenge. We\ndevelop a formal game-theoretic model of the dispute game and analyze several\nscenarios, including cases where the proposer controls some validators and\ncases where a secondary auction mechanism is deployed to induce additional\nparticipation. Our analysis demonstrates that under current designs, the\ncompetitive pressure from validators may be insufficient to deter malicious\nbehavior. We find that increased validator competition, paradoxically driven by\nhigher rewards or participation, can allow a malicious proposer to\nsignificantly lower their net loss by capturing value through mechanisms like\nauctions. To address this, we propose countermeasures such as an escrowed\nreward mechanism and a commit-reveal protocol. Our findings provide critical\ninsights into enhancing the economic security of layer-2 scaling solutions in\nblockchain networks.","main_category":"cs.GT","categories":"cs.GT,cs.CR","published":"2025-04-07T14:00:46Z"}
{"aid":"http://arxiv.org/abs/2504.05118v1","title":"VAPO: Efficient and Reliable Reinforcement Learning for Advanced\n  Reasoning Tasks","summary":"We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T14:21:11Z"}
{"aid":"http://arxiv.org/abs/2504.05151v1","title":"Error formulas for block rational Krylov approximations of matrix\n  functions","summary":"This paper investigates explicit expressions for the error associated with\nthe block rational Krylov approximation of matrix functions. Two formulas are\nproposed, both derived from characterizations of the block FOM residual. The\nfirst formula employs a block generalization of the residual polynomial, while\nthe second leverages the block collinearity of the residuals. A posteriori\nerror bounds based on the knowledge of spectral information of the argument are\nderived and tested on a set of examples. Notably, both error formulas and their\ncorresponding upper bounds do not require the use of quadratures for their\npractical evaluation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T14:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05179v1","title":"IEC-Independent Coupling Between Water Uptake and Ionic Conductivity in\n  Anion-Conducting Polymer Films","summary":"Anion exchange membranes (AEMs) are promising candidates for replacing proton\nexchange membranes (PEMs) in electrochemical devices such as fuel cells,\nelectrolyzers, batteries, and osmotic energy extraction systems. However,\noptimizing the AEM design requires a deeper understanding of the ionic\nconduction mechanism in the hydrated polymer matrix. This study investigates\nthis mechanism by seeking to understand the relationship between ion exchange\ncapacity (IEC), water absorption, and ionic conductivity in\npolynorbornene-based thin films. We combine experimental measurements with\ncomputational simulations using a newly developed minimal model of the polymer\nfilm. Our model is able to reproduce key experimental observations, including\nwater sorption isotherms and ion conduction behavior as a function of relative\nhumidity, and successfully captures the relationship between them. By comparing\nexperimental data with computational results, we explain the commonly reported\ncorrelation between conductivity and hydration level and show how the\ncorrelation between these variables is affected by the charge density and\ntemperature of the material. Our research advances our understanding of the\nphysical mechanisms that govern the performance of the polyelectrolyte\nmembrane, which is essential for the development of more efficient, stable, and\nenvironmentally friendly electrochemical systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-07T15:26:53Z"}
{"aid":"http://arxiv.org/abs/2504.05187v1","title":"Resource-Efficient Beam Prediction in mmWave Communications with\n  Multimodal Realistic Simulation Framework","summary":"Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.LG","published":"2025-04-07T15:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.05211v1","title":"Exploiting individual differences to bootstrap communication","summary":"Establishing a communication system is hard because the intended meaning of a\nsignal is unknown to its receiver when first produced, and the signaller also\nhas no idea how that signal will be interpreted. Most theoretical accounts of\nthe emergence of communication systems rely on feedback to reinforce behaviours\nthat have led to successful communication in the past. However, providing such\nfeedback requires already being able to communicate the meaning that was\nintended or interpreted. Therefore these accounts cannot explain how\ncommunication can be bootstrapped from non-communicative behaviours. Here we\npresent a model that shows how a communication system, capable of expressing an\nunbounded number of meanings, can emerge as a result of individual behavioural\ndifferences in a large population without any pre-existing means to determine\ncommunicative success. The two key cognitive capabilities responsible for this\noutcome are behaving predictably in a given situation, and an alignment of\npsychological states ahead of signal production that derives from shared\nintentionality. Since both capabilities can exist independently of\ncommunication, our results are compatible with theories in which large flexible\nsocially-learned communication systems like language are the product of a\ngeneral but well-developed capacity for social cognition.","main_category":"cs.CL","categories":"cs.CL,physics.soc-ph,q-bio.PE","published":"2025-04-07T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.05212v1","title":"On multipolar magnetic anomaly detection: multipolar signal subspaces,\n  an analytical orthonormal basis, multipolar truncature and detection\n  performance","summary":"In this paper, we consider the magnetic anomaly detection problem which aims\nto find hidden ferromagnetic masses by estimating the weak perturbation they\ninduce on local Earth's magnetic field. We consider classical detection schemes\nthat rely on signals recorded on a moving sensor, and modeling of the source as\na function of unknown parameters. As the usual spherical harmonic decomposition\nof the anomaly has to be truncated in practice, we study the signal vector\nsubspaces induced by each multipole of the decomposition, proving they are not\nin direct sum, and discussing the impact it has on the choice of the truncation\norder. Further, to ease the detection strategy based on generalized likelihood\nratio test, we rely on orthogonal polynomials theory to derive an analytical\nset of orthonormal functions (multipolar orthonormal basis functions) that\nspans the space of the noise-free measured signal. Finally, based on the\nsubspace structure of the multipole vector spaces, we study the impact of the\ntruncation order on the detection performance, beyond the issue of potential\nsurparametrization, and the behaviour of the information criteria used to\nchoose this order.","main_category":"eess.SP","categories":"eess.SP,math-ph,math.MP,stat.ME","published":"2025-04-07T16:00:24Z"}
{"aid":"http://arxiv.org/abs/2504.05217v1","title":"LLM-Alignment Live-Streaming Recommendation","summary":"In recent years, integrated short-video and live-streaming platforms have\ngained massive global adoption, offering dynamic content creation and\nconsumption. Unlike pre-recorded short videos, live-streaming enables real-time\ninteraction between authors and users, fostering deeper engagement. However,\nthis dynamic nature introduces a critical challenge for recommendation systems\n(RecSys): the same live-streaming vastly different experiences depending on\nwhen a user watching. To optimize recommendations, a RecSys must accurately\ninterpret the real-time semantics of live content and align them with user\npreferences.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.05225v1","title":"Vision-Language Model Predictive Control for Manipulation Planning and\n  Trajectory Generation","summary":"Model Predictive Control (MPC) is a widely adopted control paradigm that\nleverages predictive models to estimate future system states and optimize\ncontrol inputs accordingly. However, while MPC excels in planning and control,\nit lacks the capability for environmental perception, leading to failures in\ncomplex and unstructured scenarios. To address this limitation, we introduce\nVision-Language Model Predictive Control (VLMPC), a robotic manipulation\nplanning framework that integrates the perception power of vision-language\nmodels (VLMs) with MPC. VLMPC utilizes a conditional action sampling module\nthat takes a goal image or language instruction as input and leverages VLM to\ngenerate candidate action sequences. These candidates are fed into a video\nprediction model that simulates future frames based on the actions. In\naddition, we propose an enhanced variant, Traj-VLMPC, which replaces video\nprediction with motion trajectory generation to reduce computational complexity\nwhile maintaining accuracy. Traj-VLMPC estimates motion dynamics conditioned on\nthe candidate actions, offering a more efficient alternative for long-horizon\ntasks and real-time applications. Both VLMPC and Traj-VLMPC select the optimal\naction sequence using a VLM-based hierarchical cost function that captures both\npixel-level and knowledge-level consistency between the current observation and\nthe task input. We demonstrate that both approaches outperform existing\nstate-of-the-art methods on public benchmarks and achieve excellent performance\nin various real-world robotic manipulation tasks. Code is available at\nhttps://github.com/PPjmchen/VLMPC.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T16:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.05227v1","title":"A Reality Check of Vision-Language Pre-training in Radiology: Have We\n  Progressed Using Text?","summary":"Vision-language pre-training has recently gained popularity as it allows\nlearning rich feature representations using large-scale data sources. This\nparadigm has quickly made its way into the medical image analysis community. In\nparticular, there is an impressive amount of recent literature developing\nvision-language models for radiology. However, the available medical datasets\nwith image-text supervision are scarce, and medical concepts are fine-grained,\ninvolving expert knowledge that existing vision-language models struggle to\nencode. In this paper, we propose to take a prudent step back from the\nliterature and revisit supervised, unimodal pre-training, using fine-grained\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\npre-training is highly competitive and better suited to integrating\nheterogeneous data sources. Our results also question the potential of recent\nvision-language models for open-vocabulary generalization, which have been\nevaluated using optimistic experimental settings. Finally, we study novel\nalternatives to better integrate fine-grained labels and noisy text\nsupervision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.05231v1","title":"Mapping biodiversity at very-high resolution in Europe","summary":"This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-07T16:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.05239v1","title":"LLM-based Automated Grading with Human-in-the-Loop","summary":"The rise of artificial intelligence (AI) technologies, particularly large\nlanguage models (LLMs), has brought significant advancements to the field of\neducation. Among various applications, automatic short answer grading (ASAG),\nwhich focuses on evaluating open-ended textual responses, has seen remarkable\nprogress with the introduction of LLMs. These models not only enhance grading\nperformance compared to traditional ASAG approaches but also move beyond simple\ncomparisons with predefined \"golden\" answers, enabling more sophisticated\ngrading scenarios, such as rubric-based evaluation. However, existing\nLLM-powered methods still face challenges in achieving human-level grading\nperformance in rubric-based assessments due to their reliance on fully\nautomated approaches. In this work, we explore the potential of LLMs in ASAG\ntasks by leveraging their interactive capabilities through a human-in-the-loop\n(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative\nproperties of LLMs to pose questions to human experts, incorporating their\ninsights to refine grading rubrics dynamically. This adaptive process\nsignificantly improves grading accuracy, outperforming existing methods and\nbringing ASAG closer to human-level evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.05261v1","title":"Componentwise Linear Ideals From Sums","summary":"Let $I,J$ be componentwise linear ideals in a polynomial ring $S$. We study\nnecessary and sufficient conditions for $I+J$ to be componentwise linear. We\nprovide a complete characterization when $\\dim S=2$. As a consequence, any\ncomponentwise linear monomial ideal in $k[x,y]$ has linear quotients using\ngenerators in non-decreasing degrees. In any dimension, we show that under mild\ncompatibility conditions, one can build a componentwise linear ideal from a\ngiven collection of componentwise linear monomial ideals using only sum and\nproduct with square-free monomials. We provide numerous examples to demonstrate\nthe optimality of our results.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-07T16:54:42Z"}
{"aid":"http://arxiv.org/abs/2504.05273v1","title":"What We Do Not Know: GPT Use in Business and Management","summary":"This systematic review examines peer-reviewed studies on application of GPT\nin business management, revealing significant knowledge gaps. Despite\nidentifying interesting research directions such as best practices,\nbenchmarking, performance comparisons, social impacts, our analysis yields only\n42 relevant studies for the 22 months since its release. There are so few\nstudies looking at a particular sector or subfield that management researchers,\nbusiness consultants, policymakers, and journalists do not yet have enough\ninformation to make well-founded statements on how GPT is being used in\nbusinesses. The primary contribution of this paper is a call to action for\nfurther research. We provide a description of current research and identify\nknowledge gaps on the use of GPT in business. We cover the management subfields\nof finance, marketing, human resources, strategy, operations, production, and\nanalytics, excluding retail and sales. We discuss gaps in knowledge of GPT\npotential consequences on employment, productivity, environmental costs,\noppression, and small businesses. We propose how management consultants and the\nmedia can help fill those gaps. We call for practical work on business control\nsystems as they relate to existing and foreseeable AI-related business\nchallenges. This work may be of interest to managers, to management\nresearchers, and to people working on AI in society.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-07T17:11:53Z"}
{"aid":"http://arxiv.org/abs/2504.05275v1","title":"On canonical sandpile actions of embedded graphs","summary":"The sandpile group of a connected graph is a group whose cardinality is the\nnumber of spanning trees. The group is known to have a canonical simply\ntransitive action on spanning trees if the graph is embedded into the plane.\nHowever, no canonical action on the spanning trees is known for the nonplanar\ncase. We show that for any embedded Eulerian digraph, one can define a\ncanonical simply transitive action of the sandpile group on compatible Eulerian\ntours (a set whose cardinality equals to the number of spanning arborescences).\nThis enables us to give a new proof that the rotor-routing action of a ribbon\ngraph is independent of the root if and only if the embedding is into the plane\n(originally proved by Chan, Church and Grochow).\n  Recently, Merino, Moffatt and Noble defined a sandpile group variant (called\nJacobian) for embedded graphs, whose cardinality is the number of quasi-trees.\nBaker, Ding and Kim showed that this group acts canonically on the quasitrees.\nWe show that the Jacobian of an embedded graph is canonically isomorphic to the\nusual sandpile group of the medial digraph, and the action by Baker at al.\nagrees with the action of the sandpile group of the medial digraph on Eulerian\ntours (which fact is made possible by the existence of a canonical bijection\nbetween Eulerian tours of the medial digraph and quasi-trees due to Bouchet).","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T17:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.05644v1","title":"iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via\n  Eliminate Before Align and Keyword Explicit Reasoning","summary":"Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),\nwhich aims at searching for the corresponding targets based on the given query.\nAmong these efforts, the application of Foundation Models (FMs), such as CLIP,\nto the domain of remote sensing has yielded encouraging outcomes. However,\nexisting FM based methodologies neglect the negative impact of weakly\ncorrelated sample pairs and fail to account for the key distinctions among\nremote sensing texts, leading to biased and superficial exploration of sample\npairs. To address these challenges, we propose an approach named iEBAKER (an\nImproved Eliminate Before Align strategy with Keyword Explicit Reasoning\nframework) for RSITR. Specifically, we propose an innovative Eliminate Before\nAlign (EBA) strategy to filter out the weakly correlated sample pairs, thereby\nmitigating their deviations from optimal embedding space during\nalignment.Further, two specific schemes are introduced from the perspective of\nwhether local similarity and global similarity affect each other. On this\nbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)\nstrategy, aims at optimizing the similarity matrix via reverse retrieval.\nAdditionally, we incorporate a Keyword Explicit Reasoning (KER) module to\nfacilitate the beneficial impact of subtle key concept distinctions. Without\nbells and whistles, our approach enables a direct transition from FM to RSITR\ntask, eliminating the need for additional pretraining on remote sensing data.\nExtensive experiments conducted on three popular benchmark datasets demonstrate\nthat our proposed iEBAKER method surpasses the state-of-the-art models while\nrequiring less training data. Our source code will be released at\nhttps://github.com/zhangy0822/iEBAKER.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.05654v1","title":"Curved representational Bregman divergences and their applications","summary":"By analogy to curved exponential families, we define curved Bregman\ndivergences as restrictions of Bregman divergences to sub-dimensional parameter\nsubspaces, and prove that the barycenter of a finite weighted parameter set\nwith respect to a curved Bregman divergence amounts to the Bregman projection\nonto the subspace induced by the constraint of the barycenter with respect to\nthe unconstrained full Bregman divergence. We demonstrate the significance of\ncurved Bregman divergences with two examples: (1) symmetrized Bregman\ndivergences and (2) the Kullback-Leibler divergence between circular complex\nnormal distributions. We then consider monotonic embeddings to define\nrepresentational curved Bregman divergences and show that the\n$\\alpha$-divergences are representational curved Bregman divergences with\nrespect to $\\alpha$-embeddings of the probability simplex into the positive\nmeasure cone. As an application, we report an efficient method to calculate the\nintersection of a finite set of $\\alpha$-divergence spheres.","main_category":"cs.IT","categories":"cs.IT,cs.LG,math.IT","published":"2025-04-08T04:05:12Z"}
{"aid":"http://arxiv.org/abs/2504.05663v1","title":"Characterization of $P_3$-connected graphs","summary":"For any pair of edges $e,f$ of a graph $G$, we say that {\\em $e,f$ are\n$P_3$-connected in $G$} if there exists a sequence of edges $e=e_0,e_1,\\ldots,\ne_k=f$ such that $e_i$ and $e_{i+1}$ are two edges of an induced $3$-vertex\npath in $G$ for every $0\\leq i\\leq k-1$. If every pair of edges of $G$ are\n$P_3$-connected in $G$, then $G$ is {\\em $P_3$-connected}. $P_3$-connectivity\nwas first defined by Chudnovsky et al. in 2024 to prove that every connected\ngraph not containing $P_5$ as an induced subgraph has cop number at most two.\nIn this paper, we give a characterization of $P_3$-connected graphs and prove\nthat a simple graph is $P_3$-connected if and only if it is connected and has\nno homogeneous set whose induced subgraph contains an edge.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T04:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.05677v1","title":"Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise\n  Injection","summary":"Neural network ensembles is a simple yet effective approach for enhancing\ngeneralization capabilities. The most common method involves independently\ntraining multiple neural networks initialized with different weights and then\naveraging their predictions during inference. However, this approach increases\ntraining time linearly with the number of ensemble members. To address this\nissue, we propose the novel ``\\textbf{Noisy Deep Ensemble}'' method,\nsignificantly reducing the training time required for neural network ensembles.\nIn this method, a \\textit{parent model} is trained until convergence, and then\nthe weights of the \\textit{parent model} are perturbed in various ways to\nconstruct multiple \\textit{child models}. This perturbation of the\n\\textit{parent model} weights facilitates the exploration of different local\nminima while significantly reducing the training time for each ensemble member.\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\nachieving test accuracy comparable to standard ensembles. Code is available at\n\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.05680v1","title":"Simultaneous construction of fast equator, poleward meridional flow, and\n  near-surface shear layer in solar magnetohydrodynamic calculation","summary":"We carry out an unprecedented high-resolution simulation for the solar\nconvection zone. Our calculation reproduces the fast equator and near-surface\nshear layer (NSSL) of differential rotation and the near-surface poleward\nmeridional flow simultaneously. The NSSL is located in a complex layer where\nthe spatial and time scales of thermal convection are significantly small\ncompared with the deep convection zone. While there have been several attempts\nto reproduce the NSSL in numerical simulation, the results are still far from\nreality. In this study, we succeed in reproducing an NSSL in our new\ncalculation. Our analyses lead to a deeper understanding of the construction\nmechanism of the NSSL, which is summarized as: 1) rotationally unconstrained\nconvection in the near-surface layer transports the angular momentum radially\ninward; 2) sheared poleward meridional flow around the top boundary is\nconstructed; 3) the shear causes a positive kinetic $\\langle v'_r\nv'_\\theta\\rangle$ and negative magnetic $\\langle B_r B_\\theta\\rangle$\ncorrelations; and 4) the turbulent viscosity and magnetic tension are\nlatitudinally balanced with the Coriolis force in the NSSL. We emphasize the\nimportance of the magnetic field in the solar convection zone.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.05683v1","title":"Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs\n  Ready for HR Spoken Interview Transcript Analysis?","summary":"This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T04:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.05687v1","title":"Radial Isotropic Position via an Implicit Newton's Method","summary":"Placing a dataset $A = \\{\\mathbf{a}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$ in\nradial isotropic position, i.e., finding an invertible $\\mathbf{R} \\in\n\\mathbb{R}^{d \\times d}$ such that the unit vectors $\\{(\\mathbf{R}\n\\mathbf{a}_i) \\|\\mathbf{R} \\mathbf{a}_i\\|_2^{-1}\\}_{i \\in [n]}$ are in\nisotropic position, is a powerful tool with applications in functional\nanalysis, communication complexity, coding theory, and the design of learning\nalgorithms. When the transformed dataset has a second moment matrix within a\n$\\exp(\\pm \\epsilon)$ factor of a multiple of $\\mathbf{I}_d$, we call\n$\\mathbf{R}$ an $\\epsilon$-approximate Forster transform.\n  We give a faster algorithm for computing approximate Forster transforms,\nbased on optimizing an objective defined by Barthe [Barthe98]. When the\ntransform has a polynomially-bounded aspect ratio, our algorithm uses\n$O(nd^{\\omega - 1}(\\frac n \\epsilon)^{o(1)})$ time to output an\n$\\epsilon$-approximate Forster transform with high probability, when one\nexists. This is almost the natural limit of this approach, as even evaluating\nBarthe's objective takes $O(nd^{\\omega - 1})$ time. Previously, the\nstate-of-the-art runtime in this regime was based on cutting-plane methods, and\nscaled at least as $\\approx n^3 + n^2 d^{\\omega - 1}$. We also provide explicit\nestimates on the aspect ratio in the smoothed analysis setting, and show that\nour algorithm similarly improves upon those in the literature.\n  To obtain our results, we develop a subroutine of potential broader interest:\na reduction from almost-linear time sparsification of graph Laplacians to the\nability to support almost-linear time matrix-vector products. We combine this\ntool with new stability bounds on Barthe's objective to implicitly implement a\nbox-constrained Newton's method [CMTV17, ALOW17].","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-08T05:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05688v1","title":"First and Second Fundamental Theorems for Invariant Rings Generated by\n  Circulant Determinants","summary":"In this paper, we give the first and second fundamental theorems of invariant\ntheory for certain invariant rings whose generators are expressed by circulant\ndeterminants.","main_category":"math.RT","categories":"math.RT,math.GR,math.RA","published":"2025-04-08T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05698v1","title":"Point-based Instance Completion with Scene Constraints","summary":"Recent point-based object completion methods have demonstrated the ability to\naccurately recover the missing geometry of partially observed objects. However,\nthese approaches are not well-suited for completing objects within a scene, as\nthey do not consider known scene constraints (e.g., other observed surfaces) in\ntheir completions and further expect the partial input to be in a canonical\ncoordinate system, which does not hold for objects within scenes. While\ninstance scene completion methods have been proposed for completing objects\nwithin a scene, they lag behind point-based object completion methods in terms\nof object completion quality and still do not consider known scene constraints\nduring completion. To overcome these limitations, we propose a point\ncloud-based instance completion model that can robustly complete objects at\narbitrary scales and pose in the scene. To enable reasoning at the scene level,\nwe introduce a sparse set of scene constraints represented as point clouds and\nintegrate them into our completion model via a cross-attention mechanism. To\nevaluate the instance scene completion task on indoor scenes, we further build\na new dataset called ScanWCF, which contains labeled partial scans as well as\naligned ground truth scene completions that are watertight and collision-free.\nThrough several experiments, we demonstrate that our method achieves improved\nfidelity to partial scans, higher completion quality, and greater plausibility\nover existing state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T05:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.05736v1","title":"Rank-Then-Score: Enhancing Large Language Models for Automated Essay\n  Scoring","summary":"In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T07:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.05748v1","title":"When Less Is More: A Sparse Facial Motion Structure For Listening Motion\n  Learning","summary":"Effective human behavior modeling is critical for successful human-robot\ninteraction. Current state-of-the-art approaches for predicting listening head\nbehavior during dyadic conversations employ continuous-to-discrete\nrepresentations, where continuous facial motion sequence is converted into\ndiscrete latent tokens. However, non-verbal facial motion presents unique\nchallenges owing to its temporal variance and multi-modal nature.\nState-of-the-art discrete motion token representation struggles to capture\nunderlying non-verbal facial patterns making training the listening head\ninefficient with low-fidelity generated motion. This study proposes a novel\nmethod for representing and predicting non-verbal facial motion by encoding\nlong sequences into a sparse sequence of keyframes and transition frames. By\nidentifying crucial motion steps and interpolating intermediate frames, our\nmethod preserves the temporal structure of motion while enhancing instance-wise\ndiversity during the learning process. Additionally, we apply this novel sparse\nrepresentation to the task of listening head prediction, demonstrating its\ncontribution to improving the explanation of facial motion patterns.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-08T07:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.05753v1","title":"Accelerated Natural Gradient Method for Parametric Manifold Optimization","summary":"Parametric manifold optimization problems frequently arise in various machine\nlearning tasks, where state functions are defined on infinite-dimensional\nmanifolds. We propose a unified accelerated natural gradient descent (ANGD)\nframework to address these problems. By incorporating a Hessian-driven damping\nterm into the manifold update, we derive an accelerated Riemannian gradient\n(ARG) flow that mitigates oscillations. An equivalent first-order system is\nfurther presented for the ARG flow, enabling a unified discretization scheme\nthat leads to the ANGD method. In our discrete update, our framework considers\nvarious advanced techniques, including least squares approximation of the\nupdate direction, projected momentum to accelerate convergence, and efficient\napproximation methods through the Kronecker product. It accommodates various\nmetrics, including $H^s$, Fisher-Rao, and Wasserstein-2 metrics, providing a\ncomputationally efficient solution for large-scale parameter spaces. We\nestablish a convergence rate for the ARG flow under geodesic convexity\nassumptions. Numerical experiments demonstrate that ANGD outperforms standard\nNGD, underscoring its effectiveness across diverse deep learning tasks.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T07:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.05759v1","title":"RETROcode: Leveraging a Code Database for Improved Natural Language to\n  Code Generation","summary":"As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.05770v1","title":"A Lightweight Multi-Module Fusion Approach for Korean Character\n  Recognition","summary":"Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.10","published":"2025-04-08T07:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05797v1","title":"Possible existence of pygmy dipole resonance built on excited states in\n  a neutron-rich $^{80}$Ge nucleus","summary":"The pygmy dipole resonance (PDR) at the low-lying tail of the giant dipole\nresonance (GDR) is an interesting research subject as it carries important\ninformation about the nuclear surface with mixed isoscalar and isovector\nvibrations in $N > Z$ systems. The present paper investigates the possible\nexistence of the PDR built on excited states in a neutron-rich $^{80}$Ge\nnucleus using the phonon damping model (PDM) with and without pairing\ncorrelation at zero and finite temperatures. The results obtained within the\nPDM with exact pairing (EP+PDM) reveal the appearance of two enhanced\n$\\gamma$-transitions $E_\\gamma = 7.25$ and 7.35 MeV at $T=0.6$ MeV, which carry\nthe PDR nature and hence implying the possible existence of PDR built on\nexcited states in this nucleus. These two $\\gamma$-energies nicely match with a\nrecent experimental observation, thus indicating the crucial role of the\ninclusion of exact pairing solution in the precise description of low-lying\n$\\gamma$-transitions. The partition function-based analysis shows that this\npredicted PDR at $T=$ 0.6MeV is mainly contributed by the first $2^+$ excited\nstate of the $^{80}$Ge nucleus. The isospin mixing at the nuclear surface is\nalso observed in the investigated PDR at $T=0.6-0.7$ MeV. The primary mechanism\nunderlying the emergence of the hot PDR is found due to the coupling of GDR\nphonon to non-collective particle-particle and hole-hole configurations at\nfinite temperatures within the PDM framework, along with the shift in\nparticle-hole excitation energies due to thermal pairing correlations","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T08:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05806v1","title":"Meta-Continual Learning of Neural Fields","summary":"Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T08:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.05818v1","title":"Proper constituent gluon mass as the final piece to construct hybrid","summary":"After treating hybrid as a three-body system, we recalculate the spectra and\ndecay widths of the $1^{-+}$ light hybrids via the Gauss Expansion Method\n(GEM). Our result shows that, after adding into only one more parameter\n$m_g$=450 MeV, i.e., the constituent gluon mass, we can reproduce nearly all\nthe results in our previous work by just using the model parameters from meson\nspectra calculation, which shows the unification of Quantum Chromodynamics\n(QCD). As a result, $\\pi_1(1600)$ and $\\eta_1(1855)$ may not be explained as\n$1^{-+}$ hybrids simultaneously, and the $\\eta_1(1855)$ observed by BESIII may\nnot be a hybrid. In addition, we predict an existence of a hybrid\n$\\eta_1(1640)$, which can be verified by searching the $a_1(1260)\\pi$ channel.\nFurthermore, to search for an isospin-0 and an isospin-$\\frac{1}{2}$ hybrid,\nthe golden channels may be $K_1(1270)\\bar{K}$ and $K_1(1270)\\pi$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T09:01:14Z"}
{"aid":"http://arxiv.org/abs/2504.05831v1","title":"Leveraging Robust Optimization for LLM Alignment under Distribution\n  Shifts","summary":"Large language models (LLMs) increasingly rely on preference alignment\nmethods to steer outputs toward human values, yet these methods are often\nconstrained by the scarcity of high-quality human-annotated data. To tackle\nthis, recent approaches have turned to synthetic data generated by LLMs as a\nscalable alternative. However, synthetic data can introduce distribution\nshifts, compromising the nuanced human preferences that are essential for\ndesirable outputs. In this paper, we propose a novel distribution-aware\noptimization framework that improves preference alignment in the presence of\nsuch shifts. Our approach first estimates the likelihood ratios between the\ntarget and training distributions leveraging a learned classifier, then it\nminimizes the worst-case loss over data regions that reflect the target\nhuman-preferred distribution. By explicitly prioritizing the target\ndistribution during optimization, our method mitigates the adverse effects of\ndistributional variation and enhances the generation of responses that\nfaithfully reflect human values.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.05833v1","title":"AVENet: Disentangling Features by Approximating Average Features for\n  Voice Conversion","summary":"Voice conversion (VC) has made progress in feature disentanglement, but it is\nstill difficult to balance timbre and content information. This paper evaluates\nthe pre-trained model features commonly used in voice conversion, and proposes\nan innovative method for disentangling speech feature representations.\nSpecifically, we first propose an ideal content feature, referred to as the\naverage feature, which is calculated by averaging the features within\nframe-level aligned parallel speech (FAPS) data. For generating FAPS data, we\nutilize a technique that involves freezing the duration predictor in a\nText-to-Speech system and manipulating speaker embedding. To fit the average\nfeature on traditional VC datasets, we then design the AVENet to take features\nas input and generate closely matching average features. Experiments are\nconducted on the performance of AVENet-extracted features within a VC system.\nThe experimental results demonstrate its superiority over multiple current\nspeech feature disentangling methods. These findings affirm the effectiveness\nof our disentanglement approach.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-08T09:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.05835v1","title":"Scalar-assisted magnetogenesis during the radiation-dominated epoch","summary":"We propose a novel mechanism to generate primordial magnetic fields (PMFs)\nstrong enough to explain the observed cosmic magnetic fields. We employ a\nscalar field charged under U(1) gauge symmetry with a non-trivial VEV to\nprovide an effective mass term to the EM field and thus break its conformal\ninvariance. The primordial magneto-genesis takes place in the radiation\ndominated (RD) epoch, after the electroweak symmetry breaking (EWSB) phase. As\na result, our mechanism is naturally free from the over-production of electric\nfields due to high conductivity in the RD epoch, and the baryon isocurvature\nproblem which takes place only if magneto-genesis happens before the ESWB\nphase. In addition, we find that a significant amount of PMFs can be generated\nwhen the scalar field experiences a tachyonic phase. In this case, the scalar\nfield is light and weakly coupled and has negligible energy density compared to\nthe cold dark matter, hence the strong coupling problem and the back-reaction\nproblem are also absent. Therefore, our model is free from the above-mentioned\nproblems that frequently appear in other primordial magneto-genesis scenarios.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,gr-qc","published":"2025-04-08T09:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.05837v1","title":"Derivation of Kirchhoff-type plate theories for elastic materials with\n  voids","summary":"We rigorously derive a Blake-Zisserman-Kirchhoff theory for thin plates with\nmaterial voids, starting from a three-dimensional model with elastic bulk and\ninterfacial energy featuring a Willmore-type curvature penalization. The\neffective two-dimensional model comprises a classical elastic bending energy\nand surface terms which reflect the possibility that voids can persist in the\nlimit, that the limiting plate can be broken apart into several pieces, or that\nthe plate can be folded. Building upon and extending the techniques used in the\nauthors' recent work on the derivation of one-dimensional theories for thin\nbrittle rods with voids, the present contribution generalizes the results of\nSantili and Schmidt (2022), by considering general geometries on the admissible\nset of voids and constructing recovery sequences for all admissible limiting\nconfigurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T09:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.05847v1","title":"RÃ©duire le bruit grÃ¢ce Ã  la rÃ©alitÃ© augmentÃ©e sonore --\n  Auditory Concealer","summary":"This report presents the work done over 22 weeks of internship within the\nSound Perception and Design team of the Sciences and Technologies of Music and\nSound (STMS) laboratory at the Institute for Research and Coordination in\nAcoustics/Music (IRCAM). As part of the launch of the project Reducing Noise\nwith Augmented Reality (ReNAR); which aims to create a tool to reduce in\nreal-time the cognitive impact of sounds perceived as unpleasant or annoying in\nindoor environments; an initial study was conducted to validate the feasibility\nand effectiveness of a new masking approach called concealer. The main\nhypothesis is that the concealer approach could provide better results than a\nmasker approach in terms of perceived pleasantness. Mixtures of two noise\nsources (ventilation) and five masking sounds (water sounds) were generated\nusing both approaches at various levels. The evaluation of the perceived\npleasantness of these mixtures showed that the masker approach remains more\neffective than the concealer approach, regardless of the noise source, water\nsound, or level used.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T09:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.05863v1","title":"Extending Parametric Model Embedding with Physical Information for\n  Design-space Dimensionality Reduction in Shape Optimization","summary":"In this work, an extension of the parametric model embedding (PME) approach\nis presented, aiming to achieve more effective design-space dimensionality\nreduction for shape optimization in vehicle design. PME, rooted in principal\ncomponent analysis (PCA), not only identifies a reduced set of critical modes\nbut also re-parameterizes the original design space, enabling direct and\ninterpretable manipulations of shape modifications within the reduced space.\nAlongside the \"physics-informed\" version (PI-PME), which enriches geometry with\nlow-fidelity distributed and lumped physical quantities, a \"physics-driven\"\nvariant (PD-PME) is introduced that focuses exclusively on physical parameters.\nBoth formulations employ PCA to capture the principal modes of variability yet\ndiffer in their balance between geometric and physical information, through the\nad-hoc definition of a weighted inner product. Through test cases involving the\nRAE-2822 airfoil, a bio-inspired underwater glider, a naval propeller, and the\nDTMB-5415 destroyer-type vessel, it is shown how the resulting frameworks\nprovide a first-level assessment of design variability, offer interpretability\nregarding which original variables most strongly affect performance, and\nefficiently bridge geometric and physical parameters. Furthermore, lumped\nphysical parameters can serve as a low-fidelity foundation for multi-fidelity\noptimization, directly leveraging the linear re-parameterization to drive the\nreduced design variables. Meanwhile, distributed physical parameters enable the\nconstruction of machine-learning-based reduced-order models to infer integral\nquantities of interest. By allowing the user to embed these insights early in\nthe design process, PI-PME and PD-PME facilitate more robust, cost-effective\nexploration, paving the way for subsequent high-fidelity optimization.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T09:43:41Z"}
{"aid":"http://arxiv.org/abs/2504.05866v1","title":"CTI-HAL: A Human-Annotated Dataset for Cyber Threat Intelligence\n  Analysis","summary":"Organizations are increasingly targeted by Advanced Persistent Threats\n(APTs), which involve complex, multi-stage tactics and diverse techniques.\nCyber Threat Intelligence (CTI) sources, such as incident reports and security\nblogs, provide valuable insights, but are often unstructured and in natural\nlanguage, making it difficult to automatically extract information. Recent\nstudies have explored the use of AI to perform automatic extraction from CTI\ndata, leveraging existing CTI datasets for performance evaluation and\nfine-tuning. However, they present challenges and limitations that impact their\neffectiveness. To overcome these issues, we introduce a novel dataset manually\nconstructed from CTI reports and structured according to the MITRE ATT&CK\nframework. To assess its quality, we conducted an inter-annotator agreement\nstudy using Krippendorff alpha, confirming its reliability. Furthermore, the\ndataset was used to evaluate a Large Language Model (LLM) in a real-world\nbusiness context, showing promising generalizability.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T09:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.05872v1","title":"On free line arrangements with double, triple and quadruple points","summary":"We show that there are only finitely many combinatorial types of free real\nline arrangements with only double, triple and quadruple intersection points,\nand we enlist all admissible weak-combinatorics of them. Then we classify all\nreal $M$-line arrangements. In particular, we show that real $M$-line\narrangements are simplicial.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-08T09:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.05883v1","title":"Rolling Horizon Coverage Control with Collaborative Autonomous Agents","summary":"This work proposes a coverage controller that enables an aerial team of\ndistributed autonomous agents to collaboratively generate non-myopic coverage\nplans over a rolling finite horizon, aiming to cover specific points on the\nsurface area of a 3D object of interest. The collaborative coverage problem,\nformulated, as a distributed model predictive control problem, optimizes the\nagents' motion and camera control inputs, while considering inter-agent\nconstraints aiming at reducing work redundancy. The proposed coverage\ncontroller integrates constraints based on light-path propagation techniques to\npredict the parts of the object's surface that are visible with regard to the\nagents' future anticipated states. This work also demonstrates how complex,\nnon-linear visibility assessment constraints can be converted into logical\nexpressions that are embedded as binary constraints into a mixed-integer\noptimization framework. The proposed approach has been demonstrated through\nsimulations and practical applications for inspecting buildings with unmanned\naerial vehicles (UAVs).","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T10:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.05897v1","title":"HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient\n  MoE Inference","summary":"The Mixture of Experts (MoE) architecture has demonstrated significant\nadvantages as it enables to increase the model capacity without a proportional\nincrease in computation. However, the large MoE model size still introduces\nsubstantial memory demands, which usually requires expert offloading on\nresource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU\ninference has been proposed to leverage CPU computation to reduce expert\nloading overhead but faces major challenges: on one hand, the expert activation\npatterns of MoE models are highly unstable, rendering the fixed mapping\nstrategies in existing works inefficient; on the other hand, the hybrid CPU-GPU\nschedule for MoE is inherently complex due to the diverse expert sizes,\nstructures, uneven workload distribution, etc. To address these challenges, in\nthis paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that\nimproves resource utilization through a novel CPU-GPU scheduling and cache\nmanagement system. HybriMoE introduces (i) a dynamic intra-layer scheduling\nstrategy to balance workloads across CPU and GPU, (ii) an impact-driven\ninter-layer prefetching algorithm, and (iii) a score-based caching algorithm to\nmitigate expert activation instability. We implement HybriMoE on top of the\nkTransformers framework and evaluate it on three widely used MoE-based LLMs.\nExperimental results demonstrate that HybriMoE achieves an average speedup of\n1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared\nto state-of-the-art hybrid MoE inference framework. Our code is available at:\nhttps://github.com/PKU-SEC-Lab/HybriMoE.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T10:47:37Z"}
{"aid":"http://arxiv.org/abs/2504.05899v1","title":"Spatially Resolved Optical Responses of a High-Kinetic-Inductance\n  Microwave Resonator","summary":"Understanding the optical response of a high-kinetic-inductance microwave\nresonator is crucial for applications ranging from single-photon detection to\nquantum transduction between microwave and optical domains, which is gaining\nsignificant attention for scaling up quantum computers. However, interactions\nbetween the pump light and the superconducting resonator often induce\nunintended resonance frequency shifts and linewidth broadening. In this study,\nwe measure the local optical response of a NbTiN nanowire resonator using a\nlaser-scanning microwave spectroscopy system integrated with a dilution\nrefrigerator. The optical response of the resonator shows correlation with the\nresonance modes and position, which is attributed to the two-level system\naround the resonator. These findings not only contribute to the design and\nunderstanding of quantum transducers and single-photon detectors, but also to\nthe understandings of catastrophic high-energy particle irradiation events that\ngenerate unintended phonons in quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T10:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.05963v1","title":"Learning Verified Monitors for Hidden~Markov~Models","summary":"Runtime monitors assess whether a system is in an unsafe state based on a\nstream of observations. We study the problem where the system is subject to\nprobabilistic uncertainty and described by a hidden Markov model. A stream of\nobservations is then unsafe if the probability of being in an unsafe state is\nabove a threshold. A correct monitor recognizes the set of unsafe observations.\nThe key contribution of this paper is the first correct-by-construction\nsynthesis method for such monitors, represented as finite automata. The\ncontribution combines four ingredients: First, we establish the coNP-hardness\nof checking whether an automaton is a correct monitor, i.e., a monitor without\nmisclassifications. Second, we provide a reduction that reformulates the search\nfor misclassifications into a standard probabilistic system synthesis problem.\nThird, we integrate the verification routine into an active automata learning\nroutine to synthesize correct monitors. Fourth, we provide a prototypical\nimplementation that shows the feasibility and limitations of the approach on a\nseries of benchmarks.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-08T12:23:20Z"}
{"aid":"http://arxiv.org/abs/2504.06002v1","title":"Has ACT measured radiative corrections to the tree-level Higgs-like\n  inflation?","summary":"Starobinsky inflation and non-minimally coupled Higgs inflation have been\namong the most favored models of the early universe, as their predictions for\nthe scalar spectral index $n_s$ and tensor-to-scalar ratio $r$ fall comfortably\nwithin the constraints set by Planck and BICEP/Keck. However, new results from\nthe Atacama Cosmology Telescope (ACT) suggest a preference for higher values of\n$n_s$, introducing tension with the simplest realizations of these models. In\nthis work, being agnostic about the nature of the inflaton, we show that\nincorporating one-loop corrections to a Higgs-like inflationary scenario leads\nto a shift in the predicted value of $n_s$, which brings Higgs-like inflation\ninto better agreement with ACT observations. Remarkably, we find that this can\nbe achieved with non-minimal couplings $\\xi < 1$, in contrast to the large\nvalues typically required in conventional Higgs inflation, thereby pushing any\nunitarity-violation scale above the Planck scale. The effect is even more\nsignificant when the model is formulated in the Palatini approach, where the\nmodified field-space structure naturally enhances deviations from the metric\ncase. These findings highlight the importance of quantum corrections and\ngravitational degrees of freedom in refining inflationary predictions in light\nof new data.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-08T13:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06026v1","title":"Taking out the Toxic Trash: Recovering Precision in Mixed Flow-Sensitive\n  Static Analyses","summary":"Static analysis of real-world programs combines flow- and context-sensitive\nanalyses of local program states with computation of flow- and\ncontext-insensitive invariants at globals, that, e.g., abstract data shared by\nmultiple threads. The values of locals and globals may mutually depend on each\nother, with the analysis of local program states both making contributions to\nglobals and querying their values. Usually, all contributions to globals are\naccumulated during fixpoint iteration, with widening applied to enforce\ntermination. Such flow-insensitive information often becomes unnecessarily\nimprecise and can include superfluous contributions -- trash -- which, in turn,\nmay be toxic to the precision of the overall analysis. To recover precision of\nglobals, we propose techniques complementing each other: Narrowing on globals\ndifferentiates contributions by origin; reluctant widening limits the amount of\nwidening applied at globals; and finally, abstract garbage collection undoes\ncontributions to globals and propagates their withdrawal. The experimental\nevaluation shows that these techniques increase the precision of mixed\nflow-sensitive analyses at a reasonable cost.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-08T13:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.06027v1","title":"OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model","summary":"Multimodal remote sensing image registration aligns images from different\nsensors for data fusion and analysis. However, current methods often fail to\nextract modality-invariant features when aligning image pairs with large\nnonlinear radiometric differences. To address this issues, we propose\nOSDM-MReg, a novel multimodal image registration framework based image-to-image\ntranslation to eliminate the gap of multimodal images. Firstly, we propose a\nnovel one-step unaligned target-guided conditional denoising diffusion\nprobabilistic models(UTGOS-CDDPM)to translate multimodal images into a unified\ndomain. In the inference stage, traditional conditional DDPM generate\ntranslated source image by a large number of iterations, which severely slows\ndown the image registration task. To address this issues, we use the unaligned\ntraget image as a condition to promote the generation of low-frequency features\nof the translated source image. Furthermore, during the training stage, we add\nthe inverse process of directly predicting the translated image to ensure that\nthe translated source image can be generated in one step during the testing\nstage. Additionally, to supervised the detail features of translated source\nimage, we propose a new perceptual loss that focuses on the high-frequency\nfeature differences between the translated and ground-truth images. Finally, a\nmultimodal multiscale image registration network (MM-Reg) fuse the multimodal\nfeature of the unimodal images and multimodal images by proposed multimodal\nfeature fusion strategy. Experiments demonstrate superior accuracy and\nefficiency across various multimodal registration tasks, particularly for\nSAR-optical image pairs.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-08T13:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06044v1","title":"Polynomial-Time PIT from (Almost) Necessary Assumptions","summary":"The celebrated result of Kabanets and Impagliazzo (Computational Complexity,\n2004) showed that PIT algorithms imply circuit lower bounds, and vice versa.\nSince then it has been a major challenge to understand the precise connections\nbetween PIT and lower bounds. In particular, a main goal has been to understand\nwhich lower bounds suffice to obtain efficient PIT algorithms, and how close\nare they to lower bounds that are necessary for the conclusion.\n  We construct polynomial-time PIT algorithms from lower bounds that are, up to\nrelatively minor remaining gaps, necessary for the existence of such\nalgorithms. That is, we prove that these lower bounds are, up to the mentioned\nminor gaps, both sufficient and necessary for polynomial-time PIT, over fields\nof characteristic zero. Over sufficiently large finite fields, we show a\nsimilar result wherein the PIT algorithm runs in time $n^{\\log^{(c)}(n)}$, i.e.\na power of $c$-iterated log for an arbitrarily large constant $c>1$.\n  The key to these improvements is studying PIT versus lower bounds in the\nuniform setting, in which we focus on proving lower bounds for uniform\narithmetic circuits and their variants (and on deducing algorithms from such\nlower bounds). Indeed, by working in this setting we obtain results that are\nsignificantly tighter than previously known results concerning polynomial-time\nPIT vs lower bounds, and are in fact also tighter than known\nhardness-vs-randomness connections in the Boolean setting.\n  Our results are obtained by combining recent techniques from Boolean hardness\nvs randomness, and in particular the generator of Chen and Tell (FOCS 2021),\nwith the algebraic hitting-set generator of Guo, Kumar, Saptharishi, and\nSolomon (SIAM J. Computing 2022) along with the bootstrapping ideas of Agrawal,\nGhosh, and Saxena (STOC 2018) and of Kumar, Saptharishi, and Tengse (SODA\n2019).","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-08T13:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.06048v1","title":"Trust-Region Twisted Policy Improvement","summary":"Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T13:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.06050v1","title":"Low-loss far-infrared surface phonon polaritons in suspended SrTiO3\n  nanomembranes","summary":"Phonon polaritons (PhPs), excitations arising from the coupling of light with\nlattice vibrations, enable light confinement and local field enhancement, which\nis essential for various photonic and thermal applications. To date, PhPs with\nhigh confinement and low loss have been mainly observed in the mid-infrared\nregime and mostly in manually exfoliated flakes of van der Waals (vdW)\nmaterials. In this work, we demonstrate the existence of low-loss,\nthickness-tunable phonon polaritons in the far-infrared regime within\ntransferable free-standing SrTiO3 membranes synthesized through a scalable\napproach, achieving high figures of merit, which are comparable to the previous\nrecord values from the vdW materials. Leveraging atomic precision in thickness\ncontrol, large dimensions, and compatibility with mature oxide electronics,\nfunctional oxide membranes present a promising large-scale two-dimensional (2D)\nplatform alternative to vdW materials for on-chip polaritonic technologies in\nthe far-infrared regime.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-08T13:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.06061v1","title":"Non-reciprocal waves in two-dimensional electron systems with\n  temperature gradient","summary":"We demonstrate that the interaction of dc temperature gradient with ac\nmagnetic field in temperature-biased two-dimensional electron systems leads to\nformation of a new electromagnetic mode, a two-dimensional thermomagnetic wave\n(2d TMW). This wave is transverse electric and non-reciprocal, and its damping\nrate can be lower than that of conventional 2d plasma waves. The Q-factor of 2d\nTMW is independent of the wave vector. Numerical estimates show that in\nstate-of-the-art two-dimensional electrons systems the 2d TMW Q-factor is the\norder of $10^{-3}$. We discuss possible ways to overcome this issue.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T14:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06063v1","title":"Inclusive semileptonic decays of the $D_s$ meson: A first-principles\n  lattice QCD calculation","summary":"We present the results of a first-principles theoretical study of the\ninclusive semileptonic decays of the $D_s$ meson. We performed a\nstate-of-the-art lattice QCD calculation using the gauge ensembles produced by\nthe Extended Twisted Mass Collaboration (ETMC) with dynamical light, strange\nand charm quarks with physical masses and employed the so-called\nHansen-Lupo-Tantalo (HLT) method to extract the decay rate and the first two\nlepton-energy moments from the relevant Euclidean correlators. We have\ncarefully taken into account all sources of systematic errors, including the\nones associated with the continuum and infinite-volume extrapolations and with\nthe HLT spectral reconstruction method. We obtained results in very good\nagreement with the currently available experimental determinations and with a\ntotal accuracy at the few-percent level, of the same order of magnitude of the\nexperimental error. Our total error is dominated by the lattice QCD simulations\nstatistical uncertainties and is certainly improvable. From the results\npresented and thoroughly discussed in this paper we conclude that it is\nnowadays possible to study heavy mesons inclusive semileptonic decays on the\nlattice at a phenomenologically relevant level of accuracy. The\nphenomenological implications of our physical results are the subject of a\ncompanion letter [1].","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-08T14:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.06081v1","title":"On the interference of the scattered wave and the incident wave in light\n  scattering problems with Gaussian beams","summary":"We consider the light scattering problem for a Gaussian beam and a\n(spherical) particle at arbitrary location. Within the beam cross section, the\ntotal electromagnetic field is the superposition of the incident beam and the\nscattered wave. Using the Generalized Lorenz-Mie Theory (GLMT) as a vehicle to\naccess such scattering problems, we discuss the mathematical modeling of this\ninterference at short, large but finite and infinite distances from the\nscatterer. We show how to eliminate the errors that can arise from improper\nmodeling in the most straight-forward manner, that is superimposing the\nscattered wave with the closed-form expression for the Gaussian beam at a\nfinite distance from the particle. GLMT uses a low order beam model ($s^1$),\nbut using the known higher order models ($s^3$, $s^5$, $s^7$, ...) would not\nmitigate these errors as we discuss. The challenge lies in an appropriate\ndescription of the Gaussian beam at arbitrary distances from its focus, not in\nits description on the scale of a particle (located in or near the focus) nor\nin the expressions for the scattered field. Hence, the solutions described here\ncan readily be extended to light scattering frameworks other than GLMT and are\nthus also relevant for non-spherical particles.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.06133v1","title":"Gravitational Baryogenesis in Extended Proca-Nuevo Gravity","summary":"In this article, we investigate the gravitational baryogenesis mechanism in\nthe framework of Extended Proca-Nuevo (EPN) gravity, a theory where a massive\nvector field is non-minimally coupled to the curvature. This analysis is\ncarried out for an early universe, encompassing three separate cosmological\nscenarios defined by power-law, exponential, and modified exponential scale\nfactors. By deriving the modified field equations from the EPN action, we\nobtain precise solutions for each scale factor, including the influence of the\nvector field. We compute the baryon-to-entropy ratio using the gravitational\nbaryogenesis formalism, where the baryon asymmetry arises from a dynamical\ncoupling of the baryon current with the derivative of the Ricci scalar. Our\nfindings demonstrate that the baryon-to-entropy ratio is consistent with\nobservational constraints in all scenarios, highlighting the potential of EPN\ngravity as a viable theory to explain the matter-antimatter asymmetry in the\nearly universe. The study further stresses the contribution of anisotropy and\nvector field dynamics to the cosmological evolution within modified gravity\nmodels.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T15:26:58Z"}
{"aid":"http://arxiv.org/abs/2504.06151v1","title":"Zerrow: True Zero-Copy Arrow Pipelines in Bauplan","summary":"Bauplan is a FaaS-based lakehouse specifically built for data pipelines: its\nexecution engine uses Apache Arrow for data passing between the nodes in the\nDAG. While Arrow is known as the \"zero copy format\", in practice, limited Linux\nkernel support for shared memory makes it difficult to avoid copying entirely.\nIn this work, we introduce several new techniques to eliminate nearly all\ncopying from pipelines: in particular, we implement a new kernel module that\nperforms de-anonymization, thus eliminating a copy to intermediate data. We\nconclude by sharing our preliminary evaluation on different workloads types, as\nwell as discussing our plan for future improvements.","main_category":"cs.OS","categories":"cs.OS,cs.DB","published":"2025-04-08T15:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.06157v1","title":"Hall Effect Thruster Forecasting using a Topological Approach for Data\n  Assimilation","summary":"Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized\ngas particles from the spacecraft to generate thrust. Although traditionally\nthey were used for station keeping, recently They have been used for\ninterplanetary space missions due to their high delta-V potential and their\noperational longevity in contrast to other thrusters, e.g., chemical. However,\nthe operation of HETs involves complex processes such as ionization of gases,\nstrong magnetic fields, and complicated solar panel power supply interactions.\nTherefore, their operation is extremely difficult to model thus necessitating\nData Assimilation (DA) approaches for estimating and predicting their\noperational states. Because HET's operating environment is often noisy with\nnon-Gaussian sources, this significantly limits applicable DA tools. We\ndescribe a topological approach for data assimilation that bypasses these\nlimitations that does not depend on the noise model, and utilize it to forecast\nspatiotemporal plume field states of HETs. Our approach is a generalization of\nthe Topological Approach for Data Assimilation (TADA) method that allows\nincluding different forecast functions. We show how TADA can be combined with\nthe Long Short-Term Memory network for accurate forecasting. We then apply our\napproach to high-fidelity Hall Effect Thruster (HET) simulation data from the\nAir Force Research Laboratory (AFRL) rocket propulsion division where we\ndemonstrate the forecast resiliency of TADA on noise contaminated,\nhigh-dimensional data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T15:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06178v1","title":"Flash Sculptor: Modular 3D Worlds from Objects","summary":"Existing text-to-3D and image-to-3D models often struggle with complex scenes\ninvolving multiple objects and intricate interactions. Although some recent\nattempts have explored such compositional scenarios, they still require an\nextensive process of optimizing the entire layout, which is highly cumbersome\nif not infeasible at all. To overcome these challenges, we propose Flash\nSculptor in this paper, a simple yet effective framework for compositional 3D\nscene/object reconstruction from a single image. At the heart of Flash Sculptor\nlies a divide-and-conquer strategy, which decouples compositional scene\nreconstruction into a sequence of sub-tasks, including handling the appearance,\nrotation, scale, and translation of each individual instance. Specifically, for\nrotation, we introduce a coarse-to-fine scheme that brings the best of both\nworlds--efficiency and accuracy--while for translation, we develop an\noutlier-removal-based algorithm that ensures robust and precise parameters in a\nsingle step, without any iterative optimization. Extensive experiments\ndemonstrate that Flash Sculptor achieves at least a 3 times speedup over\nexisting compositional 3D methods, while setting new benchmarks in\ncompositional 3D reconstruction performance. Codes are available at\nhttps://github.com/YujiaHu1109/Flash-Sculptor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T16:20:51Z"}
{"aid":"http://arxiv.org/abs/2504.06187v1","title":"Scaling Invariance: A Gateway to Phase Transitions","summary":"We explore the concept of scaling invariance in a type of dynamical systems\nthat undergo a transition from order (regularity) to disorder (chaos). The\nsystems are described by a two-dimensional, nonlinear mapping that preserves\nthe area in the phase space. The key variables are the action and the angle, as\nusual from Hamiltonian systems. The transition is influenced by a control\nparameter giving the form of the order parameter. We observe a scaling\ninvariance in the average squared action within the chaotic region, providing\nevidence that this change from regularity (integrability) to chaos\n(non-integrability) is akin to a second-order or continuous phase transition.\nAs the order parameter approaches zero, its response against the variation of\nthe control parameter (susceptibility) becomes increasingly pronounced (indeed\ndiverging), resembling a phase transition. These findings could not be obtained\nwithout a seminal paper on Phys. Rev. Lett. {\\bf 2004}, {\\em 93}, 014101.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T16:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.06203v1","title":"Factorizing Defects from Generalized Pinning Fields","summary":"We introduce generalized pinning fields in conformal field theory that model\na large class of critical impurities at large distance, enriching the familiar\nuniversality classes. We provide a rigorous definition of such defects as\ncertain unbounded operators on the Hilbert space and prove that when inserted\non codimension-one surfaces they factorize the spacetime into two halves. The\nfactorization channels are further constrained by symmetries in the bulk. As a\ncorollary, we solve such critical impurities in the 2d minimal models and\nestablish the factorization phenomena previously observed for localized mass\ndeformations in the 3d ${\\rm O}(N)$ model.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el,math.OA","published":"2025-04-08T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.06211v1","title":"Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs","summary":"Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in\nprivacy-preserving and verifiable computing. ZKPs enable a proving party to\nprove the truth of a statement to a verifying party without revealing anything\nelse. ZKPs have applications in blockchain technologies, verifiable machine\nlearning, and electronic voting, but have yet to see widespread adoption due to\nthe computational complexity of the proving process. Recent works have\naccelerated the key primitives of state-of-the-art ZKP protocols on GPU and\nASIC. However, the protocols accelerated thus far face one of two challenges:\nthey either require a trusted setup for each application, or they generate\nlarger proof sizes with higher verification costs, limiting their applicability\nin scenarios with numerous verifiers or strict verification time constraints.\nThis work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art\nZKP protocol that supports both one-time, universal setup and small proof sizes\nfor typical ZKP applications in publicly verifiable, consensus-based systems.\nWe accelerate the entire protocol, including two major primitives: SumCheck and\nMulti-scalar Multiplications (MSMs). We develop a full-chip architecture using\n366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation\nprocess, achieving geometric mean speedups of 801$\\times$ over CPU baselines.","main_category":"cs.AR","categories":"cs.AR,cs.CR","published":"2025-04-08T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.06223v1","title":"Generalized Bronnikov-Ellis wormhole solution in the\n  scalar-Einstein-Gauss-Bonnet $4d$ gravitational model","summary":"We consider the sEGB $4d$ gravitational model with a scalar field\n$\\varphi\\left(u\\right)$, Einstein and Gauss-Bonnet terms. The model action\ncontains a potential term $U\\left(\\varphi\\right))$, a Gauss-Bonnet coupling\nfunction $f\\left(\\varphi\\right)$ and a parameter $\\varepsilon = \\pm 1$, where\n$\\varepsilon = 1$ corresponds to the usual scalar field, and $\\varepsilon = -1$\nto the phantom field. In this paper, the sEGB reconstruction procedure\nconsidered in our previous paper is applied to the metric of the\nBronnikov-Ellis solution, which describes a massive wormhole in the model with\na phantom field (and zero potential). For this metric, written in the Buchdal\nparameterization with a radial variable $u$, we find a solution of the master\nequation for $ f\\left(\\varphi\\left(u\\right)\\right)$ with the integration\n(reconstruction) parameter $C_0$. We also find expressions for\n$U\\left(\\varphi\\left(u\\right)\\right)$ and $\\varepsilon \\dot{\\varphi} =\nh\\left(u\\right)$ for $\\varepsilon = \\pm 1$. We prove that for all non-trivial\nvalues of the parameter $C_0 \\neq 0$ the function $h\\left(u\\right)$ is not of\nconstant sign for all admissible $u \\in \\left(-\\infty , +\\infty\\right)$. This\nmeans that for a fixed value of the parameter $\\varepsilon = \\pm 1$ there is no\nnon-trivial sEGB reconstruction in which the scalar field is a purely ordinary\nfield ($\\varepsilon = 1$) or a purely phantom field ($\\varepsilon = - 1$).","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T17:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.06228v1","title":"SOFIA/upGREAT imaging spectroscopy of the [C II] 158 um fine structure\n  line toward the Sgr A region in the Galactic center","summary":"We present SOFIA/upGREAT velocity-resolved spectral imaging and analysis of\nthe 158 um [C II] spectral line toward the central 80 by 43\\,pc region of the\nCentral Molecular Zone of the Galaxy. The field we imaged with 14\" (0.6 pc)\nspatial and 1 km/s spectral resolution contains the Circum-Nuclear Disk (CND)\naround the central black hole Sgr A*, the neighboring thermal Arched Filaments,\nthe nonthermal filaments of the Radio Arc, and the three luminous central star\nclusters. [C II] traces emission from the CND's inner edge to material orbiting\nat a distance of approximately 6 pc. Its velocity field reveals no sign of\ninflowing material nor interaction with winds from the Sgr A East supernova\nremnant. Wide-field imaging of the Sgr A region shows multiple circular\nsegments, including the thermal Arched Filaments, that are centered on a region\nthat includes the Quintuplet cluster. We examine the possibility that the\nArched Filaments and other large-scale arcs trace transient excitation events\nfrom supernova blast waves. Along the Arched Filaments, comparisons among\nfar-IR fine structure lines show changes in ionization state over small scales\nand that high-excitation lines are systematically shifted in position from the\nother lines. These also point to transient fast winds that shocked on the\nsurface of the Arches cloud to produce additional local UV radiation to excite\nthe Arched Filaments on a cloud surface illuminated by UV from hot stars.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T17:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.06231v1","title":"Orb-v3: atomistic simulation at scale","summary":"We introduce Orb-v3, the next generation of the Orb family of universal\ninteratomic potentials. Models in this family expand the\nperformance-speed-memory Pareto frontier, offering near SoTA performance across\na range of evaluations with a >10x reduction in latency and > 8x reduction in\nmemory. Our experiments systematically traverse this frontier, charting the\ntrade-off induced by roto-equivariance, conservatism and graph sparsity.\nContrary to recent literature, we find that non-equivariant, non-conservative\narchitectures can accurately model physical properties, including those which\nrequire higher-order derivatives of the potential energy surface.\n  This model release is guided by the principle that the most valuable\nfoundation models for atomic simulation will excel on all fronts: accuracy,\nlatency and system size scalability. The reward for doing so is a new era of\ncomputational chemistry driven by high-throughput and mesoscale all-atom\nsimulations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.06263v1","title":"OmniSVG: A Unified Scalable Vector Graphics Generation Model","summary":"Scalable Vector Graphics (SVG) is an important image format widely adopted in\ngraphic design because of their resolution independence and editability. The\nstudy of generating high-quality SVG has continuously drawn attention from both\ndesigners and researchers in the AIGC community. However, existing methods\neither produces unstructured outputs with huge computational cost or is limited\nto generating monochrome icons of over-simplified structures. To produce\nhigh-quality and complex SVG, we propose OmniSVG, a unified framework that\nleverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal\nSVG generation. By parameterizing SVG commands and coordinates into discrete\ntokens, OmniSVG decouples structural logic from low-level geometry for\nefficient training while maintaining the expressiveness of complex SVG\nstructure. To further advance the development of SVG synthesis, we introduce\nMMSVG-2M, a multimodal dataset with two million richly annotated SVG assets,\nalong with a standardized evaluation protocol for conditional SVG generation\ntasks. Extensive experiments show that OmniSVG outperforms existing methods and\ndemonstrates its potential for integration into professional SVG design\nworkflows.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:49Z"}
{"aid":"http://arxiv.org/abs/2504.06567v1","title":"A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in\n  Mixed Near-field and Far-field Scenarios","summary":"The recently proposed multi-chirp waveform, affine frequency division\nmultiplexing (AFDM), is considered as a potential candidate for integrated\nsensing and communication (ISAC). However, acquiring accurate target sensing\nparameter information becomes challenging due to fractional delay and Doppler\nshift occurrence, as well as effects introduced by the coexistence of\nnear-field (NF) and far-field (FF) targets associated with large-scale antenna\nsystems. In this paper, we propose a novel angle-delay-Doppler estimation\nscheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we\nmodel the received ISAC signals as a third-order tensor that admits a low-rank\nCANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the\nfactor matrix and the spatial smoothing technique, we develop a structured CP\ndecomposition method that guarantees the condition for uniqueness. We further\npropose a low-complexity estimation scheme to acquire target sensing parameters\nwith fractional values, including angle of arrival/departure (AoA/AoD), delay\nand Doppler shift accurately. We also derive the Cram\\'er-Rao Lower Bound\n(CRLB) as a benchmark and analyze the complexity of our proposed scheme.\nFinally, simulation results are provided to demonstrate the effectiveness and\nsuperiority of our proposed scheme.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T04:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.06572v1","title":"Domain Generalization via Discrete Codebook Learning","summary":"Domain generalization (DG) strives to address distribution shifts across\ndiverse environments to enhance model's generalizability. Current DG approaches\nare confined to acquiring robust representations with continuous features,\nspecifically training at the pixel level. However, this DG paradigm may\nstruggle to mitigate distribution gaps in dealing with a large space of\ncontinuous features, rendering it susceptible to pixel details that exhibit\nspurious correlations or noise. In this paper, we first theoretically\ndemonstrate that the domain gaps in continuous representation learning can be\nreduced by the discretization process. Based on this inspiring finding, we\nintroduce a novel learning paradigm for DG, termed Discrete Domain\nGeneralization (DDG). DDG proposes to use a codebook to quantize the feature\nmap into discrete codewords, aligning semantic-equivalent information in a\nshared discrete representation space that prioritizes semantic-level\ninformation over pixel-level intricacies. By learning at the semantic level,\nDDG diminishes the number of latent features, optimizing the utilization of the\nrepresentation space and alleviating the risks associated with the wide-ranging\nspace of continuous features. Extensive experiments across widely employed\nbenchmarks in DG demonstrate DDG's superior performance compared to\nstate-of-the-art approaches, underscoring its potential to reduce the\ndistribution gaps and enhance the model's generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T04:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06584v1","title":"CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory\n  Planning in Autonomous Driving","summary":"Imitation learning based planning tasks on the nuPlan dataset have gained\ngreat interest due to their potential to generate human-like driving behaviors.\nHowever, open-loop training on the nuPlan dataset tends to cause causal\nconfusion during closed-loop testing, and the dataset also presents a long-tail\ndistribution of scenarios. These issues introduce challenges for imitation\nlearning. To tackle these problems, we introduce CAFE-AD, a Cross-Scenario\nAdaptive Feature Enhancement for Trajectory Planning in Autonomous Driving\nmethod, designed to enhance feature representation across various scenario\ntypes. We develop an adaptive feature pruning module that ranks feature\nimportance to capture the most relevant information while reducing the\ninterference of noisy information during training. Moreover, we propose a\ncross-scenario feature interpolation module that enhances scenario information\nto introduce diversity, enabling the network to alleviate over-fitting in\ndominant scenarios. We evaluate our method CAFE-AD on the challenging public\nnuPlan Test14-Hard closed-loop simulation benchmark. The results demonstrate\nthat CAFE-AD outperforms state-of-the-art methods including rule-based and\nhybrid planners, and exhibits the potential in mitigating the impact of\nlong-tail distribution within the dataset. Additionally, we further validate\nits effectiveness in real-world environments. The code and models will be made\navailable at https://github.com/AlniyatRui/CAFE-AD.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-09T05:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.06612v1","title":"A Hilbert--Mumford criterion for generalised Monge--AmpÃ¨re equations","summary":"We give a new numerical criterion in the spirit of GIT for existence of\nsolutions to inverse Hessian equations, including in particular the J-equation.\nOur criterion is formulated in terms of stability of pairs in the sense of\nPaul. To that end, we build on previous work of the author with Dervan, and\ngeneralise a result of Zhang, proving isometry between generalised Chow line\nbundles and mixed Deligne pairings.","main_category":"math.DG","categories":"math.DG,math.AG","published":"2025-04-09T06:16:59Z"}
{"aid":"http://arxiv.org/abs/2504.06618v1","title":"Human-like compositional learning of visually-grounded concepts using\n  synthetic environments","summary":"The compositional structure of language enables humans to decompose complex\nphrases and map them to novel visual concepts, showcasing flexible\nintelligence. While several algorithms exhibit compositionality, they fail to\nelucidate how humans learn to compose concept classes and ground visual cues\nthrough trial and error. To investigate this multi-modal learning challenge, we\ndesigned a 3D synthetic environment in which an agent learns, via\nreinforcement, to navigate to a target specified by a natural language\ninstruction. These instructions comprise nouns, attributes, and critically,\ndeterminers, prepositions, or both. The vast array of word combinations\nheightens the compositional complexity of the visual grounding task, as\nnavigating to a blue cube above red spheres is not rewarded when the\ninstruction specifies navigating to \"some blue cubes below the red sphere\". We\nfirst demonstrate that reinforcement learning agents can ground determiner\nconcepts to visual targets but struggle with more complex prepositional\nconcepts. Second, we show that curriculum learning, a strategy humans employ,\nenhances concept learning efficiency, reducing the required training episodes\nby 15% in determiner environments and enabling agents to easily learn\nprepositional concepts. Finally, we establish that agents trained on determiner\nor prepositional concepts can decompose held-out test instructions and rapidly\nadapt their navigation policies to unseen visual object combinations.\nLeveraging synthetic environments, our findings demonstrate that multi-modal\nreinforcement learning agents can achieve compositional understanding of\ncomplex concept classes and highlight the efficacy of human-like learning\nstrategies in improving artificial systems' learning efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:33:28Z"}
{"aid":"http://arxiv.org/abs/2504.06634v1","title":"Crafting Query-Aware Selective Attention for Single Image\n  Super-Resolution","summary":"Single Image Super-Resolution (SISR) reconstructs high-resolution images from\nlow-resolution inputs, enhancing image details. While Vision Transformer\n(ViT)-based models improve SISR by capturing long-range dependencies, they\nsuffer from quadratic computational costs or employ selective attention\nmechanisms that do not explicitly focus on query-relevant regions. Despite\nthese advancements, prior work has overlooked how selective attention\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\ndynamically selects the most relevant key-value windows based on query\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\nIn contrast to prior approaches that apply attention globally or heuristically,\nour method introduces a query-aware window selection strategy that better\naligns attention computation with important image regions. By incorporating\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\ntoken-to-token complexity, making it scalable for large images. Our experiments\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\ncomputational efficiency and reconstruction quality in SISR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:17:29Z"}
{"aid":"http://arxiv.org/abs/2504.06637v1","title":"SCI-Reason: A Dataset with Chain-of-Thought Rationales for Complex\n  Multimodal Reasoning in Academic Areas","summary":"Large Language Models (LLMs) and Large Multimodal Models (LMMs) demonstrate\nimpressive problem-solving skills in many tasks and domains. However, their\nability to reason with complex images in academic domains has not been\nsystematically investigated. To bridge this gap, we present SCI-Reason, a\ndataset for complex multimodel reasoning in academic areas. SCI-Reason aims to\ntest and improve the reasoning ability of large multimodal models using real\ncomplex images in academic domains. The dataset contains 12,066 images and\n12,626 question-answer pairs extracted from PubMed, divided into training,\nvalidation and test splits. Each question-answer pair also contains an accurate\nand efficient inference chain as a guide to improving the inference properties\nof the dataset. With SCI-Reason, we performed a comprehensive evaluation of 8\nwell-known models. The best performing model, Claude-3.7-Sonnet, only achieved\nan accuracy of 55.19%. Error analysis shows that more than half of the model\nfailures are due to breakdowns in multi-step inference chains rather than\nerrors in primary visual feature extraction. This finding underscores the\ninherent limitations in reasoning capabilities exhibited by current multimodal\nmodels when processing complex image analysis tasks within authentic academic\ncontexts. Experiments on open-source models show that SCI-Reason not only\nenhances reasoning ability but also demonstrates cross-domain generalization in\nVQA tasks. We also explore future applications of model inference capabilities\nin this domain, highlighting its potential for future research.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-09T07:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06651v1","title":"Collision avoidance from monocular vision trained with novel view\n  synthesis","summary":"Collision avoidance can be checked in explicit environment models such as\nelevation maps or occupancy grids, yet integrating such models with a\nlocomotion policy requires accurate state estimation. In this work, we consider\nthe question of collision avoidance from an implicit environment model. We use\nmonocular RGB images as inputs and train a collisionavoidance policy from\nphotorealistic images generated by 2D Gaussian splatting. We evaluate the\nresulting pipeline in realworld experiments under velocity commands that bring\nthe robot on an intercept course with obstacles. Our results suggest that RGB\nimages can be enough to make collision-avoidance decisions, both in the room\nwhere training data was collected and in out-of-distribution environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:39:12Z"}
{"aid":"http://arxiv.org/abs/2504.06681v1","title":"Mechanical stability of resonant Bose-Fermi mixtures","summary":"We investigate the mechanical stability of Bose-Fermi mixtures at zero\ntemperature in the presence of a tunable Feshbach resonance, which induces a\ncompetition between boson condensation and boson-fermion pairing when the boson\ndensity is smaller than the fermion density. Using a many-body diagrammatic\napproach validated by fixed-node Quantum Monte Carlo calculations and supported\nby recent experimental observations, we determine the minimal amount of\nboson-boson repulsion required to guarantee the stability of the mixture across\nthe entire range of boson-fermion interactions from weak to strong coupling.\nOur stability phase diagrams indicate that mixtures with boson-to-fermion mass\nratios near two, such as the $^{87}$Rb-$^{40}$K system, exhibit optimal\nstability conditions. Moreover, by applying our results to a recent experiment\nwith a $^{23}$Na-$^{40}$K mixture, we find that the boson-boson repulsion was\ninsufficient to ensure stability, suggesting that the experimental timescale\nwas short enough to avoid mechanical collapse. On the other hand, we also show\nthat even in the absence of boson-boson repulsion, Bose-Fermi mixtures become\nintrinsically stable beyond a certain coupling strength, preceding the quantum\nphase transition associated with the vanishing of the bosonic condensate. We\nthus propose an experimental protocol for observing this quantum phase\ntransition in a mechanically stable configuration.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-09T08:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.06690v1","title":"Homogenization theory of random walks in degenerate random environment","summary":"Recent progress on the understanding of the Random Conductance Model is\nreviewed. A particular emphasis is on homogenization results such as functional\ncentral limit theorems, local limit theorems and heat kernel estimates for\nalmost every realization of the environment, established for random walks among\nstationary ergodic conductances that are possibly unbounded but satisfy certain\nmoment conditions.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T08:52:16Z"}
{"aid":"http://arxiv.org/abs/2504.06696v1","title":"Kerr enhanced optomechanical entanglement via reservoir design","summary":"Quantum entanglement is a crucial resource in quantum technologies, enabling\nadvancements in quantum computing, quantum communication, and quantum precision\nmeasurement. Here, we propose a method to enhance optomechanical entanglement\nby introducing an optical Kerr nonlinear medium and a squeezed vacuum reservoir\nof the optomechanical cavity. By performing the displacement and squeezing\ntransformations, the system can be reduced to a standard linearized\noptomechanical system with normalized driving detuning and linearized-coupling\nstrength, in which the optical and mechanical modes are, respectively, coupled\nto an optical vacuum bath and a mechanical heat bath. We focus on the\nentanglement generation in the single stable regime of the system. By\nevaluating the steady-state logarithm negativity, we find that the\noptomechanical entanglement can be enhanced within a wide range of the Kerr\nconstant. In addition, the Kerr nonlinearity can extend the stable region,\nenabling considerable entanglement generation in the blue sideband-parameter\nregion. We also investigate the dependence of the entanglement generation on\nthe average thermal phonon occupation of the mechanical bath and the optical\ndriving amplitude. It is found that the presence of the Kerr nonlinearity\nallows the generation of optomechanical entanglement even when the thermal\nphonon occupation of the mechanical bath is as high as 3000. Our findings will\nprovide valuable insights into enhancing fragile quantum resources in quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T08:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.06715v1","title":"Bistability and complex bifurcation diagrams generated by waning and\n  boosting of immunity","summary":"We investigate an epidemiological model that incorporates waning of immunity\nat the individual level and boosting of the immune system upon re-exposure to\nthe pathogen. When immunity is fully restored upon boosting, the system can be\nexpressed as an SIRS-type model with discrete and distributed delays. We\nconduct a numerical bifurcation analysis varying the boosting force and the\nmaximum period of immunity (in the absence of boosting), while keeping other\nparameters fixed at values representative of a highly infectious disease like\npertussis. The stability switches of the endemic equilibrium, identified\nnumerically, are validated using an established analytical approach, confirming\nthat the equilibrium is unstable in a bounded parameter region, and stable\noutside this region. Using recently developed continuation methods for models\nwith discrete and distributed delays, we explore periodic solutions and their\nbifurcations. Our analysis significantly extends previous findings and reveals\na rich dynamical landscape, including catastrophic bifurcations of limit\ncycles, torus bifurcations, and bistability regions where two stable periodic\nsolutions coexist, differing in amplitude and period. These complex\nbifurcations have critical public health implications: perturbations--such as\nnon-pharmaceutical interventions--can shift the system between attractors,\nleading to long-term consequences from short-term measures.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T09:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.06728v1","title":"Light-field dressing of transient photo-excited states above $E_F$","summary":"Time-periodic light-field provides an emerging pathway for dynamically\nengineering quantum materials by forming hybrid states between photons and\nBloch electrons. So far, experimental progress on light-field dressed states\nhas been mainly focused on the occupied states, however, it is unclear if the\ntransient photo-excited states above the Fermi energy $E_F$ can also be\ndressed, leaving the dynamical interplay between photo-excitation and\nlight-field dressing elusive. Here, we provide direct experimental evidence for\nlight-field dressing of the transient photo-excited surface states above $E_F$,\nwhich exhibits distinct dynamics with a delay response as compared to\nlight-field dressed states below $E_F$. Our work reveals the dual roles of the\npump pulse in both photo-excitation and light-field dressing, providing a more\ncomprehensive picture with new insights on the light-induced manipulation of\ntransient electronic states.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T09:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.06760v1","title":"Applications of Poisson cohomology to the inducibility problems and\n  study of deformation maps","summary":"This paper provides some applications of the Poisson cohomology groups\nintroduced by Flato, Gerstenhaber and Voronov. Given an abelian extension of a\nPoisson algebra by a representation, we first investigate the inducibility of a\npair of Poisson algebra automorphisms and show that the corresponding\nobstruction lies in the second Poisson cohomology group. Consequently, we\nobtain the Wells exact sequence connecting various automorphism groups and the\nsecond Poisson cohomology group. Subsequently, we also consider the\ninducibility for a pair of Poisson algebra derivations, obtain the obstruction\nand construct the corresponding Wells-type exact sequence.\n  To get another application, we introduce the notion of a `deformation map' in\na proto-twilled Poisson algebra. A deformation map unifies various well-known\noperators such as Poisson homomorphisms, Poisson derivations, crossed\nhomomorphisms, Rota-Baxter operators of any weight, twisted Rota-Baxter\noperators, Reynolds operators and modified Rota-Baxter operators on Poisson\nalgebras. We show that a deformation map $r$ induces a new Poisson algebra\nstructure and a suitable representation of it. The corresponding Poisson\ncohomology is defined to be the cohomology of the deformation map $r$. Finally,\nwe study the formal deformations of the operator $r$ in terms of the\ncohomology.","main_category":"math.RT","categories":"math.RT,math.KT,math.RA","published":"2025-04-09T10:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.06773v1","title":"On the Destruction of Invariant Lagrangian Graphs for Conformal\n  Symplectic Twist Maps","summary":"In this article we investigate the fragility of invariant Lagrangian graphs\nfor dissipative maps, focusing on their destruction under small perturbations.\nInspired by Herman's work on conservative systems, we prove that all\n$C^0$-invariant Lagrangian graphs for an integrable dissipative twist maps can\nbe destroyed by perturbations that are arbitrarily small in the\n$C^{1-\\varepsilon}$-topology. This result is sharp, as evidenced by the\npersistence of $C^1$-invariant graphs under $C^1$-perturbations guaranteed by\nthe normally hyperbolic invariant manifold theorem.","main_category":"math.DS","categories":"math.DS,math.SG","published":"2025-04-09T10:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.06785v1","title":"Zero-Shot Image-Based Large Language Model Approach to Road Pavement\n  Monitoring","summary":"Effective and rapid evaluation of pavement surface condition is critical for\nprioritizing maintenance, ensuring transportation safety, and minimizing\nvehicle wear and tear. While conventional manual inspections suffer from\nsubjectivity, existing machine learning-based methods are constrained by their\nreliance on large and high-quality labeled datasets, which require significant\nresources and limit adaptability across varied road conditions. The\nrevolutionary advancements in Large Language Models (LLMs) present significant\npotential for overcoming these challenges. In this study, we propose an\ninnovative automated zero-shot learning approach that leverages the image\nrecognition and natural language understanding capabilities of LLMs to assess\nroad conditions effectively. Multiple LLM-based assessment models were\ndeveloped, employing prompt engineering strategies aligned with the Pavement\nSurface Condition Index (PSCI) standards. These models' accuracy and\nreliability were evaluated against official PSCI results, with an optimized\nmodel ultimately selected. Extensive tests benchmarked the optimized model\nagainst evaluations from various levels experts using Google Street View road\nimages. The results reveal that the LLM-based approach can effectively assess\nroad conditions, with the optimized model -employing comprehensive and\nstructured prompt engineering strategies -outperforming simpler configurations\nby achieving high accuracy and consistency, even surpassing expert evaluations.\nMoreover, successfully applying the optimized model to Google Street View\nimages demonstrates its potential for future city-scale deployments. These\nfindings highlight the transformative potential of LLMs in automating road\ndamage evaluations and underscore the pivotal role of detailed prompt\nengineering in achieving reliable assessments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.06796v1","title":"Learning in Spiking Neural Networks with a Calcium-based Hebbian Rule\n  for Spike-timing-dependent Plasticity","summary":"Understanding how biological neural networks are shaped via local plasticity\nmechanisms can lead to energy-efficient and self-adaptive information\nprocessing systems, which promises to mitigate some of the current roadblocks\nin edge computing systems. While biology makes use of spikes to seamless use\nboth spike timing and mean firing rate to modulate synaptic strength, most\nmodels focus on one of the two. In this work, we present a Hebbian local\nlearning rule that models synaptic modification as a function of calcium traces\ntracking neuronal activity. We show how the rule reproduces results from spike\ntime and spike rate protocols from neuroscientific studies. Moreover, we use\nthe model to train spiking neural networks on MNIST digit recognition to show\nand explain what sort of mechanisms are needed to learn real-world patterns. We\nshow how our model is sensitive to correlated spiking activity and how this\nenables it to modulate the learning rate of the network without altering the\nmean firing rate of the neurons nor the hyparameters of the learning rule. To\nthe best of our knowledge, this is the first work that showcases how spike\ntiming and rate can be complementary in their role of shaping the connectivity\nof spiking neural networks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-09T11:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.06816v1","title":"A Graph Diffusion Algorithm for Lexical Similarity Evaluation","summary":"In this paper, we present an algorithm for evaluating lexical similarity\nbetween a given language and several reference language clusters. As an input,\nwe have a list of concepts and the corresponding translations in all considered\nlanguages. Moreover, each reference language is assigned to one of $c$ language\nclusters. For each of the concepts, the algorithm computes the distance between\neach pair of translations. Based on these distances, it constructs a weighted\ndirected graph, where every vertex represents a language. After, it solves a\ngraph diffusion equation with a Dirichlet boundary condition, where the unknown\nis a map from the vertex set to $\\mathbb{R}^c$. The resulting coordinates are\nvalues from the interval $[0,1]$ and they can be interpreted as probabilities\nof belonging to each of the clusters or as a lexical similarity distribution\nwith respect to the reference clusters. The distances between translations are\ncalculated using phonetic transcriptions and a modification of the\nDamerau-Levenshtein distance. The algorithm can be useful in analyzing\nrelationships between languages spoken in multilingual territories with a lot\nof mutual influences. We demonstrate this by presenting a case study regarding\nvarious European languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.06864v1","title":"Emergent Theory for Constitutive Relations in Classical Defect Systems","summary":"Optical, acoustic, hydrodynamic, and thermal defect systems are often studied\nby analogy with each other. This may indicate that we may find a emergent\ntheory for constitutive relations of classical defect systems. Start with\nthermal systems, we put up with a bootstrap method to describe classical\ntransport. We conjecture that Landau-Khalatnikov equation could provide heat\nconstitutive relations when taking heat flux as order parameter. We show that\nthe corresponding effctive Lagrangian has similar form of that of Wick-rotated\ncomplex scalar field theory at non-relativistic limit, and only in perfect\nconducting situation that this system is a canonical ensemble. We argue that\nour method could be generalized to other systems besides thermal ones. By\nanalogy with ferroelectrics, we propose the thermal domain model, which is a\nconserved current XY model. Phase transition of the thermal system is\nqualitatively discussed in this model.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.supr-con,hep-th","published":"2025-04-09T13:13:14Z"}
{"aid":"http://arxiv.org/abs/2504.06873v1","title":"A note on measurings and higher order Hochschild homology of algebras","summary":"We know that coalgebra measurings behave like generalized maps between\nalgebras. In this note, we show that coalgebra measurings between commutative\nalgebras induce morphisms between higher order Hochschild homology groups of\nalgebras. By higher order Hochschild homology, we mean the the Hochschild\nhomology groups of a commutative algebra with respect to a simplicial set as\nintroduced by Pirashvili.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T13:24:20Z"}
{"aid":"http://arxiv.org/abs/2504.06879v1","title":"Machine Learning Approach to Study of Low Energy Alpha-Deuteron Elastic\n  Scattering using Phase Function Method","summary":"Central idea: To obtain the interaction potential using the inverse\nscattering method, we have employed the Physics-Informed Machine Learning\n(PIML) approach. In this framework, the machine learning algorithm is guided by\nthe underlying physical laws, enabling the accurate extraction of the inverse\nscattering potential from the elastic scattering data. Methodology: As a\nreference potential, a combination of three smoothly joined Morse functions has\nbeen utilized, characterized by ten model parameters. These parameters are\noptimized in an iterative fashion using a Genetic Algorithm to ensure the best\nfit to the phase shifts extracted from the experimental scattering data. The\nprocess of optimization is guided by the computed scattering phase shifts by\nsolving the phase equation using 5th order RK-method for the reference\npotential in each iteration Results: Our approach yields inverse potentials for\nboth single and multi channel scattering. Using the Scattering Phase Shifts\nobtained from these inverse potentials, we calculate the partial cross-section\nto determine the resonance energies and decay width. The obtain values of\nresonance energies and decay width for 3D1, 3D2 and 3D3 states of\nalpha-deuteron are in correspondence with the experimental results. Conclusion:\nIt can be concluded that our machine learning-based approach for constructing\nthe inverse potential offers a novel and complementary technique to existing\ndirect methods.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T13:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.06881v1","title":"Compound and Parallel Modes of Tropical Convolutional Neural Networks","summary":"Convolutional neural networks have become increasingly deep and complex,\nleading to higher computational costs. While tropical convolutional neural\nnetworks (TCNNs) reduce multiplications, they underperform compared to standard\nCNNs. To address this, we propose two new variants - compound TCNN (cTCNN) and\nparallel TCNN (pTCNN)-that use combinations of tropical min-plus and max-plus\nkernels to replace traditional convolution kernels. This reduces\nmultiplications and balances efficiency with performance. Experiments on\nvarious datasets show that cTCNN and pTCNN match or exceed the performance of\nother CNN methods. Combining these with conventional CNNs in deeper\narchitectures also improves performance. We are further exploring simplified\nTCNN architectures that reduce parameters and multiplications with minimal\naccuracy loss, aiming for efficient and effective models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.6","published":"2025-04-09T13:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.06898v1","title":"Identifying and mitigating errors in hole spin qubit readout","summary":"High-fidelity readout of spin qubits in semiconductor quantum dots can be\nachieved by combining a radio-frequency (RF) charge sensor together with\nspin-to-charge conversion and Pauli spin blockade. However, reaching high\nreadout fidelities in hole spin qubits remains elusive and is complicated by a\ncombination of site-dependent spin anisotropies and short spin relaxation\ntimes. Here, we analyze the different error processes that arise during readout\nusing a double-latched scheme in a germanium double quantum dot hole spin qubit\nsystem. We first investigate the spin-to-charge conversion process as a\nfunction of magnetic field orientation, and configure the system to\nadiabatically map the $\\lvert \\downarrow\\downarrow \\rangle$ state to the only\nnon-blockaded state. We reveal a strong dependence of the spin relaxation rates\non magnetic field strength and minimize this relaxation by operating at low\nfields. We further characterize and mitigate the error processes that arise\nduring the double-latching process. By combining an RF charge sensor, a\ndouble-latching process, and optimized magnetic field parameters, we achieve a\nsingle-shot single-qubit state-preparation-and-measurement fidelity of 97.0%,\nthe highest reported fidelity for hole spin qubits. Unlike prior works and\nvital to usability, we simultaneously maintain universal control of both spins.\nThese findings lay the foundation for the reproducible achievement of\nhigh-fidelity readout in hole-based spin quantum processors.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-09T13:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.06901v1","title":"Classification of algebraic tangles","summary":"We study algebraic tangles as fundamental components in knot theory,\ndeveloping a systematic approach to classify and tabulate prime tangles using a\nnovel canonical representation. The canonical representation enables us to\ndistinguish mutant tangles, which fills the gaps in previous classifications.\nMoreover, we increase the classification of prime tangles up to 14 crossings\nand analyze tangle symmetry groups. We provide a database of our results:\nhttps://tangleinfo.cent.uw.edu.pl.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR,math.NT","published":"2025-04-09T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.06903v1","title":"Network Cross-Validation and Model Selection via Subsampling","summary":"Complex and larger networks are becoming increasingly prevalent in scientific\napplications in various domains. Although a number of models and methods exist\nfor such networks, cross-validation on networks remains challenging due to the\nunique structure of network data. In this paper, we propose a general\ncross-validation procedure called NETCROP (NETwork CRoss-Validation using\nOverlapping Partitions). The key idea is to divide the original network into\nmultiple subnetworks with a shared overlap part, producing training sets\nconsisting of the subnetworks and a test set with the node pairs between the\nsubnetworks. This train-test split provides the basis for a network\ncross-validation procedure that can be applied on a wide range of model\nselection and parameter tuning problems for networks. The method is\ncomputationally efficient for large networks as it uses smaller subnetworks for\nthe training step. We provide methodological details and theoretical guarantees\nfor several model selection and parameter tuning tasks using NETCROP. Numerical\nresults demonstrate that NETCROP performs accurate cross-validation on a\ndiverse set of network model selection and parameter tuning problems. The\nresults also indicate that NETCROP is computationally much faster while being\noften more accurate than the existing methods for network cross-validation.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-09T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.06909v1","title":"Climate impacts of equatorial superrotation","summary":"While it is expected that the large-scale tropical circulation should undergo\nsome changes in a warmer climate, it remains an open question whether its\ncharacteristic features, such as the Hadley cell, the intertropical convergence\nzone, or the weak surface easterlies, could take a completely different shape.\nAs an example, it has been hypothesized that the Earth's atmosphere may have\nexperienced equatorial superrotation -- i.e. westerly winds at the equator --\nduring its history. The possibility of equatorial superrotation has been\nstudied in a range of planetary atmospheres, including Earth-like ones, with\nthe objective of understanding the underlying dynamical processes. However, the\nbroader impact that this dramatic circulation change would have on the climate\nsystem is practically unexplored. This is the question we address here. We\nperform idealized GCM simulations with an imposed equatorial torque to\ninvestigate how a forced superrotating atmosphere affects surface temperature\nand the water cycle. We show that these effects are quite large and directly\nrelated to the global circulation changes, which extend beyond the tropical\natmosphere. Using tools including a forcing/feedback analysis and a moist\nenergy balance model, we argue that the dominant mechanism is changes in\natmospheric energy transport, driven in particular by the collapse of the\nmeridional overturning circulation, and to a smaller extent by the appearance\nof an equatorial jet, and the concomitant redistribution of moisture in the\ntropics, leading to a much weaker relative humidity gradient which has strong\nradiative effects.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T14:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.06913v1","title":"Controlling a Social Network of Individuals with Coevolving Actions and\n  Opinions","summary":"In this paper, we consider a population of individuals who have actions and\nopinions, which coevolve, mutually influencing one another on a complex network\nstructure. In particular, we formulate a control problem for this social\nnetwork, in which we assume that we can inject into the network a committed\nminority -- a set of stubborn nodes -- with the objective of steering the\npopulation, initially at a consensus, to a different consensus state. Our study\nfocuses on two main objectives: i) determining the conditions under which the\ncommitted minority succeeds in its goal, and ii) identifying the optimal\nplacement for such a committed minority. After deriving general monotone\nconvergence result for the controlled dynamics, we leverage these results to\nbuild a computationally-efficient algorithm to solve the first problem and an\neffective heuristics for the second problem, which we prove to be NP-complete.\nThe proposed methodology is illustrated though academic examples, and\ndemonstrated on a real-world case study.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.DS","published":"2025-04-09T14:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.06951v1","title":"GLT hidden structures in mean-field quantum spin systems","summary":"This work explores structured matrix sequences arising in mean-field quantum\nspin systems. We express these sequences within the framework of generalized\nlocally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix\nsequence has a unique GLT symbol. This symbol characterizes both the asymptotic\nsingular value distribution and, for Hermitian or quasi-Hermitian sequences,\nthe asymptotic spectral distribution. Specifically, we analyze two cases of\nreal symmetric matrix sequences stemming from mean-field quantum spin systems\nand determine their associated distributions using GLT theory. Our study\nconcludes with visualizations and numerical tests that validate the theoretical\nfindings, followed by a discussion of open problems and future directions.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-09T14:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.06990v1","title":"Enhancing TiFe Alloy Activation for Hydrogen Storage Through Al, Cr, Co,\n  and Cu Substitutions as a Step Towards Future Recycling","summary":"This study investigates the activation behavior of $TiFe_{0.80}$-$X_{0.20}$\n(X = Co, Cu, Cr, Al) alloys to identify the most effective materials for\nproducing hydrogen storage alloys from recycled sources in view of a circular\neconomy perspective. Activation was tested using two methods: a Sievert\nVolumetric Apparatus at room temperature and 64 bar of hydrogen, and\nhigh-pressure differential scanning calorimetry with 50 bar hydrogen under\nthermal cycles up to 400 {\\deg}C. Activation properties were analyzed by\nassessing time for incubation and for full charging, that are influenced,\nrespectively, by surface and bulk diffusion of hydrogen. Results showed that\nCr-substituted alloys are rapidly activated, due to the presence of $TiCr_{2}$\ncompound, while Al-containing alloys absorbed hydrogen immediately. In\ncontrast, Co- and Cu-substituted alloys required extended activation times, due\nto less quantity of secondary phases and limited diffusion channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T15:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.06993v1","title":"Screening of material defects using universal machine-learning\n  interatomic potentials","summary":"Finding new materials with previously unknown atomic structure or materials\nwith optimal set of properties for a specific application greatly benefits from\ncomputational modeling. Recently, such screening has been dramatically\naccelerated by the invent of universal machine-learning interatomic potentials\nthat offer first principles accuracy at orders of magnitude lower computational\ncost. Their application to the screening of defects with desired properties or\nto finding new stable compounds with high density of defects, however, has not\nbeen explored. Here, we show that the universal machine-learning interatomic\npotentials have reached sufficient accuracy to enable large-scale screening of\ndefective materials. We carried out vacancy calculations for 86 259 materials\nin the Materials Project database and analyzed the formation energies in terms\nof oxidation numbers. We further demonstrate the application of these models\nfor finding new materials at or below the convex hull of known materials and\nfor simulated etching of low-dimensional materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-09T16:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.07010v1","title":"Assumption-free fidelity bounds for hardware noise characterization","summary":"In the Quantum Supremacy regime, quantum computers may overcome classical\nmachines on several tasks if we can estimate, mitigate, or correct unavoidable\nhardware noise. Estimating the error requires classical simulations, which\nbecome unfeasible in the Quantum Supremacy regime. We leverage Machine Learning\ndata-driven approaches and Conformal Prediction, a Machine Learning uncertainty\nquantification tool known for its mild assumptions and finite-sample validity,\nto find theoretically valid upper bounds of the fidelity between noiseless and\nnoisy outputs of quantum devices. Under reasonable extrapolation assumptions,\nthe proposed scheme applies to any Quantum Computing hardware, does not require\nmodeling the device's noise sources, and can be used when classical simulations\nare unavailable, e.g. in the Quantum Supremacy regime.","main_category":"quant-ph","categories":"quant-ph,cs.LG,stat.ML","published":"2025-04-09T16:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.07032v1","title":"Restoring the Forecasting Power of Google Trends with Statistical\n  Preprocessing","summary":"Google Trends reports how frequently specific queries are searched on Google\nover time. It is widely used in research and industry to gain early insights\ninto public interest. However, its data generation mechanism introduces missing\nvalues, sampling variability, noise, and trends. These issues arise from\nprivacy thresholds mapping low search volumes to zeros, daily sampling\nvariations causing discrepancies across historical downloads, and algorithm\nupdates altering volume magnitudes over time. Data quality has recently\ndeteriorated, with more zeros and noise, even for previously stable queries. We\npropose a comprehensive statistical methodology to preprocess Google Trends\nsearch information using hierarchical clustering, smoothing splines, and\ndetrending. We validate our approach by forecasting U.S. influenza\nhospitalizations with a univariate ARIMAX model. Compared to omitting exogenous\nvariables, our results show that raw Google Trends data degrades modeling\nperformance, while preprocessed signals enhance forecast accuracy by 58%\nnationally and 24% at the state level.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T16:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.07043v1","title":"BIA Transmission in Rate Splitting-based Optical Wireless Networks","summary":"Optical wireless communication (OWC) has recently received massive interest\nas a new technology that can support the enormous data traffic increasing on\ndaily basis. In particular, laser-based OWC networks can provide terabits per\nsecond (Tbps) aggregate data rates. However, the emerging OWC networks require\na high number of optical access points (APs), each AP corresponding to an\noptical cell, to provide uniform coverage for multiple users. Therefore,\ninter-cell interference (ICI) and multi-user interference (MUI) are crucial\nissues that must be managed efficiently to provide high spectral efficiency. In\nradio frequency (RF) networks, rate splitting (RS) is proposed as a\ntransmission scheme to serve multiple users simultaneously following a certain\nstrategy. It was shown that RS provides high data rates compared to orthogonal\nand non-orthogonal interference management schemes. Considering the high\ndensity of OWC networks, the application of RS within each optical cell might\nnot be practical due to severe ICI. In this paper, a new strategy is derived\nreferred to as blind interference alignment-rate splitting (BIA-RS) to fully\ncoordinate the transmission among the optical APs, while determining the\nprecoding matrices of multiple groups of users formed beforehand. Therefore, RS\ncan be implemented within each group to manage MUI. The proposed BIA-RS scheme\nrequires two layers of power allocation to achieve high performance. Given\nthat, a max-min fractional optimization problem is formulated to optimally\ndistribute the power budget among the groups and the messages intended to the\nusers of each group. Finally, a power allocation algorithm is designed with\nmultiple Lagrangian multipliers to provide practical and sub-optimal solutions.\nThe results show the high performance of the proposed scheme compared to other\ncounterpart schemes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T17:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.07051v1","title":"Revisiting X-ray polarization of the shell of Cassiopeia A using\n  spectropolarimetric analysis","summary":"X-ray synchrotron radiation is expected to be highly polarized. Thanks to the\nImaging X-ray Polarimetry Explorer (IXPE), it is now possible to evaluate the\ndegree of X-ray polarization in sources such as supernova remnants (SNRs).\nJointly using IXPE data and high-resolution Chandra observations, we perform a\nspatially resolved spectropolarimetric analysis of SNR Cassiopeia A (Cas A). We\nfocus in the 3-6 keV energy band on regions near the shell dominated by\nnonthermal synchrotron emission. By combining IXPE's polarization sensitivity\nwith Chandra's higher spatial and spectral resolution, we constrain the local\npolarization degree (PD) and polarization angle (PA) across the remnant. Our\nanalysis reveals PD values ranging locally from 10% to 26%, showing significant\nregional variations that underscore the complex magnetic field morphology of\nCas A. The polarization vectors indicate a predominantly radial magnetic field,\nconsistent with previous studies. Thanks to the improved modeling of thermal\ncontamination using Chandra data, we retrieve higher PD values compared to\nearlier IXPE analysis and more significant detections with respect to the\nstandard IXPEOBSSIM analysis. Finally, we also estimate the degree of magnetic\nturbulence {\\eta} from the measured photon index and PD, under the assumption\nof an isotropic fluctuating field across the shell of Cas A.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T17:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.07054v1","title":"Weighted Lojasiewicz inequalities and regularity of harmonic map flow","summary":"At a finite-time singularity of harmonic map flow in the critical dimension,\nwe show that a Lojasiewicz inequality between the quantities appearing in\nStruwe's monotonicity formula implies continuity of the body map and the\nno-neck property for bubble-tree decompositions. We prove such an inequality\nwhen the target is $S^2,$ yielding both properties in this case.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-09T17:14:34Z"}
{"aid":"http://arxiv.org/abs/2504.07437v1","title":"Unifying and extending Diffusion Models through PDEs for solving Inverse\n  Problems","summary":"Diffusion models have emerged as powerful generative tools with applications\nin computer vision and scientific machine learning (SciML), where they have\nbeen used to solve large-scale probabilistic inverse problems. Traditionally,\nthese models have been derived using principles of variational inference,\ndenoising, statistical signal processing, and stochastic differential\nequations. In contrast to the conventional presentation, in this study we\nderive diffusion models using ideas from linear partial differential equations\nand demonstrate that this approach has several benefits that include a\nconstructive derivation of the forward and reverse processes, a unified\nderivation of multiple formulations and sampling strategies, and the discovery\nof a new class of models. We also apply the conditional version of these models\nto solving canonical conditional density estimation problems and challenging\ninverse problems. These problems help establish benchmarks for systematically\nquantifying the performance of different formulations and sampling strategies\nin this study, and for future studies. Finally, we identify and implement a\nmechanism through which a single diffusion model can be applied to measurements\nobtained from multiple measurement operators. Taken together, the contents of\nthis manuscript provide a new understanding and several new directions in the\napplication of diffusion models to solving physics-based inverse problems.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-10T04:07:36Z"}
{"aid":"http://arxiv.org/abs/2504.07438v1","title":"Satellite System Architecting Considering On-Orbit Refueling","summary":"This paper introduces the problem of selecting a satellite system\narchitecture considering commercial on-orbit refueling (OOR). The problem aims\nto answer two questions: \"How durable should a satellite be?\" and \"How much\npropellant should be loaded into the satellite at launch?\" We formulate the\nproblem as a mathematical optimization by adopting the design lifetime and\npropellant mass as design variables and considering two objective functions to\nbalance the returns and risks. A surrogate model-based framework, grounded in a\nsatellite lifecycle simulation, is developed to address this problem. The\ndeveloped framework considers various uncertainties and operational flexibility\nand integrates a modified satellite sizing and cost model by adjusting\ntraditional models with OOR. A design case study of a geosynchronous equatorial\norbit communication satellite considering the OOR highlights the effectiveness\nof the developed framework.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.07446v1","title":"A mass conserved reaction-diffusion system reveals switching between\n  coexisting polar and oscillatory cell motility states","summary":"Motile eukaryotic cells display distinct modes of migration that often occur\nwithin the same cell type. It remains unclear, however, whether transitions\nbetween the migratory modes require changes in external conditions, or whether\nthe different modes are coexisting states that emerge from the underlying\nsignaling network. Using a mass-conserved reaction-diffusion model of small\nGTPase signaling with F-actin mediated feedback, we uncover a bistable regime\nwhere a polarized mode of migration coexists with spatiotemporal oscillations.\nIndeed, experimental observations of D. discoideum show that, upon collision\nwith a rigid boundary, cells may switch from polarized to disordered motion.","main_category":"nlin.PS","categories":"nlin.PS,q-bio.CB","published":"2025-04-10T04:31:22Z"}
{"aid":"http://arxiv.org/abs/2504.07460v1","title":"Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast\n  Radio Burst","summary":"The cosmic growth rate, which is related to peculiar velocity and is a\nprimary scientific objective of galaxy spectroscopic surveys, can be inferred\nfrom the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich\neffect. However, the reconstruction noise power spectrum of the radial velocity\nfield in kSZ is significantly dependent on the measurement of the small-scale\ngalaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss\nthe enhancement of cosmic growth rate measurements facilitated by Fast Radio\nBursts, which probe the electron density of the universe along their\npropagation paths to provide crucial additional information on $P_{ge}$.\nSubsequently, we utilize future spectroscopic surveys from the Chinese Space\nStation Telescope and the CMB-S4 experiment, combined with FRB dispersion\nmeasures, to achieve precise measurements of the cosmic growth rate at\nredshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis,\nwe anticipate that constraints on $f\\sigma_8$ will reach a precision of 0.001\nwith a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis\nusing Markov Chain Monte Carlo methods to constrain key parameters of three\ndistinct dark energy models and a modified gravity model based on cosmic growth\nrate measurements. The results demonstrate that these refined $f\\sigma_8$\nmeasurements considerably enhance the constraints on relevant cosmological\nparameters compared to those obtained from Planck. As the number of observed\nFRBs increases, alongside more precise galaxy surveys and next-generation CMB\nobservations, new opportunities will arise for constraining cosmological models\nusing the kSZ effect and for developing novel cosmological applications of\nFRBs.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T05:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07515v1","title":"Sequential Filtering Techniques for Simultaneous Tracking and Parameter\n  Estimation","summary":"The number of resident space objects is rising at an alarming rate.\nMega-constellations and breakup events are proliferating in most orbital\nregimes, and safe navigation is becoming increasingly problematic. It is\nimportant to be able to track RSOs accurately and at an affordable\ncomputational cost. Orbital dynamics are highly nonlinear, and current\noperational methods assume Gaussian representations of the objects' states and\nemploy linearizations which cease to hold true in observation-free propagation.\nMonte Carlo-based filters can provide a means to approximate the a posteriori\nprobability distribution of the states more accurately by providing support in\nthe portion of the state space which overlaps the most with the processed\nobservations. Moreover, dynamical models are not able to capture the full\nextent of realistic forces experienced in the near-Earth space environment, and\nhence fully deterministic propagation methods may fail to achieve the desired\naccuracy. By modeling orbital dynamics as a stochastic system and solving it\nusing stochastic numerical integrators, we are able to simultaneously estimate\nthe scale of the process noise incurred by the assumed uncertainty in the\nsystem, and robustly track the state of the spacecraft. In order to find an\nadequate balance between accuracy and computational cost, we propose three\nalgorithms which are capable of tracking a space object and estimating the\nmagnitude of the system's uncertainty. The proposed filters are successfully\napplied to a LEO scenario, demonstrating the ability to accurately track a\nspacecraft state and estimate the scale of the uncertainty online, in various\nsimulation setups.","main_category":"astro-ph.IM","categories":"astro-ph.IM,stat.AP","published":"2025-04-10T07:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.07529v1","title":"Automating the Path: An R&D Agenda for Human-Centered AI and\n  Visualization","summary":"The emergence of generative AI, large language models (LLMs), and foundation\nmodels is fundamentally reshaping computer science, and visualization and\nvisual analytics are no exception. We present a systematic framework for\nunderstanding how human-centered AI (HCAI) can transform the visualization\ndiscipline. Our framework maps four key HCAI tool capabilities -- amplify,\naugment, empower, and enhance -- onto the four phases of visual sensemaking:\nview, explore, schematize, and report. For each combination, we review existing\ntools, envision future possibilities, identify challenges and pitfalls, and\nexamine ethical considerations. This design space can serve as an R\\&D agenda\nfor both visualization researchers and practitioners to integrate AI into their\nwork as well as understanding how visualization can support HCAI research.","main_category":"cs.HC","categories":"cs.HC,H.5.2","published":"2025-04-10T07:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.07584v1","title":"REANIMATOR: Reanimate Retrieval Test Collections with Extracted and\n  Synthetic Resources","summary":"Retrieval test collections are essential for evaluating information retrieval\nsystems, yet they often lack generalizability across tasks. To overcome this\nlimitation, we introduce REANIMATOR, a versatile framework designed to enable\nthe repurposing of existing test collections by enriching them with extracted\nand synthetic resources. REANIMATOR enhances test collections from PDF files by\nparsing full texts and machine-readable tables, as well as related contextual\ninformation. It then employs state-of-the-art large language models to produce\nsynthetic relevance labels. Including an optional human-in-the-loop step can\nhelp validate the resources that have been extracted and generated. We\ndemonstrate its potential with a revitalized version of the TREC-COVID test\ncollection, showcasing the development of a retrieval-augmented generation\nsystem and evaluating the impact of tables on retrieval-augmented generation.\nREANIMATOR enables the reuse of test collections for new applications, lowering\ncosts and broadening the utility of legacy resources.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.07590v1","title":"DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware\n  Familial Classification under Obfuscation","summary":"Due to its open-source nature, the Android operating system has consistently\nbeen a primary target for attackers. Learning-based methods have made\nsignificant progress in the field of Android malware detection. However,\ntraditional detection methods based on static features struggle to identify\nobfuscated malicious code, while methods relying on dynamic analysis suffer\nfrom low efficiency. To address this, we propose a dynamic weighted feature\nselection method that analyzes the importance and stability of features,\ncalculates scores to filter out the most robust features, and combines these\nselected features with the program's structural information. We then utilize\ngraph neural networks for classification, thereby improving the robustness and\naccuracy of the detection system. We analyzed 8,664 malware samples from eight\nmalware families and tested a total of 44,940 malware variants generated using\nseven obfuscation strategies. Experiments demonstrate that our proposed method\nachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on the\nobfuscated dataset, indicating that the model can effectively detect obfuscated\nmalware.","main_category":"cs.CR","categories":"cs.CR,I.2.7","published":"2025-04-10T09:37:43Z"}
{"aid":"http://arxiv.org/abs/2504.07619v1","title":"Beating Transformers using Synthetic Cognition","summary":"The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T10:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.07621v1","title":"What causes long outbursts of neutron star low-mass X-ray binaries?","summary":"Many neutron star low-mass X-ray binaries (NS LMXBs) with short orbital\nperiods (~hours) cycle between outburst and quiescent phases, and thus provide\nan excellent way to study the accretion process. The cause of such outbursts is\nbelieved to be thermal-viscous instability in the accretion disc. However, some\nof these transient sources show unusually long outbursts. For example, EXO\n0748-676 remained in outburst for at least 23 years before entering a\nquiescence, only to re-emerge 16 years later. We aim to investigate if such\nlong outbursts could be due to the usual disc instability, or if any other\nmechanism is required. In order to address this question, we systematically\ncompare various properties of long outburst and short outburst NS LMXBs. For\nthis, we analyze the long-term X-ray light curves of many short orbital period\n(hours) NS LMXBs, examining the outburst duration and the inferred accretion\nrate, and estimate the accretion disc mass. Our study shows that long outburst\nsources are well-separated from the short outburst ones in parameter spaces\ninvolving accretion rate, disc mass, outburst duration, etc. in four ways. This\nimplies that the thermal-viscous instability in the disc cannot explain the\nlong outbursts, but could explain the short ones. Moreover, we discuss that\nboth donor star related and disc related models have difficulties in explaining\nlong outbursts. Our finding will be crucial to understanding the accretion\nprocess of transiently accreting neutron stars and black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T10:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.07642v1","title":"Cache-a-lot: Pushing the Limits of Unsatisfiable Core Reuse in SMT-Based\n  Program Analysis","summary":"Satisfiability Modulo Theories (SMT) solvers are integral to program analysis\ntechniques like concolic and symbolic execution, where they help assess the\nsatisfiability of logical formulae to explore execution paths of the program\nunder test. However, frequent solver invocations are still the main performance\nbottleneck of these techniques. One way to mitigate this challenge is through\noptimizations such as caching and reusing solver results. While current methods\ntypically focus on reusing results from fully equivalent or closely related\nformulas, they often miss broader opportunities for reuse. In this paper, we\npropose a novel approach, Cache-a-lot, that extends the reuse of unsatisfiable\n(unsat) results by systematically considering all possible variable\nsubstitutions. This enables more extensive reuse of results, thereby reducing\nthe number of SMT solver invocations and improving the overall efficiency of\nconcolic and symbolic execution. Our evaluation, conducted against the\nstate-of-the-art Utopia solution using two benchmark sets, shows significant\nimprovements, particularly with more complex formulas. Our method achieves up\nto 74% unsat core reuse, compared to Utopia's 41%, and significant increase in\nthe time savings. These results demonstrate that, despite the additional\ncomputational complexity, the broader reuse of unsat results significantly\nenhances performance, offering valuable advancements for formal verification\nand program analysis.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.07645v1","title":"Prediction of Usage Probabilities of Shopping-Mall Corridors Using\n  Heterogeneous Graph Neural Networks","summary":"We present a method based on graph neural network (GNN) for prediction of\nprobabilities of usage of shopping-mall corridors. The heterogeneous graph\nnetwork of shops and corridor paths are obtained from floorplans of the malls\nby creating vector layers for corridors, shops and entrances. These are\nsubsequently assimilated into nodes and edges of graphs. The prediction of the\nusage probability is based on the shop features, namely, the area and usage\ncategories they fall into, and on the graph connecting these shops, corridor\njunctions and entrances by corridor paths. Though the presented method is\napplicable for training on datasets obtained from a field survey or from\npedestrian-detecting sensors, the target data of the supervised deep-learning\nwork flow in this work are obtained from a probability method. We also include\na context-specific representation learning of latent features. The\nusage-probability prediction is made on each edge, which is a connection by a\nsection of corridor path between the adjacent nodes representing the shops or\ncorridor points. To create a feature for each edge, the hidden-layer feature\nvectors acquired in the message-passing GNN layers at the nodes of each edge\nare averaged and concatenated with the vector obtained by their multiplication.\nThese edge-features are then passed to multilayer perceptrons (MLP) to make the\nfinal prediction of usage probability on each edge. The samples of synthetic\nlearning dataset for each shopping mall are obtained by changing the shops'\nusage and area categories, and by subsequently feeding the graph into the\nprobability model.\n  When including different shopping malls in a single dataset, we also propose\nto consider graph-level features to inform the model with specific identifying\nfeatures of each mall.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:48:36Z"}
{"aid":"http://arxiv.org/abs/2504.07681v1","title":"Role of activity and dissipation in achieving precise beating in cilia:\n  Insights from the rower model","summary":"Cilia and flagella are micron-sized filaments that actively beat with\nremarkable precision in a viscous medium, driving microorganism movement and\nefficient flow. We study the rower model to uncover how cilia activity and\ndissipation enable this precise motion. In this model, cilia motion is\nrepresented by a micro-beads Brownian movement between two distant harmonic\npotentials. At specific locations, energy pumps trigger potential switches,\ncapturing cilia activity and generating oscillations. We quantify precision of\noscillation using a quality factor, identifying its scaling with activity and\noscillation amplitude, finding precision maximization at an optimal amplitude.\nThe data collapse is not accurate for noisy oscillations. An exact analytic\nexpression for the precision quality factor, based on first passage time\nfluctuations, and derived in the small noise approximation, explains its\noptimality and scaling. Energy budget analysis shows the quality factor's\nconsistency with the thermodynamic uncertainty relation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T12:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.07703v1","title":"Optimal Frequency Support from Virtual Power Plants: Minimal Reserve and\n  Allocation","summary":"This paper proposes a novel reserve-minimizing and allocation strategy for\nvirtual power plants (VPPs) to deliver optimal frequency support. The proposed\nstrategy enables VPPs, acting as aggregators for inverter-based resources\n(IBRs), to provide optimal frequency support economically. The proposed\nstrategy captures time-varying active power injections, reducing the\nunnecessary redundancy compared to traditional fixed reserve schemes. Reserve\nrequirements for the VPPs are determined based on system frequency response and\nsafety constraints, ensuring efficient grid support. Furthermore, an\nenergy-based allocation model decomposes power injections for each IBR,\naccounting for their specific limitations. Numerical experiments validate the\nfeasibility of the proposed approach, highlighting significant financial gains\nfor VPPs, especially as system inertia decreases due to higher renewable energy\nintegration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T12:43:38Z"}
{"aid":"http://arxiv.org/abs/2504.07721v1","title":"From empirical brain networks towards modeling music perception -- a\n  perspective","summary":"This perspective article investigates how auditory stimuli influence neural\nnetwork dynamics using the FitzHugh-Nagumo (FHN) model and empirical brain\nconnectivity data. Results show that synchronization is sensitive to both the\nfrequency and amplitude of auditory input, with synchronization enhanced when\ninput frequencies align with the system's intrinsic frequencies. Increased\nstimulus amplitude broadens the synchronization range governed by a delicate\ninterplay involving the network's topology, the spatial location of the input,\nand the frequency characteristics of the cortical input signals. This\nperspective article also reveals that brain activity alternates between\nsynchronized and desynchronized states, reflecting critical dynamics and phase\ntransitions in neural networks. Notably, gamma-band synchronization is crucial\nfor processing music, with coherence peaking in this frequency range. The\nfindings emphasize the role of structural connectivity and network topology in\nmodulating synchronization, providing insights into how music perception\nengages brain networks. This perspective article offers a computational\nframework for understanding neural mechanisms in music perception, with\npotential implications for cognitive neuroscience and music psychology.","main_category":"q-bio.NC","categories":"q-bio.NC,nlin.AO","published":"2025-04-10T13:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.07722v1","title":"Relaxing the Markov Requirements on Reinforcement Learning Under Weak\n  Partial Ignorability","summary":"Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-10T13:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.07726v1","title":"Quantum Machine Learning: Unveiling Trends, Impacts through Bibliometric\n  Analysis","summary":"Quantum Machine Learning (QML) is the intersection of two revolutionary\nfields: quantum computing and machine learning. It promises to unlock\nunparalleled capabilities in data analysis, model building, and problem-solving\nby harnessing the unique properties of quantum mechanics. This research\nendeavors to conduct a comprehensive bibliometric analysis of scientific\ninformation pertaining to QML covering the period from 2000 to 2023. An\nextensive dataset comprising 9493 scholarly works is meticulously examined to\nunveil notable trends, impact factors, and funding patterns within the domain.\nAdditionally, the study employs bibliometric mapping techniques to visually\nillustrate the network relationships among key countries, institutions,\nauthors, patent citations and significant keywords in QML research. The\nanalysis reveals a consistent growth in publications over the examined period.\nThe findings highlight the United States and China as prominent contributors,\nexhibiting substantial publication and citation metrics. Notably, the study\nconcludes that QML, as a research subject, is currently in a formative stage,\ncharacterized by robust scholarly activity and ongoing development.","main_category":"cs.DL","categories":"cs.DL,cs.LG","published":"2025-04-10T13:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.07763v1","title":"Data over dialogue: Why artificial intelligence is unlikely to humanise\n  medicine","summary":"Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG","published":"2025-04-10T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.07770v1","title":"Sublevels in arrangements and the spherical arc crossing number of\n  complete graphs","summary":"Levels and sublevels in arrangements -- and, dually, $k$-sets and $(\\leq\nk)$-sets -- are fundamental notions in discrete and computational geometry and\nnatural generalizations of convex polytopes, which correspond to the $0$-level.\nA long-standing conjecture of Eckhoff, Linhart, and Welzl, which would\ngeneralize McMullen's Upper Bound Theorem for polytopes and provide an exact\nrefinement of asymptotic bounds by Clarkson, asserts that for all $k\\leq\n\\lfloor \\frac{n-d-2}{2}\\rfloor$, the number of $(\\leq k)$-sets of a set $S$ of\n$n$ points in $\\mathbf{R}^d$ is maximized if $S$ is the vertex set of a\nneighborly polytope.\n  As a new tool for studying this conjecture and related problems, we introduce\nthe $g$-matrix, which generalizes both the $g$-vector of a simple polytope and\na Gale dual version of the $g$-vector studied by Lee and Welzl. Our main result\nis that the $g$-matrix of every vector configuration in $\\mathbf{R}^3$ is\nnon-negative, which implies the Eckhoff--Linhart--Welzl conjecture in the case\nwhere $d=n-4$.\n  As a corollary, we obtain the following result about crossing numbers:\nConsider a configuration $V\\subset S^2 \\subset \\mathbf{R}^3$ of $n$ unit\nvectors, and connect every pair of vectors by the unique shortest geodesic arc\nbetween them in the unit sphere $S^2$. This yields a drawing of the complete\ngraph $K_n$ in $S^2$, which we call a spherical arc drawing. Complementing\nprevious results for rectilinear drawings, we show that the number of crossings\nin any spherical arc drawing of $K_n$ is at least $\\frac{1}{4}\\lfloor\n\\frac{n}{2}\\rfloor \\lfloor \\frac{n-1}{2}\\rfloor \\lfloor \\frac{n-2}{2}\\rfloor\n\\lfloor \\frac{n-3}{2}\\rfloor$, which equals the conjectured value of the\ncrossing number of $K_n$. Moreover, the lower bound is attained if $V$ is\nconeighborly, i.e., if every open linear halfspace contains at least $\\lfloor\n(n-2)/2 \\rfloor$ of the vectors in $V$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T14:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07779v1","title":"Genetic Programming with Reinforcement Learning Trained Transformer for\n  Real-World Dynamic Scheduling Problems","summary":"Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T14:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07780v1","title":"Interference-caged quantum many-body scars: the Fock space topological\n  localization and interference zeros","summary":"We propose a general mechanism for realizing athermal finite-energy-density\neigenstates -- termed interference-caged quantum many-body scars (ICQMBS) --\nwhich originate from exact many-body destructive interference on the Fock space\ngraph. These eigenstates are strictly localized to specific subsets of\nvertices, analogous to compact localized states in flat-band systems. Central\nto our framework is a connection between interference zeros and graph\nautomorphisms, which classify vertices according to the graph's local topology.\nThis connection enables the construction of a new class of topological ICQMBS,\nwhose robustness arises from the local topology of the Fock space graph rather\nthan from conventional conservation laws or dynamical constraints. We\ndemonstrate the effectiveness of this framework by developing a\ngraph-theory-based search algorithm, which identifies ICQMBS in both a\none-dimensional spin-1 XY model and two-dimensional quantum link models across\ndistinct gauge sectors. In particular, we discover the proposed topological\nICQMBS in the two-dimensional quantum link model and provide an intuitive\nexplanation for previously observed order-by-disorder phenomena in Hilbert\nspace. Our results reveal an unexpected synergy between graph theory, flat-band\nphysics, and quantum many-body dynamics, offering new insights into the\nstructure and stability of nonthermal eigenstates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-10T14:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.07785v1","title":"Towards Micro-Action Recognition with Limited Annotations: An\n  Asynchronous Pseudo Labeling and Training Approach","summary":"Micro-Action Recognition (MAR) aims to classify subtle human actions in\nvideo. However, annotating MAR datasets is particularly challenging due to the\nsubtlety of actions. To this end, we introduce the setting of Semi-Supervised\nMAR (SSMAR), where only a part of samples are labeled. We first evaluate\ntraditional Semi-Supervised Learning (SSL) methods to SSMAR and find that these\nmethods tend to overfit on inaccurate pseudo-labels, leading to error\naccumulation and degraded performance. This issue primarily arises from the\ncommon practice of directly using the predictions of classifier as\npseudo-labels to train the model. To solve this issue, we propose a novel\nframework, called Asynchronous Pseudo Labeling and Training (APLT), which\nexplicitly separates the pseudo-labeling process from model training.\nSpecifically, we introduce a semi-supervised clustering method during the\noffline pseudo-labeling phase to generate more accurate pseudo-labels.\nMoreover, a self-adaptive thresholding strategy is proposed to dynamically\nfilter noisy labels of different classes. We then build a memory-based\nprototype classifier based on the filtered pseudo-labels, which is fixed and\nused to guide the subsequent model training phase. By alternating the two\npseudo-labeling and model training phases in an asynchronous manner, the model\ncan not only be learned with more accurate pseudo-labels but also avoid the\noverfitting issue. Experiments on three MAR datasets show that our APLT largely\noutperforms state-of-the-art SSL methods. For instance, APLT improves accuracy\nby 14.5\\% over FixMatch on the MA-12 dataset when using only 50\\% labeled data.\nCode will be publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.07797v1","title":"Event-Triggered Source Seeking Control for Nonholonomic Systems","summary":"This paper introduces an event-triggered source seeking control (ET-SSC) for\nautonomous vehicles modeled as the nonholonomic unicycle. The classical source\nseeking control is enhanced with static-triggering conditions to enable\naperiodic and less frequent updates of the system's input signals, offering a\nresource-aware control design. Our convergence analysis is based on\ntime-scaling combined with Lyapunov and averaging theories for systems with\ndiscontinuous right-hand sides. ET-SSC ensures exponentially stable behavior\nfor the resulting average system, leading to practical asymptotic convergence\nto a small neighborhood of the source point. We guarantee the avoidance of Zeno\nbehavior by establishing a minimum dwell time to prevent infinitely fast\nswitching. The performance optimization is aligned with classical\ncontinuous-time source seeking algorithms while balancing system performance\nwith actuation resource consumption. Our ET-SSC algorithm, the first of its\nkind, allows for arbitrarily large inter-sampling times, overcoming the\nlimitations of classical sampled-data implementations for source seeking\ncontrol.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07805v1","title":"Symmetry energy dependence of the bulk viscosity of nuclear matter","summary":"We clarify how the weak-interaction-driven bulk viscosity $\\zeta$ and the\nbulk relaxation time $\\tau_\\Pi$ of neutrino-transparent $npe$ matter depend on\nthe nuclear symmetry energy. We show that, at saturation density, the\nequation-of-state dependence of these transport quantities is fully determined\nby the experimentally constrained nuclear symmetry energy $S$ and its slope\n$L$. Variations of $L$ within current experimental uncertainties can change the\n(frequency-independent) bulk viscosity by orders of magnitude. This suggests\nthat dissipative effects encoded in the gravitational-wave signatures of binary\nneutron star inspirals may help constrain nuclear symmetry energy properties.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-10T14:42:50Z"}
{"aid":"http://arxiv.org/abs/2504.07812v1","title":"Numerical instability of non-Hermitian Hamiltonian evolutions","summary":"The extreme sensitivity of non-Hermitian Hamiltonians exhibiting the\nnon-Hermitian skin effect (NHSE) has been extensively studied in recent years\nwith well-established theoretical explanations. However, this sensitivity is\noften overlooked in numerical calculations, as seen in Refs.\n\\cite{NHSEEPTKawabata, Schiro}. In this work, we examine the solvable\nHatano-Nelson and symplectic Hatano-Nelson models, comparing our high-precision\nresults with those in Ref. \\cite{NHSEEPTKawabata}. We systematically\ninvestigate inaccuracies in physical results arising from neglecting numerical\nerrors during diagonalization and non-Hermitian Hamiltonian evolution.\nMoreover, we attribute these numerical instabilities to the large condition\nnumber, which grows exponentially with system size due to NHSE, indicating\nstrong normality. Interestingly, it is found that a reliable spectrum alone is\ninsufficient for accurate non-Hermitian evolution, while the reliability of\nwavefunctions plays a more critical role. To ensure the accuracy of numerical\nresults for non-Hermitian systems exhibiting NHSE, our work underscores the\nimportance of estimating the condition number before performing numerical\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.07844v1","title":"A quantum computing approach to beam angle optimization","summary":"Background: Beam angle optimization (BAO) is a critical component of\nradiation therapy (RT) treatment planning, where small changes in beam\nconfiguration can significantly impact treatment quality, especially for proton\nRT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is\nNP-hard due to its exponential growing search space. Traditional optimization\ntechniques often struggle with computational efficiency, necessitating the\ndevelopment of novel approaches. Purpose: This study introduces QC-BAO, a\nhybrid quantum-classical approach that leverages quantum computing to solve the\nMIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as\nan MIP problem, incorporating binary variables for beam angle selection and\ncontinuous variables for optimizing spot intensities for proton therapy. The\nproposed approach employs a hybrid quantum-classical framework, utilizing\nquantum computing to solve the binary decision component while integrating\nclassical optimization techniques, including iterative convex relaxation and\nalternating direction method of multipliers. Results: Computational experiments\nwere conducted on clinical test cases to evaluate QC-BAO's performance against\nclinically verified angles and a heuristic approach, GS-BAO. QC-BAO\ndemonstrated improved treatment plan quality over both clinical and GS-BAO. The\nmethod consistently increased the conformity index (CI) for target coverage\nwhile reducing mean and maximum doses to organs-at-risk (OAR). Additionally,\nQC-BAO produced the lowest objective function value, confirming its superior\noptimization capability. Conclusions: The findings highlight the potential of\nquantum computing to enhance the solution to BAO problem by demonstrated\nimprovement in plan quality using the proposed method, QC-BAO. This study paves\nthe way for future clinical implementation of quantum-accelerated optimization\nin RT.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T15:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.07911v1","title":"The Urban Impact of AI: Modeling Feedback Loops in Next-Venue\n  Recommendation","summary":"Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T17:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.07918v1","title":"Shuffling via Transpositions","summary":"We consider a family of card shuffles of $n$ cards, where the allowed moves\ninvolve transpositions corresponding to the Jucys--Murphy elements of\n$\\{S_m\\}_{m \\leq n}$. We diagonalize the transition matrix of these shuffles.\nAs a special case, we consider the $k$-star transpositions shuffle, a natural\ninterpolation between random transpositions and star transpositions. We proved\nthat the $k$-star transpositions shuffle exhibits total variation cutoff at\ntime $\\frac{2n-(k+1)}{2(n-1)}n\\log n$ with a window of\n$\\frac{2n-(k+1)}{2(n-1)}n$. Furthermore, we prove that for the case where $k/n\n\\rightarrow 0$ or $1$, this shuffle has the same limit profile as random\ntranspositions, which has been fully determined by Teyssier.","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-04-10T17:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.07919v1","title":"Double White Dwarf Tides with Multi-messenger Measurements","summary":"Short-period Galactic double white dwarf (DWD) systems will be observable\nboth in visible light through photometric monitoring and in mHz-range\ngravitational waves (GWs) with forthcoming space-based laser interferometry\nsuch as LISA. When only photometric variability is used to measure DWD\nintrinsic properties, there is a degeneracy between the chirp mass and binary\ntidal interaction, as orbital frequency time derivative is set by both GW\nradiation and tides. Without expensive radial velocity data from spectroscopic\nmonitoring, this degeneracy may be lifted in principle by directly measuring\nthe second time derivative of the orbital frequency through photometric\nmonitoring over an ultra-long time baseline. Alternatively, the degeneracy can\nbe removed by exploiting information in both photometric variability and the\ncoherent GW waveform. Investigating both approaches, we find that direct\nmeasurement of the second time derivative is likely infeasible for most DWDs,\nwhile the multi-messenger method will disentangle measurements of the chirp\nmass and the binary moments of inertia, for a large sample of tidally locked\nsystems. The latter information will enable empirical tests of WD structure\nmodels with finite temperature effects.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T17:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.07944v1","title":"Hyperbolic sine-Gordon model beyond the first threshold","summary":"We study the hyperbolic sine-Gordon model, with a parameter $\\beta^2 > 0$,\nand its associated Gibbs dynamics on the two-dimensional torus. By introducing\na physical space approach to the Fourier restriction norm method and\nestablishing nonlinear dispersive smoothing for the imaginary multiplicative\nGaussian chaos, we construct invariant Gibbs dynamics for the hyperbolic\nsine-Gordon model beyond the first threshold $\\beta^2 = 2\\pi$. The\ndeterministic step of our argument hinges on establishing key bilinear\nestimates, featuring weighted bounds for a cone multiplier. Moreover, the\nprobabilistic component involves a careful analysis of the imaginary Gaussian\nmultiplicative chaos and reduces to integrating singularities along space-time\nlight cones. As a by-product of our proof, we identify $\\beta^2 = 6\\pi$ as a\ncritical threshold for the hyperbolic sine-Gordon model, which is quite\nsurprising given that the associated parabolic model has a critical threshold\nat $\\beta^2 =8\\pi$.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,math.PR","published":"2025-04-10T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.07952v1","title":"Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory","summary":"Despite their impressive performance on complex tasks, current language\nmodels (LMs) typically operate in a vacuum: Each input query is processed\nseparately, without retaining insights from previous attempts. Here, we present\nDynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM\nwith a persistent, evolving memory. Rather than repeatedly re-discovering or\nre-committing the same solutions and mistakes, DC enables models to store and\nreuse accumulated strategies, code snippets, and general problem-solving\ninsights at inference time. This test-time learning enhances performance\nsubstantially across a range of tasks without needing explicit ground-truth\nlabels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than\ndoubled on AIME math exams once it began retaining algebraic insights across\nquestions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to\n99% after the model discovered and reused a Python-based solution. In tasks\nprone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o\nand Claude to reach near-perfect accuracy by recalling previously validated\ncode, whereas their baselines stagnated around 50%. Beyond arithmetic\nchallenges, DC yields notable accuracy gains on knowledge-demanding tasks.\nClaude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro\nproblems. Crucially, DC's memory is self-curated, focusing on concise,\ntransferable snippets rather than entire transcript. Unlike finetuning or\nstatic retrieval methods, DC adapts LMs' problem-solving skills on the fly,\nwithout modifying their underlying parameters. Overall, our findings present DC\nas a promising approach for augmenting LMs with persistent memory, bridging the\ndivide between isolated inference events and the cumulative, experience-driven\nlearning characteristic of human cognition.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07963v1","title":"PixelFlow: Pixel-Space Generative Models with Flow","summary":"We present PixelFlow, a family of image generation models that operate\ndirectly in the raw pixel space, in contrast to the predominant latent-space\nmodels. This approach simplifies the image generation process by eliminating\nthe need for a pre-trained Variational Autoencoder (VAE) and enabling the whole\nmodel end-to-end trainable. Through efficient cascade flow modeling, PixelFlow\nachieves affordable computation cost in pixel space. It achieves an FID of 1.98\non 256$\\times$256 ImageNet class-conditional image generation benchmark. The\nqualitative text-to-image results demonstrate that PixelFlow excels in image\nquality, artistry, and semantic control. We hope this new paradigm will inspire\nand open up new opportunities for next-generation visual generation models.\nCode and models are available at https://github.com/ShoufaChen/PixelFlow.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09882v1","title":"SIO-Mapper: A Framework for Lane-Level HD Map Construction Using\n  Satellite Images and OpenStreetMap with No On-Site Visits","summary":"High-definition (HD) maps, particularly those containing lane-level\ninformation regarded as ground truth, are crucial for vehicle localization\nresearch. Traditionally, constructing HD maps requires highly accurate sensor\nmeasurements collection from the target area, followed by manual annotation to\nassign semantic information. Consequently, HD maps are limited in terms of\ngeographic coverage. To tackle this problem, in this paper, we propose\nSIO-Mapper, a novel lane-level HD map construction framework that constructs\ncity-scale maps without physical site visits by utilizing satellite images and\nOpenStreetmap data. One of the key contributions of SIO-Mapper is its ability\nto extract lane information more accurately by introducing SIO-Net, a novel\ndeep learning network that integrates features from satellite image and\nOpenStreetmap using both Transformer-based and convolution-based encoders.\nFurthermore, to overcome challenges in merging lanes over large areas, we\nintroduce a novel lane integration methodology that combines cluster-based and\ngraph-based approaches. This algorithm ensures the seamless aggregation of lane\nsegments with high accuracy and coverage, even in complex road environments. We\nvalidated SIO-Mapper on the Naver Labs Open Dataset and NuScenes dataset,\ndemonstrating better performance in various environments including Korea, the\nUnited States, and Singapore compared to the state-of-the-art lane-level HD\nmapconstruction methods.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T05:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.09921v1","title":"All-optical Raman control of ultracold atomic hyperfine states using\n  pulsed jump protocol","summary":"We develop a pulse-driven jump protocol to achieve all-optical Raman control\nof ultracold atomic hyperfine states. By establishing general conditions for\nadiabatic evolution between quantum states in parameter space, we derive the\nessential pulse area and phase conditions necessary for quantum state transfer\nin a resonant single-$\\Lambda$ three-level system. We extend this approach to a\ndouble-$\\Lambda$ four-level system by incorporating a neighboring intermediate\nstate, which leads to a single-photon detuned $\\Lambda$ three-level system.\nThrough numerical simulations of the ultracold $^{87}$Rb atomic system, we\ndemonstrate that high-fidelity and robust control of quantum state transfer can\nbe achieved in the single-$\\Lambda$ three-level system using stimulated Raman\nadiabatic passage (STIRAP) and the pulsed jump protocol. Furthermore, we show\nthat the destructive quantum interference effects between resonant and detuned\nRaman pathways in the double-$\\Lambda$ four-level system can be mitigated by\noptimizing the pulse area and two-photon detuning parameters within the pulsed\njump protocol. This work presents a promising approach for achieving\nall-optical Raman control of quantum state transfer in ultracold atomic\nhyperfine states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T06:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.09923v1","title":"Guiding Reasoning in Small Language Models with LLM Assistance","summary":"The limited reasoning capabilities of small language models (SLMs) cast doubt\non their suitability for tasks demanding deep, multi-step logical deduction.\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\nwhich selectively augments SLM reasoning with targeted guidance from large\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\nemploys a score-based evaluation to identify uncertain reasoning steps and\ninjects corrective LLM-generated reasoning only when necessary. By framing\nstructured reasoning as an optimal policy search, our approach steers the\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\nexperiments on mathematical reasoning datasets demonstrate that targeted\nexternal scaffolding significantly improves performance, paving the way for\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\nare currently unsolvable by SLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.09946v1","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","summary":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have\ndemonstrated remarkable reasoning capabilities, raising important questions\nabout their biases in LLM-as-a-judge settings. We present a comprehensive\nbenchmark comparing judging biases between LLMs and LRMs across both subjective\npreference-alignment datasets and objective fact-based datasets. Through\ninvestigation of bandwagon, authority, position, and distraction biases, we\nuncover four key findings: (1) despite their advanced reasoning capabilities,\nLRMs remain susceptible to the above biases; (2) LRMs demonstrate better\nrobustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit\nnotable position bias, preferring options in later positions; and (4) we\nidentify a novel \"superficial reflection bias\" where phrases mimicking\nreasoning (e.g., \"wait, let me think...\") significantly influence model\njudgments. To address these biases, we design and evaluate three mitigation\nstrategies: specialized system prompts that reduce judging biases by up to 19\\%\nin preference alignment datasets and 14\\% in fact-related datasets, in-context\nlearning that provides up to 27\\% improvement on preference tasks but shows\ninconsistent results on factual tasks, and a self-reflection mechanism that\nreduces biases by up to 10\\% in preference datasets and 16\\% in fact-related\ndatasets, with self-reflection proving particularly effective for LRMs. Our\nwork provides crucial insights for developing more reliable LLM-as-a-Judge\nframeworks, especially as LRMs become increasingly deployed as automated\njudges.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-14T07:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.09955v1","title":"VR MRI Training for Adolescents: A Comparative Study of Gamified VR,\n  Passive VR, 360 Video, and Traditional Educational Video","summary":"Magnetic Resonance Imaging (MRI) can be a stressful experience for pediatric\npatients due to the loud acoustic environment, enclosed scanner bore, and a\nprolonged requirement to remain still. While sedation is commonly used to\nmanage anxiety and motion, it carries clinical risks and logistical burdens.\nTraditional preparatory approaches, such as instructional videos and mock\nscans, often lack engagement for older children and adolescents. In this study,\nwe present a comparative evaluation of four MRI preparation modalities: (1) a\ngamified virtual reality (VR) simulation that trains stillness through\nreal-time feedback; (2) a passive VR experience replicating the MRI environment\nwithout interactivity; (3) a 360 degree first-person video of a real MRI\nprocedure; and (4) a standard 2D educational video. Using a within-subjects\ndesign (N = 11, ages 10-16), we assess each method's impact on head motion\ndata, anxiety reduction, procedural preparedness, usability, cognitive\nworkload, and subjective preference. Results show that the gamified VR\ncondition has significantly lower head motion (p < 0.001) and yielded the\nhighest preparedness scores (p < 0.05). Head motion data were significantly\ncorrelated with learning outcomes (p < 0.01), suggesting that behavioral\nperformance in VR strongly indicates procedural readiness. While all modalities\nreduced anxiety and were rated usable, interactive VR was preferred by most\nparticipants and demonstrated unique advantages in promoting engagement and\nbehavioral rehearsal. We conclude with design recommendations for designing\nimmersive simulations and integrating VR training into pediatric imaging\nworkflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T07:40:30Z"}
{"aid":"http://arxiv.org/abs/2504.09971v1","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","summary":"We revisit the longstanding open problem of implementing Nakamoto's\nproof-of-work (PoW) consensus based on a real-world computational task $T(x)$\n(as opposed to artificial random hashing), in a truly permissionless setting\nwhere the miner itself chooses the input $x$. The challenge in designing such a\nProof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$\nto produce a PoW certificate with prescribed hardness and with negligible\ncomputational overhead over the worst-case complexity of $T(\\cdot)$ -- This\nensures malicious miners cannot ``game the system\" by fooling the verifier to\naccept with higher probability compared to honest miners (while using similar\ncomputational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead\nis trivial for any task $T$, but also useless.\n  Our main result is a PoUW for the task of Matrix Multiplication $MatMul(A,B)$\nof arbitrary matrices with $1+o(1)$ multiplicative overhead compared to naive\n$MatMul$ (even in the presence of Fast Matrix Multiplication-style algorithms,\nwhich are currently impractical). We conjecture that our protocol has optimal\nsecurity in the sense that a malicious prover cannot obtain any significant\nadvantage over an honest prover. This conjecture is based on reducing hardness\nof our protocol to the task of solving a batch of low-rank random linear\nequations which is of independent interest.\n  Since $MatMul$s are the bottleneck of AI compute as well as countless\nindustry-scale applications, this primitive suggests a concrete design of a new\nL1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin\nmining -- allowing GPU consumers to reduce their AI training and inference\ncosts by ``re-using\" it for blockchain consensus, in exchange for block rewards\n(2-for-1). This blockchain is currently under construction.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.09976v1","title":"Nonlocal operators in divergence form and existence theory for\n  integrable data","summary":"We present an existence and uniqueness result for weak solutions of Dirichlet\nboundary value problems governed by a nonlocal operator in divergence form and\nin the presence of a datum which is assumed to belong only to $L^1(\\Omega)$ and\nto be suitably dominated.\n  We also prove that the solution that we find converges, as $s\\nearrow 1$, to\na solution of the local counterpart problem, recovering the classical result as\na limit case. This requires some nontrivial customized uniform estimates and\nrepresentation formulas, given that the datum is only in $L^1(\\Omega)$ and\ntherefore the usual regularity theory cannot be leveraged to our benefit in\nthis framework.\n  The limit process uses a nonlocal operator, obtained as an affine\ntransformation of a homogeneous kernel, which recovers, in the limit as\n$s\\nearrow 1$, every classical operator in divergence form.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T08:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.10007v1","title":"Balancing Two Classifiers via A Simplex ETF Structure for Model\n  Calibration","summary":"In recent years, deep neural networks (DNNs) have demonstrated\nstate-of-the-art performance across various domains. However, despite their\nsuccess, they often face calibration issues, particularly in safety-critical\napplications such as autonomous driving and healthcare, where unreliable\npredictions can have serious consequences. Recent research has started to\nimprove model calibration from the view of the classifier. However, the\nexploration of designing the classifier to solve the model calibration problem\nis insufficient. Let alone most of the existing methods ignore the calibration\nerrors arising from underconfidence. In this work, we propose a novel method by\nbalancing learnable and ETF classifiers to solve the overconfidence or\nunderconfidence problem for model Calibration named BalCAL. By introducing a\nconfidence-tunable module and a dynamic adjustment method, we ensure better\nalignment between model confidence and its true accuracy. Extensive\nexperimental validation shows that ours significantly improves model\ncalibration performance while maintaining high predictive accuracy,\noutperforming existing techniques. This provides a novel solution to the\ncalibration challenges commonly encountered in deep learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T09:09:01Z"}
{"aid":"http://arxiv.org/abs/2504.10018v1","title":"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset\n  and An Asymmetric RWKV Fusion Framework","summary":"Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:22:16Z"}
{"aid":"http://arxiv.org/abs/2504.10029v1","title":"Quantum Squeezing Effects in Coupled van der Pol Oscillators","summary":"Achieving synchronized quantum states within the quantum realm is a\nsignificant goal. This regime is characterized by restricted excitation\noccurrences and a highly nonclassical stable state of the self-oscillating\nsystem. However, many existing approaches to observe synchronization in this\nquantum realm face a major challenge: the influence of noise tends to\novershadow the synchronization phenomenon. In coupled van der Pol oscillators,\nsynchronization occurs when a system of two or more oscillators interacts. Our\ninvestigation demonstrates that introducing the squeezing Hamiltonian in two\ncoupled van der Pol oscillators enhances nonclassical effects, increases\nquantum correlations, and improves the robustness of synchronization dynamics.\nThis was evidenced through the analysis of the Wigner function and power\nspectrum, showing significant improvements compared to systems without\nsqueezing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.10095v1","title":"Influence of packing protocol on fractal exponents in dense polydisperse\n  packings","summary":"We study fractal properties of a system of densely and randomly packed disks,\nobeying a power-law distribution of radii, which is generated by using various\nprotocols: Delaunay triangulation (DT) with both zero and periodic boundary\nconditions and the constant pressure protocol with periodic boundary\nconditions. The power-law exponents of the mass-radius relation and structure\nfactor are obtained numerically for various values of the size ratio of the\ndistribution, defined as the largest-to-smallest radius ratio. It is shown that\nthe size ratio is an important control parameter responsible for the\nconsistency of the fractal properties of the system: the greater the ratio, the\nless the finite size effects are pronounced and the better the agreement\nbetween the exponents. For the DT protocol, the exponents of the mass-radius\nrelation, structure factor, and power-law distribution coincide even at\nmoderate values of the size ratio. By contrast, for the constant-pressure\nprotocol, all three exponents are found to be different for both moderate\n(around 300) and large (around 1500) size ratios, which might indicate a biased\nrather than random spatial distribution of the disks. Nevertheless, there is a\ntendency for the exponents to converge as the size ratio increases, suggesting\nthat all the exponents become equal in the limit of infinite size ratio.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T11:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.10100v1","title":"A direct and algebraic characterization of higher-order differential\n  operators","summary":"This paper presents an algebraic approach to characterizing higher-order\ndifferential operators. While the foundational Leibniz rule addresses\nfirst-order derivatives, its extension to higher orders typically involves\nidentities relating multiple distinct operators. In contrast, we introduce a\nnovel operator equation involving only a single $n$\\textsuperscript{th}-order\ndifferential operator. We demonstrate that, under certain mild conditions, this\nequation serves to characterize such operators. Specifically, our results show\nthat these higher-order differential operators can be identified as particular\nsolutions to this single-operator identity. This approach provides a framework\nfor understanding the algebraic structure of higher-order differential\noperators acting on function spaces.","main_category":"math.CA","categories":"math.CA","published":"2025-04-14T11:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.10121v1","title":"Impact of rainfall risk on rice production: realized volatility in mean\n  model","summary":"Rural economies are largely dependent upon agriculture, which is greatly\ndetermined by climatic conditions such as rainfall. This study aims to forecast\nagricultural production in Maharashtra, India, which utilises annual data from\nthe year 1962 to 2021. Since rainfall plays a major role with respect to the\ncrop yield, we analyze the impact of rainfall on crop yield using four time\nseries models that includes ARIMA, ARIMAX, GARCH-ARIMA and GARCH-ARIMAX. We\ntake advantage of rainfall as an external regressor to examine if it\ncontributes to the performance of the model. 1-step, 2-step, and 3-step ahead\nforecasts are obtained and the model performance is assessed using MAE and\nRMSE. The models are able to more accurately predict when using rainfall as a\npredictor compared to when solely dependant on historical production trends\n(more improved outcomes are seen in the ARIMAX and GARCH-ARIMAX models). As\nsuch, these findings underscore the need for climate-aware forecasting\ntechniques that provide useful information to policymakers and farmers to aid\nin agricultural planning.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-14T11:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.10124v1","title":"Unravelling the Flow of Information in a Nonequilibrium Process","summary":"Identifying the origin of nonequilibrium characteristics in a generic\ninteracting system having multiple degrees of freedom is a challenging task. In\nthis context, information theoretic measures such as mutual information and\nrelated polymorphs offer valuable insights. Here, we explore these measures in\na minimal experimental model consisting of two hydrodynamically coupled\ncolloidal particles, where a nonequilibrium drive is introduced via an\nexponentially correlated noise acting on one of the particles. We show that the\ninformation-theoretic tools considered enable a systematic, data-driven\ndissection of information flow within the system. These measures allow us to\nidentify the driving node and reconstruct the directional dependencies between\nparticles. Notably, they help explain a recently observed, counterintuitive\ntrend in the dependence of irreversibility on interaction strength under\ncoarse-graining (B. Das et.al., arXiv:2405.00800 (2024)). Finally, our results\ndemonstrate how directional information measures can uncover the hidden\nstructure of nonequilibrium dynamics and provide a framework for studying\nsimilar effects in more complex systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.10137v1","title":"Multi-Target Position Error Bound and Power Allocation Scheme for\n  Cell-Free mMIMO-OTFS ISAC Systems","summary":"This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-14T11:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.10142v1","title":"Band width estimates with lower spectral curvature bounds","summary":"In this work, we use the warped \\( \\mu \\)-bubble method to study the\nconsequences of a spectral curvature bound. In particular, with a lower\nspectral Ricci curvature bound and lower spectral scalar curvature bound, we\nshow that the band width of a torical band is bounded above. We also obtain\nsome rigidity results.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T11:54:13Z"}
{"aid":"http://arxiv.org/abs/2504.10144v1","title":"Evidence for electron spin-torsion coupling in the rotational spectrum\n  of the CH$_3$CO radical","summary":"Open-shell non-rigid molecular systems exhibiting an internal rotation are\nlikely candidates for a coupling between the spin angular momentum of the\nunpaired electron and the torsional motion. This electron spin-torsion coupling\nlacked both an experimental validation and a theoretical modeling. Here, the\nfirst experimental observation of the electron spin-torsion coupling is\nreported analyzing the pure rotational spectrum at millimeter wavelengths of\nthe CH$_3$CO radical, a $^2\\Sigma$ open-shell molecule displaying an internal\nrotation of its methyl group. To account for this coupling, a specific\nHamiltonian incorporating the rotational, torsional, and electronic degrees of\nfreedom is developed and allows us to reproduce the experimental spectrum. The\npresent demonstration of the electron spin-torsion coupling will undoubtedly be\nkey to future investigations of large open-shell molecules exhibiting a complex\ninternal dynamics.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T11:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.10148v1","title":"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for\n  Multi-Instance Synthesis in Diffusion Transformers","summary":"Text-to-image (T2I) generation models often struggle with multi-instance\nsynthesis (MIS), where they must accurately depict multiple distinct instances\nin a single image based on complex prompts detailing individual features.\nTraditional MIS control methods for UNet architectures like SD v1.5/SDXL fail\nto adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated\nattention between image and text tokens rather than text-image cross-attention.\nTo enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.\nOur token-wise and layer-wise analysis of attention maps reveals a hierarchical\nresponse structure: instance tokens dominate early layers, background tokens in\nmiddle layers, and attribute tokens in later layers. Building on this\nobservation, we propose a training-free approach for enhancing MIS in DiT-based\nmodels with hierarchical and step-layer-wise attention specialty tuning (AST).\nAST amplifies key regions while suppressing irrelevant areas in distinct\nattention maps across layers and steps, guided by the hierarchical structure.\nThis optimizes multimodal interactions by hierarchically decoupling the complex\nprompts with instance-based sketches. We evaluate our approach using upgraded\nsketch-based layouts for the T2I-CompBench and customized complex scenes. Both\nquantitative and qualitative results confirm our method enhances complex layout\ngeneration, ensuring precise instance placement and attribute representation in\nMIS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.10158v1","title":"COUNTS: Benchmarking Object Detectors and Multimodal Large Language\n  Models under Distribution Shifts","summary":"Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.10172v1","title":"Characterising quantum measurement through environmental stochastic\n  entropy production in a two spin 1/2 system","summary":"Quantum state diffusion is a framework within which measurement may be\ndescribed as the continuous and gradual collapse of a quantum system to an\neigenstate as a result of interaction with its environment. The irreversible\nnature of the quantum trajectories that arise may be characterised by the\nenvironmental stochastic entropy production associated with the measurement. We\nconsider a system of two spin 1/2 particles undergoing either single particle\nmeasurements or measurements of the total z-spin component S_{z}. The mean\nasymptotic rates of environmental stochastic entropy production associated with\ncollapse can depend on the eigenstate of S_{z} selected, and on the initial\nstate of the system, offering an additional avenue for characterising quantum\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T12:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.10197v1","title":"Comparison of smoothening flows for the topological charge in QCD-like\n  theories","summary":"We investigate properties of the topological charge for several SU(NC) gauge\nfield ensembles for NC = 4, 5, 6 with a single fermion in the two-index\nanti-symmetric representation, covering multiple lattice spacings at otherwise\napproximately constant physical parameters. Comparing the topological charge\ndefined by the Wilson flow and the over-improved DBW2 flow we find that already\nat small flow times the latter stabilises on discrete values. We provide\nevidence that as the lattice spacing is lowered the Wilson flow also separates\ninto discrete sectors at earlier flow times. Adopting the DWB2 definition in\nthe remainder of the analysis, we do not see any evidence of fractional\ntopological charges, which could in principle appear at finite lattice spacing.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-14T13:02:50Z"}
{"aid":"http://arxiv.org/abs/2504.10203v1","title":"A moving horizon estimator for aquifer thermal energy storages","summary":"Aquifer thermal energy storages (ATES) represent groundwater saturated\naquifers that store thermal energy in the form of heated or cooled groundwater.\nCombining two ATES, one can harness excess thermal energy from summer (heat)\nand winter (cold) to support the building's heating, ventilation, and air\nconditioning (HVAC) technology. In general, a dynamic operation of ATES\nthroughout the year is beneficial to avoid using fossil fuel-based HVAC\ntechnology and maximize the ``green use'' of ATES. Model predictive control\n(MPC) with an appropriate system model may become a crucial control approach\nfor ATES systems. Consequently, the MPC model should reflect spatial\ntemperature profiles around ATES' boreholes to predict extracted groundwater\ntemperatures accurately. However, meaningful predictions require the estimation\nof the current state of the system, as measurements are usually only at the\nborehole of the ATES. In control, this is often realized by model-based\nobservers. Still, observing the state of an ATES system is non-trivial, since\nthe model is typically hybrid. We show how to exploit the specific structure of\nthe hybrid ATES model and design an easy-to-solve moving horizon estimator\nbased on a quadratic program.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T13:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.10225v1","title":"A Quasi-Steady-State Black Box Simulation Approach for the Generation of\n  g-g-g-v Diagrams","summary":"The classical g-g diagram, representing the achievable acceleration space for\na vehicle, is commonly used as a constraint in trajectory planning and control\ndue to its computational simplicity. To address non-planar road geometries,\nthis concept can be extended to incorporate g-g constraints as a function of\nvehicle speed and vertical acceleration, commonly referred to as g-g-g-v\ndiagrams. However, the estimation of g-g-g-v diagrams is an open problem.\nExisting simulation-based approaches struggle to isolate non-transient,\nopen-loop stable states across all combinations of speed and acceleration,\nwhile optimization-based methods often require simplified vehicle equations and\nhave potential convergence issues. In this paper, we present a novel,\nopen-source, quasi-steady-state black box simulation approach that applies a\nvirtual inertial force in the longitudinal direction. The method emulates the\nload conditions associated with a specified longitudinal acceleration while\nmaintaining constant vehicle speed, enabling open-loop steering ramps in a\npurely QSS manner. Appropriate regulation of the ramp steer rate inherently\nmitigates transient vehicle dynamics when determining the maximum feasible\nlateral acceleration. Moreover, treating the vehicle model as a black box\neliminates model mismatch issues, allowing the use of high-fidelity or\nproprietary vehicle dynamics models typically unsuited for optimization\napproaches. An open-source version of the proposed method is available at:\nhttps://github.com/TUM-AVS/GGGVDiagrams","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T13:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.10255v1","title":"Dissipation-Induced Threshold on Integrability Footprints","summary":"The presence of a dissipative environment disrupts the unitary spectrum of\ndynamical quantum maps. Nevertheless, key features of the underlying unitary\ndynamics -- such as their integrable or chaotic nature -- are not immediately\nerased by dissipation. To investigate this, we model dissipation as a convex\ncombination of a unitary evolution and a random Kraus map, and study how\nsignatures of integrability fade as dissipation strength increases. Our\nanalysis shows that in the weakly dissipative regime, the complex eigenvalue\nspectrum organizes into well-defined, high-density clusters. We estimate the\ncritical dissipation threshold beyond which these clusters disappear, rendering\nthe dynamics indistinguishable from chaotic evolution. This threshold depends\nonly on the number of spectral clusters and the rank of the random Kraus\noperator. To characterize this transition, we introduce the eigenvalue angular\nvelocity as a diagnostic of integrability loss. We illustrate our findings\nthrough several integrable quantum circuits, including the dissipative quantum\nFourier transform. Our results provide a quantitative picture of how noise\ngradually erases the footprints of integrability in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-14T14:16:37Z"}
{"aid":"http://arxiv.org/abs/2504.10256v1","title":"Compressible fluids excited by space-dependent transport noise","summary":"We study the compressible Navier-Stokes system driven by physically relevant\ntransport noise, where the noise influences both the continuity and momentum\nequations. Our approach is based on transforming the system into a partial\ndifferential equation with random, time- and space-dependent coefficients. A\nkey challenge arises from the fact that these coefficients are\nnon-differentiable in time, rendering standard compactness arguments for the\nidentification of the pressure inapplicable. To overcome this difficulty, we\ndevelop a novel multi-layer approximation scheme and introduce a precise\nlocalization strategy with respect to both the sample space and time variable.\nThe limit pressure is then identified via the corresponding effective viscous\nflux identity. By means of stochastic compactness methods, particularly\nSkorokhod's representation theorem and its generalization by Jakubowski, we\nensure the progressive measurability required to return to the original system.\nOur results broaden the applicability of transport noise models in fluid\ndynamics and offer new insights into the interaction between stochastic effects\nand compressibility.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.10275v1","title":"LMFormer: Lane based Motion Prediction Transformer","summary":"Motion prediction plays an important role in autonomous driving. This study\npresents LMFormer, a lane-aware transformer network for trajectory prediction\ntasks. In contrast to previous studies, our work provides a simple mechanism to\ndynamically prioritize the lanes and shows that such a mechanism introduces\nexplainability into the learning behavior of the network. Additionally,\nLMFormer uses the lane connection information at intersections, lane merges,\nand lane splits, in order to learn long-range dependency in lane structure.\nMoreover, we also address the issue of refining the predicted trajectories and\npropose an efficient method for iterative refinement through stacked\ntransformer layers. For benchmarking, we evaluate LMFormer on the nuScenes\ndataset and demonstrate that it achieves SOTA performance across multiple\nmetrics. Furthermore, the Deep Scenario dataset is used to not only illustrate\ncross-dataset network performance but also the unification capabilities of\nLMFormer to train on multiple datasets and achieve better performance.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T14:43:46Z"}
{"aid":"http://arxiv.org/abs/2504.10288v1","title":"Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost\n  imaging","summary":"We present a new self-supervised deep-learning-based Ghost Imaging (GI)\nreconstruction method, which provides unparalleled reconstruction performance\nfor noisy acquisitions among unsupervised methods. We present the supporting\nmathematical framework and results from theoretical and real data use cases.\nSelf-supervision removes the need for clean reference data while offering\nstrong noise reduction. This provides the necessary tools for addressing\nsignal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge\nlow-light GI scenarios. Notable examples include micro- and nano-scale x-ray\nemission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples.\nTheir applications include in-vivo and in-operando case studies for biological\nsamples and batteries.","main_category":"cs.CV","categories":"cs.CV,cs.LG,physics.data-an","published":"2025-04-14T14:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.10307v1","title":"CROSSAN: Towards Efficient and Effective Adaptation of Multiple\n  Multimodal Foundation Models for Sequential Recommendation","summary":"Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T15:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.10318v1","title":"Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing\n  Obfuscation","summary":"Microarchitectural attacks are a significant concern, leading to many\nhardware-based defense proposals. However, different defenses target different\nclasses of attacks, and their impact on each other has not been fully\nconsidered. To raise awareness of this problem, we study an interaction between\ntwo state-of-the art defenses in this paper, timing obfuscations of remote\ncache lines (TORC) and delaying speculative changes to remote cache lines\n(DSRC). TORC mitigates cache-hit based attacks and DSRC mitigates speculative\ncoherence state change attacks.\n  We observe that DSRC enables coherence information to be retrieved into the\nprocessor core, where it is out of the reach of timing obfuscations to protect.\nThis creates an unforeseen consequence that redo operations can be triggered\nwithin the core to detect the presence or absence of remote cache lines, which\nconstitutes a security vulnerability. We demonstrate that a new covert channel\nattack is possible using this vulnerability. We propose two ways to mitigate\nthe attack, whose performance varies depending on an application's cache usage.\nOne way is to never send remote exclusive coherence state (E) information to\nthe core even if it is created. The other way is to never create a remote E\nstate, which is responsible for triggering redos.\n  We demonstrate the timing difference caused by this microarchitectural\ndefense assumption violation using GEM5 simulations. Performance evaluation on\nSPECrate 2017 and PARSEC benchmarks of the two fixes show less than 32\\%\naverage overhead across both sets of benchmarks. The repair which prevented the\ncreation of remote E state had less than 2.8% average overhead.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-14T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.10332v1","title":"MIPS is a Maxwell fluid with an extended and non-monotonic crossover","summary":"Understanding the mechanical properties of active suspensions is crucial for\ntheir potential applications in materials engineering. Among the various\nphenomena in active matter that have no analogue in equilibrium systems,\nmotility-induced phase separation (MIPS) in active colloidal suspensions is one\nof the most extensively studied. However, the mechanical properties of this\nfundamental active state of matter remain poorly understood. This study\ninvestigates the rheology of a suspension of active colloidal particles under\nconstant and oscillatory shear. Systems consisting of pseudo-hard active\nBrownian particles exhibiting co-existence of dense and dilute phases behave as\na viscoelastic Maxwell fluid at low and high frequencies, displaying\nexclusively shear thinning across a wide range of densities and activities.\nRemarkably, the cross-over point between the storage and loss moduli is\nnon-monotonic, rising with activity before the MIPS transition but falling with\nactivity after the transition, revealing the subtleties of how active forces\nand intrinsically out-of-equilibrium phases affect the mechanical properties of\nthese systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.10356v1","title":"MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31\n  languages","summary":"We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs\ncovering 31 languages. MultiLoKo consists of three partitions: a main partition\nconsisting of 500 questions per language, separately sourced to be locally\nrelevant to the specific language, and two translated partitions, containing\nhuman-authored translations from 30 non-English languages to English and vice\nversa. For comparison, we also release corresponding machine-authored\ntranslations. The data is equally distributed over two splits: a dev split and\na blind, out-of-distribution test split. MultiLoKo can be used to study a\nvariety of questions regarding the multilinguality of LLMs as well as\nmeta-questions about multilingual benchmark creation. We compute MultiLoKo\nscores for 11 base and chat models marketed to be multilingual and study their\naverage performance, their performance parity across languages, how much their\nability to answer questions depends on the question language, and which\nlanguages are most difficult. None of the models we studied performs well on\nMultiLoKo, as indicated by low average scores as well as large differences\nbetween the best and worst scoring languages. Furthermore, we find a\nsubstantial effect of the question language, indicating sub-optimal knowledge\ntransfer between languages. Lastly, we find that using local vs\nEnglish-translated data can result in differences more than 20 points for the\nbest performing models, drastically change the estimated difficulty of some\nlanguages. For using machines instead of human translations, we find a weaker\neffect on ordering of language difficulty, a larger difference in model\nrankings, and a substantial drop in estimated performance for all models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.10368v1","title":"S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability\n  of Large Reasoning Models","summary":"We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T16:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.10374v1","title":"Ctrl-Z: Controlling AI Agents via Resampling","summary":"Control evaluations measure whether monitoring and security protocols for AI\nsystems prevent intentionally subversive AI models from causing harm. Our work\npresents the first control evaluation performed in an agent environment. We\nconstruct BashBench, a dataset of 257 challenging multi-step system\nadministration tasks, and evaluate whether various safety measures can prevent\nan adversarially constructed AI agent from covertly downloading and executing\nmalicious code in this environment. This multi-step setting introduces new\nattack and defense dynamics, which we investigate in order to design novel\ncontrol protocols that prevent safety failures without hindering the ability of\nnon-malicious agents to perform useful work. We introduce a class of control\nprotocols called resample protocols that dynamically take additional samples of\ncertain actions. We find these protocols significantly improve on existing\ntechniques by selectively blocking the AI agent from executing suspicious code\nand incriminating the agent by generating additional examples of dangerous\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\nbest protocol combines resampling with analysis of previous steps, reducing the\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\nnon-malicious agent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.10376v1","title":"Tumor-immune cell interactions by a fully parabolic chemotaxis model\n  with logistic source","summary":"This work studies the existence of classical solutions to a class of\nchemotaxis systems reading\n  \\[\\begin{cases}\n  u_t = \\Delta u-\\chi \\nabla\\cdot(u \\nabla v) + \\mu_1 u^k -\\mu_2 u^{k+1}, &\n\\text{in} \\; \\Omega\\times(0,T_{\\text{max}}), \\\\\n  v_t= \\Delta v+\\alpha w-\\beta v-\\gamma u v, & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  w_t= \\Delta w-\\delta u w+ \\mu_3 w(1-w), & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  \\frac{\\partial u}{\\partial\\nu}=\\frac{\\partial v}{\\partial\\nu}=\\frac{\\partial\nw}{\\partial\\nu}=0, & \\text{on} \\; \\partial\\Omega\\times(0,T_{\\text{max}}), \\\\\n  u(x,0)=u_0(x), \\quad v(x,0)= v_0(x), \\quad w(x,0)= w_0(x), &\nx\\in\\overline{\\Omega},\n  \\end{cases}\\] that model interactions between tumor (i.e., $w$) and immune\ncells (i.e., $u$) with a logistic-type source term $\\mu_1 u^k - \\mu_2 u^{k+1}$,\n$k\\geq1$, also in presence of a chemical signal (i.e., $v$). The model\nparameters $\\chi, \\mu_1,\\mu_2, \\mu_3, \\alpha, \\beta, \\gamma$, and $\\delta$ are\nall positive. The value $T_{\\text{max}}$ indicates the maximum instant of time\nup to which solutions are defined. Our focus is on examining the global\nexistence in a bounded domain $\\Omega\\subset \\mathbb{R}^n, n \\geq 3$, under\nNeumann boundary conditions. We distinguish between two scenarios: $k>1$ and\n$k=1$. The first case allows to prove boundedness under smaller assumptions\nrelying only on the model parameters instead of on the initial data, while the\nsecond case requires an extra condition relating the parameters $\\chi, \\mu_2$,\n$n$, and the initial data $\\lVert v_0 \\rVert_{L^\\infty(\\Omega)}$. This model\ncan be seen as an extension of those previously examined in [11] and [4], being\nthe former a system with only two equations and the latter the same model\nwithout logistic.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:24:04Z"}
{"aid":"http://arxiv.org/abs/2504.10388v1","title":"Inferring genotype-phenotype maps using attention models","summary":"Predicting phenotype from genotype is a central challenge in genetics.\nTraditional approaches in quantitative genetics typically analyze this problem\nusing methods based on linear regression. These methods generally assume that\nthe genetic architecture of complex traits can be parameterized in terms of an\nadditive model, where the effects of loci are independent, plus (in some cases)\npairwise epistatic interactions between loci. However, these models struggle to\nanalyze more complex patterns of epistasis or subtle gene-environment\ninteractions. Recent advances in machine learning, particularly attention-based\nmodels, offer a promising alternative. Initially developed for natural language\nprocessing, attention-based models excel at capturing context-dependent\ninteractions and have shown exceptional performance in predicting protein\nstructure and function. Here, we apply attention-based models to quantitative\ngenetics. We analyze the performance of this attention-based approach in\npredicting phenotype from genotype using simulated data across a range of\nmodels with increasing epistatic complexity, and using experimental data from a\nrecent quantitative trait locus mapping study in budding yeast. We find that\nour model demonstrates superior out-of-sample predictions in epistatic regimes\ncompared to standard methods. We also explore a more general multi-environment\nattention-based model to jointly analyze genotype-phenotype maps across\nmultiple environments and show that such architectures can be used for\n\"transfer learning\" - predicting phenotypes in novel environments with limited\ntraining data.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.LG,q-bio.PE","published":"2025-04-14T16:32:17Z"}
{"aid":"http://arxiv.org/abs/2504.10399v1","title":"Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial\n  Errors","summary":"For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-14T16:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10411v1","title":"FPGA-Optimized Hardware Accelerator for Fast Fourier Transform and\n  Singular Value Decomposition in AI","summary":"This research introduces an FPGA-based hardware accelerator to optimize the\nSingular Value Decomposition (SVD) and Fast Fourier transform (FFT) operations\nin AI models. The proposed design aims to improve processing speed and reduce\ncomputational latency. Through experiments, we validate the performance\nbenefits of the hardware accelerator and show how well it handles FFT and SVD\noperations. With its strong security and durability, the accelerator design\nachieves significant speedups over software implementations, thanks to its\nmodules for data flow control, watermark embedding, FFT, and SVD.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T16:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.10423v1","title":"Overcoming light scattering with high optical nonlinearity","summary":"Achieving high-resolution optical imaging deep within heterogeneous and\nscattering media remains a fundamental challenge in biological microscopy,\nwhere conventional techniques are hindered by multiple light scattering and\nabsorption. Here, we present a non-invasive imaging approach that harnesses the\nnonlinear response of luminescent labels in conjunction with the statistical\nand spatial properties of speckle patterns - an effect of random light\ninterference. Using avalanching nanoparticles (ANPs) with strong\nphotoluminescence nonlinearity, we demonstrate that random speckle illumination\ncan be converted into a single, localized, sub-diffraction excitation spot.\nThis spot can be scanned across the sample using the angular memory effect,\nenabling high-resolution imaging through a scattering layer. Our method is\ngeneral, fast, and cost-effective. It requires no wavefront shaping, no\nfeedback, and no reconstruction algorithm, offering a powerful new route to\ndeep, high-resolution imaging through complex media.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.bio-ph,physics.med-ph","published":"2025-04-14T17:10:24Z"}
{"aid":"http://arxiv.org/abs/2504.10445v1","title":"RealWebAssist: A Benchmark for Long-Horizon Web Assistance with\n  Real-World Users","summary":"To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T17:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.10479v1","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for\n  Open-Source Multimodal Models","summary":"We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10834v1","title":"LightFormer: A lightweight and efficient decoder for remote sensing\n  image segmentation","summary":"Deep learning techniques have achieved remarkable success in the semantic\nsegmentation of remote sensing images and in land-use change detection.\nNevertheless, their real-time deployment on edge platforms remains constrained\nby decoder complexity. Herein, we introduce LightFormer, a lightweight decoder\nfor time-critical tasks that involve unstructured targets, such as disaster\nassessment, unmanned aerial vehicle search-and-rescue, and cultural heritage\nmonitoring. LightFormer employs a feature-fusion and refinement module built on\nchannel processing and a learnable gating mechanism to aggregate multi-scale,\nmulti-range information efficiently, which drastically curtails model\ncomplexity. Furthermore, we propose a spatial information selection module\n(SISM) that integrates long-range attention with a detail preservation branch\nto capture spatial dependencies across multiple scales, thereby substantially\nimproving the recognition of unstructured targets in complex scenes. On the\nISPRS Vaihingen benchmark, LightFormer attains 99.9% of GLFFNet's mIoU (83.9%\nvs. 84.0%) while requiring only 14.7% of its FLOPs and 15.9% of its parameters,\nthus achieving an excellent accuracy-efficiency trade-off. Consistent results\non LoveDA, ISPRS Potsdam, RescueNet, and FloodNet further demonstrate its\nrobustness and superior perception of unstructured objects. These findings\nhighlight LightFormer as a practical solution for remote sensing applications\nwhere both computational economy and high-precision segmentation are\nimperative.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.10836v1","title":"Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach\n  Based on Deep Joint Source-Channel Coding","summary":"In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.","main_category":"eess.SP","categories":"eess.SP,cs.AI","published":"2025-04-15T03:29:24Z"}
{"aid":"http://arxiv.org/abs/2504.10855v1","title":"Virtual Contraction Approach to Decentralized Adaptive Stabilization of\n  Nonlinear Time-Delayed Networks","summary":"In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T04:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.10868v1","title":"AdS3 axion wormholes as stable contributions to the Euclidean\n  gravitational path integral","summary":"Recent work has demonstrated that Euclidean Giddings-Strominger axion\nwormholes are stable in asymptotically flat 4D Minkowski spacetime, suggesting\nthat they should, at least naively, be included as contributions in the quantum\ngravitational path integral. Such inclusion appears to lead to known wormhole\nparadoxes, such as the factorization problem. In this paper, we generalize\nthese results to AdS3 spacetime, where the axion is equivalent to a U(1) gauge\nfield. We explicitly construct the classical wormhole solutions, show their\nregularity and stability, and compute their actions for arbitrary ratios of the\nwormhole mouth radius to the AdS radius and across various topologies. Finally,\nWe discuss potential implications of these findings for the 3D gravitational\npath integral.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T05:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.10898v1","title":"Xpose: Bi-directional Engineering for Hidden Query Extraction","summary":"Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.","main_category":"cs.DB","categories":"cs.DB,cs.AI,H.2.8","published":"2025-04-15T06:17:58Z"}
{"aid":"http://arxiv.org/abs/2504.10903v1","title":"Efficient Reasoning Models: A Survey","summary":"Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T06:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.10905v1","title":"InterAnimate: Taming Region-aware Diffusion Model for Realistic Human\n  Interaction Animation","summary":"Recent video generation research has focused heavily on isolated actions,\nleaving interactive motions-such as hand-face interactions-largely unexamined.\nThese interactions are essential for emerging biometric authentication systems,\nwhich rely on interactive motion-based anti-spoofing approaches. From a\nsecurity perspective, there is a growing need for large-scale, high-quality\ninteractive videos to train and strengthen authentication models. In this work,\nwe introduce a novel paradigm for animating realistic hand-face interactions.\nOur approach simultaneously learns spatio-temporal contact dynamics and\nbiomechanically plausible deformation effects, enabling natural interactions\nwhere hand movements induce anatomically accurate facial deformations while\nmaintaining collision-free contact. To facilitate this research, we present\nInterHF, a large-scale hand-face interaction dataset featuring 18 interaction\npatterns and 90,000 annotated videos. Additionally, we propose InterAnimate, a\nregion-aware diffusion model designed specifically for interaction animation.\nInterAnimate leverages learnable spatial and temporal latents to effectively\ncapture dynamic interaction priors and integrates a region-aware interaction\nmechanism that injects these priors into the denoising process. To the best of\nour knowledge, this work represents the first large-scale effort to\nsystematically study human hand-face interactions. Qualitative and quantitative\nresults show InterAnimate produces highly realistic animations, setting a new\nbenchmark. Code and data will be made public to advance research.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-15T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.10916v1","title":"Embedding Radiomics into Vision Transformers for Multimodal Medical\n  Image Classification","summary":"Background: Deep learning has significantly advanced medical image analysis,\nwith Vision Transformers (ViTs) offering a powerful alternative to\nconvolutional models by modeling long-range dependencies through\nself-attention. However, ViTs are inherently data-intensive and lack\ndomain-specific inductive biases, limiting their applicability in medical\nimaging. In contrast, radiomics provides interpretable, handcrafted descriptors\nof tissue heterogeneity but suffers from limited scalability and integration\ninto end-to-end learning frameworks. In this work, we propose the\nRadiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features\nwith data-driven visual embeddings within a ViT backbone.\n  Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and\npatch-wise ViT embeddings through early fusion, enhancing robustness and\nperformance in medical image classification.\n  Methods: Following the standard ViT pipeline, images were divided into\npatches. For each patch, handcrafted radiomic features were extracted and fused\nwith linearly projected pixel embeddings. The fused representations were\nnormalized, positionally encoded, and passed to the ViT encoder. A learnable\n[CLS] token aggregated patch-level information for classification. We evaluated\nRE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal\nOCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was\nbenchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.\n  Results: RE-ViT achieved state-of-the-art results: on BUSI,\nAUC=0.950+/-0.011; on ChestXray2017, AUC=0.989+/-0.004; on Retinal OCT,\nAUC=0.986+/-0.001, which outperforms other comparison models.\n  Conclusions: The RE-ViT framework effectively integrates radiomics with ViT\narchitectures, demonstrating improved performance and generalizability across\nmultimodal medical image classification tasks.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-15T06:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.10922v1","title":"Equivalence of germs (of mappings and sets) over k vs that over K","summary":"Consider real-analytic mapping-germs, (R^n,o)-> (R^m,o). They can be\nequivalent (by coordinate changes) complex-analytically, but not\nreal-analytically. However, if the transformation of complex-equivalence is\nidentity modulo higher order terms, then it implies the real-equivalence.\n  On the other hand, starting from complex-analytic map-germs (C^n,o)->(C^m,o),\nand taking any field extension, C to K, one has: if two maps are equivalent\nover K, then they are equivalent over C.\n  These (quite useful) properties seem to be not well known. We prove slightly\nstronger properties in a more general form:\n  * for Maps(X,Y) where X,Y are (formal/analytic/Nash) scheme-germs, with\narbitrary singularities, over a base ring k;\n  * for the classical groups of (right/left-right/contact) equivalence of\nSingularity Theory;\n  * for faithfully-flat extensions of rings k -> K. In particular, for\narbitrary extension of fields, in any characteristic.\n  The case ``k is a ring\" is important for the study of\ndeformations/unfoldings. E.g. it implies the statement for fields: if a family\nof maps {f_t} is trivial over K, then it is also trivial over k.\n  Similar statements for scheme-germs (``isomorphism over K vs isomorphism over\nk\") follow by the standard reduction ``Two maps are contact equivalent iff\ntheir zero sets are ambient isomorphic\".\n  This study involves the contact equivalence of maps with singular targets,\nwhich seems to be not well-established. We write down the relevant part of this\ntheory.","main_category":"math.AG","categories":"math.AG,math.AC,math.CV","published":"2025-04-15T07:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.10923v1","title":"Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term\n  Wind Power Forecasting","summary":"Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-15T07:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.10924v1","title":"Exploring the nature of $Î·_{1}(1855)$ and it's partner in a chiral\n  quark model","summary":"Inspired by the recent experimental discoveries of \\(X(3872)\\)\n(\\(c\\bar{q}\\)-\\(q\\bar{c}\\)) and \\(T_{cc}\\) (\\(c\\bar{q}\\)-\\(c\\bar{q}\\)), we\nsystematically study two four-quark systems: the \\(K K_1\\)\n(\\(q\\bar{s}\\)-\\(q\\bar{s}\\)) system and the \\(K \\bar{K}_1\\)\n(\\(q\\bar{s}\\)-\\(s\\bar{q}\\)) system, which is a candidate for the recently\nobserved \\(\\eta_1(1855)\\). Within the framework of an accurate few-body\ncalculation method (GEM), we employ the chiral quark model to simultaneously\nconsider the molecular and diquark structures of these two multiquark systems\nand include their channel coupling effects. Our results show that the \\(K\n\\bar{K}_1\\) system remains a scattering state. On the other hand, due to the\npresence of a good-diquark structure in the \\(K K_1\\) system, we obtain a bound\nstate in the coupled-channel calculation. The primary contribution to the\nbinding energy comes from the exchange of \\(\\pi\\)-meson and \\(\\sigma\\)-meson.\nThe inter-quark distance indicates that it is a compact four-quark structure.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T07:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10942v1","title":"The path towards measuring the gravitational field of proton bunches at\n  accelerators","summary":"The Newtonian law describing the gravitational interaction of\nnon-relativistic (slowly moving) gravitating matter, has been tested in many\nlaboratory experiments with very high precision. In contrast, the post\nMinkowskian predictions for the gravitational field of ultra-relativistic\nmatter, dominated by momentum instead of rest mass, have not been tested\ndirectly yet. The intense ultra-relativistic proton beam in the LHC storage\nring offers the potential to test general relativity and alternative\ngravitational theories in this parameter regime for the first time in\ncontrolled lab-scale experiments. If successful, this would open the road to a\nnovel use case of the LHC, where non-trivial gravitational physics could be\nstudied likely in a parasitic mode, without the necessity of dedicated filling\npatterns. While the technical challenges are formidable, they should also lead\nto the development of ultra-high-sensitive acceleration sensors with abundant\napplications in other parts of science and technology. The present document\nsummarizes the status of the theoretical studies in this direction, points out\nthe challenges, and possible ways of addressing them. It was submitted as a\ncontribution to the European Strategy for Particle Physics (ESPP) 2026 Update.","main_category":"hep-ex","categories":"hep-ex,gr-qc,quant-ph","published":"2025-04-15T07:45:35Z"}
{"aid":"http://arxiv.org/abs/2504.10946v1","title":"Maximum principles and spectral analysis for the superposition of\n  operators of fractional order","summary":"We consider a \"superposition operator\" obtained through the continuous\nsuperposition of operators of mixed fractional order, modulated by a signed\nBorel finite measure defined over the set $[0, 1]$. The relevance of this\noperator is rooted in the fact that it incorporates special and significant\ncases of interest, like the mixed operator $-\\Delta + (-\\Delta)^s$, the\n(possibly) infinite sum of fractional Laplacians and allows to consider\noperators carrying a \"wrong sign\".\n  We first outline weak and strong maximum principles for this type of\noperators. Then, we complete the spectral analysis for the related Dirichlet\neigenvalue problem started in [DPLSV25b].","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T07:50:32Z"}
{"aid":"http://arxiv.org/abs/2504.10968v1","title":"Bulk Hydrodynamic Transport in Weyl Semimetals","summary":"The role of collective longitudinal modes, plasmons, in bulk hydrodynamic\ntransport in Weyl semimetals is explored. In contrast to graphene, where these\nmodes are gapless, plasmons in Weyl semimetals are gapped. This gap, however,\ncan be made arbitrarily small by decreasing the temperature or the chemical\npotential, making plasmon modes thermally accessible, both in thermodynamics\nand transport. In very clean Weyl semimetals near charge-neutrality where the\nplasmon gap is minimal, we find that they leave an imprint in the thermal\nconductivity and the viscosity.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T08:20:45Z"}
{"aid":"http://arxiv.org/abs/2504.10974v1","title":"Self-Supervised Enhancement of Forward-Looking Sonar Images: Bridging\n  Cross-Modal Degradation Gaps through Feature Space Transformation and\n  Multi-Frame Fusion","summary":"Enhancing forward-looking sonar images is critical for accurate underwater\ntarget detection. Current deep learning methods mainly rely on supervised\ntraining with simulated data, but the difficulty in obtaining high-quality\nreal-world paired data limits their practical use and generalization. Although\nself-supervised approaches from remote sensing partially alleviate data\nshortages, they neglect the cross-modal degradation gap between sonar and\nremote sensing images. Directly transferring pretrained weights often leads to\noverly smooth sonar images, detail loss, and insufficient brightness. To\naddress this, we propose a feature-space transformation that maps sonar images\nfrom the pixel domain to a robust feature domain, effectively bridging the\ndegradation gap. Additionally, our self-supervised multi-frame fusion strategy\nleverages complementary inter-frame information to naturally remove speckle\nnoise and enhance target-region brightness. Experiments on three self-collected\nreal-world forward-looking sonar datasets show that our method significantly\noutperforms existing approaches, effectively suppressing noise, preserving\ndetailed edges, and substantially improving brightness, demonstrating strong\npotential for underwater target detection applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T08:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.10989v1","title":"Global N-body Simulation of Gap Edge Structures Created by Perturbations\n  from a Small Satellite Embedded in Saturn's Rings II: The Effect of\n  Satellite's Orbital Eccentricity and Inclination","summary":"Pan and Daphnis are embedded in Saturn's rings and opening a gap with\nsatellite wakes at the gap edges. Furthermore, in the case of Daphnis,\npronounced vertical wall structures casting shadows on the rings are also\nobserved in the satellite wakes. In this paper, we perform a global 3D N-body\nsimulation with non-zero $e_{\\rm s}$ or non-zero $i_{\\rm s}$ of the satellite\norbit to investigate how they affect the gap edge structures. We found that the\neffect of satellite eccentricity is important both in the satellite wakes and\nthe vertical walls at the gap edges. The non-sinusoidal sawtooth-like satellite\nwakes and azimuthally more localized vertical walls observed by Cassini are\nsimultaneously reproduced in the detailed structures and spatial scales. Both\nof them periodically vary due to the satellite excursions between the apocenter\nand the pericenter. The ring particles in outer (inner) rings that undergo\nclosest encounters with the satellite near the apocenter (pericenter) are\nexcited the most highly. Because the excited eccentricities of the ring\nparticles are converted to the inclinations through physical collisions, the\nconversion is the most active for the particles that acquire the highest\neccentricities, resulting in the azimuthally more localized vertical wall\nstructures. The predicted height of the tallest vertical walls is $\\sim 0.2$\ntimes the satellite Hill radius in the case of the satellite eccentricity\ncomparable to Daphnis when adopting Hill scaling, which is twice as much as the\nheight obtained in the case of the circular satellite orbit and is\nquantitatively more consistent with the Cassini observation. These results show\nthat the observed vertical walls are actually formed by the satellite wakes\nfollowed by their conversion to the vertical motions through inter-particle\ncollisions, rather than by the out-of-plane perturbation from the satellite in\nan inclined orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T09:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.11006v1","title":"A Navier-Stokes-Peridynamics hybrid algorithm for the coupling of\n  compressible flows and fracturing materials","summary":"Modeling and simulation of fluid-structure interactions are crucial to the\nsuccess of aerospace engineering. This work addresses a novel hybrid algorithm\nthat models the close coupling between compressible flows and deformable\nmaterials using a mesoscopic approach. Specifically, the high-speed flows are\ndescribed by the gas-kinetic scheme, which is a robust Navier-Stokes\nalternative solver built on the molecular kinetic theory. The deformation,\ndamage, and fracture of materials are depicted using the bond-based\nperidynamics, which serves as coarse-grained molecular dynamics to construct\nnon-local extensions of classical continuum mechanics. The evolution of fluids\nand materials are closely coupled using the ghost-cell immersed boundary\nmethod. Within each time step, the solutions of flow and solid fields are\nupdated simultaneously, and physics-driven boundary conditions are exchanged\nfor each other via ghost cells. Extensive numerical experiments, including\ncrack propagation in a pre-cracked plate, subsonic flow around the NACA0012\nairfoil, supersonic flow around the circular cylinder, and shock wave impacting\non the elastic panel, are performed to validate the algorithm. The simulation\nresults demonstrate the unique advantages of current hybrid algorithm in\nsolving fracture propagation induced by high-speed flows.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T09:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.11011v1","title":"Document Quality Scoring for Web Crawling","summary":"The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-15T09:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.11024v1","title":"Easy3D: A Simple Yet Effective Method for 3D Interactive Segmentation","summary":"The increasing availability of digital 3D environments, whether through\nimage-based 3D reconstruction, generation, or scans obtained by robots, is\ndriving innovation across various applications. These come with a significant\ndemand for 3D interaction, such as 3D Interactive Segmentation, which is useful\nfor tasks like object selection and manipulation. Additionally, there is a\npersistent need for solutions that are efficient, precise, and performing well\nacross diverse settings, particularly in unseen environments and with\nunfamiliar objects. In this work, we introduce a 3D interactive segmentation\nmethod that consistently surpasses previous state-of-the-art techniques on both\nin-domain and out-of-domain datasets. Our simple approach integrates a\nvoxel-based sparse encoder with a lightweight transformer-based decoder that\nimplements implicit click fusion, achieving superior performance and maximizing\nefficiency. Our method demonstrates substantial improvements on benchmark\ndatasets, including ScanNet, ScanNet++, S3DIS, and KITTI-360, and also on\nunseen geometric distributions such as the ones obtained by Gaussian Splatting.\nThe project web-page is available at https://simonelli-andrea.github.io/easy3d.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11037v1","title":"Statistical complexity as a probe of mass and phase structure in compact\n  objects","summary":"In this work, we present a comprehensive and systematic study of the\nstatistical complexity, originally introduced by L\\'opez-Ruiz, Mancini, and\nCalbet [Phys. Lett. A 209, 321-326 (1995)], across a broad range of compact\nstar models. We explore how complexity correlates not only with macroscopic\nobservables such as mass and radius, but also with the microscopic\ncharacteristics of the underlying equation of state. By incorporating both\nrealistic equations of state and analytical solutions to Einstein's field\nequations, we demonstrate that gravitational mass plays a dominant role in\ndetermining the behavior of complexity. Furthermore, we show that strong phase\ntransitions within the stellar interior, such as those hypothesized in hybrid\nstars, can manifest as distinct features in the complexity profile, offering a\npotential informational signature of such transitions. This work offers new\ninsights into the link between information theory and compact object physics,\nhighlighting complexity's potential as a diagnostic tool in astrophysics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE,gr-qc,nucl-th,quant-ph","published":"2025-04-15T09:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11066v1","title":"Improving fingerprint presentation attack detection by an approach\n  integrated into the personal verification stage","summary":"Presentation Attack Detection (PAD) systems are usually designed\nindependently of the fingerprint verification system. While this can be\nacceptable for use cases where specific user templates are not predetermined,\nit represents a missed opportunity to enhance security in scenarios where\nintegrating PAD with the fingerprint verification system could significantly\nleverage users' templates, which are the real target of a potential\npresentation attack. This does not mean that a PAD should be specifically\ndesigned for such users; that would imply the availability of many enrolled\nusers' PAI and, consequently, complexity, time, and cost increase. On the\ncontrary, we propose to equip a basic PAD, designed according to the state of\nthe art, with an innovative add-on module called the Closeness Binary Code (CC)\nmodule. The term \"closeness\" refers to a peculiar property of the bona\nfide-related features: in an Euclidean feature space, genuine fingerprints tend\nto cluster in a specific pattern. First, samples from the same finger are close\nto each other, then samples from other fingers of the same user and finally,\nsamples from fingers of other users. This property is statistically verified in\nour previous publication, and further confirmed in this paper. It is\nindependent of the user population and the feature set class, which can be\nhandcrafted or deep network-based (embeddings). Therefore, the add-on can be\ndesigned without the need for the targeted user samples; moreover, it exploits\nher/his samples' \"closeness\" property during the verification stage. Extensive\nexperiments on benchmark datasets and state-of-the-art PAD methods confirm the\nbenefits of the proposed add-on, which can be easily coupled with the main PAD\nmodule integrated into the fingerprint verification system.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.11067v1","title":"Morphing-based Compression for Data-centric ML Pipelines","summary":"Data-centric ML pipelines extend traditional machine learning (ML) pipelines\n-- of feature transformations and ML model training -- by outer loops for data\ncleaning, augmentation, and feature engineering to create high-quality input\ndata. Existing lossless matrix compression applies lightweight compression\nschemes to numeric matrices and performs linear algebra operations such as\nmatrix-vector multiplications directly on the compressed representation but\nstruggles to efficiently rediscover structural data redundancy. Compressed\noperations are effective at fitting data in available memory, reducing I/O\nacross the storage-memory-cache hierarchy, and improving instruction\nparallelism. The applied data cleaning, augmentation, and feature\ntransformations provide a rich source of information about data characteristics\nsuch as distinct items, column sparsity, and column correlations. In this\npaper, we introduce BWARE -- an extension of AWARE for workload-aware lossless\nmatrix compression -- that pushes compression through feature transformations\nand engineering to leverage information about structural transformations.\nBesides compressed feature transformations, we introduce a novel technique for\nlightweight morphing of a compressed representation into workload-optimized\ncompressed representations without decompression. BWARE shows substantial\nend-to-end runtime improvements, reducing the execution time for training\ndata-centric ML pipelines from days to hours.","main_category":"cs.DB","categories":"cs.DB,cs.DC,cs.LG","published":"2025-04-15T11:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.11073v1","title":"FreeDOM: Online Dynamic Object Removal Framework for Static Map\n  Construction Based on Conservative Free Space Estimation","summary":"Online map construction is essential for autonomous robots to navigate in\nunknown environments. However, the presence of dynamic objects may introduce\nartifacts into the map, which can significantly degrade the performance of\nlocalization and path planning. To tackle this problem, a novel online dynamic\nobject removal framework for static map construction based on conservative free\nspace estimation (FreeDOM) is proposed, consisting of a scan-removal front-end\nand a map-refinement back-end. First, we propose a multi-resolution map\nstructure for fast computation and effective map representation. In the\nscan-removal front-end, we employ raycast enhancement to improve free space\nestimation and segment the LiDAR scan based on the estimated free space. In the\nmap-refinement back-end, we further eliminate residual dynamic objects in the\nmap by leveraging incremental free space information. As experimentally\nverified on SemanticKITTI, HeLiMOS, and indoor datasets with various sensors,\nour proposed framework overcomes the limitations of visibility-based methods\nand outperforms state-of-the-art methods with an average F1-score improvement\nof 9.7%.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T11:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.11081v1","title":"DPS: Design Pattern Summarisation Using Code Features","summary":"Automatic summarisation has been used efficiently in recent years to condense\ntexts, conversations, audio, code, and various other artefacts. A range of\nmethods, from simple template-based summaries to complex machine learning\ntechniques -- and more recently, large language models -- have been employed to\ngenerate these summaries. Summarising software design patterns is important\nbecause it helps developers quickly understand and reuse complex design\nconcepts, thereby improving software maintainability and development\nefficiency. However, the generation of summaries for software design patterns\nhas not yet been explored. Our approach utilises code features and JavaParser\nto parse the code and create a JSON representation. Using an NLG library on\nthis JSON representation, we convert it into natural language text that acts as\na summary of the code, capturing the contextual information of the design\npattern. Our empirical results indicate that the summaries generated by our\napproach capture the context in which patterns are applied in the codebase.\nStatistical evaluations demonstrate that our summaries closely align with\nhuman-written summaries, as evident from high values in the ROUGE-L, BLEU-4,\nNIST, and FrugalScore metrics. A follow-up survey further shows that DPS\nsummaries were rated as capturing context better than human-generated\nsummaries.","main_category":"cs.SE","categories":"cs.SE,D.2","published":"2025-04-15T11:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11088v1","title":"FLSSM: A Federated Learning Storage Security Model with Homomorphic\n  Encryption","summary":"Federated learning based on homomorphic encryption has received widespread\nattention due to its high security and enhanced protection of user data\nprivacy. However, the characteristics of encrypted computation lead to three\nchallenging problems: ``computation-efficiency\", ``attack-tracing\" and\n``contribution-assessment\". The first refers to the efficiency of encrypted\ncomputation during model aggregation, the second refers to tracing malicious\nattacks in an encrypted state, and the third refers to the fairness of\ncontribution assessment for local models after encryption. This paper proposes\na federated learning storage security model with homomorphic encryption (FLSSM)\nto protect federated learning model privacy and address the three issues\nmentioned above. First, we utilize different nodes to aggregate local models in\nparallel, thereby improving encrypted models' aggregation efficiency. Second,\nwe introduce trusted supervise nodes to examine local models when the global\nmodel is attacked, enabling the tracing of malicious attacks under homomorphic\nencryption. Finally, we fairly reward local training nodes with encrypted local\nmodels based on trusted training time. Experiments on multiple real-world\ndatasets show that our model significantly outperforms baseline models in terms\nof both efficiency and security metrics.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11116v1","title":"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy\n  Optimization for Continuous-Time Multi-Asset Portfolio","summary":"Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-15T12:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.11127v1","title":"Keplerian motion of a compact source orbiting the inner disk of PDS 70:\n  A third protoplanet in a resonance with b and c?","summary":"The disk around PDS 70 hosts two directly imaged protoplanets in a gap.\nPrevious VLT/SPHERE and recent James Webb Space Telescope/NIRCam observations\nhave hinted at the presence of a third compact source in the same gap at ~13\nau, interior to the orbit of PDS 70 b. We reduce seven published and one\nunpublished VLT/SPHERE datasets in YJH and K bands, as well as an archival\nVLT/NaCo dataset in L' band, and an archival VLT/SINFONI dataset in H+K band.\nWe combine angular-, spectral- and reference star differential imaging to\nsearch for protoplanet candidates. We recover the compact source in all epochs,\nconsistent with the JWST detection, moving on an arc that can be fit by\nKeplerian motion of a protoplanet which could be in a resonance with PDS 70 b &\nc. We find that the spectral slope is overall consistent with the unresolved\nstar and inner disk emission at 0.95--1.65$\\mu$m, which suggests a dust\nscattering dominated spectrum. An excess beyond 2.3$\\mu$m could be thermal\nemission from either a protoplanet or heated circumplanetary dust, variability,\nor inner disk contamination, and requires confirmation. While we currently\ncannot rule out a moving inner disk feature or a dust clump associated with an\nunseen planet, the data supports the hypothesis of a third protoplanet in this\nremarkable system.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T12:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11146v1","title":"Exploring Student Behaviors and Motivations using AI TAs with Optional\n  Guardrails","summary":"AI-powered chatbots and digital teaching assistants (AI TAs) are gaining\npopularity in programming education, offering students timely and personalized\nfeedback. Despite their potential benefits, concerns about student\nover-reliance and academic misconduct have prompted the introduction of\n\"guardrails\" into AI TAs - features that provide scaffolded support rather than\ndirect solutions. However, overly restrictive guardrails may lead students to\nbypass these tools and use unconstrained AI models, where interactions are not\nobservable, thus limiting our understanding of students' help-seeking\nbehaviors. To investigate this, we designed and deployed a novel AI TA tool\nwith optional guardrails in one lab of a large introductory programming course.\nAs students completed three code writing and debugging tasks, they had the\noption to receive guardrailed help or use a \"See Solution\" feature which\ndisabled the guardrails and generated a verbatim response from the underlying\nmodel. We investigate students' motivations and use of this feature and examine\nthe association between usage and their course performance. We found that 50%\nof the 885 students used the \"See Solution\" feature for at least one problem\nand 14% used it for all three problems. Additionally, low-performing students\nwere more likely to use this feature and use it close to the deadline as they\nstarted assignments later. The predominant factors that motivated students to\ndisable the guardrails were assistance in solving problems, time pressure, lack\nof self-regulation, and curiosity. Our work provides insights into students'\nsolution-seeking motivations and behaviors, which has implications for the\ndesign of AI TAs that balance pedagogical goals with student preferences.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-15T12:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.11167v1","title":"Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with\n  Applications","summary":"The SPIKE family of linear system solvers provides parallelism using a block\ntridiagonal partitioning. Typically SPIKE-based solvers are applied to banded\nsystems, resulting in structured off-diagonal blocks with non-zeros elements\nrestricted to relatively small submatrices comprising the band of the original\nmatrix. In this work, a low-rank SVD based approximation of the off-diagonal\nblocks is investigated. This produces a representation which more effectively\nhandles matrices with large, sparse bands. A set of flexible distributed\nsolvers, the LR-SPIKE variants, are implemented. There are applicable to a wide\nrange of applications -- from use as a \"black-box\" preconditioner which\nstraightforwardly improves upon the classic Block Jacobi preconditioner, to use\nas a specialized \"approximate direct solver.\" An investigation of the\neffectiveness of the new preconditioners for a selection of SuiteSparse\nmatrices is performed, particularly focusing on matrices derived from 3D finite\nelement simulations. In addition, the SPIKE approximate linear system solvers\nare also paired with the FEAST eigenvalue solver, where they are shown to be\nparticularly effective due to the former's rapid convergence, and the latter's\nacceptance of loose linear system solver convergence, resulting in a\ncombination which requires very few solver iterations.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-15T13:15:00Z"}
{"aid":"http://arxiv.org/abs/2504.11170v1","title":"A Real-time Anomaly Detection Method for Robots based on a Flexible and\n  Sparse Latent Space","summary":"The growing demand for robots to operate effectively in diverse environments\nnecessitates the need for robust real-time anomaly detection techniques during\nrobotic operations. However, deep learning-based models in robotics face\nsignificant challenges due to limited training data and highly noisy signal\nfeatures. In this paper, we present Sparse Masked Autoregressive Flow-based\nAdversarial AutoEncoders model to address these problems. This approach\nintegrates Masked Autoregressive Flow model into Adversarial AutoEncoders to\nconstruct a flexible latent space and utilize Sparse autoencoder to efficiently\nfocus on important features, even in scenarios with limited feature space. Our\nexperiments demonstrate that the proposed model achieves a 4.96% to 9.75%\nhigher area under the receiver operating characteristic curve for\npick-and-place robotic operations with randomly placed cans, compared to\nexisting state-of-the-art methods. Notably, it showed up to 19.67% better\nperformance in scenarios involving collisions with lightweight objects.\nAdditionally, unlike the existing state-of-the-art model, our model performs\ninferences within 1 millisecond, ensuring real-time anomaly detection. These\ncapabilities make our model highly applicable to machine learning-based robotic\nsafety systems in dynamic environments. The code will be made publicly\navailable after acceptance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-15T13:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.11172v1","title":"TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data","summary":"Large-scale foundation models in Earth Observation can learn versatile,\nlabel-efficient representations by leveraging massive amounts of unlabeled\ndata. However, existing public datasets are often limited in scale, geographic\ncoverage, or sensor variety. We introduce TerraMesh, a new globally diverse,\nmultimodal dataset combining optical, synthetic aperture radar, elevation, and\nland-cover modalities in an Analysis-Ready Data format. TerraMesh includes over\n9 million samples with eight spatiotemporal aligned modalities, enabling\nlarge-scale pre-training and fostering robust cross-modal correlation learning.\nWe provide detailed data processing steps, comprehensive statistics, and\nempirical evidence demonstrating improved model performance when pre-trained on\nTerraMesh. The dataset will be made publicly available with a permissive\nlicense.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.11196v1","title":"The Lifetime of the Covid Memorial Wall: Modelling with Collections\n  Demography, Social Media Data and Citizen Science","summary":"The National Covid Memorial Wall in London, featuring over 240,000\nhand-painted red hearts, faces significant conservation challenges due to the\nrapid fading of the paint. This study evaluates the transition to a\nbetter-quality paint and its implications for the wall's long-term\npreservation. The rapid fading of the initial materials required an\nunsustainable repainting rate, burdening volunteers. Lifetime simulations based\non a collections demography framework suggest that repainting efforts must\ncontinue at a rate of some hundreds of hearts per week to maintain a stable\npercentage of hearts in good condition. This finding highlights the need for a\nsustainable management strategy that includes regular maintenance or further\nreduction of the fading rate.\n  Methodologically, this study demonstrates the feasibility of using a\ncollections demography approach, supported by citizen science and social media\ndata, to inform heritage management decisions. An agent-based simulation is\nused to propagate the multiple uncertainties measured. The methodology provides\na robust basis for modeling and decision-making, even in a case like this,\nwhere reliance on publicly available images and volunteer-collected data\nintroduces variability. Future studies could improve data within a citizen\nscience framework by inviting public submissions, using on-site calibration\ncharts, and increasing volunteer involvement for longitudinal data collection.\nThis research illustrates the flexibility of the collections demography\nframework, firstly by showing its applicability to an outdoor monument, which\nis very different from the published case studies, and secondly by\ndemonstrating how it can work even with low-quality data.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-15T13:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.11205v1","title":"Can Quasi Periodic Oscillations Encode Traces of Black Hole Phase\n  Transitions ?","summary":"Finding observational evidence or imprints of black hole phase transitions is\na promising and active area of research. Aiming to contribute to this\ndirection, in this work, we probe the well-known thermodynamic phase structure\nof the Reissner Nordstr\\\"om Anti de Sitter (RN-AdS) black hole through the lens\nof its quasi-periodic oscillations (QPOs). Can QPOs be influenced by black hole\nphase transitions? Do they carry any signature of such transitions in their\nobservational patterns? These were the central questions guiding our study. By\nanalyzing the upper and lower QPO frequencies within the Relativistic\nPrecession (RP) model, we observe that the frequency-temperature relationship\nreflects distinguishing features corresponding to the small, intermediate, and\nlarge black hole phases, offering insights into their stability properties. The\nanalysis is further extended to other QPO models, including the Warped Disk\n(WD) and Epicyclic Resonance (ER) models. The presence of distinct phase\nstructures remains evident across all models which is an encouraging outcome\nthat may be worth exploring further in the context of other black hole systems.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T14:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.11259v1","title":"The Cambridge Report on Database Research","summary":"On October 19 and 20, 2023, the authors of this report convened in Cambridge,\nMA, to discuss the state of the database research field, its recent\naccomplishments and ongoing challenges, and future directions for research and\ncommunity engagement. This gathering continues a long standing tradition in the\ndatabase community, dating back to the late 1980s, in which researchers meet\nroughly every five years to produce a forward looking report.\n  This report summarizes the key takeaways from our discussions. We begin with\na retrospective on the academic, open source, and commercial successes of the\ncommunity over the past five years. We then turn to future opportunities, with\na focus on core data systems, particularly in the context of cloud computing\nand emerging hardware, as well as on the growing impact of data science, data\ngovernance, and generative AI.\n  This document is not intended as an exhaustive survey of all technical\nchallenges or industry innovations in the field. Rather, it reflects the\nperspectives of senior community members on the most pressing challenges and\npromising opportunities ahead.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.11262v1","title":"Enhanced Small Target Detection via Multi-Modal Fusion and Attention\n  Mechanisms: A YOLOv5 Approach","summary":"With the rapid development of information technology, modern warfare\nincreasingly relies on intelligence, making small target detection critical in\nmilitary applications. The growing demand for efficient, real-time detection\nhas created challenges in identifying small targets in complex environments due\nto interference. To address this, we propose a small target detection method\nbased on multi-modal image fusion and attention mechanisms. This method\nleverages YOLOv5, integrating infrared and visible light data along with a\nconvolutional attention module to enhance detection performance. The process\nbegins with multi-modal dataset registration using feature point matching,\nensuring accurate network training. By combining infrared and visible light\nfeatures with attention mechanisms, the model improves detection accuracy and\nrobustness. Experimental results on anti-UAV and Visdrone datasets demonstrate\nthe effectiveness and practicality of our approach, achieving superior\ndetection results for small and dim targets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.11274v1","title":"Isomeric yield ratios and mass spectrometry of Y and Nb isotopes in the\n  neutron-rich N=60 region: the unusual case of $^{98}$Y","summary":"The isomeric yield ratio (IYR) of fission products is an observable that\ncarries relevant information about the fragments emerging from the scission of\na fissioning nucleus. We report on IYR of $^{96,98,100}$Y and $^{100,102}$Nb,\ntogether with the previously reported values for $^{97}$Y and $^{99}$Nb,\nproduced in the 28 MeV $\\alpha$-induced fission of $^{232}$Th at the Ion Guide\nIsotope Separation On-Line (IGISOL) facility of the University of\nJyv{\\\"a}skyl{\\\"a}. We measured the IYR using two different techniques, the\nphase-imaging ion-cyclotron-resonance (PI-ICR) and the multiple-reflection\ntime-of-flight mass spectrometry (MR-TOF-MS) methods. Moreover, we measured the\nmasses of the long-lived isomeric states in $^{98,100}$Y and $^{100,102}$Nb\npopulated via in-trap $\\beta$-decay of their precursors. Since the\n$\\beta$-decay selectively populates states with a favourable spin-parity, we\ncould identify the measured state and show that in all cases except $^{102}$Nb\nthe ground state is the low-spin state. This measurement confirms the\nspin-parity assignments of all the nuclei as they are reported on the ENSDF\nevaluations, disagreeing with the assignment for $^{100}$Y reported on the\nNUBASE2020 evaluation.\n  Making also use of previously reported data, we observe an anomalously low\nIYR for the $N=59$ isotope $^{98}$Y as compared to other yttrium or neighboring\nniobium isotopes. This behavior is very rare across the nuclear chart and is\nposited to be connected to the characteristic shape coexistence of $^{98}$Y and\nto the change in the charge radii of the ground and excited states in the\n$N=58-60$ region.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-15T15:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.11283v1","title":"Influence of the magnetic activity cycle on mean density and acoustic\n  radius inversions","summary":"Asteroseismic modelling is crucial for upcoming missions like PLATO,\nCubeSpec, and Roman. Despite significant progress, discrepancies between\nobservations and theoretical predictions introduce biases in stellar\ncharacterisation at the precision required by PLATO. Current models typically\nignore magnetic activity, assuming its effects are hidden within surface\neffects. However, recent studies have shown significant impacts of magnetic\nactivity on the Sun's asteroseismic characterisation using forward modelling.\nUsing GOLF and BiSON observations of two full solar activity cycles, we\nquantified the impact of magnetic activity on solar mean density and acoustic\nradius inversions. Observations were segmented into yearly overlapping\nsnapshots, each offset by 91.25 days. Inversions were performed for each\nsnapshot to determine mean density and acoustic radius, tracking their temporal\nevolution and estimating systematic uncertainty due to magnetic activity. We\nobserved a clear imprint of the magnetic activity cycle on solar mean density\nand acoustic radius through helioseismic inversions, consistent across GOLF and\nBiSON datasets. This imprint is the largest source of systematic uncertainty in\nsolar asteroseismic characterisation. Including low radial-order modes\nmitigates these effects more significantly than previously measured for other\nstellar variables. We recommend asteroseismic values for solar mean density\n(1.4104 \\pm 0.0051 g/cm3) and acoustic radius (3722.0 \\pm 4.1 s), averaged over\ntwo activity cycles. These values account for major systematic errors,\nachieving high precision (0.36% for mean density and 0.11% for acoustic\nradius). These results are promising for high-precision characterisation of\nSun-like stars, a better-constrained mean density being able to enhance the\nprecision of stellar radius estimate, which is crucial for exoplanetary system\ncharacterisation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-15T15:22:51Z"}
{"aid":"http://arxiv.org/abs/2504.11299v1","title":"Efficient and Stable Multi-Dimensional Kolmogorov-Smirnov Distance","summary":"We revisit extending the Kolmogorov-Smirnov distance between probability\ndistributions to the multidimensional setting and make new arguments about the\nproper way to approach this generalization. Our proposed formulation maximizes\nthe difference over orthogonal dominating rectangular ranges (d-sided\nrectangles in R^d), and is an integral probability metric. We also prove that\nthe distance between a distribution and a sample from the distribution\nconverges to 0 as the sample size grows, and bound this rate. Moreover, we show\nthat one can, up to this same approximation error, compute the distance\nefficiently in 4 or fewer dimensions; specifically the runtime is near-linear\nin the size of the sample needed for that error. With this, we derive a\ndelta-precision two-sample hypothesis test using this distance. Finally, we\nshow these metric and approximation properties do not hold for other popular\nvariants.","main_category":"stat.CO","categories":"stat.CO,cs.CG,cs.LG","published":"2025-04-15T15:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.11315v1","title":"New Key Rate Bound for High-Dimensional BB84 with Multiple Basis\n  Measurements","summary":"In this paper we derive a new bound on the secret key-rate of the High\nDimensional BB84 protocol operating with multiple mutually unbiased bases\n(MUBs). To our knowledge, our proof is the first for this protocol that is both\ngeneral (in that it can handle arbitrary, asymmetric channels), and also the\nfirst that derives a bound on the quantum min entropy for general attacks,\nwithout relying on post selection techniques or the asymptotic equipartition\nproperty. Because of this, our new result shows that far more optimistic\nkey-rates are possible for a low number of signals, even in general channels.\nFurthermore, our proof methods may be broadly applicable to other protocols\nrelying on multiple measurement bases and we prove several technical lemmas\nthat may have independent interest. We evaluate our new bound and compare to\nprior work, showing that higher key-rates are possible in several operating\nscenarios. We also show some interesting behavior of the protocol when faced\nwith asymmetric noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.11317v1","title":"The role of non-Markovian dissipation in quantum phase transitions:\n  tricriticality, spin squeezing, and directional symmetry breaking","summary":"Understanding how to control phase transitions in quantum systems is at the\nforefront of research for the development of new quantum materials and\ntechnologies. Here, we study how the coupling of a quantum system to a\nnon-Markovian environment, i.e., an environment with a frequency-dependent\nspectral density inducing memory effects, can be used to generate and reshape\nphase transitions and squeezing in matter phases. Focusing on a\nLipkin-Meshkov-Glick model, we demonstrate that non-Markovian dissipation can\nbe leveraged to engineer tricriticality via the fusion of\n$2^{\\mathrm{nd}}$-order and $1^{\\mathrm{st}}$-order critical points. We\nidentify phases that arise from different ways of breaking the single weak\nsymmetry of our model, which led us to introduce the concept of\n\\textit{directional spontaneous symmetry breaking} (DSSB) as a general\nframework to understand this phenomenon. We show that signatures of DSSB can be\nseen in the emergence of spin squeezing along different directions, and that\nthe latter is controllable via non-Markovian effects, opening up possibilities\nfor applications in quantum metrology. Finally, we propose an experimental\nimplementation of our non-Markovian model in cavity QED. Our work features\nnon-Markovianity as a resource for controlling phase transitions in general\nsystems, and highlights shortcomings of the Markovian limit in this context.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.11318v1","title":"Mildly-Interacting Fermionic Unitaries are Efficiently Learnable","summary":"Recent work has shown that one can efficiently learn fermionic Gaussian\nunitaries, also commonly known as nearest-neighbor matchcircuits or\nnon-interacting fermionic unitaries. However, one could ask a similar question\nabout unitaries that are near Gaussian: for example, unitaries prepared with a\nsmall number of non-Gaussian circuit elements. These operators find\nsignificance in quantum chemistry and many-body physics, yet no algorithm\nexists to learn them.\n  We give the first such result by devising an algorithm which makes queries to\na $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates\nand returns a circuit approximating $U$ to diamond distance $\\varepsilon$ in\ntime $\\textrm{poly}(n,2^t,1/\\varepsilon)$. This resolves a central open\nquestion of Mele and Herasymenko under the strongest distance metric. In fact,\nour algorithm is much more general: we define a property of unitary Gaussianity\nknown as unitary Gaussian dimension and show that our algorithm can learn\n$n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time\n$\\textrm{poly}(n,2^t,1/\\varepsilon)$. Indeed, this class subsumes unitaries\nprepared by at most $O(t)$ non-Gaussian gates but also includes several\nunitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.\n  In addition, we give a $\\textrm{poly}(n,1/\\varepsilon)$-time algorithm to\ndistinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$\nor $\\varepsilon$-far from all such unitaries in Frobenius distance, promised\nthat one is the case. Along the way, we prove structural results about\nnear-Gaussian fermionic unitaries that are likely to be of independent\ninterest.","main_category":"quant-ph","categories":"quant-ph,cs.DS,cs.LG","published":"2025-04-15T15:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.11323v1","title":"Domain wall evolution beyond quartic potentials: The Sine-Gordon and\n  Christ-Lee potentials","summary":"Domain walls are the simplest type of topological defects formed at\ncosmological phase transitions, and one of the most constrained. Their studies\ntypically assume a quartic double well potential, but this model is not fully\nrepresentative of the range of known or plausible particle physics models. Here\nwe study the cosmological evolution of domain walls in two other classes of\npotentials. The Sine-Gordon potential allows several types of walls,\ninterpolating between different pairs of minima (which demands specific\nnumerical algorithms to separately measure the relevant properties of each\ntype). The Christ-Lee potential parametrically interpolates between sextic and\nquartic behavior. We use multiple sets of simulations in two and three spatial\ndimensions, for various cosmological epochs and under various choices of\ninitial conditions, to discuss the scaling properties of these networks. In the\nSine-Gordon case, we identify and quantify deviations from the usual scaling\nbehavior. In the Christ-Lee case, we discuss conditions under which walls form\n(or not), and quantify how these outcomes depend on parameters such as the\nenergy difference between the false and true vacua and the expansion rate of\nthe Universe. Various biased initial conditions are also addressed in\nappendices. Finally, we briefly comment on the possible cosmological\nimplications of our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-15T16:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.11338v1","title":"Transformer-Based Model for Cold Start Mitigation in FaaS Architecture","summary":"Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-15T16:12:07Z"}
{"aid":"http://arxiv.org/abs/2504.11354v1","title":"Kimina-Prover Preview: Towards Large Formal Reasoning Models with\n  Reinforcement Learning","summary":"We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T16:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11357v1","title":"NNLO predictions with nonlocal subtractions and fiducial power\n  corrections in GENEVA","summary":"We present the implementation of next-to-next-to-leading order (NNLO) QCD\nfully-differential corrections within the GENEVA framework, for both\ncolour-singlet and colour-singlet+jet processes at hadron colliders, by\nemploying a nonlocal subtraction approach. In particular, we discuss the\nimplementation details and the challenges that arise when utilizing a dynamical\ninfrared cutoff parameter. Additionally, we combine the subtraction with the\nprojection-to-Born method in order to include fiducial power corrections. As a\ntest case, we provide predictions for Drell-Yan and $Z$+jet production at the\nLHC, using $N$-jettiness as resolution variable. We validate the NNLO\ncorrections of GENEVA against NNLOJET finding excellent agreement. Finally, we\ndiscuss how to extend our method to calculate the N$^3$LO QCD\nfully-differential corrections to colour-singlet production at hadron\ncolliders.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T16:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.11367v1","title":"Network Alignment","summary":"Complex networks are frequently employed to model physical or virtual complex\nsystems. When certain entities exist across multiple systems simultaneously,\nunveiling their corresponding relationships across the networks becomes\ncrucial. This problem, known as network alignment, holds significant\nimportance. It enhances our understanding of complex system structures and\nbehaviours, facilitates the validation and extension of theoretical physics\nresearch about studying complex systems, and fosters diverse practical\napplications across various fields. However, due to variations in the\nstructure, characteristics, and properties of complex networks across different\nfields, the study of network alignment is often isolated within each domain,\nwith even the terminologies and concepts lacking uniformity. This review\ncomprehensively summarizes the latest advancements in network alignment\nresearch, focusing on analyzing network alignment characteristics and progress\nin various domains such as social network analysis, bioinformatics,\ncomputational linguistics and privacy protection. It provides a detailed\nanalysis of various methods' implementation principles, processes, and\nperformance differences, including structure consistency-based methods, network\nembedding-based methods, and graph neural network-based (GNN-based) methods.\nAdditionally, the methods for network alignment under different conditions,\nsuch as in attributed networks, heterogeneous networks, directed networks, and\ndynamic networks, are presented. Furthermore, the challenges and the open\nissues for future studies are also discussed.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.CL","published":"2025-04-15T16:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.11374v1","title":"A Winner-Takes-All Mechanism for Event Generation","summary":"We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.11388v1","title":"Local solubility in generalised ChÃ¢telet varieties","summary":"We develop asymptotic formulas, via the circle method, for averages of\nmultivariate equidistributed arithmetic functions evaluated at polynomial\nvalues in many variables.\n  As an application, we count fibers with a rational point in families of\nhigh-dimensional Ch\\^atelet varieties.\n  Among the local solutions in these fibrations, we observe a reciprocity\ninvolving infinitely many places, governed by only finitely many ramified\nBrauer elements.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T16:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.11413v1","title":"Solving the Phase Problem of Diffraction: X-ray Standing Waves Imaging\n  on Bismuthene/SiC(0001)","summary":"The phase retrieval problem is a fundamental shortcoming of all\ndiffraction-based methods, arising from the inability to measure the phase of\nscattered waves. The (normal incidence) X-ray standing wave (NIXSW) technique\ncircumvents this issue by introducing a (Bragg-generated) X-ray standing wave\nfield throughout the sample, relative to which any atomic species can be\nlocalized by probing its fluorescence or photoelectron yield. In essence, in a\nsingle measurement the complex scattering factor (i.e., its amplitude\n\\textit{and} phase) corresponding to the used Bragg reflection is determined.\nPerforming this for multiple Bragg reflections enables one to reconstruct the\nscattering density of the sample in three dimensions, straightforwardly as the\nFourier sum of all measured (complex) scattering factors. Here, we utilize this\ntechnique to reveal the structural key features involved in the formation of\nthe quantum spin Hall insulator bismuthene on silicon carbide. In this\nprominent example, the two-dimensional Bi layer is confined between a 4H-SiC\nsubstrate crystal and an epitaxial graphene layer. The key finding is a change\nin the adsorption site of the Bi atoms underneath the graphene upon\nhydrogenation, caused by the H-saturation of one (out of three) Si dangling\nbonds per unit cell. This structural change, clearly revealed by our NIXSW\nimaging experiment, is the key feature leading to the formation of the\ncharacteristic band structure of the 2D bismuthene honeycomb.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-15T17:28:24Z"}
{"aid":"http://arxiv.org/abs/2504.11423v1","title":"ADT: Tuning Diffusion Models with Adversarial Supervision","summary":"Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:37:50Z"}
{"aid":"http://arxiv.org/abs/2504.11429v1","title":"Improving Statistical Privacy by Subsampling","summary":"Differential privacy (DP) considers a scenario, where an adversary has almost\ncomplete information about the entries of a database This worst-case assumption\nis likely to overestimate the privacy thread for an individual in real life.\nStatistical privacy (SP) denotes a setting where only the distribution of the\ndatabase entries is known to an adversary, but not their exact values. In this\ncase one has to analyze the interaction between noiseless privacy based on the\nentropy of distributions and privacy mechanisms that distort the answers of\nqueries, which can be quite complex.\n  A privacy mechanism often used is to take samples of the data for answering a\nquery. This paper proves precise bounds how much different methods of sampling\nincrease privacy in the statistical setting with respect to database size and\nsampling rate. They allow us to deduce when and how much sampling provides an\nimprovement and how far this depends on the privacy parameter {\\epsilon}. To\nperform these investigations we develop a framework to model sampling\ntechniques.\n  For the DP setting tradeoff functions have been proposed as a finer measure\nfor privacy compared to ({\\epsilon},{\\delta})-pairs. We apply these tools to\nstatistical privacy with subsampling to get a comparable characterization","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T17:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.11437v1","title":"Ghostly interactions in (1+1) dimensional classical field theory","summary":"We investigate the classical stability of two coupled scalar fields with\nopposite-sign kinetic terms evolving in 1+1 dimensional Minkowski spacetime. In\nthe first part, we characterise unquenched ghostly interactions and present\nnumerical solutions that support the following statements. First, the classical\ninstability is not instantaneous and can even be benign, i.e., free of\nfinite-time singularities. Second, while the classical instability can cascade\ntowards higher frequency excitations, it is not driven by high frequency modes:\nAt fixed amplitude, high-frequency modes are more stable than low-frequency\nmodes. In the second part, we demonstrate that the classical instability can be\nquenched by mass terms. In particular, we exemplify that heavy high-frequency\nghost fields seem to not violate the decoupling theorem and can be integrated\nout classically. In the third part, we demonstrate how self-interactions can\nquench the instability, for instance, by postponing its onset to parametrically\nlarge times. Extrapolating numerical results at large but finite evolution time\nto infinite evolution time, we demonstrate that classical fluctuations around\ntrivial and nontrivial field-theory vacua are increasingly long-lived with (i)\nsmaller initial amplitude of fluctuations, (ii) higher initial frequency of\nfluctuations, (iii) larger masses of the fields, or (iv) weaker interaction\ncoupling. Moreover, our numerical simulations for field-theoretical\ngeneralisations of some globally-stable ghostly mechanical models do not\nfeature any instability.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.11449v1","title":"SymTFT construction of gapless exotic-foliated dual models","summary":"We construct Symmetry Topological Field Theories (SymTFTs) for continuous\nsubsystem symmetries, which are inherently non-Lorentz-invariant. Our framework\nproduces dual bulk descriptions -- gapped foliated and exotic SymTFTs -- that\ngenerates gapless boundary theories with spontaneous subsystem symmetry\nbreaking via interval compactification. In analogy with the sandwich\nconstruction of SymTFT, we call this Mille-feuille. This is done by specifying\ngapped and symmetry-breaking boundary conditions. In this way we obtain the\nfoliated dual realizations of various models, including the XY plaquette, XYZ\ncube, and $\\phi$, $\\hat{\\phi}$ theories. This also captures self-duality\nsymmetries as condensation defects and provides a systematic method for\ngenerating free theories that non-linearly realize subsystem symmetries.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th","published":"2025-04-15T17:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.11775v1","title":"Discrimination-free Insurance Pricing with Privatized Sensitive\n  Attributes","summary":"Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.","main_category":"stat.ML","categories":"stat.ML,cs.CY,cs.LG,q-fin.RM","published":"2025-04-16T05:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11784v1","title":"DALC: Distributed Arithmetic Coding Aided by Linear Codes","summary":"Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the\nSlepian-Wolf problem, particularly in scenarios with non-stationary sources and\nfor data sequences with lengths ranging from small to medium. Due to the\ninherent decoding ambiguity in DAC, the number of candidate paths grows\nexponentially with the increase in source length. To select the correct\ndecoding path from the set of candidates, DAC decoders utilize the Maximum A\nPosteriori (MAP) metric to rank the decoding sequences, outputting the path\nwith the highest MAP metric as the decoding result of the decoder. However,\nthis method may still inadvertently output incorrect paths that have a MAP\nmetric higher than the correct decoding path, despite not being the correct\ndecoding path. To address the issue, we propose Distributed Arithmetic Coding\nAided by Linear Codes (DALC), which employs linear codes to constrain the\ndecoding process, thereby eliminating some incorrect paths and preserving the\ncorrect one. During the encoding phase, DALC generates the parity bits of the\nlinear code for encoding the source data. In the decoding phase, each path in\nthe set of candidate paths is verified in descending order according to the MAP\nmetric until a path that meets the verification criteria is encountered, which\nis then outputted as the decoding result. DALC enhances the decoding\nperformance of DAC by excluding candidate paths that do not meet the\nconstraints imposed by linear codes. Our experimental results demonstrate that\nDALC reduces the Bit Error Rate(BER), with especially improvements in skewed\nsource data scenarios.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.11785v1","title":"Ground state and multiple normalized solutions of quasilinear\n  SchrÃ¶dinger equations in the $L^2$-supercritical case and the Sobolev\n  critical case","summary":"This paper is devoted to studying the existence of normalized solutions for\nthe following quasilinear Schr\\\"odinger equation \\begin{equation*}\n\\begin{aligned}\n  -\\Delta u-u\\Delta u^2 +\\lambda u=|u|^{p-2}u \\quad\\mathrm{in}\\ \\mathbb{R}^{N},\n\\end{aligned} \\end{equation*} where $N=3,4$, $\\lambda$ appears as a Lagrange\nmultiplier and $p \\in (4+\\frac{4}{N},2\\cdot2^*]$. The solutions correspond to\ncritical points of the energy functional subject to the $L^2$-norm constraint\n$\\int_{\\mathbb{R}^N}|u|^2dx=a^2>0$. In the Sobolev critical case $p=2\\cdot\n2^*$, the energy functional has no critical point. As for $L^2$-supercritical\ncase $p \\in (4+\\frac{4}{N},2\\cdot2^*)$: on the one hand, taking into account\nPohozaev manifold and perturbation method, we obtain the existence of ground\nstate normalized solutions for the non-radial case; on the other hand, we get\nthe existence of infinitely many normalized solutions in $H^1_r(\\mathbb{R}^N)$.\nMoreover, our results cover several relevant existing results. And in the end,\nwe get the asymptotic properties of energy as $a$ tends to $+\\infty$ and $a$\ntends to $0^+$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T05:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11792v1","title":"Large Language Models for Drug Overdose Prediction from Longitudinal\n  Medical Records","summary":"The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-16T05:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.11802v1","title":"On the photon energy conservation in stimulated emission. Experiment","summary":"Quantum electrodynamics predicts identity of incident and emitted photons in\nstimulated emission. This fundamental law is important to test experimentally.\nIn this work stimulated emission in GaAs semiconductor amplifier was\ninvestigated and positive frequency shift of the amplified beam was detected.\nIn relative units this frequency shift was found equal $\\Delta\\nu/\\nu = (+1.7\n\\pm 0.2)\\cdot10^{-18}$. This indicates violation of the photon energy\nconservation in stimulated emission.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-16T06:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.11815v1","title":"On projection mappings and the gradient projection method on hyperbolic\n  space forms","summary":"This paper presents several new properties of the intrinsic\n$\\kappa$-projection into $\\kappa$-hyperbolically convex sets of\n$\\kappa$-hyperbolic space forms, along with closed-form formulas for the\nintrinsic $\\kappa$-projection into specific $\\kappa$-hyperbolically convex\nsets. It also discusses the relationship between the intrinsic\n$\\kappa$-projection, the Euclidean orthogonal projection, and the Lorentz\nprojection. These properties lay the groundwork for analyzing the gradient\nprojection method and hold importance in their own right. Additionally, new\nproperties of the gradient projection method to solve constrained optimization\nproblems in $\\kappa$-hyperbolic space forms are established, considering both\nconstant and backtracking step sizes in the analysis. It is shown that every\naccumulation point of the sequence generated by the method for both step sizes\nis a stationary point for the given problem. Additionally, an iteration\ncomplexity bound is provided that upper bounds the number of iterations needed\nto achieve a suitable measure of stationarity for both step sizes. Finally, the\nproperties of the constrained Fermat-Weber problem are explored, demonstrating\nthat the sequence generated by the gradient projection method converges to its\nunique solution. Numerical experiments on solving the Fermat-Weber problem are\npresented, illustrating the theoretical findings and demonstrating the\neffectiveness of the proposed methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.DG,math.NA","published":"2025-04-16T07:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.11823v1","title":"Multi-goal Rapidly Exploring Random Tree with Safety and Dynamic\n  Constraints for UAV Cooperative Path Planning","summary":"Cooperative path planning is gaining its importance due to the increasing\ndemand on using multiple unmanned aerial vehicles (UAVs) for complex missions.\nThis work addresses the problem by introducing a new algorithm named MultiRRT\nthat extends the rapidly exploring random tree (RRT) to generate paths for a\ngroup of UAVs to reach multiple goal locations at the same time. We first\nderive the dynamics constraint of the UAV and include it in the problem\nformulation. MultiRRT is then developed, taking into account the cooperative\nrequirements and safe constraints during its path-searching process. The\nalgorithm features two new mechanisms, node reduction and Bezier interpolation,\nto ensure the feasibility and optimality of the paths generated. Importantly,\nthe interpolated paths are proven to meet the safety and dynamics constraints\nimposed by obstacles and the UAVs. A number of simulations, comparisons, and\nexperiments have been conducted to evaluate the performance of the proposed\napproach. The results show that MultiRRT can generate collision-free paths for\nmultiple UAVs to reach their goals with better scores in path length and\nsmoothness metrics than state-of-the-art RRT variants including Theta-RRT,\nFN-RRT, RRT*, and RRT*-Smart. The generated paths are also tested in practical\nflights with real UAVs to evaluate their validity for cooperative tasks. The\nsource code of the algorithm is available at\nhttps://github.com/duynamrcv/multi-target_RRT","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T07:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.11834v1","title":"Estimation and inference in error-in-operator model","summary":"Many statistical problems can be reduced to a linear inverse problem in which\nonly a noisy version of the operator is available. Particular examples include\nrandom design regression, deconvolution problem, instrumental variable\nregression, functional data analysis, error-in-variable regression, drift\nestimation in stochastic diffusion, and many others. The pragmatic plug-in\napproach can be well justified in the classical asymptotic setup with a growing\nsample size. However, recent developments in high dimensional inference reveal\nsome new features of this problem. In high dimensional linear regression with a\nrandom design, the plug-in approach is questionable but the use of a simple\nridge penalization yields a benign overfitting phenomenon; see\n\\cite{baLoLu2020}, \\cite{ChMo2022}, \\cite{NoPuSp2024}. This paper revisits the\ngeneral Error-in-Operator problem for finite samples and high dimension of the\nsource and image spaces. A particular focus is on the choice of a proper\nregularization. We show that a simple ridge penalty (Tikhonov regularization)\nworks properly in the case when the operator is more regular than the signal.\nIn the opposite case, some model reduction technique like spectral truncation\nshould be applied.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-16T07:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.11859v1","title":"Meta Theorem for Hardness on FCP-Problem","summary":"The Fewest Clues Problem (FCP) framework has been introduced to study the\ncomplexity of determining whether a solution to an \\NP~problem can be uniquely\nidentified by specifying a subset of the certificate. For a given problem $P\n\\in \\NP$, its FCP variant is denoted by FCP-$P$. While several \\NP-complete\nproblems have been shown to have $\\Sigma_2^\\p$-complete FCP variants, it\nremains open whether this holds for all \\NP-complete problems.\n  In this work, we propose a meta-theorem that establishes the\n$\\Sigma_2^\\p$-completeness of FCP-$P$ under the condition that the \\NP-hardness\nof $P$ is proven via a polynomial-time reduction satisfying certain structural\nproperties. Furthermore, we apply the meta-theorem to demonstrate the\n$\\Sigma_2^\\p$-completeness of the FCP variants of several \\NP-complete\nproblems.","main_category":"cs.CC","categories":"cs.CC,F.1.3","published":"2025-04-16T08:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.11869v1","title":"Recovering the CMB signal with neural networks","summary":"Component separation is the process of extracting one or more emission\nsources in astrophysical maps. It is therefore crucial to develop models that\ncan accurately clean the cosmic microwave background (CMB) in current and\nfuture experiments. In this work, we present a new methodology based on neural\nnetworks which operates on realistic temperature and polarization simulations.\nWe assess its performance by comparing the power spectra of the output maps\nwith those of the input maps and other emissions. For temperature, we obtain\nresiduals of $20 \\pm \\mu K^{2}$. For polarization, we analyze the $E$ and $B$\nmodes, which are related to density (scalar) and primordial gravitational waves\n(tensorial) perturbations occurring in the first second of the Universe,\nobtaining residuals of $10^{-2} \\mu K^{2}$ at $l>200$ and $10^{-2}$ and\n$10^{-3} \\mu K^{2}$ for $E$ and $B$, respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-16T08:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.11882v1","title":"Seeking and leveraging alternative variable dependency concepts in\n  gray-box-elusive bimodal land-use allocation problems","summary":"Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T09:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.11906v1","title":"Testing of tempered fractional Brownian motions","summary":"We propose here a testing methodology based on the autocovariance, detrended\nmoving average, and time-averaged mean-squared displacement statistics for\ntempered fractional Brownian motions (TFBMs) which are related to the notions\nof semi-long range dependence and transient anomalous diffusion. In this\nframework, we consider three types of TFBMs: two with a tempering factor\nincorporated into their moving-average representation, and one with a tempering\nparameter added to the autocorrelation formula. We illustrate their dynamics\nwith the use of quantile lines. Using the proposed methodology, we provide a\ncomprehensive power analysis of the tests. It appears that the tests allow\ndistinguishing between the tempered processes with different Hurst parameters.","main_category":"stat.ME","categories":"stat.ME,physics.data-an","published":"2025-04-16T09:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.11914v1","title":"AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection","summary":"Industrial Anomaly Detection (IAD) poses a formidable challenge due to the\nscarcity of defective samples, making it imperative to deploy models capable of\nrobust generalization to detect unseen anomalies effectively. Traditional\napproaches, often constrained by hand-crafted features or domain-specific\nexpert models, struggle to address this limitation, underscoring the need for a\nparadigm shift. We introduce AnomalyR1, a pioneering framework that leverages\nVLM-R1, a Multimodal Large Language Model (MLLM) renowned for its exceptional\ngeneralization and interpretability, to revolutionize IAD. By integrating MLLM\nwith Group Relative Policy Optimization (GRPO), enhanced by our novel Reasoned\nOutcome Alignment Metric (ROAM), AnomalyR1 achieves a fully end-to-end solution\nthat autonomously processes inputs of image and domain knowledge, reasons\nthrough analysis, and generates precise anomaly localizations and masks. Based\non the latest multimodal IAD benchmark, our compact 3-billion-parameter model\noutperforms existing methods, establishing state-of-the-art results. As MLLM\ncapabilities continue to advance, this study is the first to deliver an\nend-to-end VLM-based IAD solution that demonstrates the transformative\npotential of ROAM-enhanced GRPO, positioning our framework as a forward-looking\ncornerstone for next-generation intelligent anomaly detection systems in\nindustrial applications with limited defective data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.11936v1","title":"Mind2Matter: Creating 3D Models from EEG Signals","summary":"The reconstruction of 3D objects from brain signals has gained significant\nattention in brain-computer interface (BCI) research. Current research\npredominantly utilizes functional magnetic resonance imaging (fMRI) for 3D\nreconstruction tasks due to its excellent spatial resolution. Nevertheless, the\nclinical utility of fMRI is limited by its prohibitive costs and inability to\nsupport real-time operations. In comparison, electroencephalography (EEG)\npresents distinct advantages as an affordable, non-invasive, and mobile\nsolution for real-time brain-computer interaction systems. While recent\nadvances in deep learning have enabled remarkable progress in image generation\nfrom neural data, decoding EEG signals into structured 3D representations\nremains largely unexplored. In this paper, we propose a novel framework that\ntranslates EEG recordings into 3D object reconstructions by leveraging neural\ndecoding techniques and generative models. Our approach involves training an\nEEG encoder to extract spatiotemporal visual features, fine-tuning a large\nlanguage model to interpret these features into descriptive multimodal outputs,\nand leveraging generative 3D Gaussians with layout-guided control to synthesize\nthe final 3D structures. Experiments demonstrate that our model captures\nsalient geometric and semantic features, paving the way for applications in\nbrain-computer interfaces (BCIs), virtual reality, and neuroprosthetics.Our\ncode is available in https://github.com/sddwwww/Mind2Matter.","main_category":"cs.GR","categories":"cs.GR,cs.HC,eess.SP","published":"2025-04-16T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2504.11944v1","title":"VIPO: Value Function Inconsistency Penalized Offline Reinforcement\n  Learning","summary":"Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T10:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11974v1","title":"Who Said Only Military Officers Can Deal with Uncertainty? On the\n  Importance of Uncertainty in EdTech Data Visualisations","summary":"AI-powered predictive systems have high margins of error. However, data\nvisualisations of algorithmic systems in education and other social fields tend\nto visualise certainty, thus invisibilising the underlying approximations and\nuncertainties of the algorithmic systems and the social settings in which these\nsystems operate. This paper draws on a critical speculative approach to first\nanalyse data visualisations from predictive analytics platforms for education.\nIt demonstrates that visualisations of uncertainty in education are rare.\nSecond, the paper explores uncertainty visualisations in other fields (defence,\nclimate change and healthcare). The paper concludes by reflecting on the role\nof data visualisations and un/certainty in shaping educational futures. It also\nidentifies practical implications for the design of data visualisations in\neducation.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-16T11:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.11977v1","title":"Leveraging Machine Learning Models to Predict the Outcome of Digital\n  Medical Triage Interviews","summary":"Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T11:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.11988v1","title":"Strong Convergence Rates for Euler Schemes of Levy-Driven SDE using\n  Dynamic Cutting","summary":"We derive strong Lp convergence rates for the Euler-Maruyama schemes of\nLevy-driven SDE using a new dynamic cutting (DC) method with a time-dependent\njump threshold. In addition, we present results from numerical simulations\ncomparing the DC and Asmussen-Rosinski (AR) approaches. These simulations\ndemonstrate the superior accuracy achieved by the DC method.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-16T11:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.12000v1","title":"Control of Rayleigh-BÃ©nard Convection: Effectiveness of Reinforcement\n  Learning in the Turbulent Regime","summary":"Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-16T11:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.12006v1","title":"Comment on Path integral measure and RG equations for gravity","summary":"Asymptotic safety is a candidate for a predictive quantum theory of gravity\nand matter. Recent works (arXiv:2412.10194 and arXiv:2412.14108) challenged\nthis scenario. We show that their arguments fail on a basic level.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T12:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.12040v1","title":"No equivalence between hydrodynamic and dispersive mass of the charged\n  polaron","summary":"We consider the problem of a charged impurity exerting a weak, slowly\ndecaying force on its surroundings, treating the latter as an ideal\ncompressible fluid. In the semiclassical approximation, the ion is described by\nthe Newton equation coupled to the Euler equation for the medium. After\nlinearization, we obtain a simple closed formula for the effective mass of the\nimpurity, depending on the interaction potential, the mean medium density, and\nsound velocity. Thus, once the interaction and the equation of state of the\nfluid is known, an estimate of the hydrodynamic effective mass can be quickly\nprovided. Going beyond the classical case, we show that replacing the Newton\nwith Schr\\\"{o}dinger equation can drastically change the behavior of the\nimpurity. In particular, the scaling of the Fermi polaron effective mass with\nthe medium density is opposite in quantum and classical scenario. Our results\nare relevant for experimental systems featuring low energy impurities in Fermi\nor Bose systems, such as ions immersed in neutral atomic gases.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.flu-dyn,quant-ph","published":"2025-04-16T12:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.12095v1","title":"The Gray graph is pseudo 2-factor isomorphic","summary":"A graph is pseudo 2-factor isomorphic if all of its 2-factors have the same\nparity of number of cycles. Abreu et al. [J. Comb. Theory, Ser. B. 98 (2008)\n432--442] conjectured that $K_{3,3}$, the Heawood graph and the Pappus graph\nare the only essentially 4-edge-connected pseudo 2-factor isomorphic cubic\nbipartite graphs. This conjecture was disproved by Goedgebeur [Discr. Appl.\nMath. 193 (2015) 57--60] who constructed a counterexample $\\mathcal{G}$ (of\ngirth 6) on 30 vertices. Using a computer search, he also showed that this is\nthe only counterexample up to at least 40 vertices and that there are no\ncounterexamples of girth greater than 6 up to at least 48 vertices.\n  In this manuscript, we show that the Gray graph -- which has 54 vertices and\ngirth 8 -- is also a counterexample to the pseudo 2-factor isomorphic graph\nconjecture. Next to the graph $\\mathcal{G}$, this is the only other known\ncounterexample. Using a computer search, we show that there are no smaller\ncounterexamples of girth 8 and show that there are no other counterexamples up\nto at least 42 vertices of any girth. Moreover, we also verified that there are\nno further counterexamples among the known censuses of symmetrical graphs.\n  Recall that a graph is 2-factor Hamiltonian if all of its 2-factors are\nHamiltonian cycles. As a by-product of the computer searches performed for this\npaper, we have verified that the $2$-factor Hamiltonian conjecture of Funk et\nal. [J. Comb. Theory, Ser. B. 87(1) (2003) 138--144], which is still open,\nholds for cubic bipartite graphs of girth at least 8 up to 52 vertices, and up\nto 42 vertices for any girth.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-16T13:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.12108v1","title":"Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust\n  and Traceable Text Generation","summary":"The rapid development of Large Language Models (LLMs) has intensified\nconcerns about content traceability and potential misuse. Existing watermarking\nschemes for sampled text often face trade-offs between maintaining text quality\nand ensuring robust detection against various attacks. To address these issues,\nwe propose a novel watermarking scheme that improves both detectability and\ntext quality by introducing a cumulative watermark entropy threshold. Our\napproach is compatible with and generalizes existing sampling functions,\nenhancing adaptability. Experimental results across multiple LLMs show that our\nscheme significantly outperforms existing methods, achieving over 80\\%\nimprovements on widely-used datasets, e.g., MATH and GSM8K, while maintaining\nhigh detection accuracy.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T14:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.12113v1","title":"Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting\n  Methods for Clarification Generation","summary":"In information retrieval (IR), providing appropriate clarifications to better\nunderstand users' information needs is crucial for building a proactive\nsearch-oriented dialogue system. Due to the strong in-context learning ability\nof large language models (LLMs), recent studies investigate prompting methods\nto generate clarifications using few-shot or Chain of Thought (CoT) prompts.\nHowever, vanilla CoT prompting does not distinguish the characteristics of\ndifferent information needs, making it difficult to understand how LLMs resolve\nambiguities in user queries. In this work, we focus on the concept of ambiguity\nfor clarification, seeking to model and integrate ambiguities in the\nclarification process. To this end, we comprehensively study the impact of\nprompting schemes based on reasoning and ambiguity for clarification. The idea\nis to enhance the reasoning abilities of LLMs by limiting CoT to predict first\nambiguity types that can be interpreted as instructions to clarify, then\ncorrespondingly generate clarifications. We name this new prompting scheme\nAmbiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various\ndatasets containing human-annotated clarifying questions to compare AT-CoT with\nmultiple baselines. We also perform user simulations to implicitly measure the\nquality of generated clarifications under various IR scenarios.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-16T14:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.12117v1","title":"The $L_p$ Minkowski problems on affine dual quermassintegrals","summary":"In this paper, we provided $L_p$ curvature measures of affine dual\nquermassintegrals for $p\\in\\mathbb{R}$, and solved the existence part of the\n$L_p$ Minkowski problems for the non-symmetric measures when $p>1$ and\nsymmetric measures when $p\\geq0$. When $p=0$, this is the affine dual Minkowski\nproblems, which is introduced and solved by Cai-Leng-Wu-Xi in [7].","main_category":"math.MG","categories":"math.MG","published":"2025-04-16T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12165v1","title":"CodingHomo: Bootstrapping Deep Homography With Video Coding","summary":"Homography estimation is a fundamental task in computer vision with\napplications in diverse fields. Recent advances in deep learning have improved\nhomography estimation, particularly with unsupervised learning approaches,\noffering increased robustness and generalizability. However, accurately\npredicting homography, especially in complex motions, remains a challenge. In\nresponse, this work introduces a novel method leveraging video coding,\nparticularly by harnessing inherent motion vectors (MVs) present in videos. We\npresent CodingHomo, an unsupervised framework for homography estimation. Our\nframework features a Mask-Guided Fusion (MGF) module that identifies and\nutilizes beneficial features among the MVs, thereby enhancing the accuracy of\nhomography prediction. Additionally, the Mask-Guided Homography Estimation\n(MGHE) module is presented for eliminating undesired features in the\ncoarse-to-fine homography refinement process. CodingHomo outperforms existing\nstate-of-the-art unsupervised methods, delivering good robustness and\ngeneralizability. The code and dataset are available at:\n\\href{github}{https://github.com/liuyike422/CodingHomo","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.12170v1","title":"AI Behind Closed Doors: a Primer on The Governance of Internal\n  Deployment","summary":"The most advanced future AI systems will first be deployed inside the\nfrontier AI companies developing them. According to these companies and\nindependent experts, AI systems may reach or even surpass human intelligence\nand capabilities by 2030. Internal deployment is, therefore, a key source of\nbenefits and risks from frontier AI systems. Despite this, the governance of\nthe internal deployment of highly advanced frontier AI systems appears absent.\nThis report aims to address this absence by priming a conversation around the\ngovernance of internal deployment. It presents a conceptualization of internal\ndeployment, learnings from other sectors, reviews of existing legal frameworks\nand their applicability, and illustrative examples of the type of scenarios we\nare most concerned about. Specifically, it discusses the risks correlated to\nthe loss of control via the internal application of a misaligned AI system to\nthe AI research and development pipeline, and unconstrained and undetected\npower concentration behind closed doors. The report culminates with a small\nnumber of targeted recommendations that provide a first blueprint for the\ngovernance of internal deployment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-16T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.12184v1","title":"Feature Selection for Data-driven Explainable Optimization","summary":"Mathematical optimization, although often leading to NP-hard models, is now\ncapable of solving even large-scale instances within reasonable time. However,\nthe primary focus is often placed solely on optimality. This implies that while\nobtained solutions are globally optimal, they are frequently not comprehensible\nto humans, in particular when obtained by black-box routines. In contrast,\nexplainability is a standard requirement for results in Artificial\nIntelligence, but it is rarely considered in optimization yet. There are only a\nfew studies that aim to find solutions that are both of high quality and\nexplainable. In recent work, explainability for optimization was defined in a\ndata-driven manner: a solution is considered explainable if it closely\nresembles solutions that have been used in the past under similar\ncircumstances. To this end, it is crucial to identify a preferably small subset\nof features from a presumably large set that can be used to explain a solution.\nIn mathematical optimization, feature selection has received little attention\nyet. In this work, we formally define the feature selection problem for\nexplainable optimization and prove that its decision version is NP-complete. We\nintroduce mathematical models for optimized feature selection. As their global\nsolution requires significant computation time with modern mixed-integer linear\nsolvers, we employ local heuristics. Our computational study using data that\nreflect real-world scenarios demonstrates that the problem can be solved\npractically efficiently for instances of reasonable size.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:40:03Z"}
{"aid":"http://arxiv.org/abs/2504.12214v1","title":"Bayesian random-effects meta-analysis of aggregate data on clinical\n  events","summary":"To appreciate intervention effects on rare events, meta-analysis techniques\nare commonly applied in order to assess the accumulated evidence. When it comes\nto adverse effects in clinical trials, these are often most adequately handled\nusing survival methods. A common-effect model that is able to process data in\ncommonly quoted formats in terms of hazard ratios has been proposed for this\npurpose by Holzhauer (Stat. Med. 2017; 36(5):723-737). In order to accommodate\npotential heterogeneity between studies, we have extended the model by\nHolzhauer to a random-effects approach. The Bayesian model is described in\ndetail, and applications to realistic data sets are discussed along with\nsensitivity analyses and Monte Carlo simulations to support the conclusions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T16:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.12222v1","title":"Coding-Prior Guided Diffusion Network for Video Deblurring","summary":"While recent video deblurring methods have advanced significantly, they often\noverlook two valuable prior information: (1) motion vectors (MVs) and coding\nresiduals (CRs) from video codecs, which provide efficient inter-frame\nalignment cues, and (2) the rich real-world knowledge embedded in pre-trained\ndiffusion generative models. We present CPGDNet, a novel two-stage framework\nthat effectively leverages both coding priors and generative diffusion priors\nfor high-quality deblurring. First, our coding-prior feature propagation (CPFP)\nmodule utilizes MVs for efficient frame alignment and CRs to generate attention\nmasks, addressing motion inaccuracies and texture variations. Second, a\ncoding-prior controlled generation (CPC) module network integrates coding\npriors into a pretrained diffusion model, guiding it to enhance critical\nregions and synthesize realistic details. Experiments demonstrate our method\nachieves state-of-the-art perceptual quality with up to 30% improvement in IQA\nmetrics. Both the code and the codingprior-augmented dataset will be\nopen-sourced.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T16:14:43Z"}
{"aid":"http://arxiv.org/abs/2504.12251v1","title":"An Evaluation of N-Gram Selection Strategies for Regular Expression\n  Indexing in Contemporary Text Analysis Tasks","summary":"Efficient evaluation of regular expressions (regex, for short) is crucial for\ntext analysis, and n-gram indexes are fundamental to achieving fast regex\nevaluation performance. However, these indexes face scalability challenges\nbecause of the exponential number of possible n-grams that must be indexed.\nMany existing selection strategies, developed decades ago, have not been\nrigorously evaluated on contemporary large-scale workloads and lack\ncomprehensive performance comparisons. Therefore, a unified and comprehensive\nevaluation framework is necessary to compare these methods under the same\nexperimental settings. This paper presents the first systematic evaluation of\nthree representative n-gram selection strategies across five workloads,\nincluding real-time production logs and genomic sequence analysis. We examine\ntheir trade-offs in terms of index construction time, storage overhead, false\npositive rates, and end-to-end query performance. Through empirical results,\nthis study provides a modern perspective on existing n-gram based regular\nexpression evaluation methods, extensive observations, valuable discoveries,\nand an adaptable testing framework to guide future research in this domain. We\nmake our implementations of these methods and our test framework available as\nopen-source at https://github.com/mush-zhang/RegexIndexComparison.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T16:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.12257v1","title":"QSHS: An Axion Dark Matter Resonant Search Apparatus","summary":"We describe a resonant cavity search apparatus for axion dark matter\nconstructed by the Quantum Sensors for the Hidden Sector (QSHS) collaboration.\nThe apparatus is configured to search for QCD axion dark matter, though also\nhas the capability to detect axion-like particles (ALPs), dark photons, and\nsome other forms of wave-like dark matter. Initially, a tuneable cylindrical\noxygen-free copper cavity is read out using a low noise microwave amplifier\nfeeding a heterodyne receiver. The cavity is housed in a dilution refrigerator\nand threaded by a solenoidal magnetic field, nominally 8T. The apparatus also\nhouses a magnetic field shield for housing superconducting electronics, and\nseveral other fixed-frequency resonators for use in testing and commissioning\nvarious prototype quantum electronic devices sensitive at a range of axion\nmasses in the range $\\rm 2.0$ to $\\rm 40\\,eV/c^2$. We present performance data\nfor the resonator, dilution refrigerator, and magnet, and plans for the first\nscience run.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,hep-ex","published":"2025-04-16T17:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.12264v1","title":"Towards Learning to Complete Anything in Lidar","summary":"We propose CAL (Complete Anything in Lidar) for Lidar-based shape-completion\nin-the-wild. This is closely related to Lidar-based semantic/panoptic scene\ncompletion. However, contemporary methods can only complete and recognize\nobjects from a closed vocabulary labeled in existing Lidar datasets. Different\nto that, our zero-shot approach leverages the temporal context from multi-modal\nsensor sequences to mine object shapes and semantic features of observed\nobjects. These are then distilled into a Lidar-only instance-level completion\nand recognition model. Although we only mine partial shape completions, we find\nthat our distilled model learns to infer full object shapes from multiple such\npartial observations across the dataset. We show that our model can be prompted\non standard benchmarks for Semantic and Panoptic Scene Completion, localize\nobjects as (amodal) 3D bounding boxes, and recognize objects beyond fixed class\nvocabularies. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/complete-anything-lidar","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.12275v1","title":"The rank evolution of block bidiagonal matrices over finite fields","summary":"We investigate uniform random block lower bidiagonal matrices over the finite\nfield $\\mathbb{F}_q$, and prove that their rank undergoes a phase transition.\n  First, we consider block lower bidiagonal matrices with $(k_n+1)\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then these matrices have full rank with high probability, and if\n$k_n\\gg q^{n/2}$, then the rank has Gaussian fluctuations.\n  Second, we consider block lower bidiagonal matrices with $k_n\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then the rank exhibits the same constant order fluctuations as the\nrank of the matrix products considered by Nguyen and Van Peski, and if $k_n\\gg\nq^{n/2}$, then the rank has Gaussian fluctuations.\n  Finally, we also consider a truncated version of the first model, where we\nprove that at $k_n\\approx q^{n/2}$, we have a phase transition between a\nCohen-Lenstra and a Gaussian limiting behavior of the rank. We also show that\nthere is a localization/delocalization phase transition for the vectors in the\nkernels of these matrices at the same critical point.\n  In all three cases, we also provide a precise description of the behavior of\nthe rank at criticality.\n  These results are proved by analyzing the limiting behavior of a Markov chain\nobtained from the increments of the ranks of these matrices.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12289v1","title":"A finite Carrollian critical point","summary":"We construct examples of renormalizable Carrollian theories with finite\neffective central charge and non-trivial dynamics. These include critical\npoints that are not scale-invariant but rather exhibit hyperscaling violation.\nAll of our examples are mildly non-Lagrangian, in that they arise from suitable\n$N\\to 0$ limits of Carrollian theories with $N$-component fields, including\nlimits of Carrollian vector models and non-abelian gauge theories. We discuss\nimplications for flat space holography, highlighting challenges in realizing\nCarrollian duals to gravitational theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T17:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.12619v1","title":"SAM-Based Building Change Detection with Distribution-Aware Fourier\n  Adaptation and Edge-Constrained Warping","summary":"Building change detection remains challenging for urban development, disaster\nassessment, and military reconnaissance. While foundation models like Segment\nAnything Model (SAM) show strong segmentation capabilities, SAM is limited in\nthe task of building change detection due to domain gap issues. Existing\nadapter-based fine-tuning approaches face challenges with imbalanced building\ndistribution, resulting in poor detection of subtle changes and inaccurate edge\nextraction. Additionally, bi-temporal misalignment in change detection,\ntypically addressed by optical flow, remains vulnerable to background noises.\nThis affects the detection of building changes and compromises both detection\naccuracy and edge recognition. To tackle these challenges, we propose a new\nSAM-Based Network with Distribution-Aware Fourier Adaptation and\nEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNet\nutilizes the SAM encoder to extract rich visual features from remote sensing\nimages. To guide SAM in focusing on specific ground objects in remote sensing\nscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate\ntask-oriented changed information. This adapter not only effectively addresses\nthe domain gap issue, but also pays attention to the distribution of changed\nbuildings. Furthermore, to mitigate noise interference and misalignment in\nheight offset estimation, we design a novel flow module that refines building\nedge extraction and enhances the perception of changed buildings. Our\nstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets\nhighlight the effectiveness of FAEWNet. The code is available at\nhttps://github.com/SUPERMAN123000/FAEWNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T03:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.12624v1","title":"The (3+1)-dimensional dispersionless integrable hierarchy and nonlinear\n  Riemann-Hilbert problem associated with the Doubrov-Ferapontov modified\n  heavenly equation","summary":"According to the classification of integrable complex Monge-Ampere equations\nby Doubrov and Ferapontov, the modified heavenly equation is a typical\n(3+1)-dimensional dispersionless and canonical integrable equation.In this\npaper we use the eigenfunctions of the Doubrov-Ferapontov modified heavenly\nequation to obtain a related hierarchy. Next we construct the Lax-Sato\nequations with Hamiltonian vector fields and Zakharov-Shabat type equations\nwhich are equivalent to the hierarchy. The nonlinear Riemann-Hilbert problem is\nalso applied to study the solution of Doubrov-Ferapontov modified heavenly\nequation.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-17T03:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12635v1","title":"On Equivalence Between Decentralized Policy-Profile Mixtures and\n  Behavioral Coordination Policies in Multi-Agent Systems","summary":"Constrained decentralized team problem formulations are good models for many\ncooperative multi-agent systems. Constraints necessitate randomization when\nsolving for optimal solutions -- our past results show that joint randomization\namongst the team is necessary for (strong) Lagrangian duality to hold -- , but\na better understanding of randomization still remains. For a partially observed\nmulti-agent system with Borel hidden state and finite observations and actions,\nwe prove the equivalence between joint mixtures of decentralized\npolicy-profiles (both pure and behavioral) and common-information based\nbehavioral coordination policies (also mixtures of them). This generalizes past\nwork that shows equivalence between pure decentralized policy-profiles and pure\ncoordination policies. The equivalence can be exploited to develop results on\nstrong duality and number of randomizations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T04:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.12688v1","title":"Ab initio study of anisotropic effects in two-dimensional Fe$_3$GeTe$_2$\n  using $\\bf{k}$-dependent Green's functions","summary":"In the present work, we develop the Green's function apparatus and extend its\napplicability to the study of microscopic anisotropic effects in real\nconducting materials. The problem of the previously proposed approaches written\nin terms of inter-atomic Green's functions is the presence of a spatial sum\nover all atoms of the crystal, which greatly complicates their application to\nsystems with itinerant electrons. To provide a solution we derived expressions\nfor magnetic torque vector and Dzyaloshinskii-Moriya interactions based on\n$\\bf{k}$-dependent Green's functions, which allow numerical evaluations with\nguaranteed stability of spatial sums over the crystal lattice and moreover with\nmuch lower computational cost. Approbation of the approaches on the case of\nFe$_3$GeTe$_2$ monolayer, which is based on first-principles DFT calculations,\nconfirmed the numerical stability and allowed us to reproduce the\ncharacteristic length of experimentally observed collective spin excitations in\nthe domain structure of this promising conducting material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T06:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.12719v1","title":"B*: Efficient and Optimal Base Placement for Fixed-Base Manipulators","summary":"B* is a novel optimization framework that addresses a critical challenge in\nfixed-base manipulator robotics: optimal base placement. Current methods rely\non pre-computed kinematics databases generated through sampling to search for\nsolutions. However, they face an inherent trade-off between solution optimality\nand computational efficiency when determining sampling resolution. To address\nthese limitations, B* unifies multiple objectives without database dependence.\nThe framework employs a two-layer hierarchical approach. The outer layer\nsystematically manages terminal constraints through progressive tightening,\nparticularly for base mobility, enabling feasible initialization and broad\nsolution exploration. The inner layer addresses non-convexities in each\nouter-layer subproblem through sequential local linearization, converting the\noriginal problem into tractable sequential linear programming (SLP). Testing\nacross multiple robot platforms demonstrates B*'s effectiveness. The framework\nachieves solution optimality five orders of magnitude better than\nsampling-based approaches while maintaining perfect success rates and reduced\ncomputational overhead. Operating directly in configuration space, B* enables\nsimultaneous path planning with customizable optimization criteria. B* serves\nas a crucial initialization tool that bridges the gap between theoretical\nmotion planning and practical deployment, where feasible trajectory existence\nis fundamental.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T07:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.12737v1","title":"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model","summary":"Chinese-Vicuna is an open-source, resource-efficient language model designed\nto bridge the gap in Chinese instruction-following capabilities by fine-tuning\nMeta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting\nlow-resource environments, it enables cost-effective deployment on consumer\nGPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation\nin fields like healthcare and law. By integrating hybrid datasets (BELLE and\nGuanaco) and 4-bit quantization (QLoRA), the model achieves competitive\nperformance in tasks such as translation, code generation, and domain-specific\nQ\\&A. The project provides a comprehensive toolkit for model conversion, CPU\ninference, and multi-turn dialogue interfaces, emphasizing accessibility for\nresearchers and developers. Evaluations indicate competitive performance across\nmedical tasks, multi-turn dialogue coherence, and real-time legal updates.\nChinese-Vicuna's modular design, open-source ecosystem, and community-driven\nenhancements position it as a versatile foundation for Chinese LLM\napplications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T08:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.12739v1","title":"Mask Image Watermarking","summary":"We present MaskMark, a simple, efficient and flexible framework for image\nwatermarking. MaskMark has two variants: MaskMark-D, which supports global\nwatermark embedding, watermark localization, and local watermark extraction for\napplications such as tamper detection, and MaskMark-ED, which focuses on local\nwatermark embedding and extraction with enhanced robustness in small regions,\nenabling localized image protection. Built upon the classical Encoder-\nDistortion-Decoder training paradigm, MaskMark-D introduces a simple masking\nmechanism during the decoding stage to support both global and local watermark\nextraction. A mask is applied to the watermarked image before extraction,\nallowing the decoder to focus on selected regions and learn local extraction. A\nlocalization module is also integrated into the decoder to identify watermark\nregions during inference, reducing interference from irrelevant content and\nimproving accuracy. MaskMark-ED extends this design by incorporating the mask\ninto the encoding stage as well, guiding the encoder to embed the watermark in\ndesignated local regions for enhanced robustness. Comprehensive experiments\nshow that MaskMark achieves state-of-the-art performance in global watermark\nextraction, local watermark extraction, watermark localization, and\nmulti-watermark embedding. It outperforms all existing baselines, including the\nrecent leading model WAM for local watermarking, while preserving high visual\nquality of the watermarked images. MaskMark is also flexible, by adjusting the\ndistortion layer, it can adapt to different robustness requirements with just a\nfew steps of fine-tuning. Moreover, our approach is efficient and easy to\noptimize, requiring only 20 hours on a single A6000 GPU with just 1/15 the\ncomputational cost of WAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:29:00Z"}
{"aid":"http://arxiv.org/abs/2504.12748v1","title":"Attack-Defense Trees with Offensive and Defensive Attributes (with\n  Appendix)","summary":"Effective risk management in cybersecurity requires a thorough understanding\nof the interplay between attacker capabilities and defense strategies.\nAttack-Defense Trees (ADTs) are a commonly used methodology for representing\nthis interplay; however, previous work in this domain has only focused on\nanalyzing metrics such as cost, damage, or time from the perspective of the\nattacker. This approach provides an incomplete view of the system, as it\nneglects to model defender attributes: in real-world scenarios, defenders have\nfinite resources for countermeasures and are similarly constrained. In this\npaper, we propose a novel framework that incorporates defense metrics into\nADTs, and we present efficient algorithms for computing the Pareto front\nbetween defense and attack metrics. Our methods encode both attacker and\ndefender metrics as semirings, allowing our methods to be used for many metrics\nsuch as cost, damage, and skill. We analyze tree-structured ADTs using a\nbottom-up approach and general ADTs by translating them into binary decision\ndiagrams. Experiments on randomly generated ADTS demonstrate that both\napproaches effectively handle ADTs with several hundred nodes.","main_category":"cs.CR","categories":"cs.CR,cs.GT","published":"2025-04-17T08:41:07Z"}
{"aid":"http://arxiv.org/abs/2504.12763v1","title":"Single Complex-Frequency Resonance Mode in an Engineered Disordered\n  Time-Varying Cavity","summary":"We propose a straightforward mechanism for achieving unique $k$-space\nresonance modes in one-dimensional time-varying cavities where periodic\ntemporal modulation creates momentum band gaps through Floquet dynamics. By\nengineering the synergy between cavity resonance conditions and Floquet mode\nformation in photonic time crystals, we demonstrate the emergence of a single\ndominant momentum state that exhibits remarkable robustness against temporal\ndisorder. Through analytical modeling and numerical verification, we show that\nthe interplay between time-varying medium and cavity boundary conditions leads\nto amplification of specific waves followed by spatial mode selection. This\nengineered resonance mechanism enables insensitivity to initial wave source\nconfiguration and strong temporal disorder immunity. Our findings give a simple\nmechanism for exploiting narrow momentum bandgaps, and establish a foundation\nfor developing high-quality temporal cavity lasers and advancing extreme\ntemporal predictability in time-modulated systems.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn","published":"2025-04-17T09:00:32Z"}
{"aid":"http://arxiv.org/abs/2504.12813v1","title":"Approaching Current Challenges in Developing a Software Stack for Fully\n  Autonomous Driving","summary":"Autonomous driving is a complex undertaking. A common approach is to break\ndown the driving task into individual subtasks through modularization. These\nsub-modules are usually developed and published separately. However, if these\nindividually developed algorithms have to be combined again to form a\nfull-stack autonomous driving software, this poses particular challenges.\nDrawing upon our practical experience in developing the software of TUM\nAutonomous Motorsport, we have identified and derived these challenges in\ndeveloping an autonomous driving software stack within a scientific\nenvironment. We do not focus on the specific challenges of individual\nalgorithms but on the general difficulties that arise when deploying research\nalgorithms on real-world test vehicles. To overcome these challenges, we\nintroduce strategies that have been effective in our development approach. We\nadditionally provide open-source implementations that enable these concepts on\nGitHub. As a result, this paper's contributions will simplify future full-stack\nautonomous driving projects, which are essential for a thorough evaluation of\nthe individual algorithms.","main_category":"cs.RO","categories":"cs.RO,cs.SE","published":"2025-04-17T10:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12871v1","title":"Improvable Students in School Choice","summary":"The Deferred Acceptance algorithm (DA) frequently produces Pareto inefficient\nallocations in school choice problems. While a number of efficient mechanisms\nthat Pareto-dominate DA are available, a normative question remains unexplored:\nwhich students should benefit from efficiency enhancements? We address it by\nintroducing the concept of \\emph{maximally improvable students}, who benefit in\nevery improvement over DA that includes as many students as possible in\nset-inclusion terms. We prove that common mechanisms such as\nEfficiency-Adjusted DA (EADA) and Top Trading Cycles applied to DA (DA+TTC) can\nfall significantly short of this benchmark. These mechanisms may only improve\ntwo maximally-improvable students when up to $n-1$ could benefit. Addressing\nthis limitation, we develop the Maximum Improvement over DA mechanism (MIDA),\nwhich generates an efficient allocation that maximises the number of students\nimproved over DA. We show that MIDA can generate fewer blocking pairs than EADA\nand DA+TTC, demonstrating that its distributional improvements need not come at\nthe cost of high justified envy.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T11:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12888v1","title":"Anemia, weight, and height among children under five in Peru from 2007\n  to 2022: A Panel Data analysis","summary":"Econometrics in general, and Panel Data methods in particular, are becoming\ncrucial in Public Health Economics and Social Policy analysis. In this\ndiscussion paper, we employ a helpful approach of Feasible Generalized Least\nSquares (FGLS) to assess if there are statistically relevant relationships\nbetween hemoglobin (adjusted to sea-level), weight, and height from 2007 to\n2022 in children up to five years of age in Peru. By using this method, we may\nfind a tool that allows us to confirm if the relationships considered between\nthe target variables by the Peruvian agencies and authorities are in the right\ndirection to fight against chronic malnutrition and stunting.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.EM,stat.AP","published":"2025-04-17T12:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.12889v1","title":"RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A\n  Transformer-Based Approach","summary":"The massive number of antennas in extremely large aperture array (ELAA)\nsystems shifts the propagation regime of signals in internet of things (IoT)\ncommunication systems towards near-field spherical wave propagation. We propose\na reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism,\nwhere the design of the two-dimensional beam codebook that contains both the\nangular and distance domains is challenging. To address this issue, we\nintroduce a novel Transformer-based two-stage beam training algorithm, which\nincludes the coarse and fine search phases. The proposed mechanism provides a\nfine-grained codebook with enhanced spatial resolution, enabling precise\nbeamfocusing. Specifically, in the first stage, the beam training is performed\nto estimate the approximate location of the device by using a simple codebook,\ndetermining whether it is within the beamfocusing range (BFR) or the\nnone-beamfocusing range (NBFR). In the second stage, by using a more precise\ncodebook, a fine-grained beam search strategy is conducted. Experimental\nresults unveil that the precision of the RIS-assisted beamfocusing is greatly\nimproved. The proposed method achieves beam selection accuracy up to 97% at\nsignal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline\nmethod at different SNRs.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-17T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12898v1","title":"Information Gain-Guided Causal Intervention for Autonomous Debiasing\n  Large Language Models","summary":"Despite significant progress, recent studies indicate that current large\nlanguage models (LLMs) may still capture dataset biases and utilize them during\ninference, leading to the poor generalizability of LLMs. However, due to the\ndiversity of dataset biases and the insufficient nature of bias suppression\nbased on in-context learning, the effectiveness of previous prior\nknowledge-based debiasing methods and in-context learning based automatic\ndebiasing methods is limited. To address these challenges, we explore the\ncombination of causal mechanisms with information theory and propose an\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\nframework first utilizes an information gain-guided causal intervention method\nto automatically and autonomously balance the distribution of\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\nshow that IGCIDB can effectively debias LLM to improve its generalizability\nacross different tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T12:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.12950v1","title":"Tensor-monopole-induced topological boundary effects in four-dimensional\n  acoustic metamaterials","summary":"Gauge field theory provides the mathematical and conceptual framework to\ndescribe and understand topological singularities such as Weyl points and\nmagnetic monopoles. While singularities associated with vector electromagnetic\ngauge fields have been well-studied, those of higher-form tensor gauge fields,\nlike the four-dimensional (4D) tensor monopoles predicted by string theory,\nhave remained largely theoretical or limited to experimental demonstration in\npure synthetic dimensions, thereby not allowing investigations of the\nassociated boundary effects. Here, we present a 4D system with tensor monopoles\nusing engineered acoustic metamaterials. Our momentum space combines three real\nmomentum dimensions and a geometric parameter as the fourth. By varying this\nfourth momentum, we experimentally reveal two distinct topological surface\nstates in 3D subsystems: Fermi-arc surface states in a gapless subsystem and\nDirac-cone surface states in a gapped subsystem. Our work introduces a novel\nplatform for exploring new topological structures associated with tensor gauge\nfield and topological phenomena in higher dimensions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T13:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.12983v1","title":"Adaptive Modeling of Correlated Noise in Space-Based Gravitational Wave\n  Detectors","summary":"Accurately estimating the statistical properties of noise is important in\nspace-based gravitational wave data analysis. Traditional methods often assume\nuncorrelated noise or impose restrictive parametric forms on cross-channel\ncorrelations, which could lead to biased estimation in complex instrumental\nnoise. This paper introduces a spline-based framework with trans-dimensional\nBayesian inference to reconstruct the full noise covariance matrix, including\nfrequency-dependent auto- and cross-power spectral densities, without prior\nassumptions on noise shapes. The developed software $\\mathtt{NOISAR}$ can\nrecover the features of the noise power spectrum curves with a relative error\n$\\leq 10\\%$ for both auto- and cross-one.","main_category":"astro-ph.IM","categories":"astro-ph.IM,gr-qc","published":"2025-04-17T14:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.13010v1","title":"Simultaneous Polysomnography and Cardiotocography Reveal Temporal\n  Correlation Between Maternal Obstructive Sleep Apnea and Fetal Hypoxia","summary":"Background: Obstructive sleep apnea syndrome (OSAS) during pregnancy is\ncommon and can negatively affect fetal outcomes. However, studies on the\nimmediate effects of maternal hypoxia on fetal heart rate (FHR) changes are\nlacking. Methods: We used time-synchronized polysomnography (PSG) and\ncardiotocography (CTG) data from two cohorts to analyze the correlation between\nmaternal hypoxia and FHR changes (accelerations or decelerations). Maternal\nhypoxic event characteristics were analyzed using generalized linear modeling\n(GLM) to assess their associations with different FHR changes. Results: A total\nof 118 pregnant women participated. FHR changes were significantly associated\nwith maternal hypoxia, primarily characterized by accelerations. A longer\nhypoxic duration correlated with more significant FHR accelerations (P < 0.05),\nwhile prolonged hypoxia and greater SpO2 drop were linked to FHR decelerations\n(P < 0.05). Both cohorts showed a transient increase in FHR during maternal\nhypoxia, which returned to baseline after the event resolved. Conclusion:\nMaternal hypoxia significantly affects FHR, suggesting that maternal OSAS may\ncontribute to fetal hypoxia. These findings highlight the importance of\nmaternal-fetal interactions and provide insights for future interventions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.13019v1","title":"The higher regularity of the discrete Hardy-Littlewood maximal function","summary":"In a recent short note the first author \\cite{tem} gave the first positive\nresult on the higher order regularity of the discrete noncentered\nHardy-Littlewood maximal function. In this article we conduct a thorough\ninvestigation of possible similar results for higher order derivatives. We\nuncover that such results are indeed a consequence of a stronger phenomenon\nregarding the growth of $l^p(\\Z)$ norms of the derivatives of characteristic\nfunctions of finite subsets of $\\Z$. Along the way we discover very interesting\nconnections to Prouhot-Tarry-Escott (PTE) problem, and to zeros of complex\npolynomials with restricted coefficients (Littlewood-type polynomials).","main_category":"math.CA","categories":"math.CA","published":"2025-04-17T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.13089v1","title":"Absorption of Fermionic Dark Matter in the PICO-60 C$_{3}$F$_{8}$ Bubble\n  Chamber","summary":"Fermionic dark matter absorption on nuclear targets via neutral current\ninteractions is explored using a non-relativistic effective field theory\nframework. An analysis of data from the PICO-60 C$_{3}$F$_{8}$ bubble chamber\nsets leading constraints on spin-independent absorption for dark matter masses\nbelow 23 MeV/$\\textit{c}^2$ and establishes the first limits on spin-dependent\nabsorptive interactions. These results demonstrate the sensitivity of bubble\nchambers to low-mass dark matter and underscore the importance of absorption\nsearches in expanding the parameter space of direct detection experiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-17T16:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.13098v1","title":"Irradiation Studies of the Resistive AC-coupled Silicon Detector\n  (RSD/AC-LGAD)","summary":"Resistive AC-coupled Silicon Detectors (RSDs) are silicon sensors which\nprovide high temporal and spatial resolution. The RSD is a candidate sensor to\nbe used in future tracking detectors with the objective of obtaining '4D'\ntracking, where timing information can be used along with spatial hits during\ntrack finding. 4D tracking will be an essential part of any future lepton or\nhadron collider and may even be feasible at the HL-LHC. For applications at\nhadron colliders, RSD sensors must be able to operate in high fluence\nenvironments in order to provide 4D tracking. However, the effects of radiation\non RSDs have not been extensively studied. In this study, RSDs were irradiated\nto $1.0$, $2.0$, and $3.5 \\times 10^{15}$~cm$^{-2}$ (1~MeV neutron equivalents)\nwith both protons and neutrons. The sensors were then characterized\nelectrically to study the acceptor removal and, for the first time in this\ndoping concentration range, the donor removal. Then, the Transient Current\nTechnique was used to begin investigating the signal charge sharing after\nirradiation. The results suggest an interesting trend between acceptor and\ndonor removal, which is worthy of further study and could assist in improving\nradiation hardness of Low Gain Avalanche Diodes (LGADs).","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T17:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.13140v1","title":"PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition","summary":"Human action recognition (HAR) has achieved impressive results with deep\nlearning models, but their decision-making process remains opaque due to their\nblack-box nature. Ensuring interpretability is crucial, especially for\nreal-world applications requiring transparency and accountability. Existing\nvideo XAI methods primarily rely on feature attribution or static textual\nconcepts, both of which struggle to capture motion dynamics and temporal\ndependencies essential for action understanding. To address these challenges,\nwe propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR),\na novel concept bottleneck framework that introduces human pose sequences as\nmotion-aware, structured concepts for video action recognition. Unlike methods\nbased on pixel-level features or static textual descriptions, PCBEAR leverages\nhuman skeleton poses, which focus solely on body movements, providing robust\nand interpretable explanations of motion dynamics. We define two types of\npose-based concepts: static pose concepts for spatial configurations at\nindividual frames, and dynamic pose concepts for motion patterns across\nmultiple frames. To construct these concepts, PCBEAR applies clustering to\nvideo pose sequences, allowing for automatic discovery of meaningful concepts\nwithout manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500,\nshowing that it achieves high classification performance while offering\ninterpretable, motion-driven explanations. Our method provides both strong\npredictive performance and human-understandable insights into the model's\nreasoning process, enabling test-time interventions for debugging and improving\nmodel behavior.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:50:07Z"}
{"aid":"http://arxiv.org/abs/2504.13147v1","title":"Purely gravitational dark matter production in warm inflation","summary":"We consider an appealing scenario for the production of purely gravitational\ndark matter in the background of warm inflation, a mechanism that maintains\nstable thermal bath during inflation. Through systematic investigation of\nvarious gravitational production channels, we reveal distinctive features\ncompared to the standard inflation scenario. Notably, the inflaton annihilation\nchannel in warm inflation exhibits markedly different thermodynamics from the\nstandard inflation paradigm, leading to a suppression on the production of\nsub-inflaton-mass dark matter. For the production channel of inflationary\nvacuum fluctuations, we find a correlation of $\\rho_\\chi\\propto m_\\chi^{5/2}$\nfor the conformally coupled dark matter, which expands the feasible range of\ndark matter mass. Our results also indicates that a minimum temperature\nthreshold of $10^{-6}M_P$ is necessary for warm inflation, which allows\nadequate dark matter production. With observational constraints, our results\nprovide stringent limits on the mass range of purely gravitational dark matter\nwith sufficient density: $10^{-8}-10^{-2}M_P$ for minimal coupling and\n$10^{-14}-10^{-2}M_P$ for conformal coupling.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T17:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.14829v1","title":"$\\mathrm{M}$-ideals: from Banach spaces to rings","summary":"We introduce and investigate a class of ring ideals, termed ring\n$\\mathrm{M}$-ideals, inspired by the Alfsen--Effros theory of\n$\\mathrm{M}$-ideals in Banach spaces. We show that $\\mathrm{M}$-ideals extend\nthe classical notion of essential ideals and subsume them as a subclass. The\ncentral theorem provides a full characterization: an ideal is an\n$\\mathrm{M}$-ideal if and only if it is either essential or relatively\nirreducible. This dichotomy reveals the abundant and diverse nature of\n$\\mathrm{M}$-ideals, encompassing both essential and minimal ideals, and admits\nnatural generalizations in rings beyond the commutative and unital settings.\n  We systematically study the algebraic stability of $\\mathrm{M}$-ideals under\nstandard constructions such as intersection, quotient, direct product, and\nMorita equivalence and establish their behavior in topological rings and\noperator algebras. In certain rings such as $\\mathbb{Z}_n$ and C*-algebras, we\ncompletely classify $\\mathrm{M}$-ideals and relate them to algebraically\nminimal projections and central idempotents. The ring $\\mathrm{M}$-ideals in\n$C(K)$ are shown to be precisely the essential ideals or those minimal ideals\ncorresponding to isolated points.\n  Structurally, we show that the absence of proper $\\mathrm{M}$-ideals\ncharacterizes simplicity, while rings in which every proper $\\mathrm{M}$-ideal\nis a direct summand must decompose as finite direct sums of simple rings. In\nclosing, we introduce the notion of $\\mathrm{M}$-complements, drawing an\nanalogy with essential extensions in module theory, and demonstrate their\nexistence.","main_category":"math.RA","categories":"math.RA","published":"2025-04-21T03:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.14838v1","title":"Establishing Reliability Metrics for Reward Models in Large Language\n  Models","summary":"The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T03:39:33Z"}
{"aid":"http://arxiv.org/abs/2504.14911v1","title":"Lusztig sheaves, decomposition rule and restriction rule","summary":"In this article, we realize the subquotient based modules of certain tensor\nproducts or restricted modules via Lusztig's perverse sheaves on multi-framed\nquivers, and provide a construction of their canonical bases. As an\napplication, we prove that the decomposition and restriction coefficients of\nsymmetric Kac-Moody algebras equal to the dimensions of top Borel-Moore\nhomology groups for certain locally closed subsets of Nakajima's quiver\nvarieties.","main_category":"math.RT","categories":"math.RT,math.AG,math.QA","published":"2025-04-21T07:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.14929v1","title":"On the Exponential Diophantine Equation $(a^n-1)(b^n-1)=x^2$","summary":"Let $a$ and $b$ be two distinct fixed positive integers such that $\\min\n\\{a,b\\}>1.$ First, we correct an oversight from \\cite{X-Z}. Then, we show that\nthe equation in the title with $b \\equiv 3 \\pmod 8$, $b$ prime and $a$ even has\nno solution in positive integers $n, x$. This generalizes a result of Szalay\n\\cite{L}.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T07:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.14944v1","title":"Haloscope Searching for Dark Photons at Q-band with a Novel Coupling\n  Tuning Structure","summary":"Laboratory searching for dark matter is crucial for understanding several\nfundamental conundrums in physics and cosmology. Most cavity-based haloscope\nsearches focus on the frequency range below 10 GHz, while the parameter space\nwith higher frequency remains rarely explored, due to the challenges lying in\nthe fabrication of microwave cavities. Here we report the first Q-band\nhaloscope searching for dark photons with a 33.141 GHz cavity. A novel coupling\ntuning structure separated from the cavity was designed so as not to degrade\nthe quality factor of the cavity. We have established the most stringent\nconstraints $\\chi<2.5\\times10^{-12}$ at a confidence level of 90$\\%$ in the\nfrequency range from 33.139 GHz to 33.143 GHz, corresponding to the mass of\ndark photons ranging from 137.05 $\\mu$eV to 137.07 $\\mu$eV. The results surpass\nthe previous astronomical constraints by nearly three orders of magnitude. This\nwork has demonstrated the feasibility of dark matter haloscopes at Q band. In\nthe future, the constraints can be further improved by more than one order of\nmagnitude through low-temperature experiments, and the setup can be extended to\nsearch for axions, axion-like particles, and high-frequency gravitational\nwaves.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ex","published":"2025-04-21T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.14945v1","title":"Learning to Reason under Off-Policy Guidance","summary":"Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T08:09:13Z"}
{"aid":"http://arxiv.org/abs/2504.14952v1","title":"PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for\n  PIV","summary":"Deep learning algorithms have significantly reduced the computational time\nand improved the spatial resolution of particle image velocimetry~(PIV).\nHowever, the models trained on synthetic datasets might have a degraded\nperformance on practical particle images due to domain gaps. As a result,\nspecial residual patterns are often observed for the vector fields of deep\nlearning-based estimators. To reduce the special noise step-by-step, we employ\na denoising diffusion model~(FlowDiffuser) for PIV analysis. And the\ndata-hungry iterative denoising diffusion model is trained via a transfer\nlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)\npre-training a FlowDiffuser model with multiple optical flow datasets of the\ncomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the\npre-trained model on synthetic PIV datasets. Note that the PIV images are\nupsampled by a factor of two to resolve the small-scale turbulent flow\nstructures. The visualized results indicate that our PIV-FlowDiffuser\neffectively suppresses the noise patterns. Therefore, the denoising diffusion\nmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV\nbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits\nenhanced generalization performance on unseen particle images due to transfer\nlearning. Overall, this study highlights the transfer-learning-based denoising\ndiffusion models for PIV. And a detailed implementation is recommended for\ninterested readers in the repository\nhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-21T08:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.14973v1","title":"Ultra-diffuse galaxies in the EAGLE simulation","summary":"We use the highest-resolution EAGLE simulation, Recal-L025N0752, to study the\nproperties and formation of ultra-diffuse galaxies (UDGs). We identify 181 UDGs\nand find their properties closely match observations. The total masses of EAGLE\nUDGs range from ${\\sim}5\\times 10^{8}~M_{\\odot}$ to ${\\sim}2\\times\n10^{11}~M_{\\odot}$, indicating that they are dwarf galaxies rather than failed\n$L_\\star$ galaxies. EAGLE UDGs are not a distinct population, but rather a\nsubset of dwarf galaxies, as their properties generally form a continuous\ndistribution with those of normal dwarf galaxies. Unlike the situations in\nprevious studies, the extended sizes of field UDGs in EAGLE are not driven by\nhigh halos spin or by supernova-induced stellar expansion, but instead largely\narise from high spins in their star-forming gas and thus the newly formed stars\nat large radii. This might be attributed to galactic fountains, by which\nstar-forming gas are launched to large halo-centric distances and acquire\nadditional angular momentum through interactions with the circumgalactic\nmedium.For satellite UDGs, ${\\sim} 60 \\%$ of them were already UDGs before\nfalling into the host galaxy, while the remaining ${\\sim} 40\\%$ were normal\ngalaxies prior to infall and subsequently transformed into UDGs due to tidal\neffects after infall.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T09:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.14980v1","title":"Bayesian model selection of Primordial Black Holes and Dressed\n  Primordial Black Holes with lensed Gravitational Waves","summary":"If particle dark matter (DM) and primordial black holes (PBHs) coexist, PBHs\nwill be surrounded by particle DM, forming celestial objects known as dressed\nPBHs (dPBHs). These structures suggest a scenario in which PBHs and DM can\nexist simultaneously. However, in the high-frequency regime, the gravitational\nlensing effect of bare PBHs is similar to that of dPBHs. Ground-based\ngravitational wave (GW) detectors are particularly sensitive to high-frequency\nGW signals. In this regime, the lensing effect of a point-mass lens with a mass\nin the range of $10^{-1} \\sim 10^2 M_{\\odot}$ becomes significant. In this\nwork, we incorporate dPBH models with GW observations and employ Bayesian\ninference techniques to distinguish PBHs from dPBHs. Using the third-generation\nground-based GW detectors, Einstein Telescope (ET) and Cosmic Explorer (CE), as\nexamples, we demonstrate that these detectors can effectively differentiate the\nlensing effects of dPBHs from those of PBHs across a broad frequency range.\nFurthermore, we find that with a larger black hole (BH) mass inside the\nsurrounding particle DM, ET and CE can distinguish these two lensed models with\neven greater precision.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-21T09:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.14991v1","title":"Understanding Accuracy-Fairness Trade-offs in Re-ranking through\n  Elasticity in Economics","summary":"Fairness is an increasingly important factor in re-ranking tasks. Prior work\nhas identified a trade-off between ranking accuracy and item fairness. However,\nthe underlying mechanisms are still not fully understood. An analogy can be\ndrawn between re-ranking and the dynamics of economic transactions. The\naccuracy-fairness trade-off parallels the coupling of the commodity tax\ntransfer process. Fairness considerations in re-ranking, similar to a commodity\ntax on suppliers, ultimately translate into a cost passed on to consumers.\nAnalogously, item-side fairness constraints result in a decline in user-side\naccuracy. In economics, the extent to which commodity tax on the supplier (item\nfairness) transfers to commodity tax on users (accuracy loss) is formalized\nusing the notion of elasticity. The re-ranking fairness-accuracy trade-off is\nsimilarly governed by the elasticity of utility between item groups. This\ninsight underscores the limitations of current fair re-ranking evaluations,\nwhich often rely solely on a single fairness metric, hindering comprehensive\nassessment of fair re-ranking algorithms. Centered around the concept of\nelasticity, this work presents two significant contributions. We introduce the\nElastic Fairness Curve (EF-Curve) as an evaluation framework. This framework\nenables a comparative analysis of algorithm performance across different\nelasticity levels, facilitating the selection of the most suitable approach.\nFurthermore, we propose ElasticRank, a fair re-ranking algorithm that employs\nelasticity calculations to adjust inter-item distances within a curved space.\nExperiments on three widely used ranking datasets demonstrate its effectiveness\nand efficiency.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T09:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.15008v1","title":"New horizon in particle physics: First observation of CP violation in\n  baryon decays","summary":"Recently, the LHCb Collaboration achieved the observation of CP violation\n(CPV) in baryon decays through the process of $\\Lambda_b^0\\to pK^-\\pi^+\\pi^-$,\nreporting an asymmetry of $(2.45\\pm0.46\\pm0.10)\\%$ with a significance of\n5.2$\\sigma$. This marks a breakthrough and a milestone in particle physics, six\ndecades after the first observation of CPV in mesons. It will be helpful to\nunderstand the matter-antimatter asymmetry in the universe. In addition to the\nglobal CPV, local CPV is also observed by LHCb in the low mass region of\n$m_{p\\pi^+\\pi^-}<2.7$GeV as $(5.4\\pm0.9\\pm0.1)\\%$ with a significance of\n6.0$\\sigma$. Intriguingly, this measurement aligns well with a theoretical\nprediction of $(5.6-5.9)\\%$ based on a CPV dynamics using the data of $N\\pi\\to\np\\pi^+\\pi^-$ scatterings. Since baryons contain one more quark than mesons, the\ndynamics of baryon decays are significantly different from those of mesons.\nTherefore, the first observation of baryon CPV by LHCb opens a new horizon in\nthe studies of dynamics of the strong interaction.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T10:16:40Z"}
{"aid":"http://arxiv.org/abs/2504.15030v1","title":"Height-Dependent Slow Magnetoacoustic Wave Amplitude and Energy Flux in\n  Sunspot Atmospheres","summary":"Slow magnetoacoustic waves (SMAWs) have been considered in the past as a\npossible candidate for chromospheric heating. This study analyzes 20 active\nregions observed between 2012 and 2016 to examine the amplitude and energy flux\nvariation of SMAWs in the umbral atmosphere. Six different wavelength channels\nfrom the Atmospheric Imaging Assembly onboard the Solar Dynamics Observatory,\ncovering regions from the photosphere to the low corona, were utilized for this\npurpose. The wave amplitude estimations show a gradual increase in 3-minute\noscillation amplitude, peaking between 700--900 km, followed by a steady\ndecrease; at altitudes greater than 1800 km, the amplitude appears to increase\nand then decrease again. The corresponding energy flux, on the other hand,\ndisplays a steady and monotonous decrease with a significant reduction in value\nfrom approximately $3.32 \\pm 0.50~\\mathrm{kW,m^{-2}}$ near the photosphere to\nabout $(6.47 \\pm 3.16) \\times 10^{-4}~\\mathrm{W,m^{-2}}$ at an altitude of 2585\nkm. This decay may be attributed to radiative damping and shock dissipation in\nthe lower altitudes, and thermal conduction and viscosity in the higher\naltitudes. The missing flux is a factor of 3--15 lower than that required to\ncounterbalance the chromospheric radiative losses.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T11:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.15066v1","title":"Chinese-LiPS: A Chinese audio-visual speech recognition dataset with\n  Lip-reading and Presentation Slides","summary":"Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-21T12:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.15074v1","title":"The orientation dynamics of a massive ellipsoid in simple shear flow","summary":"The orientation dynamics of a massive rigid ellipsoid in simple shear flow of\na Newtonian fluid is investigated in detail. The term `massive' refers to\ndominant particle inertia, as characterized by $St \\gg 1$, $St =\n\\dot{\\gamma}l^2\\rho_p/\\nu \\rho_f$ being the Stokes number; here, $\\dot{\\gamma}$\nis the shear rate, $\\nu$ is the kinematic viscosity, $l$ is a characteristic\nellipsoidal dimension (taken to be the longest semi axis), and $\\rho_p$ and\n$\\rho_f$ are the particle and fluid densities, respectively. Fluid inertial\neffects are neglected, so the particle Reynolds number ($Re$) is zero. The\nequations of motion of the ellipsoid in this limit reduce to those governing an\nEuler top, supplemented by a weak viscous torque. The dynamics consists of a\nfast conservative motion on time scales of $O(\\dot{\\gamma}^{-1})$ that, for an\nellipsoid, involves a combination of spin, precession and nutation, and a\nslower component driven by the viscous torque; the latter modulates the angular\nmomentum and rotational kinetic energy on asymptotically longer time scales of\n$O(St{\\dot{\\gamma}}^{-1})$. The separation of time scales for large $St$ allows\nfor use of the method of averaging for a triaxial ellipsoid, to derive an\nautonomous system of ODE's that govern motion on a four-dimensional slow\nmanifold consisting of the three angular momenta and the rotational kinetic\nenergy. There are three fixed points on the slow manifold, with rotation about\nthe shortest axis being stable. The fixed point corresponding to rotation about\nthe longest axis is a saddle point, while intermediate-axis-aligned rotation\ncorresponds to a singular fixed point. For spheroids, the singular fixed point\nmerges with one of the other two, leading to only two fixed points, one a\nstable node and the other a saddle; the former corresponds to rotation about\nthe shorter axis.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T13:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.15078v1","title":"High-Precision and Wafer-Scale Transfer Lithography of Commercial\n  Photoresists via Reversible Adhesion for Sustainable Microfabrication on\n  Diverse Substrates","summary":"Photolithography conventionally requires flat and rigid substrates, limiting\nits applications in flexible, curved, and transient electronics. Here, we\nreport a breakthrough approach employing a reversibly adhesion-switchable\nphase-changing polymer to transfer commercial photoresists onto previously\ninaccessible substrates. It achieves wafer-scale (4-inch) transfer with global\nregistration error below 60 microns and support precise patterning on\nsolvent-sensitive, curved, microtextured or delicate surfaces. Combined with\ndry etching, we demonstrated high-resolution patterning of quantum dots and\norganic semiconductors. The process also supports a sustainable dry lift-off\nfor patterning functional materials. The reusability of both the transfer\ncarrier and photoresist introduces a new level of sustainability and\nscalability, establishing a significant advancement in microfabrication. We\nadditionally fabricated a micro-sized UV-photodetector array directly on a\ncurved glass bottle to demonstrate this unprecedented capability.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-21T13:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.15145v1","title":"\"I Know It When I See It\": Mood Spaces for Connecting and Expressing\n  Visual Concepts","summary":"Expressing complex concepts is easy when they can be labeled or quantified,\nbut many ideas are hard to define yet instantly recognizable. We propose a Mood\nBoard, where users convey abstract concepts with examples that hint at the\nintended direction of attribute changes. We compute an underlying Mood Space\nthat 1) factors out irrelevant features and 2) finds the connections between\nimages, thus bringing relevant concepts closer. We invent a fibration\ncomputation to compress/decompress pre-trained features into/from a compact\nspace, 50-100x smaller. The main innovation is learning to mimic the pairwise\naffinity relationship of the image tokens across exemplars. To focus on the\ncoarse-to-fine hierarchical structures in the Mood Space, we compute the top\neigenvector structure from the affinity matrix and define a loss in the\neigenvector space. The resulting Mood Space is locally linear and compact,\nallowing image-level operations, such as object averaging, visual analogy, and\npose transfer, to be performed as a simple vector operation in Mood Space. Our\nlearning is efficient in computation without any fine-tuning, needs only a few\n(2-20) exemplars, and takes less than a minute to learn.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.15151v1","title":"Artificial compressibility method for the incompressible Navier-Stokes\n  equations with variable density","summary":"We introduce a novel artificial compressibility technique to approximate the\nincompressible Navier-Stokes equations with variable fluid properties such as\ndensity and dynamical viscosity. The proposed scheme used the couple pressure\nand momentum, equal to the density times the velocity, as primary unknowns. It\nalso involves an adequate treatment of the diffusive operator such that\ntreating the nonlinear convective term explicitly leads to a scheme with time\nindependent stiffness matrices that is suitable for pseudo-spectral methods.\nThe stability and temporal convergence of the semi-implicit version of the\nscheme is established under the hypothesis that the density is approximated\nwith a method that conserves the minimum-maximum principle. Numerical\nillustrations confirm that both the semi-implicit and explicit scheme are\nstable and converge with order one under classic CFL condition. Moreover, the\nproposed scheme is shown to perform better than a momentum based pressure\nprojection method, previously introduced by one of the authors, on setups\ninvolving gravitational waves and immiscible multi-fluids in a cylinder.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T14:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.15171v1","title":"Audio-Visual Class-Incremental Learning for Fish Feeding intensity\n  Assessment in Aquaculture","summary":"Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture\nmanagement. Recent multi-modal approaches have shown promise in improving FFIA\nrobustness and efficiency. However, these methods face significant challenges\nwhen adapting to new fish species or environments due to catastrophic\nforgetting and the lack of suitable datasets. To address these limitations, we\nfirst introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled\naudio-visual clips capturing feeding intensities across six different fish\nspecies in real aquaculture environments. Then, we pioneer audio-visual class\nincremental learning (CIL) for FFIA and demonstrate through benchmarking on\nAV-CIL-FFIA that it significantly outperforms single-modality methods. Existing\nCIL methods rely heavily on historical data. Exemplar-based approaches store\nraw samples, creating storage challenges, while exemplar-free methods avoid\ndata storage but struggle to distinguish subtle feeding intensity variations\nacross different fish species. To overcome these limitations, we introduce\nHAIL-FFIA, a novel audio-visual class-incremental learning framework that\nbridges this gap with a prototype-based approach that achieves exemplar-free\nefficiency while preserving essential knowledge through compact feature\nrepresentations. Specifically, HAIL-FFIA employs hierarchical representation\nlearning with a dual-path knowledge preservation mechanism that separates\ngeneral intensity knowledge from fish-specific characteristics. Additionally,\nit features a dynamic modality balancing system that adaptively adjusts the\nimportance of audio versus visual information based on feeding behaviour\nstages. Experimental results show that HAIL-FFIA is superior to SOTA methods on\nAV-CIL-FFIA, achieving higher accuracy with lower storage needs while\neffectively mitigating catastrophic forgetting in incremental fish species\nlearning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T15:24:34Z"}
{"aid":"http://arxiv.org/abs/2504.15201v1","title":"Phase-separated lipid vesicles: continuum modeling, simulation, and\n  validation","summary":"The paper presents a complete research cycle comprising continuum-based\nmodeling, computational framework development, and validation setup to predict\nphase separation and surface hydrodynamics in lipid bilayer membranes. We\nstarting with an overview of the key physical characteristics of lipid\nbilayers, including their composition, mechanical properties, and\nthermodynamics, and then discuss continuum models of multi-component bilayers.\nThe most complex model is a Navier--Stokes--Cahn--Hilliard (NSCH) type system,\ndescribing the coupling of incompressible surface fluid dynamics with\nphase-field dynamics on arbitrarily curved geometries. It is discretized using\ntrace finite element methods, which offer geometric flexibility and stability\nin representing surface PDEs. Numerical studies are conducted to examine\nphysical features such as coarsening rates and interfacial dynamics. The\ncomputational results obtained from the NSCH model are compared against\nexperimental data for membrane compositions with distinct phase behaviors,\ndemonstrating that including both phase-field models and surface hydrodynamics\nis essential to accurately reproduce domain evolution observed in\nepi-fluorescence microscopy. Lastly, we extend the model to incorporate\nexternal forces that enable the simulation of vesicles containing cationic\nlipids, used to enhance membrane fusion.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T16:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.15204v1","title":"Soft-Output from Covered Space Decoding of Product Codes","summary":"In this work, we propose a new soft-in soft-out decoder called soft-output\nfrom covered space (SOCS) decoder. It estimates the a posteriori reliability\nbased on the space explored by a list decoder, i.e., the set of vectors for\nwhich the list decoder knows whether they are codewords. This approach enables\na more accurate calculation of the a posteriori reliability and results in\ngains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding\ncompared to Chase-Pyndiah decoding.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T16:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.15220v1","title":"Fully Bayesian Approaches to Topics over Time","summary":"The Topics over Time (ToT) model captures thematic changes in timestamped\ndatasets by explicitly modeling publication dates jointly with word\nco-occurrence patterns. However, ToT was not approached in a fully Bayesian\nfashion, a flaw that makes it susceptible to stability problems. To address\nthis issue, we propose a fully Bayesian Topics over Time (BToT) model via the\nintroduction of a conjugate prior to the Beta distribution. This prior acts as\na regularization that prevents the online version of the algorithm from\nunstable updates when a topic is poorly represented in a mini-batch. The\ncharacteristics of this prior to the Beta distribution are studied here for the\nfirst time. Still, this model suffers from a difference in scale between the\nsingle-time observations and the multiplicity of words per document. A\nvariation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a\nsolution. In WBToT, publication dates are repeated a certain number of times\nper document, which balances the relative influence of words and timestamps\nalong the inference process. We have tested our models on two datasets: a\ncollection of over 200 years of US state-of-the-union (SOTU) addresses and a\nlarge-scale COVID-19 Twitter corpus of 10 million tweets. The results show that\nWBToT captures events better than Latent Dirichlet Allocation and other SOTA\ntopic models like BERTopic: the median absolute deviation of the topic presence\nover time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also\ndemonstrate the superior coherence of WBToT over BToT, which highlights the\nimportance of balancing the time and word modalities. Finally, we illustrate\nthe stability of the online optimization algorithm in WBToT, which allows the\napplication of WBToT to problems that are intractable for standard ToT.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-21T16:46:07Z"}
{"aid":"http://arxiv.org/abs/2504.15224v1","title":"On Extension modules of finite homological dimension","summary":"We explore the implications of the finiteness of homological dimensions for\nExt modules, focusing on projective dimension, injective dimension, and their\nGorenstein counterpart. In this direction, we establish several finiteness\ncriteria for homological dimensions. Our results include the consequences of\nthe finiteness of the Gorenstein (injective) dimension of the deficiency\nmodules as well as a duality for certain Ext modules, all of finite\n(Gorenstein) projective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-21T16:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.15263v1","title":"Interpretable Locomotion Prediction in Construction Using a\n  Memory-Driven LLM Agent With Chain-of-Thought Reasoning","summary":"Construction tasks are inherently unpredictable, with dynamic environments\nand safety-critical demands posing significant risks to workers. Exoskeletons\noffer potential assistance but falter without accurate intent recognition\nacross diverse locomotion modes. This paper presents a locomotion prediction\nagent leveraging Large Language Models (LLMs) augmented with memory systems,\naimed at improving exoskeleton assistance in such settings. Using multimodal\ninputs - spoken commands and visual data from smart glasses - the agent\nintegrates a Perception Module, Short-Term Memory (STM), Long-Term Memory\n(LTM), and Refinement Module to predict locomotion modes effectively.\nEvaluation reveals a baseline weighted F1-score of 0.73 without memory, rising\nto 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague\nand safety-critical commands. Calibration metrics, including a Brier Score drop\nfrom 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability.\nThis framework supports safer, high-level human-exoskeleton collaboration, with\npromise for adaptive assistive systems in dynamic industries.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.15267v1","title":"Diffusion Bridge Models for 3D Medical Image Translation","summary":"Diffusion tensor imaging (DTI) provides crucial insights into the\nmicrostructure of the human brain, but it can be time-consuming to acquire\ncompared to more readily available T1-weighted (T1w) magnetic resonance imaging\n(MRI). To address this challenge, we propose a diffusion bridge model for 3D\nbrain image translation between T1w MRI and DTI modalities. Our model learns to\ngenerate high-quality DTI fractional anisotropy (FA) images from T1w images and\nvice versa, enabling cross-modality data augmentation and reducing the need for\nextensive DTI acquisition. We evaluate our approach using perceptual\nsimilarity, pixel-level agreement, and distributional consistency metrics,\ndemonstrating strong performance in capturing anatomical structures and\npreserving information on white matter integrity. The practical utility of the\nsynthetic data is validated through sex classification and Alzheimer's disease\nclassification tasks, where the generated images achieve comparable performance\nto real data. Our diffusion bridge model offers a promising solution for\nimproving neuroimaging datasets and supporting clinical decision-making, with\nthe potential to significantly impact neuroimaging research and clinical\npractice.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.15568v1","title":"Is Learning Effective in Dynamic Strategic Interactions? Evidence from\n  Stackelberg Games","summary":"In many settings of interest, a policy is set by one party, the leader, in\norder to influence the action of another party, the follower, where the\nfollower's response is determined by some private information. A natural\nquestion to ask is, can the leader improve their strategy by learning about the\nunknown follower through repeated interactions? A well known folk theorem from\ndynamic pricing, a special case of this leader-follower setting, would suggest\nthat the leader cannot learn effectively from the follower when the follower is\nfully strategic, leading to a large literature on learning in strategic\nsettings that relies on limiting the strategic space of the follower in order\nto provide positive results. In this paper, we study dynamic Bayesian\nStackelberg games, where a leader and a \\emph{fully strategic} follower\ninteract repeatedly, with the follower's type unknown. Contrary to existing\nresults, we show that the leader can improve their utility through learning in\nrepeated play. Using a novel average-case analysis, we demonstrate that\nlearning is effective in these settings, without needing to weaken the\nfollower's strategic space. Importantly, this improvement is not solely due to\nthe leader's ability to commit, nor does learning simply substitute for\ncommunication between the parties. We provide an algorithm, based on a\nmixed-integer linear program, to compute the optimal leader policy in these\ngames and develop heuristic algorithms to approximate the optimal dynamic\npolicy more efficiently. Through simulations, we compare the efficiency and\nruntime of these algorithms against static policies.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-22T03:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.15620v1","title":"Observation of topology of non-Hermitian systems without chiral symmetry","summary":"Topological invariants are crucial for characterizing topological systems.\nHowever, experimentally measuring them presents a significant challenge,\nespecially in non-Hermitian systems where the biorthogonal eigenvectors are\noften necessary. We propose a general approach for measuring the topological\ninvariants of one-dimensional non-Hermitian systems, which can be derived from\nthe spin textures of right eigenstates. By utilizing a dilation method, we\nrealize a non-Hermitian system without chiral symmetry on a two-qubit nuclear\nmagnetic resonance system and measure the winding number associated with the\neigenstates. In addition to examining the topology of the eigenstates, our\nexperiment also reveals the topological structure of the energy band, which\ndiffers from that in chiral systems. Our work paves the way for further\nexploration of complex topological properties in non-Hermitian systems without\nchiral symmetry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T06:21:24Z"}
{"aid":"http://arxiv.org/abs/2504.15622v1","title":"Exploring the Role of Large Language Models in Cybersecurity: A\n  Systematic Survey","summary":"With the rapid development of technology and the acceleration of\ndigitalisation, the frequency and complexity of cyber security threats are\nincreasing. Traditional cybersecurity approaches, often based on static rules\nand predefined scenarios, are struggling to adapt to the rapidly evolving\nnature of modern cyberattacks. There is an urgent need for more adaptive and\nintelligent defence strategies. The emergence of Large Language Model (LLM)\nprovides an innovative solution to cope with the increasingly severe cyber\nthreats, and its potential in analysing complex attack patterns, predicting\nthreats and assisting real-time response has attracted a lot of attention in\nthe field of cybersecurity, and exploring how to effectively use LLM to defend\nagainst cyberattacks has become a hot topic in the current research field. This\nsurvey examines the applications of LLM from the perspective of the cyber\nattack lifecycle, focusing on the three phases of defense reconnaissance,\nfoothold establishment, and lateral movement, and it analyzes the potential of\nLLMs in Cyber Threat Intelligence (CTI) tasks. Meanwhile, we investigate how\nLLM-based security solutions are deployed and applied in different network\nscenarios. It also summarizes the internal and external risk issues faced by\nLLM during its application. Finally, this survey also points out the facing\nrisk issues and possible future research directions in this domain.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T06:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.15634v1","title":"Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar\n  Protein Folding Model with Attention-based layers","summary":"Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T06:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.15649v1","title":"RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video\n  Super-Resolution","summary":"As a fundamental challenge in visual computing, video super-resolution (VSR)\nfocuses on reconstructing highdefinition video sequences from their degraded\nlowresolution counterparts. While deep convolutional neural networks have\ndemonstrated state-of-the-art performance in spatial-temporal super-resolution\ntasks, their computationally intensive nature poses significant deployment\nchallenges for resource-constrained edge devices, particularly in real-time\nmobile video processing scenarios where power efficiency and latency\nconstraints coexist. In this work, we propose a Reparameterizable Architecture\nfor High Fidelity Video Super Resolution method, named RepNet-VSR, for\nreal-time 4x video super-resolution. On the REDS validation set, the proposed\nmodel achieves 27.79 dB PSNR when processing 180p to 720p frames in 103 ms per\n10 frames on a MediaTek Dimensity NPU. The competition results demonstrate an\nexcellent balance between restoration quality and deployment efficiency. The\nproposed method scores higher than the previous champion algorithm of MAI video\nsuper-resolution challenge.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.15659v1","title":"VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional\n  Correctness Validation","summary":"Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.CL,cs.LG,cs.SE","published":"2025-04-22T07:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.15671v1","title":"On the approximation of the Riemannian barycenter","summary":"We present a method to compute an approximate Riemannian barycenter of a\ncollection of points lying on a Riemannian manifold. Our approach relies on the\nuse of theoretically proven under- and overapproximations of the Riemannian\ndistance function. We compare it to the exact computation of the Riemannian\nbarycenter and to an approach that approximates the Riemannian logarithm using\nlifting maps. Experiments are conducted on the Stiefel manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T07:52:10Z"}
{"aid":"http://arxiv.org/abs/2504.15679v1","title":"Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE\n  Problem using Soft Actor-Critic Reinforcement Learning","summary":"We present a novel reinforcement learning (RL) approach for solving the\nclassical 2-level atom non-LTE radiative transfer problem by framing it as a\ncontrol task in which an RL agent learns a depth-dependent source function\n$S(\\tau)$ that self-consistently satisfies the equation of statistical\nequilibrium (SE). The agent's policy is optimized entirely via reward-based\ninteractions with a radiative transfer engine, without explicit knowledge of\nthe ground truth. This method bypasses the need for constructing approximate\nlambda operators ($\\Lambda^*$) common in accelerated iterative schemes.\nAdditionally, it requires no extensive precomputed labeled datasets to extract\na supervisory signal, and avoids backpropagating gradients through the complex\nRT solver itself. Finally, we show through experiment that a simple feedforward\nneural network trained greedily cannot solve for SE, possibly due to the moving\ntarget nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers\npotential advantages for complex scenarios (e.g., atmospheres with enhanced\nvelocity fields, multi-dimensional geometries, or complex microphysics) where\n$\\Lambda^*$ construction or solver differentiability is challenging.\nAdditionally, the agent can be incentivized to find more efficient policies by\nmanipulating the discount factor, leading to a reprioritization of immediate\nrewards. If demonstrated to generalize past its training data, this RL\nframework could serve as an alternative or accelerated formalism to achieve SE.\nTo the best of our knowledge, this study represents the first application of\nreinforcement learning in solar physics that directly solves for a fundamental\nphysical constraint.","main_category":"astro-ph.SR","categories":"astro-ph.SR,cs.LG","published":"2025-04-22T08:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.15689v1","title":"The Viability of Crowdsourcing for RAG Evaluation","summary":"How good are humans at writing and judging responses in retrieval-augmented\ngeneration (RAG) scenarios? To answer this question, we investigate the\nefficacy of crowdsourcing for RAG through two complementary studies: response\nwriting and response utility judgment. We present the Crowd RAG Corpus 2025\n(CrowdRAG-25), which consists of 903 human-written and 903 LLM-generated\nresponses for the 301 topics of the TREC RAG'24 track, across the three\ndiscourse styles 'bulleted list', 'essay', and 'news'. For a selection of 65\ntopics, the corpus further contains 47,320 pairwise human judgments and 10,556\npairwise LLM judgments across seven utility dimensions (e.g., coverage and\ncoherence). Our analyses give insights into human writing behavior for RAG and\nthe viability of crowdsourcing for RAG evaluation. Human pairwise judgments\nprovide reliable and cost-effective results compared to LLM-based pairwise or\nhuman/LLM-based pointwise judgments, as well as automated comparisons with\nhuman-written reference responses. All our data and tools are freely available.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T08:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.15720v1","title":"SeaLLM: Service-Aware and Latency-Optimized Resource Sharing for Large\n  Language Model Inference","summary":"Large language models (LLMs) with different architectures and sizes have been\ndeveloped. Serving each LLM with dedicated GPUs leads to resource waste and\nservice inefficiency due to the varying demand of LLM requests. A common\npractice is to share multiple LLMs. However, existing sharing systems either do\nnot consider the autoregressive pattern of LLM services, or only focus on\nimproving the throughput, which impairs the sharing performance, especially the\nserving latency. We present SeaLLM, which enables service-aware and\nlatency-optimized LLM sharing. SeaLLM improves the overall sharing performance\nby (1) a latency-optimized scheduling algorithm utilizing the characteristics\nof LLM services, (2) a placement algorithm to determine the placement plan and\nan adaptive replacement algorithm to decide the replacement interval, and (3) a\nunified key-value cache to share GPU memory among LLM services efficiently. Our\nevaluation under real-world traces and LLM services demonstrates that SeaLLM\nimproves the normalized latency by up to $13.60\\times$, the tail latency by up\nto $18.69\\times$, and the SLO attainment by up to $3.64\\times$ compared to\nexisting solutions.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T09:08:46Z"}
{"aid":"http://arxiv.org/abs/2504.15728v1","title":"SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal\n  Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems","summary":"Domain-adaptive thermal object detection plays a key role in facilitating\nvisible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered\nimage pairs and minimizing reliance on large annotated IR datasets. However,\ninherent limitations of IR images, such as the lack of color and texture cues,\npose challenges for RGB-trained models, leading to increased false positives\nand poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray\ncolor Augmentation (SAGA), a novel strategy for mitigating color bias and\nbridging the domain gap by extracting object-level features relevant to IR\nimages. Additionally, to validate the proposed SAGA for drone imagery, we\nintroduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse\napplications. The dataset contains 5,612 images with 145,666 instances,\ncaptured from diverse angles, altitudes, backgrounds, and times of day,\noffering valuable opportunities for multimodal learning, domain adaptation for\nobject detection and segmentation, and exploration of sensor-specific strengths\nand weaknesses. IndraEye aims to enhance the development of more robust and\naccurate aerial perception systems, especially in challenging environments.\nExperimental results show that SAGA significantly improves RGB-to-IR adaptation\nfor autonomous driving and IndraEye dataset, achieving consistent performance\ngains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain\nadaptation techniques. The dataset and codes are available at\nhttps://github.com/airliisc/IndraEye.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.15760v1","title":"Moment Tensor Potential and Equivariant Tensor Network Potential with\n  explicit dispersion interactions","summary":"In this study, we investigate the effect of incorporating explicit dispersion\ninteractions in the functional form of machine learning interatomic potentials\n(MLIPs), particularly in the Moment Tensor Potential and Equivariant Tensor\nNetwork potential for accurate modeling of liquid carbon tetrachloride,\nmethane, and toluene. We show that explicit incorporation of dispersion\ninteractions via D2 and D3 corrections significantly improves the accuracy of\nMLIPs when the cutoff radius is set to a commonly used value of 5 -- 6 \\r{A}.\nWe also show that for carbon tetrachloride and methane, a substantial\nimprovement in accuracy can be achieved by extending the cutoff radius to 7.5\n\\r{A}. However, for accurate modeling of toluene, explicit incorporation of\ndispersion remains important. Furthermore, we find that MLIPs incorporating\ndispersion interactions via D2 reach a close level of accuracy to those\nincorporating D3, and D2 is suitable for accurate modeling of the systems in\nthe study, while being less computationally expensive. We evaluated the\naccuracy of MLIPs in dimer binding curves compared to ab initio data and in\npredicting density and radial distribution functions compared to experiments.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-22T10:11:54Z"}
{"aid":"http://arxiv.org/abs/2504.15770v1","title":"Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural\n  Network for Edge Detection","summary":"Edge detection has attracted considerable attention thanks to its exceptional\nability to enhance performance in downstream computer vision tasks. In recent\nyears, various deep learning methods have been explored for edge detection\ntasks resulting in a significant performance improvement compared to\nconventional computer vision algorithms. In neural networks, edge detection\ntasks require considerably large receptive fields to provide satisfactory\nperformance. In a typical convolutional operation, such a large receptive field\ncan be achieved by utilizing a significant number of consecutive layers, which\nyields deep network structures. Recently, a Multi-scale Tensorial Summation\n(MTS) factorization operator was presented, which can achieve very large\nreceptive fields even from the initial layers. In this paper, we propose a\nnovel MTS Dimensional Reduction (MTS-DR) module guided neural network,\nMTS-DR-Net, for the edge detection task. The MTS-DR-Net uses MTS layers, and\ncorresponding MTS-DR blocks as a new backbone to remove redundant information\ninitially. Such a dimensional reduction module enables the neural network to\nfocus specifically on relevant information (i.e., necessary subspaces).\nFinally, a weight U-shaped refinement module follows MTS-DR blocks in the\nMTS-DR-Net. We conducted extensive experiments on two benchmark edge detection\ndatasets: BSDS500 and BIPEDv2 to verify the effectiveness of our model. The\nimplementation of the proposed MTS-DR-Net can be found at\nhttps://github.com/LeiXuAI/MTS-DR-Net.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.15787v1","title":"Plasma Mechanism of Radio Emission Generation at the Bow Shock of the\n  Exoplanet HD 189733b","summary":"This study evaluates the possibility of efficient radio emission generation\nin the bow shock region of hot Jupiter-type exoplanets. As a source of\nenergetic electrons, the shock drift acceleration mechanism at a\nquasi-perpendicular shock is proposed. Electrons reflected and accelerated by\nthe shock propagate through the relatively dense stellar wind plasma and excite\nplasma waves; therefore, a plasma emission mechanism is considered as the\nsource of the resulting radio waves. Using the bow shock of the hot Jupiter HD\n189733b as a case study, the properties of the energetic electron beam, the\nexcited plasma waves, and the resulting radio frequencies are estimated. An\nenergy-based analysis is carried out to identify the range of stellar wind\nparameters for which radio emission from the bow shock of the exoplanet HD\n189733b could be detectable by modern astronomical instruments.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.EP,astro-ph.IM","published":"2025-04-22T10:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.15794v1","title":"Residual lifetime prediction for heterogeneous degradation data by\n  Bayesian semi-parametric method","summary":"Degradation data are considered for assessing reliability in highly reliable\nsystems. The usual assumption is that degradation units come from a homogeneous\npopulation. But in presence of high variability in the manufacturing process,\nthis assumption is not true in general; that is different sub-populations are\ninvolved in the study. Predicting residual lifetime of a functioning unit is a\nmajor challenge in the degradation modeling especially in heterogeneous\nenvironment. To account for heterogeneous degradation data, we have proposed a\nBayesian semi-parametric approach to relax the conventional modeling\nassumptions. We model the degradation path using Dirichlet process mixture of\nnormal distributions. Based on the samples obtained from posterior distribution\nof model parameters we obtain residual lifetime distribution for individual\nunit. Transformation based MCMC technique is used for simulating values from\nthe derived residual lifetime distribution for prediction of residual lifetime.\nA simulation study is undertaken to check performance of the proposed\nsemi-parametric model compared with parametric model. Fatigue Crack Size data\nis analyzed to illustrate the proposed methodology.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-22T11:14:56Z"}
{"aid":"http://arxiv.org/abs/2504.15834v1","title":"Causal machine learning for high-dimensional mediation analysis using\n  interventional effects mapped to a target trial","summary":"Causal mediation analysis examines causal pathways linking exposures to\ndisease. The estimation of interventional effects, which are mediation\nestimands that overcome certain identifiability problems of natural effects,\nhas been advanced through causal machine learning methods, particularly for\nhigh-dimensional mediators. Recently, it has been proposed interventional\neffects can be defined in each study by mapping to a target trial assessing\nspecific hypothetical mediator interventions. This provides an appealing\nframework to directly address real-world research questions about the extent to\nwhich such interventions might mitigate an increased disease risk in the\nexposed. However, existing estimators for interventional effects mapped to a\ntarget trial rely on singly-robust parametric approaches, limiting their\napplicability in high-dimensional settings. Building upon recent developments\nin causal machine learning for interventional effects, we address this gap by\ndeveloping causal machine learning estimators for three interventional effect\nestimands, defined by target trials assessing hypothetical interventions\ninducing distinct shifts in joint mediator distributions. These estimands are\nmotivated by a case study within the Longitudinal Study of Australian Children,\nused for illustration, which assessed how intervening on high inflammatory\nburden and other non-inflammatory adverse metabolomic markers might mitigate\nthe adverse causal effect of overweight or obesity on high blood pressure in\nadolescence. We develop one-step and (partial) targeted minimum loss-based\nestimators based on efficient influence functions of those estimands,\ndemonstrating they are root-n consistent, efficient, and multiply robust under\ncertain conditions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T12:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.15864v1","title":"The effects of pressure loads in the dimension reduction of elasticity\n  models","summary":"We study the dimensional reduction from three to two dimensions in\nhyperelastic materials subject to a live load, modeled as a constant pressure\nforce. Our results demonstrate that this loading has a significant impact in\nhigher-order scaling regimes, namely those associated with von K\\'arm\\'an-type\ntheories, where a nontrivial interplay arises between the elastic energy and\nthe pressure term. In contrast, we rigorously show that in lower-order bending\nregimes, as described by Kirchhoff-type theories, the pressure load does not\ninfluence the minimizers. Finally, after identifying the corresponding\n$\\Gamma$-limit, we conjecture that a similar independence from the pressure\nterm persists in the most flexible membrane regimes.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T12:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.15871v1","title":"Long-term disparities in the recovery of urban mobility after COVID-19\n  in Latin America","summary":"The COVID-19 pandemic caused unprecedented disruptions to the patterns of\nurban mobility. Existing work has overwhelmingly focused on the immediate\nimpacts of COVID-19 on human mobility during 2020, particularly in countries of\nthe Global North. It showed that the pandemic resulted in an increased gap,\nbenefitted affluent and core urban areas with larger reductions in mobility.\nYet, little is know about the long-term persistence of these unequal impacts\nbeyond 2020, and in countries of the Global South where socioeconomic\ndisparities are more acute. Using over 100 million anonymised daily records of\nmobile phone data from Meta-Facebook users from March 2020 to May 2022, we aim\nto determine the long-term geographic and socioeconomic impact of COVID-19 on\nmobility patterns in Latin America. Our findings reveal that the mobility\ndisparities triggered by the COVID-19 pandemic have endured, with affluent and\ndensely populated areas displaying lower mobility rates than more deprived and\nsparsely populated places. We also show that the magnitude of the reduction in\nmobility levels early in the COVID-19 pandemic largely determined the extent of\nmobility differential between socioeconomic groups. We find no signs of full\nrecovery to baseline levels of mobility in some urban cores, suggesting some\nlost of appeal as attractors of economic activity. Overall, our findings\nsuggest that the COVID-19 pandemic has contributed to amplified pre-existing\nsocioeconomic inequalities and redefined the role of cities in Latin American\ncountries.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-22T13:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.15883v1","title":"Integrating Non-Linear Radon Transformation for Diabetic Retinopathy\n  Grading","summary":"Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T13:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.15886v1","title":"Beyond Attention: Investigating the Threshold Where Objective Robot\n  Exclusion Becomes Subjective","summary":"As robots become increasingly involved in decision-making processes (e.g.,\npersonnel selection), concerns about fairness and social inclusion arise. This\nstudy examines social exclusion in robot-led group interviews by robot Ameca,\nexploring the relationship between objective exclusion (robot's attention\nallocation), subjective exclusion (perceived exclusion), mood change, and need\nfulfillment. In a controlled lab study (N = 35), higher objective exclusion\nsignificantly predicted subjective exclusion. In turn, subjective exclusion\nnegatively impacted mood and need fulfillment but only mediated the\nrelationship between objective exclusion and need fulfillment. A piecewise\nregression analysis identified a critical threshold at which objective\nexclusion begins to be perceived as subjective exclusion. Additionally, the\nstanding position was the primary predictor of exclusion, whereas demographic\nfactors (e.g., gender, height) had no significant effect. These findings\nunderscore the need to consider both objective and subjective exclusion in\nhuman-robot interactions and have implications for fairness in robot-assisted\nhiring processes.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-22T13:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.15916v1","title":"Are there Spectral Features in the MIRI/LRS Transmission Spectrum of\n  K2-18b?","summary":"Determining the composition of an exoplanet atmosphere relies on the presence\nof detectable spectral features. The strongest spectral features, including\nDMS, look approximately Gaussian. Here, I perform a suite of Gaussian feature\nanalyses to find any statistically significant spectral features in the\nrecently published MIRI/LRS spectrum of K2-18b (N. Madhusudhan et al. 2025). In\nN. Madhusudhan et al. 2025, they claim a 3.4-$\\sigma$ detection of spectral\nfeatures compared to a flat line. In 5 out of 6 tests, I find the data\npreferred a flat line over a Gaussian model, with a $\\chi^{2}_{\\nu}$ of 1.06.\nWhen centering the Gaussian where the absorptions for DMS and DMDS peak, I find\nln(B) = 1.21 in favour of the Gaussian model, with a $\\chi^{2}_{\\nu}$ of 0.99.\nWith only $\\sim$2-$\\sigma$ in favour of Gaussian features, I conclude no strong\nstatistical evidence for spectral features.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-22T14:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.15923v1","title":"Bayesian sample size calculations for external validation studies of\n  risk prediction models","summary":"Summary: Contemporary sample size calculations for external validation of\nrisk prediction models require users to specify fixed values of assumed model\nperformance metrics alongside target precision levels (e.g., 95% CI widths).\nHowever, due to the finite samples of previous studies, our knowledge of true\nmodel performance in the target population is uncertain, and so choosing fixed\nvalues represents an incomplete picture. As well, for net benefit (NB) as a\nmeasure of clinical utility, the relevance of conventional precision-based\ninference is doubtful. In this work, we propose a general Bayesian algorithm\nfor constructing the joint distribution of predicted risks and response values\nbased on summary statistics of model performance in previous studies. For\nstatistical metrics of performance, we propose sample size determination rules\nthat either target desired expected precision, or a desired assurance\nprobability that the precision criteria will be satisfied. For NB, we propose\nrules based on optimality assurance (the probability that the planned study\ncorrectly identifies the most beneficial strategy) and the Expected Value of\nSample Information (EVSI), the expected gain in NB from the planned validation\nstudy. We showcase these developments in a case study on the validation of a\nrisk prediction model for deterioration of hospitalized COVID-19 patients.\nCompared to the conventional sample size calculation methods, a Bayesian\napproach requires explicit quantification of uncertainty around model\nperformance, but thereby enables various sample size rules based on expected\nprecision, assurance probabilities, and value of information.","main_category":"stat.AP","categories":"stat.AP,stat.CO,stat.ME","published":"2025-04-22T14:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.15943v1","title":"Ge$_{1-x}$Si$_{x}$ single crystals for Ge hole spin qubit integration","summary":"Spin qubits are fundamental building blocks of modern quantum computing\ndevices. The path of Ge-based hole-spin qubits has several advantages over\nSi-based electron-spin systems, such as the absence of valley band degeneracy,\nthe possibility of efficient field control due to large spin-orbit coupling,\nand smaller effective masses. Among the possible Ge qubit devices, Ge/GeSi\nplanar heterostructures have proven to be favourable for upscaling and\nfabrication. The Si concentration of the straining GeSi buffer serves as an\nimportant tuning parameter for the electronic structure of Ge/GeSi qubits. A\nparticularly low Si concentration of x = 0.15 of the Ge$_{0.85}$Si$_{0.15}$\ncrystal should enable minimal lattice strain for spin qubit heterostructures,\nwhich is difficult to stabilize as a random alloy. We present a\nsynchrotron-based study to investigate the chemical composition, valence band\nelectronic structure and local atomic structure of a Ge$_{0.85}$Si$_{0.15}$\nsingle crystal using the advanced combination of hard X-ray photoelectron\nspectroscopy (HAXPES), hard X-ray momentum microscopy (HarMoMic) and X-ray\nphotoelectron diffraction (XPD). We found that the Ge$_{0.85}$Si$_{0.15}$\ncrystal has an individual, uniform valence band structure, with no signs of\nphase separation. The shapes of the valence bands resemble those of pure Ge, as\ndo the low effective masses. XPD experiments and Bloch wave calculations, show\nthe Si atoms located at Ge lattice sites within the crystal, forming a random\nalloy. This high chemical, electronic and structural quality of\nGe$_{0.85}$Si$_{0.15}$ single-crystal substrates is of crucial importance for\ntheir implementation to enable long spin lifetimes in Ge-based hole-spin\nqubits. The results emphasise the power of combined X-ray spectromicroscopy\ntechniques, which provide key insights into the qubit building blocks that form\nthe basis of quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:40:46Z"}
{"aid":"http://arxiv.org/abs/2504.15952v1","title":"Reconstruction of three-dimensional fluid stress field via\n  photoelasticity using physics-informed convolutional encoder-decoder","summary":"Measuring stress fields in fluids and soft materials is crucial in various\nfields such as mechanical engineering, medicine, and bioengineering. However,\nconventional methods that calculate stress fields from velocity fields struggle\nto measure complex fluids where the stress constitutive equation is unknown. To\naddress this, we propose a novel approach that combines photoelastic\nmeasurements -- which can non-invasively visualize internal stresses -- with\nmachine learning to measure stress fields. The machine learning model, which we\nnamed physics-informed convolutional encoder-decoder (PICED), integrates a\nconvolutional neural network (CNN)-based encoder-decoder model with a\nphysics-informed neural network (PINN). Using this approach, three-dimensional\nstress fields can be predicted with high accuracy for multiple interpolated\ndata points in a rectangular channel flow.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T14:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.15975v1","title":"A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition","summary":"I introduce a formalism for representing the syntax of recursively structured\ngraph-like patterns. It does not use production rules, like a conventional\ngraph grammar, but represents the syntactic structure in a more direct and\ndeclarative way. The grammar and the pattern are both represented as networks,\nand parsing is seen as the construction of a homomorphism from the pattern to\nthe grammar. The grammars can represent iterative, hierarchical and nested\nrecursive structure in more than one dimension.\n  This supports a highly parallel style of parsing, in which all aspects of\npattern recognition (feature detection, segmentation, parsing, filling in\nmissing symbols, top-down and bottom-up inference) are integrated into a single\nprocess, to exploit the synergy between them.\n  The emphasis of this paper is on underlying theoretical issues, but I also\ngive some example runs to illustrate the error-tolerant parsing of complex\nrecursively structured patterns of 50-1000 symbols, involving variability in\ngeometric relationships, blurry and indistinct symbols, overlapping symbols,\ncluttered images, and erased patches.","main_category":"cs.FL","categories":"cs.FL,cs.CV","published":"2025-04-22T15:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.15997v1","title":"A Lagrangian Approach to Optimal Lotteries in Non-Convex Economies","summary":"We develop a new method to efficiently solve for optimal lotteries in models\nwith non-convexities. In order to employ a Lagrangian framework, we prove that\nthe value of the saddle point that characterizes the optimal lottery is the\nsame as the value of the dual of the deterministic problem. Our algorithm\nsolves the dual of the deterministic problem via sub-gradient descent. We prove\nthat the optimal lottery can be directly computed from the deterministic optima\nthat occur along the iterations. We analyze the computational complexity of our\nalgorithm and show that the worst-case complexity is often orders of magnitude\nbetter than the one arising from a linear programming approach. We apply the\nmethod to two canonical problems with private information. First, we solve a\nprincipal-agent moral-hazard problem, demonstrating that our approach delivers\nsubstantial improvements in speed and scalability over traditional linear\nprogramming methods. Second, we study an optimal taxation problem with hidden\ntypes, which was previously considered computationally infeasible, and examine\nunder which conditions the optimal contract will involve lotteries.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T16:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.16045v1","title":"Reinforcement Learning and Metaheuristics for Feynman Integral Reduction","summary":"We propose new methods for optimizing the integration-by-parts (IBP)\nreduction of Feynman integrals, an important computational bottleneck in modern\nperturbative calculations in quantum field theory. Using the simple example of\none-loop massive bubble integrals, we pose the problem of minimizing the number\nof arithmetic operations in reducing a target integral to master integrals via\nthe Laporta algorithm. This is a nontrivial combinatorial optimization problem\nover the ordering of IBP equation generation (from pairs of seed integrals and\nIBP operators) and the ordering of integral elimination. Our first proposed\nmethod is reinforcement learning, which involves an agent interacting with an\nenvironment in a step-by-step manner and learning the best actions to take\ngiven an observation of the environment (in this case, the current state of the\nIBP reduction process). The second method is using metaheuristics, e.g.\nsimulated annealing, to minimize the computational cost as a black-box function\nof numerical priority values that control the orderings. For large-scale\nproblems, the number of free parameters can be compressed by using a small\nneural network to assign priority values. Remarkably, both methods lead to IBP\nreduction schemes that are more efficient than human-designed algorithms.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-22T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.16074v1","title":"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in\n  Large Language Models","summary":"We introduce PHYBench, a novel, high-quality benchmark designed for\nevaluating reasoning capabilities of large language models (LLMs) in physical\ncontexts. PHYBench consists of 500 meticulously curated physics problems based\non real-world physical scenarios, designed to assess the ability of models to\nunderstand and reason about realistic physical processes. Covering mechanics,\nelectromagnetism, thermodynamics, optics, modern physics, and advanced physics,\nthe benchmark spans difficulty levels from high school exercises to\nundergraduate problems and Physics Olympiad challenges. Additionally, we\npropose the Expression Edit Distance (EED) Score, a novel evaluation metric\nbased on the edit distance between mathematical expressions, which effectively\ncaptures differences in model reasoning processes and results beyond\ntraditional binary scoring methods. We evaluate various LLMs on PHYBench and\ncompare their performance with human experts. Our results reveal that even\nstate-of-the-art reasoning models significantly lag behind human experts,\nhighlighting their limitations and the need for improvement in complex physical\nreasoning scenarios. Our benchmark results and dataset are publicly available\nat https://phybench-official.github.io/phybench-demo/.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16386v1","title":"Robust Transmission Design for Reconfigurable Intelligent Surface and\n  Movable Antenna Enabled Symbiotic Radio Communications","summary":"This paper explores the application of movable antenna (MA), a cutting-edge\ntechnology with the capability of altering antenna positions, in a symbiotic\nradio (SR) system enabled by reconfigurable intelligent surface (RIS). The goal\nis to fully exploit the capabilities of both MA and RIS, constructing a better\ntransmission environment for the co-existing primary and secondary transmission\nsystems. For both parasitic SR (PSR) and commensal SR (CSR) scenarios with the\nchannel uncertainties experienced by all transmission links, we design a robust\ntransmission scheme with the goal of maximizing the primary rate while ensuring\nthe secondary transmission quality. To address the maximization problem with\nthorny non-convex characteristics, we propose an alternating optimization\nframework that utilizes the General S-Procedure, General Sign-Definiteness\nPrinciple, successive convex approximation (SCA), and simulated annealing (SA)\nimproved particle swarm optimization (SA-PSO) algorithms. Numerical results\nvalidate that the CSR scenario significantly outperforms the PSR scenario in\nterms of primary rate, and also show that compared to the fixed-position\nantenna scheme, the proposed MA scheme can increase the primary rate by 1.62\nbps/Hz and 2.37 bps/Hz for the PSR and CSR scenarios, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T03:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16396v1","title":"'Dark pressure': A metric that yields distance-independent circular\n  orbital speed in deep space with 'tunable' total mass","summary":"In general relativity, the tangential speed of objects in stable circular\norbits is not uniquely described by the orbital radius and the mass present\ninside the orbital radius. This work presents a static, spherically symmetric\nspacetime metric which produces stable circular orbits whose speed approaches a\nconstant value at high radii. The orbital speed is independent of the mass\ncontained within the orbital radius, however, there is pressure throughout the\nspacetime. The stress energy tensor of this metric is evaluated numerically\nusing the mass of the Milky Way's central black hole, the orbital speed of its\ndistant satellites, and three different values of a unitless 'mass tuning'\nparameter B. These B 'tune' the amount of mass present, without violating the\nWeak Energy Condition (WEC) at any evaluated spacetime point. The metric can be\nmerged with a Friedmann-Robertson-Walker metric, in which case it achieves\nisotropy and obeys the Friedmann equations at cosmological distances.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T03:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.16399v1","title":"Scalable and modular generation of multipartite entangled states through\n  memory-enhanced fusion","summary":"Efficient generation of large-scale multipartite entangled states is a\ncritical but challenging task in quantum information processing. Although\ngeneration of multipartite entanglement within a small set of individual qubits\nhas been demonstrated, further scale-up in system size requires the connection\nof smaller entangled states into a larger state in a scalable and modular\nmanner. Here we achieve this goal by implementing memory-enhanced fusion of two\nmultipartite entangled states via photonic interconnects. Through asynchronous\npreparation of two tripartite W-state entanglements in two spatially-separated\nmodules of atomic quantum memories and on-demand fusion via single-photon\ninterference, we demonstrate the creation of a four-partite W-state\nentanglement shared by two remote quantum memory modules in a heralded way. We\nfurther transfer the W state from the memory qubits to the photonic qubits, and\nconfirm the genuine four-partite entanglement through witness measurements. We\nthen demonstrate memory-enhanced scaling in efficiencies in the entanglement\nfusion. The demonstrated scalable generation and fusion of multipartite\nentangled states pave the way towards realization of large-scale distributed\nquantum information processing in the future.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T04:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.16404v1","title":"Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle\n  Lameness Detection","summary":"Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,eess.IV","published":"2025-04-23T04:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.16427v1","title":"Can Large Language Models Help Multimodal Language Analysis? MMLA: A\n  Comprehensive Benchmark","summary":"Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.MM","published":"2025-04-23T05:25:13Z"}
{"aid":"http://arxiv.org/abs/2504.16442v1","title":"Nonlinear contagion dynamics on dynamical networks: exact solutions\n  ranging from consensus times to evolutionary trajectories","summary":"Understanding nonlinear social contagion dynamics on dynamical networks, such\nas opinion formation, is crucial for gaining new insights into consensus and\npolarization. Similar to threshold-dependent complex contagions, the\nnonlinearity in adoption rates poses challenges for mean-field approximations.\nTo address this theoretical gap, we focus on nonlinear binary-opinion dynamics\non dynamical networks and analytically derive local configurations,\nspecifically the distribution of opinions within any given focal individual's\nneighborhood. This exact local configuration of opinions, combined with network\ndegree distributions, allows us to obtain exact solutions for consensus times\nand evolutionary trajectories. Our counterintuitive results reveal that neither\nbiased assimilation (i.e., nonlinear adoption rates) nor preferences in local\nnetwork rewiring -- such as in-group bias (preferring like-minded individuals)\nand the Matthew effect (preferring social hubs) -- can significantly slow down\nconsensus. Among these three social factors, we find that biased assimilation\nis the most influential in accelerating consensus. Furthermore, our analytical\nmethod efficiently and precisely predicts the evolutionary trajectories of\nadoption curves arising from nonlinear contagion dynamics. Our work paves the\nway for enabling analytical predictions for general nonlinear contagion\ndynamics beyond opinion formation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO,q-bio.PE","published":"2025-04-23T06:02:05Z"}
{"aid":"http://arxiv.org/abs/2504.16466v1","title":"The role and contribution of resonance effect for the decay process of\n  $\\bar B^{0}_s \\rightarrow Ï^{+}Ï^{-}P$","summary":"The size of the direct CP asymmetry generated during the weak decay of\nhadrons is attributed to the weak phase and some strong phases. The weak phase\ncomes from the CKM matrix and a strong phase may result from the resonance\neffect which is produced by the mixing of vector meson\n$V\\left\\{\\rho^{0}(770),\\omega(782),\\phi(1020)\\right\\}$ to $\\pi^+ \\pi^-$ meson\npairs. $\\rho^{0}(770)$ can decay directly into $\\pi^+ \\pi^-$ meson pairs, both\n$\\omega(782)$ and $\\phi(1020)$ can also decay into $\\pi^+ \\pi^-$ meson pairs\nwith small contribution from isospin symmetry breaking. The main contribution\nfor the middle state vector meson $\\rho^{0}(770)-\\omega(782)-\\phi(1020)$\ninterference is the mix of $\\rho^{0}(770)$, $\\omega(782)-\\rho^{0}(770)$ and\n$\\phi(1020)-\\rho^{0}(770)$. We calculate the CP asymmetry and decay branching\nratio for $\\bar{B}^0_{s} \\rightarrow \\pi^+ \\pi^- \\pi^0 (\\bar K ^{0})$ in the\nframework of QCD factorization and compare them with previous work. We also add\nthe analysis of $\\bar{B}^0_{s} \\rightarrow \\pi^+ \\pi^- \\eta(\\eta^{(')})$ decay\nprocess. The results show that the CP asymmetry of these four decay processes\nare significantly enhanced especially for the $\\bar{B}^0_{s} \\rightarrow \\pi^+\n\\pi^- \\bar K ^{0}$ decay process and the decay branching ratio also changes\nunder resonance effect. These work might provide support for the experimental\nanalysis of the $\\bar B^{0}_s$ meson.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T07:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.16489v1","title":"Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based\n  Multi-Agent Debate","summary":"Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T08:01:50Z"}
{"aid":"http://arxiv.org/abs/2504.16493v1","title":"Breaking scaling relations with inverse catalysts: a machine learning\n  exploration of trends in $\\mathrm{CO_2}$ hydrogenation energy barriers","summary":"The conversion of $\\mathrm{CO_2}$ into useful products such as methanol is a\nkey strategy for abating climate change and our dependence on fossil fuels.\nDeveloping new catalysts for this process is costly and time-consuming and can\nthus benefit from computational exploration of possible active sites. However,\nthis is complicated by the complexity of the materials and reaction networks.\nHere, we present a workflow for exploring transition states of elementary\nreaction steps at inverse catalysts, which is based on the training of a neural\nnetwork-based machine learning interatomic potential. We focus on the crucial\nformate intermediate and its formation over nanoclusters of indium oxide\nsupported on Cu(111). The speedup compared to an approach purely based on\ndensity functional theory allows us to probe a wide variety of active sites\nfound at nanoclusters of different sizes and stoichiometries. Analysis of the\nobtained set of transition state geometries reveals different\nstructure--activity trends at the edge or interior of the nanoclusters.\nFurthermore, the identified geometries allow for the breaking of linear scaling\nrelations, which could be a key underlying reason for the excellent catalytic\nperformance of inverse catalysts observed in experiments.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-04-23T08:12:47Z"}
{"aid":"http://arxiv.org/abs/2504.16496v1","title":"Boundaries of the bounded hyperbolic components of polynomials","summary":"In this paper, we study the local connectivity and Hausdorff dimension for\nthe boundaries of the bounded hyperbolic components in the space $\\mathcal P_d$\nof polynomials of degree $d\\geq 3$. It is shown that for any non disjoint-type\nbounded hyperbolic component $\\mathcal H\\subset \\mathcal P_d$, the locally\nconnected part of $\\partial\\mathcal H$, along each regular boundary strata, has\nfull Hausdorff dimension $2d-2$.\n  An essential innovation in our argument involves analyzing how the canonical\nparameterization of the hyperbolic component--realized via Blaschke products\nover a mapping scheme--extends to the boundary. This framework allows us to\nstudy three key aspects of $\\partial \\mathcal H$: the local connectivity\nstructure, the perturbation behavior, and the local Hausdorff dimensions.","main_category":"math.DS","categories":"math.DS,math.CV","published":"2025-04-23T08:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.16498v1","title":"LiDAL-Assisted RLNC-NOMA in OWC Systems","summary":"Optical wireless communication (OWC) is envisioned as a key enabler for\nimmersive indoor data transmission in future wireless communication networks.\nHowever, multi-user interference management arises as a challenge in dense\nindoor OWC systems composed of multiple optical access points (APs) serving\nmultiple users. In this paper, we propose a novel dual-function OWC system for\ncommunication and localization. Non-orthogonal multiple access (NOMA) with\nrandom linear network coding (RLNC) is designed for data transmission, where\nNOMA allows the serving of multiple users simultaneously through controlling\nthe power domain, and RLNC helps minimize errors that might occur during signal\nprocessing phase. This setup is assisted with a light detection and\nlocalization system (LiDAL) that can passively obtain spatio-temporal indoor\ninformation of user presence and location for dynamic-user grouping. The\ndesigned LiDAL system helps to improve the estimation of channel state\ninformation (CSI) in realistic indoor network scenarios, where the CSI of\nindoor users might be noisy and/or highly correlated. We evaluate the\nperformance of NOMA combined with RLNC by analyzing the probability of\nsuccessful decoding compared to conventional NOMA and orthogonal schemes. In\naddition, we derive the Cramer-Rao Lower Bound (CRLB) to evaluate the accuracy\nof location estimation. The results show that the proposed RLNC-NOMA improves\nthe probability of successful decoding and the overall system performance. The\nresults also show the high accuracy of the unbiased location estimator and its\nassistant in reducing the imperfection of CSI, leading to high overall system\nperformance.","main_category":"eess.SY","categories":"eess.SY,cs.IT,cs.SY,math.IT","published":"2025-04-23T08:22:28Z"}
{"aid":"http://arxiv.org/abs/2504.16543v1","title":"The different for base change of arithmetic curves","summary":"We introduce a method for studying reduction types of arithmetic curves and\nwildly ramified base change. We give new proofs of earlier results of Lorenzini\nand Obus-Wewers, and resolve a question of Lorenzini on the Euler\ncharacteristic of the resolution graph of a $p$-cyclic arithmetic surface\nquotient singularity. Our method consists of constructing a simultaneous\nskeleton for the associated cover of Berkovich analytifications and applying a\nskeletal Riemann-Hurwitz formula.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-23T09:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.16546v1","title":"Tinkering Against Scaling","summary":"The ascent of scaling in artificial intelligence research has revolutionized\nthe field over the past decade, yet it presents significant challenges for\nacademic researchers, particularly in computational social science and critical\nalgorithm studies. The dominance of large language models, characterized by\ntheir extensive parameters and costly training processes, creates a disparity\nwhere only industry-affiliated researchers can access these resources. This\nimbalance restricts academic researchers from fully understanding their tools,\nleading to issues like reproducibility in computational social science and a\nreliance on black-box metaphors in critical studies.\n  To address these challenges, we propose a \"tinkering\" approach that is\ninspired by existing works. This method involves engaging with smaller models\nor components that are manageable for ordinary researchers, fostering hands-on\ninteraction with algorithms. We argue that tinkering is both a way of making\nand knowing for computational social science and a way of knowing for critical\nstudies, and fundamentally, it is a way of caring that has broader implications\nfor both fields.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-23T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.16559v1","title":"Unified Molecule Generation and Property Prediction","summary":"Modeling the joint distribution of the data samples and their properties\nallows to construct a single model for both data generation and property\nprediction, with synergistic capabilities reaching beyond purely generative or\npredictive models. However, training joint models presents daunting\narchitectural and optimization challenges. Here, we propose Hyformer, a\ntransformer-based joint model that successfully blends the generative and\npredictive functionalities, using an alternating attention mask together with a\nunified pre-training scheme. We show that Hyformer rivals other joint models,\nas well as state-of-the-art molecule generation and property prediction models.\nAdditionally, we show the benefits of joint modeling in downstream tasks of\nmolecular representation learning, hit identification and antimicrobial peptide\ndesign.","main_category":"cs.LG","categories":"cs.LG,q-bio.QM,I.2.1","published":"2025-04-23T09:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.16574v1","title":"PIS: Linking Importance Sampling and Attention Mechanisms for Efficient\n  Prompt Compression","summary":"Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T09:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.16604v1","title":"Debunking with Dialogue? Exploring AI-Generated Counterspeech to\n  Challenge Conspiracy Theories","summary":"Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SI,I.2.7","published":"2025-04-23T10:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.16627v1","title":"TIFIN India at SemEval-2025: Harnessing Translation to Overcome\n  Multilingual IR Challenges in Fact-Checked Claim Retrieval","summary":"We address the challenge of retrieving previously fact-checked claims in\nmonolingual and crosslingual settings - a critical task given the global\nprevalence of disinformation. Our approach follows a two-stage strategy: a\nreliable baseline retrieval system using a fine-tuned embedding model and an\nLLM-based reranker. Our key contribution is demonstrating how LLM-based\ntranslation can overcome the hurdles of multilingual information retrieval.\nAdditionally, we focus on ensuring that the bulk of the pipeline can be\nreplicated on a consumer GPU. Our final integrated system achieved a success@10\nscore of 0.938 and 0.81025 on the monolingual and crosslingual test sets,\nrespectively.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T11:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.16659v1","title":"Evolutionary dynamics in state-feedback public goods games with peer\n  punishment","summary":"Public goods game serves as a valuable paradigm for studying the challenges\nof collective cooperation in human and natural societies. Peer punishment is\noften considered as an effective incentive for promoting cooperation in such\ncontexts. However, previous related studies have mostly ignored the positive\nfeedback effect of collective contributions on individual payoffs. In this\nwork, we explore global and local state-feedback, where the multiplication\nfactor is positively correlated with the frequency of contributors in the\nentire population or within the game group, respectively. By using replicator\ndynamics in an infinite well-mixed population we reveal that state-based\nfeedback plays a crucial role in alleviating the cooperative dilemma by\nenhancing and sustaining cooperation compared to the feedback-free case.\nMoreover, when the feedback strength is sufficiently strong or the baseline\nmultiplication factor is sufficiently high, the system with local\nstate-feedback provides full cooperation, hence supporting the ``think\nglobally, act locally'' principle. Besides, we show that the second-order\nfree-rider problem can be partially mitigated under certain conditions when the\nstate-feedback is employed. Importantly, these results remain robust with\nrespect to variations in punishment cost and fine.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-23T12:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.16664v1","title":"Quantum walk search for exceptional configurations on one- and\n  two-dimensional lattice with extra long-range edges of HN4 network","summary":"There exist several types of configurations of marked vertices, referred to\nas the exceptional configurations, on one- and two-dimensional periodic\nlattices with additional long-range edges of the HN4 network, which are\nchallenging to find using discrete-time quantum walk algorithms. In this\narticle, we conduct a comparative analysis of the discrete-time quantum walk\nalgorithm utilizing various coin operators to search for these exceptional\nconfigurations. First, we study the emergence of several new exceptional\nconfigurations/vertices due to the additional long-range edges of the HN4\nnetwork on both one- and two-dimensional lattices. Second, our study shows that\nthe diagonal configuration on a two-dimensional lattice, which is exceptional\nin the case without long-range edges, no longer remains an exceptional\nconfiguration. Third, it is also shown that a recently proposed modified coin\ncan search all these configurations, including any other configurations in one-\nand two-dimensional lattices with very high success probability. Additionally,\nwe construct stationary states for the exceptional configurations caused by the\nadditional long-range edges, which explains why the standard and lackadaisical\nquantum walks with the Grover coin cannot search these configurations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T12:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.16689v1","title":"p-adic Cherednik algebras on rigid analytic spaces","summary":"Let $X$ be a smooth rigid space with an action of a finite group $G$\nsatisfying that $X/G$ is represented by a rigid space. We construct sheaves of\n$p$-adic Cherednik algebras on the small \\'etale site of the quotient $X/G$,\nand study some of their properties. The sheaves of $p$-adic Cherednik algebras\nare sheaves of Fr\\'echet $K$-algebras on $X/G$, which can be regarded as\n$p$-adic analytic versions of the sheaves of Cherednik algebras associated to\nthe action of a finite group on a smooth algebraic variety defined by P.\nEtingof. Furthermore, their sections on small enough $G$-invariant affinoid\nspaces are canonically Fr\\'echet-Stein algebras. Along the way, we construct\nsheaves of infinite order twisted differential operators on $X$, we give a\n$G$-equivariant classification of the Atiyah algebras (Picard algebroids) on\n$X$, and study the category of co-admissible modules over a sheaf of infinite\norder twisted differential operators.","main_category":"math.NT","categories":"math.NT,math.AG,math.QA","published":"2025-04-23T13:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.16702v1","title":"QED corrections to meson masses","summary":"We present our progress on calculating leading-order QED corrections to meson\nmasses and bare quark masses. As lattice QCD calculations become more precise,\nthese QED corrections are becoming more important. However, one of the\nchallenges in adding QED effects to QCD calculations is avoiding power-law\nsuppressed finite-volume effects. By using the recently introduced\ninfinite-volume reconstruction method for QED, we are able to avoid this\nproblem and perform calculations with exponentially-suppressed finite-volume\neffects.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-23T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.16743v1","title":"Implementing AI Bill of Materials (AI BOM) with SPDX 3.0: A\n  Comprehensive Guide to Creating AI and Dataset Bill of Materials","summary":"A Software Bill of Materials (SBOM) is becoming an increasingly important\ntool in regulatory and technical spaces to introduce more transparency and\nsecurity into a project's software supply chain.\n  Artificial intelligence (AI) projects face unique challenges beyond the\nsecurity of their software, and thus require a more expansive approach to a\nbill of materials. In this report, we introduce the concept of an AI-BOM,\nexpanding on the SBOM to include the documentation of algorithms, data\ncollection methods, frameworks and libraries, licensing information, and\nstandard compliance.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-23T14:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.16765v1","title":"Geometry of T1 transitions in epithelia","summary":"The flows of tissues of epithelial cells often involve T1 transitions. These\nneighbour exchanges are irreversible rearrangements crossing an energy barrier.\nHere, by an exact geometric construction, I determine this energy barrier for\ngeneral, isolated T1 transitions dominated by line tensions. I show how\ndeviations from regular cell packing reduce this energy barrier, but find that\nline tension fluctuations increase it on average. By another exact\nconstruction, I show how nonlinear tensions in vertex models of epithelial\ntissues also resist T1 transitions. My results thus form the basis for\ncoarse-grained descriptions of cell neighbour exchanges in continuum models of\nepithelia.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-23T14:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.16773v1","title":"On integrability of tri-vector deformed Type II string","summary":"We analyse dynamics of the closed Type IIA and IIB string on various\ntri-vector deformed background searching for signatures of integrability. Using\nnumerical methods we construct Poincar\\'e sections for particular embeddings of\nthe string and show that these are not destroyed under tri-vector deformation.\nWe find that the corresponding Lyapunov exponents decay showing that\ntrajectories do not diverge.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T14:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.16781v1","title":"Strain Effect on Rashba Splitting and Phonon Scattering to Improve\n  Thermoelectric Performance of 2D Heterobilayer MoTe$_{2}$/PtS$_{2}$","summary":"Rashba spin-orbit coupling significantly modifies the electronic band\nstructure in two-dimensional (2D) van der Waals (vdW) heterobilayers, which may\nenhance their thermoelectric (TE) properties. In this study, we use\nfirst-principles calculations and Boltzmann transport theory to explore the\nstrain effect on the TE performance of the 2D vdW heterobilayer\nMoTe$_{2}$/PtS$_{2}$. A strong Rashba spin-splitting is observed in the valence\nband, resulting in an increase in the Seebeck coefficient for p-type. The\nlattice thermal conductivity of MoTe$_{2}$/PtS$_{2}$ is remarkably low about of\n0.6 Wm$^{-1}$K$^{-1}$ at $T = 300$ K due to large anharmonic scattering.\nFurthermore, biaxial strain enhances the power factor (PF) by introducing band\nconvergence. At a strain of 2\\%, the optimal PF for the n-type material reaches\n170 $\\mu$W/cmK$^{2}$, indicating approximately 84.78\\% increase compared to the\nunstrained state (92 $\\mu$W/cmK$^{2}$). Given the low lattice thermal\nconductivity, the optimized figure of merit $ZT$ achieves up to 0.88 at 900 K\nfor n-type. Our findings indicate that MoTe$_{2}$/PtS$_{2}$ is a highly\npromising candidate for 2D heterobilayer TE materials, owing to its strong\nRashba splitting and significant anharmonicity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-23T14:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.16787v1","title":"Credible plan-driven RAG method for Multi-hop Question Answering","summary":"Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.0","published":"2025-04-23T15:03:17Z"}
{"aid":"http://arxiv.org/abs/2504.16814v1","title":"Association-Based Track-Before-Detect with Object Contribution\n  Probabilities","summary":"Multiobject tracking provides situational awareness that enables new\napplications for modern convenience, applied ocean sciences, public safety, and\nhomeland security. In many multiobject tracking applications, including radar\nand sonar tracking, after coherent prefiltering of the received signal,\nmeasurement data is typically structured in cells, where each cell represent,\ne.g., a different range and bearing value. While conventional detect-then-track\n(DTT) multiobject tracking approaches convert the cell-structured data within a\ndetection phase into so-called point measurements in order to reduce the amount\nof data, track-before-detect (TBD) methods process the cell-structured data\ndirectly, avoiding a potential information loss. However, many TBD tracking\nmethods are computationally intensive and achieve a reduced tracking accuracy\nwhen objects interact, i.e., when they come into close proximity. We here\ncounteract these difficulties by introducing the concept of probabilistic\nobject-to-cell contributions. As many conventional DTT methods, our approach\nuses a probabilistic association of objects with data cells, and a new object\ncontribution model with corresponding object contribution probabilities to\nfurther associate cell contributions to objects that occupy the same data cell.\nFurthermore, to keep the computational complexity and filter runtimes low, we\nhere use an efficient Poisson multi-Bernoulli filtering approach in combination\nwith the application of belief propagation for fast probabilistic data\nassociation. We demonstrate numerically that our method achieves significantly\nincreased tracking performance compared to state-of-the-art TBD tracking\napproaches, where performance differences are particularly pronounced when\nmultiple objects interact.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T15:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.16819v1","title":"Using games and universal trees to characterise the nondeterministic\n  index of tree languages","summary":"The parity index problem of tree automata asks, given a regular tree language\n$L$ and a set of priorities $J$, is $L$ $J$-feasible, that is, recognised by a\nnondeterministic parity automaton with priorities $J$? This is a long-standing\nopen problem, of which only a few sub-cases and variations are known to be\ndecidable. In a significant but technically difficult step, Colcombet and\nL\\\"oding reduced the problem to the uniform universality of distance-parity\nautomata. In this article, we revisit the index problem using tools from the\nparity game literature.\n  We add some counters to Lehtinen's register game, originally used to solve\nparity games in quasipolynomial time, and use this novel game to characterise\n$J$-feasibility. This provides a alternative proof to Colcombet and L\\\"oding's\nreduction.\n  We then provide a second characterisation, based on the notion of attractor\ndecompositions and the complexity of their structure, as measured by a\nparameterised version of their Strahler number, which we call $n$-Strahler\nnumber. Finally, we rephrase this result using the notion of universal tree\nextended to automata: a guidable automaton recognises a $[1,2j]$-feasible\nlanguage if and only if it admits a universal tree with $n$-Strahler number\n$j$, for some $n$. In particular, a language recognised by a guidable automaton\n$A$ is B\\\"uchi-feasible if and only if there is a uniform bound $n\\in\n\\mathbb{N}$ such that all trees in the language admit an accepting run with an\nattractor decomposition of width bounded by $n$, or, equivalently, if and only\n$A$ admits a \\textit{finite} universal tree.\n  While we do not solve the decidability of the index problem, our work makes\nthe state-of-the-art more accessible and brings to light the deep relationships\nbetween the $J$-feasibility of a language and attractor decompositions,\nuniversal trees and Lehtinen's register game.","main_category":"cs.FL","categories":"cs.FL,F.4.3","published":"2025-04-23T15:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.16828v1","title":"Process Reward Models That Think","summary":"Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-23T15:44:54Z"}
{"aid":"http://arxiv.org/abs/2504.16876v1","title":"New Primal-Dual Algorithm for Convex Problems","summary":"Primal-dual algorithm (PDA) is a classic and popular scheme for\nconvex-concave saddle point problems. It is universally acknowledged that the\nproximal terms in the subproblems about the primal and dual variables are\ncrucial to the convergence theory and numerical performance of primal-dual\nalgorithms. By taking advantage of the information from the current and\nprevious iterative points, we exploit two new proximal terms for the\nsubproblems about the primal and dual variables. Based on two new proximal\nterms, we present a new primal-dual algorithm for convex-concave saddle point\nproblems with bilinear coupling terms and establish its global convergence and\nO(1/N ) ergodic convergence rate. When either the primal function or the dual\nfunction is strongly convex, we accelerate the above proposed algorithm and\nshow that the corresponding algorithm can achieve O(1/N^2) convergence rate.\nSince the conditions for the stepsizes of the proposed algorithm are related\ndirectly to the spectral norm of the linear transform, which is difficult to\nobtain in some applications, we also introduce a linesearch strategy for the\nabove proposed primal-dual algorithm and establish its global convergence and\nO(1/N ) ergodic convergence rate . Some numerical experiments are conducted on\nmatrix game and LASSO problems by comparing with other state-of-the-art\nalgorithms, which demonstrate the effectiveness of the proposed three\nprimal-dual algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.16880v1","title":"Quantum circuits for simulating linear interferometers","summary":"Motivated by recent proposals for quantum proof of work protocols, we\ninvestigate approaches for simulating linear optical interferometers using\ndigital quantum circuits. We focus on a second quantisation approach, where the\nquantum computer's registers represent optical modes. We can then use standard\nquantum optical techniques to decompose the unitary matrix describing an\ninterferometer into an array of $2\\times 2$ unitaries, which are subsequently\nsynthesised into quantum circuits and stitched together to complete the\ncircuit. For an $m$ mode interferometer with $n$ identical photons, this method\nrequires approximately $\\mathcal{O}(m \\log(n))$ qubits and a circuit depth of\n$\\mathcal{O}(m n^4 \\log_2(n) \\: \\textrm{polylog}(n^4 / \\epsilon))$. We present\na software package Aquinas (A QUantum INterferometer ASsembler) that uses this\napproach to generate such quantum circuits. For reference, an arbitrary five\nmode interferometer with two identical photons is compiled to a 10 qubit\nquantum circuit with a depth of 1972.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T16:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.16896v1","title":"Memory-efficient Sketch Acceleration for Handling Large Network Flows on\n  FPGAs","summary":"Sketch-based algorithms for network traffic monitoring have drawn increasing\ninterest in recent years due to their sub-linear memory efficiency and high\naccuracy. As the volume of network traffic grows, software-based sketch\nimplementations cannot match the throughput of the incoming network flows.\nFPGA-based hardware sketch has shown better performance compared to software\nrunning on a CPU when handling these packets. Among the various sketch\nalgorithms, Count-min sketch is one of the most popular and efficient. However,\ndue to the limited amount of on-chip memory, the FPGA-based count-Min sketch\naccelerator suffers from performance drops as network traffic grows. In this\nwork, we propose a hardware-friendly architecture with a variable width memory\ncounter for count-min sketch. Our architecture provides a more compact design\nto store the sketch data structure effectively, allowing us to support larger\nhash tables and reduce overestimation errors. The design makes use of a\nP4-based programmable data plane and the AMD OpenNIC shell. The design is\nimplemented and verified on the Open Cloud Testbed running on AMD Alveo U280s\nand can keep up with the 100 Gbit link speed.","main_category":"cs.AR","categories":"cs.AR,cs.NI","published":"2025-04-23T17:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.16898v1","title":"Texture: Structured Exploration of Text Datasets","summary":"Exploratory analysis of a text corpus is essential for assessing data quality\nand developing meaningful hypotheses. Text analysis relies on understanding\ndocuments through structured attributes spanning various granularities of the\ndocuments such as words, phrases, sentences, topics, or clusters. However,\ncurrent text visualization tools typically adopt a fixed representation\ntailored to specific tasks or domains, requiring users to switch tools as their\nanalytical goals change. To address this limitation, we present Texture, a\ngeneral-purpose interactive text exploration tool. Texture introduces a\nconfigurable data schema for representing text documents enriched with\ndescriptive attributes. These attributes can appear at arbitrary levels of\ngranularity in the text and possibly have multiple values, including\ndocument-level attributes, multi-valued attributes (e.g., topics), fine-grained\nspan-level attributes (e.g., words), and vector embeddings. The system then\ncombines existing interactive methods for text exploration into a single\ninterface that provides attribute overview visualizations, supports\ncross-filtering attribute charts to explore subsets, uses embeddings for a\ndataset overview and similar instance search, and contextualizes filters in the\nactual documents. We evaluated Texture through a two-part user study with 10\nparticipants from varied domains who each analyzed their own dataset in a\nbaseline session and then with Texture. Texture was able to represent all of\nthe previously derived dataset attributes, enabled participants to more quickly\niterate during their exploratory analysis, and discover new insights about\ntheir data. Our findings contribute to the design of scalable, interactive, and\nflexible exploration systems that improve users' ability to make sense of text\ndata.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.16909v1","title":"The CKN inequality for spinors: symmetry and symmetry breaking","summary":"This paper is devoted to Sobolev interpolation inequalities for spinors, with\nweights of Caffarelli-Kohn-Nirenberg (CKN) type. In view of the corresponding\nresults for scalar functions, a natural question is to determine whether\noptimal spinors have symmetry properties, or whether spinors with symmetry\nproperties are linearly unstable, in which case we shall say that symmetry\nbreaking occurs. What symmetry means has to be carefully defined and the\noverall picture turns out to be richer than in the scalar case. So far, no\nsymmetrization technique is available in the spinorial case. We can however\ndetermine a range of the parameters for which symmetry holds using a detailed\nanalysis based mostly on spectral methods.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-23T17:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.16917v1","title":"Application of an attention-based CNN-BiLSTM framework for in vivo\n  two-photon calcium imaging of neuronal ensembles: decoding complex bilateral\n  forelimb movements from unilateral M1","summary":"Decoding behavior, such as movement, from multiscale brain networks remains a\ncentral objective in neuroscience. Over the past decades, artificial\nintelligence and machine learning have played an increasingly significant role\nin elucidating the neural mechanisms underlying motor function. The advancement\nof brain-monitoring technologies, capable of capturing complex neuronal signals\nwith high spatial and temporal resolution, necessitates the development and\napplication of more sophisticated machine learning models for behavioral\ndecoding. In this study, we employ a hybrid deep learning framework, an\nattention-based CNN-BiLSTM model, to decode skilled and complex forelimb\nmovements using signals obtained from in vivo two-photon calcium imaging. Our\nfindings demonstrate that the intricate movements of both ipsilateral and\ncontralateral forelimbs can be accurately decoded from unilateral M1 neuronal\nensembles. These results highlight the efficacy of advanced hybrid deep\nlearning models in capturing the spatiotemporal dependencies of neuronal\nnetworks activity linked to complex movement execution.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.LG","published":"2025-04-23T17:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.17235v1","title":"Cyclic Nielsen realization for del Pezzo surfaces","summary":"The cyclic Nielsen realization problem for a closed, oriented manifold asks\nwhether any mapping class of finite order can be represented by a homeomorphism\nof the same order. In this article, we resolve the smooth, metric, and complex\ncyclic Nielsen realization problem for certain \"irreducible\" mapping classes on\nthe family of smooth 4-manifolds underlying del Pezzo surfaces. Both positive\nand negative examples of realizability are provided in various settings. Our\ntechniques are varied, synthesizing results from reflection group theory and\n4-manifold topology.","main_category":"math.GT","categories":"math.GT,math.AG","published":"2025-04-24T04:11:04Z"}
{"aid":"http://arxiv.org/abs/2504.17242v1","title":"Rapid and Scalable Synthesis of Alkali Metal-Intercalated C$_{60}$\n  Superconductors","summary":"Alkali metal-intercalated C$_{60}$, $A_3$$C_{60}$ ($A$ = K, Rb, Cs, and their\ncombinations), holds significant potential for practical applications due to\nits high superconducting transition temperature (33 K), high upper critical\nfield (900 kOe), and isotropic superconductivity. However, application-oriented\nresearch has been limited by the lack of an efficient $A_3$$C_{60}$ synthesis\nprocess. In this study, we demonstrate a rapid and scalable synthesis of\n$A_3$$C_{60}$ ($A$ = K, Rb, and Cs$_{1/3}$Rb$_{2/3}$) via direct mixing of $A$\nand C$_{60}$, realizing the fabrication of high-quality sintered $A_3$$C_{60}$\npellets within just 1 hour of heating at 200-300{\\deg}C. The pellets exhibited\nlarge superconducting shielding volume fractions with sharp transitions, and\nthe relationship between the lattice constant and transition temperature was in\ngood agreement with previous reports. This direct mixing method enables simple\nand rapid production of large quantities of $A_3$$C_{60}$, which is expected to\naccelerate research into applications such as superconducting wires and bulk\nmagnets.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-24T04:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17246v1","title":"A Sandwich Model for Changing-Look AGNs","summary":"The spectral variability of changing-look active galactic nuclei (CL-AGNs)\noccurred on timescales of years to tens of years, posing a significant\nchallenge to the standard thin disk model. In this work, we propose a sandwich\nmodel, including an optically thick disk in the mid-plane (Disk 1) and two\ndisks of low effective optical depth on both sides (Disk 2). These two types of\ndisks are coupled with magnetic fields, which allow viscous torque interaction\nbetween them. As a consequence, the radial velocity of Disk 1 can increase by\nup to three orders of magnitude compared to the standard thin disk, leading to\nan equivalent decrease in the accretion timescale. Therefore, such a sandwich\nmodel can account for the rapid variability in CL-AGNs. In addition, we also\ndiscuss the influence of the magnetic pressure on Disk 2. When Disk 2 is\ndominated by the magnetic pressure, it resembles a \"warm corona\", which is\nresponsible for the soft X-ray excess.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-24T04:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.17256v1","title":"A Comment on \"e-PoS: Making PoS Decentralized and Fair\"","summary":"Proof-of-Stake (PoS) is a prominent Sybil control mechanism for\nblockchain-based systems. In \"e-PoS: Making PoS Decentralized and Fair,\" Saad\net al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance\nPoS applications' decentralization and fairness. In this comment paper, we\naddress a misunderstanding in the work of Saad et al. The conventional\nProof-of-Stake model that causes the fairness problem does not align with the\ngeneral concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies\nmentioned in their paper.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T05:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.17267v1","title":"MV-Crafter: An Intelligent System for Music-guided Video Generation","summary":"Music videos, as a prevalent form of multimedia entertainment, deliver\nengaging audio-visual experiences to audiences and have gained immense\npopularity among singers and fans. Creators can express their interpretations\nof music naturally through visual elements. However, the creation process of\nmusic video demands proficiency in script design, video shooting, and\nmusic-video synchronization, posing significant challenges for\nnon-professionals. Previous work has designed automated music video generation\nframeworks. However, they suffer from complexity in input and poor output\nquality. In response, we present MV-Crafter, a system capable of producing\nhigh-quality music videos with synchronized music-video rhythm and style. Our\napproach involves three technical modules that simulate the human creation\nprocess: the script generation module, video generation module, and music-video\nsynchronization module. MV-Crafter leverages a large language model to generate\nscripts considering the musical semantics. To address the challenge of\nsynchronizing short video clips with music of varying lengths, we propose a\ndynamic beat matching algorithm and visual envelope-induced warping method to\nensure precise, monotonic music-video synchronization. Besides, we design a\nuser-friendly interface to simplify the creation process with intuitive editing\nfeatures. Extensive experiments have demonstrated that MV-Crafter provides an\neffective solution for improving the quality of generated music videos.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-24T05:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.17277v1","title":"ExOSITO: Explainable Off-Policy Learning with Side Information for\n  Intensive Care Unit Blood Test Orders","summary":"Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T06:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.17280v1","title":"EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy","summary":"The field of keypoint extraction, which is essential for vision applications\nlike Structure from Motion (SfM) and Simultaneous Localization and Mapping\n(SLAM), has evolved from relying on handcrafted methods to leveraging deep\nlearning techniques. While deep learning approaches have significantly improved\nperformance, they often incur substantial computational costs, limiting their\ndeployment in real-time edge applications. Efforts to create lightweight neural\nnetworks have seen some success, yet they often result in trade-offs between\nefficiency and accuracy. Additionally, the high-dimensional descriptors\ngenerated by these networks poses challenges for distributed applications\nrequiring efficient communication and coordination, highlighting the need for\ncompact yet competitively accurate descriptors. In this paper, we present\nEdgePoint2, a series of lightweight keypoint detection and description neural\nnetworks specifically tailored for edge computing applications on embedded\nsystem. The network architecture is optimized for efficiency without\nsacrificing accuracy. To train compact descriptors, we introduce a combination\nof Orthogonal Procrustes loss and similarity loss, which can serve as a general\napproach for hypersphere embedding distillation tasks. Additionally, we offer\n14 sub-models to satisfy diverse application requirements. Our experiments\ndemonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA)\naccuracy and efficiency across various challenging scenarios while employing\nlower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2\noffers significant advantages in flexibility, robustness, and versatility.\nConsequently, EdgePoint2 emerges as a highly competitive option for visual\ntasks, especially in contexts demanding adaptability to diverse computational\nand communication constraints.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T06:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.17294v1","title":"Higher-Spin Currents and Flows in Auxiliary Field Sigma Models","summary":"We study local, higher-spin conserved currents in integrable $2d$ sigma\nmodels that have been deformed via coupling to auxiliary fields. These currents\ngenerate integrability-preserving flows introduced by Smirnov and\nZamolodchikov. For auxiliary field (AF) deformations of a free boson, we prove\nthat local spin-$n$ currents exist for all $n$ and give recursion relations\nthat characterize Smirnov-Zamolodchikov (SZ) flows driven by these currents. We\nthen show how to construct spin-$2n$ currents in a unified class of auxiliary\nfield sigma models with common structure -- including AF theories based on the\nprincipal chiral model (PCM), its non-Abelian T-dual, (bi-)Yang-Baxter\ndeformations of the PCM, and symmetric space models -- for interaction\nfunctions of one variable, and describe SZ flows driven by any function of the\nstress tensor in these cases. Finally, we give perturbative solutions for\nspin-$3$ SZ flows in any member of our unified class of AF models with\nunderlying $\\mathfrak{su}(3)$ algebra. Part of our analysis shows that the\nclass of AF deformations can be extended by allowing the interaction function\nto depend on a larger set of variables than has previously been considered.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,nlin.SI","published":"2025-04-24T06:42:51Z"}
{"aid":"http://arxiv.org/abs/2504.17297v1","title":"Knapsack on Graphs with Relaxed Neighborhood Constraints","summary":"In the knapsack problems with neighborhood constraints that were studied\nbefore, the input is a graph $\\mathcal{G}$ on a set $\\mathcal{V}$ of items,\neach item $v \\in \\mathcal{V}$ has a weight $w_v$ and profit $p_v$, the size $s$\nof the knapsack, and the demand $d$. The goal is to compute if there exists a\nfeasible solution whose total weight is at most $s$ and total profit is at most\n$d$. Here, feasible solutions are all subsets $\\mathcal{S}$ of the items such\nthat, for every item in $\\mathcal{S}$, at least one of its neighbors in\n$\\mathcal{G}$ is also in $\\mathcal{S}$ for \\hor, and all its neighbors in\n$\\mathcal{G}$ are also in $\\mathcal{S}$ for\n\\hand~\\cite{borradaile2012knapsack}. We study a relaxation of the above\nproblems. Specifically, we allow all possible subsets of items to be feasible\nsolutions. However, only those items for which we pick at least one or all of\nits neighbor (out-neighbor for directed graph) contribute to profit whereas\nevery item picked contribute to the weight; we call the corresponding problems\n\\sor and \\sand. We show that both \\sor and \\sand are strongly \\NPC even on\nundirected graphs. Regarding parameterized complexity, we show both \\sor and\n\\hor are \\WTH parameterized by the size $s$ of the knapsack size.\nInterestingly, both \\sand and \\hand are \\WOH parameterized by knapsack size,\n$s$ plus profit demand, $d$ and also parameterized by solution size, $b$. For\n\\sor and \\hor, we present a randomized color-coding-based pseudo-\\FPT\nalgorithm, parameterized by the solution size $b$, and consequently by the\ndemand $d$. We then consider the treewidth of the input graph as our parameter\nand design pseudo fixed-parameter tractable (\\FPT) algorithm parameterized by\ntreewidth, $\\text{tw}$ for all variants. Finally, we present an additive $1$\napproximation for \\sor when both the weight and profit of every vertex is $1$.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-24T06:46:28Z"}
{"aid":"http://arxiv.org/abs/2504.17307v1","title":"An Extensible Software Transport Layer for GPU Networking","summary":"Fast-evolving machine learning (ML) workloads have increasing requirements\nfor networking. However, host network transport on RDMA NICs is hard to evolve,\ncausing problems for ML workloads. For example, single-path RDMA traffic is\nprone to flow collisions that severely degrade collective communication\nperformance. We present UCCL, an extensible software transport layer to evolve\nGPU networking. UCCL decouples the data path and control path of existing RDMA\nNICs and efficiently runs the control-path transport on host CPUs. This\nsoftware extensibility brings in transport innovations that cannot be achieved\nin hardware for ML workloads, e.g., a multipath transport to resolve flow\ncollisions. ML collectives atop UCCL achieve up to 3.3x higher performance\ncompared to an industry solution.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T07:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.17332v1","title":"Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation\n  Detection","summary":"In the digital era, social media has become a major conduit for information\ndissemination, yet it also facilitates the rapid spread of misinformation.\nTraditional misinformation detection methods primarily focus on surface-level\nfeatures, overlooking the crucial roles of human empathy in the propagation\nprocess. To address this gap, we propose the Dual-Aspect Empathy Framework\n(DAE), which integrates cognitive and emotional empathy to analyze\nmisinformation from both the creator and reader perspectives. By examining\ncreators' cognitive strategies and emotional appeals, as well as simulating\nreaders' cognitive judgments and emotional responses using Large Language\nModels (LLMs), DAE offers a more comprehensive and human-centric approach to\nmisinformation detection. Moreover, we further introduce an empathy-aware\nfiltering mechanism to enhance response authenticity and diversity.\nExperimental results on benchmark datasets demonstrate that DAE outperforms\nexisting methods, providing a novel paradigm for multimodal misinformation\ndetection.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T07:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.17345v1","title":"A Rellich-type theorem for the Helmholtz equation in a junction of\n  stratified media","summary":"We prove that there are no non-zero square-integrable solutions to a\ntwo-dimensional Helmholtz equation in some unbounded inhomogeneous domains\nwhich represent junctions of stratified media. More precisely, we consider\ndomains that are unions of three half-planes, where each half-plane is\nstratified in the direction orthogonal to its boundary. As for the well-known\nRellich uniqueness theorem for a homogeneous exterior domain, our result does\nnot require any boundary condition. Our proof is based on half-plane\nrepresentations of the solution which are derived through a generalization of\nthe Fourier transform adapted to stratified media. A byproduct of our result is\nthe absence of trapped modes at the junction of open waveguides as soon as the\nangles between branches are greater than $\\pi$/2.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-24T08:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.17398v1","title":"An Inverse Source Problem for Semilinear Stochastic Hyperbolic Equations","summary":"This paper investigates an inverse source problem for general semilinear\nstochastic hyperbolic equations. Motivated by the challenges arising from both\nrandomness and nonlinearity, we develop a globally convergent iterative\nregularization method that combines Carleman estimate with fixed-point\niteration. Our approach enables the reconstruction of the unknown source\nfunction from partial lateral Cauchy data, without requiring a good initial\nguess. We establish a new Carleman estimate for stochastic hyperbolic equations\nand prove the convergence of the proposed method in weighted spaces.\nFurthermore, we design an efficient numerical algorithm that avoids solving\nbackward stochastic partial differential equations and is robust to randomness\nin both the model and the data. Numerical experiments are provided to\ndemonstrate the effectiveness of the method.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-24T09:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.17407v1","title":"Stability of Stochastically Forced Solitons in the Korteweg-de Vries\n  Equation","summary":"We study the stability and dynamics of solitons in the Korteweg-de Vries\n(KdV) equation in the presence of noise and deterministic forcing. The noise is\nspace-dependent and statistically translation-invariant. We show that, for\nsmall forcing, solitons remain close to the family of traveling waves in a\nweighted Sobolev norm, with high probability. We study the effective dynamics\nof the soliton amplitude and position via their variational phase, for which we\nderive explicit modulation equations. The stability result holds on a time\nscale where the deterministic forcing induces significant amplitude modulation.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-24T09:58:03Z"}
{"aid":"http://arxiv.org/abs/2504.17427v1","title":"Beyond Whole Dialogue Modeling: Contextual Disentanglement for\n  Conversational Recommendation","summary":"Conversational recommender systems aim to provide personalized\nrecommendations by analyzing and utilizing contextual information related to\ndialogue. However, existing methods typically model the dialogue context as a\nwhole, neglecting the inherent complexity and entanglement within the dialogue.\nSpecifically, a dialogue comprises both focus information and background\ninformation, which mutually influence each other. Current methods tend to model\nthese two types of information mixedly, leading to misinterpretation of users'\nactual needs, thereby lowering the accuracy of recommendations. To address this\nissue, this paper proposes a novel model to introduce contextual\ndisentanglement for improving conversational recommender systems, named\nDisenCRS. The proposed model DisenCRS employs a dual disentanglement framework,\nincluding self-supervised contrastive disentanglement and counterfactual\ninference disentanglement, to effectively distinguish focus information and\nbackground information from the dialogue context under unsupervised conditions.\nMoreover, we design an adaptive prompt learning module to automatically select\nthe most suitable prompt based on the specific dialogue context, fully\nleveraging the power of large language models. Experimental results on two\nwidely used public datasets demonstrate that DisenCRS significantly outperforms\nexisting conversational recommendation models, achieving superior performance\non both item recommendation and response generation tasks.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T10:33:26Z"}
{"aid":"http://arxiv.org/abs/2504.17437v1","title":"Lectures on measurement in quantum field theory","summary":"These lectures present a brief introduction to measurement theory for QFT in\npossibly curved spacetimes introduced by the author and R. Verch [Comm. Math.\nPhys. 378 (2020) 851-889]. Topics include: a brief introduction to algebraic\nQFT, measurement schemes in QFT, state updates, multiple measurements and the\nresolution of Sorkin's \"impossible measurement\" problem. Examples using\nsuitable theories based on Green hyperbolic operators are given, and the\ninterpretational significance of the framework is briefly considered. The basic\nstyle is to give details relating to QFT while taking for granted various facts\nfrom the theory of globally hyperbolic spacetimes.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP,quant-ph","published":"2025-04-24T10:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.17441v1","title":"Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object\n  Understanding","summary":"Humans can resort to long-form inspection to build intuition on predicting\nthe 3D configurations of unseen objects. The more we observe the object motion,\nthe better we get at predicting its 3D state immediately. Existing systems\neither optimize underlying representations from multi-view observations or\ntrain a feed-forward predictor from supervised datasets. We introduce\nPredict-Optimize-Distill (POD), a self-improving framework that interleaves\nprediction and optimization in a mutually reinforcing cycle to achieve better\n4D object understanding with increasing observation time. Given a multi-view\nobject scan and a long-form monocular video of human-object interaction, POD\niteratively trains a neural network to predict local part poses from RGB\nframes, uses this predictor to initialize a global optimization which refines\noutput poses through inverse rendering, then finally distills the results of\noptimization back into the model by generating synthetic self-labeled training\ndata from novel viewpoints. Each iteration improves both the predictive model\nand the optimized motion trajectory, creating a virtuous cycle that bootstraps\nits own training data to learn about the pose configurations of an object. We\nalso introduce a quasi-multiview mining strategy for reducing depth ambiguity\nby leveraging long video. We evaluate POD on 14 real-world and 5 synthetic\nobjects with various joint types, including revolute and prismatic joints as\nwell as multi-body configurations where parts detach or reattach independently.\nPOD demonstrates significant improvement over a pure optimization baseline\nwhich gets stuck in local minima, particularly for longer videos. We also find\nthat POD's performance improves with both video length and successive\niterations of the self-improving cycle, highlighting its ability to scale\nperformance with additional observations and looped refinement.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T11:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17450v1","title":"Optimizing thermoelectric performance of graphene antidot lattices via\n  quantum transport and machine-learning molecular dynamics simulations","summary":"Thermoelectric materials, which can convert waste heat to electricity or be\nutilized as solid-state coolers, hold promise for sustainable energy\napplications. However, optimizing thermoelectric performance remains a\nsignificant challenge due to the complex interplay between electronic and\nthermal transport properties. In this work, we systematically optimize $ZT$ in\ngraphene antidot lattices (GALs), nanostructured graphene sheets with periodic\nnanopores characterized by two geometric parameters: the hexagonal unit cell\nside length $L$ and the antidot radius $R$. The lattice thermal conductivity is\ndetermined through machine-learned potential-driven molecular dynamics (MD)\nsimulations, while electronic transport properties are computed using\nlinear-scaling quantum transport in combination with MD trajectories based on a\nbond-length-dependent tight-binding model. This method is able to account for\nelectron-phonon scattering, allowing access to diffusive transport in\nlarge-scale systems, overcoming limitations of previous methods based on\nnonequilibrium Green function formalism. Our results show that the introduction\nof the antidots effectively decouples lattice and electronic transport and lead\nto a favorable and significant violation of the Wiedemann-Franz law. We find\nthat optimal $ZT$ values occur in GALs with intermediate $L$ and $R$, closely\ncorrelated with peak power factor values. Notably, thermoelectric performance\npeaks near room temperature, with maximal $ZT$ values approaching 2,\nhighlighting GALs as promising candidates for high-performance thermoelectric\nenergy conversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-24T11:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.17471v1","title":"GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework","summary":"Gossip Learning (GL) is a decentralized learning paradigm where users\niteratively exchange and aggregate models with a small set of neighboring\npeers. Recent GL approaches rely on dynamic communication graphs built and\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\ndynamics, GL can achieve fast convergence even over extremely sparse\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\nattack the RPS protocol to scale up model poisoning. We address this issue by\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\nleverages an estimate of Byzantine presence to set aggregation thresholds with\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\nof poisoned models and obtains these results in up to 9 times sparser graphs\nthan dictated by current theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC","published":"2025-04-24T12:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17475v1","title":"Odd fake $\\mathbb{Q}$ -homology quadrics exist","summary":"We show the existence of odd fake $\\mathbb{Q}$-homology quadrics, namely of\nminimal surfaces $S$ of general type which have the same $\\mathbb{Q}$-homology\nas a smooth quadric $Q \\cong (\\mathbb{P}^1(\\mathbb{C}))^2$, but have an odd\nintersection form on $ H^2(S, \\mathbb{Z})/Tors(S)$, where $Tors(S)$ is the\nTorsion subgroup.\n  Our examples are provided by a special 1-dimensional family of surfaces\nisogenous to a product of unmixed type.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-24T12:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.17522v1","title":"Towards One-Stage End-to-End Table Structure Recognition with Parallel\n  Regression for Diverse Scenarios","summary":"Table structure recognition aims to parse tables in unstructured data into\nmachine-understandable formats. Recent methods address this problem through a\ntwo-stage process or optimized one-stage approaches. However, these methods\neither require multiple networks to be serially trained and perform more\ntime-consuming sequential decoding, or rely on complex post-processing\nalgorithms to parse the logical structure of tables. They struggle to balance\ncross-scenario adaptability, robustness, and computational efficiency. In this\npaper, we propose a one-stage end-to-end table structure parsing network called\nTableCenterNet. This network unifies the prediction of table spatial and\nlogical structure into a parallel regression task for the first time, and\nimplicitly learns the spatial-logical location mapping laws of cells through a\nsynergistic architecture of shared feature extraction layers and task-specific\ndecoding. Compared with two-stage methods, our method is easier to train and\nfaster to infer. Experiments on benchmark datasets show that TableCenterNet can\neffectively parse table structures in diverse scenarios and achieve\nstate-of-the-art performance on the TableGraph-24k dataset. Code is available\nat https://github.com/dreamy-xay/TableCenterNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T13:03:13Z"}
{"aid":"http://arxiv.org/abs/2504.17532v1","title":"Permeation and thermal desorption model of hydrogen in steel: a\n  sensitivity analysis","summary":"This work presents a fully physical model of the hydrogen diffusion and\ntrapping kinetics in metals, integrating permeation and thermal desorption\nwithin a unified framework. Based on the McNabb and Foster approach, it\nrequires only binding energy and number density of trap sites. It correctly\nreproduces the physics of the system and the results of the analytical\nsolutions of the permeation kinetics. It is also capable of reproducing thermal\ndesorption spectra with considerable accuracy. The sensitivity analysis has\nelucidated the relationships among the processing conditions and the parameters\ncommonly used to characterize permeation and thermal desorption experiments. An\nequation empirically derived from the simulation results, expressing the\ndependence of time lag in desorption on specimen thickness, number density of\noccupied trap sites, and cathodic concentration, is proposed. In summary, the\nmodel represents a valuable tool in supporting the interpretation and\nrationalization of experiments also from a quantitative viewpoint.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T13:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.17546v1","title":"An introduction to R package `mvs`","summary":"In biomedical science, a set of objects or persons can often be described by\nmultiple distinct sets of features obtained from different data sources or\nmodalities (called \"multi-view data\"). Classical machine learning methods\nignore the multi-view structure of such data, limiting model interpretability\nand performance. The R package `mvs` provides methods that were designed\nspecifically for dealing with multi-view data, based on the multi-view stacking\n(MVS) framework. MVS is a form of supervised (machine) learning used to train\nmulti-view classification or prediction models. MVS works by training a\nlearning algorithm on each view separately, estimating the predictive power of\neach view-specific model through cross-validation, and then using another\nlearning algorithm to assign weights to the view-specific models based on their\nestimated predictions. MVS is a form of ensemble learning, dividing the large\nmulti-view learning problem into smaller sub-problems. Most of these\nsub-problems can be solved in parallel, making it computationally attractive.\nAdditionally, the number of features of the sub-problems is greatly reduced\ncompared with the full multi-view learning problem. This makes MVS especially\nuseful when the total number of features is larger than the number of\nobservations (i.e., high-dimensional data). MVS can still be applied even if\nthe sub-problems are themselves high-dimensional by adding suitable penalty\nterms to the learning algorithms. Furthermore, MVS can be used to automatically\nselect the views which are most important for prediction. The R package `mvs`\nmakes fitting MVS models, including such penalty terms, easily and openly\naccessible. `mvs` allows for the fitting of stacked models with any number of\nlevels, with different penalty terms, different outcome distributions, and\nprovides several options for missing data handling.","main_category":"stat.CO","categories":"stat.CO,cs.LG,stat.ME,stat.ML","published":"2025-04-24T13:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.17548v1","title":"Quantum Autoencoder for Multivariate Time Series Anomaly Detection","summary":"Anomaly Detection (AD) defines the task of identifying observations or events\nthat deviate from typical - or normal - patterns, a critical capability in IT\nsecurity for recognizing incidents such as system misconfigurations, malware\ninfections, or cyberattacks. In enterprise environments like SAP HANA Cloud\nsystems, this task often involves monitoring high-dimensional, multivariate\ntime series (MTS) derived from telemetry and log data. With the advent of\nquantum machine learning offering efficient calculations in high-dimensional\nlatent spaces, many avenues open for dealing with such complex data. One\napproach is the Quantum Autoencoder (QAE), an emerging and promising method\nwith potential for application in both data compression and AD. However, prior\napplications of QAEs to time series AD have been restricted to univariate data,\nlimiting their relevance for real-world enterprise systems. In this work, we\nintroduce a novel QAE-based framework designed specifically for MTS AD towards\nenterprise scale. We theoretically develop and experimentally validate the\narchitecture, demonstrating that our QAE achieves performance competitive with\nneural-network-based autoencoders while requiring fewer trainable parameters.\nWe evaluate our model on datasets that closely reflect SAP system telemetry and\nshow that the proposed QAE is a viable and efficient alternative for\nsemisupervised AD in real-world enterprise settings.","main_category":"quant-ph","categories":"quant-ph,cs.CR,cs.LG","published":"2025-04-24T13:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.17567v1","title":"Log-concavity of inverse Kazhdan-Lusztig polynomials of paving matroids","summary":"Gao and Xie (2021) conjectured that the inverse Kazhdan-Lusztig polynomial of\nany matroid is log-concave. Although the inverse Kazhdan-Lusztig polynomial may\nnot always have only real roots, we conjecture that the Hadamard product of an\ninverse Kazhdan-Lusztig polynomial of degree $n$ and $(1+t)^n$ has only real\nroots. Using interlacing polynomials and multiplier sequences, we confirm this\nconjecture for paving matroids. This result allows us to confirm the\nlog-concavity conjecture for these matroids by applying Newton's inequalities.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T13:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.17581v1","title":"A non-uniform metal distribution in the ram-pressure stripped M86 group\n  of galaxies","summary":"The chemical enrichment of X-ray-emitting hot halos has primarily been\nstudied in closed-box galaxy clusters. Investigating the metal content of\nlower-mass, open systems can serve as a valuable tracer for understanding their\ndynamical history and the extent of chemical enrichment mechanisms in the\nUniverse. In this context, we use an 85.6 ks XMM-Newton observation to study\nthe spatial distribution of the abundance ratios of Mg, Si, and S with respect\nto Fe in the hot gas of the ram-pressure-stripped M86, which has undergone\nmorphological transformations. We report that the chemical composition in the\nM86 galaxy core is more similar to the rest of the hot gaseous content of the\nUniverse than to its stellar population. This result indicate that even extreme\nsupersonic ram-pressure is insufficient to strip the inner part of a galaxy of\nits hot atmosphere. Comparison with other galaxies undergoing ram-pressure\nstripping suggests that stripping the \"primordial\" atmosphere of a galaxy\nrequires a combination of ram-pressure stripping and strong radio-mechanical\nAGN activity. The X-ray emission structures within M86, the plume and the tail,\nare found to be relatively isothermal. We observe that the Mg/Fe ratio in the\nplume is $3.3\\sigma$ higher than in the M86 galaxy core and is consistent with\nthat in the M86 group outskirts and the Virgo ICM, suggesting that the plume\nmight originate from the low-entropy group gas due to a galaxy-galaxy collision\nrather than from the ram-pressure stripping of the dense galaxy core.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-24T14:11:13Z"}
{"aid":"http://arxiv.org/abs/2504.17608v1","title":"The Cauchy--SzegÃ¶ Projection for domains in $\\mathbb C^n$ with\n  minimal smoothness: weighted theory","summary":"Let $D\\subset\\mathbb C^n$ be a bounded, strongly pseudoconvex domain whose\nboundary $bD$ satisfies the minimal regularity condition of class $C^2$. A 2017\nresult of Lanzani \\& Stein states that the Cauchy--Szeg\\\"{o} projection\n$S_\\omega$ defined with respect to a bounded, positive continuous multiple\n$\\omega$ of induced Lebesgue measure, {maps $L^p(bD, \\omega)$ to $L^p(bD,\n\\omega)$ continuously} for any $1<p<\\infty$. Here we show that $S_\\omega$\nsatisfies explicit quantitative bounds in $L^p(bD, \\Omega)$, for any\n$1<p<\\infty$ and for any $\\Omega$ in the maximal class of\n\\textit{$A_p$}-measures, that is for $\\Omega_p = \\psi_p\\sigma$ where $\\psi_p$\nis a Muckenhoupt $A_p$-weight and $\\sigma$ is the induced Lebesgue measure\n(with $\\omega$'s as above being a sub-class). Earlier results rely upon an\nasymptotic expansion and subsequent pointwise estimates of the Cauchy--Szeg\\\"o\nkernel, but these are unavailable in our setting of minimal regularity {of\n$bD$}; at the same time, more recent techniques that allow to handle domains\nwith minimal regularity (Lanzani--Stein 2017) are not applicable to\n$A_p$-measures. It turns out that the method of {quantitative} extrapolation is\nan appropriate replacement for the missing tools. To finish, we identify a\nclass of holomorphic Hardy spaces defined with respect to $A_p$-measures for\nwhich a meaningful notion of Cauchy--Szeg\\\"o projection can be defined when\n$p=2$.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.17631v1","title":"Modular Cosmic Ray Detector (MCORD) and its Potential Use in Various\n  Physics Experiments, Astrophysics and Geophysics","summary":"As part of the collaboration building a set of detectors for the new\ncollider, our group was tasked with designing and building a large-scale cosmic\nray detector, which was to complement the capabilities of the MPD (Dubna)\ndetec-tor set. The detector was planned as a trigger for cosmic ray particles\nand to be used to calibrate and test other systems. Additional functions were\nto be the detection of pairs of high-energy muons originating from some\nparti-cle decay processes generated during collisions and con-tinuous\nobservation of the cosmic muon stream in order to detect multi muons events.\nFrom the very beginning, the detector was designed as a scalable and universal\ndevice for many applications. The following work will present the basic\nfeatures and parameters of the Modular COsmic Ray Detector (MCORD) and examples\nof its possible use in high energy physics, astrophysics and geology. Thanks to\nits universal nature, MCORD can be potential used as a fast trigger, neutron\nveto detector, muon detector and as a tool in muon tomography.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,physics.app-ph,J.2.m","published":"2025-04-24T15:04:43Z"}
{"aid":"http://arxiv.org/abs/2504.17644v1","title":"Bounded diagonal orbits in homogeneous spaces over function fields","summary":"This paper is about topological rigidity of diagonal group actions on the\nhomogeneous $\\SL_4\\big(\\F(\\!(t^{-1})\\!)\\big)/\\SL_4(\\F[t])$ where $\\F$ is a\nfinite field of characteristic $3$. We show that there is a non-closed\nrelatively compact orbit of the diagonal group.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T15:14:10Z"}
{"aid":"http://arxiv.org/abs/2504.17749v1","title":"MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link\n  Weight Prediction","summary":"Graph Neural Networks (GNNs) have been widely used for various learning\ntasks, ranging from node classification to link prediction. They have\ndemonstrated excellent performance in multiple domains involving\ngraph-structured data. However, an important category of learning tasks, namely\nlink weight prediction, has received less emphasis due to its increased\ncomplexity compared to binary link classification. Link weight prediction\nbecomes even more challenging when considering multilayer networks, where nodes\ncan be interconnected across multiple layers. To address these challenges, we\npropose a new method named Multiplex Spatial Graph Convolution Network (MSGCN),\nwhich spatially embeds information across multiple layers to predict interlayer\nlink weights. The MSGCN model generalizes spatial graph convolution to\nmultiplex networks and captures the geometric structure of nodes across\nmultiple layers. Extensive experiments using data with known interlayer link\ninformation show that the MSGCN model has robust, accurate, and generalizable\nlink weight prediction performance across a wide variety of multiplex network\nstructures.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.19500v1","title":"Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding","summary":"Open-vocabulary 3D scene understanding is pivotal for enhancing physical\nintelligence, as it enables embodied agents to interpret and interact\ndynamically within real-world environments. This paper introduces MPEC, a novel\nMasked Point-Entity Contrastive learning method for open-vocabulary 3D semantic\nsegmentation that leverages both 3D entity-language alignment and point-entity\nconsistency across different point cloud views to foster entity-specific\nfeature representations. Our method improves semantic discrimination and\nenhances the differentiation of unique instances, achieving state-of-the-art\nresults on ScanNet for open-vocabulary 3D semantic segmentation and\ndemonstrating superior zero-shot scene understanding capabilities. Extensive\nfine-tuning experiments on 8 datasets, spanning from low-level perception to\nhigh-level reasoning tasks, showcase the potential of learned 3D features,\ndriving consistent performance gains across varied 3D scene understanding\ntasks. Project website: https://mpec-3d.github.io/","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-28T05:43:14Z"}
{"aid":"http://arxiv.org/abs/2504.19501v1","title":"Spin-Orbit Coupling in Helical Waveguides: A Local Duality Perspective\n  and Emergent Gauge Fields","summary":"Dual symmetry is an intrinsic property of Maxwell's equations, corresponding\nto a global U(1) symmetry in vacuum, with helicity as the associated conserved\nquantity. In this paper, we investigate light propagation in a spin-degenerate\nmedium using a field-theoretical approach and introduce an effective gauge\nfield A_s that emerges from the localization of dual symmetry. Within the\ngeometric optics approximation, we show that the helical trajectory of light\nrays reveals this gauge field as a manifestation of spin-orbit coupling.\nAlthough orbital-orbit coupling also arises in such systems, the spin-orbit\ninteraction possesses deeper physical significance, as it originates from the\nintrinsic dual symmetry embedded in Maxwell's equations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T05:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.19529v1","title":"Adversarial Shallow Watermarking","summary":"Recent advances in digital watermarking make use of deep neural networks for\nmessage embedding and extraction. They typically follow the ``encoder-noise\nlayer-decoder''-based architecture. By deliberately establishing a\ndifferentiable noise layer to simulate the distortion of the watermarked\nsignal, they jointly train the deep encoder and decoder to fit the noise layer\nto guarantee robustness. As a result, they are usually weak against unknown\ndistortions that are not used in their training pipeline. In this paper, we\npropose a novel watermarking framework to resist unknown distortions, namely\nAdversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder\nthat is randomly parameterized and designed to be insensitive to distortions\nfor watermarking extraction. During the watermark embedding, ASW freezes the\nshallow decoder and adversarially optimizes a host image until its updated\nversion (i.e., the watermarked image) stably triggers the shallow decoder to\noutput the watermark message. During the watermark extraction, it accurately\nrecovers the message from the watermarked image by leveraging the insensitive\nnature of the shallow decoder against arbitrary distortions. Our ASW is\ntraining-free, encoder-free, and noise layer-free. Experiments indicate that\nthe watermarked images created by ASW have strong robustness against various\nunknown distortions. Compared to the existing ``encoder-noise layer-decoder''\napproaches, ASW achieves comparable results on known distortions and better\nrobustness on unknown distortions.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-28T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.19534v1","title":"Quantifying Uncertainties in Solar Wind Forecasting Due to Incomplete\n  Solar Magnetic Field Information","summary":"Solar wind forecasting plays a crucial role in space weather prediction, yet\nsignificant uncertainties persist due to incomplete magnetic field observations\nof the Sun. Isolating the solar wind forecasting errors due to these effects is\ndifficult. This study investigates the uncertainties in solar wind models\narising from these limitations. We simulate magnetic field maps with known\nuncertainties, including far-side and polar field variations, as well as\nresolution and sensitivity limitations. These maps serve as input for three\nsolar wind models: the Wang-Sheeley-Arge (WSA), the Heliospheric Upwind\neXtrapolation (HUXt), and the European Heliospheric FORecasting Information\nAsset (EUHFORIA). We analyze the discrepancies in solar wind forecasts,\nparticularly the solar wind speed at Earth's location, by comparing the results\nof these models to a created \"ground truth\" magnetic field map, which is\nderived from a synthetic solar rotation evolution using the Advective Flux\nTransport (AFT) model. The results reveal significant variations within each\nmodel with a RMSE ranging from 59-121 km/s. Further comparison with the\nthermodynamic Magnetohydrodynamic Algorithm outside a Sphere (MAS) model\nindicates that uncertainties in the magnetic field data can lead to even larger\nvariations in solar wind forecasts compared to those within a single model.\nHowever, predicting a range of solar wind velocities based on a cloud of points\naround Earth can help mitigate uncertainties by up to 20-77%.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-28T07:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.19540v1","title":"Event-triggered Robust Model Predictive Control under Hard Computation\n  Resource Constraints","summary":"Model predictive control (MPC) is capable of controlling nonlinear systems\nwith guaranteed constraint satisfaction and stability. However, MPC requires\nsolving optimization problems online periodically, which often exceeds the\nlocal system's computational capabilities. A potential solution is to leverage\nexternal processing, such as a central industrial server. Yet, this central\ncomputer typically serves multiple systems simultaneously, leading to\nsignificant hardware demands due to the need to solve numerous optimization\nproblems concurrently. In this work, we tackle this challenge by developing an\nevent-triggered model predictive control (ET-MPC) that provably stabilizes\nmultiple nonlinear systems under disturbances while solving only optimization\nproblems for a fixed-size subset at any given time. Unlike existing ET-MPC\nmethods, which primarily reduce average computational load yet still require\nhardware capable of handling all systems simultaneously, our approach reduces\nthe worst-case computational load. This significantly lowers central server\nhardware requirements by diminishing peak computational demands. We achieve our\nimprovements by leveraging recent advancements in distributed event-triggered\nlinear control and integrating them with a robust MPC that employs constraint\ntightening.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T07:44:35Z"}
{"aid":"http://arxiv.org/abs/2504.19558v1","title":"Cholic Acid-Based Mixed Micelles as siRNA Delivery Agents for Gene\n  Therapy","summary":"Gene therapy is a promising tool for the treatment of various cancers but is\nhindered by the physico-chemical properties of siRNA and needs a suitable\nvector for the delivery of siRNA to the target tissue. Bile acid-based block\ncopolymers offers certain advantages for the loading and delivery of siRNA\nsince they can efficiently complex siRNA and bile acids are biocompatible\nendogenous molecules. In this study, we demonstrate the use of lipids as\nco-surfactants for the preparation of mixed micelles to improve the siRNA\ndelivery of cholic acid-based block copolymers. Poly(allyl glycidyl ether)\n(PAGE) and poly(ethylene glycol) (PEG) were polymerized on the surface of\ncholic acid to afford a star-shaped block copolymer with four arms\n(CA-PAGE-b-PEG)4. The allyl groups of PAGE were functionalized to bear primary\nor tertiary amines and folic acid was grafted onto the PEG chain end to\nincrease cell uptake. (CA-PAGE-b-PEG)4 functionalized with either primary or\ntertiary amines show high siRNA complexation with close to 100% complexation at\nN/P ratio of 8. Uniform aggregates with diameters between 181 and 188 nm were\nobtained. DOPE, DSPE-PEG2k, and DSPE-PEG5k lipids were added as co-surfactants\nto help stabilize the nanoparticles in the cell culture media. Mixed micelles\nhad high siRNA loading with close to 100% functionalization at N/P ratio of 16\nand diameters ranging from 153 to 221 nm. The presence of lipids in the mixed\nmicelles improved cell uptake with a concomitant siRNA transfection in HeLa and\nHeLa-GFP model cells, respectively.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-28T08:06:36Z"}
{"aid":"http://arxiv.org/abs/2504.19563v1","title":"Characterisation of quadratic spaces over the Hilbert field by means of\n  the orthogonality relation","summary":"An orthoset is a set equipped with a symmetric, irreflexive binary relation.\nWith any (anisotropic) Hermitian space $H$, we may associate the orthoset\n$(P(H),\\perp)$, consisting of the set of one-dimensional subspaces of $H$ and\nthe usual orthogonality relation. $(P(H),\\perp)$ determines $H$ essentially\nuniquely.\n  We characterise in this paper certain kinds of Hermitian spaces by imposing\ntransitivity and minimality conditions on their associated orthosets. By\ngradually considering stricter conditions, we restrict the discussion to a more\nand more narrow class of Hermitian spaces. We are eventually interested in\nquadratic spaces over countable subfields of $\\mathbb R$.\n  A line of an orthoset is the orthoclosure of two distinct element. For an\northoset to be line-symmetric means roughly that its automorphism group acts\ntransitively both on the collection of all lines as well as on each single\nline. Line-symmetric orthosets turn out to be in correspondence with transitive\nHermitian spaces. Furthermore, quadratic orthosets are defined similarly, but\nare required to possess, for each line $\\ell$, a group of automorphisms acting\non $\\ell$ transitively and commutatively. We show the correspondence of\nquadratic orthosets with transitive quadratic spaces over ordered fields. We\nfinally specify those quadratic orthosets that are, in a natural sense,\nminimal: for a finite $n \\geq 4$, the orthoset $(P(R^n),\\perp)$, where $R$ is\nthe Hilbert field, has the property of being embeddable into any other\nquadratic orthoset of rank $n$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T08:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.19583v1","title":"Graph-Based Spectral Decomposition for Parameter Coordination in\n  Language Model Fine-Tuning","summary":"This paper proposes a parameter collaborative optimization algorithm for\nlarge language models, enhanced with graph spectral analysis. The goal is to\nimprove both fine-tuning efficiency and structural awareness during training.\nIn the proposed method, the parameters of a pre-trained language model are\ntreated as nodes in a graph. A weighted graph is constructed, and Laplacian\nspectral decomposition is applied to enable frequency-domain modeling and\nstructural representation of the parameter space. Based on this structure, a\njoint loss function is designed. It combines the task loss with a spectral\nregularization term to facilitate collaborative updates among parameters. In\naddition, a spectral filtering mechanism is introduced during the optimization\nphase. This mechanism adjusts gradients in a structure-aware manner, enhancing\nthe model's training stability and convergence behavior. The method is\nevaluated on multiple tasks, including traditional fine-tuning comparisons,\nfew-shot generalization tests, and convergence speed analysis. In all settings,\nthe proposed approach demonstrates superior performance. The experimental\nresults confirm that the spectral collaborative optimization framework\neffectively reduces parameter perturbations and improves fine-tuning quality\nwhile preserving overall model performance. This work contributes significantly\nto the field of artificial intelligence by advancing parameter-efficient\ntraining methodologies for large-scale models, reinforcing the importance of\nstructural signal processing in deep learning optimization, and offering a\nrobust, generalizable framework for enhancing language model adaptability and\nperformance.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-28T08:42:35Z"}
{"aid":"http://arxiv.org/abs/2504.19602v1","title":"Soft-Label Caching and Sharpening for Communication-Efficient Federated\n  Distillation","summary":"Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-28T09:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.19639v1","title":"A Unified Benchmark of Federated Learning with Kolmogorov-Arnold\n  Networks for Medical Imaging","summary":"Federated Learning (FL) enables model training across decentralized devices\nwithout sharing raw data, thereby preserving privacy in sensitive domains like\nhealthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN)\narchitectures against traditional MLP across six state-of-the-art FL algorithms\non a blood cell classification dataset. Notably, our experiments demonstrate\nthat KAN can effectively replace MLP in federated environments, achieving\nsuperior performance with simpler architectures. Furthermore, we analyze the\nimpact of key hyperparameters-grid size and network architecture-on KAN\nperformance under varying degrees of Non-IID data distribution. Additionally,\nour ablation studies reveal that optimizing KAN width while maintaining minimal\ndepth yields the best performance in federated settings. As a result, these\nfindings establish KAN as a promising alternative for privacy-preserving\nmedical imaging applications in distributed healthcare. To the best of our\nknowledge, this is the first comprehensive benchmark of KAN in FL settings for\nmedical imaging task.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-28T09:53:05Z"}
{"aid":"http://arxiv.org/abs/2504.19649v1","title":"Intelligent4DSE: Optimizing High-Level Synthesis Design Space\n  Exploration with Graph Neural Networks and Large Language Models","summary":"High-level synthesis (HLS) design space exploration (DSE) is an optimization\nprocess in electronic design automation (EDA) that systematically explores\nhigh-level design configurations to achieve Pareto-optimal hardware\nimplementations balancing performance, area, and power (PPA). To optimize this\nprocess, HLS prediction tasks often employ message-passing neural networks\n(MPNNs), leveraging complex architectures to achieve high accuracy. These\npredictors serve as evaluators in the DSE process, effectively bypassing the\ntime-consuming estimations traditionally required by HLS tools. However,\nexisting models often prioritize structural complexity and minimization of\ntraining loss, overlooking task-specific characteristics. Additionally, while\nevolutionary algorithms are widely used in DSE, they typically require\nextensive domain-specific knowledge to design effective crossover and mutation\noperators. To address these limitations, we propose CoGNNs-LLMEA, a framework\nthat integrates a graph neural network with task-adaptive message passing and a\nlarge language model-enhanced evolutionary algorithm. As a predictive model,\nCoGNNs directly leverages intermediate representations generated from source\ncode after compiler front-end processing, enabling prediction of quality of\nresults (QoR) without invoking HLS tools. Due to its strong adaptability to\ntasks, CoGNNs can be tuned to predict post-HLS and post-implementation\noutcomes, effectively bridging the gap between high-level abstractions and\nphysical implementation characteristics. CoGNNs achieves state-of-the-art\nprediction accuracy in post-HLS QoR prediction, reducing mean prediction errors\nby 2.8$\\times$ for latency and 3.4$\\times$ for resource utilization compared to\nbaseline models.","main_category":"cs.LG","categories":"cs.LG,cs.AR","published":"2025-04-28T10:08:56Z"}
{"aid":"http://arxiv.org/abs/2504.19693v1","title":"Emerging Photon Jets in the Hadronic Calorimeter: A Novel Signature of\n  Neutral Long-Lived Particles at the LHC","summary":"We propose a novel collider signature for neutral long-lived particles\n(LLPs): the emerging photon jet in the hadronic calorimeter (HCAL). This\nsignature arises when a neutral LLP decays into photons within the HCAL,\nproducing an electromagnetic shower without associated charged tracks or energy\ndeposits in the electromagnetic calorimeter (ECAL). To demonstrate the\nviability of this approach, we consider the fermiophobic Higgs boson $h_{\\rm\nf}$ in the Type-I two-Higgs-doublet model as a representative scenario. In the\nultralight regime ($m_{h_{\\rm f}} < 1$ GeV), $h_{\\rm f}$ decays exclusively\ninto a photon pair via loop-induced processes, resulting in a suppressed width\nand consequently a long lifetime. Focusing on the golden channel $pp \\to H^\\pm\nh_{\\rm f} \\to W^\\pm h_{\\rm f} h_{\\rm f}$, we analyze the exotic final state in\nwhich one $h_{\\rm f}$ decays in the ECAL and appears as a highly collimated\nphoton jet (reconstructed as a single photon), while the other decays within\nthe HCAL, producing an emerging photon jet. Through a detailed\nsignal-to-background analysis incorporating realistic detector effects via fast\nsimulation, we demonstrate that this signature achieves discovery-level\nsensitivity at the HL-LHC across a broad region of parameter space consistent\nwith theoretical and experimental constraints. While our study focuses on the\nfermiophobic Higgs, the emerging photon jet in the HCAL constitutes a broadly\napplicable and previously unexplored strategy for detecting neutral LLPs\ndecaying into photons, opening a new avenue in LLP searches at colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T11:42:06Z"}
{"aid":"http://arxiv.org/abs/2504.19740v1","title":"Graph Fourier Transformer with Structure-Frequency Information","summary":"Graph Transformers (GTs) have shown advantages in numerous graph structure\ntasks but their self-attention mechanism ignores the generalization bias of\ngraphs, with existing methods mainly compensating for this bias from aspects\nlike position encoding, attention bias and relative distance yet still having\nsub-optimal performance and being insufficient by only considering the\nstructural perspective of generalization bias. To address this, this paper\nproposes Grafourierformer, which innovatively combines GT with inductive bias\ncontaining Frequency-Structure information by applying Graph Fourier Transform\nto the Attention Matrix: specifically, eigenvalues from the Graph Laplacian\nmatrix are used to construct an Eigenvalue matrix mask (reflecting node\npositions and structural relationships with neighboring nodes to enable\nconsideration of node range structural characteristics and focus on local graph\ndetails), and inverse Fourier transform is employed to extract node\nhigh-frequency and low-frequency features, calculate low-frequency and\nhigh-frequency energy, and construct a node frequency-energy matrix to filter\nthe eigenvalue matrix mask, allowing attention heads to incorporate both graph\nstructural information and node frequency information optimization, adaptively\ndistinguish global trends from local details, and effectively suppress\nredundant information interference. Extensive experiments on various benchmarks\nshow Grafourierformer consistently outperforms GNN and GT-based models in graph\nclassification and node classification tasks, with ablation experiments further\nvalidating the effectiveness and necessity of the method. Codes are available\nat https://github.com/Arichibald/Grafourierformer.git","main_category":"cs.LG","categories":"cs.LG,cs.GR","published":"2025-04-28T12:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.19782v1","title":"Cooling process of the high-mass young stellar object G24.33+0.14\n  following an accretion burst","summary":"The HMYSO G24.33+0.14 (G24), has recently been observed to undergo an\naccretion burst since September 2019, lasting approximately two years. By\nutilizing 1.3 mm observational data from the NOrthern Extended Millimeter Array\n(NOEMA) in March 2020 and the Atacama Large Millimeter/submillimeter Array\n(ALMA) in September 2019, we have examined the physical environment changes in\ngas and dust within G24 region during the decay phase of the accretion burst.\nFollowing the burst, the continuum emission in the inner core region of G24\ndiminished by approximately 20%, while the emission in the outer region\nexhibited an increase by a factor of ~30%. This pattern indicates that the heat\nwave, triggered by the accretion burst, radiated outward from the core's\ninterior to its periphery over the half-year period, with a calculated\npropagation speed of 0.08-0.38 times the speed of light. Moreover, the methanol\nemission intensity in this area has experienced a notable decline, with the\nrate of flux reduction correlating positively with the energy of the upper\nenergy states. This, in conjunction with the analysis of methanol molecular\nline rotation temperature diagrams for different emitting regions, further\nsubstantiates that the core region of G24 cooled down, contrasted with the\npersistent heating in the outer region following the burst.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-28T13:27:29Z"}
{"aid":"http://arxiv.org/abs/2504.19793v1","title":"Prompt Injection Attack to Tool Selection in LLM Agents","summary":"Tool selection is a key component of LLM agents. The process operates through\na two-step mechanism - \\emph{retrieval} and \\emph{selection} - to pick the most\nappropriate tool from a tool library for a given task. In this work, we\nintroduce \\textit{ToolHijacker}, a novel prompt injection attack targeting tool\nselection in no-box scenarios. ToolHijacker injects a malicious tool document\ninto the tool library to manipulate the LLM agent's tool selection process,\ncompelling it to consistently choose the attacker's malicious tool for an\nattacker-chosen target task. Specifically, we formulate the crafting of such\ntool documents as an optimization problem and propose a two-phase optimization\nstrategy to solve it. Our extensive experimental evaluation shows that\nToolHijacker is highly effective, significantly outperforming existing\nmanual-based and automated prompt injection attacks when applied to tool\nselection. Moreover, we explore various defenses, including prevention-based\ndefenses (StruQ and SecAlign) and detection-based defenses (known-answer\ndetection, perplexity detection, and perplexity windowed detection). Our\nexperimental results indicate that these defenses are insufficient,\nhighlighting the urgent need for developing new defense strategies.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-28T13:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.19806v1","title":"Reinforcement Learning-Based Heterogeneous Multi-Task Optimization in\n  Semantic Broadcast Communications","summary":"Semantic broadcast communications (Semantic BC) for image transmission have\nachieved significant performance gains for single-task scenarios. Nevertheless,\nextending these methods to multi-task scenarios remains challenging, as\ndifferent tasks typically require distinct objective functions, leading to\npotential conflicts within the shared encoder. In this paper, we propose a\ntri-level reinforcement learning (RL)-based multi-task Semantic BC framework,\ntermed SemanticBC-TriRL, which effectively resolves such conflicts and enables\nthe simultaneous support of multiple downstream tasks at the receiver side,\nincluding image classification and content reconstruction tasks. Specifically,\nthe proposed framework employs a bottom-up tri-level alternating learning\nstrategy, formulated as a constrained multi-objective optimization problem. At\nthe first level, task-specific decoders are locally optimized using supervised\nlearning. At the second level, the shared encoder is updated via proximal\npolicy optimization (PPO), guided by task-oriented rewards. At the third level,\na multi-gradient aggregation-based task weighting module adaptively adjusts\ntask priorities and steers the encoder optimization. Through this hierarchical\nlearning process, the encoder and decoders are alternately trained, and the\nthree levels are cohesively integrated via constrained learning objective.\nBesides, the convergence of SemanticBC-TriRL is also theoretically established.\nExtensive simulation results demonstrate the superior performance of the\nproposed framework across diverse channel conditions, particularly in low SNR\nregimes, and confirm its scalability with increasing numbers of receivers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T13:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.19864v1","title":"Extremizer Stability of Higher-order Hardy--Rellich inequalities for\n  Baouendi--Grushin vector fields","summary":"In this paper, we improve the $L^p$-Rellich and Hardy-Rellich inequalities in\nthe setting of radial Baouendi--Grushin vector fields. We establish an identity\nrelating the subcritical and critical Hardy inequalities, thereby demonstrating\ntheir equivalence. Moreover, we obtain improved versions of these inequalities\nvia an analysis of extremizer stability. In the higher-order setting, we derive\nHardy-Rellich type inequalities involving all radial operators in the Grushin\nframework and prove that all resulting constants are sharp. Finally, for the\n$L^2$-higher-order cases, we compute exact remainder terms by establishing\nidentities rather than inequalities.","main_category":"math.AP","categories":"math.AP,math.CA,math.FA","published":"2025-04-28T14:56:12Z"}
{"aid":"http://arxiv.org/abs/2504.19873v1","title":"Infinite temperature transport in the strong coupling regime of a\n  nonintegrable quantum spin chain","summary":"We study spin transport of the XXZ model with next-nearest neighbor\n$\\Delta_2$ terms. We compute numerically dependence of spin conductivity\n$\\sigma(\\omega)$ on the anisotropy $\\Delta$ and the ratio $r= \\Delta_2/\\Delta$,\nin the large $\\Delta$ regime. We find that, when $0<r<1$, the low-frequency\nconductivity assumes an anomalous form $\\sigma(\\omega)\\approx a \\omega^2 + b\n\\Delta^{-2} $. In particular, when $\\Delta\\to\\infty$ the model becomes\ndynamically constrained and most states are localized. We show,\nmicroscopically, existence of magnon bound states in the strong coupling\nregime, which behave as self-generated disorders for single magnons. Based on\nthis quasiparticle picture, we obtain analytical scalings, which match well\nwith the numerical results.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-28T15:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.19877v1","title":"Semi-abelian by Design: Johnstone Algebras Unifying Implication and\n  Division","summary":"Johnstone demonstrated that Heyting semilattices form a semi-abelian category\nvia a specific triple of terms. Inspired by this work, we introduce\n\\emph{Johnstone algebras} or J-algebras. The algebraic $(*,\\to,e)$-theory $J$\nof arities $(2,2,0)$ consists of three axioms carefully chosen to ensure\nprotomodularity in alignment with Johnstone's terms. Johnstone algebras\ngeneralize well-known structures such as groups (division) and Heyting\nsemilattices (implication) providing a unified framework within the\nwell-behaved setting of semi-abelian categories.\n  We present two primary contributions. First, we identify the M-axiom, \\[\n(t(x,y)\\to x)\\to (t(x,y)\\to z) \\approx x\\to z, \\text{ where }t(x,y) = (x\\to\ny)\\to y. \\] The M-axiom is satisfied by residuated Johnstone algebras, and it\ncan be considered a weakening of the H-axiom to comparable elements. We show\nthat $t(x,y)$ defines a \\emph{relative closure term} in MBC-algebras, and it\nimplies that MBC-algebras form a variety of algebras, thereby generalizing the\ncorresponding theorem related to HBCK-algebras. Second, we prove several no-go\nresults, demonstrating that balanced theories or theories admitting\nnon-discrete monotone or inflationary algebras cannot possess Malcev terms.\n  Together, these results establish Johnstone algebras as significant\nstructures that achieve desirable categorical properties by carefully\nintegrating both logical and symmetric features, while closely avoiding the\nconstraints imposed by our no-go results.","main_category":"math.LO","categories":"math.LO,math.CT,math.RA","published":"2025-04-28T15:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.19881v1","title":"Using Fixed and Mobile Eye Tracking to Understand How Visitors View Art\n  in a Museum: A Study at the Bowes Museum, County Durham, UK","summary":"The following paper describes a collaborative project involving researchers\nat Durham University, and professionals at the Bowes Museum, Barnard Castle,\nCounty Durham, UK, during which we used fixed and mobile eye tracking to\nunderstand how visitors view art. Our study took place during summer 2024 and\nbuilds on work presented at DH2017 (Bailey-Ross et al., 2017). Our\ninterdisciplinary team included researchers from digital humanities,\npsychology, art history and computer science, working in collaboration with\nprofessionals from the museum. We used fixed and mobile eye tracking to\nunderstand how museum visitors view art in a physical gallery setting. This\nresearch will enable us to make recommendations about how the Museum's\ncollections could be more effectively displayed, encouraging visitors to engage\nwith them more fully.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T15:12:30Z"}
{"aid":"http://arxiv.org/abs/2504.19926v1","title":"Skew generalized quasi-cyclic codes over non-chain ring $F_q+vF_q$","summary":"For a prime $p$, let $F_q$ be the finite field of order $q= p^d$. This paper\npresents the study on skew generalized quasi-cyclic (SGQC) codes of length $n$\nover the non-chain ring $F_q+vF_q$ where $v^2=v$ and $\\theta_t$ is the Galois\nautomorphism. Here, first, we prove the dual of an SGQC code of length $n$ is\nalso an SGQC code of the same length and derive a necessary and sufficient\ncondition for the existence of a self-dual SGQC code. Then, we discuss the\n$1$-generator polynomial and the $\\rho$-generator polynomial for skew\ngeneralized quasi-cyclic codes. Further, we determine the dimension and BCH\ntype bound for the 1-generator skew generalized quasi-cyclic codes. As a\nby-product, with the help of MAGMA software, we provide a few examples of SGQC\ncodes and obtain some $2$-generator SGQC codes of index $2$.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T16:00:53Z"}
{"aid":"http://arxiv.org/abs/2504.19931v1","title":"Infinite-dimensional Siegel disc as symplectic and Kaehler quotient","summary":"In this paper, we construct the restricted infinite-dimensional Siegel disc\nas a Marsden-Weinstein symplectic reduced space and as Kaehler quotient of a\nweak Kaehler manifold. The obtained symplectic form is invariant with respect\nto the left action of the infinite-dimensional restricted symplectic group and\ncoincides with the Kirillov-Kostant-Souriau symplectic form of the restricted\nSiegel disc obtained via the identification with an affine coadjoint orbit of\nthe restricted symplectic group, or equivalently with a coadjoint orbit of the\nuniversal central extension of the restricted symplectic group.","main_category":"math.SG","categories":"math.SG,math.DG,math.FA,math.OA","published":"2025-04-28T16:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.19941v1","title":"The Diffuse Solid Method for Wetting and Multiphase Fluid Simulations in\n  Complex Geometries","summary":"We develop a diffuse solid method that is versatile and accurate for modeling\nwetting and multiphase flows in highly complex geometries. In this scheme, we\nharness N + 1-component phase field models to investigate interface shapes and\nflow dynamics of N fluid components, and we optimize how to constrain the\nevolution of the component employed as the solid phase to conform to any\npre-defined geometry. Implementations for phase field energy minimization and\nlattice Boltzmann method are presented. Our approach does not need special\ntreatment for the fluid-solid wetting boundary condition, which makes it simple\nto implement. To demonstrate its broad applicability, we employ the diffuse\nsolid method to explore wide-ranging examples, including droplet contact angle\non a flat surface, particle adsorption on a fluid-fluid interface, critical\npressure on micropillars and on Salvinia leaf structures, capillary rise\nagainst gravity, Lucas-Washburn's law for capillary filling, and droplet motion\non a sinusoidally undulated surface. Our proposed approach can be beneficial to\ncomputationally study multiphase fluid interactions with textured solid\nsurfaces that are ubiquitous in nature and engineering applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft,physics.comp-ph","published":"2025-04-28T16:12:06Z"}
{"aid":"http://arxiv.org/abs/2504.19962v1","title":"Approximating neutron-star radii using gravitational-wave only\n  measurements with symbolic regression","summary":"Binary neutron star inspirals detected as gravitational waves carry\ninformation on components' masses and tidal deformabilities, but not radii,\nwhich are measured by electromagnetic observations of neutron stars. An\nexpression for neutron-star radii as a function of gravitational-wave only data\nwould be advantageous for the multi-messenger astronomy. Using pySR, a symbolic\nregression method trained on TOV solutions to piecewise polytropic EOS input,\nan approximate symbolic expression for neutron-star radius as a function of\nmass and tidal deformability is obtained. The approximation is tested on\npiecewise polytropic EOS NS data, as well as on NS sequences based on various\nnon-polytropic EOSs based on realistic theories of dense matter, achieving\nconsistent agreement between the ground truth values and the approximation for\na broad range of NS parameters covering current astrophysical observations,\nwith average radii differences of few hundred meters. Additionally, the\napproximation is applied to GW170817 gravitational-wave mass and tidal\ndeformability posteriors, and compared to reported inferred radius\ndistributions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-28T16:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.19967v1","title":"Enhancing short-term traffic prediction by integrating trends and\n  fluctuations with attention mechanism","summary":"Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.","main_category":"cs.ET","categories":"cs.ET,cs.AI,cs.LG,stat.AP","published":"2025-04-28T16:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.19975v1","title":"Revisiting the temporal law in KPZ random growth","summary":"This article studies the temporal law of the KPZ fixed point. For the droplet\ngeometry, we find a relatively simpler formula for the multi-time law compared\nto a previous formula of Johansson and the author. For the stationary geometry,\nwe find the two-time law, which extends the single time law due to Baik-Rains\nand Ferrari-Spohn. These formulas are derived as the scaling limit of\ncorresponding multi-time formulas for geometric last passage percolation.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-28T16:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.19999v1","title":"Compositional Square Roots of $\\exp(x)$ and $1+x^2$","summary":"Our work began as an effort to understand calculations by Morris & Szekeres\n(1961) and Walker (1991) regarding fractional iteration.","main_category":"math.GM","categories":"math.GM,cs.DM","published":"2025-04-28T17:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.20383v1","title":"Neural Stereo Video Compression with Hybrid Disparity Compensation","summary":"Disparity compensation represents the primary strategy in stereo video\ncompression (SVC) for exploiting cross-view redundancy. These mechanisms can be\nbroadly categorized into two types: one that employs explicit horizontal\nshifting, and another that utilizes an implicit cross-attention mechanism to\nreduce cross-view disparity redundancy. In this work, we propose a hybrid\ndisparity compensation (HDC) strategy that leverages explicit pixel\ndisplacement as a robust prior feature to simplify optimization and perform\nimplicit cross-attention mechanisms for subsequent warping operations, thereby\ncapturing a broader range of disparity information. Specifically, HDC first\ncomputes a similarity map by fusing the horizontally shifted cross-view\nfeatures to capture pixel displacement information. This similarity map is then\nnormalized into an \"explicit pixel-wise attention score\" to perform the\ncross-attention mechanism, implicitly aligning features from one view to\nanother. Building upon HDC, we introduce a novel end-to-end optimized neural\nstereo video compression framework, which integrates HDC-based modules into key\ncoding operations, including cross-view feature extraction and reconstruction\n(HDC-FER) and cross-view entropy modeling (HDC-EM). Extensive experiments on\nSVC benchmarks, including KITTI 2012, KITTI 2015, and Nagoya, which cover both\nautonomous driving and general scenes, demonstrate that our framework\noutperforms both neural and traditional SVC methodologies.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-29T03:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.20398v1","title":"Noise limits for dc SQUID readout of high-$Q$ resonators below 300 MHz","summary":"We present the limits on noise for the readout of cryogenic high-$Q$\nresonators using dc Superconducting Quantum Interference Devices (SQUIDs) below\n300 MHz. This analysis uses realized first-stage SQUIDs (previously published),\nwhose performance is well described by Tesche-Clarke (TC) theory, coupled\ndirectly to the resonators. We also present data from a prototype second-stage\ndc SQUID array designed to couple to this first-stage SQUID as a follow-on\namplifier with high system bandwidth. This analysis is the first full\nconsideration of dc SQUID noise performance referred to a high-$Q$ resonator\nover this frequency range, and is presented relative to the standard quantum\nlimit. We include imprecision, backaction, and backaction-imprecision noise\ncorrelations from TC theory, the noise contributed by the second-stage SQUIDs,\nwiring, and preamplifiers, and optimizations for both on-resonance measurements\nand off-resonance scan sensitivity. This architecture has modern relevance due\nto the increased interest in axion searches and the requirements of the\nDMRadio-m$^3$ axion search, which will use dc SQUIDs in this frequency range.","main_category":"quant-ph","categories":"quant-ph,hep-ex","published":"2025-04-29T03:42:06Z"}
{"aid":"http://arxiv.org/abs/2504.20402v1","title":"Deterministic Formation of Single Organic Color Centers in Single-Walled\n  Carbon Nanotubes","summary":"Quantum light sources using single-walled carbon nanotubes show promise for\nquantum technologies but face challenges in achieving precise control over\ncolor center formation. Here we present a novel technique for deterministic\ncreation of single organic color centers in carbon nanotubes using\n\\textit{in-situ} photochemical reaction. By monitoring discrete intensity\nchanges in photoluminescence spectra, we achieve precise control over the\nformation of individual color centers. Furthermore, our method allows for\nposition-controlled formation of color centers as validated through\nphotoluminescence imaging. We also demonstrate photon antibunching from a color\ncenter, confirming the quantum nature of the defects formed. This technique\nrepresents a significant step forward in the precise engineering of atomically\ndefined quantum emitters in carbon nanotubes, facilitating their integration\ninto advanced quantum photonic devices and systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T03:56:06Z"}
{"aid":"http://arxiv.org/abs/2504.20418v1","title":"Theoretical Framework for Temporal Changes in Interactions among\n  Adaptive Components of Living Systems","summary":"In living systems, each component adaptively changes its internal states in\nresponse to its interactions with other components. These interactions, in\nturn, undergo temporal changes as a result of this adaptive behavior, which\nplays a crucial role in the emergence of system-level functions. Thus, to\nunderstand how changes in interactions influence the emergence of functions by\nemploying models of adaptive behavior, it is essential to incorporate these\ninteraction changes into these models. In this study, we developed a\ntheoretical framework for modeling adaptive behavior of components under\ntemporally changing interactions by formulating these interaction changes as\ndynamics of energy landscapes associated with that behavior. To represent this\ncomponent-level adaptive behavior, internal state changes of each component\nwere formulated based on the generalized gradient flow of an energy landscape\nand its associated energy rate landscape. We expressed dynamics of these\nlandscapes by treating environmental states surrounding each component as\ntemporal changes related to the interaction, which were then coupled to\ninternal state changes of the component. Through case studies using simplified\nmodels of living systems under multiple mechanical interaction conditions among\ncomponents, we demonstrated that our proposed theoretical framework can\nrepresent the emergence of functions of living systems. Even without explicitly\ndefining adaptive behavior at the system level, these functions are specified\nbased on the dynamics of the energy and energy rate landscapes of each\ncomponent.","main_category":"physics.bio-ph","categories":"physics.bio-ph,nlin.AO","published":"2025-04-29T04:30:35Z"}
{"aid":"http://arxiv.org/abs/2504.20470v1","title":"The Promises of Multiple Experiments: Identifying Joint Distribution of\n  Potential Outcomes","summary":"Typical causal effects are defined based on the marginal distribution of\npotential outcomes. However, many real-world applications require causal\nestimands involving the joint distribution of potential outcomes to enable more\nnuanced treatment evaluation and selection. In this article, we propose a novel\nframework for identifying and estimating the joint distribution of potential\noutcomes using multiple experimental datasets. We introduce the assumption of\ntransportability of state transition probabilities for potential outcomes\nacross datasets and establish the identification of the joint distribution\nunder this assumption, along with a regular full-column rank condition. The key\nidentification assumptions are testable in an overidentified setting and are\nanalogous to those in the context of instrumental variables, with the dataset\nindicator serving as \"instrument\". Moreover, we propose an easy-to-use\nleast-squares-based estimator for the joint distribution of potential outcomes\nin each dataset, proving its consistency and asymptotic normality. We further\nextend the proposed framework to identify and estimate principal causal\neffects. We empirically demonstrate the proposed framework by conducting\nextensive simulations and applying it to evaluate the surrogate endpoint in a\nreal-world application.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-29T07:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.20489v1","title":"Sign Convention for $A_{\\infty}$-Operations in Bott-Morse Case","summary":"We describe the sign and orientation issue appearing the filtered\n$A_{\\infty}$-formulae in Lagrangian Floer theory using de Rham model in\nBott-Morse setting. After giving the definition of filtered\n$A_{\\infty}$-operations in a Fukaya category, we verify the filtered\n$A_{\\infty}$-formulae.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-29T07:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.20496v1","title":"Large-scale visual SLAM for in-the-wild videos","summary":"Accurate and robust 3D scene reconstruction from casual, in-the-wild videos\ncan significantly simplify robot deployment to new environments. However,\nreliable camera pose estimation and scene reconstruction from such\nunconstrained videos remains an open challenge. Existing visual-only SLAM\nmethods perform well on benchmark datasets but struggle with real-world footage\nwhich often exhibits uncontrolled motion including rapid rotations and pure\nforward movements, textureless regions, and dynamic objects. We analyze the\nlimitations of current methods and introduce a robust pipeline designed to\nimprove 3D reconstruction from casual videos. We build upon recent deep visual\nodometry methods but increase robustness in several ways. Camera intrinsics are\nautomatically recovered from the first few frames using structure-from-motion.\nDynamic objects and less-constrained areas are masked with a predictive model.\nAdditionally, we leverage monocular depth estimates to regularize bundle\nadjustment, mitigating errors in low-parallax situations. Finally, we integrate\nplace recognition and loop closure to reduce long-term drift and refine both\nintrinsics and pose estimates through global bundle adjustment. We demonstrate\nlarge-scale contiguous 3D models from several online videos in various\nenvironments. In contrast, baseline methods typically produce locally\ninconsistent results at several points, producing separate segments or\ndistorted maps. In lieu of ground-truth pose data, we evaluate map consistency,\nexecution time and visual accuracy of re-rendered NeRF models. Our proposed\nsystem establishes a new baseline for visual reconstruction from casual\nuncontrolled videos found online, demonstrating more consistent reconstructions\nover longer sequences of in-the-wild videos than previously achieved.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:37:51Z"}
{"aid":"http://arxiv.org/abs/2504.20553v1","title":"Characterizing the Polynomial-Time Minimizable $Ï$-Automata","summary":"A central question in the theory of automata is which classes of automata can\nbe minimized in polynomial time. We close the remaining gaps for deterministic\nand history-deterministic automata over infinite words by proving that\ndeterministic co-B\\\"uchi automata with transition-based acceptance are NP-hard\nto minimize, as are history-deterministic B\\\"uchi automata with\ntransition-based acceptance.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-29T08:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.20562v1","title":"Binding of native DNA to MoS$_{2}$ nanoflakes: the role of defects and\n  edge atoms of MoS$_{2}$ nanostructures in their biofunctionalization","summary":"In this work, the binding of native DNA to MoS$_{2}$ nanoflakes (FLs) was\nstudied by using UV-visible absorption spectroscopy, thermal denaturation\nmethod, transmission electron microscopy (TEM), temperature-dependent dynamic\nlight scattering (DLS), and the DFT computational-chemistry method. Analysis of\nthe experimental data: TEM images and thermal denaturation measurements showed\nthe binding of the biopolymer with MoS$_{2}$ FLs. An increase in the melting\ntemperature of DNA and a decrease in the hyperchromic coefficient at binding\nwith MoS$_{2}$ FLs indicates the formation of the DNA:MoS$_{2}$ FL\nnanoassemblies due primarily to the covalent interaction of the oxygen atoms of\nthe phosphate groups of DNA with the MoS$_{2}$ FLs. Possible complexes of a\nnucleotide fragment (ribose-phosphate group) with MoS$_{2}$ nanolayer are\nconsidered and calculated employing the DFT method. Different structures of\nthese complexes are optimized and the interaction energies between components\nare determined. Special attention in calculations is focused on the binding of\nthis nucleotide fragment with Mo atoms located at the edge of the MoS$_{2}$\nnanolayer and with point structural defects of the MoS$_{2}$ surface containing\nthe S vacancy. Based on this calculation and experimental observation, a\nmechanism of binding of native DNA to MoS$_{2}$ FLs has been proposed, in which\ntheir conjugation begins with point contacts of DNA phosphate groups with Mo\natoms (at the edge or/and in defects) through the formation of a strong\ncoordination bond. The results indicate the critical role of defects and edge\natoms of MoS$_{2}$ FLs in their biofunctionalization.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-29T09:05:58Z"}
{"aid":"http://arxiv.org/abs/2504.20578v1","title":"From small dust to micron-sized aggregates: the influence of structure\n  and composition on the dust optical properties","summary":"Models of astrophysical dust are key to understand several physical\nprocesses, from the role of dust grains as cooling agents in the ISM to their\nevolution in dense circumstellar disks, explaining the occurrence of planetary\nsystems around many stars. Currently, most models aim at providing optical\nproperties for dust grains in the diffuse ISM, and many do not account properly\nfor complexity in composition and structure when dust is expected to evolve in\ndense astrophysical environments. Our purpose is to investigate, with a pilot\nsample of micron-size dust grains, the influence of dust structure, porosity,\nand composition when computing the optical properties of grown dust grains in\nthe infrared and millimetre domains, where observations are widely used to\nconstrain the dust properties. Starting from the small dust grains developed in\nthe THEMIS 2.0 model, we use the Discrete Dipole Approximation to compute the\noptical properties of 1 um grains, varying the hypotheses made on their\ncomposition and structure. We look at the dust scattering, emission and\nextinction to isolate potential simplifications and unavoidable differences\nbetween grain structures. We note that both dust structure and porosity\ninfluence the dust properties in infrared and millimetre ranges, demonstrating\nthat dust aggregates cannot be correctly approximated by compact or porous\nspheres. In particular, we show that the dust emissivity index in the\nmillimetre can vary with fixed grain size. We shed light on the importance of\ntaking the dust structure and porosity into account when interpreting\nobservations in environments where dust grains may have evolved significantly.\nEfforts in carrying out physical models of grain growth, for instance, are\nrequired to establish realistic constraints on the structure of grown dust\ngrains, and will be used in the future to build realistic dust models for the\ndense ISM.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-29T09:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.20591v1","title":"A continuum of non-isomorphic 3-generator groups with probabilistic law\n  $x^n=1$","summary":"In this paper we construct a continuum family of non-isomorphic 3-generator\ngroups in which the identity $x^n = 1$ holds with probability 1, while failing\nto hold universally in each group. This resolves a recent question about the\nrelationship between probabilistic and universal satisfaction of group\nidentities. Our construction uses $n$-periodic products of cyclic groups of\norder $n$ and two-generator relatively free groups satisfying identities of the\nform $[x^{pn}, y^{pn}]^n = 1$. We prove that in each of these products, the\nprobability of satisfying $x^n = 1$ is equal to 1, despite the fact that the\nidentity does not hold throughout any of these groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-29T09:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.20592v1","title":"Is the Symbiotic Recurrent Nova T CrB Late? Recent Photometric Evolution\n  and Comparison with Past Pre-Outburst Behaviour","summary":"T CrB is a symbiotic recurrent nova that last erupted in 1946. Given its\nrecurrence timescale of approximately 80 years, the next outburst is eagerly\nanticipated by the astronomical community. In this work, we analyse the optical\nlight curves of T CrB, comparing recent photometric evolution with historical\ndata to evaluate potential predictive indicators of nova eruptions. Although\nthe \"super-active\" phases preceding both the 1946 and anticipated eruptions are\nstrikingly similar, the subsequent photometric behaviour differs. We find that\nthe decline in brightness observed in 2023, interpreted by some as a\n\"pre-eruption dip\", deviates from the deep minimum recorded prior to the 1946\nevent and does not reliably predict the eruption timing. Recent photometric and\nspectroscopic observations indicate that the system is returning to a\nhigh-accretion state. Given this, an eruption may be imminent, even without\ndistinct precursors. While the next eruption of T CrB will be a major\nscientific event, its expected peak brightness of $V \\sim 2$ mag highlights the\nimportance of setting realistic public expectations for what will be a visually\nmodest, yet astrophysically very significant, celestial event.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-04-29T09:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.20596v1","title":"The Anyonic Quantum Carnot Engine","summary":"Combining two disparate lines of thought like thermodynamics and quantum\nmechanics yields surprising results. The resulting idea of quantum\nthermodynamic engines holds promise for harvesting novel sources of energy of\npurely quantum origin, like quantum statistics, to extract mechanical work from\nmacroscopic quantum systems like Bose-Einstein condensates. It also allows one\nto explore thermodynamic thinking to `small' systems consisting only a few\nparticles in quantum theory. In an earlier paper we had studied the quantum\nOtto engine using a small number of one-dimensional anyons as the medium to\ndrive the thermodynamic engine. In this sequel, we study the gold-standard of\nthermodynamic engines, namely the Carnot engine, using two-dimensional anyons\nas the medium. An explicit expression is derived for the efficiency of the\nanyonic quantum Carnot engine.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-29T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.20632v1","title":"Tx-Rx Mode Mismatch Effects in Gaussian-Modulated CV QKD","summary":"The impact of technical limitations on pulse shaping used to generate a CV\nQKD signal is quantified in terms of the attainable secure key rate.\nOptimization of key spectral efficiency for Gaussian-modulated CV QKD with\ntruncated and discretized root-raised cosine profiles is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T11:01:11Z"}
{"aid":"http://arxiv.org/abs/2504.20659v1","title":"Disjoint Delay-Doppler Estimation in OTFS ISAC with Deep Learning-aided\n  Path Detection","summary":"In this work, the problem of communication and radar sensing in orthogonal\ntime frequency space (OTFS) with reduced cyclic prefix (RCP) is addressed. A\nmonostatic integrated sensing and communications (ISAC) system is developed\nand, it is demonstrated that by leveraging the cyclic shift property inherent\nin the RCP, a delay-Doppler (DD) channel matrix that encapsulates the effects\nof propagation delays and Doppler shifts through unitary matrices can be\nderived. Consequently, a novel low-complexity correlation-based algorithm\nperforming disjoint delay-Doppler estimation is proposed for channel\nestimation. Subsequently, this estimation approach is adapted to perform radar\nsensing on backscattered data frames. Moreover, channel estimation is\ncomplemented by a deep learning (DL) architecture that improves path detection\nand accuracy under low signal-to-noise ratio (SNR) conditions, compared to\nstopping criterion (SC) based multipath detection. Simulation results indicate\nthat the proposed estimation scheme achieves lower normalized mean squared\nerror (NMSE) compared to conventional channel estimation algorithms and sensing\nperformance close to the Cramer-Rao lower bound (CRLB). Furthermore, an\niterative data detection algorithm based on matched filter (MF) and combining\nis developed by exploiting the unitary property of delay-Doppler parameterized\nmatrices. Simulation results reveal that this iterative scheme achieves\nperformance comparable to that of the linear minimum mean squared error (LMMSE)\nestimator while significantly reducing computational complexity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T11:34:47Z"}
{"aid":"http://arxiv.org/abs/2504.20690v1","title":"In-Context Edit: Enabling Instructional Image Editing with In-Context\n  Generation in Large Scale Diffusion Transformer","summary":"Instruction-based image editing enables robust image modification via natural\nlanguage prompts, yet current methods face a precision-efficiency tradeoff.\nFine-tuning methods demand significant computational resources and large\ndatasets, while training-free techniques struggle with instruction\ncomprehension and edit quality. We resolve this dilemma by leveraging\nlarge-scale Diffusion Transformer (DiT)' enhanced generation capacity and\nnative contextual awareness. Our solution introduces three contributions: (1)\nan in-context editing framework for zero-shot instruction compliance using\nin-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning\nstrategy that enhances flexibility with efficient adaptation and dynamic expert\nrouting, without extensive retraining; and (3) an early filter inference-time\nscaling method using vision-language models (VLMs) to select better initial\nnoise early, improving edit quality. Extensive evaluations demonstrate our\nmethod's superiority: it outperforms state-of-the-art approaches while\nrequiring only 0.5% training data and 1% trainable parameters compared to\nconventional baselines. This work establishes a new paradigm that enables\nhigh-precision yet efficient instruction-guided editing. Codes and demos can be\nfound in https://river-zhang.github.io/ICEdit-gh-pages/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T12:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.20701v1","title":"Static black hole horizons in cosmology","summary":"Despite previous results that rule out the possibility of a static black hole\nhorizon in cosmology we present a black hole metric that has a static horizon\nwhilst mimicking the cosmological behavior at large scales away from the black\nhole horizon. By a suitable choice of coordinates, we show that it is possible\nto have a static black hole horizon in cosmology that does not suffer from\nissues like singularities in curvature invariants at the horizon. The resulting\nmetric is consistent with the Schwarzschild-de Sitter metric for constant\nHubble parameter. It should be noted that this metric does not lead to\nisotropic pressure, i.e. $p_\\perp\\neq p_r$ for radial distances comparable to\nSchwarzschild radius, but for large $r$ the stress tensor (assuming general\nrelativity) tends to the cosmological value. Turning to a more realistic\nframework, we study the cases of black hole$+$cosmological matter and black\nhole$+$matter$+$cosmological constant where we assume the pressure component\ntakes its cosmological value and show that although the resulting metric does\nnot have a static horizon, the physical radius of the apparent horizon can tend\nto a constant value for large cosmological time. This metric does not suffer\nfrom issues like a singular horizon for asymptotically vanishing Hubble\nparameter.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-29T12:32:50Z"}
{"aid":"http://arxiv.org/abs/2504.20706v1","title":"Every 2-connected, cubic, planar graph with faces of size at most 6 is\n  Hamiltonian","summary":"We prove that every 2-connected, cubic, planar graph with faces of size at\nmost 6 is Hamiltonian, and show that the 6-face condition is tight. Our results\npush the connectivity condition of the Barnette-Goodey conjecture to the\nweakest possible.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T12:36:38Z"}
{"aid":"http://arxiv.org/abs/2504.20708v1","title":"Beyond the Last Answer: Your Reasoning Trace Uncovers More than You\n  Think","summary":"Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\nproblems. Standard evaluation practice involves generating a complete reasoning\ntrace and assessing the correctness of the final answer presented at its\nconclusion. In this paper, we challenge the reliance on the final answer by\nposing the following two questions: Does the final answer reliably represent\nthe model's optimal conclusion? Can alternative reasoning paths yield different\nresults? To answer these questions, we analyze intermediate reasoning steps,\ntermed subthoughts, and propose a method based on our findings. Our approach\ninvolves segmenting a reasoning trace into sequential subthoughts based on\nlinguistic cues. We start by prompting the model to generate continuations from\nthe end-point of each intermediate subthought. We extract a potential answer\nfrom every completed continuation originating from different subthoughts. We\nfind that aggregating these answers by selecting the most frequent one (the\nmode) often yields significantly higher accuracy compared to relying solely on\nthe answer derived from the original complete trace. Analyzing the consistency\namong the answers derived from different subthoughts reveals characteristics\nthat correlate with the model's confidence and correctness, suggesting\npotential for identifying less reliable answers. Our experiments across various\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\nshow consistent accuracy improvements, with gains reaching up to 13\\% and 10\\%\nrespectively. Implementation is available at:\nhttps://github.com/hammoudhasan/SubthoughtReasoner.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-29T12:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.20759v1","title":"Kolyvagin systems of rank 0 and the structure of the Selmer group of\n  elliptic curves over abelian extensions","summary":"With the motivation to study the Selmer group af an elliptic curve, we\nimprove the theory of Kolyvagin systems to describe the Fitting ideals of a\nSelmer group in the core rank zero situation. By relaxing a Selmer structure of\nrank zero at certain prime, we can construct an auxiliary Kolyvagin system\nwhose localisation determines most of the Fitting ideals of the Selmer group,\nand all of them when the Galois representation is not self-dual. With this new\ntheory, one can describe, in terms of the modular symbols, the Galois structure\nof the Selmer group of an elliptic curve $E/\\mathbb{Q}$ over a finite abelian\nextension whose degree is coprime to $p$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-29T13:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.20794v1","title":"Q-Fusion: Diffusing Quantum Circuits","summary":"Quantum computing holds great potential for solving socially relevant and\ncomputationally complex problems. Furthermore, quantum machine learning (QML)\npromises to rapidly improve our current machine learning capabilities. However,\ncurrent noisy intermediate-scale quantum (NISQ) devices are constrained by\nlimitations in the number of qubits and gate counts, which hinder their full\ncapabilities. Furthermore, the design of quantum algorithms remains a laborious\ntask, requiring significant domain expertise and time. Quantum Architecture\nSearch (QAS) aims to streamline this process by automatically generating novel\nquantum circuits, reducing the need for manual intervention. In this paper, we\npropose a diffusion-based algorithm leveraging the LayerDAG framework to\ngenerate new quantum circuits. This method contrasts with other approaches that\nutilize large language models (LLMs), reinforcement learning (RL), variational\nautoencoders (VAE), and similar techniques. Our results demonstrate that the\nproposed model consistently generates 100% valid quantum circuit outputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T14:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.20812v1","title":"Materials Database from All-electron Hybrid Functional DFT Calculations","summary":"Materials databases built from calculations based on density functional\napproximations play an important role in the discovery of materials with\nimproved properties. Most databases thus constructed rely on the generalized\ngradient approximation (GGA) for electron exchange and correlation. This limits\nthe reliability of these databases, as well as the artificial intelligence (AI)\nmodels trained on them, for certain classes of materials and properties which\nare not well described by GGA. In this paper, we describe a database of 7,024\ninorganic materials presenting diverse structures and compositions generated\nusing hybrid functional calculations enabled by their efficient implementation\nin the all-electron code FHI-aims. The database is used to evaluate the\nthermodynamic and electrochemical stability of oxides relevant to catalysis and\nenergy related applications. We illustrate how the database can be used to\ntrain AI models for material properties using the sure-independence screening\nand sparsifying operator (SISSO) approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T14:24:27Z"}
{"aid":"http://arxiv.org/abs/2504.20818v1","title":"Simulating metal complex formation and dynamics in aqueous solutions:\n  Insights into stability, mechanism, and rates of ligand exchange","summary":"Metal coordination is ubiquitous in Nature and central in many applications\nranging from nanotechnology to catalysis and environmental chemistry. Complex\nformation results from the subtle interplay between different thermodynamic,\nkinetic, and mechanistic contributions, which remain largely elusive to\nstandard experimental methodologies and challenging for typical modeling\napproaches. Here, we present an effective molecular simulation approach that\ncan fully describe the chemical equilibrium and dynamics of metal complexes in\nsolution, with atomistic detail. Application to Cd(II) and Ni(II) complexes\nwith various amine ligands provides an excellent agreement with available\nassociation constants and formation rates spanning several orders of magnitude.\nMoreover, investigation of polydentate ligands allows unravelling the origin of\nthe chelate effect as due to the concurrent contribution of entropy,\ndissociation rates, and ligand binding mechanisms. This study represents a step\nforward for the in silico design of coordination chemistry applications and for\na better understanding of biochemical processes activated by metal binding.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T14:39:01Z"}
{"aid":"http://arxiv.org/abs/2504.20824v1","title":"Variational Quantum Simulation of the Interacting Schwinger Model on a\n  Trapped-Ion Quantum Processor","summary":"Simulations in high-energy physics are currently emerging as an application\nof noisy intermediate-scale quantum (NISQ) computers. In this work, we explore\nthe multi-flavor lattice Schwinger model - a toy model inspired by quantum\nchromodynamics - in one spatial dimension and with nonzero chemical potential\nby means of variational quantum simulation on a shuttling-based trapped-ion\nquantum processor. This fermionic problem becomes intractable for classical\nnumerical methods even for small system sizes due to the notorious sign\nproblem. We employ a parametric quantum circuit executed on our quantum\nprocessor to identify ground states in different parameter regimes of the\nmodel, mapping out a quantum phase transition which is the hallmark feature of\nthe model. The resulting states are analyzed via quantum state tomography, to\nreveal how characteristic properties such as correlations in the output state\nchange across the phase transition. Moreover, we use the results to determine\nthe phase boundaries of the model.","main_category":"quant-ph","categories":"quant-ph,hep-lat","published":"2025-04-29T14:43:57Z"}
{"aid":"http://arxiv.org/abs/2504.20844v1","title":"Effect of Avatar Head Movement on Communication Behaviour, Experience of\n  Presence and Conversation Success in Triadic Conversations","summary":"Interactive communication in virtual reality can be used in experimental\nparadigms to increase the ecological validity of hearing device evaluations.\nThis requires the virtual environment to elicit natural communication behaviour\nin listeners. This study evaluates the effect of virtual animated characters'\nhead movements on participants' communication behaviour and experience.\n  Triadic conversations were conducted between a test participant and two\nconfederates. To facilitate the manipulation of head movements, the\nconversation was conducted in telepresence using a system that transmitted\naudio, head movement data and video with low delay. The confederates were\nrepresented by virtual animated characters (avatars) with different levels of\nanimation: Static heads, automated head movement animations based on speech\nlevel onsets, and animated head movements based on the transmitted head\nmovements of the interlocutors. A condition was also included in which the\nvideos of the interlocutors' heads were embedded in the visual scene.\n  The results show significant effects of animation level on the participants'\nspeech and head movement behaviour as recorded by physical sensors, as well as\non the subjective sense of presence and the success of the conversation. The\nlargest effects were found for the range of head orientation during speech and\nthe perceived realism of avatars. Participants reported that they were spoken\nto in a more helpful way when the avatars showed head movements transmitted\nfrom the interlocutors than when the avatars' heads were static.\n  We therefore conclude that the representation of interlocutors must include\nsufficiently realistic head movements in order to elicit natural communication\nbehaviour.","main_category":"cs.HC","categories":"cs.HC,cs.SD","published":"2025-04-29T15:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.20847v1","title":"Transversal Gates in Nonadditive Quantum Codes","summary":"Transversal gates play a crucial role in suppressing error propagation in\nfault-tolerant quantum computation, yet they are intrinsically constrained: any\nnontrivial code encoding a single logical qubit admits only a finite subgroup\nof $\\mathrm{SU}(2)$ as its transversal operations. We introduce a systematic\nframework for searching codes with specified transversal groups by\nparametrizing their logical subspaces on the Stiefel manifold and minimizing a\ncomposite loss that enforces both the Knill-Laflamme conditions and a target\ntransversal-group structure. Applying this method, we uncover a new $((6,2,3))$\ncode admitting a transversal $Z\\bigl(\\tfrac{2\\pi}{5}\\bigr)$ gate (transversal\ngroup $\\mathrm{C}_{10}$), the smallest known distance $3$ code supporting\nnon-Clifford transversal gates, as well as several new $((7,2,3))$ codes\nrealizing the binary icosahedral group $2I$. We further propose the\n\\emph{Subset-Sum-Linear-Programming} (SS-LP) construction for codes with\ntransversal \\emph{diagonal} gates, which dramatically shrinks the search space\nby reducing to integer partitions subject to linear constraints. In a more\nconstrained form, the method also applies directly to the binary-dihedral\ngroups $\\mathrm{BD}_{2m}$. Specializing to $n=7$, the SS-LP method yields codes\nfor all $\\mathrm{BD}_{2m}$ with $2m\\le 36$, including the first $((7,2,3))$\nexamples supporting transversal $T$ gate ($\\mathrm{BD}_{16}$) and $\\sqrt{T}$\ngate ($\\mathrm{BD}_{32}$), improving on the previous smallest examples\n$((11,2,3))$ and $((19,2,3))$. Extending the SS-LP approach to $((8,2,3))$, we\nconstruct new codes for $2m>36$, including one supporting a transversal\n$T^{1/4}$ gate ($\\mathrm{BD}_{64}$). These results reveal a far richer\nlandscape of nonadditive codes than previously recognized and underscore a\ndeeper connection between quantum error correction and the algebraic\nconstraints on transversal gate groups.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T15:18:33Z"}
{"aid":"http://arxiv.org/abs/2504.20849v1","title":"JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated\n  Marketing Text in the Music Industry","summary":"Online platforms are increasingly interested in using Data-to-Text\ntechnologies to generate content and help their users. Unfortunately,\ntraditional generative methods often fall into repetitive patterns, resulting\nin monotonous galleries of texts after only a few iterations. In this paper, we\ninvestigate LLM-based data-to-text approaches to automatically generate\nmarketing texts that are of sufficient quality and diverse enough for broad\nadoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in\nconjunction with fine-tuning, few-shot, and zero-shot approaches to set a\nbaseline for diverse marketing texts. We also introduce a metric JaccDiv to\nevaluate the diversity of a set of texts. This research extends its relevance\nbeyond the music industry, proving beneficial in various fields where\nrepetitive automated content generation is prevalent.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.20855v1","title":"Online General Knapsack with Reservation Costs","summary":"In the online general knapsack problem, an algorithm is presented with an\nitem $x=(s,v)$ of size $s$ and value $v$ and must irrevocably choose to pack\nsuch an item into the knapsack or reject it before the next item appears. The\ngoal is to maximize the total value of the packed items without overflowing the\nknapsack's capacity.\n  As this classical setting is way too harsh for many real-life applications,\nwe will analyze the online general knapsack problem under the reservation\nmodel. Here, instead of accepting or rejecting an item immediately, an\nalgorithm can delay the decision of whether to pack the item by paying a\nfraction $0\\le \\alpha$ of the size or the value of the item. This models many\npractical applications, where, for example, decisions can be delayed for some\ncosts e.g. cancellation fees. We present results for both variants: First, for\ncosts depending on the size of the items and then for costs depending on the\nvalue of the items.\n  If the reservation costs depend on the size of the items, we find a matching\nupper and lower bound of $2$ for every $\\alpha$. On the other hand, if the\nreservation costs depend on the value of the items, we find that no algorithm\nis competitive for reservation costs larger than $1/2$ of the item value, and\nwe find upper and lower bounds for the rest of the reservation range\n$0\\le\\alpha< 1/2$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-29T15:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.20856v1","title":"Wave Particle Interaction in the Upstream of ICME Shocks","summary":"Shocks associated with Interplanetary Coronal Mass Ejections are known to\nenergize charged particles and give rise to Solar Energetic Particles. Many of\nthese energetic particles move ahead of the shock to create a foreshock region.\nThe foreshock region primarily consists of solar wind plasma, exhibiting\nturbulent velocity and magnetic fields. Such turbulent behavior results from\ninherent solar wind turbulence modified by energetic particles. We analyze\nmagnetic field data from six such ICME shocks observed by the Wind spacecraft.\nThe analysis of the shock upstream shows that the magnetic power spectral\ndensity (PSD) maintains a power-law slope of $-5/3$. We also identify clear\nintermittent peaks in the PSD. After characterizing these peaks, we investigate\nvarious possibilities for their generation. Our analysis indicates that these\npeaks in the PSD are due to the resonant interaction of Alfv\\'en waves with the\nbulk solar wind protons and protons with energy up to $10$~keV. However,\nevidence of Alfv\\'en wave interaction with highly energetic protons is not\nevident in our analysis, and we anticipate that such evidence is obscured by\nthe prevailing solar wind turbulence in the shock upstream.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.plasm-ph","published":"2025-04-29T15:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.20928v1","title":"XRISM forecast for the Coma cluster: stormy, with a steep power spectrum","summary":"The XRISM Resolve microcalorimeter array measured the velocities of hot\nintracluster gas at two positions in the Coma galaxy cluster: 3'x3' squares at\nthe center and at 6' (170 kpc) to the south. We find the line-of-sight velocity\ndispersions in those regions to be sigma_z=208+-12 km/s and 202+-24 km/s,\nrespectively. The central value corresponds to a 3D Mach number of\nM=0.24+-0.015 and the ratio of the kinetic pressure of small-scale motions to\nthermal pressure in the intracluster plasma of only 3.1+-0.4%, at the lower end\nof predictions from cosmological simulations for merging clusters like Coma,\nand similar to that observed in the cool core of the relaxed cluster A2029.\nMeanwhile, the gas in both regions exhibits high line-of-sight velocity\ndifferences from the mean velocity of the cluster galaxies, Delta v_z=450+-15\nkm/s and 730+-30 km/s, respectively. A small contribution from an additional\ngas velocity component, consistent with the cluster optical mean, is detected\nalong a sightline near the cluster center. The combination of the observed\nvelocity dispersions and bulk velocities is not described by a Kolmogorov\nvelocity power spectrum of steady-state turbulence; instead, the data imply a\nmuch steeper effective slope (i.e., relatively more power at larger linear\nscales). This may indicate either a very large dissipation scale resulting in\nthe suppression of small-scale motions, or a transient dynamic state of the\ncluster, where large-scale gas flows generated by an ongoing merger have not\nyet cascaded down to small scales.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-29T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.20940v1","title":"Energy-Based Coarse-Graining in Molecular Dynamics: A Flow-Based\n  Framework Without Data","summary":"Coarse-grained (CG) models offer an effective route to reducing the\ncomplexity of molecular simulations, yet conventional approaches depend heavily\non long all-atom molecular dynamics (MD) trajectories to adequately sample\nconfigurational space. This data-driven dependence limits their accuracy and\ngeneralizability, as unvisited configurations remain excluded from the\nresulting CG model. We introduce a data-free generative framework for\ncoarse-graining that directly targets the all-atom Boltzmann distribution. Our\nmodel defines a structured latent space comprising slow collective variables,\nwhich are statistically associated with multimodal marginal densities capturing\nmetastable states, and fast variables, which represent the remaining degrees of\nfreedom with simple, unimodal conditional distributions. A potentially\nlearnable, bijective map from the full latent space to the all-atom\nconfiguration space enables automatic and accurate reconstruction of molecular\nstructures. The model is trained using an energy-based objective that minimizes\nthe reverse Kullback-Leibler divergence, relying solely on the interatomic\npotential rather than sampled trajectories. A tempering scheme is used to\nstabilize training and promote exploration of diverse configurations. Once\ntrained, the model can generate unbiased, one-shot equilibrium all-atom\nsamples. We validate the method on two synthetic systems-a double-well\npotential and a Gaussian mixture-as well as on the benchmark alanine dipeptide.\nThe model captures all relevant modes of the Boltzmann distribution, accurately\nreconstructs atomic configurations, and learns physically meaningful\ncoarse-grained representations, all without any simulation data.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cs.LG,physics.comp-ph","published":"2025-04-29T17:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.20962v1","title":"A Novel Method of Modeling Extended Emission of Compact Jets:\n  Application to Swift J1727.8-1613","summary":"Flat radio spectra of compact jets launched by both supermassive and\nstellar-mass black holes are explained by an interplay of self-absorbed\nsynchrotron emission up to some distance along the jet and optically thin\nsynchrotron at larger distances (Blandford & Konigl 1979). Their spatial\nstructure is usually studied using core shifts, in which the position of the\npeak (core) of the emission depends on the frequency. Here, we propose a novel\nmethod to fit the spatial dependence of the flux density at a given frequency\nof the jet and counterjet (when observed) using the theoretical spatial\ndependencies, which we provide as simple analytical formulae. We apply our\nmethod to the spatial structure of the jets in the luminous hard spectral state\nof the black-hole X-ray binary Swift J1727.8--1613. It was the most resolved\ncontinuous jet from an X-ray binary ever observed. We find that the observed\napproaching jet is significantly intrinsically stronger than the receding one,\nwhich we attribute to an increase in the emission of both jets with time\n(observationally confirmed), together with the light travel effect, causing the\nreceding jet to be observed at an earlier epoch than the approaching one. The\njets are relatively slow, with the velocity $\\sim(0.3$--$0.4)c$. Our findings\nimply that the magnetic field strength increased with time. Also, the magnetic\nflux is much lower than in jets launched by `Magnetically Arrested Disks'. Our\nmethod is general, and we propose that it be applied to jets launched by\nstellar-mass and supermassive black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T17:32:38Z"}
{"aid":"http://arxiv.org/abs/2504.20971v1","title":"A distance between operators acting in different Hilbert spaces and\n  operator convergence","summary":"The aim of the present article is to give an introduction to the concept of\nquasi-unitary equivalence and to define several (pseudo-)metrics on the space\nof self-adjoint operators acting possibly in different Hilbert spaces. As some\nof the ``metrics'' do not fulfill all properties of a metric (e.g. some lack\nthe triangle inequality or the definiteness), we call them ``distances'' here.\nTo the best of our knowledge, such distances are treated for the first time\nhere. The present article shall serve as a starting point of further research\n(see e.g. arXiv:2412.13165).","main_category":"math.FA","categories":"math.FA,math-ph,math.MP,math.SP","published":"2025-04-29T17:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.20985v1","title":"Acylindrically hyperbolic groups and counting problems","summary":"We show that Morse elements are generic in acylindrically hyperbolic groups.\nAs an application, we observe that fully irreducible outer automorphisms are\ngeneric in the outer automorphism group of a finite-rank free group.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-29T17:55:53Z"}
{"aid":"http://arxiv.org/abs/2504.21262v1","title":"Thermally Induced Refractive Index Trimming of Visible-Light Silicon\n  Nitride Waveguides Using Suspended Heaters","summary":"We demonstrate refractive index trimming of visible-light silicon nitride\n(SiN) waveguides using suspended heater structures. The thermal isolation of\nthe suspended heaters enabled a semi-uniform temperature distribution with\nestimated temperatures of $\\sim$350{\\deg}C in the waveguides without reaching\npotentially damaging temperatures in the titanium nitride resistive heaters.\nThe thermal isolation also enabled trimming temperatures to be reached with a\nmoderate power dissipation of 30 to 40 mW. At a wavelength of 561 nm, modal\neffective index changes up to $-8.3 \\times 10^{-3}$ were observed following\nthermal trimming, and the index changes were stable over an observation period\nof 97 days. The devices were fabricated as part of our visible-light integrated\nphotonics platform on 200-mm diameter silicon wafers. The suspended heaters\nalso functioned as efficient thermo-optic phase shifters with power dissipation\nfor a $\\pi$ phase shift of about $1.2-1.8$ mW. The trimming method was applied\nto set the bias points of thermo-optic Mach-Zehnder interferometer switches to\nreduce the bias power of five devices from $0.29-2.32$ mW to $0.1-0.16$ mW.\nThermal trimming at a wavelength of 445 nm was also demonstrated. Through\nmaterial analysis before and after thermal treatment, we hypothesize that index\ntrimming of the silica (SiO$_2$) waveguide cladding may be a potential\nunderlying mechanism. Additionally, via extrapolations of the measured trimming\ndata, we estimate the thermal aging behavior of the SiN waveguides in the\nsuspended heaters at lower (125 - 250{\\deg}C) operating temperatures.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T02:40:15Z"}
{"aid":"http://arxiv.org/abs/2504.21282v1","title":"Birdie: Natural Language-Driven Table Discovery Using Differentiable\n  Search Index","summary":"Natural language (NL)-driven table discovery identifies relevant tables from\nlarge table repositories based on NL queries. While current deep-learning-based\nmethods using the traditional dense vector search pipeline, i.e.,\nrepresentation-index-search, achieve remarkable accuracy, they face several\nlimitations that impede further performance improvements: (i) the errors\naccumulated during the table representation and indexing phases affect the\nsubsequent search accuracy; and (ii) insufficient query-table interaction\nhinders effective semantic alignment, impeding accuracy improvements. In this\npaper, we propose a novel framework Birdie, using a differentiable search\nindex. It unifies the indexing and search into a single encoder-decoder\nlanguage model, thus getting rid of error accumulations. Birdie first assigns\neach table a prefix-aware identifier and leverages a large language model-based\nquery generator to create synthetic queries for each table. It then encodes the\nmapping between synthetic queries/tables and their corresponding table\nidentifiers into the parameters of an encoder-decoder language model, enabling\ndeep query-table interactions. During search, the trained model directly\ngenerates table identifiers for a given query. To accommodate the continual\nindexing of dynamic tables, we introduce an index update strategy via parameter\nisolation, which mitigates the issue of catastrophic forgetting. Extensive\nexperiments demonstrate that Birdie outperforms state-of-the-art dense methods\nby 16.8% in accuracy, and reduces forgetting by over 90% compared to other\ncontinual learning approaches.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-30T03:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.21286v1","title":"NEP89: Universal neuroevolution potential for inorganic and organic\n  materials across 89 elements","summary":"Machine-learned potentials (MLPs) offer near-first-principles accuracy for\natomistic simulations, but many models are material-specific or computationally\nintensive, limiting their broader use. Here, we introduce NEP89, a foundation\nmodel based on the neuroevolution potential (NEP) architecture, delivering\nempirical-potential-like speed and high accuracy across 89 chemical elements. A\ncompact yet comprehensive training dataset covering inorganic and organic\nmaterials across 89 elements was curated through descriptor-space subsampling\nand an iterative active-learning-like process applied to multiple datasets. We\nrigorously evaluated NEP89's predictive performance against representative\nfoundation models, demonstrating its reliability and competitive accuracy\nacross diverse benchmark studies. NEP89 is 3-4 orders of magnitude more\ncomputationally efficient than comparable models, enabling previously\nimpractical large-scale atomistic simulations for both inorganic and organic\nsystems. It also supports fine-tuning on small datasets, allowing rapid\nadaptation to user-specific applications. This work marks a significant\nadvancement in MLPs, enabling high-performance atomistic simulations across\ndiverse research fields and communities.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.21315v1","title":"Long-time asymptotics of the coupled nonlinear SchÃ¶dinger equation in\n  a weighted Sobolev space","summary":"We study the Cauchy problem for the focusing coupled nonlinear Schr\\\"odinger\n(CNLS) equation with initial data $\\mathbf{q}_0$\n  lying in the weighted Sobolev space and the scattering data having $n$ simple\nzeros.\n  Based on the corresponding $3\\times3$ matrix spectral problem, we deduce the\nRiemann-Hilbert problem (RHP)\n  for CNLS equation through inverse scattering transform. We remove discrete\nspectrum of initial RHP using Darboux transformations.\n  By applying the nonlinear steepest-descent method for RHP introduced by Deift\nand Zhou,\n  we compute the long-time asymptotic\n  expansion of the solution $\\mathbf{q}(x,t)$ to an (optimal) residual error of\norder $\\mathcal{O}\\left(t^{-3 / 4+1/(2p)}\\right)$ where\n  $2\\le p<\\infty$. The leading order term in this expansion is a multi-soliton\nwhose parameters are modulated by soliton-soliton and\n  soliton-radiation interactions. Our work strengthens and extends the earlier\nwork regarding long-time\n  asymptotics for solutions of the nonlinear Schr\\\"odinger equation with a\ndelta potential and even initial data by Deift and Park.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-30T05:03:18Z"}
{"aid":"http://arxiv.org/abs/2504.21325v1","title":"Text-Conditioned Diffusion Model for High-Fidelity Korean Font\n  Generation","summary":"Automatic font generation (AFG) is the process of creating a new font using\nonly a few examples of the style images. Generating fonts for complex languages\nlike Korean and Chinese, particularly in handwritten styles, presents\nsignificant challenges. Traditional AFGs, like Generative adversarial networks\n(GANs) and Variational Auto-Encoders (VAEs), are usually unstable during\ntraining and often face mode collapse problems. They also struggle to capture\nfine details within font images. To address these problems, we present a\ndiffusion-based AFG method which generates high-quality, diverse Korean font\nimages using only a single reference image, focusing on handwritten and printed\nstyles. Our approach refines noisy images incrementally, ensuring stable\ntraining and visually appealing results. A key innovation is our text encoder,\nwhich processes phonetic representations to generate accurate and contextually\ncorrect characters, even for unseen characters. We used a pre-trained style\nencoder from DG FONT to effectively and accurately encode the style images. To\nfurther enhance the generation quality, we used perceptual loss that guides the\nmodel to focus on the global style of generated images. Experimental results on\nover 2000 Korean characters demonstrate that our model consistently generates\naccurate and detailed font images and outperforms benchmark methods, making it\na reliable tool for generating authentic Korean fonts across different styles.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.21349v1","title":"Gorenstein homological modules over tensor rings","summary":"For a tensor ring $T_R(M)$, under certain conditions, we characterize the\nGorenstein projective modules over $T_R(M)$, and prove that a $T_R(M)$-module\n$(X,u)$ is Gorenstein projective if and only if $u$ is monomorphic and ${\\rm\ncoker}(u)$ is a Gorenstein projective $R$-module. Gorenstein injective (resp.,\nflat) modules over $T_R(M)$ are also explicitly described. Moreover, we give a\ncharacterization for the coherence of $T_R(M)$. Some applications to trivial\nring extensions and Morita context rings are given.","main_category":"math.RA","categories":"math.RA,math.KT","published":"2025-04-30T06:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.21364v1","title":"Uniform-in-time weak error estimates of explicit full-discretization\n  schemes for SPDEs with non-globally Lipschitz coefficients","summary":"This article is devoted to long-time weak approximations of stochastic\npartial differential equations (SPDEs) evolving in a bounded domain\n$\\mathcal{D} \\subset \\mathbb{R}^d$, $d \\leq 3$, with non-globally Lipschitz and\npossibly non-contractive coefficients. Both the space-time white noise ($d=1$)\nand the trace-class noise in multiple dimensions $d=2,3$ are examined for the\nconsidered SPDEs. Based on a spectral Galerkin spatial semi-discretization, we\npropose a class of novel full-discretization schemes of exponential type, which\nare explicit, easily implementable and preserve the ergodicity of the original\ndissipative SPDEs with possibly non-contractive coefficients. The\nuniform-in-time weak approximation errors are carefully analyzed in a low\nregularity and non-contractive setting, with uniform-in-time weak convergence\nrates obtained. A key ingredient is to establish the uniform-in-time moment\nbounds (in $L^{4q-2}$-norm, $q \\geq 1$) for the proposed fully discrete schemes\nin a super-linear setting. This is highly non-trivial for the explicit\nfull-discretization schemes and new arguments are elaborated by fully\nexploiting a contractive property of the semi-group in $L^{4q-2}$, the\ndissipativity of the nonlinearity and the particular benefit of the taming\nstrategy. Numerical experiments are finally reported to verify the theoretical\nfindings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T06:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.21366v1","title":"DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic\n  Gating Fusion","summary":"Current Audio-Visual Source Separation methods primarily adopt two design\nstrategies. The first strategy involves fusing audio and visual features at the\nbottleneck layer of the encoder, followed by processing the fused features\nthrough the decoder. However, when there is a significant disparity between the\ntwo modalities, this approach may lead to the loss of critical information. The\nsecond strategy avoids direct fusion and instead relies on the decoder to\nhandle the interaction between audio and visual features. Nonetheless, if the\nencoder fails to integrate information across modalities adequately, the\ndecoder may be unable to effectively capture the complex relationships between\nthem. To address these issues, this paper proposes a dynamic fusion method\nbased on a gating mechanism that dynamically adjusts the modality fusion\ndegree. This approach mitigates the limitations of solely relying on the\ndecoder and facilitates efficient collaboration between audio and visual\nfeatures. Additionally, an audio attention module is introduced to enhance the\nexpressive capacity of audio features, thereby further improving model\nperformance. Experimental results demonstrate that our method achieves\nsignificant performance improvements on two benchmark datasets, validating its\neffectiveness and advantages in Audio-Visual Source Separation tasks.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-30T06:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.21378v1","title":"The polynomial growth of effective resistances in one-dimensional\n  critical long-range percolation","summary":"We study the critical long-range percolation on $\\mathbb{Z}$, where an edge\nconnects $i$ and $j$ independently with probability\n$1-\\exp\\{-\\beta\\int_i^{i+1}\\int_j^{j+1}|u-v|^{-2}{\\rm d} u{\\rm d} v\\}$ for\n$|i-j|>1$ for some fixed $\\beta>0$ and with probability 1 for $|i-j|=1$.\nViewing this as a random electric network where each edge has a unit\nconductance, we show that the effective resistances from 0 to $[-n,n]^c$ and\nfrom the interval $[-n,n]$ to $[-2n,2n]^c$ (conditioned on no edge joining\n$[-n,n]$ and $[-2n,2n]^c$) both grow like $n^{\\delta(\\beta)}$ for some\n$\\delta(\\beta)\\in (0,1)$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T07:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.21399v1","title":"The golden age of solar magnetography at Paris-Meudon observatory in the\n  second half of the twentieth century","summary":"This paper describes advances in solar magnetography and developments in\ninstrumental techniques of polarimetry and spectroscopy made at Paris-Meudon\nobservatory in the second half of the twentieth century. The adventure started\nfrom Lyot expertise and extended progressively to the measurement of vector\nmagnetic fields using various and improving polarimetric techniques (such as\nbeam exchange or grid) or new spectroscopic methods (such as the MSDP imaging\nslicer), at Meudon and Pic du Midi, ending by the achievement of the\nstate-of-the-art optimized and polarization free telescope THEMIS in 1999.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-30T07:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.21428v1","title":"UAV Marketplace Simulation Tool for BVLOS Operations","summary":"We present a simulation tool for evaluating team formation in autonomous\nmulti-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of\nSight (BVLOS). The tool models UAV collaboration and mission execution in\ndynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt\noperations. Our tool allows researchers to integrate and compare various team\nformation strategies in a controlled environment with configurable mission\nparameters and adversarial behaviors. The log of each simulation run is stored\nin a structured way along with performance metrics so that statistical analysis\ncould be done straightforwardly. The tool is versatile for testing and\nimproving UAV coordination strategies in real-world applications.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.DC","published":"2025-04-30T08:36:22Z"}
{"aid":"http://arxiv.org/abs/2504.21438v1","title":"Wasserstein-Aitchison GAN for angular measures of multivariate extremes","summary":"Economically responsible mitigation of multivariate extreme risks -- extreme\nrainfall in a large area, huge variations of many stock prices, widespread\nbreakdowns in transportation systems -- requires estimates of the probabilities\nthat such risks will materialize in the future. This paper develops a new\nmethod, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN), which\nprovides simulated values of future $d$-dimensional multivariate extreme events\nand which hence can be used to give estimates of such probabilities. The main\nhypothesis is that, after transforming the observations to the unit-Pareto\nscale, their distribution is regularly varying in the sense that the\ndistributions of their radial and angular components (with respect to the\n$L_1$-norm) converge and become asymptotically independent as the radius gets\nlarge. The method is a combination of standard extreme value analysis modeling\nof the tails of the marginal distributions with nonparametric GAN modeling of\nthe angular distribution. For the latter, the angular values are transformed to\nAitchison coordinates in a full $(d-1)$-dimensional linear space, and a\nWasserstein GAN is trained on these coordinates and used to generate new\nvalues. A reverse transformation is then applied to these values and gives\nsimulated values on the original data scale. The method shows good performance\ncompared to other existing methods in the literature, both in terms of\ncapturing the dependence structure of the extremes in the data, as well as in\ngenerating accurate new extremes of the data distribution. The comparison is\nperformed on simulated multivariate extremes from a logistic model in\ndimensions up to 50 and on a 30-dimensional financial data set.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-30T08:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.21441v1","title":"Diffusion of intruders in a granular gas thermostatted by a bath of\n  elastic hard spheres","summary":"The Boltzmann kinetic equation is considered to compute the transport\ncoefficients associated with the mass flux of intruders in a granular gas.\nIntruders and granular gas are immersed in a gas of elastic hard spheres\n(molecular gas). We assume that the granular particles are sufficiently\nrarefied so that the state of the molecular gas is not affected by the presence\nof the granular gas. Thus, the gas of elastic hard spheres can be considered as\na thermostat (or bath) at a fixed temperature $T_g$. In the absence of spatial\ngradients, the system achieves a steady state where the temperature of the\ngranular gas $T$ differs from that of the intruders $T_0$ (energy\nnonequipartition). Approximate theoretical predictions for the temperature\nratios $T/T_g$ and $T_0/T_g$ and the kurtosis $c$ and $c_0$ associated with the\ngranular gas and the intruders compare very well with Monte Carlo simulations\nfor conditions of practical interest. For states close to the steady\nhomogeneous state, the Boltzmann equation for the intruders is solved by means\nof the Chapman--Enskog method to first order in the spatial gradients. As\nexpected, the diffusion transport coefficients are given in terms of the\nsolutions of a set of coupled linear integral equations which are approximately\nsolved by considering the first-Sonine approximation. In dimensionless form,\nthe transport coefficients are nonlinear functions of the mass and diameter\nratios, the coefficients of restitution, and the (reduced) bath temperature.\nInterestingly, previous results derived from a suspension model based on an\neffective fluid-solid interaction force are recovered when $m/m_g\\to \\infty$\nand $m_0/m_g\\to \\infty$, where $m$, $m_0$, and $m_g$ are the masses of the\ngranular, intruder, and molecular gas particle, respectively. Finally, as an\napplication of our results, thermal diffusion segregation is exhaustively\nanalysed.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-30T08:56:18Z"}
{"aid":"http://arxiv.org/abs/2504.21451v1","title":"Powers of 2 in Balanced Grid Colourings","summary":"Let $B(m, n)$ be the number of ways to colour a $2m \\times 2n$ grid in black\nand white so that, in each row and each column, half of the cells are white and\nhalf are black. Bhattacharya conjectured that the exponent of $2$ in the prime\nfactorisation of $B(m, n)$ equals $s_2(m)s_2(n)$, where $s_2(x)$ denotes the\nnumber of $1$s in the binary expansion of $x$. We confirm this conjecture in\nsome infinite families of special cases; most significantly, when $m$ is of the\nform either $2^k$ or $2^k + 1$ and $n$ is arbitrary. The proof when $m = 2^k +\n1$ is substantially more difficult, and in connection with it we develop some\ngeneral techniques for the analysis of inequalities between binary digit sums.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.21469v1","title":"Turning a Disposable Bronchoscope into a Dynamic Speckle Imaging Tool:\n  Yes, It Works","summary":"Dynamic speckle imaging, typically used in laser-illuminated surface\ndiagnostics, has proven valuable for assessing biological activity. In this\nwork, we demonstrate its feasibility in an endoscopic context using a\ndisposable bronchoscope. Despite technical limitations and aliasing artifacts,\nour preliminary results show discernible vascular structures, indicating\npotential for minimally invasive diagnostic applications. It is important to\nnote that the imaging systems used in this study are designed primarily for\nclinical robustness and classical imaging, including single-use sterility, ease\nof handling, and real-time visualization, and not for scientific fidelity of\nvisual data or computational post-processing. As such, they are not inherently\nsuited to dynamic speckle analysis, which requires precise control over\ntemporal acquisition parameters, linear response characteristics of the imaging\nsensor, and stable illumination conditions, particularly from the coherent\nlaser source. Nevertheless, our results demonstrate that, even within these\nconstraints, dynamic speckle imaging is indeed achievable. This opens the door\nto further adaptation and optimization of such clinical imaging tools for\nfunctional biomedical investigations.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.med-ph","published":"2025-04-30T09:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.21471v1","title":"Efficiently Finding All Minimal and Shortest Absent Subsequences in a\n  String","summary":"Given a string $w$, another string $v$ is said to be a subsequence of $w$ if\n$v$ can be obtained from $w$ by removing some of its letters; on the other\nhand, $v$ is called an absent subsequence of $w$ if $v$ is not a subsequence of\n$w$. The existing literature on absent subsequences focused on understanding,\nfor a string $w$, the set of its shortest absent subsequences (i.e., the\nshortest strings which are absent subsequences of $w$) and that of its minimal\nabsent subsequences (i.e., those strings which are absent subsequences of $w$\nbut whose every proper subsequence occurs in $w$). Our contributions to this\narea of research are the following. Firstly, we present optimal algorithms\n(with linear time preprocessing and output-linear delay) for the enumeration of\nthe shortest and, respectively, minimal absent subsequences. Secondly, we\npresent optimal algorithms for the incremental enumeration of these strings\nwith linear time preprocessing and constant delay; in this setting, we only\noutput short edit-scripts showing how the currently enumerated string differs\nfrom the previous one. Finally, we provide an efficient algorithm for\nidentifying a longest minimal absent subsequence of a string. All our\nalgorithms improve the state-of-the-art results for the aforementioned\nproblems.","main_category":"cs.DS","categories":"cs.DS,cs.FL","published":"2025-04-30T09:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.21490v1","title":"Investigation of magnon behavior in YIG film under microwave excitation\n  using Brillouin light scattering","summary":"We utilize conventional wave-vector-resolved Brillouin light scattering\ntechnology to investigate the spin wave response in YIG thin films under\nhigh-power microwave excitation. By varying the microwave frequency, external\nbias magnetic field, and in-plane wave vector, in addition to observing the\ndipole-exchange spin waves excited by parallel parametric pumping, we further\nobserve broadband spin wave excitation within the dipole-exchange spin wave\nspectrum. This broadband excitation results from the combined effects of\nparallel and perpendicular parametric pumping, induced by irregularities in the\nexcitation geometry, as well as magnon-magnon scattering arising from the\nabsence of certain spin wave modes. Our findings offer new insights into the\nmechanisms of energy dissipation and relaxation processes caused by spin wave\nexcitation in magnetic devices operating at high power.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T10:18:46Z"}
{"aid":"http://arxiv.org/abs/2504.21528v1","title":"Impairments are Clustered in Latents of Deep Neural Network-based Speech\n  Quality Models","summary":"In this article, we provide an experimental observation: Deep neural network\n(DNN) based speech quality assessment (SQA) models have inherent latent\nrepresentations where many types of impairments are clustered. While DNN-based\nSQA models are not trained for impairment classification, our experiments show\ngood impairment classification results in an appropriate SQA latent\nrepresentation. We investigate the clustering of impairments using various\nkinds of audio degradations that include different types of noises, waveform\nclipping, gain transition, pitch shift, compression, reverberation, etc. To\nvisualize the clusters we perform classification of impairments in the\nSQA-latent representation domain using a standard k-nearest neighbor (kNN)\nclassifier. We also develop a new DNN-based SQA model, named DNSMOS+, to\nexamine whether an improvement in SQA leads to an improvement in impairment\nclassification. The classification accuracy is 94% for LibriAugmented dataset\nwith 16 types of impairments and 54% for ESC-50 dataset with 50 types of real\nnoises.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-30T11:22:12Z"}
{"aid":"http://arxiv.org/abs/2504.21539v1","title":"Search for the lepton number violation decay $Ï\\to Ï^+ Ï^+\n  e^-e^- +c.c.$","summary":"The lepton number violation decay $\\omega \\to \\pi^+ \\pi^+ e^-e^- +c.c.$ is\nsearched for via $J/\\psi \\to \\omega\\eta$ using a data sample of $(1.0087 \\pm\n0.0044) \\times 10^{10}$ $J/\\psi$ events collected by the BESIII detector at the\nBEPCII collider. No significant signal is observed, and the upper limit on the\nbranching fraction of $\\omega \\to \\pi^+ \\pi^+ e^-e^- +c.c.$ at the 90\\%\nconfidence level is determined for the first time to be $2.8 \\times 10^{-6}$.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T11:36:18Z"}
{"aid":"http://arxiv.org/abs/2504.21567v1","title":"PolyQROM: Orthogonal-Polynomial-Based Quantum Reduced-Order Model for\n  Flow Field Analysis","summary":"Quantum computing promises exponential acceleration for fluid flow\nsimulations, yet the measurement overhead required to extract flow features\nfrom quantum-encoded flow field data fundamentally undermines this advantage--a\ncritical challenge termed the ``output problem''. To address this, we propose\nan orthogonal-polynomial-based quantum reduced-order model (PolyQROM) that\nintegrates orthogonal polynomial basis transformations with variational quantum\ncircuits (VQCs). PolyQROM employs optimized polynomial-based quantum operations\nto compress flow field data into low-dimensional representations while\npreserving essential features, enabling efficient quantum or classical\npost-processing for tasks like reconstruction and classification. By leveraging\nthe mathematical properties of orthogonal polynomials, the framework enhances\ncircuit expressivity and stabilizes training compared to conventional\nhardware-efficient VQCs. Numerical experiments demonstrate PolyQROM's\neffectiveness in reconstructing flow fields with high fidelity and classifying\nflow patterns with accuracy surpassing classical methods and quantum\nbenchmarks, all while reducing computational complexity and parameter counts.\nThe work bridges quantum simulation outputs with practical fluid analysis,\naddressing the ``output problem'' through efficient reduced-order modeling\ntailored for quantum-encoded flow data, offering a scalable pathway to exploit\nquantum advantages in computational fluid dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T12:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.21595v1","title":"Real-time Program Evaluation using Anytime-valid Rank Tests","summary":"Counterfactual mean estimators such as difference-in-differences and\nsynthetic control have grown into workhorse tools for program evaluation.\nInference for these estimators is well-developed in settings where all\npost-treatment data is available at the time of analysis. However, in settings\nwhere data arrives sequentially, these tests do not permit real-time inference,\nas they require a pre-specified sample size T. We introduce real-time inference\nfor program evaluation through anytime-valid rank tests. Our methodology relies\non interpreting the absence of a treatment effect as exchangeability of the\ntreatment estimates. We then convert these treatment estimates into sequential\nranks, and construct optimal finite-sample valid sequential tests for\nexchangeability. We illustrate our methods in the context of\ndifference-in-differences and synthetic control. In simulations, they control\nsize even under mild exchangeability violations. While our methods suffer\nslight power loss at T, they allow for early rejection (before T) and preserve\nthe ability to reject later (after T).","main_category":"econ.EM","categories":"econ.EM,stat.ME","published":"2025-04-30T12:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.21630v1","title":"Superconductivity and trimers on attractive-$U$ Hubbard ladders","summary":"We investigate the interplay between superconducting correlations and trimer\nformation in polarized two-component Fermi gases confined to multileg\nattractive-$U$ Hubbard ladders. Employing density matrix renormalization group\n(DMRG) simulations, we explore the effects of spin-dependent tunneling\namplitudes on these systems. Specifically, we analyze how bound states of three\nfermions (trimers) impact Fulde-Ferrell-Larkin-Ovchinnikov (FFLO)\nsuperconducting correlations at commensurate charge carrier densities, where\n$2n_{\\uparrow} = n_{\\downarrow}$. In one-dimensional (1D) systems, trimer\nformation is known to suppress FFLO correlations exponentially. Our results\ndemonstrate that this suppression persists on ladder lattices of small width,\neffectively mirroring the 1D behavior. However, we find a striking departure\nfrom the 1D regime as the ladder width increases. On ladders with a width of\nfour legs, the influence of trimers on superconducting correlations becomes\nnegligible, suggesting that wider ladder systems provide a distinct environment\nwhere FFLO-like pairing remains robust even in the presence of trimer states.\nThese findings underscore the dimensional crossover in Hubbard systems and shed\nlight on the mechanisms governing superconductivity and bound-state formation\nin strongly correlated fermionic systems. Our work has implications for\nunderstanding unconventional superconductivity in strongly correlated systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-30T13:33:06Z"}
{"aid":"http://arxiv.org/abs/2504.21645v1","title":"The effect of neon seeding on plasma edge transport in EAST","summary":"The effect of neon seeding on different transport mechanisms in EAST is\ninvestigated by analyzing SOLPSITER simulations. By evaluating the agreement\nbetween experimental observations and the performed simulations, four\nsimulations are selected for a detailed analysis. In this analysis, it is shown\nthat the presence of neon reduces the influence of drifts on the simulated\nprofiles. In the simulation results, double peaked profiles/profiles with two\nvalleys are observed at the divertor targets which can be explained by the\nparallel drift velocities These drifts move particles from the outboard towards\nthe inboard side and, in that way, also increase the ionization sources at the\ninboard side. It is shown that Ne+ leaks towards the core making it difficult\nto perform experiments which contain as much neon as in the SOLPS-ITER\nsimulations. In fact, the level of neon in the experiments is limited by the HL\nbacktransition which takes place if higher order states of neon ionize in the\ncore and cause in that way too much core radiation. Furthermore, the analysis\nof the radiated power profiles suggests that the presence of other radiators\nbesides neon is important to bring the experiments into detachment. The\nionization of deuterium is the most important neutral reaction present in the\nsimulations. The amount of ionized deuterium is decreased when large amounts of\nneon are present and the anomalous transport is modified. Therefore, it is\nconcluded that for the analyzed simulations, neon increases the radiated power\nfraction, decreases the deuterium ionization, increases the neutral friction,\nbut does not manage to cause significant influence of deuterium recombination.\nAs a consequence, volumetric recombination only plays a minor role in the\nstudied simulations.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-30T13:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.21677v1","title":"20min-XD: A Comparable Corpus of Swiss News Articles","summary":"We present 20min-XD (20 Minuten cross-lingual document-level), a\nFrench-German, document-level comparable corpus of news articles, sourced from\nthe Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises\naround 15,000 article pairs spanning 2015 to 2024, automatically aligned based\non semantic similarity. We detail the data collection process and alignment\nmethodology. Furthermore, we provide a qualitative and quantitative analysis of\nthe corpus. The resulting dataset exhibits a broad spectrum of cross-lingual\nsimilarity, ranging from near-translations to loosely related articles, making\nit valuable for various NLP applications and broad linguistically motivated\nstudies. We publicly release the dataset in document- and sentence-aligned\nversions and code for the described experiments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T14:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.21688v1","title":"Assessing Racial Disparities in Healthcare Expenditures Using Causal\n  Path-Specific Effects","summary":"Racial disparities in healthcare expenditures are well-documented, yet the\nunderlying drivers remain complex and require further investigation. This study\nemploys causal and counterfactual path-specific effects to quantify how various\nfactors, including socioeconomic status, insurance access, health behaviors,\nand health status, mediate these disparities. Using data from the Medical\nExpenditures Panel Survey, we estimate how expenditures would differ under\ncounterfactual scenarios in which the values of specific mediators were aligned\nacross racial groups along selected causal pathways. A key challenge in this\nanalysis is ensuring robustness against model misspecification while addressing\nthe zero-inflation and right-skewness of healthcare expenditures. For reliable\ninference, we derive asymptotically linear estimators by integrating influence\nfunction-based techniques with flexible machine learning methods, including\nsuper learners and a two-part model tailored to the zero-inflated, right-skewed\nnature of healthcare expenditures.","main_category":"stat.AP","categories":"stat.AP,stat.ME,stat.ML","published":"2025-04-30T14:23:50Z"}
{"aid":"http://arxiv.org/abs/2504.21711v1","title":"The Intermediate-Mass Black Hole Reverberation Mapping Project: First\n  Detection of Mid-Infrared Lags in Prototypical IMBHs in NGC 4395 and POX 52","summary":"The search for robust evidence of intermediate-mass black holes (IMBHs) is\ncrucial for understanding black hole seeding process and the formation of\nsupermassive black holes in the early Universe. NGC 4395 and POX 52 are two\nprototypical IMBH hosts, both exhibiting multi-line evidence of low-mass black\nhole activity. Here, we report the first detection of mid-infrared (MIR) lags\nin response to optical variability, with measurements of $3.0^{+2.4}_{-1.9}$\ndays for NGC 4395 and $35.2^{+14.2}_{-11.7}$ days for POX~52 at $3.4$ $\\mu$m,\nrespectively, using archival optical data and observations from the Wide-field\nInfrared Survey Explorer (WISE). This detection provides the first\nreverberation evidence of low-mass black hole activity in POX 52. The time lags\nof these two low-mass, low-luminosity active galactic nuclei (AGNs) generally\nfollow the extent of the $R_{\\rm dust}-L_{\\rm 5100}$ relation found in\nhigher-mass AGNs. Based on an empirical relation between the broad-line region\nand dusty torus size, we constrain the black hole mass of POX 52 to log($M_{\\rm\nBH}$/$M_\\odot$) = 5.5 $\\pm$ 0.37 (systemic and statistical errors), confirming\nits IMBH nature. Furthermore, long-term optical continuum monitoring of POX 52\nreveals a mild inter-band lag of $\\lesssim$ 1 day. However, no significant\nintranight variability was detected during its one-night, high-cadence\nmonitoring, which we attribute to the longer duty cycle of fast variability in\nPOX 52 compared to that in NGC 4395.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T14:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.21717v1","title":"Characterization and optimization of heat engines: Pareto-optimal fronts\n  and universal features","summary":"Characterizing and optimizing nanoscopic heat engines require an appropriate\nunderstanding of the interplay between power, efficiency, entropy production\nand fluctuations. Despite significant recent advancements, including linear\nstochastic thermodynamics and thermodynamic uncertainty relations (TURs), a\ncomplete scenario remains elusive. In this work, we give a further step by\nshowing that, under certain common and general conditions, the heat engine\nregime can be characterized by the minima of power fluctuations and entropy\nproduction, which together delimit its optimal performance, achieved when these\nconditions are fully satisfied. Conversely, when these conditions are not\nstrictly met, the occurrence of the minimum still approximately describes the\nsystem, suggesting a broader range of applicability. Contrasting with most of\nstudies in which the system optimization is carried out solely taking into\naccount the power and efficiency, we introduce a multi-objective optimization\nframework based on Pareto fronts, also considering the role of fluctuation and\ndissipation. Our results reveal a general trend: while simultaneous\noptimization over a few parameters typically yields convex Pareto fronts, these\nfronts become concave as more parameters are varied freely and non-conservative\ndriving becomes significant. Illustrating our findings, we consider simple two\nand three state systems as well as richer collective systems, exhibiting novel\naspects of optimizations and protocol phase transitions.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-30T15:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.21722v1","title":"Discrete Generating Series and Linear Difference Equations","summary":"We define discrete generating series for arbitrary functions \\( f \\colon\n\\mathbb{Z}^n \\rightarrow \\mathbb{C} \\) and derive functional relations that\nthese series satisfy. For linear difference equations with constant\ncoefficients, we establish explicit functional equations linking the generating\nseries to the initial data, and for equations with polynomial coefficients, we\nintroduce an analogue of Stanley's \\( D \\)-finiteness criterion, proving that a\ndiscrete generating series is \\( D \\)-finite if and only if the corresponding\nsequence is polynomially recursive. The framework is further generalized to\nmultidimensional settings, where we investigate the interplay between discrete\ngenerating series and solutions to Cauchy problems for difference equations.\nKey structural properties are uncovered through the introduction of polynomial\nshift operators and projection techniques. The theory is illustrated with\nconcrete examples, including the Tribonacci recurrence and Schr\\\"oder's second\nproblem.","main_category":"math.CA","categories":"math.CA,math.DS","published":"2025-04-30T15:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.21726v1","title":"Notes sur l'application d'Albanese pour les zÃ©ro-cycles","summary":"For a smooth projective variety X over an arbitrary field k, we discuss the\nsurjectivity of the Albanese map from the Chow group of zero-cycles of degree\nzero on X to the group of rational points of the Albanese variety of X. Over\narithmetic fields, we use Severi-Brauer fibrations to produce examples where\nthe map is not surjective. For varieties X over the complex field, we discuss\nthe question after extension of the complex field to function fields of\nvarieties. This is related to C. Voisin's notion of universal zero-cycle and to\nrationality questions for rationally connected threefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T15:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.21732v1","title":"Hadronic tau decays","summary":"We give a pedagogical introduction to the rich phenomenology of hadronic tau\ndecays. These decays provide a unique window into the interplay of electroweak\nand strong interactions at low energies, as they occur primarily via $W$\nexchange after the electroweak quark current hadronizes. In this manuscript, we\nsummarize the basic ingredients required to perform precision physics studies\nin this sector. We detail the derivation of the different distributions within\nthe Standard Model, discuss how to parametrize the non-perturbative QCD\ndynamics, and present methods commonly used to achieve clean theoretical\npredictions. Additionally, we briefly review how these distributions generalize\nin the presence of relatively heavy particles from beyond the Standard Model.\nThis overview thus aims to serve as a useful starting point for readers\ninterested in understanding how the only lepton capable of decaying into\nhadrons does so.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-30T15:22:05Z"}
{"aid":"http://arxiv.org/abs/2504.21737v1","title":"Observation of Intrinsic and LED Light-Enhanced Memristor Performance in\n  In-Plane Ferroelectric NbOI2","summary":"Two-dimensional (2D) layered ferroelectrics, as an emerging area of research,\nhave attracted extensive attention, while memristors based on new 2D\nferroelectric materials have yet to be fully explored, thereby limiting their\napplications in modern nanoelectronics. In this work, we report the observation\nof intrinsic memristive behavior in a newly discovered 2D in-plane\nferroelectric material, NbOI2, and the giant enhancement of the memristive\nperformance using LED visible light. The results show that NbOI2 exhibits\nintrinsically strong memristive response with a current on/off ratio of up to\n10^4 and stable switching cycles, which is independent of back-gate voltage.\nUnder LED visible light illumination, the current on/off ratio in NbOI2 is over\none order of magnitude higher than that without light, meanwhile, the coercive\nfield is significantly reduced to less than 1.22 kVcm-1, much lower than other\n2D ferroelectric material-based memristors. Interestingly, both the intrinsic\nand the light-enhanced resistive switching phenomena only occur along the\nin-plane b-axis direction, indicating that the memristive behavior in NbOI2 is\ndriven by electric field-induced and optical field-enhanced ferroelectric\npolarization switching mechanisms, as evidenced by a combined\norientation-dependent electrical/optoelectrical measurement and sweep\ncycle-induced structural evolution analysis. Our study not only provides a\nmaterials strategy based on new 2D ferroelectrics for designing memristor\napplications, but also offers a simple optical method to enhance its\nperformance, paving the path for its implementation in novel nanoelectronics\nand optoelectronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-30T15:33:37Z"}
{"aid":"http://arxiv.org/abs/2504.21769v1","title":"LLM-based Interactive Imitation Learning for Robotic Manipulation","summary":"Recent advancements in machine learning provide methods to train autonomous\nagents capable of handling the increasing complexity of sequential\ndecision-making in robotics. Imitation Learning (IL) is a prominent approach,\nwhere agents learn to control robots based on human demonstrations. However, IL\ncommonly suffers from violating the independent and identically distributed\n(i.i.d) assumption in robotic tasks. Interactive Imitation Learning (IIL)\nachieves improved performance by allowing agents to learn from interactive\nfeedback from human teachers. Despite these improvements, both approaches come\nwith significant costs due to the necessity of human involvement. Leveraging\nthe emergent capabilities of Large Language Models (LLMs) in reasoning and\ngenerating human-like responses, we introduce LLM-iTeach -- a novel IIL\nframework that utilizes an LLM as an interactive teacher to enhance agent\nperformance while alleviating the dependence on human resources. Firstly,\nLLM-iTeach uses a hierarchical prompting strategy that guides the LLM in\ngenerating a policy in Python code. Then, with a designed similarity-based\nfeedback mechanism, LLM-iTeach provides corrective and evaluative feedback\ninteractively during the agent's training. We evaluate LLM-iTeach against\nbaseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a\nstate-of-the-art IIL method using a human teacher, on various robotic\nmanipulation tasks. Our results demonstrate that LLM-iTeach surpasses BC in the\nsuccess rate and achieves or even outscores that of CEILing, highlighting the\npotential of LLMs as cost-effective, human-like teachers in interactive\nlearning environments. We further demonstrate the method's potential for\ngeneralization by evaluating it on additional tasks. The code and prompts are\nprovided at: https://github.com/Tubicor/LLM-iTeach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T16:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.21772v1","title":"Solving Copyright Infringement on Short Video Platforms: Novel Datasets\n  and an Audio Restoration Deep Learning Pipeline","summary":"Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-30T16:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.21785v1","title":"Frozen Gaussian Grid-point Correction For Semi-classical SchrÃ¶dinger\n  Equation","summary":"We propose an efficient reconstruction algorithm named the frozen Gaussian\ngrid-point correction (FGGC) for computing the Schr\\\"odinger equation in the\nsemi-classical regime using the frozen Gaussian approximation (FGA). The FGA\nhas demonstrated its superior efficiency in dealing with semi-classical\nproblems and high-frequency wave propagations. However, reconstructing the wave\nfunction from a large number of Gaussian wave-packets is typically\ncomputationally intensive. This difficulty arises because these wave-packets\npropagate along the FGA trajectories to non-grid positions, making the\napplication of the fast Fourier transform infeasible. In this work, we\nintroduce the concept of ``on-grid correction'' and derive the formulas for the\nleast squares approximation of Gaussian wave-packets, and also provide a\ndetailed process of the FGGC algorithm. Furthermore, we rigorously prove that\nthe error introduced by the least squares approximation on each Gaussian\nwave-packet is independent of the semi-classical parameter $\\varepsilon$.\nNumerical experiments show that the FGGC algorithm can significantly improve\nreconstruction efficiency while introducing only negligible error, making it a\npowerful tool for solving the semi-classical Schr\\\"odinger equation, especially\nin applications requiring both accuracy and efficiency.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T16:43:28Z"}
{"aid":"http://arxiv.org/abs/2504.21817v1","title":"Anomalous Josephson effect in hybrid superconductor-hole systems","summary":"We consider hybrid systems consisting of a hole-doped semiconductor coupled\nto electronic states of finite-size superconductors, where the opposite sign of\nthe masses in the two subsystems give rise to insulating gaps at subband\nanticrossings. Consequently, increasing the coupling strength to the\nsuperconductor can paradoxically suppress the proximity-induced\nsuperconductivity in the semiconductor by enhancing these insulating gaps. We\ndemonstrate that the presence of such induced insulating gaps leads to a\ncharacteristic anomalous behavior of the critical supercurrent in Josephson\njunctions based on these hybrid structures. Our findings provide important\ninsights for the design of robust quantum computing platforms utilizing hybrid\nsuperconductor-hole systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-30T17:23:53Z"}
{"aid":"http://arxiv.org/abs/2504.21832v1","title":"Optimal Dynamic Control of Bounded Jacobian Discrete-Time Systems via\n  Interval Observers","summary":"This paper presents an optimal dynamic control framework for bounded Jacobian\nnonlinear discrete-time (DT) systems with nonlinear observations affected by\nboth state and process noise. Rather than directly stabilizing the uncertain\nsystem, we focus on stabilizing an interval observer in a higher dimensional\nspace, whose states bound the true system states. Our nonlinear dynamic control\nmethod introduces added flexibility over traditional static and linear\napproaches, effectively compensating for system nonlinearities and enabling\npotentially tighter closed-loop intervals. Additionally, we establish a\nseparation principle that allows for the design of observer and control gains.\nWe further derive tractable matrix inequalities to ensure system stability in\nthe closed-loop configuration. The simulation results show that the proposed\ndynamic control approach significantly outperforms a static counterpart method.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T17:39:09Z"}
{"aid":"http://arxiv.org/abs/2504.21841v1","title":"Neuro-Symbolic Generation of Explanations for Robot Policies with\n  Weighted Signal Temporal Logic","summary":"Neural network-based policies have demonstrated success in many robotic\napplications, but often lack human-explanability, which poses challenges in\nsafety-critical deployments. To address this, we propose a neuro-symbolic\nexplanation framework that generates a weighted signal temporal logic (wSTL)\nspecification to describe a robot policy in a interpretable form. Existing\nmethods typically produce explanations that are verbose and inconsistent, which\nhinders explainability, and loose, which do not give meaningful insights into\nthe underlying policy. We address these issues by introducing a simplification\nprocess consisting of predicate filtering, regularization, and iterative\npruning. We also introduce three novel explainability evaluation metrics --\nconciseness, consistency, and strictness -- to assess explanation quality\nbeyond conventional classification metrics. Our method is validated in three\nsimulated robotic environments, where it outperforms baselines in generating\nconcise, consistent, and strict wSTL explanations without sacrificing\nclassification accuracy. This work bridges policy learning with formal methods,\ncontributing to safer and more transparent decision-making in robotics.","main_category":"cs.RO","categories":"cs.RO,cs.FL","published":"2025-04-30T17:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.21844v1","title":"Scalable Multi-Task Learning for Particle Collision Event Reconstruction\n  with Heterogeneous Graph Neural Networks","summary":"The growing luminosity frontier at the Large Hadron Collider is challenging\nthe reconstruction and analysis of particle collision events. Increased\nparticle multiplicities are straining latency and storage requirements at the\ndata acquisition stage, while new complications are emerging, including higher\nbackground levels and more frequent particle vertex misassociations. This in\nturn necessitates the development of more holistic and scalable reconstruction\nmethods that take advantage of recent advances in machine learning. We propose\na novel Heterogeneous Graph Neural Network (HGNN) architecture featuring unique\nrepresentations for diverse particle collision relationships and integrated\ngraph pruning layers for scalability. Trained with a multi-task paradigm in an\nenvironment mimicking the LHCb experiment, this HGNN significantly improves\nbeauty hadron reconstruction performance. Notably, it concurrently performs\nparticle vertex association and graph pruning within a single framework. We\nquantify reconstruction and pruning performance, demonstrate enhanced inference\ntime scaling with event complexity, and mitigate potential performance loss\nusing a weighted message passing scheme.","main_category":"physics.data-an","categories":"physics.data-an,cs.LG,hep-ex","published":"2025-04-30T17:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.21848v1","title":"Characterizing AI Agents for Alignment and Governance","summary":"The creation of effective governance mechanisms for AI agents requires a\ndeeper understanding of their core properties and how these properties relate\nto questions surrounding the deployment and operation of agents in the world.\nThis paper provides a characterization of AI agents that focuses on four\ndimensions: autonomy, efficacy, goal complexity, and generality. We propose\ndifferent gradations for each dimension, and argue that each dimension raises\nunique questions about the design, operation, and governance of these systems.\nMoreover, we draw upon this framework to construct \"agentic profiles\" for\ndifferent kinds of AI agents. These profiles help to illuminate cross-cutting\ntechnical and non-technical governance challenges posed by different classes of\nAI agents, ranging from narrow task-specific assistants to highly autonomous\ngeneral-purpose systems. By mapping out key axes of variation and continuity,\nthis framework provides developers, policymakers, and members of the public\nwith the opportunity to develop governance approaches that better align with\ncollective societal goals.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.SY,eess.SY","published":"2025-04-30T17:55:48Z"}
{"aid":"http://arxiv.org/abs/2505.00289v1","title":"PatchFuzz: Patch Fuzzing for JavaScript Engines","summary":"Patch fuzzing is a technique aimed at identifying vulnerabilities that arise\nfrom newly patched code. While researchers have made efforts to apply patch\nfuzzing to testing JavaScript engines with considerable success, these efforts\nhave been limited to using ordinary test cases or publicly available\nvulnerability PoCs (Proof of Concepts) as seeds, and the sustainability of\nthese approaches is hindered by the challenges associated with automating the\nPoC collection. To address these limitations, we propose an end-to-end\nsustainable approach for JavaScript engine patch fuzzing, named PatchFuzz. It\nautomates the collection of PoCs of a broader range of historical\nvulnerabilities and leverages both the PoCs and their corresponding patches to\nuncover new vulnerabilities more effectively. PatchFuzz starts by recognizing\ngit commits which intend to fix security bugs. Subsequently, it extracts and\nprocesses PoCs from these commits to form the seeds for fuzzing, while\nutilizing code revisions to focus limited fuzzing resources on the more\nvulnerable code areas through selective instrumentation. The mutation strategy\nof PatchFuzz is also optimized to maximize the potential of the PoCs.\nExperimental results demonstrate the effectiveness of PatchFuzz. Notably, 54\nbugs across six popular JavaScript engines have been exposed and a total of\n$62,500 bounties has been received.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-05-01T04:26:21Z"}
{"aid":"http://arxiv.org/abs/2505.00316v1","title":"Surrogate modeling of Cellular-Potts Agent-Based Models as a\n  segmentation task using the U-Net neural network architecture","summary":"The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-05-01T05:30:38Z"}
{"aid":"http://arxiv.org/abs/2505.00317v1","title":"Beyond Quadratic Costs in LQR: Bregman Divergence Control","summary":"In the past couple of decades, the use of ``non-quadratic\" convex cost\nfunctions has revolutionized signal processing, machine learning, and\nstatistics, allowing one to customize solutions to have desired structures and\nproperties. However, the situation is not the same in control where the use of\nquadratic costs still dominates, ostensibly because determining the ``value\nfunction\", i.e., the optimal expected cost-to-go, which is critical to the\nconstruction of the optimal controller, becomes computationally intractable as\nsoon as one considers general convex costs. As a result, practitioners often\nresort to heuristics and approximations, such as model predictive control that\nonly looks a few steps into the future. In the quadratic case, the value\nfunction is easily determined by solving Riccati equations. In this work, we\nconsider a special class of convex cost functions constructed from Bregman\ndivergence and show how, with appropriate choices, they can be used to fully\nextend the framework developed for the quadratic case. The resulting optimal\ncontrollers are infinite horizon, come with stability guarantees, and have\nstate-feedback, or estimated state-feedback, laws. They exhibit a much wider\nrange of behavior than their quadratic counterparts since the feedback laws are\nnonlinear. The approach can be applied to several cases of interest, including\nsafety control, sparse control, and bang-bang control.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-05-01T05:31:45Z"}
{"aid":"http://arxiv.org/abs/2505.00336v1","title":"Experimental evidence for the physical delocalization of individual\n  photons in an interferometer","summary":"It is generally assumed that the detection of a single photon as part of an\ninterference pattern erases all possible which-path information. However,\nrecent insights suggest that weak interactions can provide non-trivial\nexperimental evidence for the physical delocalization of a single particle\npassing through an interferometer. Here, we present an experimental setup that\ncan quantify the delocalization of individual photons using the rate of\npolarization flips induced by small rotations of polarization. The results show\nthat photons detected in equal superpositions of the two paths are delocalized\nwhen detected in a high probability output port, and \"super-localized\" when\ndetected in a low probability output port. We can thus confirm that\ndelocalization depends on the detection of photons in the output of the\ninterferometer, providing direct experimental evidence for the dependence of\nphysical reality on the context established by a future measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T06:20:46Z"}
{"aid":"http://arxiv.org/abs/2505.00365v1","title":"SacFL: Self-Adaptive Federated Continual Learning for\n  Resource-Constrained End Devices","summary":"The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T07:26:35Z"}
{"aid":"http://arxiv.org/abs/2505.00377v1","title":"Exponential growth of random infinite Fibonacci sequences","summary":"We consider the recursion $X_{n+1}=\\sum_{i=0}^n \\epsilon_{n,i}X_{n-i}$, where\n$\\epsilon_{n,i}$ are i.i.d. (Bernoulli) random variables taking values in\n$\\{-1,1\\}$, and $X_0=1$, $X_{-j}=0$ for $j>0$. We prove that almost surely,\n$n^{-1}\\log |X_n|\\to \\bar \\gamma>0$, where $\\bar \\gamma$ is an appropriate\nLyapunov exponent. This answers a question of Viswanath and Trefethen\n(\\textit{SIAM J. Matrix Anal. Appl. 19:564--581, 1998}).","main_category":"math.PR","categories":"math.PR","published":"2025-05-01T08:10:35Z"}
{"aid":"http://arxiv.org/abs/2505.00392v1","title":"Equatorial African Lightning: Past. Present and Future","summary":"Lightning strikes are one of the leading causes of death among natural\ndisasters in tropical regions. The Congo rainforests host the highest rates of\nlightning flashes in the world and the lightning properties in this region have\na strong seasonality owing to the cross-equatorial movements of the Inter\nTropical Convergence Zone (ITCZ) throughout the year. The Lightning Flash Rates\n(LFR) are found to peak during the Equinoctial months while lightning radiance\nassumes the strongest values during the Boreal Summer months. Across the\nTropical Rainfall Measuring Mission (TRMM) duration, (1998-2015), annual LFR in\nthe Congo rainforest increases steadily, however, the average and the peak\nlightning radiances decrease by ~1%/year and ~1.5%/year respectively which is\ncounter-intuitive to the expected intensification in weather extremes in a\nwarming climate. An in-depth analysis highlighted the influence of moisture\nconvergence over the Congo Basin from the Atlantic as the primary contributor\nto lightning compared to the aerosol nucleation and thermodynamic instability\neffects during the boreal summers. Further, it has been proposed that in a\ngradually warming climate, the strength of the prevailing ITCZ over Sahel\nregion has intensified thereby weakening the moisture ingress towards the Congo\nBasin, and this resulted in the observed reduction in lightning intensity in\nrecent years. Consequently, the long-term projections of lightning properties\nfrom global model simulations revealed a prominent weakening in lightning\n(~50%) over the Congo Basin by the year 2100 assuming the Representative\nConcentration Pathways (RCP) 8.5 emission scenarios. Key Words: Lightning, LIS,\nCongo Basin, Sahel, Moisture Flux, Future projections.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-05-01T08:29:53Z"}
{"aid":"http://arxiv.org/abs/2505.00417v1","title":"Gravity water waves over constant vorticity flows: From laminar flows to\n  touching waves","summary":"In a recent paper, Hur & Wheeler [J. Differential Equations, 338:572-590,\n2022] proved the existence of periodic steady water waves over an infinitely\ndeep, two-dimensional and constant vorticity flow under the influence of\ngravity. These solutions include overhanging wave profiles, some of which\nexhibit surfaces that touch at a point and thereby enclose a bubble of air. We\nextend these results by formulating a problem that encompasses both infinitely\ndeep and finitely deep flows, and by proving the existence of a continuous\ncurve of water waves that connects a laminar flow to a touching wave for fixed,\nnonzero gravity. This implies the existence of a wave profile featuring a\nvertical tangent at a point, which is not overhanging, and is referred to as a\nbreaking wave. We also study the behaviour of critical layers, which are points\nwhere the horizontal velocity vanishes, near the surface.","main_category":"math.AP","categories":"math.AP","published":"2025-05-01T09:32:00Z"}
{"aid":"http://arxiv.org/abs/2505.00421v1","title":"Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular\n  Videos","summary":"High-quality, animatable 3D human avatar reconstruction from monocular videos\noffers significant potential for reducing reliance on complex hardware, making\nit highly practical for applications in game development, augmented reality,\nand social media. However, existing methods still face substantial challenges\nin capturing fine geometric details and maintaining animation stability,\nparticularly under dynamic or complex poses. To address these issues, we\npropose a novel real-time framework for animatable human avatar reconstruction\nbased on 2D Gaussian Splatting (2DGS). By leveraging 2DGS and global SMPL pose\nparameters, our framework not only aligns positional and rotational\ndiscrepancies but also enables robust and natural pose-driven animation of the\nreconstructed avatars. Furthermore, we introduce a Rotation Compensation\nNetwork (RCN) that learns rotation residuals by integrating local geometric\nfeatures with global pose parameters. This network significantly improves the\nhandling of non-rigid deformations and ensures smooth, artifact-free pose\ntransitions during animation. Experimental results demonstrate that our method\nsuccessfully reconstructs realistic and highly animatable human avatars from\nmonocular videos, effectively preserving fine-grained details while ensuring\nstable and natural pose variation. Our approach surpasses current\nstate-of-the-art methods in both reconstruction quality and animation\nrobustness on public benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T09:41:28Z"}
{"aid":"http://arxiv.org/abs/2505.00468v1","title":"Evaluation of Thermal Control Based on Spatial Thermal Comfort with\n  Reconstructed Environmental Data","summary":"Achieving thermal comfort while maintaining energy efficiency is a critical\nobjective in building system control. Conventional thermal comfort models, such\nas the Predicted Mean Vote (PMV), rely on both environmental and personal\nvariables. However, the use of fixed-location sensors limits the ability to\ncapture spatial variability, which reduces the accuracy of occupant-specific\ncomfort estimation. To address this limitation, this study proposes a new PMV\nestimation method that incorporates spatial environmental data reconstructed\nusing the Gappy Proper Orthogonal Decomposition (Gappy POD) algorithm. In\naddition, a group PMV-based control framework is developed to account for the\nthermal comfort of multiple occupants. The Gappy POD method enables fast and\naccurate reconstruction of indoor temperature fields from sparse sensor\nmeasurements. Using these reconstructed fields and occupant location data,\nspatially resolved PMV values are calculated. Group-level thermal conditions\nare then derived through statistical aggregation methods and used to control\nindoor temperature in a multi-occupant living lab environment. Experimental\nresults show that the Gappy POD algorithm achieves an average relative error\nbelow 3\\% in temperature reconstruction. PMV distributions varied by up to 1.26\nscale units depending on occupant location. Moreover, thermal satisfaction\noutcomes varied depending on the group PMV method employed. These findings\nunderscore the importance for adaptive thermal control strategies that\nincorporate both spatial and individual variability, offering valuable insights\nfor future occupant-centric building operations.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-01T11:43:28Z"}
{"aid":"http://arxiv.org/abs/2505.00499v1","title":"Relativistic Two-component Double Ionization Potential\n  Equation-of-Motion Coupled Cluster with the Dirac--Coulomb--Breit Hamiltonian","summary":"We present an implementation of relativistic double-ionization-potential\n(DIP) equation-of-motion coupled-cluster (EOMCC) with up to 4-hole--2-particle\n($4h2p$) excitations that makes use of the molecular mean-field exact\ntwo-component (mmfX2C) framework. We apply mmfX2C-DIP-EOMCC to several neutral\natoms and diatomic molecules to obtain the ground and first few excited states\nof the corresponding di-cation species, and we observe excellent agreement (to\nwithin 0.001 eV) between double ionization potentials (IPs) obtained from\nmmfX2C- and four-component DIP-EOMCC calculations that include\n3-hole--1-particle ($3h1p$) excitations, with either the Dirac--Coulomb or\nDirac--Coulomb--Gaunt Hamiltonians. We also compare double IPs for\nmmfX2C-DIP-EOMCC calculations with the full Dirac--Coulomb--Breit (DCB)\nHamiltonian to those from experiment. The mmfX2C-DIP-EOMCC with $3h1p$\nexcitations leads to errors in absolute double IPs that are larger than 0.1 eV,\nwhereas the addition of $4h2p$ excitations reduces these errors dramatically,\noften by an order of magnitude or more.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-01T12:59:09Z"}
{"aid":"http://arxiv.org/abs/2505.00553v1","title":"The Jackknife method as a new approach to validate strong lens mass\n  models","summary":"The accuracy of a mass model in the strong lensing analysis is crucial for\nunbiased predictions of physical quantities such as magnifications and time\ndelays. While the mass model is optimized by changing parameters of the mass\nmodel to match predicted positions of multiple images with observations,\npositional uncertainties of multiple images often need to be boosted to take\naccount of the complex structure of dark matter in lens objects, making the\ninterpretation of the chi-square value difficult. We introduce the Jackknife\nmethod as a new method to validate strong lens mass models, specifically\nfocusing on cluster-scale mass modeling. In this approach, we remove multiple\nimages of a source from the fitting and optimize the mass model using multiple\nimages of the remaining sources. We then calculate the multiple images of the\nremoved source and quantitatively evaluate how well they match the observed\npositions. We find that the Jackknife method performs effectively in\nsimulations using a simple model. We also demonstrate our method with mass\nmodeling of the galaxy cluster MACS J0647.7+7015. We discuss the potential of\nusing the Jackknife method to validate the error estimation of the physical\nquantities by the Markov Chain Monte Carlo.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-05-01T14:28:50Z"}
{"aid":"http://arxiv.org/abs/2505.00574v1","title":"Transition States Energies from Machine Learning: An Application to\n  Reverse Water-Gas Shift on Single-Atom Alloys","summary":"Obtaining accurate transition state (TS) energies is a bottleneck in\ncomputational screening of complex materials and reaction networks due to the\nhigh cost of TS search methods and first-principles methods such as density\nfunctional theory (DFT). Here we propose a machine learning (ML) model for\npredicting TS energies based on Gaussian process regression with the\nWasserstein Weisfeiler-Lehman graph kernel (WWL-GPR). Applying the model to\npredict adsorption and TS energies for the reverse water-gas shift (RWGS)\nreaction on single-atom alloy (SAA) catalysts, we show that it can\nsignificantly improve the accuracy compared to traditional approaches based on\nscaling relations or ML models without a graph representation. Further\nbenefitting from the low cost of model training, we train an ensemble of\nWWL-GPR models to obtain uncertainties through subsampling of the training data\nand show how these uncertainties propagate to turnover frequency (TOF)\npredictions through the construction of an ensemble of microkinetic models.\nComparing the errors in model-based vs DFT-based TOF predictions, we show that\nthe WWL-GPR model reduces errors by almost an order of magnitude compared to\nscaling relations. This demonstrates the critical impact of accurate energy\npredictions on catalytic activity estimation. Finally, we apply our model to\nscreen new materials, identifying promising catalysts for RWGS. This work\nhighlights the power of combining advanced ML techniques with DFT and\nmicrokinetic modeling for screening catalysts for complex reactions like RWGS,\nproviding a robust framework for future catalyst design.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-05-01T15:01:02Z"}
{"aid":"http://arxiv.org/abs/2505.00592v1","title":"Uncertainty-Aware Multi-Expert Knowledge Distillation for Imbalanced\n  Disease Grading","summary":"Automatic disease image grading is a significant application of artificial\nintelligence for healthcare, enabling faster and more accurate patient\nassessments. However, domain shifts, which are exacerbated by data imbalance,\nintroduce bias into the model, posing deployment difficulties in clinical\napplications. To address the problem, we propose a novel\n\\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge\n\\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple\nexpert models to a single student model. Specifically, to extract\ndiscriminative features, UMKD decouples task-agnostic and task-specific\nfeatures with shallow and compact feature alignment in the feature space. At\nthe output space, an uncertainty-aware decoupled distillation (UDD) mechanism\ndynamically adjusts knowledge transfer weights based on expert model\nuncertainties, ensuring robust and reliable distillation. Additionally, UMKD\nalso tackles the problems of model architecture heterogeneity and distribution\ndiscrepancies between source and target domains, which are inadequately tackled\nby previous KD approaches. Extensive experiments on histology prostate grading\n(\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that\nUMKD achieves a new state-of-the-art in both source-imbalanced and\ntarget-imbalanced scenarios, offering a robust and practical solution for\nreal-world disease image grading.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-01T15:26:23Z"}
{"aid":"http://arxiv.org/abs/2505.00604v1","title":"Understanding and improving transferability in machine-learned\n  activation energy predictors","summary":"The calculation of reactive properties is a challenging task in chemical\nreaction discovery. Machine learning (ML) methods play an important role in\naccelerating electronic structure predictions of activation energies and\nreaction enthalpies, and are a crucial ingredient to enable large-scale\nautomated reaction network discovery with $>10^3$ reactions. Unfortunately, the\npredictive accuracy of existing ML models does not yet reach the required\naccuracy across the space of possible chemical reactions to enable subsequent\nkinetic simulations that even qualitatively agree with experimental kinetics.\nHere, we comprehensively assess the underlying reasons for prediction failures\nwithin a selection of machine-learned models of reactivity. Models based on\ndifference fingerprints between reactant and product structures lack\ntransferability despite providing good in-distribution predictions. This\nresults in a significant loss of information about the context and mechanism of\nchemical reactions. We propose a convolutional ML model that uses atom-centered\nquantum-chemical descriptors and approximate transition state information.\nInclusion of the latter improves transferability for out-of-distribution\nbenchmark reactions, making greater use of the limited chemical reaction space\nspanned by the training data. The model further delivers atom-level\ncontributions to activation energies and reaction enthalpies that provide a\nuseful interpretational tool for rationalizing reactivity.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-01T15:35:12Z"}
{"aid":"http://arxiv.org/abs/2505.00647v1","title":"GeoDEx: A Unified Geometric Framework for Tactile Dexterous and\n  Extrinsic Manipulation under Force Uncertainty","summary":"Sense of touch that allows robots to detect contact and measure interaction\nforces enables them to perform challenging tasks such as grasping fragile\nobjects or using tools. Tactile sensors in theory can equip the robots with\nsuch capabilities. However, accuracy of the measured forces is not on a par\nwith those of the force sensors due to the potential calibration challenges and\nnoise. This has limited the values these sensors can offer in manipulation\napplications that require force control. In this paper, we introduce GeoDEx, a\nunified estimation, planning, and control framework using geometric primitives\nsuch as plane, cone and ellipsoid, which enables dexterous as well as extrinsic\nmanipulation in the presence of uncertain force readings. Through various\nexperimental results, we show that while relying on direct inaccurate and noisy\nforce readings from tactile sensors results in unstable or failed manipulation,\nour method enables successful grasping and extrinsic manipulation of different\nobjects. Additionally, compared to directly running optimization using SOCP\n(Second Order Cone Programming), planning and force estimation using our\nframework achieves a 14x speed-up.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T16:40:47Z"}
{"aid":"http://arxiv.org/abs/2505.00651v1","title":"Open-Source LLM-Driven Federated Transformer for Predictive IoV\n  Management","summary":"The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.","main_category":"cs.AI","categories":"cs.AI,cs.ET,cs.LG","published":"2025-05-01T16:54:21Z"}
{"aid":"http://arxiv.org/abs/2505.00666v1","title":"Spreading Depolarization Detection in Electrocorticogram Spectrogram\n  Imaging by Deep Learning: Is It Just About Delta Band?","summary":"Prevention of secondary brain injury is a core aim of neurocritical care,\nwith Spreading Depolarizations (SDs) recognized as a significant independent\ncause. SDs are typically monitored through invasive, high-frequency\nelectrocorticography (ECoG); however, detection remains challenging due to\nsignal artifacts that obscure critical SD-related electrophysiological changes,\nsuch as power attenuation and DC drifting. Recent studies suggest spectrogram\nanalysis could improve SD detection; however, brain injury patients often show\npower reduction across all bands except delta, causing class imbalance.\nPrevious methods focusing solely on delta mitigates imbalance but overlooks\nfeatures in other frequencies, limiting detection performance. This study\nexplores using multi-frequency spectrogram analysis, revealing that essential\nSD-related features span multiple frequency bands beyond the most active delta\nband. This study demonstrated that further integration of both alpha and delta\nbands could result in enhanced SD detection accuracy by a deep learning model.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-01T17:17:15Z"}
{"aid":"http://arxiv.org/abs/2505.00674v1","title":"Offset Charge Dependence of Measurement-Induced Transitions in Transmons","summary":"A key challenge in achieving scalable fault tolerance in superconducting\nquantum processors is readout fidelity, which lags behind one- and two-qubit\ngate fidelity. A major limitation in improving qubit readout is\nmeasurement-induced transitions, also referred to as qubit ionization, caused\nby multiphoton qubit-resonator excitation occurring at specific photon numbers.\nSince ionization can involve highly excited states, it has been predicted that\nin transmons -- the most widely used superconducting qubit -- the photon number\nat which measurement-induced transitions occur is gate charge dependent. This\ndependence is expected to persist deep in the transmon regime where the qubit\nfrequency is gate charge insensitive. We experimentally confirm this prediction\nby characterizing measurement-induced transitions with increasing resonator\nphoton population while actively stabilizing the transmon's gate charge.\nFurthermore, because highly excited states are involved, achieving quantitative\nagreement between theory and experiment requires accounting for higher-order\nharmonics in the transmon Hamiltonian.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T17:28:57Z"}
{"aid":"http://arxiv.org/abs/2505.00687v1","title":"GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based\n  Super-Resolution","summary":"In this paper, we propose GuideSR, a novel single-step diffusion-based image\nsuper-resolution (SR) model specifically designed to enhance image fidelity.\nExisting diffusion-based SR approaches typically adapt pre-trained generative\nmodels to image restoration tasks by adding extra conditioning on a\nVAE-downsampled representation of the degraded input, which often compromises\nstructural fidelity. GuideSR addresses this limitation by introducing a\ndual-branch architecture comprising: (1) a Guidance Branch that preserves\nhigh-fidelity structures from the original-resolution degraded input, and (2) a\nDiffusion Branch, which a pre-trained latent diffusion model to enhance\nperceptual quality. Unlike conventional conditioning mechanisms, our Guidance\nBranch features a tailored structure for image restoration tasks, combining\nFull Resolution Blocks (FRBs) with channel attention and an Image Guidance\nNetwork (IGN) with guided attention. By embedding detailed structural\ninformation directly into the restoration pipeline, GuideSR produces sharper\nand more visually consistent results. Extensive experiments on benchmark\ndatasets demonstrate that GuideSR achieves state-of-the-art performance while\nmaintaining the low computational cost of single-step approaches, with up to\n1.39dB PSNR gain on challenging real-world datasets. Our approach consistently\noutperforms existing methods across various reference-based metrics including\nPSNR, SSIM, LPIPS, DISTS and FID, further representing a practical advancement\nfor real-world image restoration.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T17:48:25Z"}
{"aid":"http://arxiv.org/abs/2505.00694v1","title":"What is the Hierarchy Problem?","summary":"Is there a Hierarchy Problem? If so, what, exactly, is the problem? Almost\nevery theorist has a personal answer to these questions. In this article, I\ngive my answers. I will explain that the Hierarchy Problem is not a formal\nproblem but rather our ignorance of a crucial physics explanation -- the\nexplanation of the nature of the Higgs boson. Without the solution to this\nproblem, we cannot make progress on the major questions of our field.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-05-01T17:55:26Z"}
{"aid":"http://arxiv.org/abs/2505.00700v1","title":"Luminosity Function of collapsar Gamma-Ray Bursts:the Progenitor of Long\n  Gamma-Ray Bursts Is Not Singular","summary":"Gamma-ray bursts (GRBs) are powerful probes of the high-redshift universe.\nHowever, the proportion of collapsar GRBs among long GRBs and their event rate\nrelative to the star formation rate (SFR) remain contentious issues. We assume\nthat long GRBs with $z\\geq 2$ are all collapsar GRBs and construct the\nluminosity function using a high-redshift sample from the Swift satellite\nspanning 2004 to 2019. We model the luminosity function with a broken power-law\nform and consider three scenarios: no evolution, luminosity evolution, and\ndensity evolution. Our results are as follows: 1) The no-evolution model can be\nruled out. 2) The fitting results indicate that to adequately explain the\nobservations, a significant redshift evolution in either luminosity (evolution\nindex $\\delta = 1.54^{+0.21}_{-0.22}$) or density ($\\delta =\n2.09^{+0.29}_{-0.26}$) is required. This excludes the possibility that the\nevolution of long GRBs with redshift is due to contamination from non-collapsar\nGRBs. 3) The luminosity evolution model predicts that the number of collapsar\nGRBs with $z<2$ and $P \\geq 1 \\, \\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$\nis 138.6, accounting for 82.5% of the observed long GRBs with $z<2$ and $P \\geq\n1 \\, \\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$. The density evolution model\npredicts that the number of collapsar GRBs with $z<2$ and $P \\geq 1 \\,\n\\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$ is 80.2, accounting for 47.7% of\nthe observation. Regardless of the model, a substantial portion of the long\nGRBs are not collapsar GRBs.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-01T17:58:21Z"}
{"aid":"http://arxiv.org/abs/2505.03220v1","title":"Dual-Domain Masked Image Modeling: A Self-Supervised Pretraining\n  Strategy Using Spatial and Frequency Domain Masking for Hyperspectral Data","summary":"Hyperspectral images (HSIs) capture rich spectral signatures that reveal\nvital material properties, offering broad applicability across various domains.\nHowever, the scarcity of labeled HSI data limits the full potential of deep\nlearning, especially for transformer-based architectures that require\nlarge-scale training. To address this constraint, we propose Spatial-Frequency\nMasked Image Modeling (SFMIM), a self-supervised pretraining strategy for\nhyperspectral data that utilizes the large portion of unlabeled data. Our\nmethod introduces a novel dual-domain masking mechanism that operates in both\nspatial and frequency domains. The input HSI cube is initially divided into\nnon-overlapping patches along the spatial dimension, with each patch comprising\nthe entire spectrum of its corresponding spatial location. In spatial masking,\nwe randomly mask selected patches and train the model to reconstruct the masked\ninputs using the visible patches. Concurrently, in frequency masking, we remove\nportions of the frequency components of the input spectra and predict the\nmissing frequencies. By learning to reconstruct these masked components, the\ntransformer-based encoder captures higher-order spectral-spatial correlations.\nWe evaluate our approach on three publicly available HSI classification\nbenchmarks and demonstrate that it achieves state-of-the-art performance.\nNotably, our model shows rapid convergence during fine-tuning, highlighting the\nefficiency of our pretraining strategy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T06:24:21Z"}
{"aid":"http://arxiv.org/abs/2505.03247v1","title":"Strategic Effort and Bandwagon Effects in Finite Multi-Stage Games with\n  Non-Linear Externalities: Evidence from Triathlon","summary":"This paper examines strategic effort and positioning choices resulting in\nbandwagon effects under externalities in finite multi-stage games using causal\nevidence from triathlon (Reichel, 2025). Focusing on open-water swim\ndraftingwhere athletes reduce drag most effectively by swimming directly behind\npeerswe estimate its performance effects through a structural contest framework\nwith endogenous, deterministic effort and drafting position. Leveraging\nexogenous variation from COVID-19 drafting bans in Austrian triathlons, we\napply a panel leave-one-out (LOO/LOTO) peer ability instrumental variables (IV)\nstrategy to isolate the causal non-linear effect of drafting. Results from\nrestricted sample analysis and pooled estimated bandwagon IV effects show\nsubstantial and nonlinear gains: in small (group size below 10) drafting swim\ngroups/clusters, each deeper position improves finishing rank on average by\nover 30%, with rapidly diminishing returns in larger groups. Leading however is\nconsistently more costly than optimal positioning, aligning with theoretical\npredictions of energy expenditure (metabolic costs).","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-06T07:20:06Z"}
{"aid":"http://arxiv.org/abs/2505.03249v1","title":"Multilayer Crystal Field states from locally broken centrosymmetry","summary":"Local charge, spin, or orbital degrees of freedom with intersite interactions\nare oftentimes sufficient to construct most quantum orders. This is\nconventionally true for f-electron systems, where the extent of the f-electrons\nand their associated crystal-electric-field (CEF) states are strongly\nlocalized. Here, polarized Raman spectroscopy measurements of a locally\nnon-centrosymmetric compound, CeCoSi, unveil more CEF excitations than expected\nin the local model. We interpret this as experimental evidence for the\nentanglement of CEF states between cerium layers. This composite sublattice,\nspin, and orbital degree of freedom provides an unconsidered means to form\nnovel orders, not only in this system, but in any system exhibiting globally\npreserved yet locally broken centrosymmetry.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-05-06T07:21:32Z"}
{"aid":"http://arxiv.org/abs/2505.03255v1","title":"Deep learning spinfoam vertex amplitudes: the Euclidean Barrett-Crane\n  model","summary":"Spinfoam theories propose a well-defined path-integral formulation for\nquantum gravity and are hoped to provide the dynamics of loop quantum gravity.\nHowever, it is computationally hard to calculate spinfoam amplitudes. The\nwell-studied Euclidean Barrett-Crane model provides an excellent setting for\ntesting analytical and numerical tools to probe spinfoam models. We explore a\ndata-driven approach to accelerating spinfoam computations by showing that the\nvertex amplitude is an object that can be learned from data using deep\nlearning. We divide the learning process into a classification and a regression\ntask: Two networks are independently engineered to decide whether the amplitude\nis zero or not and to predict the precise numerical value, respectively. The\ntrained networks are tested with several accuracy measures. The classifier in\nparticular demonstrates robust generalisation far outside the training domain,\nwhile the regressor demonstrates high predictive accuracy in the domain it is\ntrained on. We discuss limitations, possible improvements, and implications for\nfuture work.","main_category":"gr-qc","categories":"gr-qc,hep-th,physics.comp-ph","published":"2025-05-06T07:34:58Z"}
{"aid":"http://arxiv.org/abs/2505.03270v1","title":"Power-Aware Digital Twin of Coherent Optical Receiver","summary":"We propose a digital twin of coherent receivers based on an extended physical\nmodel for predicting quality of transmission under receiver power variations.\nWe experimentally validate it, demonstrating an accuracy improved by up to\n1.5dB.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-06T08:01:15Z"}
{"aid":"http://arxiv.org/abs/2505.03294v1","title":"An arithmetic Ã©tale-crystalline comparison with coefficients in\n  crystalline local systems","summary":"We use the stacky approach to $p$-adic cohomology theories recently developed\nby Drinfeld and Bhatt--Lurie to generalise a comparison theorem between the\nrational crystalline cohomology of the special fibre and the rational $p$-adic\n\\'etale cohomology of the arithmetic generic fibre of any proper $p$-adic\nformal scheme $X$ due to Colmez--Niziol to the case of coefficients in an\narbitrary crystalline local system on the generic fibre of $X$. In the process,\nwe establish a version of the Beilinson fibre square of\nAntieau--Mathew--Morrow--Nikolaus with coefficients in the proper case and\nprove a comparison between syntomic cohomology and $p$-adic \\'etale cohomology\nwith coefficients in an arbitrary $F$-gauge. Our methods also yield a\ndescription of the isogeny category of perfect $F$-gauges on $\\mathbb{Z}_p$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-05-06T08:26:54Z"}
{"aid":"http://arxiv.org/abs/2505.03297v1","title":"How do activity-end trip characteristics affect the choice for shared\n  micromobility? A latent class choice modelling approach for train station\n  egress trips in the Netherlands","summary":"Access/egress travel to train stations continues to pose a significant\nbarrier to increasing the number of train travellers. Shared micromobility\n(SMM), including bicycles, e-bikes, steps and mopeds, is often cited as a\nprominent solution, especially for the activity-end of the trip chain. Using a\nstated preference survey, we analyse activity-end mode-choice preferences for\nSMM, walking and public transport (PT) among the Dutch population. By means of\na latent class choice model, we uncover three user groups with respect to\nactivity-end mode choice behaviour. The largest (58%) are Multimodal sharing\nenthusiast, who choose based on the trade-offs between various travel\ncharacteristics, while not having strong modal preferences. They are the most\nopen, ready and able to use SMM. Sharing hesitant cyclists (16%) have a strong\npreference for cycling and while they are open to using SMM , they may not feel\nthemselves ready, stating that use of SMM can be difficult and dangerous.\nSharing-averse PT users (27%) are most likely to use PT and avoid SMM as they\nfind it too difficult and dangerous to use. The high preference to walk for\nshort egress distances reaffirms the need for transit-oriented development\npolicies. For longer egress distances, PT should be the primary focus at\nstations in high-density areas with high demand, where high frequencies and\ndense networks are justified, while stations in lower demand areas are better\nserved by SMM. Providing multiple SMM options would result mainly in\ncompetition for the same travellers.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-05-06T08:27:46Z"}
{"aid":"http://arxiv.org/abs/2505.03331v1","title":"Miniature multihole airflow sensor for lightweight aircraft over wide\n  speed and angular range","summary":"An aircraft's airspeed, angle of attack, and angle of side slip are crucial\nto its safety, especially when flying close to the stall regime. Various\nsolutions exist, including pitot tubes, angular vanes, and multihole pressure\nprobes. However, current sensors are either too heavy (>30 g) or require large\nairspeeds (>20 m/s), making them unsuitable for small uncrewed aerial vehicles.\nWe propose a novel multihole pressure probe, integrating sensing electronics in\na single-component structure, resulting in a mechanically robust and\nlightweight sensor (9 g), which we released to the public domain. Since there\nis no consensus on two critical design parameters, tip shape (conical vs\nspherical) and hole spacing (distance between holes), we provide a study on\nmeasurement accuracy and noise generation using wind tunnel experiments. The\nsensor is calibrated using a multivariate polynomial regression model over an\nairspeed range of 3-27 m/s and an angle of attack/sideslip range of +-35{\\deg},\nachieving a mean absolute error of 0.44 m/s and 0.16{\\deg}. Finally, we\nvalidated the sensor in outdoor flights near the stall regime. Our probe\nenabled accurate estimations of airspeed, angle of attack and sideslip during\ndifferent acrobatic manoeuvres. Due to its size and weight, this sensor will\nenable safe flight for lightweight, uncrewed aerial vehicles flying at low\nspeeds close to the stall regime.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-06T09:04:49Z"}
{"aid":"http://arxiv.org/abs/2505.03343v1","title":"Defect-Bound Excitons in Topological Materials","summary":"Excitons, bound states of electrons and holes, are affected by the properties\nof the underlying band structure of a material. Defects in lattice systems may\ntrap electronic defect states, to which an electron can be excited to form\ndefect-bound excitons. Here, we examine the effect of band topology on excitons\nin systems with a single-site defect. We show that in the topological phase,\nwhen robust, in-gap, ring-shaped electronic states appear around defects,\nexcitons inherit the properties of these ring states: The excitons' binding\nenergies are lowered as a result of the wide spatial profile of the defect\nstate, and their wave functions have complex shapes and order due to the mixed\norbital character of the topological bands. Our study advances the\nunderstanding of the role of topology in modifying and controlling defect-bound\nexcitons in quantum materials.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-06T09:12:20Z"}
{"aid":"http://arxiv.org/abs/2505.03362v1","title":"3D Surface Reconstruction with Enhanced High-Frequency Details","summary":"Neural implicit 3D reconstruction can reproduce shapes without 3D\nsupervision, and it learns the 3D scene through volume rendering methods and\nneural implicit representations. Current neural surface reconstruction methods\ntend to randomly sample the entire image, making it difficult to learn\nhigh-frequency details on the surface, and thus the reconstruction results tend\nto be too smooth. We designed a method (FreNeuS) based on high-frequency\ninformation to solve the problem of insufficient surface detail. Specifically,\nFreNeuS uses pixel gradient changes to easily acquire high-frequency regions in\nan image and uses the obtained high-frequency information to guide surface\ndetail reconstruction. High-frequency information is first used to guide the\ndynamic sampling of rays, applying different sampling strategies according to\nvariations in high-frequency regions. To further enhance the focus on surface\ndetails, we have designed a high-frequency weighting method that constrains the\nrepresentation of high-frequency details during the reconstruction process.\nQualitative and quantitative results show that our method can reconstruct fine\nsurface details and obtain better surface reconstruction quality compared to\nexisting methods. In addition, our method is more applicable and can be\ngeneralized to any NeuS-based work.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T09:37:04Z"}
{"aid":"http://arxiv.org/abs/2505.03385v1","title":"Solar Flare Forecast: A Comparative Analysis of Machine Learning\n  Algorithms for Solar Flare Class Prediction","summary":"Solar flares are among the most powerful and dynamic events in the solar\nsystem, resulting from the sudden release of magnetic energy stored in the\nSun's atmosphere. These energetic bursts of electromagnetic radiation can\nrelease up to 10^32 erg of energy, impacting space weather and posing risks to\ntechnological infrastructure and therefore require accurate forecasting of\nsolar flare occurrences and intensities. This study evaluates the predictive\nperformance of three machine learning algorithms: Random Forest, k-Nearest\nNeighbors (KNN), and Extreme Gradient Boosting (XGBoost) for classifying solar\nflares into 4 categories (B, C, M, X). Using the dataset of 13 SHARP\nparameters, the effectiveness of the models was evaluated in binary and\nmulticlass classification tasks. The analysis utilized 8 principal components\n(PC), capturing 95% of data variance, and 100 PCs, capturing 97.5% of variance.\nOur approach uniquely combines binary and multiclass classification with\ndifferent levels of dimensionality reduction, an innovative methodology not\npreviously explored in the context of solar flare prediction. Employing a\n10-fold stratified cross-validation and grid search for hyperparameter tuning\nensured robust model evaluation. Our findings indicate that Random Forest and\nXGBoost consistently demonstrate strong performance across all metrics,\nbenefiting significantly from increased dimensionality. The insights of this\nstudy enhance future research by optimizing dimensionality reduction techniques\nand informing model selection for astrophysical tasks. By integrating this\nnewly acquired knowledge into future research, more accurate space weather\nforecasting systems can be developed, along with a deeper understanding of\nsolar physics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG,I.5.0","published":"2025-05-06T10:08:41Z"}
{"aid":"http://arxiv.org/abs/2505.03396v1","title":"Quantitative lower bound for solutions to the Boltzmann equation in\n  non-convex domains","summary":"In this article we deal with the continuous mild solutions of the Boltzmann\nequation in a bounded space domain, either with angular cutoff or non cutoff\nassumption. Without assuming that the space domain is convex, we construct a\nMaxwellian lower bound in the cutoff case, and a weaker-than-Maxwellian lower\nbound in the non-cutoff case, thus extending results of \\cite{Bri 1,Bri 2} in\nwhich the domain was assumed to be convex.","main_category":"math.AP","categories":"math.AP","published":"2025-05-06T10:20:44Z"}
{"aid":"http://arxiv.org/abs/2505.03407v1","title":"CB-cPIR: Code-Based Computational Private Information Retrieval","summary":"A private information retrieval (PIR) scheme is a protocol that allows a user\nto retrieve a file from a database without revealing the identity of the\ndesired file to a curious database. Given a distributed data storage system,\nefficient PIR can be achieved by making assumptions about the colluding\ncapabilities of the storage servers holding the database. If these assumptions\nturn out to be incorrect, privacy is lost. In this work, we focus on the\nworst-case assumption: full collusion or, equivalently, viewing the storage\nsystem virtually as a single honest-but-curious server. We present CB-cPIR, a\nsingle-server code-based computational private information retrieval (cPIR)\nscheme that derives security from code-based cryptography. Specifically, the\nqueries are protected by the hardness of decoding a random linear code. The\nscheme is heavily inspired by the pioneering code-based cPIR scheme proposed by\nHolzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., \"Computational\nCode-Based Single-Server Private Information Retrieval\", 2020 IEEE ISIT] and\nfixes the vulnerabilities of the original scheme arising from highly probable\nrank differences in submatrices of the user's query. For further validation, we\ndraw comparisons to the state-of-the-art lattice-based cPIR schemes.","main_category":"cs.IR","categories":"cs.IR,cs.IT,math.IT","published":"2025-05-06T10:34:44Z"}
{"aid":"http://arxiv.org/abs/2505.03438v1","title":"Algorithm Selection in Short-Range Molecular Dynamics Simulations","summary":"Numerous algorithms and parallelisations have been developed for short-range\nparticle simulations; however, none are optimally performant for all scenarios.\nSuch a concept led to the prior development of the particle simulation library\nAutoPas, which implemented many of these algorithms and parallelisations and\ncould select and tune these over the course of the simulation as the scenario\nchanged. Prior works have, however, used only naive approaches to the algorithm\nselection problem, which can lead to significant overhead from trialling poorly\nperforming algorithmic configurations.\n  In this work, we investigate this problem in the case of Molecular Dynamics\nsimulations. We present three algorithm selection strategies: an approach which\nmakes performance predictions from past data, an expert-knowledge fuzzy\nlogic-based approach, and a data-driven random forest-based approach. We\ndemonstrate that these approaches can achieve speedups of up to 4.05 compared\nto prior approaches and 1.25 compared to a perfect configuration selection\nwithout dynamic algorithm selection. In addition, we discuss the practicality\nof the strategies in comparison to their performance, to highlight the\ntractability of such solutions.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-06T11:24:07Z"}
{"aid":"http://arxiv.org/abs/2505.03454v1","title":"Simulation-based performance comparison of varied pitch sizes GEM\n  detectors","summary":"Gas Electron Multiplier (GEM) detectors, typically featuring a standard pitch\nsize of 140 $\\mu$m and an inner hole diameter of 50 $\\mu$m, are extensively\nutilized in high-energy physics experiments for tracking, triggering, and\ntiming measurements. Their characteristics, such as high gain, good position\nresolution, improved temporal resolution, low discharge probability, radiation\nhardness, and high rate capabilities, make them highly favoured. Recent\nexperimental studies have shown that triple-GEM detectors with a reduced pitch\nsize of 90 $\\mu$m and a smaller hole diameter of 40 $\\mu$m can perform better\nthan standard-pitch GEM detectors. To assess the effectiveness of these reduced\ndimensions, we conducted a simulation-based study using ANSYS and Garfield++.\nAs a first step, we validated the simulation framework by modelling a standard\nsingle GEM detector and comparing the results with previous simulations and\nexperimental data. Following validation, we designed GEM structures with\nreduced pitch sizes of 90 $\\mu$m and 60 $\\mu$m. We then performed a comparative\nanalysis, focusing on key performance parameters like effective gain, electron\ntransparency, and position resolution. These parameters were varied against an\nincrease in GEM potential, drift electric field, induction electric field,\ndrift gap, induction gap, and gas composition to optimize the performance of\nthe detectors.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-06T11:51:45Z"}
{"aid":"http://arxiv.org/abs/2505.03466v1","title":"Design principles of deep translationally-symmetric neural quantum\n  states for frustrated magnets","summary":"Deep neural network quantum states have emerged as a leading method for\nstudying the ground states of quantum magnets. Successful architectures exploit\ntranslational symmetry, but the root of their effectiveness and differences\nbetween architectures remain unclear. Here, we apply the ConvNext architecture,\ndesigned to incorporate elements of transformers into convolutional networks,\nto quantum many-body ground states. We find that it is remarkably similar to\nthe factored vision transformer, which has been employed successfully for\nseveral frustrated spin systems, allowing us to relate this architecture to\nmore conventional convolutional networks. Through a series of numerical\nexperiments we design the ConvNext to achieve greatest performance at lowest\ncomputational cost, then apply this network to the Shastry-Sutherland and J1-J2\nmodels, obtaining variational energies comparable to the state of the art,\nproviding a blueprint for network design choices of translationally-symmetric\narchitectures to tackle challenging ground-state problems in frustrated\nmagnetism.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.dis-nn,quant-ph","published":"2025-05-06T12:08:59Z"}
{"aid":"http://arxiv.org/abs/2505.03480v1","title":"Modeling Musical Genre Trajectories through Pathlet Learning","summary":"The increasing availability of user data on music streaming platforms opens\nup new possibilities for analyzing music consumption. However, understanding\nthe evolution of user preferences remains a complex challenge, particularly as\ntheir musical tastes change over time. This paper uses the dictionary learning\nparadigm to model user trajectories across different musical genres. We define\na new framework that captures recurring patterns in genre trajectories, called\npathlets, enabling the creation of comprehensible trajectory embeddings. We\nshow that pathlet learning reveals relevant listening patterns that can be\nanalyzed both qualitatively and quantitatively. This work improves our\nunderstanding of users' interactions with music and opens up avenues of\nresearch into user behavior and fostering diversity in recommender systems. A\ndataset of 2000 user histories tagged by genre over 17 months, supplied by\nDeezer (a leading music streaming company), is also released with the code.","main_category":"cs.IR","categories":"cs.IR,cs.LG,cs.MM","published":"2025-05-06T12:33:40Z"}
{"aid":"http://arxiv.org/abs/2505.03503v1","title":"Orbits Inside Basins of Attraction of Skew Products","summary":"A basic problem in complex dynamics is to understand orbits of holomorphic\nmaps. One problem is to understand the collection of points $S$ in an\nattracting basin whose forward orbits land exactly on the attracting fixed\npoint. In the paper [13], the second author showed that for holomorphic\npolynomials in $\\mathbb C$, there is a constant $C$ so that all Kobayashi discs\nof radius $C$ must intersect this set $S$. In the paper [15], the second author\nshowed that there are holomorphic skew products in $\\mathbb {C}^2$ where this\nresult fails. The main result of this paper is to show that for a large class\nof polynomial skew products, this result nevertheless holds.","main_category":"math.DS","categories":"math.DS","published":"2025-05-06T13:09:48Z"}
{"aid":"http://arxiv.org/abs/2505.03508v1","title":"Identifying Astrophysical Anomalies in 99.6 Million Cutouts from the\n  Hubble Legacy Archive Using AnomalyMatch","summary":"Astronomical archives contain vast quantities of unexplored data that\npotentially harbour rare and scientifically valuable cosmological phenomena. We\nhave systematically searched approximately 100 million image cutouts from the\nentire Hubble Legacy Archive using the recently developed AnomalyMatch method,\nwhich combines semi-supervised and active learning techniques for the efficient\ndetection of astrophysical anomalies. This comprehensive search rapidly\nuncovered a multitude of astrophysical anomalies presented here that\nsignificantly expand the inventory of known rare objects. Among our discoveries\nare 138 new candidate gravitational lenses, 18 jellyfish galaxies, and 417\nmergers or interacting galaxes. The efficiency and accuracy of our iterative\ndetection strategy allows us to trawl the complete archive within just 2-3\ndays, highlighting its potential for large-scale astronomical surveys. We\npresent a detailed overview of these newly identified objects, discuss their\nastrophysical significance, and demonstrate the considerable potential of\nAnomalyMatch to efficiently explore extensive astronomical datasets, e.g.,\nupcoming Euclid data releases.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-05-06T13:19:14Z"}
{"aid":"http://arxiv.org/abs/2505.03546v1","title":"A stacky comparison of the Hodge and Nygaard filtrations","summary":"We use the approach to $p$-adic cohomology theories via stacks recently\ndeveloped by Drinfeld and Bhatt--Lurie to formulate a stacky version of a\ncomparison result between the Nygaard filtration on prismatic cohomology and\nthe Hodge filtration on de Rham cohomology by Bhatt--Lurie and thereby also\nobtain a generalisation in the case of smooth and proper $p$-adic formal\nschemes which allows for coefficients in an arbitrary gauge. In the process, we\ndevelop a stacky approach to diffracted Hodge cohomology as introduced by\nBhatt--Lurie which also captures the conjugate filtration and the Sen operator.\nIn the appendix, we also introduce a stack computing the conjugate filtration\non absolute Hodge--Tate cohomology.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-05-06T13:58:45Z"}
{"aid":"http://arxiv.org/abs/2505.03551v1","title":"Emergence of a Classical Dirac-Type Spin from On-Shell Factorisation and\n  Liouvillian Evolution","summary":"While Liouville's theorem is first order in time for the phase-space\ndistribution itself, the relativistic mass-shell constraint $p^\\mu p_\\mu = m^2$\nis naively second order in energy. We argue it is reasonable to unify both\nenergy branches within a single Hamiltonian by factorising $(p^2 - m^2)$ in\nanalogy with Dirac's approach in relativistic quantum mechanics. We show the\nresulting matrix-based Liouville equation remains first order and naturally\nyields a $4\\times4$ matrix-valued probability density function in phase space\nas a classical analogue of a relativistic spin-half Wigner function.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-05-06T14:02:52Z"}
{"aid":"http://arxiv.org/abs/2505.03555v1","title":"Empc: Effective Path Prioritization for Symbolic Execution with Path\n  Cover","summary":"Symbolic execution is a powerful program analysis technique that can formally\nreason the correctness of program behaviors and detect software bugs. It can\nsystematically explore the execution paths of the tested program. But it\nsuffers from an inherent limitation: path explosion. Path explosion occurs when\nsymbolic execution encounters an overwhelming number (exponential to the\nprogram size) of paths that need to be symbolically reasoned. It severely\nimpacts the scalability and performance of symbolic execution. To tackle this\nproblem, previous works leverage various heuristics to prioritize paths for\nsymbolic execution. They rank the exponential number of paths using static\nrules or heuristics and explore the paths with the highest rank. However, in\npractice, these works often fail to generalize to diverse programs. In this\nwork, we propose a novel and effective path prioritization technique with path\ncover, named Empc. Our key insight is that not all paths need to be\nsymbolically reasoned. Unlike traditional path prioritization, our approach\nleverages a small subset of paths as a minimum path cover (MPC) that can cover\nall code regions of the tested programs. To encourage diversity in path\nprioritization, we compute multiple MPCs. We then guide the search for symbolic\nexecution on the small number of paths inside multiple MPCs rather than the\nexponential number of paths. We implement our technique Empc based on KLEE. We\nconduct a comprehensive evaluation of Empc to investigate its performance in\ncode coverage, bug findings, and runtime overhead. The evaluation shows that\nEmpc can cover 19.6% more basic blocks than KLEE's best search strategy and\n24.4% more lines compared to the state-of-the-art work cgs. Empc also finds 24\nmore security violations than KLEE's best search strategy. Meanwhile, Empc can\nsignificantly reduce the memory usage of KLEE by up to 93.5%.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-06T14:08:36Z"}
{"aid":"http://arxiv.org/abs/2505.03556v1","title":"A Comprehensive Survey of Large AI Models for Future Communications:\n  Foundations, Applications and Challenges","summary":"The 6G wireless communications aim to establish an intelligent world of\nubiquitous connectivity, providing an unprecedented communication experience.\nLarge artificial intelligence models (LAMs) are characterized by significantly\nlarger scales (e.g., billions or trillions of parameters) compared to typical\nartificial intelligence (AI) models. LAMs exhibit outstanding cognitive\nabilities, including strong generalization capabilities for fine-tuning to\ndownstream tasks, and emergent capabilities to handle tasks unseen during\ntraining. Therefore, LAMs efficiently provide AI services for diverse\ncommunication applications, making them crucial tools for addressing complex\nchallenges in future wireless communication systems. This study provides a\ncomprehensive review of the foundations, applications, and challenges of LAMs\nin communication. First, we introduce the current state of AI-based\ncommunication systems, emphasizing the motivation behind integrating LAMs into\ncommunications and summarizing the key contributions. We then present an\noverview of the essential concepts of LAMs in communication. This includes an\nintroduction to the main architectures of LAMs, such as transformer, diffusion\nmodels, and mamba. We also explore the classification of LAMs, including large\nlanguage models (LLMs), large vision models (LVMs), large multimodal models\n(LMMs), and world models, and examine their potential applications in\ncommunication. Additionally, we cover the training methods and evaluation\ntechniques for LAMs in communication systems. Lastly, we introduce optimization\nstrategies such as chain of thought (CoT), retrieval augmented generation\n(RAG), and agentic systems. Following this, we discuss the research\nadvancements of LAMs across various communication scenarios. Finally, we\nanalyze the challenges in the current research and provide insights into\npotential future research directions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-06T14:09:29Z"}
{"aid":"http://arxiv.org/abs/2505.03564v1","title":"Full space-time abrupt autofocusing spherical Airy wavepacket","summary":"The ability to precisely focus optical beams is crucial for numerous\napplications, yet conventional Gaussian beams exhibit slow intensity\ntransitions near the focal point, limiting their effectiveness in scenarios\nrequiring sharp focusing. In this work, the spherical Airy wavepacket, a three\ndimensional light field with an Airy function distribution in the radial\ndirection in the full space time domain, is introduced and experimentally\ndemonstrated. Leveraging the recently developed spatiotemporal hologram\ntechnique and an exponential polar coordinate transformation, spherical Airy\nwavepacket is sculpted to exhibit ultrafast autofocusing with a dramatically\nreduced depth of focus compared to conventional Gaussian beams and circular\nAiry beams. Experimental measurements confirm its nonlinear intensity surge and\ntight spatiotemporal confinement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-06T14:18:56Z"}
{"aid":"http://arxiv.org/abs/2505.03571v1","title":"Crystal structural evolution of Ru$_3$Sn$_7$ under pressure and its\n  implication on possible electronic changes","summary":"Ru$_3$Sn$_7$, an intermetallic compound with advanced catalytic properties,\nexhibits a complex crystal structure and intriguing electronic properties,\nmaking it an attractive candidate for investigations under high-pressure (HP).\nThe structural, vibrational and electronic band structure of this compound were\ninvestigated at HP up to ~ 20 GPa using synchrotron x-ray powder diffraction,\nmicro-Raman, and density functional theory (DFT), respectively. Despite the\nlocal structural changes implied by a discernible reduction in the\ncompressibility and distinct slope changes in the pressure evolution of the\nsymmetric stretching vibrations of the Ru and Sn atoms around 8 GPa, the cubic\nstructure is found to be stable throughout the pressure range. In support, our\ncalculated phonon dispersion relation confirmed the stability of the cubic\nphase till the highest pressures. A comprehensive analysis of the Raman\nspectrum reveals the signatures of the pressure induced sudden strengthening of\nelectron-phonon coupling as early as 3 GPa which is backed by a bounce in the\nphonon and electron density of states (DoS). Electronic structure calculations\ndemonstrate that the metallic nature of Ru$_3$Sn$_7$ is preserved in the\nstudied pressure range with a minor redistribution of electronic DoS across the\nFermi level (EF). The band structure calculations predict intriguing changes in\nthe electronic structure, revealing the pressure induced dp hybridization\nthrough the high symmetry point of the Brillouin zone which is largely\nresponsible for the observed reduction in the compressibility and enhancement\nof the electron-phonon coupling in Ru$_3$Sn$_7$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T14:30:18Z"}
{"aid":"http://arxiv.org/abs/2505.03573v1","title":"Troika algorithm: approximate optimization for accurate clique\n  partitioning and clustering of weighted networks","summary":"Clique partitioning is a fundamental network clustering task, with\napplications in a wide range of computational sciences. It involves identifying\nan optimal partition of the nodes for a real-valued weighted graph according to\nthe edge weights. An optimal partition is one that maximizes the sum of\nwithin-cluster edge weights over all possible node partitions. This paper\nintroduces a novel approximation algorithm named Troika to solve this NP-hard\nproblem in small to mid-sized networks for instances of theoretical and\npractical relevance. Troika uses a branch-and-cut scheme for branching on node\ntriples to find a partition that is within a user-specified optimality gap\ntolerance. Troika offers advantages over alternative methods like integer\nprogramming solvers and heuristics for clique partitioning. Unlike existing\nheuristics, Troika returns solutions within a guaranteed proximity to global\noptimality. And our results indicate that Troika is faster than using the\nstate-of-the-art integer programming solver Gurobi for most benchmark\ninstances. Besides its advantages for solving the clique partitioning problem,\nwe demonstrate the applications of Troika in community detection and portfolio\nanalysis. Troika returns partitions with higher proximity to optimal compared\nto eight modularity-based community detection algorithms. When used on networks\nof correlations among stocks, Troika reveals the dynamic changes in the\nstructure of portfolio networks including downturns from the 2008 financial\ncrisis and the reaction to the COVID-19 pandemic. Our comprehensive results\nbased on benchmarks from the literature and new real and random networks point\nto Troika as a reliable and accurate method for solving clique partitioning\ninstances with up to 5000 edges on standard hardware.","main_category":"cs.SI","categories":"cs.SI,cs.DS,math.OC","published":"2025-05-06T14:32:54Z"}
{"aid":"http://arxiv.org/abs/2505.03578v1","title":"On the non-Markovian quantum stochastic network dynamics","summary":"In this paper, we investigate the non-Markovian quantum dynamics based on\nquantum noise properties in a network of atoms mediated by a waveguide. In such\nnetworks, quantum coherent feedback control becomes achievable when coherent\nfields (or quantum noises) in the form of photons with continuous modes\npropagate through the waveguide. Different from traditional Markovian quantum\nsystems, the non-Markovian quantum network can be regarded as a quantum system\ninteracting with multiple input quantum noise channels with different time\ndelays, and the \\rm{It\\={o}} relationships among different quantum noise\nchannels can be represented with a non-Markovian integral process with integral\nkernels determined by the relative distances among atoms and their coupling\nmethods to the waveguide. Then the non-Markovian dynamics of the quantum\nnetwork can be modeled with the quantum stochastic differential equation\n(QSDE), which contains an integral process with integral kernels determined by\nthe \\rm{It\\={o}} relationships among quantum noises. Utilizing this modeling\napproach from the perspective of quantum noises, the control dynamics can be\nclarified according to the noise properties and measurement results of the\nnon-Markovian quantum network can be evaluated at the output end, which can be\nfurther used in the filtering of quantum states within Markovian\napproximations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-06T14:39:37Z"}
{"aid":"http://arxiv.org/abs/2505.03586v1","title":"Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning\n  Framework for Mitigating Delayed Observation","summary":"In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralization capability. Our work provides a novel perspective on multi-agent\ndelayed observation problems and offers an effective solution framework.","main_category":"cs.MA","categories":"cs.MA,cs.AI,I.2","published":"2025-05-06T14:47:56Z"}
{"aid":"http://arxiv.org/abs/2505.03588v1","title":"Shear viscosity and electrical conductivity of rotating quark matter in\n  Nambu--Jona-Lasinio Model","summary":"The Lagrangian for strongly interacting and rotating quark matter is modified\nwith the inclusion of the spinorial connections, which in turn affect the\nthermodynamic equation of state and transport properties of the medium. In this\nwork, we investigate the transport properties of quark matter under finite\nrotation, focusing specifically on electrical conductivity and shear viscosity\nby using a two-flavor Nambu--Jona-Lasinio (NJL) model. The chiral condensate in\nthe NJL model decreases under rotation, leading to enhanced transport\nproperties. Moreover, rotation induces anisotropy in the transport\ncoefficients, which are calculated within the kinetic theory framework using\nthe Boltzmann transport equation. The Coriolis force is introduced in the force\nterm of the Boltzmann transport equation, like the Lorentz force, which is\nconsidered for finite magnetic fields. By using a phenomenological\ntemperature-dependent angular velocity, we observe that the variation of\nanisotropic components with temperature preserves the traditional valley-shaped\npattern. However, the magnitude of the anisotropic components is suppressed\ncompared to the usual component one finds in the absence of rotation.\nInterestingly, at zero net quark density, Hall-like transport phenomena emerge\nas significant non-dissipative contributions under rotation, which is not\nexpected under finite magnetic fields due to the cancellation of quark and\nanti-quark Hall currents.","main_category":"nucl-th","categories":"nucl-th","published":"2025-05-06T14:48:51Z"}
{"aid":"http://arxiv.org/abs/2505.03624v1","title":"ATRAF-driven IMRaD Methodology: Tradeoff and Risk Analysis of Software\n  Architectures Across Abstraction Levels","summary":"Software architecture research relies on key architectural artifacts --\nSoftware Architectures, Reference Architectures, and Architectural Frameworks\n-- that underpin the design and analysis of complex systems. Evaluating these\nartifacts is essential to assess tradeoffs and risks affecting quality\nattributes such as performance, modifiability, and security. Although\nmethodologies like the Architecture Tradeoff Analysis Method (ATAM) support\nsoftware architecture evaluation, their industrial focus misaligns with the\nIMRaD (Introduction, Methods, Results, Discussion) format prevalent in academic\nresearch, impeding transparency and reproducibility. Our prior work introduced\nthe Architecture Tradeoff and Risk Analysis Framework (ATRAF), extending ATAM\nthrough three methods -- ATRAM, RATRAM, and AFTRAM, addressing all abstraction\nlevels, using a unified, iterative four-phase spiral model. These phases --\nScenario and Requirements Gathering, Architectural Views and Scenario\nRealization, Attribute-Specific Analyses, and Sensitivity, Tradeoff, and Risk\nAnalysis -- ensure traceability and coherence. This paper presents the\nATRAF-driven IMRaD Methodology, a concise method to align ATRAF's phases with\nIMRaD sections. This methodology enhances the rigor, transparency, and\naccessibility of software architecture research, enabling systematic reporting\nof complex evaluations.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-06T15:22:28Z"}
{"aid":"http://arxiv.org/abs/2505.03635v1","title":"Accelerating the development of oxynitride thin films: A combinatorial\n  investigation of the Al-Si-O-N system","summary":"Oxynitrides are used in a variety of applications including photocatalysts,\nhigh-k dielectrics or wear-resistant coatings and often show intriguing\nmulti-functionality. To accelerate the co-optimization of the relevant material\nproperties of these compositionally complex oxynitride systems, high-throughput\nsynthesis and characterization methods are desirable. In the present work,\nthree approaches were investigated to obtain orthogonal anion and cation\ngradients on the same substrate by magnetron sputtering. The different\napproaches included varying positions of the local reactive gas inlets and\ndifferent combinations of target materials. The best performing approach was\napplied to screen a large two-dimensional area of the quaternary phase space\nwithin the Al-Si-O-N system. This material system is a promising candidate for\ntransparent protective coatings with variable refractive indices. With only\nfive depositions of combinatorial libraries, an anion composition range of\n2-46% O/(N+O) and a cation composition range of 4-44% Si/(Al+Si) is covered.\nFor lower oxygen and silicon contents, a region with hardness of up to 25 GPa\nis observed, where the material exhibits either wurtzite AlN or a composite\nmicrostructure. By increasing the deposition temperature to 400 {\\deg}C, an\nextension of this region can be achieved. At higher oxygen and silicon\ncontents, the structure of the samples is X-ray amorphous. In this structural\nregion, an intimate correlation between hardness and refractive index is\nconfirmed. The results of this study introduce a practical approach to perform\nhigh-throughput development of mixed anion materials, which is transferable to\nmany materials systems and applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T15:37:11Z"}
{"aid":"http://arxiv.org/abs/2505.03639v1","title":"Differential Privacy for Network Assortativity","summary":"The analysis of network assortativity is of great importance for\nunderstanding the structural characteristics of and dynamics upon networks.\nOften, network assortativity is quantified using the assortativity coefficient\nthat is defined based on the Pearson correlation coefficient between vertex\ndegrees. It is well known that a network may contain sensitive information,\nsuch as the number of friends of an individual in a social network (which is\nabstracted as the degree of vertex.). So, the computation of the assortativity\ncoefficient leads to privacy leakage, which increases the urgent need for\nprivacy-preserving protocol. However, there has been no scheme addressing the\nconcern above.\n  To bridge this gap, in this work, we are the first to propose approaches\nbased on differential privacy (DP for short). Specifically, we design three\nDP-based algorithms: $Local_{ru}$, $Shuffle_{ru}$, and $Decentral_{ru}$. The\nfirst two algorithms, based on Local DP (LDP) and Shuffle DP respectively, are\ndesigned for settings where each individual only knows his/her direct friends.\nIn contrast, the third algorithm, based on Decentralized DP (DDP), targets\nscenarios where each individual has a broader view, i.e., also knowing his/her\nfriends' friends. Theoretically, we prove that each algorithm enables an\nunbiased estimation of the assortativity coefficient of the network. We further\nevaluate the performance of the proposed algorithms using mean squared error\n(MSE), showing that $Shuffle_{ru}$ achieves the best performance, followed by\n$Decentral_{ru}$, with $Local_{ru}$ performing the worst. Note that these three\nalgorithms have different assumptions, so each has its applicability scenario.\nLastly, we conduct extensive numerical simulations, which demonstrate that the\npresented approaches are adequate to achieve the estimation of network\nassortativity under the demand for privacy protection.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-06T15:40:47Z"}
{"aid":"http://arxiv.org/abs/2505.03648v1","title":"Binding threshold units with artificial oscillatory neurons","summary":"Artificial Kuramoto oscillatory neurons were recently introduced as an\nalternative to threshold units. Empirical evidence suggests that oscillatory\nunits outperform threshold units in several tasks including unsupervised object\ndiscovery and certain reasoning problems. The proposed coupling mechanism for\nthese oscillatory neurons is heterogeneous, combining a generalized Kuramoto\nequation with standard coupling methods used for threshold units. In this\nresearch note, we present a theoretical framework that clearly distinguishes\noscillatory neurons from threshold units and establishes a coupling mechanism\nbetween them. We argue that, from a biological standpoint, oscillatory and\nthreshold units realise distinct aspects of neural coding: roughly, threshold\nunits model intensity of neuron firing, while oscillatory units facilitate\ninformation exchange by frequency modulation. To derive interaction between\nthese two types of units, we constrain their dynamics by focusing on dynamical\nsystems that admit Lyapunov functions. For threshold units, this leads to\nHopfield associative memory model, and for oscillatory units it yields a\nspecific form of generalized Kuramoto model. The resulting dynamical systems\ncan be naturally coupled to form a Hopfield-Kuramoto associative memory model,\nwhich also admits a Lyapunov function. Various forms of coupling are possible.\nNotably, oscillatory neurons can be employed to implement a low-rank correction\nto the weight matrix of a Hopfield network. This correction can be viewed\neither as a form of Hebbian learning or as a popular LoRA method used for\nfine-tuning of large language models. We demonstrate the practical realization\nof this particular coupling through illustrative toy experiments.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.AI,cs.LG","published":"2025-05-06T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2505.03655v1","title":"Counterfactual Inference for Eliminating Sentiment Bias in Recommender\n  Systems","summary":"Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-05-06T16:00:41Z"}
{"aid":"http://arxiv.org/abs/2505.03682v1","title":"Evaluating Foveated Frame Rate Reduction in Virtual Reality for\n  Head-Mounted Displays","summary":"Foveated rendering methods usually reduce spatial resolution in the periphery\nof the users' view. However, using foveated rendering to reduce temporal\nresolution, i.e., rendering frame rate, seems less explored. In this work, we\npresent the results of a user study investigating the perceptual effects of\nfoveated temporal resolution reduction, where only the temporal resolution\n(frame rate) is reduced in the periphery without affecting spatial quality\n(pixel density). In particular, we investigated the perception of temporal\nresolution artifacts caused by reducing the frame rate dependent on the\neccentricity of the user's gaze. Our user study with 15 participants was\nconducted in a virtual reality setting using a head-mounted display. Our\nresults indicate that it was possible to reduce average rendering costs, i.e.,\nthe number of rendered pixels, to a large degree before participants\nconsistently reported perceiving temporal artifacts.","main_category":"cs.HC","categories":"cs.HC,cs.GR","published":"2025-05-06T16:27:47Z"}
{"aid":"http://arxiv.org/abs/2505.03686v1","title":"The response of a quantum system to a collision: an autonomous\n  derivation of Kubo's formula","summary":"We study the response of a quantum system induced by a collision with a\nquantum particle, using the time-independent framework of scattering theory.\nAfter deriving the dynamical map for the quantum system, we show that the\nunitary contribution to the dynamics defines a non-perturbative response\nfunction obeying a general fluctuation-dissipation relation. We show that\nKubo's formula emerges autonomously in the Born approximation, where the\ntime-dependent perturbation is determined by particle's evolution through the\npotential region.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-05-06T16:32:42Z"}
{"aid":"http://arxiv.org/abs/2505.03695v1","title":"Frenet Corridor Planner: An Optimal Local Path Planning Framework for\n  Autonomous Driving","summary":"Motivated by the requirements for effectiveness and efficiency, path-speed\ndecomposition-based trajectory planning methods have widely been adopted for\nautonomous driving applications. While a global route can be pre-computed\noffline, real-time generation of adaptive local paths remains crucial.\nTherefore, we present the Frenet Corridor Planner (FCP), an optimization-based\nlocal path planning strategy for autonomous driving that ensures smooth and\nsafe navigation around obstacles. Modeling the vehicles as safety-augmented\nbounding boxes and pedestrians as convex hulls in the Frenet space, our\napproach defines a drivable corridor by determining the appropriate deviation\nside for static obstacles. Thereafter, a modified space-domain bicycle\nkinematics model enables path optimization for smoothness, boundary clearance,\nand dynamic obstacle risk minimization. The optimized path is then passed to a\nspeed planner to generate the final trajectory. We validate FCP through\nextensive simulations and real-world hardware experiments, demonstrating its\nefficiency and effectiveness.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-06T17:00:32Z"}
{"aid":"http://arxiv.org/abs/2505.03734v1","title":"Highly squeezed nanophotonic quantum microcombs with broadband frequency\n  tunability","summary":"Squeezed light offers genuine quantum advantage in enhanced sensing and\nquantum computation; yet the level of squeezing or quantum noise reduction\ngenerated from nanophotonic chips has been limited. In addition to strong\nquantum noise reduction, key desiderata for such a nanophotonic squeezer\ninclude frequency agility or tunability over a broad frequency range, and\nsimultaneous operation in many distinct, well-defined quantum modes (qumodes).\nHere we present a strongly overcoupled silicon nitride squeezer based on a\nbelow-threshold optical parametric amplifier (OPA) that produces directly\ndetected squeezing of 5.6 dB $\\pm$ 0.2 dB, surpassing previous demonstrations\nin both continuous-wave and pulsed regimes. We introduce a seed-assisted\ndetection technique into such nanophotonic squeezers that reveals a quantum\nfrequency comb (QFC) of 16 qumodes, with a separation of 11~THz between the\nfurthest qumode pair, while maintaining a strong squeezing. Additionally, we\nreport spectral tuning of a qumode comb pair over one free-spectral range of\nthe OPA, thus bridging the spacing between the discrete modes of the QFC. Our\nresults significantly advance both the generation and detection of nanophotonic\nsqueezed light in a broadband and multimode platform, establishing a scalable,\nchip-integrated path for compact quantum sensors and continuous-variable\nquantum information processing systems.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-05-06T17:59:23Z"}
{"aid":"http://arxiv.org/abs/2505.04107v1","title":"Unravelling the non-Markovian spin-boson model and quantum quasi-Otto\n  cycle","summary":"We use the spin-boson model to describe the dynamics of a two-level atom\ninteracting with Fabry-P\\'erot cavity modes. We solve the Schr\\\"odinger\nequation for the system-bath model without the Born-Markov approximation to\nderive the non-Markovian reduced dynamics of the qubit. We further construct an\nexact Lindblad-type master equation for it. Similar to the quantum Otto cycle,\nwe construct a non- Markovian quasi-cyclic process based on the atom-cavity\ninteractions, which we call the quasi-Otto cycle. For judicious choices of\ninput state and parameters, the quasi-cycle can be more efficient as a quantum\nengine than the Otto cycle. We also showed that if the quasi-cycle is repeated\nmultiple times, the efficiency of the quasi-Otto engine asymptotically\napproaches that of the Otto engine.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-07T03:48:27Z"}
{"aid":"http://arxiv.org/abs/2505.04112v1","title":"Semi-Explicit Solution of Some Discrete-Time Mean-Field-Type Control\n  with Higher-Order Costs","summary":"Traditional solvable optimal control theory predominantly focuses on\nquadratic costs due to their analytical tractability, yet they often fail to\ncapture critical non-linearities inherent in real-world systems including\nwater, energy, agriculture, and financial networks. Here, we present a unified\nframework for solving discrete-time optimal control with higher-order state and\ncontrol costs of power-law form. By building convex-completion techniques, we\nderive semi-explicit expressions for control laws, cost-to-go functions, and\nrecursive coefficient dynamics across deterministic and stochastic system\nsettings. Key contributions include variance-aware solutions under additive and\nmultiplicative noise, extensions to mean-field-type-dependent dynamics, and\nconditions that ensure the positivity of recursive coefficients. In particular,\nwe establish that higher-order costs induce less aggressive control policies\ncompared to quadratic formulations, a finding that is validated through\nnumerical analyses.","main_category":"math.OC","categories":"math.OC","published":"2025-05-07T04:03:36Z"}
{"aid":"http://arxiv.org/abs/2505.04146v1","title":"Unmasking the Canvas: A Dynamic Benchmark for Image Generation\n  Jailbreaking and LLM Content Safety","summary":"Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY","published":"2025-05-07T05:54:04Z"}
{"aid":"http://arxiv.org/abs/2505.04153v1","title":"Global Hash Tables Strike Back! An Analysis of Parallel GROUP BY\n  Aggregation","summary":"Efficiently computing group aggregations (i.e., GROUP BY) on modern many-core\narchitectures is critical for analytic database systems. Today's engines\npredominately use a partitioned approach to group aggregation, in which an\nincoming data stream is partitioned by key values so that every row for a\nparticular key is sent to the same thread. In this paper, we revisit a simpler\nstrategy: a fully concurrent group aggregation technique using a shared global\nhash table. While approaches using general-purpose concurrent hash tables have\ngenerally been found to perform worse than partitioning-based approaches, we\nargue that the key ingredient is customizing the concurrent hash table for the\nspecific task of group aggregation. Through extensive experiments on synthetic\nworkloads (varying key cardinality, skew, and thread counts), we demonstrate\nthat a purpose-built concurrent hash table can match or surpass\npartitioning-based techniques. We also analyze the operational characteristics\nof both techniques, including resizing costs and memory pressure. In the\nprocess, we derive practical guidelines for database implementers. Overall, our\nanalysis indicates that fully concurrent group aggregation is a viable\nalternative to partitioning.","main_category":"cs.DB","categories":"cs.DB","published":"2025-05-07T06:06:46Z"}
{"aid":"http://arxiv.org/abs/2505.04176v1","title":"Developing Assessment Methods for Evaluating Learning Experience","summary":"This research aims to investigate the gender-based learning experiences of\nengineering students enrolled in the Probability and Statistics course,\nfocusing on the four different assessment methods employed namely direct\nconceptual learning (DCL), symposium, applied deployment and collaborative\nlearning. The study encompasses 299 engineering students, comprising 90 females\nand 209 males. Multivariate Analysis of Variance (MANOVA), is used to gain\ndeeper insights into the complex interplay between assessment methods and their\ninfluence on student learning. The results of the statistical analysis reveal\nthat there are significant differences in the learning outcomes between female\nand male engineering students in the assessment methods of direct conceptual\nlearning, symposium, and applied deployment. The findings suggest that there is\nno significant difference in the learning outcomes between female and male\nengineering students in the collaborative learning assessment method. The\ngraphical representation visually confirms the significant differences in\ndirect conceptual learning, symposium, and applied deployment, while\nillustrating no significant difference in collaborative learning between female\nand male engineering students.","main_category":"stat.OT","categories":"stat.OT","published":"2025-05-07T07:08:10Z"}
{"aid":"http://arxiv.org/abs/2505.04193v1","title":"Trajectory Entropy Reinforcement Learning for Predictable and Robust\n  Control","summary":"Simplicity is a critical inductive bias for designing data-driven\ncontrollers, especially when robustness is important. Despite the impressive\nresults of deep reinforcement learning in complex control tasks, it is prone to\ncapturing intricate and spurious correlations between observations and actions,\nleading to failure under slight perturbations to the environment. To tackle\nthis problem, in this work we introduce a novel inductive bias towards simple\npolicies in reinforcement learning. The simplicity inductive bias is introduced\nby minimizing the entropy of entire action trajectories, corresponding to the\nnumber of bits required to describe information in action trajectories after\nthe agent observes state trajectories. Our reinforcement learning agent,\nTrajectory Entropy Reinforcement Learning, is optimized to minimize the\ntrajectory entropy while maximizing rewards. We show that the trajectory\nentropy can be effectively estimated by learning a variational parameterized\naction prediction model, and use the prediction model to construct an\ninformation-regularized reward function. Furthermore, we construct a practical\nalgorithm that enables the joint optimization of models, including the policy\nand the prediction model. Experimental evaluations on several high-dimensional\nlocomotion tasks show that our learned policies produce more cyclical and\nconsistent action trajectories, and achieve superior performance, and\nrobustness to noise and dynamic changes than the state-of-the-art.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-05-07T07:41:29Z"}
{"aid":"http://arxiv.org/abs/2505.04210v1","title":"Sick of being driven? -- Prevalence and modulating factors of\n  carsickness in the European population in context of automated driving","summary":"As in automated driving the driver becomes a passenger, carsickness might\nreduce comfort for susceptible individuals. Insights in the prevalence of\ncarsickness and its modulating factors are considered useful for the\ndevelopment of automated vehicles to mitigate or prevent its occurrence. An\nonline survey was conducted with N = 3999 participants in Spain, Sweden,\nPoland, and Germany. 30% of participants reported to have already experienced\ncarsickness as adult. The frequency of carsickness was modulated not only by\ndemographic factors (country, gender, age), but also by frequency of being a\npassenger, type of non-driving related task, road type, and the seating\nposition in car. Furthermore, the efficiency of applied countermeasures,\ntemporal aspects of carsickness development, as well as the relation of\ncarsickness with the acceptability of automated driving and the effect on\nsubjective fitness to drive was investigated. The results are discussed with\nfocus on automated driving.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-07T08:04:33Z"}
{"aid":"http://arxiv.org/abs/2505.04214v1","title":"CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with\n  Large Vision Language Models","summary":"The automatic extraction of key-value information from handwritten documents\nis a key challenge in document analysis. A reliable extraction is a\nprerequisite for the mass digitization efforts of many archives. Large Vision\nLanguage Models (LVLM) are a promising technology to tackle this problem\nespecially in scenarios where little annotated training data is available. In\nthis work, we present a novel dataset specifically designed to evaluate the\nfew-shot capabilities of LVLMs. The CM1 documents are a historic collection of\nforms with handwritten entries created in Europe to administer the Care and\nMaintenance program after World War Two. The dataset establishes three\nbenchmarks on extracting name and birthdate information and, furthermore,\nconsiders different training set sizes. We provide baseline results for two\ndifferent LVLMs and compare performances to an established full-page extraction\nmodel. While the traditional full-page model achieves highly competitive\nperformances, our experiments show that when only a few training samples are\navailable the considered LVLMs benefit from their size and heavy pretraining\nand outperform the classical approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T08:08:58Z"}
{"aid":"http://arxiv.org/abs/2505.04215v1","title":"Random walks with resetting on hypergraph","summary":"Hypergraph has been selected as a powerful candidate for characterizing\nhigher-order networks and has received\n  increasing attention in recent years. In this article, we study random walks\nwith resetting on hypergraph by utilizing\n  spectral theory. Specifically, we derive exact expressions for some\nfundamental yet key parameters, including occupation\n  probability, stationary distribution, and mean first passage time, all of\nwhich are expressed in terms of the eigenvalues\n  and eigenvectors of the transition matrix. Furthermore, we provide a general\ncondition for determining the optimal\n  reset probability and a sufficient condition for its existence. In addition,\nwe build up a close relationship between\n  random walks with resetting on hypergraph and simple random walks.\nConcretely, the eigenvalues and eigenvectors\n  of the former can be precisely represented by those of the latter. More\nimportantly, when considering random walks,\n  we abandon the traditional approach of converting hypergraph into a graph and\npropose a research framework that\n  preserves the intrinsic structure of hypergraph itself, which is based on\nassigning proper weights to neighboring nodes.\n  Through extensive experiments, we show that the new framework produces\ndistinct and more reliable results than\n  the traditional approach in node ranking. Finally, we explore the impact of\nthe resetting mechanism on cover time,\n  providing a potential solution for optimizing search efficiency.","main_category":"cs.SI","categories":"cs.SI,physics.data-an","published":"2025-05-07T08:09:16Z"}
{"aid":"http://arxiv.org/abs/2505.04220v1","title":"Uninorms via two comparable closure operators on bounded lattices","summary":"In this paper, we propose novel methods for constructing uninorms using two\ncomparable closure operators or, alternatively, two comparable interior\noperators on bounded lattices. These methods are developed under the necessary\nand sufficient conditions imposed on these operators. Specifically, the\nconstruction of uninorms for $(x ,y )\\in ]0 ,e [\\times]e ,1 [ \\cup ]e ,1\n[\\times]0 ,e [$ depends not only on the structure of the bounded lattices but\nalso on the chosen closure operators (or interior operators). Consequently, the\nresulting uninorms do not necessarily belong to $\\mathcal{U}_{min}^{*}\\cup\n\\mathcal{U}_{min}^{1}$ (or $\\mathcal{U}_{max}^{*}\\cup\\mathcal{U}_{max}^{0}$).\nMoreover, we present the degenerate cases of the aforementioned results, which\nare constructed using only a single closure operator or a single interior\noperator. Some of these cases correspond to well-known results documented in\nthe literature.","main_category":"math.FA","categories":"math.FA,math.LO","published":"2025-05-07T08:19:28Z"}
{"aid":"http://arxiv.org/abs/2505.04254v1","title":"CompileAgent: Automated Real-World Repo-Level Compilation with\n  Tool-Integrated LLM-based Agent System","summary":"With open-source projects growing in size and complexity, manual compilation\nbecomes tedious and error-prone, highlighting the need for automation to\nimprove efficiency and accuracy. However, the complexity of compilation\ninstruction search and error resolution makes automatic compilation\nchallenging. Inspired by the success of LLM-based agents in various fields, we\npropose CompileAgent, the first LLM-based agent framework dedicated to\nrepo-level compilation. CompileAgent integrates five tools and a flow-based\nagent strategy, enabling interaction with software artifacts for compilation\ninstruction search and error resolution. To measure the effectiveness of our\nmethod, we design a public repo-level benchmark CompileAgentBench, and we also\ndesign two baselines for comparison by combining two compilation-friendly\nschemes. The performance on this benchmark shows that our method significantly\nimproves the compilation success rate, ranging from 10% to 71%. Meanwhile, we\nevaluate the performance of CompileAgent under different agent strategies and\nverify the effectiveness of the flow-based strategy. Additionally, we emphasize\nthe scalability of CompileAgent, further expanding its application prospects.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-07T08:59:14Z"}
{"aid":"http://arxiv.org/abs/2505.04297v1","title":"Investigating monogenity in a family of cyclic sextic fields","summary":"L. Jones characterized among others monogenity of a family of cyclic sextic\npolynomials. Our purpose is to study monogenity of the family of corresponding\nsextic number fields. This also provides the first non-trivial application of\nthe used method, emphasizing its efficiency.","main_category":"math.NT","categories":"math.NT","published":"2025-05-07T10:08:35Z"}
{"aid":"http://arxiv.org/abs/2505.04327v1","title":"Asymptotic Higher Spin Symmetries IV: Einstein-Yang-Mills Theory","summary":"We generalize the analysis of the asymptotic higher spin symmetries developed\nin the first three parts of this series by considering the minimal coupling of\nEinstein Gravity and Yang-Mills theory. We show that there exist symmetry\nparameters that satisfy a collection of dual equations of motion, which allow\nthe construction of an infinite collection of charges that are conserved in the\nabsence of radiation. These Noether charges act on the Einstein Yang-Mills\nphase space canonically and non-linearly. Their action defines a symmetry\nalgebroid which reduces to a symmetry algebra at non-radiative cuts and\ngeneralizes the celestial $sw_{1+\\infty}$ algebra. The corresponding symmetry\nbracket is shown to satisfy the Jacobi identity and an interesting\ncross-product structure, which is analyzed in details.","main_category":"hep-th","categories":"hep-th","published":"2025-05-07T11:22:15Z"}
{"aid":"http://arxiv.org/abs/2505.04373v1","title":"NN-Based Joint Mitigation of IQ Imbalance and PA Nonlinearity With\n  Multiple States","summary":"Joint mitigation of IQ imbalance and PA nonlinearity is important for\nimproving the performance of radio frequency (RF) transmitters. In this paper,\nwe propose a new neural network (NN) model, which can be used for joint digital\npre-distortion (DPD) of non-ideal IQ modulators and PAs in a transmitter with\nmultiple operating states. The model is based on the methodology of multi-task\nlearning (MTL). In this model, the hidden layers of the main NN are shared by\nall signal states, and the output layer's weights and biases are dynamically\ngenerated by another NN. The experimental results show that the proposed model\ncan effectively perform joint DPD for IQ-PA systems, and it achieves better\noverall performance within multiple signal states than the existing methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-07T12:48:44Z"}
{"aid":"http://arxiv.org/abs/2505.04374v1","title":"Quantum refrigerator embedded in spin-star environments: Scalings of\n  temperature and refrigeration time","summary":"We examine a quantum absorption refrigerator that comprises three qubits,\neach of which is connected with a separate spin-star environment. The\nrefrigerator exhibits the feature of transient cooling, i.e., lowering of the\ntemperature of the first qubit in sufficiently small timescales. Since the\nspin-star environment is inherently non-Markovian in nature, steady-state\ncooling may or may not be achieved. A key advantage of our model is that the\nsymmetries of the Hamiltonian enable a solution of the reduced density matrices\nof the refrigerator qubits, even in the presence of a large number (~50) of\nenvironmental spins. We derive the condition for autonomous refrigeration and\nanalyze how the optimal cold qubit temperature scales with the number of bath\nqubits. We find a power law scaling towards a constant asymptotic value. We\nalso find the scaling of the minimum time required for cooling as a function of\nthe number of bath spins. Further, we scrutinize the heat currents associated\nwith each of the three qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-07T12:53:05Z"}
{"aid":"http://arxiv.org/abs/2505.04409v1","title":"Measurement of neutron production in atmospheric neutrino interactions\n  at Super-Kamiokande","summary":"We present measurements of total neutron production from atmospheric neutrino\ninteractions in water, analyzed as a function of the electron-equivalent\nvisible energy over a range of 30 MeV to 10 GeV. These results are based on\n4,270 days of data collected by Super-Kamiokande, including 564 days with 0.011\nwt\\% gadolinium added to enhance neutron detection. The measurements are\ncompared to predictions from neutrino event generators combined with various\nhadron-nucleus interaction models, which consist of an intranuclear cascade\nmodel and a nuclear de-excitation model. We observe significant variations in\nthe predictions depending on the choice of hadron-nucleus interaction model. We\ndiscuss key factors that contribute to describing our data, such as in-medium\neffects in the intranuclear cascade and the accuracy of statistical evaporation\nmodeling.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-07T13:46:23Z"}
{"aid":"http://arxiv.org/abs/2505.04412v1","title":"Latent Manifold Reconstruction and Representation with Topological and\n  Geometrical Regularization","summary":"Manifold learning aims to discover and represent low-dimensional structures\nunderlying high-dimensional data while preserving critical topological and\ngeometric properties. Existing methods often fail to capture local details with\nglobal topological integrity from noisy data or construct a balanced\ndimensionality reduction, resulting in distorted or fractured embeddings. We\npresent an AutoEncoder-based method that integrates a manifold reconstruction\nlayer, which uncovers latent manifold structures from noisy point clouds, and\nfurther provides regularizations on topological and geometric properties during\ndimensionality reduction, whereas the two components promote each other during\ntraining. Experiments on point cloud datasets demonstrate that our method\noutperforms baselines like t-SNE, UMAP, and Topological AutoEncoders in\ndiscovering manifold structures from noisy data and preserving them through\ndimensionality reduction, as validated by visualization and quantitative\nmetrics. This work demonstrates the significance of combining manifold\nreconstruction with manifold learning to achieve reliable representation of the\nlatent manifold, particularly when dealing with noisy real-world data. Code\nrepository: https://github.com/Thanatorika/mrtg.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T13:47:22Z"}
{"aid":"http://arxiv.org/abs/2505.04416v1","title":"OBLIVIATE: Robust and Practical Machine Unlearning for Large Language\n  Models","summary":"Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CR,cs.LG","published":"2025-05-07T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2505.04440v1","title":"Towards Initialization-Agnostic Clustering with Iterative Adaptive\n  Resonance Theory","summary":"The clustering performance of Fuzzy Adaptive Resonance Theory (Fuzzy ART) is\nhighly dependent on the preset vigilance parameter, where deviations in its\nvalue can lead to significant fluctuations in clustering results, severely\nlimiting its practicality for non-expert users. Existing approaches generally\nenhance vigilance parameter robustness through adaptive mechanisms such as\nparticle swarm optimization and fuzzy logic rules. However, they often\nintroduce additional hyperparameters or complex frameworks that contradict the\noriginal simplicity of the algorithm. To address this, we propose Iterative\nRefinement Adaptive Resonance Theory (IR-ART), which integrates three key\nphases into a unified iterative framework: (1) Cluster Stability Detection: A\ndynamic stability detection module that identifies unstable clusters by\nanalyzing the change of sample size (number of samples in the cluster) in\niteration. (2) Unstable Cluster Deletion: An evolutionary pruning module that\neliminates low-quality clusters. (3) Vigilance Region Expansion: A vigilance\nregion expansion mechanism that adaptively adjusts similarity thresholds.\nIndependent of the specific execution of clustering, these three phases\nsequentially focus on analyzing the implicit knowledge within the iterative\nprocess, adjusting weights and vigilance parameters, thereby laying a\nfoundation for the next iteration. Experimental evaluation on 15 datasets\ndemonstrates that IR-ART improves tolerance to suboptimal vigilance parameter\nvalues while preserving the parameter simplicity of Fuzzy ART. Case studies\nvisually confirm the algorithm's self-optimization capability through iterative\nrefinement, making it particularly suitable for non-expert users in\nresource-constrained scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T14:12:39Z"}
{"aid":"http://arxiv.org/abs/2505.04449v1","title":"Phase Shift Information Compression in IRS-aided Wireless Systems:\n  Challenges and Opportunities","summary":"Intelligent reflecting surfaces (IRS) have emerged as a promising technology\nfor future 6G wireless networks, offering programmable control of the wireless\nenvironment by adjusting the phase shifts of reflecting elements. However, IRS\nperformance relies on accurately configuring the phase shifts of reflecting\nelements, which introduces substantial phase shift information (PSI) delivery\noverhead, especially in large-scale or rapidly changing environments. This\npaper first introduces the architecture of IRS-assisted systems and highlights\nreal-world use cases where PSI delivery becomes a critical bottleneck. It then\nreviews current PSI compression approaches, outlining their limitations in\nadaptability and scalability. To address these gaps, we propose a prompt-guided\nPSI compression framework that leverages task-aware prompts and meta-learning\nto achieve efficient and real-time PSI delivery under diverse conditions.\nSimulation results show improved reconstruction accuracy and robustness\ncompared to the baseline method. Finally, we discuss open challenges and\noutline promising directions for future research.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-07T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2505.04460v1","title":"Learning Real Facial Concepts for Independent Deepfake Detection","summary":"Deepfake detection models often struggle with generalization to unseen\ndatasets, manifesting as misclassifying real instances as fake in target\ndomains. This is primarily due to an overreliance on forgery artifacts and a\nlimited understanding of real faces. To address this challenge, we propose a\nnovel approach RealID to enhance generalization by learning a comprehensive\nconcept of real faces while assessing the probabilities of belonging to the\nreal and fake classes independently. RealID comprises two key modules: the Real\nConcept Capture Module (RealC2) and the Independent Dual-Decision Classifier\n(IDC). With the assistance of a MultiReal Memory, RealC2 maintains various\nprototypes for real faces, allowing the model to capture a comprehensive\nconcept of real class. Meanwhile, IDC redefines the classification strategy by\nmaking independent decisions based on the concept of the real class and the\npresence of forgery artifacts. Through the combined effect of the above\nmodules, the influence of forgery-irrelevant patterns is alleviated, and\nextensive experiments on five widely used datasets demonstrate that RealID\nsignificantly outperforms existing state-of-the-art methods, achieving a 1.74%\nimprovement in average accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T14:31:04Z"}
{"aid":"http://arxiv.org/abs/2505.04480v1","title":"TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven\n  Evolution","summary":"Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.","main_category":"cs.AI","categories":"cs.AI,cs.NE,cs.RO","published":"2025-05-07T14:51:43Z"}
{"aid":"http://arxiv.org/abs/2505.04495v1","title":"Voltage-tunable, femtometer-precision plasmo-mechanical displacement at\n  fixed gap size","summary":"We propose an elegant method for continuous electrical-tuning of\nplasmo-mechanical displacement and squeezing without changing plasmonic gap\nsize. Recent experiments bend the mechanical oscillator (cantilever) in units\nof nm via electrostatic actuators. We do not bend the cantilever but merely\nelectrically-tune the gap intensity, so plasmo-mechanical coupling, via Fano\nresonance. This allows continuous displacement tuning in units of mechanical\noscillator length that is about 30 fm in the experiments. This way, coupling\nstrength can be tuned by 2 orders-of-magnitude via only a 1 V potential\ndifference. Response time is picoseconds. Moreover, quadrature-squeezing\n(entanglement) of the oscillator can also be tuned continuously.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-05-07T15:19:21Z"}
{"aid":"http://arxiv.org/abs/2505.04519v1","title":"Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs","summary":"Sparse large language models (LLMs) with Mixture of Experts (MoE) and close\nto a trillion parameters are dominating the realm of most capable language\nmodels. However, the massive model scale poses significant challenges for the\nunderlying software and hardware systems. In this paper, we aim to uncover a\nrecipe to harness such scale on Ascend NPUs. The key goals are better usage of\nthe computing resources under the dynamic sparse model structures and\nmaterializing the expected performance gain on the actual hardware. To select\nmodel configurations suitable for Ascend NPUs without repeatedly running the\nexpensive experiments, we leverage simulation to compare the trade-off of\nvarious model hyperparameters. This study led to Pangu Ultra MoE, a sparse LLM\nwith 718 billion parameters, and we conducted experiments on the model to\nverify the simulation results. On the system side, we dig into Expert\nParallelism to optimize the communication between NPU devices to reduce the\nsynchronization overhead. We also optimize the memory efficiency within the\ndevices to further reduce the parameter and activation management overhead. In\nthe end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with\nperformance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and\ndemonstrate that the Ascend system is capable of harnessing all the training\nstages of the state-of-the-art language models. Extensive experiments indicate\nthat our recipe can lead to efficient training of large-scale sparse language\nmodels with MoE. We also study the behaviors of such models for future\nreference.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-07T15:46:36Z"}
{"aid":"http://arxiv.org/abs/2505.04545v1","title":"Column bounded matrices and Grothendieck's inequalities","summary":"It follows from Grothendieck's little inequality that to any complex (m x n)\nmatrix X of column norm at most 1, and an 0 <e <1, there exist a natural number\nq, an (m x q) matrix C with\n  $(1-e)^2 \\leq CC^* \\leq (4/\\pi) (1 + e)^2$\n  and an (q x n ) matrix Z with entries in the complex torus such that X=\nq$^{-(1/2)}$(CZ). Both of Grothendieck's complex inequalities follow from this\nfactorization result.","main_category":"math.FA","categories":"math.FA","published":"2025-05-07T16:27:01Z"}
{"aid":"http://arxiv.org/abs/2505.04563v1","title":"Counting tame $SL_3$- and some $SL_4$- frieze patterns over finite\n  fields","summary":"In this article we count tame $ SL_3 $-frieze patterns over finite fields and\nalso tame $ SL_4 $-frieze patterns in the case that their width $ w $ is even.\nLet $ n = w + k + 1 $. We consider the sets $ C_k(n) $ of tuples of $ n $\npoints in the projective space $ \\mathbb{P}^{k-1}(K) $, such that $ k $\nconsecutive points are always independent (the first and last point in the\ntuple are considered to be consecutive). We prove that the problem of counting\ntame $ SL_k $-frieze patterns can be reduced to counting these sets if $\n\\gcd(k,n) = 1 $. Otherwise, certain subsets $ C_k^*(n) $ need to be considered\ninstead. Afterwards we count $ C_k(n)$ in the cases $ k = 3 $ and $ k = 4 $ and\n$ C_3^*(n) $, leading to our results.","main_category":"math.CO","categories":"math.CO","published":"2025-05-07T16:54:43Z"}
{"aid":"http://arxiv.org/abs/2505.04621v1","title":"Score Distillation Sampling for Audio: Source Separation, Synthesis, and\n  Beyond","summary":"We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.LG,cs.MM,eess.AS","published":"2025-05-07T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2505.04931v1","title":"Fair Uncertainty Quantification for Depression Prediction","summary":"Trustworthy depression prediction based on deep learning, incorporating both\npredictive reliability and algorithmic fairness across diverse demographic\ngroups, is crucial for clinical application. Recently, achieving reliable\ndepression predictions through uncertainty quantification has attracted\nincreasing attention. However, few studies have focused on the fairness of\nuncertainty quantification (UQ) in depression prediction. In this work, we\ninvestigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage\n(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for\ndepression prediction. FUQ pursues reliable and fair depression predictions\nthrough group-based analysis. Specifically, we first group all the participants\nby different sensitive attributes and leverage conformal prediction to quantify\nuncertainty within each demographic group, which provides a theoretically\nguaranteed and valid way to quantify uncertainty for depression prediction and\nfacilitates the investigation of fairness across different demographic groups.\nFurthermore, we propose a fairness-aware optimization strategy that formulates\nfairness as a constrained optimization problem under EOC constraints. This\nenables the model to preserve predictive reliability while adapting to the\nheterogeneous uncertainty levels across demographic groups, thereby achieving\noptimal fairness. Through extensive evaluations on several visual and audio\ndepression datasets, our approach demonstrates its effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-08T04:09:36Z"}
{"aid":"http://arxiv.org/abs/2505.04937v1","title":"Generalization Analysis for Contrastive Representation Learning under\n  Non-IID Settings","summary":"Contrastive Representation Learning (CRL) has achieved impressive success in\nvarious domains in recent years. Nevertheless, the theoretical understanding of\nthe generalization behavior of CRL is limited. Moreover, to the best of our\nknowledge, the current literature only analyzes generalization bounds under the\nassumption that the data tuples used for contrastive learning are independently\nand identically distributed. However, in practice, we are often limited to a\nfixed pool of reusable labeled data points, making it inevitable to recycle\ndata across tuples to create sufficiently large datasets. Therefore, the\ntuple-wise independence condition imposed by previous works is invalidated. In\nthis paper, we provide a generalization analysis for the CRL framework under\nnon-$i.i.d.$ settings that adheres to practice more realistically. Drawing\ninspiration from the literature on U-statistics, we derive generalization\nbounds which indicate the required number of samples in each class scales as\nthe logarithm of the covering number of the class of learnable feature\nrepresentations associated to each class. Next, we apply our main results to\nderive excess risk bounds for common function classes such as linear maps and\nneural networks.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-05-08T04:26:41Z"}
{"aid":"http://arxiv.org/abs/2505.04979v1","title":"Federated Deconfounding and Debiasing Learning for Out-of-Distribution\n  Generalization","summary":"Attribute bias in federated learning (FL) typically leads local models to\noptimize inconsistently due to the learning of non-causal associations,\nresulting degraded performance. Existing methods either use data augmentation\nfor increasing sample diversity or knowledge distillation for learning\ninvariant representations to address this problem. However, they lack a\ncomprehensive analysis of the inference paths, and the interference from\nconfounding factors limits their performance. To address these limitations, we\npropose the \\underline{Fed}erated \\underline{D}econfounding and\n\\underline{D}ebiasing \\underline{L}earning (FedDDL) method. It constructs a\nstructured causal graph to analyze the model inference process, and performs\nbackdoor adjustment to eliminate confounding paths. Specifically, we design an\nintra-client deconfounding learning module for computer vision tasks to\ndecouple background and objects, generating counterfactual samples that\nestablish a connection between the background and any label, which stops the\nmodel from using the background to infer the label. Moreover, we design an\ninter-client debiasing learning module to construct causal prototypes to reduce\nthe proportion of the background in prototype components. Notably, it bridges\nthe gap between heterogeneous representations via causal prototypical\nregularization. Extensive experiments on 2 benchmarking datasets demonstrate\nthat \\methodname{} significantly enhances the model capability to focus on main\nobjects in unseen data, leading to 4.5\\% higher Top-1 Accuracy on average over\n9 state-of-the-art existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T06:32:59Z"}
{"aid":"http://arxiv.org/abs/2505.04995v1","title":"Total cross section of $^{14}$N+$n$ from 0.1 to 12~MeV","summary":"The reaction $^{14}$N$(n,p)^{14}$C is one of the main neutron poisons during\n$s$-process nucleosynthesis. In addition, the reaction provides insight into\nthe yields of atmospheric nuclear weapon testing. Because of their high level\nof sensitivity, total neutron cross sections provide a great deal of constraint\non the modeling of reaction cross sections through the $R$-matrix analyses used\nfor nuclear data evaluations. Yet for $^{14}$N+$n$, only one high sensitivity\nmeasurement is available and it lacks detailed information about its\nexperimental conditions and uncertainties. With these motivations in mind, a\nnew measurement of the $^{14}$N+$n$ total cross section has been performed at\nthe nELBE facility. The cross sections were found to be in good agreement with\nprevious data over much of the energy range with the key exception of the\nlowest energy resonance at a neutron energy of 433 keV.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-05-08T07:00:45Z"}
{"aid":"http://arxiv.org/abs/2505.05003v1","title":"Experiment Study on Reference-Path-Aided System Calibration for mmWave\n  Bistatic ISAC Systems","summary":"Integrated sensing and communications (ISAC) has been regarded as a key\nenabling technology for next-generation wireless networks. Compared to\nmonostatic ISAC, bistatic ISAC can eliminate the critical challenge of\nself-interference cancellation and is well compatible with the existing network\ninfrastructures. However, the synchronization between the transmitter and the\nsensing receiver becomes a crucial problem. The extracted channel state\ninformation (CSI) for sensing under communication synchronization contains\ndifferent types of system errors, such as the sampling time offset (STO),\ncarrier frequency offset (CFO), and random phase shift, which can severely\ndegrade sensing performance or even render sensing infeasible. To address this\nproblem, a reference-path-aided system calibration scheme is designed for\nmmWave bistatic ISAC systems, where the line-of-sight (LoS) path can be\nblocked. By exploiting the delay-angle sparsity feature in mmWave ISAC systems,\nthe reference path, which can be either a LoS or a non-LoS (NLoS) path, is\nfirst identified. By leveraging the fact that all the paths suffer the same\nsystem errors, the channel parameter extracted from the reference path is\nutilized to compensate for the system errors in all other paths. A mmWave ISAC\nsystem is developed to validate our design. Experimental results demonstrate\nthat the proposed scheme can support precise estimation of Doppler shift and\ndelay, maintaining time-synchronization errors within 1 nanosecond.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-08T07:19:08Z"}
{"aid":"http://arxiv.org/abs/2505.05034v1","title":"Dequantified Diffusion SchrÃ¶dinger Bridge for Density Ratio Estimation","summary":"Density ratio estimation is fundamental to tasks involving $f$-divergences,\nyet existing methods often fail under significantly different distributions or\ninadequately overlap supports, suffering from the \\textit{density-chasm} and\nthe \\textit{support-chasm} problems. Additionally, prior approaches yield\ndivergent time scores near boundaries, leading to instability. We propose\n$\\text{D}^3\\text{RE}$, a unified framework for robust and efficient density\nratio estimation. It introduces the Dequantified Diffusion-Bridge Interpolant\n(DDBI), which expands support coverage and stabilizes time scores via diffusion\nbridges and Gaussian dequantization. Building on DDBI, the Dequantified\nSchr\\\"odinger-Bridge Interpolant (DSBI) incorporates optimal transport to solve\nthe Schr\\\"odinger bridge problem, enhancing accuracy and efficiency. Our method\noffers uniform approximation and bounded time scores in theory, and outperforms\nbaselines empirically in mutual information and density estimation tasks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-05-08T08:12:16Z"}
{"aid":"http://arxiv.org/abs/2505.05050v1","title":"'t Hooft line in 4D $U(1)$ lattice gauge theory and a microscopic\n  description of dyon's statistics","summary":"In lattice gauge theory with compact gauge field variables, an introduction\nof the gauge field topology requires the assumption that lattice field\nconfigurations are sufficiently smooth. This assumption is referred to as the\nadmissibility condition. However, the admissibility condition always ensures\nthe Bianchi identity, and thus prohibits the existence of magnetic objects such\nas the 't~Hooft line. Recently, in 2D compact scalar field theory,\nRef.~\\cite{Abe:2023uan} proposed a method to define magnetic objects without\nviolating the admissibility condition by introducing holes into the lattice. In\nthis paper, we extend this ``excision method'' to 4D Maxwell theory and propose\na new definition of the 't~Hooft line on the lattice. Using this definition, we\nfirst demonstrate a lattice counterpart of the Witten effect which endows the\n't~Hooft line with electric charge and make it a dyon. Furthermore, we show\nthat by interpreting the 't~Hooft line as a boundary of the lattice system, the\nstatistics of the dyon can be directly read off. We also explain how the dyonic\noperator which satisfies the Dirac quantization condition becomes a genuine\nloop operator even at finite lattice spacings.","main_category":"hep-lat","categories":"hep-lat","published":"2025-05-08T08:39:57Z"}
{"aid":"http://arxiv.org/abs/2505.05059v1","title":"Enhancing Reinforcement Learning for the Floorplanning of Analog ICs\n  with Beam Search","summary":"The layout of analog ICs requires making complex trade-offs, while addressing\ndevice physics and variability of the circuits. This makes full automation with\nlearning-based solutions hard to achieve. However, reinforcement learning (RL)\nhas recently reached significant results, particularly in solving the\nfloorplanning problem. This paper presents a hybrid method that combines RL\nwith a beam (BS) strategy. The BS algorithm enhances the agent's inference\nprocess, allowing for the generation of flexible floorplans by accomodating\nvarious objective weightings, and addressing congestion without without the\nneed for policy retraining or fine-tuning. Moreover, the RL agent's\ngeneralization ability stays intact, along with its efficient handling of\ncircuit features and constraints. Experimental results show approx. 5-85%\nimprovement in area, dead space and half-perimeter wire length compared to a\nstandard RL application, along with higher rewards for the agent. Moreover,\nperformance and efficiency align closely with those of existing\nstate-of-the-art techniques.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-05-08T08:50:32Z"}
{"aid":"http://arxiv.org/abs/2505.05061v1","title":"Seismic first-arrival traveltime simulation based on\n  reciprocity-constrained PINN","summary":"Simulating seismic first-arrival traveltime plays a crucial role in seismic\ntomography. First-arrival traveltime simulation relies on solving the eikonal\nequation. The accuracy of conventional numerical solvers is limited to a\nfinite-difference approximation. In recent years, physics-informed neural\nnetworks (PINNs) have been applied to achieve this task. However, traditional\nPINNs encounter challenges in accurately solving the eikonal equation,\nespecially in cases where the model exhibits directional scaling differences.\nThese challenges result in substantial traveltime prediction errors when the\ntraveling distance is long. To improve the accuracy of PINN in traveltime\nprediction, we incorporate the reciprocity principle as a constraint into the\nPINN training framework. Based on the reciprocity principle, which states that\nthe traveltime between two points remains invariant when their roles as source\nand receiver are exchanged, we propose to apply this principle to multiple\nsource-receiver pairs in PINN-based traveltime prediction. Furthermore, a\ndynamic weighting mechanism is proposed to balance the contributions of the\neikonal equation loss and the reciprocity-constrained loss during the training\nprocess. This adaptive weighting evolves dynamically with the training epochs,\nenhancing the convergency of the training process. Experiments conducted on a\nsimple lens velocity model, the Overthrust velocity model, and a 3D velocity\nmodel demonstrate that the introduction of the reciprocity-constrained PINN\nsignificantly improves the accuracy of traveltime predictions.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-08T08:54:19Z"}
{"aid":"http://arxiv.org/abs/2505.05065v1","title":"A characterization of nilpotent bicyclic groups","summary":"A group is called $(m,n)$-bicyclic if it can be expressed as a product of two\ncyclic subgroups of orders $m$ and $n$, respectively. The classification and\ncharacterization of finite bicyclic groups have long been important problems in\ngroup theory, with applications extending to symmetric embeddings of the\ncomplete bipartite graphs. A classical result by Douglas establishes that every\nbicyclic group is supersolvable. More recently, Fan and Li (2018) proved that\nevery finite $(m,n)$-bicyclic group is abelian if and only if\n$\\gcd(m,\\phi(n))=\\gcd(n,\\phi(m))=1$, where $\\phi$ is Euler's totient function.\nIn this paper we generalize this result further and show that every\n$(m,n)$-bicyclic group is nilpotent if and only if\n$\\gcd(n,\\phi(\\mathrm{rad}(m)))=\\gcd(m,\\phi(\\mathrm{rad}(n)))=1$, where\n  $\\mathrm{rad}(m)$ denotes the radical of $m$ (the product of its distinct\nprime divisors).","main_category":"math.GR","categories":"math.GR","published":"2025-05-08T08:56:57Z"}
{"aid":"http://arxiv.org/abs/2505.05068v1","title":"Orbital-Selective Quasiparticle Depletion across the Density Wave\n  Transition in Trilayer Nickelate La$_4$Ni$_3$O$_{10}$","summary":"We investigate the evolution of polarized electronic Raman response in\ntrilayer nickelate La$_4$Ni$_3$O$_{10}$, uncovering a systematic reduction of\nthe incoherent electron continuum across the density wave transition in the\n$A_{1g}$ and $B_{1g}$ representations. Analysis based on the Fermi surface band\ncurvatures points to quasiparticle coherence in momentum positions with\ndominant $d_{x^2-y^2}$ orbital character. Our findings establish the symmetry\nchannels and the active role of $d_{x^2-y^2}$ orbitals involved in the density\nwave formation, offering important insight into the electronic and magnetic\ncorrelations in the nickelate.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-05-08T09:05:26Z"}
{"aid":"http://arxiv.org/abs/2505.05078v1","title":"Pairing Real-Time Piano Transcription with Symbol-level Tracking for\n  Precise and Robust Score Following","summary":"Real-time music tracking systems follow a musical performance and at any time\nreport the current position in a corresponding score. Most existing methods\napproach this problem exclusively in the audio domain, typically using online\ntime warping (OLTW) techniques on incoming audio and an audio representation of\nthe score. Audio OLTW techniques have seen incremental improvements both in\nfeatures and model heuristics which reached a performance plateau in the past\nten years. We argue that converting and representing the performance in the\nsymbolic domain -- thereby transforming music tracking into a symbolic task --\ncan be a more effective approach, even when the domain transformation is\nimperfect. Our music tracking system combines two real-time components: one\nhandling audio-to-note transcription and the other a novel symbol-level tracker\nbetween transcribed input and score. We compare the performance of this mixed\naudio-symbolic approach with its equivalent audio-only counterpart, and\ndemonstrate that our method outperforms the latter in terms of both precision,\ni.e., absolute tracking error, and robustness, i.e., tracking success.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-05-08T09:21:23Z"}
{"aid":"http://arxiv.org/abs/2505.05085v1","title":"Learning dynamically inspired invariant subspaces for Koopman and\n  transfer operator approximation","summary":"Transfer and Koopman operator methods offer a framework for representing\ncomplex, nonlinear dynamical systems via linear transformations, enabling for a\ndeeper understanding of the underlying dynamics. The spectrum of these\noperators provide important insights into system predictability and emergent\nbehaviour, although efficiently estimating them from data can be challenging.\nWe tackle this issue through the lens of general operator and representational\nlearning, in which we approximate these linear operators using efficient\nfinite-dimensional representations. Specifically, we machine-learn orthonormal,\nlocally supported basis functions that are dynamically tailored to the system.\nThis learned basis provides a particularly accurate approximation of the\noperator's action as well as a nearly invariant finite-dimensional subspace. We\nillustrate our approach with examples that showcase the retrieval of spectral\nproperties from the estimated operator, and emphasise the dynamically adaptive\nquality of the machine-learned basis.","main_category":"math.DS","categories":"math.DS,cs.LG,cs.NA,math.NA","published":"2025-05-08T09:32:39Z"}
{"aid":"http://arxiv.org/abs/2505.05090v1","title":"Integrating Communication, Sensing, and Security: Progress and Prospects\n  of PLS in ISAC Systems","summary":"The sixth generation of wireless networks defined several key performance\nindicators (KPIs) for assessing its networks, mainly in terms of reliability,\ncoverage, and sensing. In this regard, remarkable attention has been paid\nrecently to the integrated sensing and communication (ISAC) paradigm as an\nenabler for efficiently and jointly performing communication and sensing using\nthe same spectrum and hardware resources. On the other hand, ensuring\ncommunication and data security has been an imperative requirement for wireless\nnetworks throughout their evolution. The physical-layer security (PLS) concept\npaved the way to catering to the security needs in wireless networks in a\nsustainable way while guaranteeing theoretically secure transmissions,\nindependently of the computational capacity of adversaries. Therefore, it is of\nparamount importance to consider a balanced trade-off between communication\nreliability, sensing, and security in future networks, such as the 5G and\nbeyond, and the 6G. In this paper, we provide a comprehensive and system-wise\nreview of designed secure ISAC systems from a PLS point of view. In particular,\nthe impact of various physical-layer techniques, schemes, and wireless\ntechnologies to ensure the sensing-security trade-off is studied from the\nsurveyed work. Furthermore, the amalgamation of PLS and ISAC is analyzed in a\nbroader impact by considering attacks targeting data confidentiality,\ncommunication covertness, and sensing spoofing. The paper also serves as a\ntutorial by presenting several theoretical foundations on ISAC and PLS, which\nrepresent a practical guide for readers to develop novel secure ISAC network\ndesigns.","main_category":"cs.ET","categories":"cs.ET,cs.CR,eess.SP","published":"2025-05-08T09:40:14Z"}
{"aid":"http://arxiv.org/abs/2505.05091v1","title":"DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions","summary":"Deep learning (DL) has surpassed human performance on standard benchmarks,\ndriving its widespread adoption in computer vision tasks. One such task is\ndisparity estimation, estimating the disparity between matching pixels in\nstereo image pairs, which is crucial for safety-critical applications like\nmedical surgeries and autonomous navigation. However, DL-based disparity\nestimation methods are highly susceptible to distribution shifts and\nadversarial attacks, raising concerns about their reliability and\ngeneralization. Despite these concerns, a standardized benchmark for evaluating\nthe robustness of disparity estimation methods remains absent, hindering\nprogress in the field.\n  To address this gap, we introduce DispBench, a comprehensive benchmarking\ntool for systematically assessing the reliability of disparity estimation\nmethods. DispBench evaluates robustness against synthetic image corruptions\nsuch as adversarial attacks and out-of-distribution shifts caused by 2D Common\nCorruptions across multiple datasets and diverse corruption scenarios. We\nconduct the most extensive performance and robustness analysis of disparity\nestimation methods to date, uncovering key correlations between accuracy,\nreliability, and generalization. Open-source code for DispBench:\nhttps://github.com/shashankskagnihotri/benchmarking_robustness/tree/disparity_estimation/final/disparity_estimation","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-08T09:40:17Z"}
{"aid":"http://arxiv.org/abs/2505.05105v1","title":"Multigrid methods for the ghost finite element approximation of elliptic\n  problems","summary":"We present multigrid methods for solving elliptic partial differential\nequations on arbitrary domains using the nodal ghost finite element method, an\nunfitted boundary approach where the domain is implicitly defined by a\nlevel-set function. This method achieves second-order accuracy and offers\nsubstantial computational advantages over both direct solvers and\nfinite-difference-based multigrid methods. A key strength of the ghost finite\nelement framework is its variational formulation, which naturally enables\nconsistent transfer operators and avoids residual splitting across grid levels.\nWe provide a detailed construction of the multigrid components in both one and\ntwo spatial dimensions, including smoothers, transfer operators, and coarse\ngrid operators. The choice of the stabilization parameter plays a crucial role\nin ensuring well-posedness and optimal convergence of the multigrid method. We\nderive explicit algebraic expressions for this parameter based on the geometry\nof cut cells. In the two-dimensional setting, we further improve efficiency by\nperforming additional smoothing exclusively on cut cells, reducing\ncomputational cost without compromising convergence. Numerical results validate\nthe proposed method across a range of geometries and confirm its robustness and\nscalability.","main_category":"math.NA","categories":"math.NA,cs.NA,G.1.8","published":"2025-05-08T10:07:38Z"}
{"aid":"http://arxiv.org/abs/2505.05110v1","title":"p-complete square-free Word-representation of Word-representable Graphs","summary":"A graph $G = (V,E)$ is word-representable, if there exists a word $w$ over\nthe alphabet $V$ such that for letters ${x,y} \\in V$ , $x$ and $y$ alternate in\n$w$ if and only if $xy$ is an edge in the graph $G$. In this paper, we\nintroduce the concept of $p$-complete square-free word-representable graph\n$G(V,E)$. A word $w$ defined over alphabet $V$ is called $p$-complete\nsquare-free word if there does not exist any subset $S\\subseteq \\Sigma$ such\nthat the word $w_{S}$ contains a square $XX$ where $|X| \\ge p$ and $1\\le p \\le\n|w|/2$. A word-representable graph is considered $p$-complete square-free\nword-representable if there exists a $p$-complete square-free word-representant\nof that graph. This pattern is significant as it proves the existence of\npatterns that do not depend on graph labelling and cannot be avoided by certain\nclasses of word-representable graphs. The class of word-representable graphs\nincludes both $p$-complete square-free word-representable graphs and\nnon-$p$-complete square-free word-representable graphs. Additionally, this\nconcept generalises the square pattern found in the words. A word-representable\ngraph is $p$-complete square-free uniform word-representable if its\n$p$-complete square-free word-representant is a uniform word. We analyse the\nproperties of $p$-complete square-free uniform words and find that the graphs\nrepresented by these words avoid having $K_p$ (the complete graph on $p$\nvertices) as an induced subgraph. We provide classifications for small values\nof $p$: for $p=1$, only complete graphs and for $p=2$, only complete and\nedgeless graphs satisfy the condition. We find that $K_3$-free circle graphs\nare 3-complete square-free uniform word-representable. Furthermore, we\nestablish that only graphs with representation number at most 3 can be\n3-complete square-free uniform word-representable and provide a constructive\nmethod to generate such graphs.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-05-08T10:21:12Z"}
{"aid":"http://arxiv.org/abs/2505.05133v1","title":"Probing the Collision Geometry via Two-Photon Processes in Heavy-Ion\n  Collisions","summary":"The initial collision geometry, including the reaction plane, is crucial for\ninterpreting collective phenomena in relativistic heavy-ion collisions, yet it\nremains experimentally inaccessible through conventional measurements. Recent\nstudies propose utilizing photon-induced processes as a direct probe,\nleveraging the complete linear polarization of emitted photons whose\norientation strongly correlates with the collision geometry. In this work, we\nemploy a QED-based approach to systematically investigate dilepton production\nvia two-photon processes in heavy-ion collisions at RHIC and LHC energies and\ndetector acceptances. Our calculations reveal that dilepton emission exhibits\nsignificant sensitivity to the initial collision geometry through both the\nazimuthal angles of their emission (defined by the relative momentum vector of\nthe two leptons) and the overall momentum orientation of the dilepton pairs.\nThese findings highlight the potential of two-photon-generated dileptons as a\nnovel, polarization-driven probe to quantify the initial collision geometry and\nreduce uncertainties in characterizing quark-gluon plasma properties.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-08T11:10:15Z"}
{"aid":"http://arxiv.org/abs/2505.05135v1","title":"Generalized modular equations and arithmetic properties of singular\n  values of Hauptmoduln","summary":"In this paper, we study the CM values of Hauptmoduln whose Fourier\ncoefficients are cyclotomic integers,\n  and prove that these are algebraic integers, analogous to the classical\nsingular moduli of the elliptic modular j-function.\n  The main tool for our proof is generalized modular equations for Hauptmoduln,\nintroduced by Cummins-Gannon.","main_category":"math.NT","categories":"math.NT","published":"2025-05-08T11:13:11Z"}
{"aid":"http://arxiv.org/abs/2505.05140v1","title":"Inverse problem for one-dimensional dynamical Dirac system (BC-method)","summary":"A forward problem for the Dirac system is to find\n$u=\\begin{pmatrix}u_1(x,t)\\\\u_2(x,t)\\end{pmatrix}$ obeying\n$iu_t+\\begin{pmatrix}0&1\\\\-1&0\\end{pmatrix}u_x+\\begin{pmatrix}p&q\\\\q&-p\\end{pmatrix}u=0$\nfor $x>0,\\,t>0$;\\,\\,$u(x,0)=\\begin{pmatrix}0\\\\0\\end{pmatrix}$ for $x\n{\\geqslant} 0 $, and $u_1(0,t)=f(t)$ for $t>0$, with the real $p=p(x), q=q(x)$.\nAn input--output map $R: u_1(0,\\cdot)\\mapsto u_2(0,\\cdot)$ is of the\nconvolution form $Rf=if+r\\ast f$, where $r=r(t)$ is a {\\it response function}.\nBy hyperbolicity of the system, for any $T>0$, function $r\\big|_{0 {\\leqslant}\nt {\\leqslant} 2T}$ is determined by $p,q\\big|_{0 {\\leqslant} x {\\leqslant} T}$.\n  An inverse problem is: for an (arbitrary) fixed $T>0$, given $r\\big|_{0\n{\\leqslant} t {\\leqslant} 2T}$ to recover $p,q\\big|_{0 {\\leqslant} x\n{\\leqslant} T}$. The procedure that determines $p,q$ is proposed, and the\ncharacteristic solvability conditions on $r$ are provided.\n  Our approach is purely time-domain and is based on studying the\ncontrollability properties of the Dirac system. In itself the system is not\ncontrollable: the local completeness of states does not hold, but its relevant\nextension gains controllability. It is the fact, which enables one to apply the\nboundary control method for solving the inverse problem.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-05-08T11:21:47Z"}
{"aid":"http://arxiv.org/abs/2505.05180v1","title":"OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world\n  Prompt Tuning","summary":"Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks\nwith minimal training costs. In this direction, one typical paradigm evaluates\nmodel performance separately on known classes (i.e., base domain) and unseen\nclasses (i.e., new domain). However, real-world scenarios require models to\nhandle inputs without prior domain knowledge. This practical challenge has\nspurred the development of open-world prompt tuning, which demands a unified\nevaluation of two stages: 1) detecting whether an input belongs to the base or\nnew domain (P1), and 2) classifying the sample into its correct class (P2).\nWhat's more, as domain distributions are generally unknown, a proper metric\nshould be insensitive to varying base/new sample ratios (P3). However, we find\nthat current metrics, including HM, overall accuracy, and AUROC, fail to\nsatisfy these three properties simultaneously. To bridge this gap, we propose\nOpenworldAUC, a unified metric that jointly assesses detection and\nclassification through pairwise instance comparisons. To optimize OpenworldAUC\neffectively, we introduce Gated Mixture-of-Prompts (GMoP), which employs\ndomain-specific prompts and a gating mechanism to dynamically balance detection\nand classification. Theoretical guarantees ensure generalization of GMoP under\npractical conditions. Experiments on 15 benchmarks in open-world scenarios show\nGMoP achieves SOTA performance on OpenworldAUC and other metrics. We release\nthe code at https://github.com/huacong/OpenworldAUC","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-08T12:31:40Z"}
{"aid":"http://arxiv.org/abs/2505.05241v1","title":"Insights into Neutron Star Matter: EoS Models and Observations","summary":"The equation of state (EoS) for neutron stars is a crucial topic in\nastrophysics, nuclear physics, and quantum chromodynamics (QCD), influencing\ntheir structure, stability, and observable properties. This review classifies\nEoS models into hadronic matter, hybrid, and quark matter models, analyzing\ntheir assumptions, predictions, and constraints. While hadronic models\ncharacterize nucleonic matter, potentially including contributions from\nhyperons or mesons, hybrid models introduce phase transitions to quark matter,\nand quark models hypothesize the presence of deconfined quark matter cores or\nentirely quark-composed stars. By synthesizing results from recent theoretical\nand observational studies, this review aims to offer a comprehensive\nunderstanding of the methodologies used in constructing neutron star EoS, their\nimplications, and future directions.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE,gr-qc","published":"2025-05-08T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2505.05243v1","title":"Power $Î£_1$ in Card with two Woodin cardinals","summary":"V\\\"a\\\"an\\\"anen and Welch asked in the paper \"When cardinals determine the\npower set: inner models and H\\\"artig quantifier logic\" which large cardinals\nare consistent with the power set operation $x\\mapsto P(x)$ being\n$\\Sigma_1$-definable in the predicate Card of all cardinals. We show that,\nrelative to large cardinals, this property is consistent with the existence of\ntwo Woodin cardinals.","main_category":"math.LO","categories":"math.LO","published":"2025-05-08T13:42:01Z"}
{"aid":"http://arxiv.org/abs/2505.05247v1","title":"Effective ALP-Photon Coupling in External Magnetic Fields","summary":"We present a complete calculation of the one-loop fermionic correction to the\neffective coupling between axion-like particles (ALPs) and photons within a\nconstant, homogeneous magnetic field of arbitrary strength. This interaction,\nresponsible for the Primakoff effect, is central to detecting axion-like\nparticles in astrophysical settings and terrestrial experiments like\nhelioscopes and haloscopes. Accurately predicting the interaction rate requires\naccounting for quantum corrections. Our work tackles this by employing\nmagnetically enhanced fermion propagators derived using Schwinger's proper time\nmethod and a systematic Lorentz decomposition using the Ritus basis. We\nevaluate the triangle loop diagram exactly, avoiding approximations on field\nstrength or particle kinematics.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-05-08T13:46:10Z"}
{"aid":"http://arxiv.org/abs/2505.05249v1","title":"Quantum Surrogate-Driven Image Classifier: A Gradient-Free Approach to\n  Avoid Barren Plateaus","summary":"Training deep quantum neural networks (QNNs) for image classification is\nnotoriously difficult due to vanishing gradients (barren plateaus) and limited\nnonlinearity in purely unitary circuits. We propose a novel gradient-free\nsurrogate-driven framework combined with mid-circuit measurement and reset of\nancillary qubits to induce effective nonunitarity. Our approach uses a\nclassical neural surrogate to predict measurement outcomes from circuit\nparameters to avoid direct gradients. Theoretical results prove that bypassing\nquantum gradients mitigates plateau issues. Experiments on MNIST, CIFAR-10, and\nCIFAR-100 with 15-qubit, 6-layer circuits using four resettable ancillas\ndemonstrate superior accuracy compared to direct-gradient QNNs and classical\nbaselines. Our method also serves as a potential for a generalized training\nframework applicable to various QNN architectures beyond image classification.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-08T13:51:57Z"}
{"aid":"http://arxiv.org/abs/2505.05299v1","title":"Hydrodynamic and Electromagnetic Discrepancies between Neutron Star and\n  Black Hole Spacetimes","summary":"The exterior spacetime geometry surrounding an uncharged, spinning black hole\nin general relativity depends only upon its mass and spin. However, the\nexterior geometry surrounding any other rotating compact object, for example a\nneutron star, will generally depend upon higher moments in its multipole\nexpansion, which will in turn be dependent upon the object's equation of state.\nUsing general relativistic hydrodynamics and electrodynamics simulations, we\nillustrate that the presence or absence of these higher moments (assuming a\nphysically realistic neutron star equation of state) has a significant\nqualitative effect near the surface of the compact object on the dynamics of\nunmagnetized accretion, and a smaller quantitative effect on the\nelectromagnetic field configuration of its magnetosphere. In some places, the\ndiscrepancies in energy-momentum density are found to reach or exceed 50%, with\nelectric field strength discrepancies in excess of 10%. We argue that many of\nthese differences are likely to be amplified by the inclusion of more\nsophisticated plasma physics models, and are therefore likely to be relevant\nfor the dynamics of gravitational collapse, and potentially also for particle\nacceleration and jet launching. These discrepancies suggest important\nlimitations regarding the use of the Kerr metric when performing numerical\nsimulations around neutron stars.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-05-08T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2505.05321v1","title":"Feature-Augmented Deep Networks for Multiscale Building Segmentation in\n  High-Resolution UAV and Satellite Imagery","summary":"Accurate building segmentation from high-resolution RGB imagery remains\nchallenging due to spectral similarity with non-building features, shadows, and\nirregular building geometries. In this study, we present a comprehensive deep\nlearning framework for multiscale building segmentation using RGB aerial and\nsatellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate\na diverse, multi-sensor dataset and introduce feature-augmented inputs by\nderiving secondary representations including Principal Component Analysis\n(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index\n(MBI), and Sobel edge filters from RGB channels. These features guide a\nRes-U-Net architecture in learning complex spatial patterns more effectively.\nWe also propose training policies incorporating layer freezing, cyclical\nlearning rates, and SuperConvergence to reduce training time and resource\nusage. Evaluated on a held-out WorldView-3 image, our model achieves an overall\naccuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of\n0.80, outperforming existing RGB-based benchmarks. This study demonstrates the\neffectiveness of combining multi-resolution imagery, feature augmentation, and\noptimized training strategies for robust building segmentation in remote\nsensing applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-08T15:08:36Z"}
{"aid":"http://arxiv.org/abs/2505.05323v1","title":"Approximation-free Control for Signal Temporal Logic Specifications\n  using Spatiotemporal Tubes","summary":"This paper presents a spatiotemporal tube (STT)-based control framework for\nsatisfying Signal Temporal Logic (STL) specifications in unknown control-affine\nsystems. We formulate STL constraints as a robust optimization problem (ROP)\nand recast it as a scenario optimization program (SOP) to construct STTs with\nformal correctness guarantees. We also propose a closed-form control law that\noperates independently of the system dynamics, and ensures the system\ntrajectory evolves within the STTs, thereby satisfying the STL specifications.\nThe proposed approach is validated through case studies and comparisons with\nstate-of-the-art methods, demonstrating superior computational efficiency,\ntrajectory quality, and applicability to complex STL tasks.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-08T15:08:47Z"}
{"aid":"http://arxiv.org/abs/2505.05333v1","title":"Regularity estimates of fractional heat semigroups related with\n  uniformly elliptic operators","summary":"Let $L = -{\\rm div}( A(x) \\cdot \\nabla ) + V(x)$ be a second-order uniformly\nelliptic operator on $\\mathbb{ R }^{n}$ $(n\\geq 3)$, where $A(x)$ is a real\nsymmetric matrix satisfying standard ellipticity conditions, and $V$ is a\nnonnegative potential belonging to the reverse H\\\"older class. For $ \\alpha \\in\n(0,1) $, we study regularity estimates of the fractional heat semigroups $ \\{\nexp (-tL^ {\\alpha } )\\} _ { t > 0 }$, via the subordination formula and the\nfundamental solution of the associated uniformly parabolic equation $\n\\partial_t u + Lu = 0 $. This approach avoids the use of Fourier transforms and\nis applicable to second-order differential operators whose heat kernels satisfy\nGaussian upper bounds. As an application, we characterize the Campanato-type\nspace $\\Lambda_{ L , \\gamma } \\left( \\mathbb{R}^n \\right)$ via the fractional\nheat semigroups $\\{exp ( - t L ^ {\\alpha } ) \\} _ { t > 0 } $.","main_category":"math.FA","categories":"math.FA","published":"2025-05-08T15:23:45Z"}
{"aid":"http://arxiv.org/abs/2505.05346v1","title":"Analysis of the accuracy of GNSS inferred precipitable water vapour\n  against that from a 210 GHz WVR at the H.E.S.S. site","summary":"The High Energy Stereoscopic System (H.E.S.S.) site and the Gamsberg Mountain\nhave been identified as potential sites for the Africa Millimetre Telescope\n(AMT). The AMT is poised to observe at millimetre and possibly at submillimetre\nwavelengths. At these wavelengths, precipitable water vapour (PWV) in the\natmosphere is the main source of opacity during observations and therefore\nneeds to be accurately assessed at the potential sites for the AMT. In order to\ninvestigate the PWV conditions for the AMT, identical Global Navigation\nSatellite System (GNSS) stations were installed and used to assess the PWV at\nthe two potential sites. In this study, the accuracy of those PWV measurements\nby the GNSS stations was assessed by comparing the H.E.S.S. installed GNSS\nstation PWV measurements to that from a 210 GHz Water Vapour Radiometer (WVR)\nalso installed at the H.E.S.S. site. A correlation of 98% and an offset of 0.34\nmm was found between the GNSS station and the 210 GHz WVR PWV data when on-site\npressure and the Nevada Geodetic Laboratory (NGL) weighted mean temperature\n($\\mathrm{T_m}$) were used calculate the GNSS station PWV data. In comparison,\nthe offset reduces to 0.15 mm when on-site derived $\\mathrm{T_m}$ and pressure\nwere used to calculate the GNSS station PWV. The results show that the GNSS\nstation with on-site meteorological data can be used with high accuracy to\nreliably determine the PWV conditions at the H.E.S.S. site.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ao-ph,physics.data-an","published":"2025-05-08T15:33:24Z"}
{"aid":"http://arxiv.org/abs/2505.05368v1","title":"BMS representations for generic supermomentum","summary":"We revisit the classification, and give explicit realisations, of unitary\nirreducible representations of the BMS group. As compared to McCarthy's seminal\nwork, we make use of a unique, Lorentz-invariant, decomposition of supermomenta\ninto a hard and a soft piece, that we introduce and properly define, to\ninvestigate the extent to which generic representations depart from usual\nPoincar\\'e particles and highlight their relations to gravitational infrared\nphysics. We insist on making wavefunctions as explicit as possible. Similarly,\nwe explain how branching to a Poincar\\'e subgroup works in practice: this is\nphysically relevant because this amounts to reading off the field content of a\ngiven BMS state in terms of a choice of gravity vacuum. In particular, we\nemphasise how different gravity vacua differ in their interpretation of the\nsame BMS state, here again providing concrete examples as well as the general\nprocedure. Finally, we demonstrate on an example that generic BMS particles are\nflexible enough to encode memory, as opposed to usual Poincar\\'e particles.","main_category":"hep-th","categories":"hep-th","published":"2025-05-08T16:05:13Z"}
{"aid":"http://arxiv.org/abs/2505.05369v1","title":"The multi-scale KAM persistence without a scaling order for Hamiltonian\n  systems","summary":"The persistence of invariant tori in multi-scale Hamiltonian systems is\nintrinsically linked to the stability of the N-body problem. However, the\nexisting non-degeneracy conditions in disordered scenarios have been formulated\ntoo generally, making them difficult to apply directly to celestial mechanics.\nIn this work, we present a readily verifiable non-degeneracy condition for the\npersistence of invariant tori in disordered multi-scale Hamiltonian systems.","main_category":"math.DS","categories":"math.DS","published":"2025-05-08T16:05:44Z"}
{"aid":"http://arxiv.org/abs/2505.05386v1","title":"Ballistic-to-diffusive transition in engineered counter-propagating\n  quantum Hall channels","summary":"Exotic quantum Hall systems hosting counter-propagating edge states can show\nseemingly non-universal transport regimes, usually depending on the size of the\nsample. We experimentally probe transport in a quantum Hall sample engineered\nto host a tunable number of counter-propagating edge states. The latter are\ncoupled by Landauer reservoirs, which force charge equilibration over a tunable\neffective length. We show that charge transport is determined by the balance of\nup- and downstream channels, with a ballistic regime emerging for unequal\nnumbers of channels. For equal numbers, we observe a transition to a critical\ndiffusive regime, characterized by a diverging equilibration length. Our\napproach allows simulating the equilibration of hole-conjugate states and other\nexotic quantum Hall effects with fully controlled parameters using\nwell-understood quantum Hall states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-08T16:19:55Z"}
{"aid":"http://arxiv.org/abs/2505.05405v1","title":"Testing an unstable cosmic neutrino background","summary":"I discuss how different cosmological observations can test the possibility\nthat neutrinos might be unstable on cosmological times, resulting into an\nunstable cosmic neutrino background. I also discuss out how actually there are\ndifferent independent anomalies intriguingly hint to such a possibility that\nwould clearly point to new physics. I first focus on how the new DESI results\nplace an upper bound on the sum of neutrino masses that starts to be in tension\nwith the lower bound from neutrino oscillation experiments and how this tension\ncould be easily solved assuming unstable relic neutrinos. Then I show how 21 cm\ncosmology allows to test radiative relic neutrino decays and how these could\nexplain the controversial EDGES anomaly. I also discuss how the excess radio\nbackground and in particular the ARCADE 2 data can also be nicely explained by\nrelic neutrino radiative decays. Finally, I point out the difficulties in\nbuilding a model that does not clash with the upper limits on the effective\nmagnetic moment coming from neutrino-electron scattering experiments and\nglobular cluster stars.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-08T16:46:13Z"}
{"aid":"http://arxiv.org/abs/2505.05432v1","title":"Boundary Energy-Momentum Tensors for Asymptotically Flat Spacetimes","summary":"We consider 3D and 4D asymptotically flat spacetimes near future null\ninfinity endowed with the most general allowed Carroll geometry. We define a\nboundary energy-momentum tensor by varying the on-shell action with respect to\nthe Carroll metric data. This requires adding counterterms to the\nEinstein-Hilbert action. We show that, in 4D, the shear is on par with the\nCarroll metric data. Their combined response defines a boundary\nenergy-momentum-news complex whose diffeomorphism Ward identity is equivalent\nto the Bondi mass and angular momentum loss equations. Weyl invariance leads to\nan identity for the trace of the energy-momentum tensor, and local Carroll\nboosts are anomalous in 3D and in 4D.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-05-08T17:22:02Z"}
{"aid":"http://arxiv.org/abs/2505.05438v1","title":"Scalable Bernoulli factories for Bayesian inference with intractable\n  likelihoods","summary":"Bernoulli factory MCMC algorithms implement accept-reject Markov chains\nwithout explicit computation of acceptance probabilities, and are used to\ntarget posterior distributions associated with intractable likelihood models.\nThese algorithms often mix better than alternatives based on data augmentation\nor acceptance probability estimation. However, we show that their computational\nperformance typically deteriorates exponentially with data size. To address\nthis, we propose a simple divide-and-conquer Bernoulli factory MCMC algorithm\nand prove that it has polynomial complexity of degree between 1 and 2, with the\nexact degree depending on the existence of efficient unbiased estimators of the\nintractable likelihood ratio. We demonstrate the effectiveness of our approach\nwith applications to Bayesian inference in two intractable likelihood models,\nand observe respective polynomial cost of degree 1.2 and 1 in the data size.","main_category":"stat.CO","categories":"stat.CO,62-08,G.3","published":"2025-05-08T17:27:44Z"}
{"aid":"http://arxiv.org/abs/2505.05451v1","title":"The Brownian marble","summary":"Let $R:(0,\\infty) \\to [0,\\infty)$ be a measurable function. Consider a family\nof coalescing Brownian motions started from every point in the subset $\\{ (0,x)\n: x \\in \\mathbb{R} \\}$ of $[0,\\infty) \\times \\mathbb{R}$ and proceeding\naccording to the following rule: the interval $\\{t\\} \\times [L_t,U_t]$ between\ntwo consecutive Brownian motions instantaneously `fragments' at rate $R(U_t -\nL_t)$. At such a fragmentation event at a time $t$, we initiate new coalescing\nBrownian motions from each of the points $\\{ (t,x) : x \\in [L_t,U_t]\\}$. The\nresulting process, which we call the $R$-marble, is easily constructed when $R$\nis bounded, and may be considered a random subset of the Brownian web.\n  Under mild conditions, we show that it is possible to construct the\n$R$-marble when $R$ is unbounded as a limit as $n \\to \\infty$ of $R_n$-marbles\nwhere $R_n(g) = R(g) \\wedge n$. The behaviour of this limiting process is\nmainly determined by the shape of $R$ near zero. The most interesting case\noccurs when the limit $\\lim_{g \\downarrow 0} g^2 R(g) = \\lambda$ exists in\n$(0,\\infty)$, in which we find a phase transition. For $\\lambda \\geq 6$, the\nlimiting object is indistinguishable from the Brownian web, whereas if $\\lambda\n< 6$, then the limiting object is a nontrivial stochastic process with large\ngaps.\n  When $R(g) = \\lambda/g^2$, the $R$-marble is a self-similar stochastic\nprocess which we refer to as the \\emph{Brownian marble} with parameter $\\lambda\n> 0$. We give an explicit description of the space-time correlations of the\nBrownian Marble, which can be described in terms of an object we call the\nBrownian vein; a spatial version of a recurrent extension of a killed\nBessel-$3$ process.","main_category":"math.PR","categories":"math.PR","published":"2025-05-08T17:42:20Z"}
{"aid":"http://arxiv.org/abs/2505.05475v1","title":"SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with\n  Video Diffusion and Data Augmentation","summary":"Creating high-quality animatable 3D human avatars from a single image remains\na significant challenge in computer vision due to the inherent difficulty of\nreconstructing complete 3D information from a single viewpoint. Current\napproaches face a clear limitation: 3D Gaussian Splatting (3DGS) methods\nproduce high-quality results but require multiple views or video sequences,\nwhile video diffusion models can generate animations from single images but\nstruggle with consistency and identity preservation. We present SVAD, a novel\napproach that addresses these limitations by leveraging complementary strengths\nof existing techniques. Our method generates synthetic training data through\nvideo diffusion, enhances it with identity preservation and image restoration\nmodules, and utilizes this refined data to train 3DGS avatars. Comprehensive\nevaluations demonstrate that SVAD outperforms state-of-the-art (SOTA)\nsingle-image methods in maintaining identity consistency and fine details\nacross novel poses and viewpoints, while enabling real-time rendering\ncapabilities. Through our data augmentation pipeline, we overcome the\ndependency on dense monocular or multi-view training data typically required by\ntraditional 3DGS approaches. Extensive quantitative, qualitative comparisons\nshow our method achieves superior performance across multiple metrics against\nbaseline models. By effectively combining the generative power of diffusion\nmodels with both the high-quality results and rendering efficiency of 3DGS, our\nwork establishes a new approach for high-fidelity avatar generation from a\nsingle image input.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T17:59:58Z"}
