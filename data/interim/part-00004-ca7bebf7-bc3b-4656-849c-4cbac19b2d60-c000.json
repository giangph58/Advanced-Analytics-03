{"aid":"http://arxiv.org/abs/2503.21664v1","title":"Functions of bounded variation and Lipschitz algebras in metric measure\n  spaces","summary":"Given a unital algebra $\\mathscr A$ of locally Lipschitz functions defined\nover a metric measure space $({\\mathrm X},{\\mathsf d},\\mathfrak m)$, we study\ntwo associated notions of function of bounded variation and their relations:\nthe space ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$, obtained by\napproximating in energy with elements of $\\mathscr A$, and the space ${\\mathrm\nBV}_{\\mathrm W}({\\mathrm X};\\mathscr A)$, defined through an\nintegration-by-parts formula that involves derivations acting in duality with\n$\\mathscr A$. Our main result provides a sufficient condition on the algebra\n$\\mathscr A$ under which ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$\ncoincides with the standard metric BV space ${\\mathrm BV}_{\\mathrm H}({\\mathrm\nX})$, which corresponds to taking as $\\mathscr A$ the collection of all locally\nLipschitz functions. Our result applies to several cases of interest, for\nexample to Euclidean spaces and Riemannian manifolds equipped with the algebra\nof smooth functions, or to Banach and Wasserstein spaces equipped with the\nalgebra of cylinder functions. Analogous results for metric Sobolev spaces\n${\\mathrm H}^{1,p}$ of exponent $p\\in(1,\\infty)$ were previously obtained by\nseveral different authors.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-03-27T16:32:47Z"}
{"aid":"http://arxiv.org/abs/2503.21686v1","title":"Molecular Quantum Transformer","summary":"The Transformer model, renowned for its powerful attention mechanism, has\nachieved state-of-the-art performance in various artificial intelligence tasks\nbut faces challenges such as high computational cost and memory usage.\nResearchers are exploring quantum computing to enhance the Transformer's\ndesign, though it still shows limited success with classical data. With a\ngrowing focus on leveraging quantum machine learning for quantum data,\nparticularly in quantum chemistry, we propose the Molecular Quantum Transformer\n(MQT) for modeling interactions in molecular quantum systems. By utilizing\nquantum circuits to implement the attention mechanism on the molecular\nconfigurations, MQT can efficiently calculate ground-state energies for all\nconfigurations. Numerical demonstrations show that in calculating ground-state\nenergies for H_2, LiH, BeH_2, and H_4, MQT outperforms the classical\nTransformer, highlighting the promise of quantum effects in Transformer\nstructures. Furthermore, its pretraining capability on diverse molecular data\nfacilitates the efficient learning of new molecules, extending its\napplicability to complex molecular systems with minimal additional effort. Our\nmethod offers an alternative to existing quantum algorithms for estimating\nground-state energies, opening new avenues in quantum chemistry and materials\nscience.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-03-27T16:54:15Z"}
{"aid":"http://arxiv.org/abs/2503.21729v1","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large\n  Reasoning Models with Iterative Retrieval Augmented Generation","summary":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:44:18Z"}
{"aid":"http://arxiv.org/abs/2503.21731v1","title":"Cylindrical Algebraic Decomposition in \\textit{Macaulay2}","summary":"\\texttt{CylindricalAlgebraicDecomposition.m2} is the first implementation of\nCylindrical Algebraic Decomposition (CAD) in \\textit{Macaulay2}. CAD decomposes\nspace into `cells' where input polynomials are sign-invariant. This package\ncomputes an Open CAD (full-dimensional cells only) for sets of real polynomials\nwith rational coefficients, enabling users to solve existential problems\ninvolving strict inequalities. With the construction of a full CAD (cells of\nall dimensions), this tool could be extended to solve any real quantifier\nelimination problem. The current implementation employs the Lazard projection\nand introduces a new heuristic for choosing the variable ordering.","main_category":"cs.SC","categories":"cs.SC,math.AG","published":"2025-03-27T17:46:24Z"}
{"aid":"http://arxiv.org/abs/2503.21761v1","title":"Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single\n  Video","summary":"This paper presents a unified approach to understanding dynamic scenes from\ncasual videos. Large pretrained vision foundation models, such as\nvision-language, video depth prediction, motion tracking, and segmentation\nmodels, offer promising capabilities. However, training a single model for\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\nmulti-stage optimization framework that harnesses multiple pretrained models to\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\npose estimation, and dense 3D motion tracking. Our results show\nstate-of-the-art performance in dynamic 4D modeling with superior visual\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\neffectiveness of repurposing visual foundation models for 4D understanding.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:32Z"}
{"aid":"http://arxiv.org/abs/2503.23713v1","title":"GNN-Based Candidate Node Predictor for Influence Maximization in\n  Temporal Graphs","summary":"In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-03-31T04:28:37Z"}
{"aid":"http://arxiv.org/abs/2503.23752v1","title":"StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and\n  Latent Sequence Diffusion","summary":"In the field of sketch generation, raster-format trained models often produce\nnon-stroke artifacts, while vector-format trained models typically lack a\nholistic understanding of sketches, leading to compromised recognizability.\nMoreover, existing methods struggle to extract common features from similar\nelements (e.g., eyes of animals) appearing at varying positions across\nsketches. To address these challenges, we propose StrokeFusion, a two-stage\nframework for vector sketch generation. It contains a dual-modal sketch feature\nlearning network that maps strokes into a high-quality latent space. This\nnetwork decomposes sketches into normalized strokes and jointly encodes stroke\nsequences with Unsigned Distance Function (UDF) maps, representing sketches as\nsets of stroke feature vectors. Building upon this representation, our\nframework exploits a stroke-level latent diffusion model that simultaneously\nadjusts stroke position, scale, and trajectory during generation. This enables\nhigh-fidelity sketch generation while supporting stroke interpolation editing.\nExtensive experiments on the QuickDraw dataset demonstrate that our framework\noutperforms state-of-the-art techniques, validating its effectiveness in\npreserving structural integrity and semantic features. Code and models will be\nmade publicly available upon publication.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-03-31T06:03:03Z"}
{"aid":"http://arxiv.org/abs/2503.23759v1","title":"Word Break on SLP-Compressed Texts","summary":"Word Break is a prototypical factorization problem in string processing:\nGiven a word $w$ of length $N$ and a dictionary $\\mathcal{D} = \\{d_1, d_2,\n\\ldots, d_{K}\\}$ of $K$ strings, determine whether we can partition $w$ into\nwords from $\\mathcal{D}$. We propose the first algorithm that solves the Word\nBreak problem over the SLP-compressed input text $w$. Specifically, we show\nthat, given the string $w$ represented using an SLP of size $g$, we can solve\nthe Word Break problem in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$ time, where $m\n= \\max_{i=1}^{K} |d_i|$, $M = \\sum_{i=1}^{K} |d_i|$, and $\\omega \\geq 2$ is the\nmatrix multiplication exponent. We obtain our algorithm as a simple corollary\nof a more general result: We show that in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$\ntime, we can index the input text $w$ so that solving the Word Break problem\nfor any of its substrings takes $\\mathcal{O}(m^2 \\log N)$ time (independent of\nthe substring length). Our second contribution is a lower bound: We prove that,\nunless the Combinatorial $k$-Clique Conjecture fails, there is no combinatorial\nalgorithm for Word Break on SLP-compressed strings running in $\\mathcal{O}(g\n\\cdot m^{2-\\epsilon} + M)$ time for any $\\epsilon > 0$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-03-31T06:19:05Z"}
{"aid":"http://arxiv.org/abs/2503.23766v1","title":"Accelerating High-Efficiency Organic Photovoltaic Discovery via\n  Pretrained Graph Neural Networks and Generative Reinforcement Learning","summary":"Organic photovoltaic (OPV) materials offer a promising avenue toward\ncost-effective solar energy utilization. However, optimizing donor-acceptor\n(D-A) combinations to achieve high power conversion efficiency (PCE) remains a\nsignificant challenge. In this work, we propose a framework that integrates\nlarge-scale pretraining of graph neural networks (GNNs) with a GPT-2\n(Generative Pretrained Transformer 2)-based reinforcement learning (RL)\nstrategy to design OPV molecules with potentially high PCE. This approach\nproduces candidate molecules with predicted efficiencies approaching 21\\%,\nalthough further experimental validation is required. Moreover, we conducted a\npreliminary fragment-level analysis to identify structural motifs recognized by\nthe RL model that may contribute to enhanced PCE, thus providing design\nguidelines for the broader research community. To facilitate continued\ndiscovery, we are building the largest open-source OPV dataset to date,\nexpected to include nearly 3,000 donor-acceptor pairs. Finally, we discuss\nplans to collaborate with experimental teams on synthesizing and characterizing\nAI-designed molecules, which will provide new data to refine and improve our\npredictive and generative models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23768v1","title":"Texture or Semantics? Vision-Language Models Get Lost in Font\n  Recognition","summary":"Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic\ncapabilities, achieving impressive performance in various tasks such as image\nrecognition and object localization. However, their effectiveness in\nfine-grained tasks remains an open question. In everyday scenarios, individuals\nencountering design materials, such as magazines, typography tutorials,\nresearch papers, or branding content, may wish to identify aesthetically\npleasing fonts used in the text. Given their multimodal capabilities and free\naccessibility, many VLMs are often considered potential tools for font\nrecognition. This raises a fundamental question: Do VLMs truly possess the\ncapability to recognize fonts? To investigate this, we introduce the Font\nRecognition Benchmark (FRB), a compact and well-structured dataset comprising\n15 commonly used fonts. FRB includes two versions: (i) an easy version, where\n10 sentences are rendered in different fonts, and (ii) a hard version, where\neach text sample consists of the names of the 15 fonts themselves, introducing\na stroop effect that challenges model perception. Through extensive evaluation\nof various VLMs on font recognition tasks, we arrive at the following key\nfindings: (i) Current VLMs exhibit limited font recognition capabilities, with\nmany state-of-the-art models failing to achieve satisfactory performance. (ii)\nFew-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits\nin improving font recognition accuracy across different VLMs. (iii) Attention\nanalysis sheds light on the inherent limitations of VLMs in capturing semantic\nfeatures.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-03-31T06:33:21Z"}
{"aid":"http://arxiv.org/abs/2503.23771v1","title":"XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large\n  Ultra-High-Resolution Remote Sensing Imagery?","summary":"The astonishing breakthrough of multimodal large language models (MLLMs) has\nnecessitated new benchmarks to quantitatively assess their capabilities, reveal\ntheir limitations, and indicate future research directions. However, this is\nchallenging in the context of remote sensing (RS), since the imagery features\nultra-high resolution that incorporates extremely complex semantic\nrelationships. Existing benchmarks usually adopt notably smaller image sizes\nthan real-world RS scenarios, suffer from limited annotation quality, and\nconsider insufficient dimensions of evaluation. To address these issues, we\npresent XLRS-Bench: a comprehensive benchmark for evaluating the perception and\nreasoning capabilities of MLLMs in ultra-high-resolution RS scenarios.\nXLRS-Bench boasts the largest average image size (8500$\\times$8500) observed\nthus far, with all evaluation samples meticulously annotated manually, assisted\nby a novel semi-automatic captioner on ultra-high-resolution RS images. On top\nof the XLRS-Bench, 16 sub-tasks are defined to evaluate MLLMs' 10 kinds of\nperceptual capabilities and 6 kinds of reasoning capabilities, with a primary\nemphasis on advanced cognitive processes that facilitate real-world\ndecision-making and the capture of spatiotemporal changes. The results of both\ngeneral and RS-focused MLLMs on XLRS-Bench indicate that further efforts are\nneeded for real-world RS applications. We have open-sourced XLRS-Bench to\nsupport further research in developing more powerful MLLMs for remote sensing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:41:18Z"}
{"aid":"http://arxiv.org/abs/2503.23773v1","title":"Seasonal bias-correction of daily precipitation over France using a\n  stitch model designed for robust extremes representation","summary":"Highly resoluted and accurate daily precipitation data are required for\nimpact models to perform adequately and to correctly measure high-risk events'\nimpact. In order to produce such data, bias-correction is often needed. Most of\nthose statistical methods correct the probability distributions of daily\nprecipitation by modeling them using either empirical or parametric\ndistributions. A recent semi-parametric model based on a penalized Berk-Jones\n(BJ) statistical test which allows for an automatic and personalized splicing\nof parametric and nonparametric has been developed. This method, called\nStitch-BJ model, was found to be able to model daily precipitation correctly\nand showed interesting potential in a bias-correction setting. In the present\nstudy, we will consolidate these results by taking into account the seasonal\nproperties of daily precipitation in an out-of-sample context, and by\nconsidering dry days probabilities in our methodology. We evaluate the\nperformance of the Stitch-BJ method in this seasonal bias-correction setting\nagainst more classical models such as the Gamma, Exponentiated Weibull (ExpW),\nExtended Generalized Pareto (EGP) or empirical distributions. The Stitch-BJ\ndistribution was able to consistently perform as well or better than all the\nother models over the validation set, including the empirical distribution,\nwhich is often used due to its robustness.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2503.23832v1","title":"An extrapolated and provably convergent algorithm for nonlinear matrix\n  decomposition with the ReLU function","summary":"Nonlinear matrix decomposition (NMD) with the ReLU function, denoted\nReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ and\na factorization rank $r$, identify a rank-$r$ matrix $\\Theta$ such that\n$X\\approx \\max(0,\\Theta)$. This decomposition finds application in data\ncompression, matrix completion with entries missing not at random, and manifold\nlearning. The standard ReLU-NMD model minimizes the least squares error, that\nis, $\\|X - \\max(0,\\Theta)\\|_F^2$. The corresponding optimization problem is\nnondifferentiable and highly nonconvex. This motivated Saul to propose an\nalternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introduced\nand satisfies $\\max(0,Z)=X$ while minimizing $\\|Z - \\Theta\\|_F^2$ (``A\nnonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\nMath. Data Sci., 2022). Our first contribution is to show that the two\nformulations may yield different low-rank solutions $\\Theta$; in particular, we\nshow that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning that\nthere are instances in which the infimum of Latent-ReLU-NMD is not attained\nwhile that of ReLU-NMD is. We also consider another alternative model, called\n3B-ReLU-NMD, which parameterizes $\\Theta=WH$, where $W$ has $r$ columns and $H$\nhas $r$ rows, allowing one to get rid of the rank constraint in\nLatent-ReLU-NMD. Our second contribution is to prove the convergence of a block\ncoordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Our\nthird contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD,\nwhich we prove is also convergent under mild assumptions. We illustrate the\nsignificant acceleration effect of eBCD-NMD compared to BCD-NMD, and also show\nthat eBCD-NMD performs well against the state of the art on synthetic and\nreal-world data sets.","main_category":"cs.LG","categories":"cs.LG,eess.IV,math.OC,stat.ML","published":"2025-03-31T08:27:41Z"}
{"aid":"http://arxiv.org/abs/2503.23856v1","title":"Explodability criteria for the neutrino-driven supernova mechanism","summary":"Massive stars undergoing iron core collapse at the end of their evolution\nterminate their lives either in successful or failed supernovae (SNe). The\nphysics of core collapse supernovae (CCSNe) is complex, and their understanding\nrequires computationally expensive simulations. The sampling of large, densely\nsampled parameter spaces of SN progenitors, as is needed e.g. for population\nsynthesis studies, is thus not feasible. To remedy this situation, we present\ncriteria that allow us to predict the final fates of stars by evaluating\nmultiple explodability proxies derived from the stellar structure at the onset\nof core collapse. These are formulated based on the outcomes of a semi-analytic\nsupernova model, evaluated over a set of ~3,900 heterogeneous stellar\nprogenitors (single stars, binary-stripped and accretor stars). Over these, the\nexplodabiliy criteria achieve an accuracy of >99% agreement with the\nsemi-analytic model. The criteria are tested on 29 state-of-the-art 3D CCSN\nsimulation outcomes from two different groups. Furthermore, we find that all\nexplodability proxies needed for our pre-SN criteria have two distinct peaks\nand intervening valleys as a function of the carbon-oxygen (CO) core mass\n$M_\\mathrm{CO}$, which coincide with failed and successful SNe, respectively.\nThe CO core masses of explodability peaks shift systematically with\nmetallicity, $Z$, and with the timing of hydrogen-rich envelope removal in\nbinary-stripped stars. With these, we identify critical values in\n$M_\\mathrm{CO}$ that define windows over which black holes form by direct\ncollapse. The outcome is a CCSN recipe based on $M_\\mathrm{CO}$ and $Z$,\napplicable for rapid binary population synthesis and other studies. Our\nexplodability formalism is consistent with SN observations that constrain the\nprogenitor $M_\\mathrm{CO}$ and partially addresses the missing red supergiant\nproblem by direct black hole formation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T09:04:10Z"}
{"aid":"http://arxiv.org/abs/2503.23868v1","title":"Modelling Gaia photometry signals of dark halos","summary":"We use the framework of microlensing to show that observations of binary\nsystems, such as those made by {\\it Gaia}, combined with follow-up weak lensing\nmeasurements, can provide a means to probe halos of exotic matter, possibly\nclumped around compact objects such as black holes. This could potentially\ncover a broad range of physical scenarios - from dark matter mini-halos to\nblack holes with bosonic configurations around them, known as hair. Assuming\nthat light can freely propagate through the halo of the exotic matter, the\ncompanion star will produce characteristic, sizable lensing signatures due to\nthe deviation from a central gravitational potential. The signature of the\nmultiple images, the magnification and the light-curve could be the smoking gun\nof such structures. We discuss how the precise observations of the {\\it Gaia}\nsurvey offer an opportunity to search for new, yet undiscovered fundamental\nfields interacting gravitationally with baryons.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-03-31T09:17:48Z"}
{"aid":"http://arxiv.org/abs/2503.23892v1","title":"Surveying Uncertainty Representation: A Unified Model for Cyber-Physical\n  Systems","summary":"Cyber-Physical Systems (CPS) operate in dynamic environments, leading to\ndifferent types of uncertainty. This work provides a comprehensive review of\nuncertainty representations and categorizes them based on the dimensions used\nto represent uncertainty. Through this categorization, key gaps and limitations\nin existing approaches are identified. To address these issues, a Conceptual\nModel of Uncertainty Representations in CPS is introduced, integrating and\nextending existing models. Its applicability is demonstrated through examples\nfrom the automotive domain, showing its effectiveness in capturing and\nstructuring uncertainty in real-world scenarios.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:42:51Z"}
{"aid":"http://arxiv.org/abs/2503.23907v1","title":"HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human\n  Image Aesthetic Assessment","summary":"Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:58:11Z"}
{"aid":"http://arxiv.org/abs/2503.23913v1","title":"Entropy-Based Adaptive Weighting for Self-Training","summary":"The mathematical problem-solving capabilities of large language models have\nbecome a focal point of research, with growing interests in leveraging\nself-generated reasoning paths as a promising way to refine and enhance these\nmodels. These paths capture step-by-step logical processes while requiring only\nthe correct answer for supervision. The self-training method has been shown to\nbe effective in reasoning tasks while eliminating the need for external models\nand manual annotations. However, optimizing the use of self-generated data for\nmodel training remains an open challenge. In this work, we propose\nEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive\nweighting strategy designed to prioritize uncertain data during self-training.\nSpecifically, EAST employs a mapping function with a tunable parameter that\ncontrols the sharpness of the weighting, assigning higher weights to data where\nthe model exhibits greater uncertainty. This approach guides the model to focus\non more informative and challenging examples, thereby enhancing its reasoning\nability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical\nresults show that, while the vanilla method yields virtually no improvement\n(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,\nEAST attains a further 1-2% performance boost compared to the vanilla method.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T10:04:35Z"}
{"aid":"http://arxiv.org/abs/2503.23926v1","title":"Reliable Traffic Monitoring Using Low-Cost Doppler Radar Units","summary":"Road traffic monitoring typically involves the counting and recording of\nvehicles on public roads over extended periods. The data gathered from such\nmonitoring provides useful information to municipal authorities in urban areas.\nThis paper presents a low-cost, widely deployable sensing subsystem based on\nContinuous Wave Doppler radar. The proposed system can perform vehicle\ndetection and speed estimation with a total cost of less than 100 USD. The\nsensing system (including the hardware subsystem and the algorithms) is\ndesigned to be placed on the side of the road, allowing for easy deployment and\nserviceability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T10:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.23927v1","title":"Detecting Localized Density Anomalies in Multivariate Data via Coin-Flip\n  Statistics","summary":"Detecting localized density differences in multivariate data is a crucial\ntask in computational science. Such anomalies can indicate a critical system\nfailure, lead to a groundbreaking scientific discovery, or reveal unexpected\nchanges in data distribution. We introduce EagleEye, an anomaly detection\nmethod to compare two multivariate datasets with the aim of identifying local\ndensity anomalies, namely over- or under-densities affecting only localised\nregions of the feature space. Anomalies are detected by modelling, for each\npoint, the ordered sequence of its neighbours' membership label as a\ncoin-flipping process and monitoring deviations from the expected behaviour of\nsuch process. A unique advantage of our method is its ability to provide an\naccurate, entirely unsupervised estimate of the local signal purity. We\ndemonstrate its effectiveness through experiments on both synthetic and\nreal-world datasets. In synthetic data, EagleEye accurately detects anomalies\nin multiple dimensions even when they affect a tiny fraction of the data. When\napplied to a challenging resonant anomaly detection benchmark task in simulated\nLarge Hadron Collider data, EagleEye successfully identifies particle decay\nevents present in just 0.3% of the dataset. In global temperature data,\nEagleEye uncovers previously unidentified, geographically localised changes in\ntemperature fields that occurred in the most recent years. Thanks to its key\nadvantages of conceptual simplicity, computational efficiency, trivial\nparallelisation, and scalability, EagleEye is widely applicable across many\nfields.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T10:20:04Z"}
{"aid":"http://arxiv.org/abs/2503.23941v1","title":"Choco-Q: Commute Hamiltonian-based QAOA for Constrained Binary\n  Optimization","summary":"Constrained binary optimization aims to find an optimal assignment to\nminimize or maximize the objective meanwhile satisfying the constraints, which\nis a representative NP problem in various domains, including transportation,\nscheduling, and economy. Quantum approximate optimization algorithms (QAOA)\nprovide a promising methodology for solving this problem by exploiting the\nparallelism of quantum entanglement. However, existing QAOA approaches based on\npenalty-term or Hamiltonian simulation fail to thoroughly encode the\nconstraints, leading to extremely low success rate and long searching latency.\n  This paper proposes Choco-Q, a formal and universal framework for constrained\nbinary optimization problems, which comprehensively covers all constraints and\nexhibits high deployability for current quantum devices. The main innovation of\nChoco-Q is to embed the commute Hamiltonian as the driver Hamiltonian,\nresulting in a much more general encoding formulation that can deal with\narbitrary linear constraints. Leveraging the arithmetic features of commute\nHamiltonian, we propose three optimization techniques to squeeze the overall\ncircuit complexity, including Hamiltonian serialization, equivalent\ndecomposition, and variable elimination. The serialization mechanism transforms\nthe original Hamiltonian into smaller ones. Our decomposition methods only take\nlinear time complexity, achieving end-to-end acceleration. Experiments\ndemonstrate that Choco-Q shows more than 235$\\times$ algorithmic improvement in\nsuccessfully finding the optimal solution, and achieves 4.69$\\times$ end-to-end\nacceleration, compared to prior QAOA designs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:47:20Z"}
{"aid":"http://arxiv.org/abs/2503.23970v1","title":"A predator-prey model with Allee effect for a type of predator","summary":"This paper investigates the dynamical behaviors of a Holling type I\nLeslie-Gower predator-prey model where the predator exhibits an Allee effect\nand is subjected to constant harvesting. The model demonstrates three types of\nequilibrium points under different parameter conditions, which could be either\nstable or unstable nodes (foci), saddle nodes, weak centers, or cusps. The\nsystem exhibits a saddle-node bifurcation near the saddle-node point and a Hopf\nbifurcation near the weak center. By calculating the first Lyapunov\ncoefficient, the conditions for the occurrence of both supercritical and\nsubcritical Hopf bifurcations are derived. Finally, it is proven that when the\npredator growth rate and the prey capture coefficient vary within a specific\nsmall neighborhood, the system undergoes a codimension-2 Bogdanov-Takens\nbifurcation near the cusp point.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T11:34:48Z"}
{"aid":"http://arxiv.org/abs/2503.23987v1","title":"Revisiting cyclic elements in growth spaces","summary":"We revisit the problem of characterizing cyclic elements for the shift\noperator in a broad class of radial growth spaces of holomorphic functions on\nthe unit disk, focusing on functions of finite Nevanlinna characteristic. We\nprovide results in the range of Dini regular weights, and in the regime of\nlogarithmic integral divergence. Our proofs are largely constructive, enabling\nus to simplify and extend a classical result by Korenblum and Roberts, and a\nrecent Theorem due to El-Fallah, Kellay, and Seip.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-03-31T11:56:27Z"}
{"aid":"http://arxiv.org/abs/2503.24017v1","title":"Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings\n  for Robust Image Classification","summary":"Crossmodal knowledge distillation (KD) aims to enhance a unimodal student\nusing a multimodal teacher model. In particular, when the teacher's modalities\ninclude the student's, additional complementary information can be exploited to\nimprove knowledge transfer. In supervised image classification, image datasets\ntypically include class labels that represent high-level concepts, suggesting a\nnatural avenue to incorporate textual cues for crossmodal KD. However, these\nlabels rarely capture the deeper semantic structures in real-world visuals and\ncan lead to label leakage if used directly as inputs, ultimately limiting KD\nperformance. To address these issues, we propose a multi-teacher crossmodal KD\nframework that integrates CLIP image embeddings with learnable WordNet-relaxed\ntext embeddings under a hierarchical loss. By avoiding direct use of exact\nclass names and instead using semantically richer WordNet expansions, we\nmitigate label leakage and introduce more diverse textual cues. Experiments\nshow that this strategy significantly boosts student performance, whereas noisy\nor overly precise text embeddings hinder distillation efficiency.\nInterpretability analyses confirm that WordNet-relaxed prompts encourage\nheavier reliance on visual features over textual shortcuts, while still\neffectively incorporating the newly introduced textual cues. Our method\nachieves state-of-the-art or second-best results on six public datasets,\ndemonstrating its effectiveness in advancing crossmodal KD.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T12:41:26Z"}
{"aid":"http://arxiv.org/abs/2503.24022v1","title":"Wasserstein KL-divergence for Gaussian distributions","summary":"We introduce a new version of the KL-divergence for Gaussian distributions\nwhich is based on Wasserstein geometry and referred to as WKL-divergence. We\nshow that this version is consistent with the geometry of the sample space\n${\\Bbb R}^n$. In particular, we can evaluate the WKL-divergence of the Dirac\nmeasures concentrated in two points which turns out to be proportional to the\nsquared distance between these points.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-03-31T12:49:01Z"}
{"aid":"http://arxiv.org/abs/2503.24024v1","title":"Degrees in the $β$- and $β'$-Delaunay graphs","summary":"We investigate the typical cells $\\widehat{Z}$ and $\\widehat{Z}^\\prime$ of\n$\\beta$- and $\\beta'$-Voronoi tessellations in $\\mathbb{R}^d$, establishing a\nComplementary Theorem which entails: 1) a gamma distribution of the\n$\\Phi$-content (a suitable homogeneous functional) of the typical cell with\n$n$-facets; 2) the independence of this $\\Phi$-content with the shape of the\ncell; 3) a practical integral representation of the distribution of\n$Z^{(\\prime)}$. We exploit the latter to derive bounds on the distribution of\nthe facet numbers. Using duality, we get bounds on the typical degree\ndistributions of $\\beta$- and $\\beta'$-Delaunay triangulations. For\n$\\beta'$-Delaunay, the resulting exponential lower bound seems to be the first\nof its kind for random spatial graphs arising as the skeletons of random\ntessellations. For $\\beta$-Delaunay, matching super-exponential bounds allow us\nto show concentration of the maximal degree in a growing window to only a\nfinite number of deterministic values (in particular, only two values for\n$d=2$).","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T12:50:40Z"}
{"aid":"http://arxiv.org/abs/2503.24030v1","title":"Jacquetium, a new, naturally-occurring chemical element","summary":"I report the discovery of jacquetium ($_0$Jq), the first naturally occurring\nelement found since more than 80 years.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.EP","published":"2025-03-31T12:57:10Z"}
{"aid":"http://arxiv.org/abs/2503.24040v1","title":"Adventures in FRET and Specification","summary":"This paper gives an overview of previous work in which the authors used\nNASA's Formal Requirement Elicitation Tool (FRET) to formalise requirements. We\ndiscuss four case studies where we used FRET to capture the system's\nrequirements. These formalised requirements subsequently guided the case study\nspecifications in a combination of formal paradigms. For each case study we\nsummarise insights gained during this process, exploring the expressiveness and\nthe potential interoperability of these approaches. Our experience confirms\nFRET's suitability as a framework for the elicitation and understanding of\nrequirements and for providing traceability from requirements to specification.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:03:34Z"}
{"aid":"http://arxiv.org/abs/2503.24053v1","title":"ReaLM: Reliable and Efficient Large Language Model Inference with\n  Statistical Algorithm-Based Fault Tolerance","summary":"The demand for efficient large language model (LLM) inference has propelled\nthe development of dedicated accelerators. As accelerators are vulnerable to\nhardware faults due to aging, variation, etc, existing accelerator designs\noften reserve a large voltage margin or leverage algorithm-based fault\ntolerance (ABFT) techniques to ensure LLM inference correctness. However,\nprevious methods often overlook the inherent fault tolerance of LLMs, leading\nto high computation and energy overhead. To enable reliable yet efficient LLM\ninference, in this paper, we propose a novel algorithm/circuit co-design\nframework, dubbed ReaLM. For the first time, we systematically characterize the\nfault tolerance of LLMs by performing a large-scale error injection study of\nrepresentative LLMs and natural language understanding tasks. Then, we propose\na statistical ABFT algorithm that fully leverages the error robustness to\nminimize error recovery as much as possible. We also customize the error\ndetection circuits to enable a low-cost online collection of error statistics.\nExtensive experiments show that with only 1.42% circuit area and 1.79% power\noverhead, our ReaLM can reduce perplexity degradation from 18.54 to 0.29.\nCompared to existing methods, ReaLM consistently reduces recovery costs across\ndifferent operating voltages and improves energy efficiency by up to 35.83%\nwithout compromising LLM performance. Our error injection code is available at\nhttps://github.com/2000012835xt/ReaLM-DAC.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T13:15:03Z"}
{"aid":"http://arxiv.org/abs/2503.24059v1","title":"Robust Magnetic Polaron Percolation in the Antiferromagnetic CMR System\n  EuCd$_2$P$_2$","summary":"Antiferromagnetic EuCd$_2$P$_2$ has attracted considerable attention due to\nits unconventional (magneto)transport properties. At a temperature $T_{\\rm\npeak}$ significantly above the magnetic ordering temperature $T_\\textrm{N} =\n11\\,$K a large peak in resistivity is observed which gets strongly suppressed\nin magnetic field, resulting in a colossal magnetoresistance (CMR), for which\nmagnetic fluctuations and the formation of ferromagnetic clusters have been\nproposed as underlying mechanisms. Employing a selection of sensitive probes\nincluding fluctuation spectroscopy and third-harmonic resistance, Hall effect,\nAC susceptibility and $\\mu$SR measurements, allows for a direct comparison of\nelectronic and magnetic properties on multiple time scales. We find compelling\nevidence for the formation and percolation of magnetic polarons, which explains\nthe CMR of the system. Large peaks in the weakly-nonlinear transport and the\nresistance noise power spectral density at zero magnetic field signify an\ninhomogeneous, percolating electronic system below $T^\\ast \\approx\n2\\,T_\\textrm{N}$ with a percolation threshold at $T_{\\rm peak}$. In magnetic\nfields, the onset of large negative MR in the paramagnetic regime occurs at a\nuniversal critical magnetization similar to ferromagnetic CMR materials. The\nsize of the magnetic polarons at the percolation threshold is estimated to\n$\\sim 1 - 2\\,$nm. The mechanism of magntic cluster formation and percolation in\nEuCd$_2$P$_2$ appears to be rather robust despite large variations in carrier\nconcentration and likely is relevant for other Eu-based antiferromagnetic CMR\nsystems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:21:07Z"}
{"aid":"http://arxiv.org/abs/2503.24061v1","title":"Simple general magnification of circuit lower bounds","summary":"We construct so-called distinguishers, sparse matrices that retain some\nproperties of error correcting codes. They provide a technically and\nconceptually simple approach to magnification. We generalize and strengthen\nknown general (not problem specific) magnification results and in particular\nachieve magnification thresholds below known lower bounds. For example, we show\nthat fixed polynomial formula size lower bounds for NP are implied by slightly\nsuperlinear formula size lower bounds for approximating any sufficiently sparse\nproblem in NP. We also show that the thresholds achieved are sharp.\nAdditionally, our approach yields a uniform magnification result for the\nminimum circuit size problem. This seems to sidestep the localization barrier.","main_category":"cs.CC","categories":"cs.CC","published":"2025-03-31T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2503.24067v1","title":"TransMamba: Flexibly Switching between Transformer and Mamba","summary":"Transformers are the cornerstone of modern large language models, but their\nquadratic computational complexity limits efficiency in long-sequence\nprocessing. Recent advancements in Mamba, a state space model (SSM) with linear\ncomplexity, offer promising efficiency gains but suffer from unstable\ncontextual learning and multitask generalization. This paper proposes\nTransMamba, a novel framework that unifies Transformer and Mamba through shared\nparameter matrices (e.g., QKV and CBx), and thus could dynamically switch\nbetween attention and SSM mechanisms at different token lengths and layers. We\ndesign the Memory converter to bridge Transformer and Mamba by converting\nattention outputs into SSM-compatible states, ensuring seamless information\nflow at TransPoints where the transformation happens. The TransPoint scheduling\nis also thoroughly explored for further improvements. We conducted extensive\nexperiments demonstrating that TransMamba achieves superior training efficiency\nand performance compared to baselines, and validated the deeper consistency\nbetween Transformer and Mamba paradigms, offering a scalable solution for\nnext-generation sequence modeling.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2503.24082v1","title":"NUMEXO2: a versatile digitizer for nuclear physics","summary":"NUMEXO2 is a 16 channels 14bit/200MHz digitizer and processing board\ninitially developed for gamma-ray spectroscopy (for EXOGAM: EXOtic nuclei GAMma\nray). Numexo2 has been gradually extended and improved as a general purpose\ndigitizer to fulfill various needs in nuclear physics detection at GANIL. This\nwas possible thanks to reprogrammable components like FPGAs and the\noptimization of different algorithms. The originality of this work compared to\nsimilar systems is that all numerical operations follow the digital data flow\nfrom ADCs, without any storage step of samples. Some details are given on\ndigital processing of the signals, delivered by a large variety of detectors:\nHPGe, silicon strip detector, ionisation chamber, liquid and plastic\nscintillators read-out with photomultipliers, Multi Wire Proportional Counter\nand drift chamber.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-03-31T13:35:46Z"}
{"aid":"http://arxiv.org/abs/2503.24084v1","title":"Environmental effects in stellar mass gravitational wave sources I:\n  Expected fraction of signals with significant dephasing in the dynamical and\n  AGN channels","summary":"We present the first overview of the expected quantity of signals which will\nshowcase significant gravitational wave phase shifts caused by astrophysical\nenvironments, considering the upcoming A+ and A\\# LIGO/Virgo/KAGRA, Cosmic\nExplorer and Einstein Telescope detectors. We construct and analyse two general\nfamilies of dephasing prescriptions with extensions to eccentric sources, as\nwell as collect five specific prescriptions for the fundamental smoking gun\nphysical mechanisms at play in the dynamical and AGN formation channel for\nstellar mass binary black holes: Roemer delays, tidal forces and hydrodynamical\ninteractions. We compute the expected fraction of signals containing\nastrophysical dephasing, as a function of environmental properties and based on\nobserved distributions of binary parameters. We find that next generation\ndetectors can expect to find environmental effects in hundreds of detected\nsignals.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.GA,gr-qc","published":"2025-03-31T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2503.24100v1","title":"Fuzzing-based Mutation Testing of C/C++ CPS","summary":"Mutation testing can help minimize the delivery of faulty software.\nTherefore, it is a recommended practice for developing embedded software in\nsafety-critical cyber-physical systems (CPS). However, state-of-the-art\nmutation testing techniques for C and C++ software, which are common languages\nfor CPS, depend on symbolic execution. Unfortunately, symbolic execution's\nlimitations hinder its applicability (e.g., systems with black-box components).\n  We propose relying on fuzz testing, which has demonstrated its effectiveness\nfor C and C++ software. Fuzz testing tools automatically create test inputs\nthat explore program branches in various ways, exercising statements in\ndifferent program states, and thus enabling the detection of mutants, which is\nour objective.\n  We empirically evaluated our approach using software components from\noperational satellite systems. Our assessment shows that our approach can\ndetect between 40% and 90% of the mutants not detected by developers' test\nsuites. Further, we empirically determined that the best results are obtained\nby integrating the Clang compiler, a memory address sanitizer, and relying on\nlaf-intel instrumentation to collect coverage and guide fuzzing. Our approach\ndetects a significantly higher percentage of live mutants compared to symbolic\nexecution, with an increase of up to 50 percentage points; further, we observed\nthat although the combination of fuzzing and symbolic execution leads to\nadditional mutants being killed, the benefits are minimal (a gain of less than\none percentage point).","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:55:27Z"}
{"aid":"http://arxiv.org/abs/2503.24105v1","title":"Data-Driven Distributed Output Synchronization of Heterogeneous\n  Discrete-Time Multi-Agent Systems","summary":"In this paper, we assume that an autonomous exosystem generates a reference\noutput, and we consider the problem of designing a distributed data-driven\ncontrol law for a family of discrete-time heterogeneous LTI agents, connected\nthrough a directed graph, in order to synchronize the agents' outputs to the\nreference one. The agents of the network are split into two categories:\nleaders, with direct access to the exosystem output, and followers, that only\nreceive information from their neighbors. All agents aim to achieve output\nsynchronization by means of a state feedback that makes use of their own states\nas well as of an estimate of the exogenous system state, provided by an\ninternal state observer. Such observer has a different structure for leaders\nand followers. Necessary and sufficient conditions for the existence of a\nsolution are first derived in the model-based set-up and then in a data-driven\ncontext. An example illustrates both the implementation procedure and the\nperformance of the proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2503.24106v1","title":"Computing and software for LHCb Upgrade II","summary":"A second major upgrade of the LHCb experiment is necessary to allow full\nexploitation of the High Luminosity LHC for flavour physics. The new experiment\nwill operate in Run 5 of the LHC at a luminosity up to $1.5\\times\n10^{34}cm^{-2}s^{-1}$. The experiment will therefore experience extremely high\nparticle fluences and data rates, posing a high challenge not only for the\ndetector but also for the software and computing resources needed to readout,\nreconstruct, select and analyse the data. This document presents these\nchallenges and the ongoing and future R&D programme necessary to address them.\nThis programme will benefit not only the LHCb Upgrade II experiment, but the\nwhole particle physics community as similar challenges will be faced by the\nnext generation of experiments.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-03-31T13:57:27Z"}
{"aid":"http://arxiv.org/abs/2503.24128v1","title":"Perfect circle-valued Morse functions on hyperbolic 6-manifolds","summary":"We build the first example of a hyperbolic 6-manifold that admits a perfect\ncircle-valued Morse function, which can be considered as the analogue of a\nfibration over the circle for manifolds with non-vanishing Euler\ncharacteristic. As a consequence, we obtain a new example of a subgroup of a\nhyperbolic group which is of type $\\mathcal{F}_2$ but not $\\mathcal{F}_3$.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-03-31T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2503.24130v1","title":"Graph Neural Network-Based Predictive Modeling for Robotic Plaster\n  Printing","summary":"This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.","main_category":"cs.CE","categories":"cs.CE,cs.AI,cs.LG,cs.RO","published":"2025-03-31T14:15:00Z"}
{"aid":"http://arxiv.org/abs/2503.24153v1","title":"Convexity of chance constraints for elliptical and skewed distributions\n  with copula structures dependent on decision variables","summary":"Chance constraints describe a set of given random inequalities depending on\nthe decision vector satisfied with a large enough probability. They are widely\nused in decision making under uncertain data in many engineering problems. This\npaper aims to derive the convexity of chance constraints with row dependent\nelliptical and skewed random variables via a copula depending on decision\nvectors. We obtain best thresholds of the $r$-concavity for any real number $r$\nand improve probability thresholds of the eventual convexity. We prove the\neventual convexity with elliptical distributions and a Gumbel-Hougaard copula\ndespite the copula's singularity near the origin. We determine the\n$\\alpha$-decreasing densities of generalized hyperbolic distributions by\nestimating the modified Bessel functions. By applying the $\\alpha$-decreasing\nproperty and a radial decomposition, we achieve the eventual convexity for\nthree types of skewed distributions. Finally, we provide an example to\nillustrate the eventual convexity of a feasible set containing the origin.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T14:38:27Z"}
{"aid":"http://arxiv.org/abs/2503.24161v1","title":"Hypergenerated Carnot groups","summary":"In this paper we provide an algebraic characterization of those stratified\ngroups in which boundaries with locally constant normal are locally flat. We\nshow that these groups, which we call hypergenerated, are exactly the\nstratified groups where embeddings of non-characteristic hypersurfaces are\nlocally bi-Lipschitz. Finally, we extend these results to submanifolds of\narbitrary codimension.","main_category":"math.MG","categories":"math.MG,math.DG,math.GR","published":"2025-03-31T14:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.24165v1","title":"Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer\n  Using Multimodal Machine Learning","summary":"Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T14:47:02Z"}
{"aid":"http://arxiv.org/abs/2503.24183v1","title":"Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees\n  via Constrained Mean-Field Reinforcement Learning","summary":"The rapid expansion of ride-sourcing services such as Uber, Lyft, and Didi\nChuxing has fundamentally reshaped urban transportation by offering flexible,\non-demand mobility via mobile applications. Despite their convenience, these\nplatforms confront significant operational challenges, particularly vehicle\nrebalancing - the strategic repositioning of thousands of vehicles to address\nspatiotemporal mismatches in supply and demand. Inadequate rebalancing results\nin prolonged rider waiting times, inefficient vehicle utilization, and\ninequitable distribution of services, leading to disparities in driver\navailability and income.\n  To tackle these complexities, we introduce scalable continuous-state\nmean-field control (MFC) and reinforcement learning (MFRL) models that\nexplicitly represent each vehicle's precise location and employ continuous\nrepositioning actions guided by the distribution of other vehicles. To ensure\nequitable service distribution, an accessibility constraint is integrated\nwithin our optimal control formulation, balancing operational efficiency with\nequitable access to the service across geographic regions. Our approach\nacknowledges realistic conditions, including inherent stochasticity in\ntransitions, the simultaneous occurrence of vehicle-rider matching, vehicles'\nrebalancing and cruising, and variability in rider behaviors. Crucially, we\nrelax the traditional mean-field assumption of equal supply-demand volume,\nbetter reflecting practical scenarios. Extensive empirical evaluation using\nreal-world data-driven simulation of Shenzhen demonstrates the real-time\nefficiency and robustness of our approach at the scale of tens of thousands of\nvehicles.\n  The code is available at\nhttps://github.com/mjusup1501/mf-vehicle-rebalancing.","main_category":"cs.LG","categories":"cs.LG,cs.MA","published":"2025-03-31T15:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.24191v1","title":"Output Constraints as Attack Surface: Exploiting Structured Generation\n  to Bypass LLM Safety Mechanisms","summary":"Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-03-31T15:08:06Z"}
{"aid":"http://arxiv.org/abs/2503.24199v1","title":"Agent-Based Simulations of Online Political Discussions: A Case Study on\n  Elections in Germany","summary":"User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-03-31T15:17:04Z"}
{"aid":"http://arxiv.org/abs/2503.24213v1","title":"Closing the detection loophole in the triangle network with\n  high-dimensional photonic states","summary":"Bell nonlocality without input settings, e.g. in the triangle network, has\nbeen perceived to be particularly fragile, with low robustness to noise in\nphysical implementations. Here we show to the contrary that nonlocality based\non N00N states already for $N=2$ has an exceptionally high robustness to photon\nloss. For the dominant noise factor, single photon loss in the transmission\nchannels, we can certify noise robustness up to 10\\% loss, while for a\nrealistic noise model we use neural network-based heuristics to observe $\\sim\n50\\%$ robustness. Moreover we show that the robustness holds even for imperfect\nsources based on SPDC sources, where the heralding information of the sources\ncan be used to avoid any global post-processing of the outcomes, such as\ndiscarding rounds when photons fail to arrive, and thus demonstrate how the\ndetection loophole in the triangle network can be closed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:31:34Z"}
{"aid":"http://arxiv.org/abs/2503.24228v1","title":"PAARS: Persona Aligned Agentic Retail Shoppers","summary":"In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.MA","published":"2025-03-31T15:41:51Z"}
{"aid":"http://arxiv.org/abs/2503.24229v1","title":"Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance\n  Segmentation from 3D Synthetic Scenes","summary":"In the recent years, the research community has witnessed growing use of 3D\npoint cloud data for the high applicability in various real-world applications.\nBy means of 3D point cloud, this modality enables to consider the actual size\nand spatial understanding. The applied fields include mechanical control of\nrobots, vehicles, or other real-world systems. Along this line, we would like\nto improve 3D point cloud instance segmentation which has emerged as a\nparticularly promising approach for these applications. However, the creation\nof 3D point cloud datasets entails enormous costs compared to 2D image\ndatasets. To train a model of 3D point cloud instance segmentation, it is\nnecessary not only to assign categories but also to provide detailed\nannotations for each point in the large-scale 3D space. Meanwhile, the increase\nof recent proposals for generative models in 3D domain has spurred proposals\nfor using a generative model to create 3D point cloud data. In this work, we\npropose a pre-training with 3D synthetic data to train a 3D point cloud\ninstance segmentation model based on generative model for 3D scenes represented\nby point cloud data. We directly generate 3D point cloud data with Point-E for\ninserting a generated data into a 3D scene. More recently in 2025, although\nthere are other accurate 3D generation models, even using the Point-E as an\nearly 3D generative model can effectively support the pre-training with 3D\nsynthetic data. In the experimental section, we compare our pre-training method\nwith baseline methods indicated improved performance, demonstrating the\nefficacy of 3D generative models for 3D point cloud instance segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T15:42:10Z"}
{"aid":"http://arxiv.org/abs/2503.24240v1","title":"Analysis of the French system imbalance paving the way for a novel\n  operating reserve sizing approach","summary":"This paper examines the relationship between system imbalance and several\nexplanatory variables within the French electricity system. The factors\nconsidered include lagged imbalance values, observations of renewable energy\nsources (RES) generation and consumption, and forecasts for RES generation and\nconsumption. The study analyzes the distribution of system imbalance in\nrelation to these variables. Additionally, an HGBR machine-learning model is\nemployed to assess the predictability of imbalances and the explanatory power\nof the input variables studied.\n  The results indicate no clear correlation between RES generation or\nconsumption and the observed imbalances. However, it is possible to predict the\nimbalance adequately using forecasts available a few hours before real-time,\nalong with the lagged values of the imbalance. Predicting the imbalance a day\nin advance proves to be complex with the variables examined; however, the\nextreme quantiles of the imbalance used for reserve sizing and contracting can\nbe predicted with sufficient accuracy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T15:53:47Z"}
{"aid":"http://arxiv.org/abs/2503.24285v1","title":"Advanced Quantum Annealing Approach to Vehicle Routing Problems with\n  Time Windows","summary":"In this paper, we explore the potential for quantum annealing to solve\nrealistic routing problems. We focus on two NP-Hard problems, including the\nTraveling Salesman Problem with Time Windows and the Capacitated Vehicle\nRouting Problem with Time Windows. We utilize D-Wave's Quantum Annealer and\nConstrained Quadratic Model (CQM) solver within a hybrid framework to solve\nthese problems. We demonstrate that while the CQM solver effectively minimizes\nroute costs, it struggles to maintain time window feasibility as the problem\nsize increases. To address this limitation, we implement a heuristic method\nthat fixes infeasible solutions through a series of swapping operations.\nTesting on benchmark instances shows our method achieves promising results with\nan average optimality gap of 3.86%.","main_category":"cs.ET","categories":"cs.ET,quant-ph","published":"2025-03-31T16:32:40Z"}
{"aid":"http://arxiv.org/abs/2503.24300v1","title":"Solving the Best Subset Selection Problem via Suboptimal Algorithms","summary":"Best subset selection in linear regression is well known to be nonconvex and\ncomputationally challenging to solve, as the number of possible subsets grows\nrapidly with increasing dimensionality of the problem. As a result, finding the\nglobal optimal solution via an exact optimization method for a problem with\ndimensions of 1000s may take an impractical amount of CPU time. This suggests\nthe importance of finding suboptimal procedures that can provide good\napproximate solutions using much less computational effort than exact methods.\nIn this work, we introduce a new procedure and compare it with other popular\nsuboptimal algorithms to solve the best subset selection problem. Extensive\ncomputational experiments using synthetic and real data have been performed.\nThe results provide insights into the performance of these methods in different\ndata settings. The new procedure is observed to be a competitive suboptimal\nalgorithm for solving the best subset selection problem for high-dimensional\ndata.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T16:43:33Z"}
{"aid":"http://arxiv.org/abs/2503.24308v1","title":"Johnson's contribution to the Discussion of `Statistical aspects of the\n  Covid-19 response' by Wood et al","summary":"This is a response to the paper \"Some statistical aspects of the Covid-19\nresponse\" by Wood et al, submitted to the discussion at the read paper meeting\nof the Royal Statistical Society on 10th April 2025.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T16:54:44Z"}
{"aid":"http://arxiv.org/abs/2503.24312v1","title":"ALMA Band 3 Selection of Ultra-high Redshift Dropouts: The final\n  challenge to ΛCDM","summary":"The Lyman-break technique has been used to successfully identify\nhigh-redshift candidates in broad-band photometric data in the rest-frame\noptical and NIR using the dropout technique. We pioneer the application of this\ntechnique to new wavelength regimes, and search for dropouts in combined ALMA\nand JWST data. We find a candidate that is undetected in NIRCam imaging\nincluding and blueward of the F444W filter, but clearly identified in ALMA band\n3. Assuming this is a Lyman-break candidate, we measure a redshift in the range\n$40 < z < 21\\,380$. This is the highest redshift galaxy candidate discovered to\ndate, and is in significant tension with current and future predictions from\ncosmological simulations, with implications for galaxy evolution in the (very)\nearly Universe.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T16:59:15Z"}
{"aid":"http://arxiv.org/abs/2503.24313v1","title":"1-Tb/s/λ Transmission over Record 10714-km AR-HCF","summary":"We present the first single-channel 1.001-Tb/s DP-36QAM-PCS recirculating\ntransmission over 73 loops of 146.77-km ultra-low-loss & low-IMI DNANF-5 fiber,\nachieving a record transmission distance of 10,714.28 km.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-03-31T17:01:01Z"}
{"aid":"http://arxiv.org/abs/2503.24349v1","title":"Faster Releases, Fewer Risks: A Study on Maven Artifact Vulnerabilities\n  and Lifecycle Management","summary":"In modern software ecosystems, dependency management plays a critical role in\nensuring secure and maintainable applications. However, understanding the\nrelationship between release practices and their impact on vulnerabilities and\nupdate cycles remains a challenge. In this study, we analyze the release\nhistories of 10,000 Maven artifacts, covering over 203,000 releases and 1.7\nmillion dependencies. We evaluate how release speed affects software security\nand lifecycle. Our results show an inverse relationship between release speed\nand dependency outdatedness. Artifacts with more frequent releases maintain\nsignificantly shorter outdated times. We also find that faster release cycles\nare linked to fewer CVEs in dependency chains, indicating a strong negative\ncorrelation. These findings emphasize the importance of accelerated release\nstrategies in reducing security risks and ensuring timely updates. Our research\nprovides valuable insights for software developers, maintainers, and ecosystem\nmanagers.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T17:32:45Z"}
{"aid":"http://arxiv.org/abs/2503.24366v1","title":"StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian\n  Splatting","summary":"3D Gaussian splatting (3DGS) is a popular radiance field method, with many\napplication-specific extensions. Most variants rely on the same core algorithm:\ndepth-sorting of Gaussian splats then rasterizing in primitive order. This\nensures correct alpha compositing, but can cause rendering artifacts due to\nbuilt-in approximations. Moreover, for a fixed representation, sorted rendering\noffers little control over render cost and visual fidelity. For example, and\ncounter-intuitively, rendering a lower-resolution image is not necessarily\nfaster. In this work, we address the above limitations by combining 3D Gaussian\nsplatting with stochastic rasterization. Concretely, we leverage an unbiased\nMonte Carlo estimator of the volume rendering equation. This removes the need\nfor sorting, and allows for accurate 3D blending of overlapping Gaussians. The\nnumber of Monte Carlo samples further imbues 3DGS with a way to trade off\ncomputation time and quality. We implement our method using OpenGL shaders,\nenabling efficient rendering on modern GPU hardware. At a reasonable visual\nquality, our method renders more than four times faster than sorted\nrasterization.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-03-31T17:46:18Z"}
{"aid":"http://arxiv.org/abs/2503.24375v1","title":"Transverse orbital angular momentum: setting the record straight","summary":"The nature of the transverse orbital angular momentum (tOAM) associated with\nspatiotemporal optical vortex (STOV) pulses has been the subject of recent\ndebate. We demonstrate that the approaches to tOAM presented in several recent\npapers are incorrect and lead to unphysical results, including erroneous claims\nof zero total tOAM. We emphasize the importance of calculating the OAM of any\nextended physical object at a common instant of time, and reemphasize the\nspecial status of the centre of energy as a reference point for all OAM\ncalculations. The theory presented in [Phys. Rev. Lett. 127, 193901 (2021)] is\nthe only correct classical field-based framework that both agrees with\nexperiments and provides a self consistent understanding of transverse OAM in\nspatiotemporal light fields.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2503.24384v1","title":"High Energy Emission from the Intrabinary Shocks in Redback Pulsars","summary":"The intrabinary shocks (IBS) of spider pulsars emit non-thermal synchrotron\nX-rays from accelerated electrons and positrons in the shocked pulsar wind,\nlikely energized by magnetic reconnection. In redback spider pulsars, the IBS\ntypically wraps around the sub-stellar companion, leading to a near-normal IBS\nshock with relatively bright X-ray emission. The characteristic energies of\nradiating particles and the magnetic fields in the IBS suggest spectral\nfeatures in the hard X-ray band. Here we perform joint soft-hard X-ray analyses\nof three redback pulsars, J1723-2837, J2215+5135, and J2339-0533, including new\nJ2215 NuSTAR data. We identify a significant cooling break in J1723-2837 and a\nmarginal break in J2215+5135, while placing constraints on the break energy in\nJ2339-0533. Interpreting these as synchrotron cooling features allows us to\nestimate the IBS magnetic field $B_{\\rm IBS} \\sim 40-100$ G and place lower\nbounds on the maximum radiating electron energy. Our results constrain the\nmagnetization of the pulsar wind as well as pair-production in millisecond\npulsar magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.plasm-ph","published":"2025-03-31T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.24389v1","title":"SU-YOLO: Spiking Neural Network for Efficient Underwater Object\n  Detection","summary":"Underwater object detection is critical for oceanic research and industrial\nsafety inspections. However, the complex optical environment and the limited\nresources of underwater equipment pose significant challenges to achieving high\naccuracy and low power consumption. To address these issues, we propose Spiking\nUnderwater YOLO (SU-YOLO), a Spiking Neural Network (SNN) model. Leveraging the\nlightweight and energy-efficient properties of SNNs, SU-YOLO incorporates a\nnovel spike-based underwater image denoising method based solely on integer\naddition, which enhances the quality of feature maps with minimal computational\noverhead. In addition, we introduce Separated Batch Normalization (SeBN), a\ntechnique that normalizes feature maps independently across multiple time steps\nand is optimized for integration with residual structures to capture the\ntemporal dynamics of SNNs more effectively. The redesigned spiking residual\nblocks integrate the Cross Stage Partial Network (CSPNet) with the YOLO\narchitecture to mitigate spike degradation and enhance the model's feature\nextraction capabilities. Experimental results on URPC2019 underwater dataset\ndemonstrate that SU-YOLO achieves mAP of 78.8% with 6.97M parameters and an\nenergy consumption of 2.98 mJ, surpassing mainstream SNN models in both\ndetection accuracy and computational efficiency. These results underscore the\npotential of SNNs for engineering applications. The code is available in\nhttps://github.com/lwxfight/snn-underwater.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-03-31T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.01329v1","title":"Flexible and Explainable Graph Analysis for EEG-based Alzheimer's\n  Disease Classification","summary":"Alzheimer's Disease is a progressive neurological disorder that is one of the\nmost common forms of dementia. It leads to a decline in memory, reasoning\nability, and behavior, especially in older people. The cause of Alzheimer's\nDisease is still under exploration and there is no all-inclusive theory that\ncan explain the pathologies in each individual patient. Nevertheless, early\nintervention has been found to be effective in managing symptoms and slowing\ndown the disease's progression. Recent research has utilized\nelectroencephalography (EEG) data to identify biomarkers that distinguish\nAlzheimer's Disease patients from healthy individuals. Prior studies have used\nvarious machine learning methods, including deep learning and graph neural\nnetworks, to examine electroencephalography-based signals for identifying\nAlzheimer's Disease patients. In our research, we proposed a Flexible and\nExplainable Gated Graph Convolutional Network (GGCN) with Multi-Objective\nTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a\nflexible solution that efficiently identifies the optimal number of GGCN blocks\nto achieve the optimized precision, specificity, and recall outcomes, as well\nas the optimized area under the Receiver Operating Characteristic (AUC). Our\nfindings demonstrated a high efficacy with an over 0.9 Receiver Operating\nCharacteristic score, alongside precision, specificity, and recall scores in\ndistinguishing health control with Alzheimer's Disease patients in Moderate to\nSevere Dementia using the power spectrum density (PSD) of\nelectroencephalography signals across various frequency bands. Moreover, our\nresearch enhanced the interpretability of the embedded adjacency matrices,\nrevealing connectivity differences in frontal and parietal brain regions\nbetween Alzheimer's patients and healthy individuals.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T03:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.01333v1","title":"Reconfigurable Codebook-Based Beamforming for RDARS-Aided mmWave MU-MIMO\n  Systems","summary":"Reconfigurable distributed antenna and reflecting surface (RDARS) is a new\narchitecture for the sixth-generation (6G) millimeter wave (mmWave)\ncommunications. In RDARS-aided mmWave systems, the active and passive\nbeamforming design and working mode configuration for reconfigurable elements\nare crucial for system performance. In this paper, we aim to maximize the\nweighted sum rate (WSR) in the RDARS-aided mmWave system. To take advantage of\nRDARS, we first design a reconfigurable codebook (RCB) in which the number and\ndimension of the codeword can be flexibly adjusted. Then, a low overhead beam\ntraining scheme based on hierarchical search is proposed. Accordingly, the\nactive and passive beamforming for data transmission is designed to achieve the\nmaximum WSR for both space-division multiple access (SDMA) and time-division\nmultiple access (TDMA) schemes. For the TDMA scheme, the optimal number of\nRDARS transmit elements and the allocated power budget for WSR maximization are\nderived in closed form. Besides, the superiority of the RDARS is verified and\nthe conditions under which RDARS outperforms RIS and DAS are given. For the\nSDMA scheme, we characterize the relationship between the number of RDARS\nconnected elements and the user distribution, followed by the derivation of the\noptimal placement positions of the RDARS transmit elements. High-quality\nbeamforming design solutions are derived to minimize the inter-user\ninterference (IUI) at the base station and RDARS side respectively, which\nnearly leads to the maximal WSR. Finally, simulation results confirm our\ntheoretical findings and the superiority of the proposed schemes.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T03:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.01342v1","title":"Foundations and Evaluations in NLP","summary":"This memoir explores two fundamental aspects of Natural Language Processing\n(NLP): the creation of linguistic resources and the evaluation of NLP system\nperformance. Over the past decade, my work has focused on developing a\nmorpheme-based annotation scheme for the Korean language that captures\nlinguistic properties from morphology to semantics. This approach has achieved\nstate-of-the-art results in various NLP tasks, including part-of-speech\ntagging, dependency parsing, and named entity recognition. Additionally, this\nwork provides a comprehensive analysis of segmentation granularity and its\ncritical impact on NLP system performance. In parallel with linguistic resource\ndevelopment, I have proposed a novel evaluation framework, the jp-algorithm,\nwhich introduces an alignment-based method to address challenges in\npreprocessing tasks like tokenization and sentence boundary detection (SBD).\nTraditional evaluation methods assume identical tokenization and sentence\nlengths between gold standards and system outputs, limiting their applicability\nto real-world data. The jp-algorithm overcomes these limitations, enabling\nrobust end-to-end evaluations across a variety of NLP tasks. It enhances\naccuracy and flexibility by incorporating linear-time alignment while\npreserving the complexity of traditional evaluation metrics. This memoir\nprovides key insights into the processing of morphologically rich languages,\nsuch as Korean, while offering a generalizable framework for evaluating diverse\nend-to-end NLP systems. My contributions lay the foundation for future\ndevelopments, with broader implications for multilingual resource development\nand system evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:14:03Z"}
{"aid":"http://arxiv.org/abs/2504.01348v1","title":"Prompt-Guided Attention Head Selection for Focus-Oriented Image\n  Retrieval","summary":"The goal of this paper is to enhance pretrained Vision Transformer (ViT)\nmodels for focus-oriented image retrieval with visual prompting. In real-world\nimage retrieval scenarios, both query and database images often exhibit\ncomplexity, with multiple objects and intricate backgrounds. Users often want\nto retrieve images with specific object, which we define as the Focus-Oriented\nImage Retrieval (FOIR) task. While a standard image encoder can be employed to\nextract image features for similarity matching, it may not perform optimally in\nthe multi-object-based FOIR task. This is because each image is represented by\na single global feature vector. To overcome this, a prompt-based image\nretrieval solution is required. We propose an approach called Prompt-guided\nattention Head Selection (PHS) to leverage the head-wise potential of the\nmulti-head attention mechanism in ViT in a promptable manner. PHS selects\nspecific attention heads by matching their attention maps with user's visual\nprompts, such as a point, box, or segmentation. This empowers the model to\nfocus on specific object of interest while preserving the surrounding visual\ncontext. Notably, PHS does not necessitate model re-training and avoids any\nimage alteration. Experimental results show that PHS substantially improves\nperformance on multiple datasets, offering a practical and training-free\nsolution to enhance model performance in the FOIR task.","main_category":"cs.CV","categories":"cs.CV,cs.IR","published":"2025-04-02T04:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.01349v1","title":"Tasks and Roles in Legal AI: Data Curation, Annotation, and Verification","summary":"The application of AI tools to the legal field feels natural: large legal\ndocument collections could be used with specialized AI to improve workflow\nefficiency for lawyers and ameliorate the \"justice gap\" for underserved\nclients. However, legal documents differ from the web-based text that underlies\nmost AI systems. The challenges of legal AI are both specific to the legal\ndomain, and confounded with the expectation of AI's high performance in\nhigh-stakes settings. We identify three areas of special relevance to\npractitioners: data curation, data annotation, and output verification. First,\nit is difficult to obtain usable legal texts. Legal collections are\ninconsistent, analog, and scattered for reasons technical, economic, and\njurisdictional. AI tools can assist document curation efforts, but the lack of\nexisting data also limits AI performance. Second, legal data annotation\ntypically requires significant expertise to identify complex phenomena such as\nmodes of judicial reasoning or controlling precedents. We describe case studies\nof AI systems that have been developed to improve the efficiency of human\nannotation in legal contexts and identify areas of underperformance. Finally,\nAI-supported work in the law is valuable only if results are verifiable and\ntrustworthy. We describe both the abilities of AI systems to support evaluation\nof their outputs, as well as new approaches to systematic evaluation of\ncomputational systems in complex domains. We call on both legal and AI\npractitioners to collaborate across disciplines and to release open access\nmaterials to support the development of novel, high-performing, and reliable AI\ntools for legal applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.01364v1","title":"Maximizing the number of stars in graphs with forbidden properties","summary":"Erd\\H{o}s proved an upper bound on the number of edges in an $n$-vertex\nnon-Hamiltonian graph with given minimum degree and showed sharpness via two\nmembers of a particular graph family. F\\\"{u}redi, Kostochka and Luo showed that\nthese two graphs play the same role when ``number of edges'' is replaced by\n``number of t-stars,'' and that two members of a more general graph family\nmaximize the number of edges among non-$k$-edge-Hamiltonian graphs. In this\npaper we generalize their former result from Hamiltonicity to related\nproperties (traceability, Hamiltonian-connectedness, $k$-edge Hamiltonicity,\n$k$-Hamiltonicity) and their latter result from edges to $t$-stars. We identify\na family of extremal graphs for each property that is forbidden. This problem\nwithout the minimum degree condition was also open; here we conjecture a\ncomplete description of the extremal family for each property, and prove the\ncharacterization in some cases. Finally, using a different family of extremal\ngraphs, we find the maximum number of $t$-stars in non-$k$-connected graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T05:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.01371v1","title":"A simple schematic model for a cross section deficit in\n  $^{12}$C+$^{12}$C fusion reactions","summary":"A cross section deficit phenomenon has been observed in $^{12}$C+$^{12}$C\nfusion reactions at astrophysical energies, at which fusion cross sections are\nsuppressed in the off-resonance regions as compared to fusion cross sections\nfor the $^{12}$C+$^{13}$C system. I here construct a simple schematic model\nwhich simulates this phenomenon. The model consists of a random matrix\nHamiltonian based on the Gaussian Orthogonal Ensemble (GOE), which is coupled\nto an entrance channel Hamiltonian in the discrete basis representation. I show\nthat the transmission coefficients are almost unity when both the level density\nand the decay widths of the GOE configurations are large, realizing the strong\nabsorption regime. On the other hand, when these parameters are small, the\ntransmission coefficients are significantly structured as a function of energy.\nIn that situation, the transmission coefficients at resonance energies reach\nunity in this model, that is consistent with the experimental finding of the\ncross section deficit.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-02T05:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.01385v1","title":"Dynamics of ring solitons in an expanding cloud of a Bose-Einstein\n  condensate","summary":"In this paper, we derive equations for the dynamics of ring dark solitons in\nan expanding cloud of a two-dimensional Bose-Einstein condensate. Assuming that\nthe soliton's width is much smaller than its radius, we obtain the Hamilton\nequations for its evolution. Then they are transformed into the Newton\nequation, which is more convenient for applications. The general theory is\nillustrated by the solution of the Newton equation for the case of the axially\nsymmetric condensate cloud, which expands after switching off a harmonic trap.\nThe validity of our approximate analytical approach is confirmed by comparison\nwith the results of numerical simulations of the Gross-Pitaevskii equation.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-02T05:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.01400v1","title":"ToolACE-R: Tool Learning with Adaptive Self-Refinement","summary":"Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-02T06:38:56Z"}
{"aid":"http://arxiv.org/abs/2504.01402v1","title":"A Survey on Physics-based Differentiable Rendering","summary":"Physics-based differentiable rendering has emerged as a powerful technique in\ncomputer graphics and vision, with a broad range of applications in solving\ninverse rendering tasks. At its core, differentiable rendering enables the\ncomputation of gradients with respect to scene parameters, allowing\noptimization-based approaches to solve various problems. Over the past few\nyears, significant advancements have been made in both the underlying theory\nand the practical implementations of differentiable rendering algorithms. In\nthis report, we provide a comprehensive overview of the current state of the\nart in physics-based differentiable rendering, focusing on recent advances in\ngeneral differentiable rendering theory, Monte Carlo sampling strategy, and\ncomputational efficiency.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-02T06:39:50Z"}
{"aid":"http://arxiv.org/abs/2504.01417v1","title":"Hook fusion procedure for direct product of symmetric groups","summary":"In this work, we derive a new expression for the diagonal matrix elements of\nirreducible representations of the direct product group $S_r\\times S_s$ using\nGrime's hook fusion procedure for symmetric groups, which simplifies the fusion\nprocedure by reducing the number of auxiliary parameters needed. By extending\nthis approach to the product group setting, we provide a method for\nconstructing a complete set of orthogonal primitive idempotents.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T07:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.01423v1","title":"Dynamic Incentive Strategies for Smart EV Charging Stations: An\n  LLM-Driven User Digital Twin Approach","summary":"This paper presents an enhanced electric vehicle demand response system based\non large language models, aimed at optimizing the application of\nvehicle-to-grid technology. By leveraging an large language models-driven\nmulti-agent framework to construct user digital twins integrated with\nmultidimensional user profile features, it enables deep simulation and precise\nprediction of users' charging and discharging decision-making patterns.\nAdditionally, a data- and knowledge-driven dynamic incentive mechanism is\nproposed, combining a distributed optimization model under network constraints\nto optimize the grid-user interaction while ensuring both economic viability\nand security. Simulation results demonstrate that the approach significantly\nimproves load peak-valley regulation and charging/discharging strategies.\nExperimental validation highlights the system's substantial advantages in load\nbalancing, user satisfaction and grid stability, providing decision-makers with\na scalable V2G management tool that promotes the sustainable, synergistic\ndevelopment of vehicle-grid integration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T07:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.01434v1","title":"Contribution of ALEGRO to the Update of the European Strategy on\n  Particle Physics","summary":"Advanced and novel accelerators (ANAs), driven a by laser pulse or a\nrelativistic particle bunch, have made remarkable progress over the last\ndecades. They accelerated electrons by 10GeV in 30cm (laser driven) and by\n42GeV in 85cm (particle bunch driven). Rapid progress continues with lasers,\nplasma sources, computational methods, and more. In this document we highlight\nthe main contributions made by the various major collaborations, facilities,\nand experiments that develop ANAs for applications to particle and high-energy\nphysics. These include: ALiVE, ANL-AWA, AWAKE, BNL-ATF, CEPC Injector,\nDESY-KALDERA, ELI ERIC, EuPRAXIA, HALHF, LBNL-BELLA, LBNL-kBELLA, LCvison,\nPETRA IV Injector, 10TeV Collider design, SLAC-FACET II, as well as the\ndevelopment of structures, lasers and plasma sources, and sustainability, and\ndemonstrate the intense activities in the field. ANAs can have, and already\nhave, applications to particle and high-energy physics as subsystems, the\nso-called intermediate applications: injectors, lower energy experiments, beam\ndump experiments, test beds for detectors, etc. Additionally, an ANA could be\nan upgrade for any Higgs factory based on a linear accelerator, as proposed in\nthe LCvison project. ANAs have advantages over other concepts for reaching\nmulti-TeV energies: lower geographical and environmental footprints, higher\nluminosity to power ratio, and are thus more sustainable than other\naccelerators. However, ANAs must still meet a number of challenges before they\ncan produce bunches with parameters and the luminosity required for a linear\ncollider at the energy frontier. It is therefore extremely important to\nstrongly support vigorous R&D of ANAs, because they are, at this time, the most\nsustainable acceleration scheme to reach very high energies with a linear\naccelerator.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-02T07:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.01460v1","title":"K2: On Optimizing Distributed Transactions in a Multi-region Data Store\n  with TrueTime Clocks (Extended Version)","summary":"TrueTime clocks (TTCs) that offer accurate and reliable time within limited\nuncertainty bounds have been increasingly implemented in many clouds.\nMulti-region data stores that seek decentralized synchronization for high\nperformance represent an ideal application of TTC. However, the co-designs\nbetween the two were often undervalued or failed to realize their full\npotential.\n  This paper proposes K2, a multi-region data store that intensely explores the\nopportunity of using TTC for distributed transactions. Compared to its pioneer,\nGoogle Spanner, K2 augments TTC's semantics in three core design pillars.\nFirst, K2 carries a new timestamp-generating scheme that is capable of\nproviding a small time uncertainty bound at scale. Second, K2 revitalizes\nexisting multi-version timestamp-ordered concurrency control to realize\nmulti-version properties for read-write transactions. Third, K2 introduces a\nnew TTC-based visibility control protocol that provides efficient reads at\nreplicas. Our evaluation shows that, K2 achieves an order of magnitude higher\ntransaction throughput relative to other practical geo-distributed transaction\nprotocols while ensuring a lower visibility delay at asynchronous replicas.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.01471v1","title":"On the mean-field limit for the Vlasov-Poisson system","summary":"We present a probabilistic proof of the mean-field limit and propagation of\nchaos of a classical N-particle system in three dimensions with Coulomb\ninteraction force of the form $f^N(q)=\\pm\\frac{q}{|q|^3}$ and $N$-dependent\ncut-off at $|q|>N^{-\\frac{5}{12}+\\sigma}$ where $\\sigma>0$ can be chosen\narbitrarily small. This cut-off size is much smaller than the typical distance\nto the nearest neighbour. In particular, for typical initial data, we show\nconvergence of the Newtonian trajectories to the characteristics of the\nVlasov-Poisson system. The proof is based on a Gronwall estimate for the\nmaximal distance between the exact microscopic dynamics and the approximate\nmean-field dynamics. Thus our result leads to a derivation of the\nVlasov-Poisson equation from the microscopic $N$-particle dynamics with force\nterm arbitrary close to the physically relevant Coulomb force.","main_category":"math-ph","categories":"math-ph,math.DS,math.MP,physics.class-ph,G.3","published":"2025-04-02T08:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.01501v1","title":"Vertex-Based Localization of Erdős-Gallai Theorems for Paths and\n  Cycles","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-02T08:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.01513v1","title":"Laser Annealing of Transparent ZnO Thin Films: A Route to Improve\n  Electrical Conductivity and Oxygen Sensing Capabilities","summary":"The chemical deposition of high-performance Zinc Oxide (ZnO) thin films is\nchallenging, thus significant efforts have been devoted during the past decades\nto develop cost-effective, scalable fabrication methods in gas phase. This work\ndemonstrates how ultra-short-pulse Laser Beam Scanning (LBS) can be used to\nmodulate electrical conductivity in ZnO thin films deposited on soda-lime glass\nby Spatial Atomic Layer Deposition (SALD), a high-throughput, low-temperature\ndeposition technique suitable for large-area applications. By systematically\noptimizing laser parameters, including pulse energy and hatching distance,\nsignificant improvements in the electrical performance of 90 nm-thick ZnO films\nwere achieved. The optimization of the laser annealing parameters, 0.21\nuJ/pulse energy and a 1 micron hatching distance, yielded ZnO films with an\nelectrical resistivity of (9 +- 2) 10-2 Ohm cm, 3 orders of magnitude lower\nthan as deposited films. This result suggests that laser\npost-deposition-processing can play an important role in tailoring the\nproperties of ZnO thin films. Excessive laser intensity can compromise\nstructural integrity of the films, however, degrading their electrical\ntransport properties. Notably, the electrical resistance of laser-annealed ZnO\nfilms exhibited high sensitivity to oxygen concentration in the surrounding\natmosphere, suggesting exciting prospects for application in devices based on\ntransparent oxygen sensors. This study thus positions ultra-short pulsed laser\nannealing as a versatile post-deposition method for fine-tuning the properties\nof ZnO thin films, enabling their use in advanced optoelectronic and\ngas-sensing technologies, particularly on temperature-sensitive substrates.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T09:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01515v1","title":"Training-free Dense-Aligned Diffusion Guidance for Modular Conditional\n  Image Synthesis","summary":"Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T09:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.01523v1","title":"Adapting Knowledge Prompt Tuning for Enhanced Automated Program Repair","summary":"Automated Program Repair (APR) aims to enhance software reliability by\nautomatically generating bug-fixing patches. Recent work has improved the\nstate-of-the-art of APR by fine-tuning pre-trained large language models\n(LLMs), such as CodeT5, for APR. However, the effectiveness of fine-tuning\nbecomes weakened in data scarcity scenarios, and data scarcity can be a common\nissue in practice, limiting fine-tuning performance. To alleviate this\nlimitation, this paper adapts prompt tuning for enhanced APR and conducts a\ncomprehensive study to evaluate its effectiveness in data scarcity scenarios,\nusing three LLMs of different sizes and six diverse datasets across four\nprogramming languages. Prompt tuning rewrites the input to a model by adding\nextra prompt tokens and tunes both the model and the prompts on a small\ndataset. These tokens provide task-specific knowledge that can improve the\nmodel for APR, which is especially critical in data scarcity scenarios.\nMoreover, domain knowledge has proven crucial in many code intelligence tasks,\nbut existing studies fail to leverage domain knowledge during the prompt tuning\nfor APR. To close this gap, we introduce knowledge prompt tuning, an approach\nthat adapts prompt tuning with six distinct types of code- or bug-related\ndomain knowledge for APR. Our work, to the best of our knowledge, is the first\nto adapt and evaluate prompt tuning and the effectiveness of code- or\nbug-related domain knowledge for APR, particularly under data scarcity\nsettings. Our evaluation results demonstrate that prompt tuning with knowledge\ngenerally outperforms fine-tuning under various experimental settings,\nachieving an average improvement of 87.33% over fine-tuning in data scarcity\nscenarios.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.01525v1","title":"Rapid Muon Tomography for Border Security","summary":"Cosmic-ray muon tomography is a promising technique for border security\napplications, leveraging highly penetrating cosmic-ray muons and their\ninteractions with various materials to generate 3D images of large and dense\nobjects, such as shipping containers. Using scattering and absorption of muons\nas they pass through dense cargo materials, muon tomography provides a viable\nsolution for customs and border security by enabling the verification of\nshipping container declarations and preventing illegal trafficking. In this\nstudy, we utilized Monte Carlo simulations to evaluate the effectiveness of\nmuon tomography for cargo characterization and contraband detection in various\nsmuggling scenarios. Our results demonstrate that muon tomography can offers a\nnovel approach to cargo inspection, moving beyond traditional 3D image\nreconstruction. Instead, it analyzes muon scattering and absorption rates in\nreal time during scanning, enabling the prompt detection of discrepancies\nbetween actual cargo contents and declared goods within just 10 to 20 seconds.\nThis method is particularly effective for cargo consisting of uniform loads\ncomposed of a single material or product, a common practice in shipping. Unlike\ntraditional X-ray radiography, which analyzes detailed 2D images, muon\ntomography begins evaluating scatter-absorption rates within the first few\nseconds of scanning. This early assessment enables cargo evaluation long before\na statistically reliable 3D image is formed, significantly improving scanning\nthroughput without disrupting trade flow.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-02T09:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.01533v1","title":"LightDefense: A Lightweight Uncertainty-Driven Defense against\n  Jailbreaks via Shifted Token Distribution","summary":"Large Language Models (LLMs) face threats from jailbreak prompts. Existing\nmethods for defending against jailbreak attacks are primarily based on\nauxiliary models. These strategies, however, often require extensive data\ncollection or training. We propose LightDefense, a lightweight defense\nmechanism targeted at white-box models, which utilizes a safety-oriented\ndirection to adjust the probabilities of tokens in the vocabulary, making\nsafety disclaimers appear among the top tokens after sorting tokens by\nprobability in descending order. We further innovatively leverage LLM's\nuncertainty about prompts to measure their harmfulness and adaptively adjust\ndefense strength, effectively balancing safety and helpfulness. The\neffectiveness of LightDefense in defending against 5 attack methods across 2\ntarget LLMs, without compromising helpfulness to benign user queries,\nhighlights its potential as a novel and lightweight defense mechanism,\nenhancing security of LLMs.","main_category":"cs.CR","categories":"cs.CR,cs.CY","published":"2025-04-02T09:21:26Z"}
{"aid":"http://arxiv.org/abs/2504.01550v1","title":"Representation Bending for Large Language Model Safety","summary":"Large Language Models (LLMs) have emerged as powerful tools, but their\ninherent safety risks - ranging from harmful content generation to broader\nsocietal harms - pose significant challenges. These risks can be amplified by\nthe recent adversarial attacks, fine-tuning vulnerabilities, and the increasing\ndeployment of LLMs in high-stakes environments. Existing safety-enhancing\ntechniques, such as fine-tuning with human feedback or adversarial training,\nare still vulnerable as they address specific threats and often fail to\ngeneralize across unseen attacks, or require manual system-level defenses. This\npaper introduces RepBend, a novel approach that fundamentally disrupts the\nrepresentations underlying harmful behaviors in LLMs, offering a scalable\nsolution to enhance (potentially inherent) safety. RepBend brings the idea of\nactivation steering - simple vector arithmetic for steering model's behavior\nduring inference - to loss-based fine-tuning. Through extensive evaluation,\nRepBend achieves state-of-the-art performance, outperforming prior methods such\nas Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success\nrates across diverse jailbreak benchmarks, all with negligible reduction in\nmodel usability and general capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CR","published":"2025-04-02T09:47:01Z"}
{"aid":"http://arxiv.org/abs/2504.01565v1","title":"Learning and criticality in a self-organizing model of connectome growth","summary":"The exploration of brain networks has reached an important milestone as\nrelatively large and reliable information has been gathered for connectomes of\ndifferent species. Analyses of connectome data sets reveal that the structural\nlength and the distributions of in- and out-node strengths follow heavy-tailed\nlognormal statistics, while the functional network properties exhibit powerlaw\ntails, suggesting that the brain operates close to a critical point where\ncomputational capabilities and sensitivity to stimulus is optimal. Because\nthese universal network features emerge from bottom-up (self-)organization, one\ncan pose the question of whether they can be modeled via a common framework,\nparticularly through the lens of criticality of statistical physical systems.\nHere, we simultaneously reproduce the powerlaw statistics of connectome edge\nweights and the lognormal distributions of node strengths from an\navalanche-type model with learning that operates on baseline networks that\nmimic the neuronal circuitry. We observe that the avalanches created by a\nsandpile-like model on simulated neurons connected by a hierarchical modular\nnetwork (HMN) produce robust powerlaw avalanche size distributions with\ncritical exponents of 3/2 characteristic of neuronal systems. Introducing\nHebbian learning, wherein neurons that `fire together, wire together,' recovers\nthe powerlaw distribution of edge weights and the lognormal distributions of\nnode degrees, comparable to those obtained from connectome data. Our results\nstrengthen the notion of a critical brain, one whose local interactions drive\nconnectivity and learning without a need for external intervention and precise\ntuning.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-02T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.01576v1","title":"Strong Nonlinear Flexoelectricity in Bulk Ferroelectrics","summary":"Flexoelectricity induced by strain gradient in dielectrics is highly\ndesirable for electromechanical actuating and sensing systems. It is broadly\nadopted that flexoelectric polarization responds linearly to strain gradient\nwithout considering nonlinearity. Consequently, the implication of nonlinear\nflexoelectricity in electromechanical systems remains unclear. Herein, we\nestablish a nonlinear constitutive model for flexoelectricity and thereby\npropose a strategy for quantitatively measuring its nonlinearity through the\nhigh-order harmonic generations. A strong nonlinear flexoelectricity in bulk\nferroelectrics is revealed and its coefficient is determined, as evidenced by\ntheir nonlinear dependence of harmonics on strain gradient. On this basis, we\nillustrate the nonlinear flexoelectricity manifests a functionality to\ntransduce mixed mechanical excitations into coherent electrical signals\nfeaturing difference- and sum-frequencies, thereby offering utilization in\nsignal processing for frequency conversion. These findings emphasize the\nsignificance of nonlinear flexoelectricity in ferroelectrics and open up new\nopportunities for designing electromechanical transducer based on nonlinear\nflexoelectricity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.01579v1","title":"Conditions for Unitarity in Timeless Quantum Theory","summary":"Quantum timeless approaches solve the problem of time by recovering the usual\nunitary evolution of quantum theory relative to a clock in a stationary quantum\nUniverse. For some Hamiltonians of the Universe, such as those including an\ninteraction term with the clock, the dynamics is substantially altered and can\nbe non-unitary. This work derives necessary and sufficient conditions for the\nrelative dynamics to be unitary and finds the general form of the unitary\nevolution operator. A physical interpretation of these conditions is given in\nterms of the clock's rate. Unitary dynamics is associated with rates that are\nconstant in time and independent of the clock's internal structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.01582v1","title":"MERE: Hardware-Software Co-Design for Masking Cache Miss Latency in\n  Embedded Processors","summary":"Runahead execution is a technique to mask memory latency caused by irregular\nmemory accesses. By pre-executing the application code during occurrences of\nlong-latency operations and prefetching anticipated cache-missed data into the\ncache hierarchy, runahead effectively masks memory latency for subsequent cache\nmisses and achieves high prefetching accuracy; however, this technique has been\nlimited to superscalar out-of-order and superscalar in-order cores. For\nimplementation in scalar in-order cores, the challenges of\narea-/energy-constraint and severe cache contention remain.\n  Here, we build the first full-stack system featuring runahead, MERE, from SoC\nand a dedicated ISA to the OS and programming model. Through this deployment,\nwe show that enabling runahead in scalar in-order cores is possible, with\nminimal area and power overheads, while still achieving high performance. By\nre-constructing the sequential runahead employing a hardware/software co-design\napproach, the system can be implemented on a mature processor and SoC. Building\non this, an adaptive runahead mechanism is proposed to mitigate the severe\ncache contention in scalar in-order cores. Combining this, we provide a\ncomprehensive solution for embedded processors managing irregular workloads.\nOur evaluation demonstrates that the proposed MERE attains 93.5% of a 2-wide\nout-of-order core's performance while constraining area and power overheads\nbelow 5%, with the adaptive runahead mechanism delivering an additional 20.1%\nperformance gain through mitigating the severe cache contention issues.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T10:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.01583v1","title":"LL-Localizer: A Life-Long Localization System based on Dynamic i-Octree","summary":"This paper proposes an incremental voxel-based life-long localization method,\nLL-Localizer, which enables robots to localize robustly and accurately in\nmulti-session mode using prior maps. Meanwhile, considering that it is\ndifficult to be aware of changes in the environment in the prior map and robots\nmay traverse between mapped and unmapped areas during actual operation, we will\nupdate the map when needed according to the established strategies through\nincremental voxel map. Besides, to ensure high performance in real-time and\nfacilitate our map management, we utilize Dynamic i-Octree, an efficient\norganization of 3D points based on Dynamic Octree to load local map and update\nthe map during the robot's operation. The experiments show that our system can\nperform stable and accurate localization comparable to state-of-the-art LIO\nsystems. And even if the environment in the prior map changes or the robots\ntraverse between mapped and unmapped areas, our system can still maintain\nrobust and accurate localization without any distinction. Our demo can be found\non Blibili (https://www.bilibili.com/video/BV1faZHYCEkZ) and youtube\n(https://youtu.be/UWn7RCb9kA8) and the program will be available at\nhttps://github.com/M-Evanovic/LL-Localizer.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T10:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.01600v1","title":"Automatic Estimation of Pedestrian Gait Features using a single camera\n  recording: Algorithm and Statistical Analysis for Gender Difference and\n  Obstacle Interactions","summary":"The pedestrian gait features - body sway frequency, amplitude, stride length,\nand speed, along with pedestrian personal space and directional bias, are\nimportant parameters to be used in different pedestrian dynamics studies. Gait\nfeature measurements are paramount for wide-ranging applications, varying from\nthe medical field to the design of bridges. Personal space and choice of\ndirection (directional bias) play important roles during crowd simulations. In\nthis study, we formulate an automatic algorithm for calculating the gait\nfeatures of a trajectory extracted from video recorded using a single camera\nattached to the roof of a building. Our findings indicate that females have\n28.64% smaller sway amplitudes, 8.68% smaller stride lengths, and 8.14% slower\nspeeds compared to males, with no significant difference in frequency. However,\naccording to further investigation, our study reveals that the body parameters\nare the main variables that dominate gait features rather than gender. We have\nconducted three experiments in which the volunteers are walking towards the\ndestination a) without any obstruction, b) with a stationary non-living\nobstacle present in the middle of the path, and c) with a human being standing\nin the middle of the path. From a comprehensive statistical analysis, key\nobservations include no significant difference in gait features with respect to\ngender, no significant difference in gait features in the absence or presence\nof an obstacle, pedestrians treating stationary human beings and stationary\nobstacles the same given that the gender is same to match the comfort level,\nand a directional bias towards the left direction, likely influenced by\nleft-hand traffic rule in India.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T11:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01612v1","title":"The Mini-SiTian Array: first-two-year operation","summary":"The SiTian project, designed to utilize 60 telescopes distributed across\nmultiple sites in China, is a next-generation time-domain survey initiative. As\na pathfinder for the SiTian project, the Mini-SiTian (MST) has been proposed\nand implemented to test the SiTian's brain and data pipeline, and to evaluate\nthe feasibility of its technology and science cases. Mounted at the Xinglong\nObservatory, the MST project comprises three 30 cm telescopes and has been\noperated since Nov. 2022. Each telescope of the MST possesses a large field of\nview, covering $2.29^{\\circ}$ $\\times$ $1.53^{\\circ}$ FOV, and is equipped with\n$g'$, $r'$ and $i'$ filters, respectively. Acting as the pioneer of the\nforthcoming SiTian project, the MST is dedicated to the discovery of variable\nstars, transients, and outburst events, and has already obtained some\ninteresting scientific results. In this paper, we will summarize the\nfirst-two-year operation of the MST project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:07Z"}
{"aid":"http://arxiv.org/abs/2504.01637v1","title":"LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach","summary":"Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-02T11:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.01638v1","title":"Convex Computations for Controlled Safety Invariant Sets of Black-box\n  Discrete-time Dynamical Systems","summary":"Identifying controlled safety invariant sets (CSISs) is essential in\nsafety-critical applications. This paper tackles the problem of identifying\nCSISs for black-box discrete-time systems, where the model is unknown and only\nlimited simulation data is accessible. Traditionally, a CSIS is defined as a\nsubset of a safe set, encompassing initial states for which a control input\nexists that keeps the system within the set at the next time step-this is\nreferred to as the one-step invariance property. However, the requirement for\none-step invariance can be equivalently translated into a stricter condition of\n``always-invariance'', meaning that there exist control inputs capable of\nkeeping the system within this set indefinitely. Such a condition may prove\noverly stringent or impractical for black-box systems, where predictions can\nbecome unreliable beyond a single time step or a limited number of finite time\nsteps. To overcome the challenges posed by black-box systems, we reformulate\nthe one-step invariance property in a ``Probably Approximately Correct'' (PAC)\nsense. This approach allows us to assess the probability that a control input\nexists to keep the system within the CSIS at the next time step, with a\npredefined level of confidence. If the system successfully remains within the\nset at the next time step, we can then reapply the invariance evaluation to the\nnew state, thereby facilitating a recursive assurance of invariance. Our method\nemploys barrier functions and scenario optimization, resulting in a linear\nprogramming method to estimate PAC CSISs. Finally, the effectiveness of our\napproach is demonstrated on several examples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T11:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.01676v1","title":"Satellite Edge Artificial Intelligence with Large Models: Architectures\n  and Technologies","summary":"Driven by the growing demand for intelligent remote sensing applications,\nlarge artificial intelligence (AI) models pre-trained on large-scale unlabeled\ndatasets and fine-tuned for downstream tasks have significantly improved\nlearning performance for various downstream tasks due to their generalization\ncapabilities. However, many specific downstream tasks, such as extreme weather\nnowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield\nsurveillance, require real-time data processing. Traditional methods via\ntransferring raw data to ground stations for processing often cause significant\nissues in terms of latency and trustworthiness. To address these challenges,\nsatellite edge AI provides a paradigm shift from ground-based to on-board data\nprocessing by leveraging the integrated communication-and-computation\ncapabilities in space computing power networks (Space-CPN), thereby enhancing\nthe timeliness, effectiveness, and trustworthiness for remote sensing\ndownstream tasks. Moreover, satellite edge large AI model (LAM) involves both\nthe training (i.e., fine-tuning) and inference phases, where a key challenge\nlies in developing computation task decomposition principles to support\nscalable LAM deployment in resource-constrained space networks with\ntime-varying topologies. In this article, we first propose a satellite\nfederated fine-tuning architecture to split and deploy the modules of LAM over\nspace and ground networks for efficient LAM fine-tuning. We then introduce a\nmicroservice-empowered satellite edge LAM inference architecture that\nvirtualizes LAM components into lightweight microservices tailored for\nmulti-task multimodal inference. Finally, we discuss the future directions for\nenhancing the efficiency and scalability of satellite edge LAM, including\ntask-oriented communication, brain-inspired computing, and satellite edge AI\nnetwork optimization.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI,eess.SP","published":"2025-04-02T12:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.01680v1","title":"Arbitrary gauge quantisation of light-matter theories with\n  time-dependent constraints","summary":"We provide a general framework for the quantisation of light-matter theories\nwith time-dependent holonomic constraints. Unless time dependence is present\nfrom the outset at the Lagrangian level, different gauges generally produce\nnon-equivalent canonical theories. The irrotational gauge is defined as that\nwhich also yields a correct theory when time dependence is introduced at the\nHamiltonian level. We unify examples of such gauges found in existing\nliterature. In particular, we show that for describing time-dependent\nlight-matter interactions the Coulomb gauge is not generally irrotational, so\nit does not enjoy any special status, contradicting the conclusions in Phys.\nRev. A 107, 013722 (2023) and Phys. Rev. Research 3, 023079 (2021), while\nreaffirming the prior treatment and conclusions reported in Phys. Rev. Research\n3, 013116 (2021).","main_category":"quant-ph","categories":"quant-ph,cond-mat.supr-con,hep-th,physics.atom-ph,physics.optics","published":"2025-04-02T12:27:00Z"}
{"aid":"http://arxiv.org/abs/2504.01692v1","title":"Segmentation variability and radiomics stability for predicting\n  Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging","summary":"Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-04-02T12:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01707v1","title":"InfiniteICL: Breaking the Limit of Context Window Size via Long\n  Short-term Memory Transformation","summary":"In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T13:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.01730v1","title":"AI-Driven Framework for Multi-Service Multi-Modal Devices in NextG ORAN\n  Systems","summary":"In this paper, an artificial intelligence (AI)-driven efficient RAN\nmanagement framework is proposed. This framework introduces the concept of a\nintroducing the multi-service-modal UE (MSMU) system, which allows a single UE\nto handle both eMBB and uRLLC services. The proposed framework integrates\ntraffic demand prediction, route optimization, RAN slicing, service\nidentification, and radio resource management under uncertainty. The challenge\nof dynamic environments in such a system is addressed by decomposing the\noptimization problem into long-term (L-SP) and short-term (S-SP) subproblems.\nUsing a long short-term memory (LSTM) model, the proposed approach allows the\nprediction of eMBB and uRLLC traffic demands and optimal routes for RAN slicing\nin the L-SP. For the S-SP, another LSTM model is employed to handle real-time\nservice type identification and resource management based on long-term\npredictions. To support continuous adaptation, continual learning is\nincorporated into the S-SP framework, allowing the model to learn new service\ntypes while retaining prior knowledge. Experimental results show that the\nproposed framework efficiently manages dual-mode UEs, achieving low mean square\nerror for traffic demand (0.003), resource block prediction (0.003), and power\nprediction (0.002), with 99\\% accuracy in service type and route selection and\nover 95\\% average accuracy for continual service adaptation across seven tasks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T13:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.01732v1","title":"FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D\n  Scene Reconstruction and Benchmarking","summary":"The development of large-scale 3D scene reconstruction and novel view\nsynthesis methods mostly rely on datasets comprising perspective images with\nnarrow fields of view (FoV). While effective for small-scale scenes, these\ndatasets require large image sets and extensive structure-from-motion (SfM)\nprocessing, limiting scalability. To address this, we introduce a fisheye image\ndataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye\nlenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoor\nscenes. Each scene has sparse SfM point clouds and precise LIDAR-derived dense\npoint clouds that can be used as geometric ground-truth, enabling robust\nbenchmarking under challenging conditions such as occlusions and reflections.\nWhile the baseline experiments focus on vanilla Gaussian Splatting and NeRF\nbased Nerfacto methods, the dataset supports diverse approaches for scene\nreconstruction, novel view synthesis, and image-based rendering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.01736v1","title":"Design and Experimental Validation of an Urban Microclimate Tool\n  Integrating Indoor-Outdoor Detailed Longwave Radiative Fluxes at District\n  Scale","summary":"Numerical simulation is a powerful tool for assessing the causes of an Urban\nHeat Island (UHI) effect or quantifying the impact of mitigation solutions on\noutdoor and indoor thermal comfort. For that purpose, several models have been\ndeveloped at the district scale. At this scale, the outside surface energy\nbudget is detailed, however building models are very simplified and considered\nas a boundary condition of the district scale model. This shortcoming inhibits\nthe opportunity to investigate the effect of urban microclimate on the inside\nbuilding conditions. The aim of this work is to improve the representation of\nthe physical phenomena involved in the building models of a district model. For\nthat purpose, the model integrates inside and outside fully detailed long-wave\nradiative flux. The numerical model is based on finite differences to solve\nconduction through all the surfaces and the radiosity method to solve long-wave\nradiative heat fluxes inside and outside. Calculated temperatures and heat\nfluxes are evaluated with respect to \\textit{in situ} measurements from an\nexperimental demonstrator over 14 sensors and a 24-day period. Results are also\ncompared to state-of-the-art models simulation tool show improvement of the\nRMSE of $0.9 \\ \\mathsf{^{\\,\\circ}C}$ to $2.1 \\ \\mathsf{^{\\,\\circ}C}$ on the\nsurface temperature modeled.","main_category":"cs.CE","categories":"cs.CE,I.6","published":"2025-04-02T13:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.01765v1","title":"Existence and dimensional lower bound for the global attractor of a PDE\n  model for ant trail formation","summary":"We study the asymptotic behavior of a nonlinear PDE model for ant trail\nformation, which was introduced in [3]. We establish the existence of a compact\nglobal attractor and prove the nonlinear instability of the homogeneous steady\nstate under an inviscid instability condition. We also provide a dimensional\nlower bound on the attractor. Alternatively, we prove that if the interaction\nparameter is sufficiently small, the homogeneous steady state is globally\nasymptotically stable.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T14:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01800v1","title":"Motility and rotation of multi-timescale microswimmers in linear\n  background flows","summary":"Microswimming cells and robots exhibit diverse behaviours due to both their\nswimming and their environment. One of the core environmental features\nimpacting inertialess swimming is background flows. While the influence of\nselect flows, particularly shear flows, have been extensively investigated,\nthese are special cases. Here, we examine inertialess swimmers in more general\nflows, specifically general linear planar flows that may also possess rapid\noscillations. Relatively weak symmetry constraints are imposed on the swimmer\nto ensure planarity and to reduce complexity. A further constraint reflecting\ncommon observation is imposed, namely that the swimmer is inefficient, which we\nsuitably define. This introduces two separate timescales: a fast timescale\nassociated with swimmer actuation, and a second timescale associated with net\nswimmer movement, with inefficiency dictating that this latter timescale is\nmuch slower, allowing for a multiple timescale simplification of the governing\nequations. With the exception of mathematically precise edge cases, we find\nthat the behaviour of the swimmer is dictated by two parameter groupings, both\nof which measure balances between the angular velocity and rate of strain of\nthe background flow. While the measures of flow angular velocity and strain\nrates that primarily govern the rotational dynamics are modulated by swimmer\nproperties, the primary features of the translational motion are determined\nsolely by a ratio of flow angular velocity to strain rate. Hence, a simple\nclassification of the swimmer dynamics emerges. For example, this illustrates\nthe limited extent to which, and how, microswimmers may control their\norientations and trajectories in flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T15:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.01807v1","title":"Barrier Certificates for Unknown Systems with Latent States and\n  Polynomial Dynamics using Bayesian Inference","summary":"Certifying safety in dynamical systems is crucial, but barrier certificates -\nwidely used to verify that system trajectories remain within a safe region -\ntypically require explicit system models. When dynamics are unknown,\ndata-driven methods can be used instead, yet obtaining a valid certificate\nrequires rigorous uncertainty quantification. For this purpose, existing\nmethods usually rely on full-state measurements, limiting their applicability.\nThis paper proposes a novel approach for synthesizing barrier certificates for\nunknown systems with latent states and polynomial dynamics. A Bayesian\nframework is employed, where a prior in state-space representation is updated\nusing input-output data via a targeted marginal Metropolis-Hastings sampler.\nThe resulting samples are used to construct a candidate barrier certificate\nthrough a sum-of-squares program. It is shown that if the candidate satisfies\nthe required conditions on a test set of additional samples, it is also valid\nfor the true, unknown system with high probability. The approach and its\nprobabilistic guarantees are illustrated through a numerical simulation.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,stat.ML","published":"2025-04-02T15:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.01816v1","title":"Random Phase Approximation Correlation Energy using Real-Space Density\n  Functional Perturbation Theory","summary":"We present a real-space method for computing the random phase approximation\n(RPA) correlation energy within Kohn-Sham density functional theory, leveraging\nthe low-rank nature of the frequency-dependent density response operator. In\nparticular, we employ a cubic scaling formalism based on density functional\nperturbation theory that circumvents the calculation of the response function\nmatrix, instead relying on the ability to compute its product with a vector\nthrough the solution of the associated Sternheimer linear systems. We develop a\nlarge-scale parallel implementation of this formalism using the subspace\niteration method in conjunction with the spectral quadrature method, while\nemploying the Kronecker product-based method for the application of the Coulomb\noperator and the conjugate orthogonal conjugate gradient method for the\nsolution of the linear systems. We demonstrate convergence with respect to key\nparameters and verify the method's accuracy by comparing with planewave\nresults. We show that the framework achieves good strong scaling to many\nthousands of processors, reducing the time to solution for a lithium hydride\nsystem with 128 electrons to around 150 seconds on 4608 processors.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-02T15:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.01825v1","title":"How the microphysical properties of external photoevaporation influence\n  the global evolution of protoplanetary discs","summary":"External photoevaporation is one of the dominant mechanisms for mass loss\nfrom protoplanetary discs. However this mass loss is theoretically expected to\ndepend upon the microphysical properties of protoplanetary discs, which are\ncurrently poorly constrained in observations. In this work we explore the\nimpact of microphysics on the bulk evolution of discs. The polycyclic aromatic\nhydrocarbon (PAH) abundance, and the extent to which grain growth has occurred\nin the disc have profound effects on the strength of mass loss rates due to\nexternal photoevaporation, which in turn can have a significant impact on the\ndisc evolution, impacting disc radii and accretion rates over time. The\nstrongest sensitivity is to whether grain growth has occurred in the disc,\nwhich reduces the amount of dust entrained in the wind to shield the disc, thus\nincreasing the rate at which gas is lost. Additionally, larger PAH abundances\nresult in stronger heating and higher mass loss rates, but to a lesser extent\nthan grain growth. We find that plausible variations in the PAH abundance and\ndisc dust evolution can leave observable differences in disc populations. This\nwork highlights the importance of obtaining observational constraints of the\nmicrophysical properties of protoplanetary discs. Future observations from JWST\nshould soon be able to provide these constraints.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T15:30:58Z"}
{"aid":"http://arxiv.org/abs/2504.01835v1","title":"Autonomous optical navigation for DESTINY+: Enhancing misalignment\n  robustness in flyby observations with a rotating telescope","summary":"DESTINY+ is an upcoming JAXA Epsilon medium-class mission to flyby multiple\nasteroids including Phaethon. As an asteroid flyby observation instrument, a\ntelescope mechanically capable of single-axis rotation, named TCAP, is mounted\non the spacecraft to track and observe the target asteroids during flyby. As in\npast flyby missions utilizing rotating telescopes, TCAP is also used as a\nnavigation camera for autonomous optical navigation during the closest-approach\nphase. To mitigate the degradation of the navigation accuracy, past missions\nperformed calibration of the navigation camera's alignment before starting\noptical navigation. However, such calibration requires significant operational\ntime to complete and imposes constraints on the operation sequence. From the\nabove background, the DESTINY+ team has studied the possibility of reducing\noperational costs by allowing TCAP alignment errors to remain. This paper\ndescribes an autonomous optical navigation algorithm robust to the misalignment\nof rotating telescopes, proposed in this context. In the proposed method, the\nmisalignment of the telescope is estimated simultaneously with the spacecraft's\norbit relative to the flyby target. To deal with the nonlinearity between the\nmisalignment and the observation value, the proposed method utilizes the\nunscented Kalman filter, instead of the extended Kalman filter widely used in\npast studies. The proposed method was evaluated with numerical simulations on a\nPC and with hardware-in-the-loop simulation, taking the Phaethon flyby in the\nDESTINY+ mission as an example. The validation results suggest that the\nproposed method can mitigate the misalignment-induced degradation of the\noptical navigation accuracy with reasonable computational costs suited for\nonboard computers.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.LG","published":"2025-04-02T15:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.01844v1","title":"BOGausS: Better Optimized Gaussian Splatting","summary":"3D Gaussian Splatting (3DGS) proposes an efficient solution for novel view\nsynthesis. Its framework provides fast and high-fidelity rendering. Although\nless complex than other solutions such as Neural Radiance Fields (NeRF), there\nare still some challenges building smaller models without sacrificing quality.\nIn this study, we perform a careful analysis of 3DGS training process and\npropose a new optimization methodology. Our Better Optimized Gaussian Splatting\n(BOGausS) solution is able to generate models up to ten times lighter than the\noriginal 3DGS with no quality degradation, thus significantly boosting the\nperformance of Gaussian Splatting compared to the state of the art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:49:23Z"}
{"aid":"http://arxiv.org/abs/2504.01851v1","title":"Virtual Target Trajectory Prediction for Stochastic Targets","summary":"Trajectory prediction of other vehicles is crucial for autonomous vehicles,\nwith applications from missile guidance to UAV collision avoidance. Typically,\ntarget trajectories are assumed deterministic, but real-world aerial vehicles\nexhibit stochastic behavior, such as evasive maneuvers or gliders circling in\nthermals. This paper uses Conditional Normalizing Flows, an unsupervised\nMachine Learning technique, to learn and predict the stochastic behavior of\ntargets of guided missiles using trajectory data. The trained model predicts\nthe distribution of future target positions based on initial conditions and\nparameters of the dynamics. Samples from this distribution are clustered using\na time series k-means algorithm to generate representative trajectories, termed\nvirtual targets. The method is fast and target-agnostic, requiring only\ntraining data in the form of target trajectories. Thus, it serves as a drop-in\nreplacement for deterministic trajectory predictions in guidance laws and path\nplanning. Simulated scenarios demonstrate the approach's effectiveness for\naerial vehicles with random maneuvers, bridging the gap between deterministic\npredictions and stochastic reality, advancing guidance and control algorithms\nfor autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T16:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.01879v1","title":"TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving\n  Semi-structured Tables","summary":"Humans continuously make new discoveries, and understanding temporal sequence\nof events leading to these breakthroughs is essential for advancing science and\nsociety. This ability to reason over time allows us to identify future steps\nand understand the effects of financial and political decisions on our lives.\nHowever, large language models (LLMs) are typically trained on static datasets,\nlimiting their ability to perform effective temporal reasoning. To assess the\ntemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES\ndataset, which comprises 3,971 questions derived from over 14,000 tables,\nspanning 1,238 entities across multiple time periods. We introduce a\ntemplate-based question-generation pipeline that harnesses LLMs to refine both\ntemplates and questions. Additionally, we establish baseline results using\nstate-of-the-art LLMs to create a benchmark. We also introduce novel modeling\nstrategies centered around task decomposition, enhancing LLM performance.","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.IR","published":"2025-04-02T16:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.01885v1","title":"Observing Spatial Charge and Spin Correlations in a Strongly-Interacting\n  Fermi Gas","summary":"Two-dimensional correlated fermions constitute a cornerstone of quantum\nmatter, covering a broad fundamental and technological scope, and have\nattracted increasing interest with the emergence of modern materials such as\nhigh-$T_{\\rm c}$ superconductors, graphene, topological insulators, and Moir\\'e\nstructures. Atom-based quantum simulators provide a new pathway to understand\nthe microscopic mechanisms occurring at the heart of such systems. In this\nwork, we explore two-dimensional attractive Fermi gases at the microscopic\nlevel by probing spatial charge and spin correlations in situ. Using\natom-resolved continuum quantum gas microscopy, we directly observe fermion\npairing and study the evolution of two- and three-point correlation functions\nas inter-spin attraction is increased. The precision of our measurement allows\nus to reveal a marked dip in the pair correlation function, fundamentally\nforbidden by the mean-field result based on Bardeen-Cooper-Schrieffer (BCS)\ntheory but whose existence we confirm in exact auxiliary-field quantum Monte\nCarlo calculations. We demonstrate that the BCS prediction is critically\ndeficient not only in the superfluid crossover regime but also deep in the\nweakly attractive side. Guided by our measurements, we find a remarkable\nrelation between two- and three-point correlations that establishes the\ndominant role of pair-correlations. Finally, leveraging local single-pair\nlosses, we independently characterize the short-range behavior of pair\ncorrelations, via the measurement of Tan's Contact, and find excellent\nagreement with numerical predictions. Our measurements provide an unprecedented\nmicroscopic view into two-dimensional Fermi gases and constitute a paradigm\nshift for future studies of strongly-correlated fermionic matter in the\ncontinuum.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-02T16:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.01886v1","title":"GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical\n  Reasoning","summary":"Recent advances in general medical AI have made significant strides, but\nexisting models often lack the reasoning capabilities needed for complex\nmedical decision-making. This paper presents GMAI-VL-R1, a multimodal medical\nreasoning model enhanced by reinforcement learning (RL) to improve its\nreasoning abilities. Through iterative training, GMAI-VL-R1 optimizes\ndecision-making, significantly boosting diagnostic accuracy and clinical\nsupport. We also develop a reasoning data synthesis method, generating\nstep-by-step reasoning data via rejection sampling, which further enhances the\nmodel's generalization. Experimental results show that after RL training,\nGMAI-VL-R1 excels in tasks such as medical image diagnosis and visual question\nanswering. While the model demonstrates basic memorization with supervised\nfine-tuning, RL is crucial for true generalization. Our work establishes new\nevaluation benchmarks and paves the way for future advancements in medical\nreasoning models. Code, data, and model will be released at\n\\href{https://github.com/uni-medical/GMAI-VL-R1}{this link}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T16:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.01892v1","title":"Synchro-curvature description of γ-ray light curves and spectra\n  of pulsars: concurrent fitting","summary":"We present a concurrent fitting of spectra and light curves of the whole\npopulation of detected gamma-ray pulsars. Using a synchro-curvature model we\ncompare our theoretical output with the observational data published in the\nThird Fermi Pulsar Catalog, which has significantly increased the number of\nknown gamma-ray pulsars. Our model properly fits all the spectra and reproduces\nwell a considerable fraction of light curves. Light curve fitting is carried\nout with two different techniques, whose strong points and caveats are\ndiscussed. We use a weighted reduced \\{chi}^2 of light curves in time domain,\nand the Euclidean distance of the Fourier transform of the light curves, i.e.\ntransforming the light curves to the frequency domain. The performance of both\nmethods is found to be qualitatively similar, but individual best-fit solutions\nmay differ. We also show that, in our model based on few effective parameters,\nthe light curve fitting is basically insensitive to the timing and spectral\nparameters of the pulsar. Finally, we look for correlations between model and\nphysical parameters, and recover trends found in previous studies but without\nany significant correlation involving geometrical parameters.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-02T16:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.01893v1","title":"A minimal Pati-Salam theory: from cosmic defects to gravitational waves\n  and colliders","summary":"We discuss a minimal renormalizable Pati-Salam theory based on the\n$SU(4)_{\\rm C}\\,\\times\\,SU(2)_{\\rm L}\\,\\times\\,SU(2)_{\\rm R}$ gauge group, with\nunification scale Higgs multiplets taken as $SU(2)_{\\rm L}$ and $SU(2)_{\\rm R}$\ndoublets, which lead to neutrino Dirac picture. Although a number of scalar\nparticles could be light, even lying at the LHC energies, the unification scale\nis hopelessly out of reach in any foreseeable future. Moreover, phase\ntransition in the early Universe leads to the production of magnetic monopoles\nand domain walls, both incompatible with the standard cosmological model. A\nsmall explicit breaking of the discrete left-right symmetry allows the domain\nwalls to decay, and in the process possibly sweep away the monopoles,\nanalogously to the previously discussed case of $SU(5)$ grand unified theory.\nThis leaves an important imprint of gravitational waves, within the reach of\nnext generation searches, correlated with monopole detection and new light\nparticles at collider energies. The theory has a dark matter candidate in the\nform of an inert scalar doublet, with a mass below TeV, which can further\ntrigger electroweak baryogenesis.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,hep-ex","published":"2025-04-02T16:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.01923v1","title":"Sliding Dynamics of Skyrmion Molecular Crystals","summary":"Using both atomistic and particle-based simulations, we investigate the\ncurrent-driven dynamics of skyrmions on two-dimensional periodic substrates\nwhen there are multiple skyrmions per substrate minimum. At zero drive, the\nsystem forms pinned skyrmion molecular crystal states consisting of dimers,\ntrimers, or dimer-trimer mixtures that have both positional and orientational\norder. On a square substrate lattice, the motion above depinning occurs via a\nrunning soliton that travels completely transverse to the applied current. This\nmotion is generated by a torque from the Magnus force, which rotates the\n$n$-mer states perpendicular to the applied current. At higher drives, the flow\nbecomes disordered while the Hall angle diminishes and gradually approaches the\nintrinsic value. In some cases, we also find directional locking where the Hall\nangle becomes locked to certain symmetry directions of the substrate over a\nrange of currents. The transitions into and out of directionally locked states\nare accompanied by negative differential mobility in which the net velocity\ndecreases as the drive increases. On a triangular substrate, we find no\ntransverse mobility effects, but still observe directionally locked motion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T17:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.01925v1","title":"Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution\n  Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time","summary":"Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T17:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.01944v1","title":"Graphon games and an idealized limit of large network games","summary":"Graphon games are a class of games with a continuum of agents, introduced to\napproximate the strategic interactions in large network games. The first result\nof this study is an equilibrium existence theorem in graphon games, under the\nsame conditions as those in network games. We prove the existence of an\nequilibrium in a graphon game with an infinite-dimensional strategy space,\nunder the continuity and quasi-concavity of the utility functions. The second\nresult characterizes Nash equilibria in graphon games as the limit points of\nasymptotic Nash equilibria in large network games. If a sequence of large\nnetwork games converges to a graphon game, any convergent sequence of\nasymptotic Nash equilibria in these large network games also converges to a\nNash equilibrium of the graphon game. In addition, for any graphon game and its\nequilibrium, there exists a sequence of large network games that converges to\nthe graphon game and has asymptotic Nash equilibria converging to the\nequilibrium. These results suggest that the concept of a graphon game is an\nidealized limit of large network games as the number of players tends to\ninfinity.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.01952v1","title":"Image Difference Grounding with Natural Language","summary":"Visual grounding (VG) typically focuses on locating regions of interest\nwithin an image using natural language, and most existing VG methods are\nlimited to single-image interpretations. This limits their applicability in\nreal-world scenarios like automatic surveillance, where detecting subtle but\nmeaningful visual differences across multiple images is crucial. Besides,\nprevious work on image difference understanding (IDU) has either focused on\ndetecting all change regions without cross-modal text guidance, or on providing\ncoarse-grained descriptions of differences. Therefore, to push towards\nfiner-grained vision-language perception, we propose Image Difference Grounding\n(IDG), a task designed to precisely localize visual differences based on user\ninstructions. We introduce DiffGround, a large-scale and high-quality dataset\nfor IDG, containing image pairs with diverse visual variations along with\ninstructions querying fine-grained differences. Besides, we present a baseline\nmodel for IDG, DiffTracker, which effectively integrates feature differential\nenhancement and common suppression to precisely locate differences. Experiments\non the DiffGround dataset highlight the importance of our IDG dataset in\nenabling finer-grained IDU. To foster future research, both DiffGround data and\nDiffTracker model will be publicly released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.01954v1","title":"Towards Unified Referring Expression Segmentation Across Omni-Level\n  Visual Target Granularities","summary":"Referring expression segmentation (RES) aims at segmenting the entities'\nmasks that match the descriptive language expression. While traditional RES\nmethods primarily address object-level grounding, real-world scenarios demand a\nmore versatile framework that can handle multiple levels of target granularity,\nsuch as multi-object, single object or part-level references. This introduces\ngreat challenges due to the diverse and nuanced ways users describe targets.\nHowever, existing datasets and models mainly focus on designing grounding\nspecialists for object-level target localization, lacking the necessary data\nresources and unified frameworks for the more practical multi-grained RES. In\nthis paper, we take a step further towards visual granularity unified RES task.\nTo overcome the limitation of data scarcity, we introduce a new\nmulti-granularity referring expression segmentation (MRES) task, alongside the\nRefCOCOm benchmark, which includes part-level annotations for advancing\nfiner-grained visual understanding. In addition, we create MRES-32M, the\nlargest visual grounding dataset, comprising over 32.2M masks and captions\nacross 1M images, specifically designed for part-level vision-language\ngrounding. To tackle the challenges of multi-granularity RES, we propose\nUniRES++, a unified multimodal large language model that integrates\nobject-level and part-level RES tasks. UniRES++ incorporates targeted designs\nfor fine-grained visual feature exploration. With the joint model architecture\nand parameters, UniRES++ achieves state-of-the-art performance across multiple\nbenchmarks, including RefCOCOm for MRES, gRefCOCO for generalized RES, and\nRefCOCO, RefCOCO+, RefCOCOg for classic RES. To foster future research into\nmulti-grained visual grounding, our RefCOCOm benchmark, MRES-32M dataset and\nmodel UniRES++ will be publicly available at\nhttps://github.com/Rubics-Xuan/MRES.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:05Z"}
{"aid":"http://arxiv.org/abs/2504.02249v1","title":"Stock Price Prediction Using Triple Barrier Labeling and Raw OHLCV Data:\n  Evidence from Korean Markets","summary":"This paper demonstrates that deep learning models trained on raw OHLCV\n(open-high-low-close-volume) data can achieve comparable performance to\ntraditional machine learning models using technical indicators for stock price\nprediction in Korean markets. While previous studies have emphasized the\nimportance of technical indicators and feature engineering, we show that a\nsimple LSTM network trained on raw OHLCV data alone can match the performance\nof sophisticated ML models that incorporate technical indicators. Using a\ndataset of Korean stocks from 2006 to 2024, we optimize the triple barrier\nlabeling parameters to achieve balanced label proportions with a 29-day window\nand 9\\% barriers. Our experiments reveal that LSTM networks achieve similar\nperformance to traditional machine learning models like XGBoost, despite using\nonly raw OHLCV data without any technical indicators. Furthermore, we identify\nthat the optimal window size varies with model hidden size, with a\nconfiguration of window size 100 and hidden size 8 yielding the best\nperformance. Additionally, our results confirm that using full OHLCV data\nprovides better predictive accuracy compared to using only close price or close\nprice with volume. These findings challenge conventional approaches to feature\nengineering in financial forecasting and suggest that simpler approaches\nfocusing on raw data and appropriate model selection may be more effective than\ncomplex feature engineering strategies.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T03:30:50Z"}
{"aid":"http://arxiv.org/abs/2504.02276v1","title":"Distortion from spheres into Euclidean space","summary":"Any function from a round $n$-dimensional sphere of radius $r$ into\n$n$-dimensional Euclidean space must distort the metric additively by at least\n$\\frac{2\\pi r}{2 + \\sqrt{3-2/n}}$. This is proved using a fixed-point theorem\nof Granas that generalizes the classical theorem of Borsuk--Ulam to set-valued\nfunctions.","main_category":"math.MG","categories":"math.MG,math.GN","published":"2025-04-03T04:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.02284v1","title":"Non-perturbative heavy quark diffusion coefficients in a weakly\n  magnetized thermal QCD medium","summary":"In this work, the perturbative and non-perturbative contributions to the\nheavy quark (HQ) momentum ($\\kappa$) as well as spatial ($D_s$) diffusion\ncoefficients are computed in a weak background magnetic field. The formalism\nadopted here involves calculation of the in-medium potential of the HQ in a\nweak magnetic field, which then serves as a proxy for the resummed gluon\npropagator in the calculation of HQ self-energy ($\\Sigma$). The self-energy\ndetermines the scattering rate of HQs with light thermal partons, which is\nsubsequently used to evaluate $\\kappa$ and $D_s$. It is observed that\nnon-perturbative effects play a dominant role at low temperature. The spatial\ndiffusion coefficient $2\\pi T D_s$, exhibits good agreement with recent LQCD\nresults. These findings can be applied to calculate the heavy quark directed\nflow at RHIC and LHC energies. An extension of this formalism to the case of\nfinite HQ momentum has also been attempted.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T05:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.02306v1","title":"Lepton emission rates of 43-64V isotopes under stellar conditions","summary":"In astrophysical conditions prevalent during the late times of stellar\nevolution, lepton ($e^-$ and $e^+$) emission processes compete with the\ncorresponding lepton capture processes. Prior to the collapse, lepton emissions\nsignificantly affect the cooling of the core and reduce its entropy. Therefore,\nthe lepton emission rates for Fe-group nuclei serve as an important input for\ncore-collapse simulations of high-mass stars.\n  From earlier simulation studies, isotopes of vanadium (V) have great\nastrophysical significance in regard to their weak-decay rates, which\nsubstantially affect $Y_e$ (fraction of lepton to baryon number) during the\nfinal developmental stages of massive stars. The current study involves the\ncomputation of the weak lepton emission (LE) rates for V isotopes by employing\nthe improved deformed proton-neutron Quasi-particle Random Phase Approximation\n(pn-QRPA) model. The mass numbers of the selected isotopes range from 43 to 64.\nThe LE rates on these isotopes have been estimated for a broad spectrum of\ndensity and temperature under astrophysical conditions. The ranges considered\nfor density and temperature are $10^1$ to $10^{11}$ (g/cm$^3$) and $10^7$ to $3\n\\times 10^{11}$ (K), respectively.\n  The lepton emission rates from the present study were also compared to the\nrates previously estimated by using the independent-particle model (IPM) and\nlarge-scale shell model (LSSM). IPM rates are generally bigger than QRPA rates,\nwhile LSSM rates overall show a good comparison with the reported rates.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.02316v1","title":"ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D\n  Generation","summary":"Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.02318v1","title":"X-Capture: An Open-Source Portable Device for Multi-Sensory Learning","summary":"Understanding objects through multiple sensory modalities is fundamental to\nhuman perception, enabling cross-sensory integration and richer comprehension.\nFor AI and robotic systems to replicate this ability, access to diverse,\nhigh-quality multi-sensory data is critical. Existing datasets are often\nlimited by their focus on controlled environments, simulated objects, or\nrestricted modality pairings. We introduce X-Capture, an open-source, portable,\nand cost-effective device for real-world multi-sensory data collection, capable\nof capturing correlated RGBD images, tactile readings, and impact audio. With a\nbuild cost under $1,000, X-Capture democratizes the creation of multi-sensory\ndatasets, requiring only consumer-grade tools for assembly. Using X-Capture, we\ncurate a sample dataset of 3,000 total points on 500 everyday objects from\ndiverse, real-world environments, offering both richness and variety. Our\nexperiments demonstrate the value of both the quantity and the sensory breadth\nof our data for both pretraining and fine-tuning multi-modal representations\nfor object-centric tasks such as cross-sensory retrieval and reconstruction.\nX-Capture lays the groundwork for advancing human-like sensory representations\nin AI, emphasizing scalability, accessibility, and real-world applicability.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T06:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.02327v1","title":"LearNAT: Learning NL2SQL with AST-guided Task Decomposition for Large\n  Language Models","summary":"Natural Language to SQL (NL2SQL) has emerged as a critical task for enabling\nseamless interaction with databases. Recent advancements in Large Language\nModels (LLMs) have demonstrated remarkable performance in this domain. However,\nexisting NL2SQL methods predominantly rely on closed-source LLMs leveraging\nprompt engineering, while open-source models typically require fine-tuning to\nacquire domain-specific knowledge. Despite these efforts, open-source LLMs\nstruggle with complex NL2SQL tasks due to the indirect expression of user query\nobjectives and the semantic gap between user queries and database schemas.\nInspired by the application of reinforcement learning in mathematical\nproblem-solving to encourage step-by-step reasoning in LLMs, we propose LearNAT\n(Learning NL2SQL with AST-guided Task Decomposition), a novel framework that\nimproves the performance of open-source LLMs on complex NL2SQL tasks through\ntask decomposition and reinforcement learning. LearNAT introduces three key\ncomponents: (1) a Decomposition Synthesis Procedure that leverages Abstract\nSyntax Trees (ASTs) to guide efficient search and pruning strategies for task\ndecomposition, (2) Margin-aware Reinforcement Learning, which employs\nfine-grained step-level optimization via DPO with AST margins, and (3) Adaptive\nDemonstration Reasoning, a mechanism for dynamically selecting relevant\nexamples to enhance decomposition capabilities. Extensive experiments on two\nbenchmark datasets, Spider and BIRD, demonstrate that LearNAT enables a\n7B-parameter open-source LLM to achieve performance comparable to GPT-4, while\noffering improved efficiency and accessibility.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:59:44Z"}
{"aid":"http://arxiv.org/abs/2504.02336v1","title":"Spectral asymmetry via pseudodifferential projections: the massless\n  Dirac operator","summary":"A new approach to the study of spectral asymmetry for systems of partial\ndifferential equations (PDEs) on closed manifolds was proposed in a recent\nseries of papers by the first author and collaborator. They showed that\ninformation on spectral asymmetry can be encoded within and recovered from a\nnegative order pseudodifferential operator -- the asymmetry operator --\nconstructed from appropriately defined pseudodifferential (spectral)\nprojections. In this manuscript we apply these techniques to the study of the\nmassless Dirac operator; in particular, we compute the principal symbol of the\nasymmetry operator, accounting for the underlying gauge invariance.","main_category":"math-ph","categories":"math-ph,math.AP,math.DG,math.MP,math.SP","published":"2025-04-03T07:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02351v1","title":"Agglomerating Large Vision Encoders via Distillation for VFSS\n  Segmentation","summary":"The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T07:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.02352v1","title":"Liquid Neural Networks: Next-Generation AI for Telecom from First\n  Principles","summary":"Artificial intelligence (AI) has emerged as a transformative technology with\nimmense potential to reshape the next-generation of wireless networks. By\nleveraging advanced algorithms and machine learning techniques, AI offers\nunprecedented capabilities in optimizing network performance, enhancing data\nprocessing efficiency, and enabling smarter decision-making processes. However,\nexisting AI solutions face significant challenges in terms of robustness and\ninterpretability. Specifically, current AI models exhibit substantial\nperformance degradation in dynamic environments with varying data\ndistributions, and the black-box nature of these algorithms raises concerns\nregarding safety, transparency, and fairness. This presents a major challenge\nin integrating AI into practical communication systems. Recently, a novel type\nof neural network, known as the liquid neural networks (LNNs), has been\ndesigned from first principles to address these issues. In this paper, we\nexplore the potential of LNNs in telecommunications. First, we illustrate the\nmechanisms of LNNs and highlight their unique advantages over traditional\nnetworks. Then we unveil the opportunities that LNNs bring to future wireless\nnetworks. Furthermore, we discuss the challenges and design directions for the\nimplementation of LNNs. Finally, we summarize the performance of LNNs in two\ncase studies.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-03T07:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.02354v1","title":"Improving turbulence control through explainable deep learning","summary":"Turbulent-flow control aims to develop strategies that effectively manipulate\nfluid systems, such as the reduction of drag in transportation and enhancing\nenergy efficiency, both critical steps towards reducing global CO$_2$\nemissions. Deep reinforcement learning (DRL) offers novel tools to discover\nflow-control strategies, which we combine with our knowledge of the physics of\nturbulence. We integrate explainable deep learning (XDL) to objectively\nidentify the coherent structures containing the most informative regions in the\nflow, with a DRL model trained to reduce them. The trained model targets the\nmost relevant regions in the flow to sustain turbulence and produces a drag\nreduction which is higher than that of a model specifically trained to reduce\nthe drag, while using only half its power consumption. Moreover, the XDL model\nresults in a better drag reduction than other models focusing on specific\nclassically identified coherent structures. This demonstrates that combining\nDRL with XDL can produce causal control strategies that precisely target the\nmost influential features of turbulence. By directly addressing the core\nmechanisms that sustain turbulence, our approach offers a powerful pathway\ntowards its efficient control, which is a long-standing challenge in physics\nwith profound implications for energy systems, climate modeling and\naerodynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T07:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.02362v1","title":"Brightness Perceiving for Recursive Low-Light Image Enhancement","summary":"Due to the wide dynamic range in real low-light scenes, there will be large\ndifferences in the degree of contrast degradation and detail blurring of\ncaptured images, making it difficult for existing end-to-end methods to enhance\nlow-light images to normal exposure. To address the above issue, we decompose\nlow-light image enhancement into a recursive enhancement task and propose a\nbrightness-perceiving-based recursive enhancement framework for high dynamic\nrange low-light image enhancement. Specifically, our recursive enhancement\nframework consists of two parallel sub-networks: Adaptive Contrast and Texture\nenhancement network (ACT-Net) and Brightness Perception network (BP-Net). The\nACT-Net is proposed to adaptively enhance image contrast and details under the\nguidance of the brightness adjustment branch and gradient adjustment branch,\nwhich are proposed to perceive the degradation degree of contrast and details\nin low-light images. To adaptively enhance images captured under different\nbrightness levels, BP-Net is proposed to control the recursive enhancement\ntimes of ACT-Net by exploring the image brightness distribution properties.\nFinally, in order to coordinate ACT-Net and BP-Net, we design a novel\nunsupervised training strategy to facilitate the training procedure. To further\nvalidate the effectiveness of the proposed method, we construct a new dataset\nwith a broader brightness distribution by mixing three low-light datasets.\nCompared with eleven existing representative methods, the proposed method\nachieves new SOTA performance on six reference and no reference metrics.\nSpecifically, the proposed method improves the PSNR by 0.9 dB compared to the\nexisting SOTA method.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T07:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.02388v1","title":"Steiner Traveling Salesman Problem with Quantum Annealing","summary":"The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.","main_category":"quant-ph","categories":"quant-ph,cs.AI,cs.ET","published":"2025-04-03T08:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.02396v1","title":"High-Resolution Observations of a Small-Scale Cancellation Nanoflare:\n  Supporting Evidence for the Cancellation Nanoflare Model","summary":"An analytical cancellation nanoflare model has recently been established to\nshow the fundamental role that ubiquitous small-scale cancellation nanoflares\nplay in solar atmospheric heating. Although this model is well-supported by\nsimulations, observational evidence is needed to deepen our understanding of\ncancellation nanoflares. We present observations of a small-scale cancellation\nnanoflare event, analyzing its magnetic topology evolution, triggers, and\nphysical parameters. Using coordinated observations from Solar Dynamics\nObservatory and Goode Solar Telescope, we identify a photospheric flow-driven\ncancellation event with a flux cancellation rate of ~10^{15} Mx/s and a heating\nrate of 8.7 x 10^6 erg cm^{-2} s^{-1}. The event shows the characteristic\ntransition from $\\pi$-shaped to X-shaped magnetic configuration before forming\na two arcsecs current sheet, closely matching model predictions. This event\nprovides critical observational support for the cancellation nanoflare model\nand its role in solar atmospheric heating.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-03T08:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.02401v1","title":"Comparing the Sun to Sun-like stars. On the importance of addressing\n  faculae/spot domination","summary":"Whether the Sun is an ordinary G-type star is still an open scientific\nquestion. Stellar surveys by Kepler and TESS, however, revealed that Sun-like\nstars tend to show much stronger flare activity than the Sun. This study aims\nto reassess observed flare and spot activity of Sun-like Kepler stars by\nfine-tuning the criteria for a more robust definition of Sun-like conditions\nand better comparability between the current Sun and Sun-like stars. We update\none of the recent stellar Sun-like star samples by applying new empirical\nstellar relations between the starspot size and the effective stellar\ntemperature to derive more reliable starspot group sizes. From the 265\nsolar-type stars, we could select 48 stars supporting the Kepler 30-minute\ncadence light curves. These were analyzed by implementing the gradient of the\npower spectra method to distinguish between spot- and faculae-dominated stars.\nWe employed the $\\alpha$-factor to quantify the area ratio of bright and dark\nfeatures on the stellar surface. We were able to group the 48 stars as being\nspot- or faculae-dominated, revealing a preferential distribution of the Kepler\nSun-like stars towards the spot-dominated (44 stars) and transitional (four\nstars) regimes. As the current Sun is faculae-dominated, only the transitional\nstars were utilized for further evaluation. Additionally, accounting for\ncomparability in stellar mass, radius, and rotation period, we show that only\none of the utilized 265 Sun-like stars in the Kepler sample (i.e., KIC\n11599385) allows for direct comparison to the current Sun. We further show that\nthe single flare observed on KIC 11599385 falls right within the flare energy\nrange estimated for the AD774/775 event observed in the cosmogenic radionuclide\narchives of $^{10}$Be, $^{14}$C, and $^{36}$Cl.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T08:51:00Z"}
{"aid":"http://arxiv.org/abs/2504.02410v1","title":"Limits of group algebras for growing symmetric groups and wreath\n  products","summary":"Let $S(\\infty)$ denote the infinite symmetric group formed by the finitary\npermutations of the set of natural numbers; this is a countable group. We\nintroduce its virtual group algebra, a completion of the conventional group\nalgebra $\\mathbb C[S(\\infty)]$. The virtual group algebra is obtained by taking\nlarge-$n$ limits of the finite-dimensional group algebras $\\mathbb C[S(n)]$ in\nthe so-called tame representations of $S(\\infty)$. We establish a connection\nwith the centralizer construction of Molev-Olshanski [J. Algebra, 237 (2001),\n302-341; arXiv:math/0002165] and Drinfeld-Lusztig degenerate affine Hecke\nalgebras. This makes it possible to describe the structure of the virtual group\nalgebra. Then we extend the results to wreath products $G\\wr S(\\infty)$ with\narbitrary finite groups $G$.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-03T09:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.02426v1","title":"Narrative Studio: Visual narrative exploration using LLMs and Monte\n  Carlo Tree Search","summary":"Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T09:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.02430v1","title":"How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired\n  by Aristotle's Posterior Analytics","summary":"Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.","main_category":"cs.AI","categories":"cs.AI,cs.LO,I.2.4","published":"2025-04-03T09:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.02456v1","title":"The Amenability Framework: Rethinking Causal Ordering Without Estimating\n  Causal Effects","summary":"Who should we prioritize for intervention when we cannot estimate\nintervention effects? In many applied domains (e.g., advertising, customer\nretention, and behavioral nudging) prioritization is guided by predictive\nmodels that estimate outcome probabilities rather than causal effects. This\npaper investigates when these predictions (scores) can effectively rank\nindividuals by their intervention effects, particularly when direct effect\nestimation is infeasible or unreliable. We propose a conceptual framework based\non amenability: an individual's latent proclivity to be influenced by an\nintervention. We then formalize conditions under which predictive scores serve\nas effective proxies for amenability. These conditions justify using non-causal\nscores for intervention prioritization, even when the scores do not directly\nestimate effects. We further show that, under plausible assumptions, predictive\nmodels can outperform causal effect estimators in ranking individuals by\nintervention effects. Empirical evidence from an advertising context supports\nour theoretical findings, demonstrating that predictive modeling can offer a\nmore robust approach to targeting than effect estimation. Our framework\nsuggests a shift in focus, from estimating effects to inferring who is\namenable, as a practical and theoretically grounded strategy for prioritizing\ninterventions in resource-constrained environments.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-03T10:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.02471v1","title":"Semantic segmentation of forest stands using deep learning","summary":"Forest stands are the fundamental units in forest management inventories,\nsilviculture, and financial analysis within operational forestry. Over the past\ntwo decades, a common method for mapping stand borders has involved delineation\nthrough manual interpretation of stereographic aerial images. This is a\ntime-consuming and subjective process, limiting operational efficiency and\nintroducing inconsistencies. Substantial effort has been devoted to automating\nthe process, using various algorithms together with aerial images and canopy\nheight models constructed from airborne laser scanning (ALS) data, but manual\ninterpretation remains the preferred method. Deep learning (DL) methods have\ndemonstrated great potential in computer vision, yet their application to\nforest stand delineation remains unexplored in published research. This study\npresents a novel approach, framing stand delineation as a multiclass\nsegmentation problem and applying a U-Net based DL framework. The model was\ntrained and evaluated using multispectral images, ALS data, and an existing\nstand map created by an expert interpreter. Performance was assessed on\nindependent data using overall accuracy, a standard metric for classification\ntasks that measures the proportions of correctly classified pixels. The model\nachieved an overall accuracy of 0.73. These results demonstrate strong\npotential for DL in automated stand delineation. However, a few key challenges\nwere noted, especially for complex forest environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.02473v1","title":"Adaptive path planning for efficient object search by UAVs in\n  agricultural fields","summary":"This paper presents an adaptive path planner for object search in\nagricultural fields using UAVs. The path planner uses a high-altitude coverage\nflight path and plans additional low-altitude inspections when the detection\nnetwork is uncertain. The path planner was evaluated in an offline simulation\nenvironment containing real-world images. We trained a YOLOv8 detection network\nto detect artificial plants placed in grass fields to showcase the potential of\nour path planner. We evaluated the effect of different detection certainty\nmeasures, optimized the path planning parameters, investigated the effects of\nlocalization errors and different numbers of objects in the field. The YOLOv8\ndetection confidence worked best to differentiate between true and false\npositive detections and was therefore used in the adaptive planner. The optimal\nparameters of the path planner depended on the distribution of objects in the\nfield, when the objects were uniformly distributed, more low-altitude\ninspections were needed compared to a non-uniform distribution of objects,\nresulting in a longer path length. The adaptive planner proved to be robust\nagainst localization uncertainty. When increasing the number of objects, the\nflight path length increased, especially when the objects were uniformly\ndistributed. When the objects were non-uniformly distributed, the adaptive path\nplanner yielded a shorter path than a low-altitude coverage path, even with\nhigh number of objects. Overall, the presented adaptive path planner allowed to\nfind non-uniformly distributed objects in a field faster than a coverage path\nplanner and resulted in a compatible detection accuracy. The path planner is\nmade available at https://github.com/wur-abe/uav_adaptive_planner.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.02482v1","title":"Berry-Esseen bound for the Moment Estimation of the fractional\n  Ornstein-Uhlenbeck model under fixed step size discrete observations","summary":"Let the Ornstein-Uhlenbeck process $\\{X_t,\\,t\\geq 0\\}$ driven by a fractional\nBrownian motion $B^H$ described by $d X_t=-\\theta X_t dt+ d B_t^H,\\, X_0=0$\nwith known parameter $H\\in (0,\\frac34)$ be observed at discrete time instants\n$t_k=kh, k=1,2,\\dots, n $. If $\\theta>0$ and if the step size $h>0$ is\narbitrarily fixed, we derive Berry-Ess\\'{e}en bound for the ergodic type\nestimator (or say the moment estimator) $\\hat{\\theta}_n$, i.e., the Kolmogorov\ndistance between the distribution of $\\sqrt{n}(\\hat{\\theta}_n-\\theta)$ and its\nlimit distribution is bounded by a constant $C_{\\theta, H,h}$ times\n$n^{-\\frac12}$ and $ n^{4H-3}$ when $H\\in (0,\\,\\frac58]$ and $H\\in\n(\\frac58,\\,\\frac34)$, respectively. This result greatly improve the previous\nresult in literature where $h$ is forced to go zero. Moreover, we extend the\nBerry-Esseen bound to the Ornstein-Uhlenbeck model driven by a lot of Gaussian\nnoises such as the sub-bifractional Brownian motion and others. A few ideas of\nthe present paper come from Haress and Hu (2021), Sottinen and Viitasaari\n(2018), and Chen and Zhou (2021).","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.02491v1","title":"ToMCCA-3: A realistic 3-body coalescence model","summary":"The formation of light nuclei in high-energy collisions provides valuable\ninsights into the underlying dynamics of the strong interaction and the\nstructure of the particle-emitting source. Understanding this process is\ncrucial not only for nuclear physics but also for astrophysical studies, where\nthe production of rare antinuclei could serve as a probe for new physics. This\nwork presents a three-body coalescence model based on the Wigner function\nformalism, offering a refined description of light-nucleus production. By\nincorporating realistic two- and three-body nuclear interaction potentials\nconstrained by modern scattering and femtoscopic correlation data, our approach\nimproves on traditional coalescence models. The framework is validated using\nevent generators applied to proton-proton collisions at $\\sqrt{s}=13$ TeV to\npredict the momentum spectra of light (anti) nuclear nuclei with mass number\n$A=3$, which are then compared with the experimental data from ALICE. Our\nresults demonstrate the sensitivity of light nucleus yields to the choice of\nnuclear wave functions, emphasizing the importance of an accurate description\nof the coalescence process. This model lays the foundation for the extension of\ncoalescence studies of $A=3$ light nuclei to a wider range of collision systems\nand energies.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T11:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.02495v1","title":"Inference-Time Scaling for Generalist Reward Modeling","summary":"Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T11:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.02499v1","title":"The Gradient of Mean Molecular Weight Across the Radius Valley","summary":"Photo-evaporation shapes the observed radii of small exoplanets and\nconstrains the underlying distributions of atmospheric and core masses.\nHowever, the diversity of atmospheric chemistries corresponding to these\ndistributions remains unelucidated. We develop a first-principles\ncarbon-hydrogen-oxygen-sulfur-silicon (CHOSSi) outgassing model that accounts\nfor non-ideal gas behavior (via fugacities) at high pressures, as well as the\ntendency for water and hydrogen to dissolve in melt (via solubility laws). We\nuse data-driven radius valley constraints to establish the relationship between\nthe atmospheric surface pressures and melt temperatures of sub-Neptunes.\nSub-Neptunes with less massive rocky cores retain less of their primordial\nhydrogen envelopes, which leads to less heat retention and diminished melt\ntemperatures at the surfaces of these cores. Lower melt temperatures lead\nthermodynamically to the dominance of carbon-, oxygen-, sulfur- and\nsilicon-bearing molecules over molecular hydrogen, which naturally produce a\ndiversity of mean molecular weights. Our geochemical outgassing calculations\nrobustly predict a gradient of mean molecular weight across the radius valley,\nwhere the strength of this gradient is primarily driven by the oxygen fugacity\nof the molten cores and not by the carbon enrichment (or \"metallicity\") of the\natmosphere. Smaller sub-Neptunes are predicted to have less hydrogen-dominated\natmospheres. The precise relationship between the observed and outgassed\nchemistries requires an understanding of how convection near the core interacts\nwith large-scale atmospheric circulation (driven by stellar heating) near the\nphotosphere, as well as the influence of photochemistry.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph,physics.geo-ph","published":"2025-04-03T11:22:08Z"}
{"aid":"http://arxiv.org/abs/2504.02525v1","title":"Detection of cosmological dipoles aligned with transverse peculiar\n  velocities","summary":"We present the first observations of a novel dipole signature imprinted on\nthe CMB by transverse velocities. Cosmological peculiar velocities point\ntowards gravitational wells and away from potential hills, reflecting a\nlarge-scale dipole in the gravitational potential, coherent over hundreds of\nMpc. We predict large-scale dipoles in all fields correlated with the\npotential, observable via effects of gravitational lensing and the integrated\nSachs-Wolfe (ISW). The ISW dipole is distinct from the small-scale moving lens\neffect, which has a dipole of the opposite sign. We provide a unified framework\nfor analysing these dipoles, and make the first detections in galaxy density,\nCMB lensing convergence and the ISW effect. We show that the observed signals\nare consistent with LCDM predictions, and set limits on modified gravity. The\nCMB dipole signal is independent of galaxy bias, and orthogonal to the monopole\ncorrelation function, so this new observable provides additional cosmological\ninformation (abridged).","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-03T12:29:36Z"}
{"aid":"http://arxiv.org/abs/2504.02528v1","title":"RAFFLE: Active learning accelerated interface structure prediction","summary":"Interfaces between materials play a crucial role in the performance of most\ndevices. However, predicting the structure of a material interface is\ncomputationally demanding due to the vast configuration space, which requires\nevaluating an unfeasibly large number of highly complex structures. We\nintroduce RAFFLE, a software package designed to efficiently explore low-energy\ninterface configurations between any two crystals. RAFFLE leverages physical\ninsights and genetic algorithms to intelligently sample the configuration\nspace, using dynamically evolving 2-, 3-, and 4-body distribution functions as\ngeneralised structural descriptors. These descriptors are iteratively updated\nthrough active learning, which inform atom placement strategies. RAFFLE's\neffectiveness is demonstrated across a diverse set of systems, including bulk\nmaterials, intercalation structures, and interfaces. When tested on bulk\naluminium and MoS$_2$, it successfully identifies known ground-state and\nhigh-pressure phases. Applied to intercalation systems, it predicts stable\nintercalant phases. For Si|Ge interfaces, RAFFLE identifies intermixing as a\nstrain compensation mechanism, generating reconstructions that are more stable\nthan abrupt interfaces. By accelerating interface structure prediction, RAFFLE\noffers a powerful tool for materials discovery, enabling efficient exploration\nof complex configuration spaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn","published":"2025-04-03T12:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.02529v1","title":"Probabilistic Simulation of Aircraft Descent via a Hybrid Physics-Data\n  Approach","summary":"This paper presents a method for generating probabilistic descent\ntrajectories in simulations of real-world airspace. A dataset of 116,066\ntrajectories harvested from Mode S radar returns in UK airspace was used to\ntrain and test the model. Thirteen aircraft types with varying performance\ncharacteristics were investigated. It was found that the error in the mean\nprediction of time to reach the bottom of descent for the proposed method was\nless than that of the the Base of Aircraft Data (BADA) model by a factor of 10.\nFurthermore, the method was capable of generating a range of trajectories that\nwere similar to the held out test dataset when analysed in distribution. The\nproposed method is hybrid, with aircraft drag and calibrated airspeed functions\ngenerated probabilistically to parameterise the BADA equations, ensuring the\nphysical plausibility of generated trajectories.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T12:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.02543v1","title":"Probabilistic Pontryagin's Maximum Principle for Continuous-Time\n  Model-Based Reinforcement Learning","summary":"Without exact knowledge of the true system dynamics, optimal control of\nnon-linear continuous-time systems requires careful treatment of epistemic\nuncertainty. In this work, we propose a probabilistic extension to Pontryagin's\nmaximum principle by minimizing the mean Hamiltonian with respect to epistemic\nuncertainty. We show minimization of the mean Hamiltonian is a necessary\noptimality condition when optimizing the mean cost, and propose a multiple\nshooting numerical method scalable to large-scale probabilistic dynamical\nmodels, including ensemble neural ordinary differential equations. Comparisons\nagainst state-of-the-art methods in online and offline model-based\nreinforcement learning tasks show that our probabilistic Hamiltonian\nformulation leads to reduced trial costs in offline settings and achieves\ncompetitive performance in online scenarios. By bridging optimal control and\nreinforcement learning, our approach offers a principled and practical\nframework for controlling uncertain systems with learned dynamics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T12:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.02549v1","title":"Emergent version of Drinfeld's associator equations","summary":"The works of Alekseev and Torossian [AT] and Alekseev, Enriquez, and\nTorossian [AET] show that any solution of Drinfeld's associator equations gives\nrise to a solution of the Kashiwara-Vergne equations in an explicit way. We\nintroduce a weak version of Drinfeld's associator equations that we call the\nemergent version of the original equations. It is shown that solutions to the\nresulting linearized emergent Drinfeld's equations still lead to solutions to\nthe linearized Kashiwara-Vergne equations.\n  The emergent Drinfeld equations arise within a natural topological context of\nemergent braids, which we discuss. Our results are adjacent to the results of\nBar-Natan, Dancso, Hogan, Liu and Scherich [BDHLS] on the relationship between\nemergent tangles and the Goldman-Turaev Lie bialgebra. We hope that in time our\nresults will play a role in relating several bodies of work, on Drinfeld\nassociators, Kashiwara-Vergne equations, and on expansions for classical\ntangles, for w-tangles, and for the Goldman-Turaev Lie bialgebra.","main_category":"math.GT","categories":"math.GT,math.QA","published":"2025-04-03T13:02:04Z"}
{"aid":"http://arxiv.org/abs/2504.02561v1","title":"Digital Twins for Internet of Battlespace Things (IoBT) Coalitions","summary":"This paper presents a new framework for integrating Digital Twins (DTs)\nwithin Internet of battlespace Things (IoBT) coalitions. We introduce a novel\nthree-tier architecture that enables efficient coordination and management of\nDT models across coalition partners while addressing key challenges in\ninteroperability, security, and resource allocation. The architecture comprises\nspecialized controllers at each tier: Digital Twin Coalition Partner (DTCP)\ncontrollers managing individual coalition partners' DT resources, a central\nDigital Twin Coalition(DTC) controller orchestrating cross-partner\ncoordination, and Digital Twin Coalition Mission (DTCP) controllers handling\nmission-specific DT interactions. We propose a hybrid approach for DT model\nplacement across edge devices, tactical nodes, and cloud infrastructure,\noptimizing performance while maintaining security and accessibility. The\narchitecture leverages software-defined networking principles for dynamic\nresource allocation and slice management, enabling efficient sharing of\ncomputational and network resources between DT operations and primary IoBT\nfunctions. Our proposed framework aims to provide a robust foundation for\ndeploying and managing Digital Twins in coalition warfare, enhancing\nsituational awareness, decision-making capabilities, and operational\neffectiveness while ensuring secure and interoperable operations across diverse\ncoalition partners.","main_category":"cs.NI","categories":"cs.NI,cs.SY,eess.SY","published":"2025-04-03T13:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.02588v1","title":"Topological signatures of collective dynamics and turbulent-like energy\n  cascades in active granular matter","summary":"Active matter refers to a broad class of non-equilibrium systems where energy\nis continuously injected at the level of individual ``particles.\" These systems\nexhibit emergent collective behaviors that have no direct thermal-equilibrium\ncounterpart. Their scale ranges from micrometer-sized swarms of bacteria to\nmeter-scale human crowds. In recent years, the role of topology and\nself-propelled topological defects in active systems has garnered significant\nattention, particularly in polar and nematic active matter. Building on these\nideas, we investigate emergent collective dynamics in apolar active granular\nfluids. Using granular vibrators as a model experimental system of apolar\nactive Brownian particles in a dry environment, we uncover a distinctive\nthree-stage time evolution arising from the intricate interplay between\nactivity and inelastic interactions. By analyzing the statistics, spatial\ncorrelations, and dynamics of vortex-like topological defects in the\ndisplacement vector field, we demonstrate their ability to describe and predict\nthis intrinsic collective motion. Furthermore, we show that topological defects\nplay a crucial role in the development of a turbulent-like inverse energy\ncascade, where kinetic energy transfers across different length scales over\ntime. As the system evolves, the power scaling of the energy transfer increases\nwith the duration of observation. Our findings demonstrate how topological\nconcepts can be applied to predict macroscopic collective phenomena in apolar\nactive matter. This establishes a direct link between microscopic topological\ndynamics and large-scale behaviors in active granular fluids.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T13:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.02604v1","title":"LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech\n  Recognition in Tunisian Arabic Dialect","summary":"Developing Automatic Speech Recognition (ASR) systems for Tunisian Arabic\nDialect is challenging due to the dialect's linguistic complexity and the\nscarcity of annotated speech datasets. To address these challenges, we propose\nthe LinTO audio and textual datasets -- comprehensive resources that capture\nphonological and lexical features of Tunisian Arabic Dialect. These datasets\ninclude a variety of texts from numerous sources and real-world audio samples\nfeaturing diverse speakers and code-switching between Tunisian Arabic Dialect\nand English or French. By providing high-quality audio paired with precise\ntranscriptions, the LinTO audio and textual datasets aim to provide qualitative\nmaterial to build and benchmark ASR systems for the Tunisian Arabic Dialect.\n  Keywords -- Tunisian Arabic Dialect, Speech-to-Text, Low-Resource Languages,\nAudio Data Augmentation","main_category":"cs.CL","categories":"cs.CL,cs.SD,eess.AS","published":"2025-04-03T14:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.02606v1","title":"Improving Counterfactual Truthfulness for Molecular Property Prediction\n  through Uncertainty Quantification","summary":"Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T14:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.02623v1","title":"Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents\n  through Related and Dynamic Missions","summary":"Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T14:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.02635v1","title":"Continuous two-valued discrete-time dynamical systems and actions of\n  two-valued groups","summary":"We study continuous 2-valued dynamical systems with discrete time (dynamics)\non $\\mathbb{C}$. The main question addressed is whether a 2-valued dynamics can\nbe defined by the action of a 2-valued group. We construct a class of strongly\ninvertible continuous 2-valued dynamics on $\\mathbb{C}$ such that none of these\ndynamics can be given by the action of any 2-valued group. We also construct an\nexample of a continuous 2-valued dynamics on $\\mathbb{C}$ that is not strongly\ninvertible but can be defined by the action of a 2-valued group.","main_category":"math.GR","categories":"math.GR,math.DS,math.GT","published":"2025-04-03T14:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.02636v1","title":"A Framework for Developing University Policies on Generative AI\n  Governance: A Cross-national Comparative Study","summary":"As generative artificial intelligence (GAI) becomes more integrated into\nhigher education and research, universities adopt varied approaches to GAI\npolicy development. To explore these variations, this study conducts a\ncomparative analysis of leading universities in the United States, Japan, and\nChina, examining their institution-wide policies on GAI application and\ngovernance. Based on these findings, the study proposes a University Policy\nDevelopment Framework for GAI (UPDF-GAI) to provide both theoretical insights\nand practical guidance for universities in developing and refining their GAI\npolicies. A qualitative content analysis of 124 policy documents from 110\nuniversities was conducted, employing thematic coding to synthesize 20 key\nthemes and 9 sub-themes. These themes and sub-themes formed the basis for\ndeveloping the framework. The analysis reveals varying priorities and focus of\nGAI policy of universities in different countries. U.S. universities emphasize\nfaculty autonomy, practical application, and policy adaptability, shaped by\ncutting-edge research and peer collaboration. Japanese universities take a\ngovernment-regulated approach, prioritizing ethics and risk management, but\nprovide limited support for AI implementation and flexibility. Chinese\nuniversities follow a centralized, government-led model, focusing on technology\napplication over early policy development, while actively exploring GAI\nintegration in education and research. The UPDF-GAI framework offers a\nsystematic, adaptable framework for assessing and optimizing GAI policies\nacross different educational contexts. By identifying key policy\ncharacteristics, enhancing policy effectiveness, and balancing technology,\nethics, and education, enabling universities to develop sustainable,\ncontextually relevant policies that strengthen their digital competitiveness\nand institutional readiness for AI-driven education.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-03T14:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.02645v1","title":"Black Holes, Moduli Stabilisation and the Swampland","summary":"In theories with moduli, extremal black holes behave such that for generic\ninitial conditions, the distance traveled by the scalars from infinity to the\nhorizon can grow with the size of the black hole. This, in turn, implies that\nlarger black holes can probe more of the UV ingredients of the theory, in\ncontrast with (naive) EFT expectations. We relate this discrepancy to the lack\nof cosmological moduli stabilisation. Indeed, for would-be scale-separated\nstring vacua with parametrically heavy stabilised scalars -- dubbed\n\\emph{rigid} compactifications -- one recovers the EFT intuition where only\nsmall black holes probe the UV. We make this explicit in a toy model and then\nturn to top-down models and construct near-horizon solutions in IIA\nscale-separated compactifications with stabilised moduli. In these top-down\nmodels we still observe large field variations for large black holes which can\nbe traced back to the absence of parametrically heavy moduli. We are led to\nspeculate that needing UV physics to allow for non-local effects near the\nhorizon of large black holes is at odds with having a rigid compactification,\nhinting to the possibility that such compactifications are in the Swampland.","main_category":"hep-th","categories":"hep-th","published":"2025-04-03T14:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.02647v1","title":"Adaptive Frequency Enhancement Network for Remote Sensing Image Semantic\n  Segmentation","summary":"Semantic segmentation of high-resolution remote sensing images plays a\ncrucial role in land-use monitoring and urban planning. Recent remarkable\nprogress in deep learning-based methods makes it possible to generate\nsatisfactory segmentation results. However, existing methods still face\nchallenges in adapting network parameters to various land cover distributions\nand enhancing the interaction between spatial and frequency domain features. To\naddress these challenges, we propose the Adaptive Frequency Enhancement Network\n(AFENet), which integrates two key components: the Adaptive Frequency and\nSpatial feature Interaction Module (AFSIM) and the Selective feature Fusion\nModule (SFM). AFSIM dynamically separates and modulates high- and low-frequency\nfeatures according to the content of the input image. It adaptively generates\ntwo masks to separate high- and low-frequency components, therefore providing\noptimal details and contextual supplementary information for ground object\nfeature representation. SFM selectively fuses global context and local detailed\nfeatures to enhance the network's representation capability. Hence, the\ninteractions between frequency and spatial features are further enhanced.\nExtensive experiments on three publicly available datasets demonstrate that the\nproposed AFENet outperforms state-of-the-art methods. In addition, we also\nvalidate the effectiveness of AFSIM and SFM in managing diverse land cover\ntypes and complex scenarios. Our codes are available at\nhttps://github.com/oucailab/AFENet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.02664v1","title":"How humans evaluate AI systems for person detection in automatic train\n  operation: Not all misses are alike","summary":"If artificial intelligence (AI) is to be applied in safety-critical domains,\nits performance needs to be evaluated reliably. The present study aimed to\nunderstand how humans evaluate AI systems for person detection in automatic\ntrain operation. In three experiments, participants saw image sequences of\npeople moving in the vicinity of railway tracks. A simulated AI had highlighted\nall detected people, sometimes correctly and sometimes not. Participants had to\nprovide a numerical rating of the AI's performance and then verbally explain\ntheir rating. The experiments varied several factors that might influence human\nratings: the types and plausibility of AI mistakes, the number of affected\nimages, the number of people present in an image, the position of people\nrelevant to the tracks, and the methods used to elicit human evaluations. While\nall these factors influenced human ratings, some effects were unexpected or\ndeviated from normative standards. For instance, the factor with the strongest\nimpact was people's position relative to the tracks, although participants had\nexplicitly been instructed that the AI could not process such information.\nTaken together, the results suggest that humans may sometimes evaluate more\nthan the AI's performance on the assigned task. Such mismatches between AI\ncapabilities and human expectations should be taken into consideration when\nconducting safety audits of AI systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.02666v1","title":"BECAME: BayEsian Continual Learning with Adaptive Model MErging","summary":"Continual Learning (CL) strives to learn incrementally across tasks while\nmitigating catastrophic forgetting. A key challenge in CL is balancing\nstability (retaining prior knowledge) and plasticity (learning new tasks).\nWhile representative gradient projection methods ensure stability, they often\nlimit plasticity. Model merging techniques offer promising solutions, but prior\nmethods typically rely on empirical assumptions and carefully selected\nhyperparameters. In this paper, we explore the potential of model merging to\nenhance the stability-plasticity trade-off, providing theoretical insights that\nunderscore its benefits. Specifically, we reformulate the merging mechanism\nusing Bayesian continual learning principles and derive a closed-form solution\nfor the optimal merging coefficient that adapts to the diverse characteristics\nof tasks. To validate our approach, we introduce a two-stage framework named\nBECAME, which synergizes the expertise of gradient projection and adaptive\nmerging. Extensive experiments show that our approach outperforms\nstate-of-the-art CL methods and existing merging strategies.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T15:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.02674v1","title":"Limitations of Religious Data and the Importance of the Target Domain:\n  Towards Machine Translation for Guinea-Bissau Creole","summary":"We introduce a new dataset for machine translation of Guinea-Bissau Creole\n(Kiriol), comprising around 40 thousand parallel sentences to English and\nPortuguese. This dataset is made up of predominantly religious data (from the\nBible and texts from the Jehovah's Witnesses), but also a small amount of\ngeneral domain data (from a dictionary). This mirrors the typical resource\navailability of many low resource languages. We train a number of\ntransformer-based models to investigate how to improve domain transfer from\nreligious data to a more general domain. We find that adding even 300 sentences\nfrom the target domain when training substantially improves the translation\nperformance, highlighting the importance and need for data collection for\nlow-resource languages, even on a small-scale. We additionally find that\nPortuguese-to-Kiriol translation models perform better on average than other\nsource and target language pairs, and investigate how this relates to the\nmorphological complexity of the languages involved and the degree of lexical\noverlap between creoles and lexifiers. Overall, we hope our work will stimulate\nresearch into Kiriol and into how machine translation might better support\ncreole languages in general.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.02708v1","title":"The Hidden Space of Safety: Understanding Preference-Tuned LLMs in\n  Multilingual context","summary":"Alignment tuning has enabled large language models to excel in reasoning,\ninstruction-following, and minimizing harmful generations. However, despite\ntheir widespread deployment, these models exhibit a monolingual bias, raising\nconcerns about the effectiveness of alignment across languages. Current\nalignment methods predominantly focus on English, leaving it unclear how\nalignment mechanism generalize to multilingual settings. To address this, we\nconduct a systematic analysis of distributional shifts in the embedding space\nof LLMs before and after alignment, uncovering its impact on model behavior\nacross diverse languages. We leverage the alignment-induced separation in\nsafety space as a quantitative tool to measure how alignment enforces safety\nconstraints. Our study evaluates seven LLMs using balanced toxicity datasets\nand parallel text-detoxification benchmarks, revealing substantial disparities\nin the latent representation space between high-resource and low-resource\nlanguages. These findings underscore the need for language-specific fine-tuning\nto ensure fair, reliable and robust multilingual alignment. Our insights\nprovide a foundation for developing truly safe multilingual LLMs, emphasizing\nthe urgency of addressing alignment gaps in underrepresented languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.02717v1","title":"Clustering in a preferential attachment network with triangles","summary":"We study a generalization of the affine preferential attachment model where\ntriangles are randomly added to the graph. We show that the model exhibits an\nasymptotically power-law degree distribution with adjustable parameter\n$\\gamma\\in (1,\\infty)$, and positive clustering. However, the clustering\nbehaviour depends on how it is measured. With high probability, the average\nlocal clustering coefficient remains positive, independently of $\\gamma$,\nwhereas the expectation of the global clustering coefficient does not vanish\nonly when $\\gamma>3$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T16:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.02733v1","title":"Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study","summary":"Large Language Models (LLMs) are highly vulnerable to input perturbations, as\neven a small prompt change may result in a substantially different output.\nExisting methods to enhance LLM robustness are primarily focused on perturbed\ndata samples, whereas improving resiliency to perturbations of task-level\ninstructions has remained relatively underexplored. In this work, we focus on\ncharacter- and word-level edits of task-specific instructions, which\nsubstantially degrade downstream performance. We experiment with a variety of\ntechniques to enhance the robustness of LLMs, including self-denoising and\nrepresentation alignment, testing different models (Llama 3 and Flan-T5),\ndatasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and\nrole-oriented). We find that, on average, self-denoising -- whether performed\nby a frozen LLM or a fine-tuned model -- achieves substantially higher\nperformance gains than alternative strategies, including more complex baselines\nsuch as ensembling and supervised methods.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:56Z"}
{"aid":"http://arxiv.org/abs/2504.02742v1","title":"Quantum synchronization blockade induced by nonreciprocal coupling","summary":"Recently, the synchronization of coupled quantum oscillators has attracted a\ngreat deal of interest. Synchronization requires driven constituents, and in\nsuch systems, the coupling can be designed to be nonreciprocal.\nNonreciprocally-coupled oscillators exhibit a rich variety of behavior\nincluding active traveling-wave type states. In this work, we study the\ninterplay of three competing synchronization mechanisms in a setup of two\nnonreciprocally-coupled quantum van der Pol oscillators. One of the oscillators\nis driven externally which induces phase locking. A dissipative interaction\nleads to anti-phase locking, whereas a coherent interaction nurtures bistable\nphase locking and active states. We approximate the phase diagram of the\nquantum case by evaluating the synchronization measure of a perturbation\nexpansion of the steady state. Furthermore, we study the phase diagrams of two\nand three oscillators in the mean-field limit and find highly nontrivial active\nstates.","main_category":"quant-ph","categories":"quant-ph,nlin.PS","published":"2025-04-03T16:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.02749v1","title":"Bacon-Shor Board Games","summary":"We identify a period-4 measurement schedule for the checks of the Bacon-Shor\ncode that fully covers spacetime with constant-weight detectors, and is\nnumerically observed to provide the code with a threshold. Unlike previous\napproaches, our method does not rely on code concatenation and instead arises\nas the solution to a coloring game on a square grid. Under a uniform\ncircuit-level noise model, we observe a threshold of approximately $0.3\\%$ when\ndecoding with minimum weight perfect matching, and we conjecture that this\ncould be improved using a more tailored decoder.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-03T16:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.02756v1","title":"Stability of acoustic streaming jets","summary":"We study the stability of a steady Eckart streaming jet that is acoustically\nforced at one end of a closed cylindrical cavity and impinges the wall at the\nother end, where a recirculation forms. This configuration generically\nrepresents industrial processes where acoustic forcing offers a contactless\nmeans of stirring or controlling confined flows. Successfully doing so,\nhowever, requires sufficient insight into the topology of the acoustically\nforced flow. This raises the question of whether the base acoustic streaming\njet is stable and, when not, of which alternative states emerge. Using Linear\nStability Analysis (LSA) and three-dimensional nonlinear simulations, we\nidentify the instability mechanisms and determine the nature of the\nbifurcations that ensue. We show that the ratio $C_R$ between the cavity and\nthe maximum beam radii determines the dominant unstable mode. For $4 \\leq C_R\n\\leq 6$, a non-oscillatory perturbation rooted in the jet impingement triggers\na supercritical bifurcation. For $C_R = 3$, the flow destabilises through a\nsubcritical non-oscillatory bifurcation. Further reducing $C_R$ increases the\nshear within the flow, and gradually relocates the instability in the shear\nlayer between impingement-induced vortices: for $C_R = 2$, an unstable\ntravelling wave grows out of a subcritical bifurcation, which becomes\nsupercritical for $C_R=1$. For each geometry, the nonlinear 3D simulations\nvalidate the LSA, identify the saturated nonlinear state and its stability.\nThis study offers fundamental insight into the stability of acoustically-driven\nflows in general, but also opens possible pathways to either induce turbulence\nacoustically, or to avoid it in realistic configurations.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T16:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.02782v1","title":"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image\n  Generation","summary":"The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:23:16Z"}
{"aid":"http://arxiv.org/abs/2504.02823v1","title":"STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage\n  Security Inspection","summary":"Advancements in Computer-Aided Screening (CAS) systems are essential for\nimproving the detection of security threats in X-ray baggage scans. However,\ncurrent datasets are limited in representing real-world, sophisticated threats\nand concealment tactics, and existing approaches are constrained by a\nclosed-set paradigm with predefined labels. To address these challenges, we\nintroduce STCray, the first multimodal X-ray baggage security dataset,\ncomprising 46,642 image-caption paired scans across 21 threat categories,\ngenerated using an X-ray scanner for airport security. STCray is meticulously\ndeveloped with our specialized protocol that ensures domain-aware, coherent\ncaptions, that lead to the multi-modal instruction following data in X-ray\nbaggage security. This allows us to train a domain-aware visual AI assistant\nnamed STING-BEE that supports a range of vision-language tasks, including scene\ncomprehension, referring threat localization, visual grounding, and visual\nquestion answering (VQA), establishing novel baselines for multi-modal learning\nin X-ray baggage security. Further, STING-BEE shows state-of-the-art\ngeneralization in cross-domain settings. Code, data, and models are available\nat https://divs1159.github.io/STING-BEE/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.04719v1","title":"Observations of fast radio variations in microquasars by FAST","summary":"Microquasars are the compact objects generally including accreting black\nholes which produce relativistic jets. The physical mechanisms of jet\nlaunching, collimation, and acceleration are poorly understood. Microquasars\nshow strong variability in multi-wavelength observations. In X-rays, the\nsources show the fast variation features down to millisecond time scales, with\nthe prominent quasiperiodic oscillations (QPOs) around 0.1 Hz - tens of Hz in\nlight curves, however, physical origin of QPOs is still uncertain. FAST as the\nlargest radio telescope provides the opportunity to study fast variability of\nboth radio flux and polarization in microquasars. In the FAST observations from\n2020 - 2022, we reported the first evidence of radio subsecond quasi-periodic\noscillations of GRS 1915+105, providing the direct link between QPOs and the\ndynamics of relativistic jets. These QPOs with the centroid frequency around 5\nHz are transient, accompanied with strong evolution of the spectral index.\nCombined with multiwavelength observations, we discuss the possible physical\nmodels to produce radio QPOs in BH systems: the helical motion of jet knots or\nprecession of the jet base. In near future, high time resolution radio\nmonitoring of microquasars based on FAST is expected to discover more new\nphenomena in black hole systems, which will be important to understand the\nphysics in strong gravity.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T04:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04723v1","title":"Quantum Incompatibility in Parallel vs Antiparallel Spins","summary":"We investigate the joint measurability of incompatible quantum observables on\nensembles of parallel and antiparallel spin pairs. In parallel configuration,\ntwo systems are identically prepared, whereas in antiparallel configuration\neach system is paired with its spin-flipped counterpart. We demonstrate that\nthe antiparallel configuration enables exact simultaneous prediction of three\nmutually orthogonal spin components -- an advantage unattainable in the\nparallel case. As we show, this enhanced measurement compatibility in\nantiparallel configuration is better explained within the framework of\ngeneralized probabilistic theories, which allow a broader class of composite\nstructures while preserving quantum descriptions at the subsystem level.\nFurthermore, this approach extends the study of measurement incompatibility to\nmore general configurations beyond just the parallel and antiparallel cases,\nproviding deeper insights into the boundary between physical and unphysical\nquantum state evolutions. To this end, we discuss how the enhanced measurement\ncompatibility in antiparallel configuration can be observed on a finite\nensemble of qubit states, paving the way for an experimental demonstration of\nthis advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T04:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04731v1","title":"A High-Performance Curve25519 and Curve448 Unified Elliptic Curve\n  Cryptography Accelerator","summary":"In modern critical infrastructure such as power grids, it is crucial to\nensure security of data communications between network-connected devices while\nfollowing strict latency criteria. This necessitates the use of cryptographic\nhardware accelerators. We propose a high-performance unified elliptic curve\ncryptography accelerator supporting NIST standard Montgomery curves Curve25519\nand Curve448 at 128-bit and 224-bit security levels respectively. Our\naccelerator implements extensive parallel processing of Karatsuba-style\nlarge-integer multiplications, restructures arithmetic operations in the\nMontgomery Ladder and exploits special mathematical properties of the\nunderlying pseudo-Mersenne and Solinas prime fields for optimized performance.\nOur design ensures efficient resource sharing across both curve computations\nand also incorporates several standard side-channel countermeasures. Our ASIC\nimplementation achieves record performance and energy of 10.38 $\\mu$s / 54.01\n$\\mu$s and 0.72 $\\mu$J / 3.73 $\\mu$J respectively for Curve25519 / Curve448,\nwhich is significantly better than state-of-the-art.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T05:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.04753v1","title":"CADCrafter: Generating Computer-Aided Design Models from Unconstrained\n  Images","summary":"Creating CAD digital twins from the physical world is crucial for\nmanufacturing, design, and simulation. However, current methods typically rely\non costly 3D scanning with labor-intensive post-processing. To provide a\nuser-friendly design process, we explore the problem of reverse engineering\nfrom unconstrained real-world CAD images that can be easily captured by users\nof all experiences. However, the scarcity of real-world CAD data poses\nchallenges in directly training such models. To tackle these challenges, we\npropose CADCrafter, an image-to-parametric CAD model generation framework that\ntrains solely on synthetic textureless CAD data while testing on real-world\nimages. To bridge the significant representation disparity between images and\nparametric CAD models, we introduce a geometry encoder to accurately capture\ndiverse geometric features. Moreover, the texture-invariant properties of the\ngeometric features can also facilitate the generalization to real-world\nscenarios. Since compiling CAD parameter sequences into explicit CAD models is\na non-differentiable process, the network training inherently lacks explicit\ngeometric supervision. To impose geometric validity constraints, we employ\ndirect preference optimization (DPO) to fine-tune our model with the automatic\ncode checker feedback on CAD sequence quality. Furthermore, we collected a\nreal-world dataset, comprised of multi-view images and corresponding CAD\ncommand sequence pairs, to evaluate our method. Experimental results\ndemonstrate that our approach can robustly handle real unconstrained CAD\nimages, and even generalize to unseen general objects.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T06:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.04755v1","title":"Effects of Surface Corrugation on Gas-Surface Scattering and Macroscopic\n  Flows","summary":"Gas-surface scattering exhibits a transition from thermal to structure\nscattering regime as incident energy increases, characterized by changes in\nangular and energy distributions. Capturing scattering behavior across\ndifferent regimes is essential for modeling momentum and energy exchange at the\ngas-surface interface. This study presents a corrugated Cercignani-Lampis-Lord\n(CLL) model to account for surface corrugation in scattering. It extends the\nwashboard-CLL hybrid approach by incorporating tangential momentum\naccommodation in local collisions. The model is validated against molecular\nbeam scattering experiments, focusing on its ability to reproduce the variation\nin scattering behavior with increasing incident energy. Compared to the\nconventional CLL model, the proposed model qualitatively improves the\nrepresentation of key features across the scattering regimes. In particular, it\ncaptures broader angular distributions and increasing reflected energy with\nreflected angle at higher incident energy. It is further applied to Direct\nSimulation Monte-Carlo (DSMC) analysis of rarefied flows over a cylinder and\nwithin an intake to examine the influence of surface corrugation on macroscopic\nflow behavior. The results show that surface corrugation has limited impact on\ntotal drag, while decreasing pressure drag and increasing friction drag. In the\nintake, enhanced tangential accommodation reduces capture efficiency and\nincreases compression ratio. These findings highlight the importance of\nincorporating surface corrugation in rarefied flow simulations under VLEO\nconditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T06:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.04762v1","title":"Extension of Yager's negation of probability distribution based on\n  uncertainty measures","summary":"Existing research on negations primarily focuses on entropy and extropy.\nRecently, new functions such as varentropy and varextropy have been developed,\nwhich can be considered as\n  extensions of entropy and extropy. However, the impact of negation on these\nextended measures, particularly varentropy and varextropy, has not been\nextensively explored. To address\n  this gap, this paper investigates the effect of negation on Shannon entropy,\nvarentropy, and varextropy. We explore how the negation of a probability\ndistribution influences these\n  measures, showing that the negated distribution consistently leads to higher\nvalues of Shannon entropy, varentropy, and varextropy compared to the original\ndistribution.\n  Additionally, we prove that the negation of a probability distribution\nmaximizes these measures during the process. The paper provides theoretical\nproofs and a detailed analysis of\n  the behaviour of these measures, contributing to a better understanding of\nthe interplay between probability distributions, negation, and\ninformation-theoretic quantities.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T06:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.04775v1","title":"Low-Count X-ray Polarimetry using the Bayesian Approach Reveals Fast\n  Polarization Angle Variations","summary":"X-ray polarimetry of accreting compact object has revealed fast time\nvariations in the polarization angle (PA), suggesting that the geometry and/or\noptical depth of the corona is changing rapidly. This prompts investigations\ninto how fast such variability can be. Conventionally, the data are often\nbinned to examine the time variability such that the measurement in each bin is\nabove the minimum detectable polarization (MDP). Here we demonstrate that this\nis unnecessary, and even below the MDP, one can infer the posterior\ndistribution of PA reliably using the Bayesian approach and still be able to\nplace useful constraints on the physics in many cases. With this approach, we\ndiscovered that the PA variation in one of the Imaging X-ray Polarimetry\nExplorer (IXPE) observations of GX 13+1 is not following a linear rotation mode\nas suggested previously. Instead, the PA swings between two discrete angles,\nsuggesting that there are two emitting components, e.g., the boundary layer and\nthe spreading layer, competing with each other. Also in one of the observations\nof GX 13+1 and Sco X-1, the PA is found to vary in correlation with the source\ncount rate, indicating that the mass accretion rate is shaping the corona\nproperties. Also, during the IXPE observation of Sco X-1, the PA in highest\nflux level seems to deviate from the averaged value and appear to be consistent\nwith previous measurement results with PolarLight and OSO-8.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T07:09:08Z"}
{"aid":"http://arxiv.org/abs/2504.04780v1","title":"Bottom-Up Scattering Information Perception Network for SAR target\n  recognition","summary":"Deep learning methods based synthetic aperture radar (SAR) image target\nrecognition tasks have been widely studied currently. The existing deep methods\nare insufficient to perceive and mine the scattering information of SAR images,\nresulting in performance bottlenecks and poor robustness of the algorithms. To\nthis end, this paper proposes a novel bottom-up scattering information\nperception network for more interpretable target recognition by constructing\nthe proprietary interpretation network for SAR images. Firstly, the localized\nscattering perceptron is proposed to replace the backbone feature extractor\nbased on CNN networks to deeply mine the underlying scattering information of\nthe target. Then, an unsupervised scattering part feature extraction model is\nproposed to robustly characterize the target scattering part information and\nprovide fine-grained target representation. Finally, by aggregating the\nknowledge of target parts to form the complete target description, the\ninterpretability and discriminative ability of the model is improved. We\nperform experiments on the FAST-Vehicle dataset and the SAR-ACD dataset to\nvalidate the performance of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:15:08Z"}
{"aid":"http://arxiv.org/abs/2504.04792v1","title":"Uniqueness and Longtime Behavior of the Completely Positively Correlated\n  Symbiotic Branching Model","summary":"The symbiotic branching model in $\\mathbb{R}$ describes the behavior of two\nbranching populations migrating in space $\\mathbb{R}$ in terms of a\ncorresponding system of stochastic partial differential equations. The system\nis parametrized with a correlation parameter $\\rho$, which takes values in\n$[-1,1]$ and governs the correlation between the branching mechanisms of the\ntwo populations. While existence and uniqueness for this system were\nestablished for $\\rho \\in [-1,1)$, weak uniqueness for the completely\npositively correlated case of $\\rho = 1$ has been an open problem. In this\npaper, we resolve this problem, establishing weak uniqueness for the\ncorresponding system of stochastic partial differential equations. The proof\nuses a new duality between the symbiotic branching model and the well-known\nparabolic Anderson model. Furthermore, we use this duality to investigate the\nlong-term behavior of the completely positively correlated symbiotic branching\nmodel. We show that, under suitable initial conditions, after a long time, one\nof the populations dies out. We treat the case of integrable initial conditions\nand the case of bounded non-integrable initial conditions with well-defined\nmean.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.04803v1","title":"Out of Sight, Still at Risk: The Lifecycle of Transitive Vulnerabilities\n  in Maven","summary":"The modern software development landscape heavily relies on transitive\ndependencies. They enable seamless integration of third-party libraries.\nHowever, they also introduce security challenges. Transitive vulnerabilities\nthat arise from indirect dependencies expose projects to risks associated with\nCommon Vulnerabilities and Exposures (CVEs). It happens even when direct\ndependencies remain secure. This paper examines the lifecycle of transitive\nvulnerabilities in the Maven ecosystem. We employ survival analysis to measure\nthe time projects remain exposed after a CVE is introduced. Using a large\ndataset of Maven projects, we identify factors that influence the resolution of\nthese vulnerabilities. Our findings offer practical advice on improving\ndependency management.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-07T07:54:15Z"}
{"aid":"http://arxiv.org/abs/2504.04807v1","title":"Fast gates for bit-flip protected superconducting qubits","summary":"Superconducting qubits offer an unprecedentedly high degree of flexibility in\nterms of circuit encoding and parameter choices. However, in designing the\nqubit parameters one typically faces the conflicting goals of long coherence\ntimes and simple control capabilities. Both are determined by the wavefunction\noverlap of the qubit basis states and the corresponding matrix elements. Here,\nwe address this problem by introducing a qubit architecture with real-time\ntunable bit-flip protection. In the first, the `heavy' regime, the energy\nrelaxation time can be on the order of hours for fluxons located in two\nnear-degenerate ground states, as recently demonstrated in Ref. [Hassani et\nal., Nat.~Commun.~14 (2023)]. The second, `light' regime, on the other hand\nfacilitates high-fidelity control on nanosecond timescales without the need for\nmicrowave signals. We propose two different tuning mechanisms of the qubit\npotential and show that base-band flux-pulses of around 10 ns are sufficient to\nrealize a universal set of high-fidelity single- and two-qubit gates. We expect\nthat the concept of real-time wavefunction control can also be applied to other\nhardware-protected qubit designs.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-07T08:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.04814v1","title":"Explainability of AI Uncertainty: Application to Multiple Sclerosis\n  Lesion Segmentation on MRI","summary":"Trustworthy artificial intelligence (AI) is essential in healthcare,\nparticularly for high-stakes tasks like medical image segmentation. Explainable\nAI and uncertainty quantification significantly enhance AI reliability by\naddressing key attributes such as robustness, usability, and explainability.\nDespite extensive technical advances in uncertainty quantification for medical\nimaging, understanding the clinical informativeness and interpretability of\nuncertainty remains limited. This study introduces a novel framework to explain\nthe potential sources of predictive uncertainty, specifically in cortical\nlesion segmentation in multiple sclerosis using deep ensembles. The proposed\nanalysis shifts the focus from the uncertainty-error relationship towards\nrelevant medical and engineering factors. Our findings reveal that\ninstance-wise uncertainty is strongly related to lesion size, shape, and\ncortical involvement. Expert rater feedback confirms that similar factors\nimpede annotator confidence. Evaluations conducted on two datasets (206\npatients, almost 2000 lesions) under both in-domain and distribution-shift\nconditions highlight the utility of the framework in different scenarios.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-07T08:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.04824v1","title":"Optimal regularity for degenerate parabolic equations on a flat boundary","summary":"We establish the optimal regularity of viscosity solutions to\n  \\begin{equation*}\n  u_t - x_n^\\gamma \\Delta u = f,\n  \\end{equation*} which arises in the regularity theory for the porous medium\nequation. Specifically, we prove that under the zero Dirichlet boundary\ncondition on $\\{x_n=0\\}$, the optimal regularity of $u$ up to the flat boundary\n$\\{x_n=0\\}$ is $C^{1,1-\\gamma}$. Moreover, for the homogeneous equations, we\nestablish that the optimal regularity of $u$ is $C^{2,1-\\gamma}$ in the spatial\nvariables, and that $x_n^{-\\gamma}u$ is smooth in the variables $x'$ and $t$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T08:25:02Z"}
{"aid":"http://arxiv.org/abs/2504.04826v1","title":"A structure and asymptotic preserving scheme for the quasineutral limit\n  of the Vlasov-Poisson system","summary":"In this work, we propose a new numerical method for the Vlasov-Poisson system\nthat is both asymptotically consistent and stable in the quasineutral regime,\ni.e. when the Debye length is small compared to the characteristic spatial\nscale of the physical domain. Our approach consists in reformulating the\nVlasov-Poisson system as a hyperbolic problem by applying a spectral expansion\nin the basis of Hermite functions in the velocity space and in designing a\nstructure-preserving scheme for the time and spatial variables. Through this\nHermite formulation, we establish a convergence result for the electric field\ntoward its quasineutral limit together with optimal error estimates. Following\nthis path, we then propose a fully discrete numerical method for the\nVlasov-Poisson system, inspired by the approach in arXiv:2306.14605 , and\nrigorously prove that it is uniformly consistent in the quasineutral limit\nregime. Finally, we present several numerical simulations to illustrate the\nbehavior of the proposed scheme. These results demonstrate the capability of\nour method to describe quasineutral plasmas and confirm the theoretical\nfindings: stability and asymptotic preservation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T08:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.04833v1","title":"Explanation-Driven Interventions for Artificial Intelligence Model\n  Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology","summary":"The integration of Artificial Intelligence (AI) in modern society is heavily\nshifting the way that individuals carry out their tasks and activities.\nEmploying AI-based systems raises challenges that designers and developers must\naddress to ensure that humans remain in control of the interaction process,\nparticularly in high-risk domains. This article presents a novel End-User\nDevelopment (EUD) approach for black-box AI models through a redesigned user\ninterface in the Rhino-Cyt platform, a medical AI-based decision-support system\nfor medical professionals (more precisely, rhinocytologists) to carry out cell\nclassification. The proposed interface empowers users to intervene in AI\ndecision-making process by editing explanations and reconfiguring the model,\ninfluencing its future predictions. This work contributes to Human-Centered AI\n(HCAI) and EUD by discussing how explanation-driven interventions allow a blend\nof explainability, user intervention, and model reconfiguration, fostering a\nsymbiosis between humans and user-tailored AI systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-07T08:44:48Z"}
{"aid":"http://arxiv.org/abs/2504.04867v1","title":"FedSAUC: A Similarity-Aware Update Control for Communication-Efficient\n  Federated Learning in Edge Computing","summary":"Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T09:21:43Z"}
{"aid":"http://arxiv.org/abs/2504.04872v1","title":"Simulating Persuasive Dialogues on Meat Reduction with Generative Agents","summary":"Meat reduction benefits human and planetary health, but social norms keep\nmeat central in shared meals. To date, the development of communication\nstrategies that promote meat reduction while minimizing social costs has\nrequired the costly involvement of human participants at each stage of the\nprocess. We present work in progress on simulating multi-round dialogues on\nmeat reduction between Generative Agents based on large language models (LLMs).\nWe measure our main outcome using established psychological questionnaires\nbased on the Theory of Planned Behavior and additionally investigate Social\nCosts. We find evidence that our preliminary simulations produce outcomes that\nare (i) consistent with theoretical expectations; and (ii) valid when compared\nto data from previous studies with human participants. Generative agent-based\nmodels are a promising tool for identifying novel communication strategies on\nmeat reduction-tailored to highly specific participant groups-to then be tested\nin subsequent studies with human participants.","main_category":"cs.CY","categories":"cs.CY,cs.HC,cs.MA","published":"2025-04-07T09:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.04875v1","title":"Note on some Gromoll filtration groups and fundamental groups of\n  $\\mathrm{Diff}_{\\partial}(D^n)$","summary":"In this note, we will compute some Gromoll filtration groups\n$\\Gamma^{n+1}_{i+1}$ for certain $i$ when $8\\leq n \\leq 17$ and $n=4k+2\\geq\n18$. We will also use these results to obtain some information of\n$\\pi_1\\mathrm{Diff}_{\\partial} (D^n)$ when $6\\leq n \\leq 15$ and $\\pi_2\n\\mathrm{Diff}_{\\partial} (D^{4k+3})$ when $4k+3\\geq 15$.","main_category":"math.AT","categories":"math.AT,math.GT","published":"2025-04-07T09:31:20Z"}
{"aid":"http://arxiv.org/abs/2504.04879v1","title":"Mixed memories in Hopfield networks","summary":"We consider the class of Hopfield models of associative memory with\nactivation function $F$ and state space $\\{-1,1\\}^N$, where each vertex of the\ncube describes a configuration of $N$ binary neurons. $M$ randomly chosen\nconfigurations, called patterns, are stored using an energy function designed\nto make them local minima. If they are, which is known to depend on how $M$\nscales with $N$, then they can be retrieved using a dynamics that decreases the\nenergy. However, storing the patterns in the energy function also creates\nunintended local minima, and thus false memories. Although this has been known\nsince the earliest work on the subject, it has only been supported by numerical\nsimulations and non-rigorous calculations, except in elementary cases.\n  Our results are twofold. For a generic function $F$, we explicitly construct\na set of configurations, called mixed memories, whose properties are intended\nto characterise the local minima of the energy function. For three prominent\nmodels, namely the classical, the dense and the modern Hopfield models,\nobtained for quadratic, polynomial and exponential functions $F$ respectively,\nwe give conditions on the growth rate of $M$ which guarantee that, as $N$\ndiverges, mixed memories are fixed points of the retrieval dynamics and thus\nexact minima of the energy. We conjecture that in this regime, all local minima\nare mixed memories.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.04887v1","title":"A mechanism for growth of topological entropy and global changes of the\n  shape of chaotic attractors","summary":"The theoretical and numerical understanding of the key concept of topological\nentropy is an important problem in dynamical systems. Most studies have been\ncarried out on maps (discrete-time systems). We analyse a scenario of global\nchanges of the structure of an attractor in continuous-time systems leading to\nan unbounded growth of the topological entropy of the underlying dynamical\nsystem. As an example, we consider the classical Roessler system. We show that\nfor an explicit range of parameters a chaotic attractor exists. We also prove\nthe existence of a sequence of bifurcations leading to the growth of the\ntopological entropy. The proofs are computer-aided.","main_category":"math.DS","categories":"math.DS,cs.NA,math.NA,nlin.CD","published":"2025-04-07T09:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.04910v1","title":"Fault Localisation in Infinite-Dimensional Linear Electrical Networks","summary":"We present a novel fault localisation methodology for linear time-invariant\nelectrical networks with infinite-dimensional edge dynamics and uncertain fault\ndynamics. The theory accommodates instability and also bounded propagation\ndelays in the network. The goal is to estimate the location of a fault along a\ngiven network edge, using sensors positioned arbitrarily throughout the\nnetwork. Passive faults of unknown impedance are considered, along with stable\nfaults of known impedance. To illustrate the approach, we tackle a significant\nuse-case: a multi-conductor transmission line, with dynamics modelled by the\nTelegrapher's equation, subject to a line-to-ground fault. Frequency-domain\ninsights are used to reformulate the general fault localisation problem into a\nnon-convex scalar optimisation problem, of which the true fault location is\nguaranteed to be a global minimiser. Numerical experiments are run to quantify\nlocalisation performance over a range of fault resistances.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP,math.DS","published":"2025-04-07T10:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.04929v1","title":"The Linearized Vlasov-Maxwell System as a Hamiltonian System","summary":"We present a Hamiltonian formulation for the linearized Vlasov-Maxwell system\nwith a Maxwellian background distribution function. We discuss the geometric\nproperties of the model at the continuous level, and how to discretize the\nmodel in the GEMPIC framework [1]. This method allows us to keep the structure\nof the system at the semi-discrete level. To integrate the model in time, we\nemploy a Poisson splitting and discuss how to integrate each subsystem\nseparately. We test the model against the full Vlasov-Maxwell model with a\ncontrol variate method for noise reduction; the two chosen test-cases are the\nweak Landau damping and the Bernstein waves. Both test-cases exhibit the same\nphysical properties for short simulations but our model enjoys better long-time\nstability and energy conservation due to its geometric construction. The model\nis implemented in the open-source Python library STRUPHY [2, 3].","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T11:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.04946v1","title":"Scalable chip-based 3D ion traps","summary":"Ion traps are used for a wide range of applications from metrology to quantum\nsimulations and quantum information processing. Microfabricated chip-based 3D\nion traps are scalable to store many ions for the realization of a large number\nof qubits, provide deep trapping potentials compared to surface traps, and very\ngood shielding from external electric fields. In this work, we give an overview\nof our recent developments on chip-based 3D ion traps. Different types of chip\nmaterials, the integration of electronic filter components on-chip and compact\nelectrical connections in vacuum are discussed. Further, based on finite\nelement method (FEM) simulations, we discuss how integrating micro-optics in 3D\nion traps is possible without disturbing the trapped ions.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-07T11:33:37Z"}
{"aid":"http://arxiv.org/abs/2504.04988v1","title":"RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with\n  a Multi-Modal Dataset and Retrieval-Augmented Generation Model","summary":"Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T12:13:43Z"}
{"aid":"http://arxiv.org/abs/2504.05039v1","title":"Outerplanar and bounded treewidth support for hypergraphs","summary":"We study the existence and construction of sparse supports for hypergraphs\nderived from subgraphs of a graph $G$. For a hypergraph $(X,\\mathcal{H})$, a\nsupport $Q$ is a graph on $X$ s.t. $Q[H]$, the graph induced on vertices in $H$\nis connected for every $H\\in\\mathcal{H}$.\n  We consider \\emph{primal}, \\emph{dual}, and \\emph{intersection} hypergraphs\ndefined by subgraphs of a graph $G$ that are \\emph{non-piercing}, (i.e., each\nsubgraph is connected, their pairwise differences remain connected).\n  If $G$ is outerplanar, we show that the primal, dual and intersection\nhypergraphs admit supports that are outerplanar. For a bounded treewidth graph\n$G$, we show that if the subgraphs are non-piercing, then there exist supports\nfor the primal and dual hypergraphs of treewidth $O(2^{tw(G)})$ and\n$O(2^{4tw(G)})$ respectively, and a support of treewidth $2^{O(2^{tw(G)})}$ for\nthe intersection hypergraph. We also show that for the primal and dual\nhypergraphs, the exponential blow-up of treewidth is sometimes essential.\n  All our results are algorithmic and yield polynomial-time algorithms (when\nthe treewidth is bounded). The existence and construction of sparse supports is\na crucial step in the design and analysis of PTASs and/or sub-exponential time\nalgorithms for several packing and covering problems.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-07T13:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05055v1","title":"Detecting relevant dependencies under measurement error with\n  applications to the analysis of planetary system evolution","summary":"Exoplanets play an important role in understanding the mechanics of planetary\nsystem formation and orbital evolution. In this context the correlations of\ndifferent parameters of the planets and their host star are useful guides in\nthe search for explanatory mechanisms. Based on a reanalysis of the data set\nfrom \\cite{figueria14} we study the as of now still poorly understood\ncorrelation between planetary surface gravity and stellar activity of Hot\nJupiters. Unfortunately, data collection often suffers from measurement errors\ndue to complicated and indirect measurement setups, rendering standard\ninference techniques unreliable.\n  We present new methods to estimate and test for correlations in a\ndeconvolution framework and thereby improve the state of the art analysis of\nthe data in two directions. First, we are now able to account for additive\nmeasurement errors which facilitates reliable inference. Second we test for\nrelevant changes, i.e. we are testing for correlations exceeding a certain\nthreshold $\\Delta$. This reflects the fact that small nonzero correlations are\nto be expected for real life data almost always and that standard statistical\ntests will therefore always reject the null of no correlation given sufficient\ndata. Our theory focuses on quantities that can be estimated by U-Statistics\nwhich contain a variety of correlation measures. We propose a bootstrap test\nand establish its theoretical validity. As a by product we also obtain\nconfidence intervals. Applying our methods to the Hot Jupiter data set from\n\\cite{figueria14}, we observe that taking into account the measurement errors\nyields smaller point estimates and the null of no relevant correlation is\nrejected only for very small $\\Delta$. This demonstrates the importance of\nconsidering the impact of measurement errors to avoid misleading conclusions\nfrom the resulting statistical analysis.","main_category":"stat.ME","categories":"stat.ME,astro-ph.EP,astro-ph.IM,math.ST,stat.TH","published":"2025-04-07T13:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.05069v1","title":"Weak thermal fluctuations impede steering of chiral magnetic nanobots","summary":"Rotating magnetic field is an efficient method of actuation of synthetic\ncolloids in liquids. In this Letter we theoretically study the effect of the\nthermal noise on torque-driven steering of magnetic nanohelices. Using a\ncombination of numerical and analytical methods, we demonstrate that\nsurprisingly a weak thermal noise can substantially disrupt the orientation and\nrotation of the nanohelix, severely impeding its propulsion. The results of\nLangevin simulations are in excellent agreement with the numerical solution of\nthe Fokker-Planck equation and the analytical effective field approximation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.05092v1","title":"Distortions in Periodicity Analysis of Blazars: The Impact of Flares","summary":"Blazars, a unique class of active galactic nuclei, exhibit highly variable\nemission across the electromagnetic spectrum. This variability frequently\nmanifests as intense flaring events, sparking an ongoing debate in recent\nliterature about whether these flares exhibit periodic behavior in certain\nsources. However, many blazars also show clear signs of stochastic,\nuncorrelated flares that do not follow a regular pattern. This paper explores\nhow the presence of one such of these stochastic flares can distort an\nintrinsically periodic pattern of emission in blazars. Our results demonstrate\nthat, depending on the specific circumstances, the deviations in significance\nand periods can exceed 100\\%. Sometimes, these deviations can be so severe that\nthey eliminate any evidence of a periodic pattern. These findings highlight the\ndramatic impact that flares can have on periodicity searches. To confront this\nchallenge, we propose an innovative approach, the Singular Spectrum Analysis\nmethod, which appears more robust against the effects of flares. As an\nalternative solution, we also propose the sigma clipping technique to mitigate\nthe impact of flares. This framework offers a valuable foundation for analyzing\nperiodicity in similar astrophysical sources that are also subject to\nstochastic flaring events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T14:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05095v1","title":"Dust Growth in ALMA Rings: II. Dusty Rossby Wave Instability","summary":"Annular substructures serve as ideal venues for planetesimal formation. In\nthis series, we investigate the linear stage of dust growth within rings. The\nfirst paper examines the global streaming instability, while this study focuses\non the dusty Rossby wave instability (DRWI). We perform a linear analysis of\nthe two-fluid equations on a background pressure bump, representing annular\nsubstructures. The spectral code \\textsc{Dedalus} is used to solve the linear\neigenvalue problem. We identify two distinct DRWI modes: Type I, which\noriginates from dust-modified gas RWI, and Type II, which results from dust-gas\ncoupling. These modes never coexist for a given azimuthal wavenumber $\\ky$, but\ntransition between each other as $\\ky$ varies. Type I modes are driven by the\nadvection of background vorticity, whereas Type II modes involve two primary\nwaves: Rossby waves, driven by advection, and thin waves, driven by dust-gas\ndrag. Finally, we assess the relevance of DRWI in ALMA rings using DSHARP\nsources. Our findings suggest that Type I modes could explain the absence of\nazimuthal asymmetries in many ALMA disks, whereas Type II modes are entirely\nabsent in all eight observed rings, implying that unresolved narrow rings or\nalternative mechanisms may play a role in dust growth within annular\nsubstructures.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-07T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.05101v1","title":"Safe and Efficient Coexistence of Autonomous Vehicles with Human-Driven\n  Traffic at Signalized Intersections","summary":"The proliferation of connected and automated vehicles (CAVs) has positioned\nmixed traffic environments, which encompass both CAVs and human driven vehicles\n(HDVs), as critical components of emerging mobility systems. Signalized\nintersections are paramount for optimizing transportation efficiency and\nenhancing energy economy, as they inherently induce stop and go traffic\ndynamics. In this paper, we present an integrated framework that concurrently\noptimizes signal timing and CAV trajectories at signalized intersections, with\nthe dual objectives of maximizing traffic throughput and minimizing energy\nconsumption for CAVs. We first formulate an optimal control strategy for CAVs\nthat prioritizes trajectory planning to circumvent state constraints, while\nincorporating the impact of signal timing and HDV behavior. Furthermore, we\nintroduce a traffic signal control methodology that dynamically adjusts signal\nphases based on vehicular density per lane, while mitigating disruption for\nCAVs scheduled to traverse the intersection. Acknowledging the system's\ninherent dynamism, we also explore event triggered replanning mechanisms that\nenable CAVs to iteratively refine their planned trajectories in response to the\nemergence of more efficient routing options. The efficacy of our proposed\nframework is evaluated through comprehensive simulations in MATLAB.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T14:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.05115v1","title":"Inertia-induced scaling and criticality in martensites","summary":"Martensites subjected to quasistatic deformation are known to exhibit power\nlaw distributed acoustic emission in a broad range of scales. However, the\norigin of the observed scaling behavior and the mechanism of self organization\ntowards criticality remains obscure. Here we argue that the power law structure\nof the fluctuations spectrum can be interpreted as an effect of inertia. The\ngeneral insight is that inertial dynamics can become a crucial player when the\nunderlying mechanical system is only marginally stable. We first illustrate the\npossibility of inertia-induced criticality using an elementary example of mass\npoints connected by bi-stable springs. We then explore the effects of inertia\nin the fully realistic two and three dimensional continuum models of specific\nelastic phase transitions in crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-07T14:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.05120v1","title":"The intersections of the lower central series and the subgroups of\n  finite p-index of Generalized Baumslag-Solitar tree groups","summary":"For a Generalized Baumslag-Solitar group $G$ with underling graph a tree, we\ncalculate the intersection $\\gamma_{\\omega}(G)$ of the lower central series and\nthe intersection $(N_{p})_{\\omega}(G)$ of the subgroups of finite index some\npower of a prime $p$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T14:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.05129v1","title":"Superconductivity, Anomalous Hall Effect, and Stripe Order in\n  Rhombohedral Hexalayer Graphene","summary":"We report the discovery of a unique superconducting phase in rhombohedral\nhexalayer graphene characterized by its simultaneous emergence with both the\nanomalous Hall effect and stripe charge order. The onset of stripe charge order\nis revealed through angle-resolved transport measurements, which show thermally\nactivated insulating behavior along one axis and highly conductive transport\nalong the orthogonal direction. Superconductivity develops exclusively along\nthe high-conductivity axis, giving rise to a one-dimensional-like\nsuperconducting channel. This superconducting state exhibits first-order\ntransitions under an out-of-plane magnetic field, consistent with a chiral\norder parameter that breaks time-reversal symmetry. Most remarkably, thermally\ndriven superconducting transitions display pronounced hysteresis-an uncommon\nphenomenon that reflects the complex interplay among stripe formation, broken\ntime-reversal symmetry, and superconductivity. Together, these results uncover\na previously unidentified quantum phase: a chiral superconductor embedded\nwithin an anomalous Hall crystal.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-07T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.05146v1","title":"Query Smarter, Trust Better? Exploring Search Behaviours for Verifying\n  News Accuracy","summary":"While it is often assumed that searching for information to evaluate\nmisinformation will help identify false claims, recent work suggests that\nsearch behaviours can instead reinforce belief in misleading news, particularly\nwhen users generate queries using vocabulary from the source articles. Our\nresearch explores how different query generation strategies affect news\nverification and whether the way people search influences the accuracy of their\ninformation evaluation. A mixed-methods approach was used, consisting of three\nparts: (1) an analysis of existing data to understand how search behaviour\ninfluences trust in fake news, (2) a simulation of query generation strategies\nusing a Large Language Model (LLM) to assess the impact of different query\nformulations on search result quality, and (3) a user study to examine how\n'Boost' interventions in interface design can guide users to adopt more\neffective query strategies. The results show that search behaviour\nsignificantly affects trust in news, with successful searches involving\nmultiple queries and yielding higher-quality results. Queries inspired by\ndifferent parts of a news article produced search results of varying quality,\nand weak initial queries improved when reformulated using full SERP\ninformation. Although 'Boost' interventions had limited impact, the study\nsuggests that interface design encouraging users to thoroughly review search\nresults can enhance query formulation. This study highlights the importance of\nquery strategies in evaluating news and proposes that interface design can play\na key role in promoting more effective search practices, serving as one\ncomponent of a broader set of interventions to combat misinformation.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T14:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.05150v1","title":"A Reinforcement Learning Method for Environments with Stochastic\n  Variables: Post-Decision Proximal Policy Optimization with Dual Critic\n  Networks","summary":"This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T14:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05154v1","title":"CARE: Aligning Language Models for Regional Cultural Awareness","summary":"Existing language models (LMs) often exhibit a Western-centric bias and\nstruggle to represent diverse cultural knowledge. Previous attempts to address\nthis rely on synthetic data and express cultural knowledge only in English. In\nthis work, we study whether a small amount of human-written, multilingual\ncultural preference data can improve LMs across various model families and\nsizes. We first introduce CARE, a multilingual resource of 24.1k responses with\nhuman preferences on 2,580 questions about Chinese and Arab cultures, all\ncarefully annotated by native speakers and offering more balanced coverage.\nUsing CARE, we demonstrate that cultural alignment improves existing LMs beyond\ngeneric resources without compromising general capabilities. Moreover, we\nevaluate the cultural awareness of LMs, native speakers, and retrieved web\ncontent when queried in different languages. Our experiment reveals regional\ndisparities among LMs, which may also be reflected in the documentation gap:\nnative speakers often take everyday cultural commonsense and social norms for\ngranted, while non-natives are more likely to actively seek out and document\nthem. CARE is publicly available at https://github.com/Guochry/CARE (we plan to\nadd Japanese data in the near future).","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05166v1","title":"Effective spin model with anisotropic exchange interactions for the\n  spin-orbit coupled Hubbard model at half-filling","summary":"Spin-orbit coupling (SOC) in noncentrosymmetric materials is the source of\nincommensurate magnetic structures. In semiconductors, it drives the Rashba\nspin splitting and spin momentum locking, while in magnetic insulators based on\ntransition metals, it induces anisotropic spin exchange interactions, like\nDzyaloshinskii-Moriya (DM) interaction which drive chiral magnetism and\nskyrmion formation. Here, we establish a direct connection between SOC and spin\nexchange interactions by deriving an effective spin model from the SOC Hubbard\nmodel at half-filling. Using a strong-coupling expansion up to fourth order, we\nidentify Heisenberg, Ising-like, and ring exchange interactions, as well as a\nvariety of four-body terms for realistic Hubbard parameters. These parameters\nconstrain the relative strengths of spin interactions, providing a natural\ninterpolation between metallic and insulating phases that host complex magnetic\ntextures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-07T15:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.05191v1","title":"Distributed Quantum Advantage in Locally Checkable Labeling Problems","summary":"In this paper, we present the first known example of a locally checkable\nlabeling problem (LCL) that admits asymptotic distributed quantum advantage in\nthe LOCAL model of distributed computing: our problem can be solved in $O(\\log\nn)$ communication rounds in the quantum-LOCAL model, but it requires\n$\\Omega(\\log n \\cdot \\log^{0.99} \\log n)$ communication rounds in the classical\nrandomized-LOCAL model. We also show that distributed quantum advantage cannot\nbe arbitrarily large: if an LCL problem can be solved in $T(n)$ rounds in the\nquantum-LOCAL model, it can also be solved in $\\tilde O(\\sqrt{n T(n)})$ rounds\nin the classical randomized-LOCAL model. In particular, a problem that is\nstrictly global classically is also almost-global in quantum-LOCAL. Our second\nresult also holds for $T(n)$-dependent probability distributions. As a\ncorollary, if there exists a finitely dependent distribution over valid\nlabelings of some LCL problem $\\Pi$, then the same problem $\\Pi$ can also be\nsolved in $\\tilde O(\\sqrt{n})$ rounds in the classical randomized-LOCAL and\ndeterministic-LOCAL models. That is, finitely dependent distributions cannot\nexist for global LCL problems.","main_category":"cs.DC","categories":"cs.DC,cs.CC,quant-ph","published":"2025-04-07T15:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.05197v1","title":"P2Mark: Plug-and-play Parameter-intrinsic Watermarking for Neural Speech\n  Generation","summary":"Recently, a large number of advanced neural speech generation methods have\nemerged in the open-source community. Although this has facilitated the\napplication and development of technology, it has also increased the difficulty\nof preventing the abuse of generated speech and protecting copyrights. Audio\nwatermarking technology is an effective method for proactively protecting\ngenerated speech, but when the source codes and model weights of the neural\nspeech generation methods are open-sourced, audio watermarks based on previous\nwatermarking methods can be easily removed or manipulated. This paper proposes\na Plug-and-play Parameter-intrinsic WaterMarking (P2Mark) method for neural\nspeech generation system protection. The main advantage of P2Mark is that the\nwatermark information is flexibly integrated into the neural speech generation\nmodel in the form of parameters by training a watermark adapter rather than\ninjecting the watermark into the model in the form of features. After the\nwatermark adapter with the watermark embedding is merged with the pre-trained\ngeneration model, the watermark information cannot be easily removed or\nmanipulated. Therefore, P2Mark will be a reliable choice for proactively\ntracing and protecting the copyrights of neural speech generation models in\nopen-source white-box scenarios. We validated P2Mark on two main types of\ndecoders in neural speech generation: vocoder and codec. Experimental results\nshow that P2Mark achieves performance comparable to state-of-the-art audio\nwatermarking methods that cannot be used for open-source white-box protection\nscenarios in terms of watermark extraction accuracy, watermark\nimperceptibility, and robustness.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-07T15:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.05208v1","title":"On the cyclic behavior of singular inner functions in Besov and sequence\n  spaces","summary":"We show the existence of singular inner functions that are cyclic in some\nBesov-type spaces of analytic functions over the unit disc. Our sufficient\ncondition is stated only in terms of the modulus of smoothness of the\nunderlying measure. Such singular inner functions are cyclic also in the space\n$\\ell^p_A$ of holomorphic functions with coefficients in $\\ell^p$. This can\nonly happen for measures that place no mass on any Beurling-Carleson set.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-04-07T15:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.05235v1","title":"IAEmu: Learning Galaxy Intrinsic Alignment Correlations","summary":"The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,cs.LG","published":"2025-04-07T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.05238v1","title":"Federated Learning for Medical Image Classification: A Comprehensive\n  Benchmark","summary":"The federated learning paradigm is wellsuited for the field of medical image\nanalysis, as it can effectively cope with machine learning on isolated\nmulticenter data while protecting the privacy of participating parties.\nHowever, current research on optimization algorithms in federated learning\noften focuses on limited datasets and scenarios, primarily centered around\nnatural images, with insufficient comparative experiments in medical contexts.\nIn this work, we conduct a comprehensive evaluation of several state-of-the-art\nfederated learning algorithms in the context of medical imaging. We conduct a\nfair comparison of classification models trained using various federated\nlearning algorithms across multiple medical imaging datasets. Additionally, we\nevaluate system performance metrics, such as communication cost and\ncomputational efficiency, while considering different federated learning\narchitectures. Our findings show that medical imaging datasets pose substantial\nchallenges for current federated learning optimization algorithms. No single\nalgorithm consistently delivers optimal performance across all medical\nfederated learning scenarios, and many optimization algorithms may underperform\nwhen applied to these datasets. Our experiments provide a benchmark and\nguidance for future research and application of federated learning in medical\nimaging contexts. Furthermore, we propose an efficient and robust method that\ncombines generative techniques using denoising diffusion probabilistic models\nwith label smoothing to augment datasets, widely enhancing the performance of\nfederated learning on classification tasks across various medical imaging\ndatasets. Our code will be released on GitHub, offering a reliable and\ncomprehensive benchmark for future federated learning studies in medical\nimaging.","main_category":"cs.CV","categories":"cs.CV,cs.DC","published":"2025-04-07T16:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.05242v1","title":"Spectral correlations of dynamical Resonance Fluorescence","summary":"Frequency-filtered photon correlations have been proven to be extremely\nuseful in grasping how the detection process alters photon statistics.\nHarnessing the spectral correlations also permits refinement of the emission\nand unraveling of previously hidden strong correlations in a plethora of\nquantum-optical systems under continuous-wave excitation. In this work, we\ninvestigate such correlations for time-dependent excitation and develop a\nmethodology to compute efficiently time-integrated correlations, which are at\nthe heart of the photon-counting theory, and subsequently apply it to analyze\nthe photon emission of pulsed systems. By combining this formalism with the\nsensor method -- which facilitates frequency-resolved correlations -- we\ndemonstrate how spectral filtering enhances single-photon purity and suppresses\nmulti-photon noise in time-bin-encoded quantum states. Specifically, filtering\nthe central spectral peak of a dynamically driven two-level system boosts\ntemporal coherence and improves the fidelity of time-bin entanglement\npreparation, even under conditions favoring multi-photon emission. These\nresults establish spectral filtering as a critical tool for tailoring photon\nstatistics in pulsed quantum light sources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T16:27:13Z"}
{"aid":"http://arxiv.org/abs/2504.05244v1","title":"Behind the Spotlight: A systematic assessment of outshining using NIRCam\n  medium-bands in the JADES Origins Field","summary":"The spatial resolution and sensitivity of JWST's NIRCam instrument has\nrevolutionised our ability to probe the internal structure of early galaxies.\nBy leveraging deep medium-band imaging in the Jades Origins Field, we assemble\ncomprehensive spectral energy distributions (SEDs) using 19 photometric bands\nfor over 200 high-redshift galaxies ($z \\geq 4.5$). We present an analysis of\nthis sample with particular emphasis on investigating the \"outshining\"\nphenomenon, which can bias the inferred stellar populations by masking the\npresence of evolved stellar populations ($\\geq$ 100 Myr) with the light of\nbright, young O and B-type stars. We address this problem by performing\nspatially-resolved SED-fitting of both binned and full pixel-by-pixel\nphotometry, which we compare to the traditional integrated approach. We find\nevidence for systematic underestimation of stellar mass in low-mass galaxies\n($\\leq 10^9 \\rm M_\\odot$) with bursty star formation, which can exceed a factor\nof 10 in individual cases, but on average is typically a factor of 1.25-2.5,\ndepending on the binning methodology and SFH model used. The observed mass\noffset correlates with burstiness (SFR$_{10 \\ \\rm Myr}$/SFR$_{100 \\ \\rm Myr}$)\nand sSFR, such that galaxies with recently rising SFHs have larger mass\noffsets. The integrated SFH models which produce the most consistent stellar\nmasses are the double power-law and non-parametric `continuity' models,\nalthough no integrated model fully reproduces all resolved SFHs. We apply an\noutshining correction factor to the Stellar Mass Function at $z=7$, finding\nlittle impact within the uncertainties. We conclude that outshining can be\nimportant in individual low-mass galaxies, but the overall impact is limited\nand should be considered alongside other systematic SED fitting effects.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T16:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.05263v1","title":"An X-ray and Optical Study of the Dwarf Nova Candidate OGLE-BLG-DN-0064","summary":"The source OGLE-BLG-DN-0064 (hereafter OGLE64) was classified as a potential\ndwarf nova based on its regular outburst activity revealed by the OGLE optical\nsurvey. In this paper, we investigate the X-ray and optical emissions from the\nsource OGLE64 based on archival Chandra and Swift X-ray data and our optical\nobservations with the 6-m BTA telescope at the Special Astrophysical\nObservatory of the Russian Academy of Sciences. OGLE64 shows an X-ray\nluminosity $ L_X \\approx 1.6 \\times 10^{32} \\, \\text{erg s}^{-1} $ and a high\nX-ray-to-optical flux ratio $ F_X / F_{\\text{opt}} \\approx 1.5$, typical for\naccreting white dwarfs. The X-ray spectrum of OGLE64 is better fitted by the\nmodels of a power law with a photon index $\\Gamma \\approx 1.9$ and an optically\nthin plasma with a temperature $ kT \\approx 6.4 \\, \\text{keV} $. The optical\nspectrum shows hydrogen and neutral helium emission lines, in some of which a\ndouble-peaked structure is observed. An analysis of the outburst activity of\nOGLE64, based on data from the OGLE, ZTF, ATLAS, and ASAS-SN optical surveys,\nhas revealed superoutbursts with a characteristic supercycle $ P_{\\text{super}}\n\\approx 400 \\, \\text{days} $. We found no significant variability in either the\nX-ray or optical light curves of OGLE64 that could be associated with the\nchange in the visibility conditions for the emitting regions at different\norbital phases. Our estimates of the orbital period of the system by indirect\nmethods show that the period probably lies in the range $ P_{\\text{orb}} \\sim\n1.5 - 3.5 \\, \\text{h} $. The properties of the X-ray and optical emissions from\nOGLE64 lead us to conclude that the system is an SU UMa-type dwarf nova.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.05264v1","title":"Existence and characterizations of hyper-dual group inverse","summary":"Motivated by the recent work of Xiao and Zhong [AIMS Math. 9 (2024),\n35125--35150: MR4840882], we propose a generalized inverse for a hyper-dual\nmatrix called hyper-dual group generalized inverse (HDGGI). Under certain\nnecessary and sufficient conditions, we establish the existence of the HDGGI of\na hyper-dual matrix. We then show that the HDGGI is unique (whenever exists).\nThe HDGGI is then used to solve a linear hyper-dual system. We also exploit\nsome sufficient conditions under which the reverse and forward-order laws for a\nparticular form of the HDGGI and HDMPGI hold. We also discuss the least-squares\nproperties of hyper-dual group inverse. Using the definition of dual matrix of\norder $n$, we finally establish necessary and sufficient condition for the\nexistence of the group inverse of a dual matrix of order $n$.","main_category":"math.RA","categories":"math.RA,math.AC,math.FA","published":"2025-04-07T16:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.05265v1","title":"From Sparse Signal to Smooth Motion: Real-Time Motion Generation with\n  Rolling Prediction Models","summary":"In extended reality (XR), generating full-body motion of the users is\nimportant to understand their actions, drive their virtual avatars for social\ninteraction, and convey a realistic sense of presence. While prior works\nfocused on spatially sparse and always-on input signals from motion\ncontrollers, many XR applications opt for vision-based hand tracking for\nreduced user friction and better immersion. Compared to controllers, hand\ntracking signals are less accurate and can even be missing for an extended\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\nModel (RPM), an online and real-time approach that generates smooth full-body\nmotion from temporally and spatially sparse input signals. Our model generates\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\nplausible motion when inputs are missing (i.e., synthesis mode). More\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\nvice versa. To demonstrate the practical importance of handling noisy and\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\nfrom a commercial virtual reality (VR) headset with paired high quality body\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\nusing motion controllers (spatially sparse) and hand tracking (spatially and\ntemporally sparse). We benchmark RPM against the state of the art on both\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\napplications with a realistic dataset and by handling unreliable input signals.\nOur code, pretrained models, and GORP dataset are available in the project\nwebpage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05299v1","title":"SmolVLM: Redefining small and efficient multimodal models","summary":"Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-07T17:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.05300v1","title":"Dimension-Free Convergence of Diffusion Models for Approximate Gaussian\n  Mixtures","summary":"Diffusion models are distinguished by their exceptional generative\nperformance, particularly in producing high-quality samples through iterative\ndenoising. While current theory suggests that the number of denoising steps\nrequired for accurate sample generation should scale linearly with data\ndimension, this does not reflect the practical efficiency of widely used\nalgorithms like Denoising Diffusion Probabilistic Models (DDPMs). This paper\ninvestigates the effectiveness of diffusion models in sampling from complex\nhigh-dimensional distributions that can be well-approximated by Gaussian\nMixture Models (GMMs). For these distributions, our main result shows that DDPM\ntakes at most $\\widetilde{O}(1/\\varepsilon)$ iterations to attain an\n$\\varepsilon$-accurate distribution in total variation (TV) distance,\nindependent of both the ambient dimension $d$ and the number of components $K$,\nup to logarithmic factors. Furthermore, this result remains robust to score\nestimation errors. These findings highlight the remarkable effectiveness of\ndiffusion models in high-dimensional settings given the universal approximation\ncapability of GMMs, and provide theoretical insights into their practical\nsuccess.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,math.ST,stat.ML,stat.TH","published":"2025-04-07T17:59:07Z"}
{"aid":"http://arxiv.org/abs/2504.05629v1","title":"PTRL: Prior Transfer Deep Reinforcement Learning for Legged Robots\n  Locomotion","summary":"In the field of legged robot motion control, reinforcement learning (RL)\nholds great promise but faces two major challenges: high computational cost for\ntraining individual robots and poor generalization of trained models. To\naddress these problems, this paper proposes a novel framework called Prior\nTransfer Reinforcement Learning (PTRL), which improves both training efficiency\nand model transferability across different robots. Drawing inspiration from\nmodel transfer techniques in deep learning, PTRL introduces a fine-tuning\nmechanism that selectively freezes layers of the policy network during\ntransfer, making it the first to apply such a method in RL. The framework\nconsists of three stages: pre-training on a source robot using the Proximal\nPolicy Optimization (PPO) algorithm, transferring the learned policy to a\ntarget robot, and fine-tuning with partial network freezing. Extensive\nexperiments on various robot platforms confirm that this approach significantly\nreduces training time while maintaining or even improving performance.\nMoreover, the study quantitatively analyzes how the ratio of frozen layers\naffects transfer results, providing valuable insights into optimizing the\nprocess. The experimental outcomes show that PTRL achieves better walking\ncontrol performance and demonstrates strong generalization and adaptability,\noffering a promising solution for efficient and scalable RL-based control of\nlegged robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05638v1","title":"TAGC: Optimizing Gradient Communication in Distributed Transformer\n  Training","summary":"The increasing complexity of large language models (LLMs) necessitates\nefficient training strategies to mitigate the high computational costs\nassociated with distributed training. A significant bottleneck in this process\nis gradient synchronization across multiple GPUs, particularly in the\nzero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware\nGradient Compression (TAGC), an optimized gradient compression algorithm\ndesigned specifically for transformer-based models. TAGC extends the lossless\nhomomorphic compression method by adapting it for sharded models and\nincorporating transformer-specific optimizations, such as layer-selective\ncompression and dynamic sparsification. Our experimental results demonstrate\nthat TAGC accelerates training by up to 15% compared to the standard Fully\nSharded Data Parallel (FSDP) approach, with minimal impact on model quality. We\nintegrate TAGC into the PyTorch FSDP framework, the implementation is publicly\navailable at https://github.com/ipolyakov/TAGC.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T03:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.05657v1","title":"Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven\n  Speech Anti-spoofing","summary":"Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.SD","published":"2025-04-08T04:11:28Z"}
{"aid":"http://arxiv.org/abs/2504.05658v1","title":"Identification and estimation of causal peer effects using instrumental\n  variables","summary":"In social science researches, causal inference regarding peer effects often\nfaces significant challenges due to homophily bias and contextual confounding.\nFor example, unmeasured health conditions (e.g., influenza) and psychological\nstates (e.g., happiness, loneliness) can spread among closely connected\nindividuals, such as couples or siblings. To address these issues, we define\nfour effect estimands for dyadic data to characterize direct effects and\nspillover effects. We employ dual instrumental variables to achieve\nnonparametric identification of these causal estimands in the presence of\nunobserved confounding. We then derive the efficient influence functions for\nthese estimands under the nonparametric model. Additionally, we develop a\ntriply robust and locally efficient estimator that remains consistent even\nunder partial misspecification of the observed data model. The proposed robust\nestimators can be easily adapted to flexible approaches such as machine\nlearning estimation methods, provided that certain rate conditions are\nsatisfied. Finally, we illustrate our approach through simulations and an\nempirical application evaluating the peer effects of retirement on fluid\ncognitive perception among couples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T04:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.05707v1","title":"Hamilton-Jacobi-Bellman equation and Viscosity solutions for an optimal\n  control problem for stochastic convective Brinkman-Forchheimer equations","summary":"In this work, we consider the following two- and three-dimensional stochastic\nconvective Brinkman-Forchheimer (SCBF) equations in torus $\\mathbb{T}^d,\\\nd\\in\\{2,3\\}$:\n  \\begin{align*}\n  \\mathrm{d}\\boldsymbol{u}+\\left[-\\mu\n\\Delta\\boldsymbol{u}+(\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}+\\alpha\\boldsymbol{u}+\\beta|\\boldsymbol{u}|^{r-1}\\boldsymbol{u}+\\nabla\np\\right]\\mathrm{d}t=\\mathrm{d}\\mathrm{W}, \\ \\nabla\\cdot\\boldsymbol{u}=0,\n  \\end{align*}\n  where $\\mu,\\alpha,\\beta>0$, $r\\in[1,\\infty)$ and $\\mathrm{W}$ is a Hilbert\nspace valued $\\mathrm{Q}-$Wiener process. The above system can be considered as\ndamped stochastic Navier-Stokes equations. Using the dynamic programming\napproach, we study the infinite-dimensional second-order Hamilton-Jacobi\nequation associated with an optimal control problem for SCBF equations. For the\nsupercritical case, that is, $r\\in(3,\\infty)$ for $d=2$ and $r\\in(3,5)$ for\n$d=3$ ($2\\beta\\mu\\geq 1$ for $r=3$ in $d\\in\\{2,3\\}$), we first prove the\nexistence of a viscosity solution for the infinite-dimensional HJB equation,\nwhich we identify with the value function of the associated control problem. By\nestablishing a comparison principle for $r\\in(3,\\infty)$ and $r=3$ with\n$2\\beta\\mu\\geq1$ in $d\\in\\{2,3\\}$, we prove that the value function is the\nunique viscosity solution and hence we resolve the global unique solvability of\nthe HJB equation in both two and three dimensions.","main_category":"math.OC","categories":"math.OC,math.AP","published":"2025-04-08T06:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.05718v1","title":"CVA6-VMRT: A Modular Approach Towards Time-Predictable Virtual Memory in\n  a 64-bit Application Class RISC-V Processor","summary":"The increasing complexity of autonomous systems has driven a shift to\nintegrated heterogeneous SoCs with real-time and safety demands. Ensuring\ndeterministic WCETs and low-latency for critical tasks requires minimizing\ninterference on shared resources like virtual memory. Existing techniques, such\nas software coloring and memory replication, introduce significant area and\nperformance overhead, especially with virtualized memory where address\ntranslation adds latency uncertainty. To address these limitations, we propose\nCVA6-VMRT, an extension of the open-source RISC-V CVA6 core, adding hardware\nsupport for predictability in virtual memory access with minimal area overhead.\nCVA6-VMRT features dynamically partitioned Translation Look-aside Buffers\n(TLBs) and hybrid L1 cache/scratchpad memory (SPM) functionality. It allows\nfine-grained per-thread control of resources, enabling the operating system to\nmanage TLB replacements, including static overwrites, to ensure single-cycle\naddress translation for critical memory regions. Additionally, CVA6-VMRT\nenables runtime partitioning of data and instruction caches into cache and SPM\nsections, providing low and predictable access times for critical data without\nimpacting other accesses. In a virtualized setting, CVA6-VMRT enhances\nexecution time determinism for critical guests by 94% during interference from\nnon-critical guests, with minimal impact on their average absolute execution\ntime compared to isolated execution of the critical guests only. This\ninterference-aware behaviour is achieved with just a 4% area overhead and no\ntiming penalty compared to the baseline CVA6 core.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-08T06:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.05727v1","title":"SAP-CoPE: Social-Aware Planning using Cooperative Pose Estimation with\n  Infrastructure Sensor Nodes","summary":"Autonomous driving systems must operate safely in human-populated indoor\nenvironments, where challenges such as limited perception and occlusion\nsensitivity arise when relying solely on onboard sensors. These factors\ngenerate difficulties in the accurate recognition of human intentions and the\ngeneration of comfortable, socially aware trajectories. To address these\nissues, we propose SAP-CoPE, a social-aware planning framework that integrates\ncooperative infrastructure with a novel 3D human pose estimation method and a\nmodel predictive control-based controller. This real-time framework formulates\nan optimization problem that accounts for uncertainty propagation in the camera\nprojection matrix while ensuring human joint coherence. The proposed method is\nadaptable to single- or multi-camera configurations and can incorporate sparse\nLiDAR point-cloud data. To enhance safety and comfort in human environments, we\nintegrate a human personal space field based on human pose into a model\npredictive controller, enabling the system to navigate while avoiding\ndiscomfort zones. Extensive evaluations in both simulated and real-world\nsettings demonstrate the effectiveness of our approach in generating socially\naware trajectories for autonomous systems.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T06:55:39Z"}
{"aid":"http://arxiv.org/abs/2504.05733v1","title":"The evolution of a curve induced by the Pohlmeyer-Lund-Regge equation","summary":"This paper investigates the evolution of space curves governed by the\nPohlmeyer-Lund-Regge (PLR) equation, an integrable extension of the sine-Gordon\nequation. We examine a specific type of curve evolution, known as the\nLund-Regge evolution, and derive its representation in the Frenet frame. We\nshow the Frenet frame evolution aligns with the Lax system of the PLR equation\nand develop a construction method for curve families via the Sym formula. In\nconclusion, we describe the Lund-Regge evolution corresponding to Date's\nmulti-soliton solutions to the PLR equation, with illustrations of curves and\nsurfaces.","main_category":"math.DG","categories":"math.DG,nlin.SI","published":"2025-04-08T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.05746v1","title":"Exploiting Temporal Audio-Visual Correlation Embedding for Audio-Driven\n  One-Shot Talking Head Animation","summary":"The paramount challenge in audio-driven One-shot Talking Head Animation\n(ADOS-THA) lies in capturing subtle imperceptible changes between adjacent\nvideo frames. Inherently, the temporal relationship of adjacent audio clips is\nhighly correlated with that of the corresponding adjacent video frames,\noffering supplementary information that can be pivotal for guiding and\nsupervising talking head animations. In this work, we propose to learn\naudio-visual correlations and integrate the correlations to help enhance\nfeature representation and regularize final generation by a novel Temporal\nAudio-Visual Correlation Embedding (TAVCE) framework. Specifically, it first\nlearns an audio-visual temporal correlation metric, ensuring the temporal audio\nrelationships of adjacent clips are aligned with the temporal visual\nrelationships of corresponding adjacent video frames. Since the temporal audio\nrelationship contains aligned information about the visual frame, we first\nintegrate it to guide learning more representative features via a simple yet\neffective channel attention mechanism. During training, we also use the\nalignment correlations as an additional objective to supervise generating\nvisual frames. We conduct extensive experiments on several publicly available\nbenchmarks (i.e., HDTF, LRW, VoxCeleb1, and VoxCeleb2) to demonstrate its\nsuperiority over existing leading algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T07:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.05757v1","title":"A Douglas-Rachford Splitting Method for Solving Monotone Variational\n  Inequalities in Linear-quadratic Dynamic Games","summary":"This paper considers constrained linear dynamic games with quadratic\nobjective functions, which can be cast as affine variational inequalities. By\nleveraging the problem structure, we apply the Douglas-Rachford splitting,\nwhich generates a solution algorithm with linear convergence rate. The fast\nconvergence of the method enables receding-horizon control architectures.\nFurthermore, we demonstrate that the associated VI admits a closed-form\nsolution within a neighborhood of the attractor, thus allowing for a further\nreduction in computation time. Finally, we benchmark the proposed method via\nnumerical experiments in an automated driving application.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-08T07:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.05767v1","title":"Cross-Document Contextual Coreference Resolution in Knowledge Graphs","summary":"Coreference resolution across multiple documents poses a significant\nchallenge in natural language processing, particularly within the domain of\nknowledge graphs. This study introduces an innovative method aimed at\nidentifying and resolving references to the same entities that appear across\ndiffering texts, thus enhancing the coherence and collaboration of information.\nOur method employs a dynamic linking mechanism that associates entities in the\nknowledge graph with their corresponding textual mentions. By utilizing\ncontextual embeddings along with graph-based inference strategies, we\neffectively capture the relationships and interactions among entities, thereby\nimproving the accuracy of coreference resolution. Rigorous evaluations on\nvarious benchmark datasets highlight notable advancements in our approach over\ntraditional methodologies. The results showcase how the contextual information\nderived from knowledge graphs enhances the understanding of complex\nrelationships across documents, leading to better entity linking and\ninformation extraction capabilities in applications driven by knowledge. Our\ntechnique demonstrates substantial improvements in both precision and recall,\nunderscoring its effectiveness in the area of cross-document coreference\nresolution.","main_category":"cs.CL","categories":"cs.CL,cs.MA","published":"2025-04-08T07:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.05773v1","title":"Simultaneous Multiphoton-Multiatom Processes in Atomic Gases under Laser\n  Fields","summary":"We investigate simultaneous multiphoton-multiatom processes in atomic gases\nexposed to laser fields under specific frequency conditions, where multiple\natoms are simultaneously excited through the absorption of one laser photon\neach. These processes represent natural high-order quantum electrodynamics\n(QED) effects that occur independently of inter-atomic interactions. A\ncharacteristic length scale emerges, governing the physical range over which\nthese phenomena manifest. We propose experiments to demonstrate the fundamental\naspects of these collective QED processes.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas","published":"2025-04-08T07:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.05793v1","title":"Negotiating Strict Latency Limits for Dynamic Real-Time Services in\n  Vehicular Time-Sensitive Networks","summary":"Future vehicles are expected to dynamically deploy in-vehicle applications\nwithin a Service-Oriented Architecture (SOA). Critical services operate under\nhard real-time constraints, which Time-Sensitive Networking (TSN) complements\non the in-vehicle Ethernet layer. TSN ensures deterministic communication\nbetween critical services and its Credit-Based Shaper (CBS) supports dynamic\nresource reservations. However, the dynamic nature of service deployment\nchallenges network resource configuration, since any new reservation may change\nthe latency of already validated flows. In addition, standard methods of\nworst-case latency analysis for CBS have been found incorrect, and current TSN\nstream reservation procedures lack mechanisms to signal application layer\nQuality-of-Service (QoS) requirements or verify deadlines. In this paper, we\npropose a QoS negotiation scheme within the automotive SOA that interacts with\nthe TSN network controller to reserve resources while ensuring latency bounds.\nWe comparatively evaluate reservation schemes using worst-case analysis and\nsimulations of a realistic In-Vehicle Network (IVN) for demonstrating their\nimpact on QoS guarantees, resource utilization, and setup times. We find that\nonly a reservation scheme utilizing per-queue delay budgets and network\ncalculus provides valid configurations and guarantees acceptable latency bounds\nthroughout the IVN. The proposed service negotiation mechanism efficiently\nestablishes 450 vehicular network reservations in just 11ms.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-08T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.05811v1","title":"Effects of strange molecular partners of $P_c$ states in $γp \\to K\n  Σ$ reactions","summary":"Our previous studies revealed evidence of the strange molecular partners of\n$P_c$ states, $N(2080)3/2^-$ and $N(2270)3/2^-$, in the $\\gamma p \\to K^{*+}\n\\Sigma^0 / K^{*0} \\Sigma^+$ and $\\gamma p \\to \\phi p$ reactions. Motivated by\nthe differential cross-section data for $\\gamma p \\to K^+ \\Sigma^0$ from CLAS\n2010, which exhibits some bump structures at $W \\approx$ 1875, 2080 and 2270\nMeV, we extend our previous analysis by investigating the effects of\n$N(1535)1/2^-$, $N(1875)3/2^-$, $N(2080)1/2^- \\&\\ 3/2^-$ and $N(2270)1/2^- ,\n3/2^- \\&\\ 5/2^-$, as strange partners of $P_c$ molecular states, in the\nreactions $\\gamma p \\to K^+ \\Sigma^0$ and $\\gamma p \\to K^0 \\Sigma^+$. The\ntheoretical model employed in this study utilizes an effective Lagrangian\napproach in the tree-level Born approximation. It contains the contributions\nfrom $s$-channel with exchanges of $N$, $\\Delta$, $N^*$ (including the hadronic\nmolecules with hidden strangeness), and $\\Delta^*$; $t$-channel; $u$-channel;\nand the generalized contact term. The results corresponding to the final fitted\nparameters are in good agreement with all available experimental data of both\ncross-sections and polarization observables for $\\gamma p \\to K^+ \\Sigma^0$ and\n$\\gamma p \\to K^0 \\Sigma^+$. Notably, the $s$-channel exchanges of molecules\nsignificantly contribute to the bump structures in cross-sections for $\\gamma p\n\\to K \\Sigma$ at $W \\approx$ 1900, 2080 and 2270 MeV, and show considerable\ncoherence with contributions from $s$-channel exchanges of general resonances\nto construct the overall structures of cross-sections. More abundant\nexperiments, particularly for the reaction $\\gamma p \\to K^0 \\Sigma^+$, are\nnecessary to further strengthen the constraints on the theoretical models.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-08T08:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.05815v1","title":"Parasite: A Steganography-based Backdoor Attack Framework for Diffusion\n  Models","summary":"Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:53:47Z"}
{"aid":"http://arxiv.org/abs/2504.05817v1","title":"Combinatorial Ricci flows on infinite disk triangulations","summary":"In this paper, we introduce combinatorial Ricci flows (CRFs in short) in\nEuclidean and hyperbolic background geometries on infinite triangulations of\nthe open disk, which are discrete analogs of Ricci flows on simply connected\nopen surfaces. We establish well-posedness results, the existence and the\nuniqueness, of CRFs in both Euclidean and hyperbolic background geometries.\nMoreover, we prove convergence results of CRFs, which indicate a uniformization\ntheorem for CRFs on infinite disk triangulations. As an application, we prove\nan existence result of circle-packing metrics with infinite prescribed cone\nangles in hyperbolic background geometry. To our knowledge, these are the first\nresults of CRFs on infinite triangulations.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-08T08:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.05821v1","title":"On the Hopf envelope of finite-dimensional bialgebras","summary":"The Hopf envelope of a bialgebra is the free Hopf algebra generated by the\ngiven bialgebra. Its existence, as well as that of the cofree Hopf algebra, is\na well-known fact in Hopf algebra theory, but their construction is not\nparticularly handy or friendly. In this note, we offer a novel realisation of\nthe Hopf envelope and of the cofree Hopf algebra of a finite-dimensional\nbialgebra as a particular quotient and sub-bialgebra, respectively, of the\nbialgebra itself. Our construction can also be extended to the\ninfinite-dimensional case, provided that the bialgebra satisfies additional\nconditions, such as being left Artinian as an algebra or admitting a\n$n$-antipode, the latter being a notion hereby introduced.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA,math.RT","published":"2025-04-08T09:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05832v1","title":"Channel State Information Analysis for Jamming Attack Detection in\n  Static and Dynamic UAV Networks -- An Experimental Study","summary":"Networks built on the IEEE 802.11 standard have experienced rapid growth in\nthe last decade. Their field of application is vast, including smart home\napplications, Internet of Things (IoT), and short-range high throughput static\nand dynamic inter-vehicular communication networks. Within such networks,\nChannel State Information (CSI) provides a detailed view of the state of the\ncommunication channel and represents the combined effects of multipath\npropagation, scattering, phase shift, fading, and power decay. In this work, we\ninvestigate the problem of jamming attack detection in static and dynamic\nvehicular networks. We utilize ESP32-S3 modules to set up a communication\nnetwork between an Unmanned Aerial Vehicle (UAV) and a Ground Control Station\n(GCS), to experimentally test the combined effects of a constant jammer on\nrecorded CSI parameters, and the feasibility of jamming detection through CSI\nanalysis in static and dynamic communication scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.RO","published":"2025-04-08T09:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05848v1","title":"Relativistic limits on the discretization and temporal resolution of a\n  quantum clock","summary":"We provide a brief discussion regarding relativistic limits on the\ndiscretization and temporal resolution of time values in a quantum clock. Our\nclock is characterized by a time observable chosen to be the complement of a\nbounded and discrete Hamiltonian which can have an equally-spaced or a generic\nspectrum. In the first case the time observable can be described by an\nHermitian operator and we find a limit in the discretization for the time\neigenvalues. Nevertheless, in both cases, the time observable can be described\nby a POVM and, by increasing the number of time states, we can arbitrarily\nreduce the bound on the minimum time quantum, demonstrating that we can safely\ntake the time values as continuous when the number of time states tends to\ninfinity. Finally, we find a limit for temporal resolution of our time\nobservable when the clock is used (together with light signals) in a\nrelativistic framework for measuring spacetime distances.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:27:41Z"}
{"aid":"http://arxiv.org/abs/2504.05868v1","title":"Energy-Conserving Neural Network Closure Model for Long-Time Accurate\n  and Stable LES","summary":"Machine learning-based closure models for LES have shown promise in capturing\ncomplex turbulence dynamics but often suffer from instabilities and physical\ninconsistencies. In this work, we develop a novel skew-symmetric neural\narchitecture as closure model that enforces stability while preserving key\nphysical conservation laws. Our approach leverages a discretization that\nensures mass, momentum, and energy conservation, along with a face-averaging\nfilter to maintain mass conservation in coarse-grained velocity fields. We\ncompare our model against several conventional data-driven closures (including\nunconstrained convolutional neural networks), and the physics-based Smagorinsky\nmodel. Performance is evaluated on decaying turbulence and Kolmogorov flow for\nmultiple coarse-graining factors. In these test cases we observe that\nunconstrained machine learning models suffer from numerical instabilities. In\ncontrast, our skew-symmetric model remains stable across all tests, though at\nthe cost of increased dissipation. Despite this trade-off, we demonstrate that\nour model still outperforms the Smagorinsky model in unseen scenarios. These\nfindings highlight the potential of structure-preserving machine learning\nclosures for reliable long-time LES.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-08T09:49:18Z"}
{"aid":"http://arxiv.org/abs/2504.05873v1","title":"Leptophilic ALPs in Laboratory Experiments","summary":"We study the collider phenomenology of leptophilic axion-like particles\n(ALPs), i.e. pseudoscalar particles that couple only to charged leptons. Loops\nof charged leptons induce effective interactions of the ALPs with photons,\nwhich depend on the momenta of the interacting particles and differ between\npseudoscalar and derivative lepton couplings. We systematically discuss the\nform of the interaction with photons for general external momenta and identify\nthe regimes when it can be safely approximated by an effective coupling\nconstant. We use these results to derive novel constraints from LEP and\ncalculate state-of-the-art limits from E137 and NA64 for four different\nscenarios, in which the ALPs couple either to a single lepton generation or\nuniversally to all, for both pseudoscalar and derivative lepton couplings. We\ncollect complementary bounds from astrophysics, flavour, and other laboratory\nexperiments to chart the allowed parameter space of leptophilic ALPs in the\nMeV-GeV mass range.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T09:58:09Z"}
{"aid":"http://arxiv.org/abs/2504.05911v1","title":"A note on the stability of self-similar blow-up solutions for\n  superconformal semilinear wave equations","summary":"In this note, we investigate the stability of self-similar blow-up solutions\nfor superconformal semilinear wave equations in all dimensions. A central\naspect of our analysis is the spectral equivalence of the linearized operators\nunder Lorentz transformations in self-similar variables. This observation\nserves as a useful tool in proving mode stability and provides insights that\nmay aid the study of self-similar solutions in related problems. As a direct\nconsequence, we establish the asymptotic stability of the ODE blow-up family,\nextending the classical results of Merle and Zaag [Merle-Zaag, 2007, 2016] to\nthe superconformal case and generalizing the recent findings of Ostermann\n[Ostermann, 2024] to include the entire ODE blow-up family.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T11:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.05937v1","title":"On the Hamilton-Jacobi approach to inflation beyond slow roll","summary":"The Hamilton-Jacobi approach is a powerful tool to describe super-Hubble\ndynamics during cosmological inflation in a non-linear way. A key assumption of\nthis framework is to neglect anisotropic perturbations on large scales. We show\nthat neglecting the anisotropic sector in the momentum constraint corresponds\nto discarding the non-adiabatic mode of scalar-field perturbations at large\nscales. Consequently, the Hamilton-Jacobi approach cannot be used to describe\nthe evolution of large-scale perturbations during inflation beyond slow roll,\nwhen non-adiabatic fluctuations play an important role on super-Hubble scales\ndue to the absence of an attractor trajectory. As an example, we analyse the\ncase of cosmological perturbations during a phase of ultra-slow-roll inflation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-08T11:52:44Z"}
{"aid":"http://arxiv.org/abs/2504.05938v1","title":"Umbral oscillations in the photosphere. A comprehensive statistical\n  study","summary":"It is well-known that the global acoustic oscillations of the Sun's\natmosphere can excite resonance modes within large-scale magnetic\nconcentrations. These structures are conduits of energy between the different\nlayers of the solar atmosphere, and understanding their dynamics can explain\nthe processes behind coronal heating and solar wind acceleration. In this work,\nwe studied the Doppler velocity spectrum of more than a thousand large-scale\nmagnetic structures (i.e., sunspots) in the solar photosphere that crossed near\nthe disk centre of the Sun. We exploited the excellent stability and\nseeing-free conditions of the Helioseismic and Magnetic Imager (HMI) instrument\nonboard the Solar Dynamics Observatory (SDO) to cover nearly seven years of\nobservations, providing the most comprehensive statistical analysis of its\nkind. Here, we show that the power spectra of the umbra of sunspots in the\nphotosphere is remarkably different from the one of quiet-Sun regions, with\nboth exhibiting a primary peak at 3.3 mHz, but the sunspot umbrae also\ndisplaying a closely packed series of secondary peaks in the $4-6$~mHz band.\nUnderstanding the origin of such peaks is a challenging task. Here, we explore\nseveral possible explanations for the observed oscillations, all pointing\ntoward a potential resonant interaction within these structures and an unknown\ndriver. Our observational result provides further insight into the magnetic\nconnectivity between the different layers of the dynamic atmosphere of the Sun.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.05940v1","title":"A Lorentz Covariant Matrix Model for Bosonic M2-Branes: Nambu Brackets\n  and Restricted Volume-Preserving Deformations","summary":"We propose a Lorentz covariant matrix model as a nonperturbative formulation\nof the bosonic M2-brane in M-theory. Unlike previous approaches relying on the\nlight-cone gauge or symmetry-based constructions, our model retains full\n11-dimensional Lorentz invariance by introducing a novel gauge-fixing condition\nthat restricts the symmetry of volume-preserving deformations (VPD) to a\nsubclass, which we call restricted VPD (RVPD). This restriction enables a\nconsistent matrix regularization of the Nambu bracket, bypassing the\nlong-standing obstructions related to the Leibniz rule and the Fundamental\nIdentity. The resulting model exhibits RVPD symmetry, admits particle-like and\nnoncommutative membrane solutions, and lays the foundation for a\nLorentz-invariant, nonperturbative matrix description of M2-branes. Our work\noffers a new paradigm for constructing Lorentz-invariant matrix models of\nmembranes, revisiting the algebraic structure underlying M-theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-08T11:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.05942v1","title":"Higher-order meshless schemes for hyperbolic equations","summary":"We discuss the order, efficiency, stability and positivity of several\nmeshless schemes for linear scalar hyperbolic equations. Meshless schemes are\nGeneralised Finite Difference Methods (GFDMs) for arbitrary irregular grids in\nwhich there is no connectivity between the grid points. We propose a new\nMUSCL-like meshless scheme that uses a central stencil, with which we can\nachieve arbitrarily high orders, and compare it to existing meshless upwind\nschemes and meshless WENO schemes. The stability of the newly proposed scheme\nis guaranteed by an upwind reconstruction to the midpoints of the stencil. The\nnew meshless MUSCL scheme is also efficient due to the reuse of the GFDM\nsolution in the reconstruction. We combine the new MUSCL scheme with a\nMulti-dimensional Optimal Order Detection (MOOD) procedure to avoid spurious\noscillations at discontinuities. In one spatial dimension, our fourth order\nMUSCL scheme outperforms existing WENO and upwind schemes in terms of stability\nand accuracy. In two spatial dimensions, our MUSCL scheme achieves similar\naccuracy to an existing WENO scheme but is significantly more stable.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T11:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.05949v1","title":"Sharp fractional Hardy's inequality for half-spaces in the Heisenberg\n  group","summary":"In this work we establish the following fractional Hardy's inequality\n  $$C\\int_{\\mathbb{H}^n_+}\\frac{|f(\\xi)|^p}{x_1^{sp+\\alpha}}d\\xi\\leq\n\\int_{\\mathbb{H}^n}\\int_{\\mathbb{H}^n}\\frac{|f(\\xi)-f(\\xi')|^p}{d({\\xi}^{-1}\\circ\n\\xi')^{Q+sp}|z'-z|^\\alpha}d\\xi'd\\xi,\\ \\ \\forall f\\in\nC_c^{\\infty}(\\mathbb{H}^n_+)$$\n  for the half-space\n$\\{\\xi=(x,y,t)=(x_1,\\ldots,x_n,y_1,\\ldots,y_n)\\in\\mathbb{H}^n:x_1>0\\}$ in the\nHeisenberg group $\\mathbb{H}^n$ without any restriction on parameters, and\ncompute the corresponding sharp constant. In a previous joint work, we\nestablished a variant of Hardy's inequality for the same half-space, but with\ncertain parameter restrictions. However, all integrals in that work were\nconsidered over half-spaces, and here the seminorm is taken over the entire\n$\\mathbb{H}^n$. Although this inequality holds for all values of the quantity\n$sp+\\alpha$, we are only able to compute the corresponding sharp constant when\n$sp+\\alpha>1$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.05955v1","title":"Fair Resource Allocation in UAV-based Semantic Communication System with\n  Fluid Antenna","summary":"In this paper, the problem of maximization of the minimum equivalent rate in\na unmanned-aerial-vehicle (UAV)-based multi-user semantic communication system\nis investigated. In the considered model, a multi-antenna UAV employs semantic\nextraction techniques to compress the data ready to be sent to the users, which\nare equipped with fluid antennas. Our aim is to jointly optimize the trajectory\nof the UAV, the transmit beamforming and the semantic compression rate at the\nUAV, as well as the selection of activated ports in fluid antenna system (FAS),\nto maximize the minimum equivalent transmission rate among all user. An\nalternating algorithm is designed to solve the problem. Simulation results\nvalidate the effectiveness of the proposed algorithm.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T12:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.05957v1","title":"Drought forecasting using a hybrid neural architecture for integrating\n  time series and static data","summary":"Reliable forecasting is critical for early warning systems and adaptive\ndrought management. Most previous deep learning approaches focus solely on\nhomogeneous regions and rely on single-structured data. This paper presents a\nhybrid neural architecture that integrates time series and static data,\nachieving state-of-the-art performance on the DroughtED dataset. Our results\nillustrate the potential of designing neural models for the treatment of\nheterogeneous data in climate related tasks and present reliable prediction of\nUSDM categories, an expert-informed drought metric. Furthermore, this work\nvalidates the potential of DroughtED for enabling location-agnostic training of\ndeep learning models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T12:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.05965v1","title":"Generalized Parameter Lifting: Finer Abstractions for Parametric Markov\n  Chains","summary":"Parametric Markov chains (pMCs) are Markov chains (MCs) with symbolic\nprobabilities. A pMC encodes a family of MCs, where each member is obtained by\nreplacing parameters with constants. The parameters allow encoding dependencies\nbetween transitions, which sets pMCs apart from interval MCs. The verification\nproblem for pMCs asks whether each MC in the corresponding family satisfies a\ngiven temporal specification. The state-of-the-art approach for this problem is\nparameter lifting (PL) -- an abstraction-refinement loop that abstracts the pMC\nto a non-parametric model analyzed with standard probabilistic model checking\ntechniques. This paper presents two key improvements to tackle the main\nlimitations of PL. First, we introduce generalized parameter lifting (GPL) to\nlift various restrictive assumptions made by PL. Second, we present a big-step\ntransformation algorithm that reduces parameter dependencies in pMCs and,\ntherefore, results in tighter approximations. Experiments show that GPL is\nwidely applicable and that the big-step transformation accelerates pMC\nverification by up to orders of magnitude.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-08T12:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.05990v1","title":"AI analysis of medical images at scale as a health disparities probe: a\n  feasibility demonstration using chest radiographs","summary":"Health disparities (differences in non-genetic conditions that influence\nhealth) can be associated with differences in burden of disease by groups\nwithin a population. Social determinants of health (SDOH) are domains such as\nhealth care access, dietary access, and economics frequently studied for\npotential association with health disparities. Evaluating SDOH-related\nphenotypes using routine medical images as data sources may enhance health\ndisparities research. We developed a pipeline for using quantitative measures\nautomatically extracted from medical images as inputs into health disparities\nindex calculations. Our study focused on the use case of two SDOH demographic\ncorrelates (sex and race) and data extracted from chest radiographs of 1,571\nunique patients. The likelihood of severe disease within the lung parenchyma\nfrom each image type, measured using an established deep learning model, was\nmerged into a single numerical image-based phenotype for each patient. Patients\nwere then separated into phenogroups by unsupervised clustering of the\nimage-based phenotypes. The health rate for each phenogroup was defined as the\nmedian image-based phenotype for each SDOH used as inputs to four\nimaging-derived health disparities indices (iHDIs): one absolute measure\n(between-group variance) and three relative measures (index of disparity, Theil\nindex, and mean log deviation). The iHDI measures demonstrated feasible values\nfor each SDOH demographic correlate, showing potential for medical images to\nserve as a novel probe for health disparities. Large-scale AI analysis of\nmedical images can serve as a probe for a novel data source for health\ndisparities research.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-08T12:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.06024v1","title":"AriaQuanta: A Quantum Software for Quantum Computing","summary":"We introduce AriaQuanta, a powerful and flexible tool for designing,\nsimulating, and implementing quantum circuits. This open-source software is\ndesigned to make it easy for users of all experience levels to learn and use\nquantum computing. The first version includes a compiler for implementing\nvarious quantum circuits and algorithms. Additionally, parametric circuits\nallow for the implementation of variational quantum algorithms, and various\nnoise models are available for simulating noisy circuits. We performed numerous\nnumerical simulations on AriaQuanta in various applications, including quantum\nalgorithms and noisy circuits. The results, compared with popular counterparts,\ndemonstrate the high performance of AriaQuanta.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:27:58Z"}
{"aid":"http://arxiv.org/abs/2504.06036v1","title":"Multi-Sense Embeddings for Language Models and Knowledge Distillation","summary":"Transformer-based large language models (LLMs) rely on contextual embeddings\nwhich generate different (continuous) representations for the same token\ndepending on its surrounding context. Nonetheless, words and tokens typically\nhave a limited number of senses (or meanings). We propose multi-sense\nembeddings as a drop-in replacement for each token in order to capture the\nrange of their uses in a language. To construct a sense embedding dictionary,\nwe apply a clustering algorithm to embeddings generated by an LLM and consider\nthe cluster centers as representative sense embeddings. In addition, we propose\na novel knowledge distillation method that leverages the sense dictionary to\nlearn a smaller student model that mimics the senses from the much larger base\nLLM model, offering significant space and inference time savings, while\nmaintaining competitive performance. Via thorough experiments on various\nbenchmarks, we showcase the effectiveness of our sense embeddings and knowledge\ndistillation approach. We share our code at\nhttps://github.com/Qitong-Wang/SenseDict","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T13:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06052v1","title":"Categorical matrix factorizations and monomorphism categories","summary":"This article generalizes the correspondence between matrix factorizations and\nmaximal Cohen-Macaulay modules over hypersurface rings due to Eisenbud and\nYoshino. We consider factorizations with several factors in a purely\ncategorical context, extending results of Sun and Zhang for Gorenstein\nprojective module factorizations. Our formulation relies on a notion of\nhypersurface category and replaces Gorenstein projectives by objects of general\nFrobenius exact subcategories. We show that factorizations over such categories\nform again a Frobenius category. Our main result is then a triangle equivalence\nbetween the stable category of factorizations and that of chains of\nmonomorphisms.","main_category":"math.CT","categories":"math.CT,math.AC","published":"2025-04-08T13:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.06056v1","title":"$L_\\textrm{dT}$: An ionospheric activity index based on distributions in\n  GNSS-derived TEC rates of change","summary":"Many aspects of our societies now depend upon satellite telecommunications,\nsuch as those requiring Global Navigation Satellite Systems (GNSS). GNSS is\nbased on radio waves that propagate through the ionosphere and experience\ncomplicated propagation effects caused by inhomogeneities in its electron\ndensity. The Earth's ionosphere forms part of the solar-terrestrial\nenvironment, and its state is determined by the spatial distribution and\ntemporal evolution of its electron density. It varies in response to the \"space\nweather\" combination of solar activity and geomagnetic conditions. Notably, the\nradio waves used in satellite telecommunications suffer due to the dispersive\nnature of the ionospheric plasma.\n  Scales and indices that summarise the state of the solar-terrestrial\nenvironment due to solar activity and geomagnetic conditions already exist.\nHowever, the response of the ionosphere to active geomagnetic conditions, its\ngeoeffectiveness, and its likely impact on systems and services are not\nencapsulated by these. This is due to the ionosphere's intrinsic day-to-day\nvariability, persistent seasonal patterns, and because radio wave measurements\nof the ionosphere depend upon many factors.\n  Here we develop a novel index that describes the state of the ionosphere\nduring specific space weather conditions. It is based on propagation\ndisturbances in GNSS signals, and is able to characterise the spatio-temporal\nevolution of ionospheric disturbances in near real time. This new scale\nencapsulates day-to-day variability, seasonal patterns, and the geo-effective\nresponse of the ionosphere to disturbed space weather conditions; and can be\napplied to data from any GNSS network. It is intended that this new scale will\nbe utilised by agencies providing space weather services, as well as by service\noperators to appreciate the current conditions in the ionosphere, thus\ninforming their operations.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-08T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.06078v1","title":"Carbon, Cost and Capacity: Multi-objective Charging of Electric Buses","summary":"The public transport sector is in the process of decarbonizing by\nelectrifying its bus fleets. This results in challenges if the high electricity\ndemand resulting from battery charging demand is confronted with limited grid\ncapacity and high synchronicity at bus charging sites. In this paper, we\nexplore multi-objective scheduling for bus charging sites to minimize the\nemissions associated with charging processes and to aid the operation of the\nelectricity grid by mitigating peak consumption. In particular, we discuss and\nvalidate optimization approaches for those objectives, as well as their\nweighted combination, based on data from a real-life bus charging site in the\nNetherlands. The simulation results show that compared to uncontrolled\ncharging, power peaks can be reduced by up to 57%, while time-of-use emissions\nassociated with the charging of electric buses are also reduced significantly.\nFurthermore, by using a synthetic baseload, we illustrate the flexibility\npotential offered by bus charging sites, and advocate that such sites should\nshare a grid connection with other high-load assets.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T14:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.06085v1","title":"Contact embeddings of 3-dimensional contact groups","summary":"A 3-dimensional contact group is a 3-dimensional Lie group endowed with a\nleft-invariant contact structure. Making use of techniques from Riemannian\ngeometry, we prove that any simply connected 3-dimensional contact group not\nisomorphic to SU(2) satisfies a unique factorization property. As an\napplication, we develop a method to construct embeddings of 3-dimensional\nsimply connected contact groups into one among two model tight contact\nmanifolds.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-08T14:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.06088v1","title":"MCAT: Visual Query-Based Localization of Standard Anatomical Clips in\n  Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer","summary":"Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:29:15Z"}
{"aid":"http://arxiv.org/abs/2504.06089v1","title":"A Monotonicity Formula for the Extrinsic Biharmonic Map Heat Flow","summary":"We explore novel properties of the biharmonic heat kernel on Euclidean space\nand derive an entropy type quantity for the extrinsic biharmonic map heat flow\nwhich exhibits monotonicity behaviors for $n\\leq 4$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-08T14:30:03Z"}
{"aid":"http://arxiv.org/abs/2504.06090v1","title":"Low-Complexity SDP-ADMM for Physical-Layer Multicasting in Massive MIMO\n  Systems","summary":"There is a demand for the same data content from several user equipments\n(UEs) in many wireless communication applications. Physical-layer multicasting\ncombines the beamforming capability of massive MIMO (multiple-input\nmultiple-output) and the broadcast nature of the wireless channel to\nefficiently deliver the same data to a group of UEs using a single\ntransmission. This paper tackles the max-min fair (MMF) multicast beamforming\noptimization, which is an NP-hard problem. We develop an efficient semidefinite\nprogram-alternating direction method of multipliers (SDP-ADMM) algorithm to\nfind the near-global optimal rank-1 solution to the MMF multicast problem in a\nmassive MIMO system. Numerical results show that the proposed SDP-ADMM\nalgorithm exhibits similar spectral efficiency performance to state-of-the-art\nalgorithms running on standard SDP solvers at a vastly reduced computational\ncomplexity. We highlight that the proposed ADMM elimination procedure can be\nemployed as an effective low-complexity rank reduction method for other\nproblems utilizing semidefinite relaxation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T14:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.06092v1","title":"Greedy Emulators for Nuclear Two-Body Scattering","summary":"Applications of reduced basis method emulators are increasing in low-energy\nnuclear physics because they enable fast and accurate sampling of high-fidelity\ncalculations, enabling robust uncertainty quantification. In this paper, we\ndevelop, implement, and test two model-driven emulators based on\n(Petrov-)Galerkin projection using the prototypical test case of two-body\nscattering with the Minnesota potential and a more realistic local chiral\npotential. The high-fidelity scattering equations are solved with the matrix\nNumerov method, a reformulation of the popular Numerov recurrence relation for\nsolving special second-order differential equations as a linear system of\ncoupled equations. A novel error estimator based on reduced-space residuals is\napplied to an active learning approach (a greedy algorithm) to choosing\ntraining samples (\"snapshots\") for the emulator and contrasted with a proper\northogonal decomposition (POD) approach. Both approaches allow for\ncomputationally efficient offline-online decompositions, but the greedy\napproach requires much fewer snapshot calculations. These developments set the\ngroundwork for emulating scattering observables based on chiral nucleon-nucleon\nand three-nucleon interactions and optical models, where computational\nspeed-ups are necessary for Bayesian uncertainty quantification. Our emulators\nand error estimators are widely applicable to linear systems.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex,physics.data-an","published":"2025-04-08T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06098v1","title":"Extremely asymmetric bipolar magnetic field of the Bp star HD 57372","summary":"Fossil magnetic fields of early-type stars are typically characterised by\nsymmetric or slightly distorted oblique dipolar surface geometries. Contrary to\nthis trend, the late-B magnetic chemically peculiar star HD 57372 exhibits an\nunusually large rotational variation of its mean magnetic field modulus,\nsuggesting a highly atypical field configuration. In this study, we present a\nZeeman Doppler imaging analysis of HD 57372, revealing an exceptionally\nasymmetric bipolar magnetic topology, rarely observed in early-type stars.\nAccording to our magnetic field maps, reconstructed from the intensity and\ncircular polarisation profiles of Fe, Cr, and Ti lines, approximately 66 per\ncent of the stellar surface is covered by a diffuse outward-directed radial\nfield, with local field strengths reaching 11.6 kG, while the remaining 34 per\ncent hosts a highly concentrated inward-directed field with a strong horizontal\ncomponent and a peak strength of 17.8 kG. These unusual surface magnetic field\ncharacteristics make HD 57372 a notable object for testing fossil-field\ntheories and interpreting phase-resolved spectropolarimetric observations of\nearly-type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T14:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.06099v1","title":"Towards Varroa destructor mite detection using a narrow spectra\n  illumination","summary":"This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.06116v1","title":"To Match or Not to Match: Revisiting Image Matching for Reliable Visual\n  Place Recognition","summary":"Visual Place Recognition (VPR) is a critical task in computer vision,\ntraditionally enhanced by re-ranking retrieval results with image matching.\nHowever, recent advancements in VPR methods have significantly improved\nperformance, challenging the necessity of re-ranking. In this work, we show\nthat modern retrieval systems often reach a point where re-ranking can degrade\nresults, as current VPR datasets are largely saturated. We propose using image\nmatching as a verification step to assess retrieval confidence, demonstrating\nthat inlier counts can reliably predict when re-ranking is beneficial. Our\nfindings shift the paradigm of retrieval pipelines, offering insights for more\nrobust and adaptive VPR systems.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.06117v1","title":"Some Analytical Properties of Multivariate Fractal Functions in Lebesgue\n  Spaces","summary":"In this article, we focus on the construction of multivariate fractal\nfunctions in Lebesgue spaces along with some properties of associated fractal\noperator. First, we give a detailed construction of the fractal functions\nbelonging to Lebesgue spaces. Then, we give analytical properties of the\ndefined fractal operator in Lebesgue spaces. We end this article by showing the\nexistence of Schauder basis of the associated fractal functions for the space\n$\\mathcal{L}^q(I^n, \\mu_p)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T15:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.06131v1","title":"FaceCloak: Learning to Protect Face Templates","summary":"Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face raising security\nand privacy concerns. We present FaceCloak, a neural network framework that\nprotects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperforms leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. FaceCloak-based matching is\nextremely fast (inference time cost=0.28ms) and light-weight (0.57MB).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06136v1","title":"QGen Studio: An Adaptive Question-Answer Generation, Training and\n  Evaluation Platform","summary":"We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T15:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.06137v1","title":"Coexistence of magnetic and dielectric glassy states in alternating\n  kagome and triangular lattice LuBaCo$_4$O$_7$ cobaltite","summary":"To date, the alternating kagome and triangular lattice cobaltites,\nRBaCo$_4$O$_7$ (R = Ca, Y, and rare earth elements), have been well studied for\ntheir large structural distortions, anisotropic exchange interactions, chiral\nspin liquid states, and giant multiferroic properties. Here, we report the\nco-existence of magnetic and dielectric glassy states in LuBaCo$_4$O$_7$ below\n50 K. AC magnetization studies show an absence of conventional spin-freezing\nbehavior. The cooling and heating in unequal fields (CHUF), thermal cycling,\nand time-dependent magnetization measurements at low temperature ($T$) show the\npresence of magnetic glassy state. The $T$-dependent dielectric constant\n$\\epsilon'$ measurements exhibit a strong frequency-independent response at the\nfirst-order structural phase transition $T = 160$ K (trigonal $P31c$ to\nmonoclinic $Cc$) and also significant features at the $T = 110$ K (monoclinic\n$Cc$ to orthorhombic $Pbn2_1$) phase transition. Further, $\\epsilon'$ shows a\nfrequency-independent peak at 43 K ($Pbn2_1$) and also dipolar glassy features\nbelow 20 K ($Cc$). The non-equilibrium magnetic glassy dynamics and dipolar\nglassy state at low-$T$ arises from the kinetic arrest of $Cc$ and $Pbn2_1$\nphases. From the dielectric probe, we are able to clearly distinguish the\nkinetically arrested phases at low-$T$ , whereas the bulk magnetization studies\nare unable to do so as the arrested phases have low magnetic moments.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T15:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.06184v1","title":"The two-loop Higgs impact factor","summary":"In the HEFT, we consider the Regge limit of the two-loop amplitudes for Higgs\nboson production in association with a jet, expanded to NNLL accuracy. We\ndiscuss the issue of the Regge cuts versus poles in this context, and determine\nfor the first time the Higgs impact factor at two-loop accuracy.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T16:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.06235v1","title":"Decentralized Federated Domain Generalization with Style Sharing: A\n  Formal Modeling and Convergence Analysis","summary":"Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06238v1","title":"Infinite Boundary Friction Limit for Weak Solutions of the Stochastic\n  Navier-Stokes Equations","summary":"We address convergence of the unique weak solutions of the 2D stochastic\nNavier-Stokes equations with Navier boundary conditions, as the boundary\nfriction is taken uniformly to infinity, to the unique weak solution under the\nno-slip condition. Our result is that for initial velocity in $L^2_x$, the\nconvergence holds in probability in $C_tW^{-\\varepsilon,2}_x \\cap L^2_tL^2_x$\nfor any $0 < \\varepsilon$. The noise is of transport-stretching type, although\nthe theorem holds with other transport, multiplicative and additive noise\nstructures. This seems to be the first work concerning the large boundary\nfriction limit with noise, and convergence for weak solutions, due to only\n$L^2_{x}$ initial data, appears new even deterministically.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T17:34:29Z"}
{"aid":"http://arxiv.org/abs/2504.06239v1","title":"Canonical for Automated Theorem Proving in Lean","summary":"Canonical is a solver for type inhabitation in dependent type theory, that\nis, the problem of producing a term of a given type. We present a Lean tactic\nwhich invokes Canonical to generate proof terms and synthesize programs. The\ntactic supports higher-order and dependently-typed goals, structural recursion\nover indexed inductive types, and definitional equality. Canonical finds proofs\nfor 84% of Natural Number Game problems in 51 seconds total.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-08T17:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.06266v1","title":"Constraining the [CII] luminosity function from the power spectrum of\n  line intensity maps at redshift 3.6","summary":"Forthcoming measurements of the line-intensity-mapping power spectrum (PS)\nare expected to set precious constraints on several quantities of astrophysical\nand cosmological interest. Our study targets the [CII] luminosity function (LF)\nat high redshift, which is still highly uncertain, in particular at the faint\nend. As an example of future opportunities, we present forecasts for the Deep\nSpectroscopic Survey (DSS) that will be conducted with the Fred Young\nSubmillimeter Telescope at $z \\simeq 3.6$ and also make predictions for\neventual $10\\times$ wider and/or $\\sqrt{10}\\times$ more sensitive surveys. The\nhalo-occupation properties of [CII] emitters in the MARIGOLD simulations\nprovide us with the motivation to abundance match two versions of the ALPINE LF\nagainst the halo mass function. We employ the resulting luminosity-mass\nrelation within the halo model to predict the expected PS signal and its\nuncertainty. Finally, we use Bayesian inference to analyse mock PS data and\nforecast what constraints could be achieved on the first two moments of the LF\nand on Schechter fits. Depending on the actual LF, the DSS will measure the\nclustering and shot-noise amplitudes of the PS with a signal-to-noise ratio of\n$\\sim 3$ or higher. However, degeneracies with the bias parameter and\nredshift-space distortions make it unfeasible to extract the first moment of\nthe LF. Even the widest and most sensitive survey we consider can only\nconstrain it with a $50\\%$ uncertainty. By jointly fitting the PS and the LF,\nwe directly constrain Schechter-function parameters. We find that the\nnormalisation and the cutoff luminosity are precisely and accurately measured\nwhile the faint-end slope remains highly uncertain (unless the true value\napproaches $-2$). Overall, increasing the survey sensitivity at fixed sky\ncoverage yields greater improvements than covering a larger area at fixed\nsensitivity.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06562v1","title":"FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion","summary":"Heterogeneous model fusion enhances the performance of LLMs by integrating\nthe knowledge and capabilities of multiple structurally diverse models.\nHowever, existing approaches often rely solely on selecting the best output for\neach prompt from source models, which underutilizes their full potential due to\nlimited source knowledge and results in sparse optimization signals. To address\nthis limitation, we propose FuseRL, a novel two-stage framework comprising\nFuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT\nestablishes a robust initialization by integrating the strengths of\nheterogeneous source models through weighted supervised fine-tuning (SFT) on\ndiverse outputs for each prompt. FusePO optimizes weighted preferences based on\nthe outputs of multiple source models to enable superior alignment performance.\nExtensive experiments demonstrate the effectiveness of our framework across\nvarious preference alignment methods, including RLOO, DPO, and SimPO. Using\nLlama-3.1-8B-Instruct as the target model, our approach achieves\nstate-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard\nbenchmarks. Further analysis suggests that FuseSFT regularizes the training\nprocess to reduce overfitting, while FusePO introduces dense and diverse\nsignals for preference optimization.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.06580v1","title":"Exploring Ordinal Bias in Action Recognition for Instructional Videos","summary":"Action recognition models have achieved promising results in understanding\ninstructional videos. However, they often rely on dominant, dataset-specific\naction sequences rather than true video comprehension, a problem that we define\nas ordinal bias. To address this issue, we propose two effective video\nmanipulation methods: Action Masking, which masks frames of frequently\nco-occurring actions, and Sequence Shuffling, which randomizes the order of\naction segments. Through comprehensive experiments, we demonstrate that current\nmodels exhibit significant performance drops when confronted with nonstandard\naction sequences, underscoring their vulnerability to ordinal bias. Our\nfindings emphasize the importance of rethinking evaluation strategies and\ndeveloping models capable of generalizing beyond fixed action patterns in\ndiverse instructional videos.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T05:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.06606v1","title":"Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program","summary":"Recent advancements in reward signal usage for Large Language Models (LLMs)\nare remarkable. However, significant challenges exist when transitioning reward\nsignal to the multimodal domain, including labor-intensive annotations,\nover-reliance on one-step rewards, and inadequate evaluation. To address these\nissues, we propose SVIP, a novel approach to train a step-level\nmulti-dimensional Chain-of-Thought~(CoT) reward model automatically. It\ngenerates code for solving visual tasks and transforms the analysis of code\nblocks into the evaluation of CoT step as training samples. Then, we train\nSVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The\nadvantages of SVIP-Reward are evident throughout the entire process of MLLM. We\nalso introduce a benchmark for CoT reward model training and testing.\nExperimental results demonstrate that SVIP-Reward improves MLLM performance\nacross training and inference-time scaling, yielding better results on\nbenchmarks while reducing hallucinations and enhancing reasoning ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.06616v1","title":"Search for Type IL Gamma-ray Bursts: Criterion, Results, Verification\n  and Physical Implication","summary":"As an interesting subclass of gamma-ray burst (GRB), Type IL GRB (such as GRB\n211211A and GRB 230307A) features a long-duration prompt emission but\noriginating from compact binary merger. The \"long duration\" emisison of Type IL\nGRB are dominately composed of the main burst, rather than the extended\nemission, differentiating them from the traditional \"long-short\" GRB (e.g., GRB\n060614). Previous study has reported several Type IL GRBs by visual inspection\nof their light curves. In this work, we established a detailed criterion to\nidentify Type IL GRBs by light curve, and then systematically searched the\narchival \\textit{Fermi}/GBM data with this criterion, resulting in a sample of\n5 type IL GRBs from January 1, 2014 to January 1, 2024, i.e. GRB 230307A, GRB\n211211A, GRB 200914A, GRB 200311A and GRB 170228A. Apart from the light curve\npattern, we find that the temporal and spectral properties of these 5 GRBs also\nsupport this classification. Interestingly, we find that the energy ratio\nbetween extended emission and main emission is almost constant ($\\sim0.7$, with\nsmall scattering) for these GRBs, which have strong implication on the\nmechanism of Type IL burst. We discuss theoretical models to interpret the\nprogenitor, central engine, and extended emission of these Type IL bursts.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T06:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.06620v1","title":"InstantSticker: Realistic Decal Blending via Disentangled Object\n  Reconstruction","summary":"We present InstantSticker, a disentangled reconstruction pipeline based on\nImage-Based Lighting (IBL), which focuses on highly realistic decal blending,\nsimulates stickers attached to the reconstructed surface, and allows for\ninstant editing and real-time rendering. To achieve stereoscopic impression of\nthe decal, we introduce shadow factor into IBL, which can be adaptively\noptimized during training. This allows the shadow brightness of surfaces to be\naccurately decomposed rather than baked into the diffuse color, ensuring that\nthe edited texture exhibits authentic shading. To address the issues of warping\nand blurriness in previous methods, we apply As-Rigid-As-Possible (ARAP)\nparameterization to pre-unfold a specified area of the mesh and use the local\nUV mapping combined with a neural texture map to enhance the ability to express\nhigh-frequency details in that area. For instant editing, we utilize the Disney\nBRDF model, explicitly defining material colors with 3-channel diffuse albedo.\nThis enables instant replacement of albedo RGB values during the editing\nprocess, avoiding the prolonged optimization required in previous approaches.\nIn our experiment, we introduce the Ratio Variance Warping (RVW) metric to\nevaluate the local geometric warping of the decal area. Extensive experimental\nresults demonstrate that our method surpasses previous decal blending methods\nin terms of editing quality, editing speed and rendering speed, achieving the\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06622v1","title":"Quantum neural networks facilitating quantum state classification","summary":"The classification of quantum states into distinct classes poses a\nsignificant challenge. In this study, we address this problem using quantum\nneural networks in combination with a problem-inspired circuit and customised\nas well as predefined ans\\\"{a}tz. To facilitate the resource-efficient quantum\nstate classification, we construct the dataset of quantum states using the\nproposed problem-inspired circuit. The problem-inspired circuit incorporates\ntwo-qubit parameterised unitary gates of varying entangling power, which is\nfurther integrated with the ans\\\"{a}tz, developing an entire quantum neural\nnetwork. To demonstrate the capability of the selected ans\\\"{a}tz, we visualise\nthe mitigated barren plateaus. The designed quantum neural network demonstrates\nthe efficiency in binary and multi-class classification tasks. This work\nestablishes a foundation for the classification of multi-qubit quantum states\nand offers the potential for generalisation to multi-qubit pure quantum states.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-09T06:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.06639v1","title":"Dielectronic recombination studies of ions relevant to kilonovae and\n  non-LTE plasma","summary":"This study presents calculations of rate coefficients, resonance strengths,\nand cross sections for the dielectronic recombination (DR) of Y^+, Sr^+, Te^2+,\nand Ce^2+--low-charge ions relevant to kilonovae and non-local thermodynamic\nequilibrium (non-LTE) plasmas. Using relativistic atomic structure methods, we\ncomputed DR rate coefficients under conditions typical of these environments.\nOur results highlight the critical role of low-lying DR resonances in shaping\nrate coefficients at kilonova temperatures (~ 10^4 K) and regulating\ncharge-state distributions. Pronounced near-threshold DR resonances\nsignificantly influence the evolving ionization states and opacity of neutron\nstar merger ejecta. Comparisons with previous studies emphasize the necessity\nof including high-n Rydberg states for accurate DR rate coefficients,\nespecially for complex heavy ions with dense energy levels. Discrepancies with\nexisting datasets underscore the need for refined computational techniques to\nminimize uncertainties. These results provide essential input for interpreting\nspectroscopic observations of neutron star mergers, including James Webb Space\nTelescope data. We also put forward suitable candidates for experimental\nstudies, recognizing the challenges involved in such measurements. The data\npresented here have potential to refine models of heavy-element\nnucleosynthesis, enhance plasma simulation accuracy, and improve non-LTE plasma\nmodeling in astrophysical and laboratory settings.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.atom-ph","published":"2025-04-09T07:30:19Z"}
{"aid":"http://arxiv.org/abs/2504.06652v1","title":"The Shortest Temporal Exploration Problem","summary":"A temporal graph is a graph for which the edge set can change from one time\nstep to the next. This paper considers undirected temporal graphs defined over\nL time steps and connected at each time step. We study the Shortest Temporal\nExploration Problem (STEXP) that, given all the evolution of the graph, asks\nfor a temporal walk that starts at a given vertex, moves over at most one edge\nat each time step, visits all the vertices, takes at most L time steps and\ntraverses the smallest number of edges. . We prove that every constantly\nconnected temporal graph with n vertices can be explored with O(n 1.5 ) edges\ntraversed within O(n 3.5 ) time steps. This result improves the upper bound of\nO(n 2 ) edges for an exploration provided by the upper bound of time steps for\nan exploration which is also O(n 2 ). Morever, we study the case where the\ngraph has a diameter bounded by a parameter k at each time step and we prove\nthat there exists an exploration which takes O(kn 2 ) time steps and traverses\nO(kn) edges. Finally, the case where the underlying graph is a cycle is studied\nand tight bounds are provided on the number of edges traversed in the\nworst-case if L $\\ge$ 2n -3.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T07:42:25Z"}
{"aid":"http://arxiv.org/abs/2504.06675v1","title":"Probability Density Geodesics in Image Diffusion Latent Space","summary":"Diffusion models indirectly estimate the probability density over a data\nspace, which can be used to study its structure. In this work, we show that\ngeodesics can be computed in diffusion latent space, where the norm induced by\nthe spatially-varying inner product is inversely proportional to the\nprobability density. In this formulation, a path that traverses a high density\n(that is, probable) region of image latent space is shorter than the equivalent\npath through a low density region. We present algorithms for solving the\nassociated initial and boundary value problems and show how to compute the\nprobability density along the path and the geodesic distance between two\npoints. Using these techniques, we analyze how closely video clips approximate\ngeodesics in a pre-trained image diffusion space. Finally, we demonstrate how\nthese techniques can be applied to training-free image sequence interpolation\nand extrapolation, given a pre-trained image diffusion model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:28:53Z"}
{"aid":"http://arxiv.org/abs/2504.06677v1","title":"Setup-Invariant Augmented Reality for Teaching by Demonstration with\n  Surgical Robots","summary":"Augmented reality (AR) is an effective tool in robotic surgery education as\nit combines exploratory learning with three-dimensional guidance. However,\nexisting AR systems require expert supervision and do not account for\ndifferences in the mentor and mentee robot configurations. To enable novices to\ntrain outside the operating room while receiving expert-informed guidance, we\npresent dV-STEAR: an open-source system that plays back task-aligned expert\ndemonstrations without assuming identical setup joint positions between expert\nand novice. Pose estimation was rigorously quantified, showing a registration\nerror of 3.86 (SD=2.01)mm. In a user study (N=24), dV-STEAR significantly\nimproved novice performance on tasks from the Fundamentals of Laparoscopic\nSurgery. In a single-handed ring-over-wire task, dV-STEAR increased completion\nspeed (p=0.03) and reduced collision time (p=0.01) compared to dry-lab training\nalone. During a pick-and-place task, it improved success rates (p=0.004).\nAcross both tasks, participants using dV-STEAR exhibited significantly more\nbalanced hand use and reported lower frustration levels. This work presents a\nnovel educational tool implemented on the da Vinci Research Kit, demonstrates\nits effectiveness in teaching novices, and builds the foundation for further AR\nintegration into robot-assisted surgery.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.HC,cs.SY,eess.SY","published":"2025-04-09T08:34:25Z"}
{"aid":"http://arxiv.org/abs/2504.06683v1","title":"Hyperparameter Optimisation with Practical Interpretability and\n  Explanation Methods in Probabilistic Curriculum Learning","summary":"Hyperparameter optimisation (HPO) is crucial for achieving strong performance\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\ncurriculum learning strategy designed to improve RL performance by structuring\nthe agent's learning process, yet effective hyperparameter tuning remains\nchallenging and computationally demanding. In this paper, we provide an\nempirical analysis of hyperparameter interactions and their effects on the\nperformance of a PCL algorithm within standard RL tasks, including point-maze\nnavigation and DC motor control. Using the AlgOS framework integrated with\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\nAdditionally, we introduce a novel SHAP-based interpretability approach\ntailored specifically for analysing hyperparameter impacts, offering clear\ninsights into how individual hyperparameters and their interactions influence\nRL performance. Our work contributes practical guidelines and interpretability\ntools that significantly improve the effectiveness and computational\nfeasibility of hyperparameter optimisation in reinforcement learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T08:41:27Z"}
{"aid":"http://arxiv.org/abs/2504.06685v1","title":"Testing Multivariate Conditional Independence Using Exchangeable\n  Sampling and Sufficient Statistics","summary":"We consider testing multivariate conditional independence between a response\nY and a covariate vector X given additional variables Z. We introduce the\nMultivariate Sufficient Statistic Conditional Randomization Test (MS-CRT),\nwhich generates exchangeable copies of X by conditioning on sufficient\nstatistics of P(X|Z). MS-CRT requires no modelling assumption on Y and\naccommodates any test statistics, including those derived from complex\npredictive models. It relaxes the assumptions of standard conditional\nrandomization tests by allowing more unknown parameters in P(X|Z) than the\nsample size. MS-CRT avoids multiplicity corrections and effectively detects\njoint signals, even when individual components of X have only weak effects on Y\n. Our method extends to group selection with false discovery rate control. We\ndevelop efficient implementations for two important cases where P(X,Z) is\neither multivariate normal or belongs to a graphical model. For normal models,\nwe establish the minimax rate optimality. For graphical models, we demonstrate\nthe superior performance of our method compared to existing methods through\ncomprehensive simulations and real-data examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T08:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06731v1","title":"FJ-MM: The Friedkin-Johnsen Opinion Dynamics Model with Memory and\n  Higher-Order Neighbors","summary":"The Friedkin-Johnsen (FJ) model has been extensively explored and validated,\nspanning applications in social science, systems and control, game theory, and\nalgorithmic research. In this paper, we introduce an advanced generalization of\nthe FJ model, termed FJ-MM which incorporates both memory effects and multi-hop\n(higher-order neighbor) influence. This formulation allows agents to naturally\nincorporate both current and previous opinions at each iteration stage. Our\nnumerical results demonstrate that incorporating memory and multi-hop influence\nsignificantly reshapes the opinion landscape; for example, the final opinion\nprofile can exhibit reduced polarization. We analyze the stability and\nequilibrium properties of the FJ-MM model, showing that these properties can be\nreduced to those of a comparison model--namely, the standard FJ model with a\nmodified influence matrix. This reduction enables us to leverage established\nstability results from FJ dynamics. Additionally, we examine the convergence\nrate of the FJ-MM model and demonstrate that, as can be expected, the time lags\nintroduced by memory and higher-order neighbor influences result in slower\nconvergence.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC,physics.soc-ph","published":"2025-04-09T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.06750v1","title":"Robust Capacity Expansion Modelling for Renewable Energy Systems under\n  Weather and Demand Uncertainty","summary":"Future greenhouse gas neutral energy systems will be dominated by variable\nrenewable energy technologies. However, renewable electricity generation from\nwind and solar technologies, as well as electricity demand, varies with the\nweather. This work addresses the problem of determining optimal capacities for\nrenewable technologies in energy systems that ensure sufficient electricity\nsupply when dealing with multi-year time-series data. An iterative algorithm is\nproposed that starts by optimising an arbitrary starting time-series, followed\nby adding additional constraints and reoptimising the modified optimisation\nproblem until sufficient energy supply is provided for all time--series, i.e.\nthe solution is robust to weather and demand variations. This is evaluated in a\ncomputational study on a German energy system model.The results show that the\niterative algorithm finds robust solutions for an increase of 2-2.5% in total\nannual cost for a simplified model in gurobipy and 2.9% for a model built in\nthe model framework ETHOS.FINE. Testing the feasibility for non robust\nsolutions showed that supply gaps occurred in at least some of the remaining\nyears. Based on the results of this work, ensuring feasibility within an energy\nsystem model for multiple time-series boils down to two factors: ensuring\nsufficient back-up capacity to overcome periods of high demand combined with\nlow electricity generation from wind and photovoltaic, and enforcing sufficient\ntotal annual electricity generation. Our proposed open source iterative\nalgorithm is able to ensure this. For general modelling, it is recommended to\ncheck for systematic effects of different years' time--series on energy system\nmodels especially for wind, but also for photovoltaics, include dark lull and\ncold period effects on generation and demand in time--series, and assess the\nfeasibility of energy system models using different time-series.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,I.6","published":"2025-04-09T10:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.06755v1","title":"FANeRV: Frequency Separation and Augmentation based Neural\n  Representation for Video","summary":"Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block.This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06778v1","title":"Controllable Automatic Foley Artist","summary":"Foley is a key element in video production, refers to the process of adding\nan audio signal to a silent video while ensuring semantic and temporal\nalignment. In recent years, the rise of personalized content creation and\nadvancements in automatic video-to-audio models have increased the demand for\ngreater user control in the process. One possible approach is to incorporate\ntext to guide audio generation. While supported by existing methods, challenges\nremain in ensuring compatibility between modalities, particularly when the text\nintroduces additional information or contradicts the sounds naturally inferred\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\nArtist) a video-and-text-to-audio model that generates semantically and\ntemporally aligned audio for a given video, guided by text input. CAFA is built\nupon a text-to-audio model and integrates video information through a modality\nadapter mechanism. By incorporating text, users can refine semantic details and\nintroduce creative variations, guiding the audio synthesis beyond the expected\nvideo contextual cues. Experiments show that besides its superior quality in\nterms of semantic alignment and audio-visual synchronization the proposed\nmethod enable high textual controllability as demonstrated in subjective and\nobjective evaluations.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-09T10:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.06802v1","title":"The ALMA-ATOMS survey: A sample of weak hot core candidates identified\n  through line stacking","summary":"Hot cores represent critical astrophysical environments for high-mass star\nformation, distinguished by their rich spectra of organic molecular emission\nlines. We aim to utilize high-angular resolution molecular line data from ALMA\nto identify hot cores, with a particular focus on weak-emission candidates, and\nto provide one of the largest samples of hot core candidates. We propose to use\nspectral stacking and imaging techniques of complex organic molecules (COMs) in\nthe ALMA-ATOMS survey, including line identification & weights, segmentation of\nline datacubes, resampling, stacking and normalization, moment 0 maps, and data\nanalysis, to search for hot core candidates. We classify cores with dense\nemission of CH3OH and at least one molecule from the other six molecules as hot\ncore candidates. In addition to the existing sample of 60 strong hot cores from\nthe ALMA-ATOMS survey, we have detected 40 new weak candidates through\nstacking. All hot core candidates display compact emission from at least one of\nthe other six COM species. For the strong sample, the stacking method provides\nmolecular column density estimates that are consistent with previous fitting\nresults. For the newly identified weak candidates, all species except CH3CHO\nshow compact emission in the stacked image, which cannot be fully resolved\nspatially. These weak candidates exhibit column densities of COMs that are\napproximately one order of magnitude lower than those of the strong sample. The\nentire hot core sample, including the weak candidates, reveals tight\ncorrelations between the compact emission of CH3OH and other COM species,\nsuggesting they may share a similar chemical environment for COMs, with CH3OH\npotentially acting as a precursor for other COMs. The molecular line stacking\ntechnique is used to identify hot core candidates in this work, leading to the\nidentification of 40 new hot core candidates.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T11:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.06834v1","title":"Green building blocks reveal the complex anatomy of climate change\n  mitigation technologies","summary":"Climate-change mitigating innovation is considered essential for the world's\ntransition toward a sustainable global economy. To guide this transition,\nintegrated assessment models map sectoral emissions reduction targets into\nlong-term trajectories towards carbon neutrality at the macro-level, while\ndetailed engineering studies at the micro-level develop concrete\ncarbon-mitigation technologies tailored to individual industries. However, we\nlack a meso-level understanding of how solutions connect across technological\ndomains. Building on the notion that innovating often entails combining\nexisting technologies in new ways, we identify Green Building Blocks (GBBs):\nmodules of technologies that can be added to nongreen technologies to mitigate\ntheir climate-change impact. Using natural language processing and\ndimensionality reduction techniques, we show how GBBs can be extracted from\nlarge-scale patent data. Next, we describe the anatomy of the green transition\nas a network that connects nongreen technologies to GBBs. This network has a\nnontrivial structure: whereas some nongreen technologies can connect to various\nGBBs, opening up a variety of ways to mitigate their impact on the global\nclimate, other nongreen technologies only connect to a single GBB. Similarly,\nsome GBBs are general purpose technologies that can reduce green house gases in\na vast range of applications, whereas others are tailored to specific use\ncases. Furthermore, GBBs prove predictive of the green technologies that firms\ndevelop, allowing us to map the green capabilities of firms not in terms of the\nspecific green technological solutions they invent, but in terms of their\ncapacity to develop broader classes of solutions with the GBBs they possess.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SI","published":"2025-04-09T12:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.06845v1","title":"Probability density function for dispersion measure of fast radio burst\n  from extragalactic medium","summary":"Fast Radio Bursts (FRBs) have emerged as powerful probes in cosmology. An\noptimized method for extracting the cosmic baryon density from localized FRBs,\nbased on maximizing the joint likelihood function of the extragalactic\ndispersion measure ($\\mathrm{DM}_{\\mathrm{ext}}$), was proposed by Macquart et\nal. [Nature 581, 391 (2020)]. In this Letter, we identify a crucial term that\nwas omitted in their derivation of the probability density function (PDF) for\n$\\mathrm{DM}_{\\mathrm{ext}}$. Using simulated FRB data, we demonstrate that\nneglecting this term leads to a systematic bias in the inferred cosmic baryon\ndensity, with deviations exceeding the $1\\sigma$ confidence level. This\nhighlights the importance of the missing term for the reliable cosmological\napplication of FRBs. Furthermore, employing a sample of 88 real localized FRBs,\nwe find that the baryon density derived using the original PDF by Macquart et\nal. is inconsistent with the Planck 2018 CMB data, while our corrected PDF\nyields a result in excellent agreement. We conclude that the omitted term is\nessential and must be included in order to obtain accurate cosmological\nconstraints from FRB observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T13:02:33Z"}
{"aid":"http://arxiv.org/abs/2504.06872v1","title":"More connection, less community: network formation and local public\n  goods provision","summary":"This paper presents a model of network formation and public goods provision\nin local communities. Here, networks can sustain public good provision by\nspreading information about people's behaviour. I find a critical threshold in\nnetwork connectedness at which public good provision drops sharply, even though\nagents are highly heterogeneous. Technology change can tear a community's\nsocial fabric by pushing high-skilled workers to withdraw from their local\ncommunity. This can help explain rising resentment toward perceived ``elites''\n-- their withdrawal actively harms those left behind. Moreover, well-meaning\npolicies that upskill workers can make them worse off by reducing network\nconnectedness.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T13:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.06890v1","title":"Combining high-contrast imaging with high-resolution spectroscopy:\n  Actual on-sky MIRI/MRS results compared to expectations","summary":"CONTEXT: Combining high-contrast imaging with high-resolution spectroscopy\noffers a powerful way to detect and characterize exoplanets around nearby\nstars, despite challenges linked to their faintness. Instruments like\nVLT/SPHERE are state of the art in high-contrast imaging, but their spectral\nresolution (R=50) limits them to basic characterization of close companions.\nThese systems can detect planets down to 5-10 Mjup at 10 AU from their stars.\nDetection limits are mainly constrained by speckle noise, which dominates over\nphoton and detector noise at short separations, even with advanced differential\nimaging. Space-based high-contrast imaging is also limited by image stability.\nSpeckle noise can, however, be mitigated through molecular mapping, a technique\nthat leverages high-resolution spectroscopic data.\n  AIMS: We aim to predict detection limits in spectro-imaging after molecular\nmapping, analyzing how photon and detector noise propagate and comparing\npredictions with real data to assess performance losses from instrumental\neffects. We also propose mitigation strategies and validate our model using\nobservations.\n  METHODS: We analyzed JWST/MIRI/MRS data with FastCurves, an numerical tool,\nand compared results to outputs from the MIRI simulator. We also applied\nprincipal component analysis (PCA) to identify and isolate systematic effects,\nwith and without molecular mapping.\n  RESULTS: We studied various systematic effects and their impacts on signal\nand noise. PCA helped highlight and reduce straylight, fringes, and aliasing.\nWe further compared observed and modeled companion spectra.\n  CONCLUSIONS: FastCurves was improved to account for systematics and validated\nwith real data. In high-flux regimes, systematics impose contrast limits even\nwith molecular mapping. Our approach could benefit other instruments and inform\nthe planning of future facilities like ELT/ANDES and ELT/PCS.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-04-09T13:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.06910v1","title":"Identifying Aspects in Peer Reviews","summary":"Peer review is central to academic publishing, but the growing volume of\nsubmissions is straining the process. This motivates the development of\ncomputational approaches to support peer review. While each review is tailored\nto a specific paper, reviewers often make assessments according to certain\naspects such as Novelty, which reflect the values of the research community.\nThis alignment creates opportunities for standardizing the reviewing process,\nimproving quality control, and enabling computational support. While prior work\nhas demonstrated the potential of aspect analysis for peer review assistance,\nthe notion of aspect remains poorly formalized. Existing approaches often\nderive aspect sets from review forms and guidelines of major NLP venues, yet\ndata-driven methods for aspect identification are largely underexplored. To\naddress this gap, our work takes a bottom-up approach: we propose an\noperational definition of aspect and develop a data-driven schema for deriving\nfine-grained aspects from a corpus of peer reviews. We introduce a dataset of\npeer reviews augmented with aspects and show how it can be used for\ncommunity-level review analysis. We further show how the choice of aspects can\nimpact downstream applications, such as LLM-generated review detection. Our\nresults lay a foundation for a principled and data-driven investigation of\nreview aspects, and pave the path for new applications of NLP to support peer\nreview.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T14:14:42Z"}
{"aid":"http://arxiv.org/abs/2504.06921v1","title":"Leveraging Anatomical Priors for Automated Pancreas Segmentation on\n  Abdominal CT","summary":"An accurate segmentation of the pancreas on CT is crucial to identify\npancreatic pathologies and extract imaging-based biomarkers. However, prior\nresearch on pancreas segmentation has primarily focused on modifying the\nsegmentation model architecture or utilizing pre- and post-processing\ntechniques. In this article, we investigate the utility of anatomical priors to\nenhance the segmentation performance of the pancreas. Two 3D full-resolution\nnnU-Net models were trained, one with 8 refined labels from the public PANORAMA\ndataset, and another that combined them with labels derived from the public\nTotalSegmentator (TS) tool. The addition of anatomical priors resulted in a 6\\%\nincrease in Dice score ($p < .001$) and a 36.5 mm decrease in Hausdorff\ndistance for pancreas segmentation ($p < .001$). Moreover, the pancreas was\nalways detected when anatomy priors were used, whereas there were 8 instances\nof failed detections without their use. The use of anatomy priors shows promise\nfor pancreas segmentation and subsequent derivation of imaging biomarkers.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.06947v1","title":"RuOpinionNE-2024: Extraction of Opinion Tuples from Russian News Texts","summary":"In this paper, we introduce the Dialogue Evaluation shared task on extraction\nof structured opinions from Russian news texts. The task of the contest is to\nextract opinion tuples for a given sentence; the tuples are composed of a\nsentiment holder, its target, an expression and sentiment from the holder to\nthe target. In total, the task received more than 100 submissions. The\nparticipants experimented mainly with large language models in zero-shot,\nfew-shot and fine-tuning formats. The best result on the test set was obtained\nwith fine-tuning of a large language model. We also compared 30 prompts and 11\nopen source language models with 3-32 billion parameters in the 1-shot and\n10-shot settings and found the best models and prompts.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-09T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.06955v1","title":"Parametric Reachable Sets Via Controlled Dynamical Embeddings","summary":"In this work, we propose a new framework for reachable set computation\nthrough continuous evolution of a set of parameters and offsets which define a\nparametope, through the intersection of constraints. This results in a\ndynamical approach towards nonlinear reachability analysis: a single trajectory\nof an embedding system provides a parametope reachable set for the original\nsystem, and uncertainties are accounted for through continuous parameter\nevolution. This is dual to most existing computational strategies, which define\nsets through some combination of generator vectors, and usually discretize the\nsystem dynamics. We show how, under some regularity assumptions of the dynamics\nand the set considered, any desired parameter evolution can be accommodated as\nlong as the offset dynamics are set accordingly, providing a virtual \"control\ninput\" for reachable set computation. In a special case of the theory, we\ndemonstrate how closing the loop for the parameter dynamics using the adjoint\nof the linearization results in a desirable first-order cancellation of the\noriginal system dynamics. Using interval arithmetic in JAX, we demonstrate the\nefficiency and utility of reachable parametope computation through two\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-09T15:02:46Z"}
{"aid":"http://arxiv.org/abs/2504.06971v1","title":"Extinction rates for nonradial solutions to the Stefan problem","summary":"We consider the one-phase Stefan problem describing the evolution of melting\nice. On the one hand, we focus on understanding the evolution of the free\nboundary near isolated singular points, and we establish for the first time\nupper and (more surprisingly) lower estimates for its evolution. In 2D, these\nbounds almost match the best known ones for radial solutions, but hold for all\nsolutions to the Stefan problem, with no extra assumption on the initial or\nboundary data. On the other hand, as a consequence of our results, we also\ncharacterize the global regularity of the free boundary, as follows: it can be\nwritten as a graph $t = \\Gamma(x)$, where $\\Gamma$ is $C^1$ (and not $C^2$)\nnear any singular points in the lower strata $\\Sigma_m$, $m \\leq n - 2$.\nMoreover, $\\Gamma$ is not $C^1$ at singular points in $\\Sigma_{n-1}$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T15:26:54Z"}
{"aid":"http://arxiv.org/abs/2504.06982v1","title":"SIGMAN:Scaling 3D Human Gaussian Generation with Millions of Assets","summary":"3D human digitization has long been a highly pursued yet challenging task.\nExisting methods aim to generate high-quality 3D digital humans from single or\nmultiple views, but remain primarily constrained by current paradigms and the\nscarcity of 3D human assets. Specifically, recent approaches fall into several\nparadigms: optimization-based and feed-forward (both single-view regression and\nmulti-view generation with reconstruction). However, they are limited by slow\nspeed, low quality, cascade reasoning, and ambiguity in mapping low-dimensional\nplanes to high-dimensional space due to occlusion and invisibility,\nrespectively. Furthermore, existing 3D human assets remain small-scale,\ninsufficient for large-scale training. To address these challenges, we propose\na latent space generation paradigm for 3D human digitization, which involves\ncompressing multi-view images into Gaussians via a UV-structured VAE, along\nwith DiT-based conditional generation, we transform the ill-posed\nlow-to-high-dimensional mapping problem into a learnable distribution shift,\nwhich also supports end-to-end inference. In addition, we employ the multi-view\noptimization approach combined with synthetic data to construct the HGS-1M\ndataset, which contains $1$ million 3D Gaussian assets to support the\nlarge-scale training. Experimental results demonstrate that our paradigm,\npowered by large-scale training, produces high-quality 3D human Gaussians with\nintricate textures, facial details, and loose clothing deformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.06998v1","title":"A Krylov projection algorithm for large symmetric matrices with dense\n  spectra","summary":"We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d.\n$A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times\np}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output\n(MIMO) transfer functions for large-scale discretizations of problems with\ncontinuous spectral measures, such as linear time-invariant (LTI) PDEs on\nunbounded domains. Traditional Krylov methods, such as the Lanczos or CG\nalgorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with\nreal positive $s$, resulting in an adaptation to the distinctively discrete and\nnonuniform spectra. However, the adaptation is damped for matrices with dense\nspectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of\nScientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss\n-Radau quadratures computed using the block-Lanczos method significantly\nreduces approximation errors for such problems. Here, we introduce an adaptive\nKre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing\nfurther acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau\nquadrature, a low-rank modification is applied to the (block) Lanczos matrix.\nHowever, unlike the Gau\\ss -Radau quadrature, this modification depends on\n$\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e\napproximants, which are known to be efficient for problems with branch-cuts,\nthat can be good approximations to dense spectral intervals. Numerical results\nfor large-scale discretizations of heat-diffusion and quasi-magnetostatic\nMaxwell's operators in unbounded domains confirm the efficiency of the proposed\napproach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07000v1","title":"Deviation Estimates for Extremal Relay Random Geometric Graphs","summary":"In this paper, we consider a deterministic graph~\\(\\Gamma\\) drawn on the unit\nsquare with straight line segments as edges and connect vertices of~\\(\\Gamma\\)\nusing edges of a random geometric graph (RGG)~\\(G\\) with adjacency\ndistance~\\(r_n\\) as relays. We call the resulting graph as a \\emph{relay} RGG\nand determine sufficient conditions under such relay RGGs exist and are also\nnear optimal, in terms of the graph parameters of~\\(\\Gamma.\\) We then equip\nedges of~\\(G\\) with independent, exponentially distributed weights and obtain\nbounds for the maximum possible weight~\\(W_n\\) of a relay RGG with a given\nlength~\\(L_n.\\)","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.07009v1","title":"Efficient Light Generation in Ultraviolet-A Band on Chip","summary":"Lithium niobate nano photonics provides highly efficient nonlinear optics\nprocesses covering a broad spectrum from ultraviolet to mid-infrared, yet\nstudies thus far have concentrated in the near-infrared regime. Here we\ndemonstrate light generation in the Ultraviolet-A band in a periodic poled\nwaveguide via second harmonic generation. The internal efficiency reaches 1797\n$\\% W^{-1}/cm^{-2}$, marking a 9.1-times improvement over the state of art,\nthanks to better mode overlap and poling. Our technique can find applications\nin atomic clocks, frequency comb generation, sensing, and visible entanglement\ngeneration.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-09T16:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07040v1","title":"Bounds on the number of squares in recurrence sequences: arbitrary $b$,\n  III","summary":"We generalise our earlier work on the number of squares in binary recurrence\nsequences, $\\left\\{ y_{k} \\right\\}_{k \\geq -\\infty}$. In the notation of our\nprevious papers, here we consider the case when $N_{\\alpha}$ is any negative\ninteger and $y_{0}=b^{2}$ for any positive integer, $b$. We show that there are\nat most $4$ distinct squares with $y_{k}$ sufficiently large. This allows us to\nalso show that there are at most $9$ distinct squares in such sequences when\n$b=1,2$ or $3$, or once $d$ is sufficiently large.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T16:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.07070v1","title":"A Survey on Personalized and Pluralistic Preference Alignment in Large\n  Language Models","summary":"Personalized preference alignment for large language models (LLMs), the\nprocess of tailoring LLMs to individual users' preferences, is an emerging\nresearch direction spanning the area of NLP and personalization. In this\nsurvey, we present an analysis of works on personalized alignment and modeling\nfor LLMs. We introduce a taxonomy of preference alignment techniques, including\ntraining time, inference time, and additionally, user-modeling based methods.\nWe provide analysis and discussion on the strengths and limitations of each\ngroup of techniques and then cover evaluation, benchmarks, as well as open\nproblems in the field.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:39:58Z"}
{"aid":"http://arxiv.org/abs/2504.07079v1","title":"SkillWeaver: Web Agents can Self-Improve by Discovering and Honing\n  Skills","summary":"To survive and thrive in complex environments, humans have evolved\nsophisticated self-improvement mechanisms through environment exploration,\nhierarchical abstraction of experiences into reuseable skills, and\ncollaborative construction of an ever-growing skill repertoire. Despite recent\nadvancements, autonomous web agents still lack crucial self-improvement\ncapabilities, struggling with procedural knowledge abstraction, refining\nskills, and skill composition. In this work, we introduce SkillWeaver, a\nskill-centric framework enabling agents to self-improve by autonomously\nsynthesizing reusable skills as APIs. Given a new website, the agent\nautonomously discovers skills, executes them for practice, and distills\npractice experiences into robust APIs. Iterative exploration continually\nexpands a library of lightweight, plug-and-play APIs, significantly enhancing\nthe agent's capabilities. Experiments on WebArena and real-world websites\ndemonstrate the efficacy of SkillWeaver, achieving relative success rate\nimprovements of 31.8% and 39.8%, respectively. Additionally, APIs synthesized\nby strong agents substantially enhance weaker agents through transferable\nskills, yielding improvements of up to 54.3% on WebArena. These results\ndemonstrate the effectiveness of honing diverse website interactions into APIs,\nwhich can be seamlessly shared among various web agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-09T17:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.07407v1","title":"Cech - de Rham Chern character on the stack of holomorphic vector\n  bundles","summary":"We provide a formula for the Chern character of a holomorphic vector bundle\nin the hyper-cohomology of the de Rham complex of holomorphic sheaves on a\ncomplex manifold. This Chern character can be thought of as a completion of the\nChern character in Hodge cohomology obtained as the trace of the exponential of\nthe Atiyah class, which is \\v{C}ech closed, to one that is \\v{C}ech-Del closed.\nSuch a completion is a key step toward lifting O'Brian-Toledo-Tong invariants\nof coherent sheaves from Hodge cohomology to de Rham cohomology. An alternate\napproach toward the same end goal, instead using simplicial differential forms\nand Green complexes, can be found in Hosgood's works [Ho1, Ho2]. In the\nalgebraic setting, and more generally for K\\\"{a}hler manifolds, where Hodge and\nde Rham cohomologies agree, such extensions are not necessary, whereas in the\nnon-K\\\"{a}hler, or equivariant settings the two theories differ. We provide our\nformulae as a map of simplicial presheaves, which readily extend the results to\nthe equivariant setting and beyond. This paper can be viewed as a sequel to\n[GMTZ1] which covered such a discussion in Hodge cohomology. As an aside, we\ngive a conceptual understanding of how formulas obtained by Bott and Tu for\nChern classes using transition functions and those from Chern-Weil theory using\nconnections, are part of a natural unifying story.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-10T03:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.07416v1","title":"RadZero: Similarity-Based Cross-Attention for Explainable\n  Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability","summary":"Recent advancements in multi-modal models have significantly improved\nvision-language alignment in radiology. However, existing approaches struggle\nto effectively utilize complex radiology reports for learning, rely on\nlow-resolution images, and offer limited interpretability in attention\nmechanisms. To address these challenges, we introduce RadZero, a novel\nsimilarity-based cross-attention framework for vision-language alignment in\nradiology with zero-shot multi-task capability. RadZero leverages large\nlanguage models to extract minimal semantic sentences from radiology reports\nand employs a multi-positive contrastive learning strategy to effectively\ncapture relationships between images and multiple relevant textual\ndescriptions. It also utilizes a pre-trained vision encoder with additional\ntrainable Transformer layers, allowing efficient high-resolution image\nprocessing. By computing similarity between text embeddings and local image\npatch features, RadZero enables zero-shot inference with similarity probability\nfor classification and pixel-level cross-modal similarity maps for grounding\nand segmentation. Experimental results on public chest radiograph benchmarks\nshow that RadZero outperforms state-of-the-art methods in zero-shot\nclassification, grounding, and segmentation. Furthermore, cross-modal\nsimilarity map analysis highlights its potential for improving explainability\nin vision-language alignment. Additionally, qualitative evaluation demonstrates\nRadZero's capability for open-vocabulary semantic segmentation, further\nvalidating its effectiveness in medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.07421v1","title":"AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery","summary":"We introduce AgentAda, the first LLM-powered analytics agent that can learn\nand use new analytics skills to extract more specialized insights. Unlike\nexisting methods that require users to manually decide which data analytics\nmethod to apply, AgentAda automatically identifies the skill needed from a\nlibrary of analytical skills to perform the analysis. This also allows AgentAda\nto use skills that existing LLMs cannot perform out of the box. The library\ncovers a range of methods, including clustering, predictive modeling, and NLP\ntechniques like BERT, which allow AgentAda to handle complex analytics tasks\nbased on what the user needs. AgentAda's dataset-to-insight extraction strategy\nconsists of three key steps: (I) a question generator to generate queries\nrelevant to the user's goal and persona, (II) a hybrid Retrieval-Augmented\nGeneration (RAG)-based skill matcher to choose the best data analytics skill\nfrom the skill library, and (III) a code generator that produces executable\ncode based on the retrieved skill's documentation to extract key patterns. We\nalso introduce KaggleBench, a benchmark of curated notebooks across diverse\ndomains, to evaluate AgentAda's performance. We conducted a human evaluation\ndemonstrating that AgentAda provides more insightful analytics than existing\ntools, with 48.78% of evaluators preferring its analyses, compared to 27.67%\nfor the unskilled agent. We also propose a novel LLM-as-a-judge approach that\nwe show is aligned with human evaluation as a way to automate insight quality\nevaluation at larger scale.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07442v1","title":"RIS-Aided Integrated Sensing and Communication Waveform Design With\n  Tunable PAPR","summary":"Low peak-to-average power ratio (PAPR) transmission is an important and\nfavorable requirement prevalent in radar and communication systems, especially\nin transmission links integrated with high power amplifiers. Meanwhile,\nmotivated by the advantages of reconfigurable intelligent surface (RIS) in\nmitigating multi-user interference (MUI) to enhance the communication rate,\nthis paper investigates the design problem of joint waveform and passive\nbeamforming with PAPR constraint for integrated sensing and communication\n(ISAC) systems, where RIS is deployed for downlink communication. We first\nconstruct a trade-off optimization problem for the MUI and beampattern\nsimilarity under PAPR constraint. Then, in order to solve this multivariate\nproblem, an iterative optimization algorithm based on alternating direction\nmethod of multipliers (ADMM) and manifold optimization is proposed. Finally,\nthe simulation results show that the designed waveforms can well satisfy the\nPAPR requirement of the ISAC systems and achieve a trade-off between radar and\ncommunication performance. Under high signal-to-noise ratio (SNR) conditions,\ncompared to systems without RIS, RIS-aided ISAC systems have a performance\nimprovement of about 50\\% in communication rate and at least 1 dB in\nbeampatterning error.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T04:18:23Z"}
{"aid":"http://arxiv.org/abs/2504.07453v1","title":"Probability Estimation and Scheduling Optimization for Battery Swap\n  Stations via LRU-Enhanced Genetic Algorithm and Dual-Factor Decision System","summary":"To address the challenges of limited Battery Swap Stations datasets, high\noperational costs, and fluctuating user charging demand, this research proposes\na probability estimation model based on charging pile data and constructs nine\nscenario-specific battery swap demand datasets. In addition, this study\ncombines Least Recently Used strategy with Genetic Algorithm and incorporates a\nguided search mechanism, which effectively enhances the global optimization\ncapability. Thus, a dual-factor decision-making based charging schedule\noptimization system is constructed. Experimental results show that the\nconstructed datasets exhibit stable trend characteristics, adhering to 24-hour\nand 168-hour periodicity patterns, with outlier ratios consistently below\n3.26%, confirming data validity. Compared to baseline, the improved algorithm\nachieves better fitness individuals in 80% of test regions under the same\niterations. When benchmarked against immediate swap-and-charge strategy, our\nalgorithm achieves a peak cost reduction of 13.96%. Moreover, peak user\nsatisfaction reaches 98.57%, while the average iteration time remains below 0.6\nseconds, demonstrating good computational efficiency. The complete datasets and\noptimization algorithm are open-sourced at\nhttps://github.com/qingshufan/GA-EVLRU.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T04:58:24Z"}
{"aid":"http://arxiv.org/abs/2504.07469v1","title":"Vortex droplets and lattice patterns in two-dimensional traps: A\n  photonic spin-orbit-coupling perspective","summary":"In the context of the mean-field exciton-polariton (EP) theory with balanced\nloss and pump, we investigate the formation of lattice structures built of\nindividual vortex-antivortex (VAV) bound states under the action of the\ntwo-dimensional harmonic-oscillator (HO) potential trap and effective\nspin-orbit coupling (SOC), produced by the TE-TM splitting in the polariton\nsystem. The number of VAV elements (pixels) building the structures grow with\nthe increase of self- and cross-interaction coefficients. Depending upon their\nvalues and the trapping frequency, stable ring-shaped, circular, square-shaped,\nrectangular, pentagonal, hexagonal, and triangular patterns are produced, with\nthe central site left vacant or occupied in the lattice patterns of different\ntypes. The results suggest the experimental creation of the new patterns and\ntheir possible use for the design of integrated circuits in EP setups,\ncontrolled by the strengths of the TE-TM splitting, nonlinearity, and HO trap.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T05:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.07487v1","title":"Microscopic model for yields and total kinetic energy in nuclear fission","summary":"An extension of time-dependent density functional theory (TDDFT), the\ngeneralized time-dependent generator coordinate method (TDGCM), is applied to a\nstudy of induced nuclear fission dynamics. In the generalized TDGCM, the\ncorrelated nuclear wave function is represented as a coherent superposition of\ntime-dependent DFT trajectories. In the first realistic application, a large\nbasis of 25 TDDFT trajectories is employed to calculate the charge yields and\ntotal kinetic energy distribution for the fission of $^{240}$Pu. The results\nare compared with available data, and with those obtained using a standard\nTDDFT, that does not consider quantum fluctuations, and the adiabatic TDGCM+GOA\n(Gaussian overlap approximation). It is shown that fragment yields and kinetic\nenergies can simultaneously be described in a consistent microscopic framework\nthat includes fluctuations in the collective degrees of freedom and the\none-body dissipation mechanism.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-10T06:42:56Z"}
{"aid":"http://arxiv.org/abs/2504.07502v1","title":"Arithmetic and Geometric Langlands Program","summary":"We explain how the geometric Langlands program inspires some recent new\nprospectives of classical arithmetic Langlands program and leads to the\nsolutions of some problems in arithmetic geometry.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.07536v1","title":"Criteria for finite injective dimension of modules over a local ring","summary":"Let $R$ be a commutative Noetherian local ring. We prove that the finiteness\nof the injective dimension of a finitely generated $R$-module $C$ is determined\nby the existence of a Cohen--Macaulay module $M$ that satisfies an inequality\nconcerning multiplicity and type, together with the vanishing of finitely many\nExt modules. As applications, we recover a result of Rahmani and Taherizadeh\nand provide sufficient conditions for a finitely generated $R$-module to have\nfinite injective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.07544v1","title":"SeparationPINN: Physics-Informed Neural Networks for Seismic P- and\n  S-Wave Mode Separation","summary":"Accurate separation of P- and S-waves is essential for multi-component\nseismic data processing, as it helps eliminate interference between wave modes\nduring imaging or inversion, which leads to high-accuracy results. Traditional\nmethods for separating P- and S-waves rely on the Christoffel equation to\ncompute the polarization direction of the waves in the wavenumber domain, which\nis computationally expensive. Although machine learning has been employed to\nimprove the computational efficiency of the separation process, most methods\nstill require supervised learning with labeled data, which is often unavailable\nfor field data. To address this limitation, we propose a wavefield separation\ntechnique based on the physics-informed neural network (PINN). This\nunsupervised machine learning approach is applicable to unlabeled data.\nFurthermore, the trained PINN model provides a mesh-free numerical solution\nthat effectively captures wavefield features at multiple scales. Numerical\ntests demonstrate that the proposed PINN-based separation method can accurately\nseparate P- and S-waves in both homogeneous and heterogeneous media.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.07563v1","title":"Post-Newtonian dynamics of compact binaries with mass transfer","summary":"Taking into account the mass transfer effect, we derive the equations of\nmotion of a compact binary system at the second-half post-Newtonian order.\nApplying such equations of motion to quasi-circular orbits, we obtain the time\nderivative of the orbital frequency, which is consistent with the angular\nmomentum balance equation. Numerical estimates of the phase of gravitational\nwaves are provided for typical mass transfer rates. Our result can be used to\nimprove the waveforms of gravitational waves emitted by compact binaries with\nmass transfer.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:49:57Z"}
{"aid":"http://arxiv.org/abs/2504.07567v1","title":"Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf\n  Foundation Models, Fine-Tuning Strategies and Practical Trade-offs","summary":"We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CE,cs.IR,cs.LG","published":"2025-04-10T08:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.07569v1","title":"Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple\n  modelling","summary":"We provide an updated test for modifications of gravity from a sample of\nwide-binary stars from GAIA DR3, and their sky-projected relative velocities.\nHere we extend on our earlier 2023 study, using several updated selection cuts\naimed at reducing contamination from triple systems with an undetected third\nstar. We also use improved mass estimates from FLAMES, and we add refinements\nto previous modelling of the triple and other populations and the\nmodel-fitting. We fit histograms of observed vs Newtonian velocity differences\nto a flexible mixture of binary + triple populations with realistic\neccentricity distributions, plus unbound flyby and random-chance populations.\nWe find as before that Newtonian models provide a significantly better fit than\nMOND, though improved understanding of the triple population is necessary to\nmake this fully decisive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-10T09:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.07585v1","title":"High-Level Synthesis of Digital Circuits from Template Haskell and\n  SDF-AP","summary":"Functional languages as input specifications for High-Level Synthesis (HLS)\ntools allow to specify data dependencies but do not contain a notion of time\nnor execution order. In this paper, we propose a method to add this notion to\nthe functional description using the dataflow model SDF-AP. SDF-AP consists of\npatterns that express consumption and production that we can use to enforce\nresource usage. We created an HLS-tool that can synthesize parallel hardware,\nboth data and control path, based on the repetition, expressed in Higher-Order\nFunctions, combined with specified SDF-AP patterns.\n  Our HLS-tool, based on Template Haskell, generates an Abstract Syntax Tree\nbased on the given patterns and the functional description uses the\nClash-compiler to generate VHDL/Verilog.\n  Case studies show consistent resource consumption and temporal behavior for\nour HLS. A comparison with a commercially available HLS-tool shows that our HLS\ntool outperforms in terms of latency and sometimes in resource consumption.\n  The method and tool presented in this paper offer more transparency to the\ndeveloper and allow to specify more accurately the synthesized hardware\ncompared to what is possible with pragmas of the Vitis HLS-tool.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:25:47Z"}
{"aid":"http://arxiv.org/abs/2504.07591v1","title":"On the Cox rings of some hypersurfaces","summary":"We introduce a cohomological method to compute Cox rings of hypersurfaces in\nthe ambient space P^1 x P^n, which is more direct than existing methods. We\nprove that smooth hypersurfaces defined by regular sequences of coefficients\nare Mori dream spaces, generalizing a result of Ottem. We also compute Cox\nrings of certain specialized examples. In particular, we compute Cox rings in\nthe well-studied family of Calabi--Yau threefolds of bidegree (2,4) in P^1 x\nP^3, determining explicitly how the Cox ring can jump discontinuously in a\nsmooth family.","main_category":"math.AG","categories":"math.AG","published":"2025-04-10T09:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.07601v1","title":"Restricted Poisson algebras in characteristic 2","summary":"In this paper, we introduce restricted Poisson algebras in characteristic 2\nand their relationship with restricted Lie-Rinehart algebras, for which we\ndevelop a cohomology theory and investigate abelian extensions. We also\nconstruct a full cohomology complex for restricted Poisson algebras in\ncharacteristic 2 that captures formal deformations and prove that it is\nisomorphic to the cohomology complex of a suitable restricted Lie-Rinehart\nalgebra, under certain assumptions. A number of examples are provided in order\nto illustrate our constructions.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T09:54:29Z"}
{"aid":"http://arxiv.org/abs/2504.07615v1","title":"VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model","summary":"Recently DeepSeek R1 has shown that reinforcement learning (RL) can\nsubstantially improve the reasoning capabilities of Large Language Models\n(LLMs) through a simple yet effective design. The core of R1 lies in its\nrule-based reward formulation, which leverages tasks with deterministic\nground-truth answers to enable precise and stable reward computation. In the\nvisual domain, we similarly observe that a wide range of visual understanding\ntasks are inherently equipped with well-defined ground-truth annotations. This\nproperty makes them naturally compatible with rule-based reward mechanisms.\nMotivated by this observation, we investigate the extension of R1-style\nreinforcement learning to Vision-Language Models (VLMs), aiming to enhance\ntheir visual reasoning capabilities. To this end, we develop VLM-R1, a\ndedicated framework designed to harness RL for improving VLMs' performance on\ngeneral vision-language tasks. Using this framework, we further explore the\nfeasibility of applying RL to visual domain. Experimental results indicate that\nthe RL-based model not only delivers competitive performance on visual\nunderstanding tasks but also surpasses Supervised Fine-Tuning (SFT) in\ngeneralization ability. Furthermore, we conduct comprehensive ablation studies\nthat uncover a series of noteworthy insights, including the presence of reward\nhacking in object detection, the emergence of the \"OD aha moment\", the impact\nof training data quality, and the scaling behavior of RL across different model\nsizes. Through these analyses, we aim to deepen the understanding of how\nreinforcement learning enhances the capabilities of vision-language models, and\nwe hope our findings and open-source contributions will support continued\nprogress in the vision-language RL community. Our code and model are available\nat https://github.com/om-ai-lab/VLM-R1","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T10:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.07622v1","title":"A new quasar strongly-lensed candidate by the galaxy cluster WHJ0400-27\n  with a $18''$ image-separation","summary":"Time-delay cosmography (TDC) using multiply-lensed quasars (QSOs) by galaxies\nhas recently emerged as an independent and competitive tool to measure the\nvalue of the Hubble constant. Lens galaxy clusters hosting multiply-imaged\nQSOs, when coupled with an accurate and precise knowledge of their total mass\ndistribution, are equally powerful cosmological probes. However, less than ten\nsuch systems have been identified to date. Our study aims to expand the limited\nsample of cluster-lensed QSO systems by identifying new candidates within rich\ngalaxy clusters. Starting from a sample of ~$10^5$ galaxy cluster candidates\n(Wen & Han, 2022), built from Dark Energy Survey and Wide-field Infrared Survey\nExplorer imaging data, and a highly-pure catalogue of over one million QSOs,\nbased on Gaia DR3 data, we cross-correlate them to identify candidate lensed\nQSOs near the core of massive galaxy clusters. Our search yielded 3 lensed\ndouble candidates over an area of ~$5000$ sq. degree. In this work, we focus on\nthe best candidate consisting of a double QSO with Gaia-based redshift of 1.35,\nprojected behind a moderately rich cluster (WHJ0400-27) at $z_{phot}=0.65$.\nBased on a first spectroscopic follow-up study, we confirm the two QSOs at\n$z=1.345$, with indistinguishable spectra, and a brightest cluster galaxy at\n$z=0.626$. These observations seem to support the strong lensing nature of this\nsystem, although some tension emerges when the cluster mass from a preliminary\nlens model is compared with that from other mass proxies. We also discuss the\npossibility that such system is a rare physical association of two distinct\nQSOs with a projected physical distance of ~$150$ kpc. If further spectroscopic\nobservations confirm its lensing nature, such a rare lens system would exhibit\none of the largest image separations observed to date\n($\\Delta\\vartheta=17.8''$), opening interesting TDC applications.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-10T10:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.07623v1","title":"Joint Travel Route Optimization Framework for Platooning","summary":"Platooning represents an advanced driving technology designed to assist\ndrivers in traffic convoys of varying lengths, enhancing road safety, reducing\ndriver fatigue, and improving fuel efficiency. Sophisticated automated driving\nassistance systems have facilitated this innovation. Recent advancements in\nplatooning emphasize cooperative mechanisms within both centralized and\ndecentralized architectures enabled by vehicular communication technologies.\nThis study introduces a cooperative route planning optimization framework aimed\nat promoting the adoption of platooning through a centralized platoon formation\nstrategy at the system level. This approach is envisioned as a transitional\nphase from individual (ego) driving to fully collaborative driving.\nAdditionally, this research formulates and incorporates travel cost metrics\nrelated to fuel consumption, driver fatigue, and travel time, considering\nregulatory constraints on consecutive driving durations. The performance of\nthese cost metrics has been evaluated using Dijkstra's and A* shortest path\nalgorithms within a network graph framework. The results indicate that the\nproposed architecture achieves an average cost improvement of 14 % compared to\nindividual route planning for long road trips.","main_category":"cs.ET","categories":"cs.ET,cs.RO,cs.SY,eess.SY","published":"2025-04-10T10:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.07627v1","title":"Robustness of Online Identification-based Policy Iteration to Noisy Data","summary":"This article investigates the core mechanisms of indirect data-driven control\nfor unknown systems, focusing on the application of policy iteration (PI)\nwithin the context of the linear quadratic regulator (LQR) optimal control\nproblem. Specifically, we consider a setting where data is collected\nsequentially from a linear system subject to exogenous process noise, and is\nthen used to refine estimates of the optimal control policy. We integrate\nrecursive least squares (RLS) for online model estimation within a\ncertainty-equivalent framework, and employ PI to iteratively update the control\npolicy. In this work, we investigate first the convergence behavior of RLS\nunder two different models of adversarial noise, namely point-wise and energy\nbounded noise, and then we provide a closed-loop analysis of the combined model\nidentification and control design process. This iterative scheme is formulated\nas an algorithmic dynamical system consisting of the feedback interconnection\nbetween two algorithms expressed as discrete-time systems. This system\ntheoretic viewpoint on indirect data-driven control allows us to establish\nconvergence guarantees to the optimal controller in the face of uncertainty\ncaused by noisy data. Simulations illustrate the theoretical results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T10:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.07669v1","title":"Languages of Boundedly-Ambiguous Vector Addition Systems with States","summary":"The aim of this paper is to deliver broad understanding of a class of\nlanguages of boundedly-ambiguous VASS, that is k-ambiguous VASS for some\nnatural k. These are languages of Vector Addition Systems with States with the\nacceptance condition defined by the set of accepting states such that each\naccepted word has at most k accepting runs. We develop tools for proving that a\ngiven language is not accepted by any k-ambiguous VASS. Using them we show a\nfew negative results: lack of some closure properties of languages of\nk-ambiguous VASS and undecidability of the k-ambiguity problem, namely the\nquestion whether a given VASS language is a language of some k-ambiguous VASS.\nFinally, we show that the regularity problem is decidable for k-ambiguous VASS.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-10T11:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.07674v1","title":"Is the atmospheric river operating at a self-organized criticality\n  state?","summary":"Atmospheric rivers (ARs) are essential components of the global hydrological\ncycle, with profound implications for water resources, extreme weather events,\nand climate dynamics. Yet, the statistical organization and underlying physical\nmechanisms of AR intensity and evolution remain poorly understood. Here we\napply methods from statistical physics to analyze the full life cycle of ARs\nand identify universal signatures of self-organized criticality (SOC). We\ndemonstrate that AR morphology exhibits nontrivial fractal geometry, while AR\nevent sizes, quantified via integrated water vapor transport, follow robust\npower-law distributions, displaying finite-size scaling. These scaling\nbehaviors persist under warming scenarios, suggesting that ARs operate near a\ncritical state as emergent, self-regulating systems. Concurrently, we observe a\nsystematic poleward migration and intensification of ARs, linked to\nthermodynamic amplification and dynamical reorganization. Our findings\nestablish a statistical physics framework for ARs, linking critical phenomena\nto the spatiotemporal structure of extreme events in a warming climate.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T11:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.07685v1","title":"Context-Aware Monolingual Human Evaluation of Machine Translation","summary":"This paper explores the potential of context-aware monolingual human\nevaluation for assessing machine translation (MT) when no source is given for\nreference. To this end, we compare monolingual with bilingual evaluations (with\nsource text), under two scenarios: the evaluation of a single MT system, and\nthe comparative evaluation of pairwise MT systems. Four professional\ntranslators performed both monolingual and bilingual evaluations by assigning\nratings and annotating errors, and providing feedback on their experience. Our\nfindings suggest that context-aware monolingual human evaluation achieves\ncomparable outcomes to human bilingual evaluations, and suggest the feasibility\nand potential of monolingual evaluation as an efficient approach to assessing\nMT.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-10T12:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.07686v1","title":"Measurements of Higgs boson production via gluon-gluon fusion and\n  vector-boson fusion using $H\\rightarrow WW^\\ast \\rightarrow \\ellν\\ellν$\n  decays in $pp$ collisions with the ATLAS detector and their effective field\n  theory interpretations","summary":"Higgs boson production cross-sections via gluon-gluon fusion and vector-boson\nfusion in proton-proton collisions are measured in the $H\\rightarrow WW^\\ast\n\\rightarrow \\ell\\nu\\ell\\nu$ decay channel. The Large Hadron Collider delivered\nproton-proton collisions at a centre-of-mass energy of $13\\,\\textrm{TeV}$\nbetween 2015 and 2018, which were recorded by the ATLAS detector, corresponding\nto an integrated luminosity of $140\\,\\textrm{fb}^{-1}$. The total\ncross-sections for Higgs boson production by gluon-gluon fusion and\nvector-boson fusion times the $H\\rightarrow WW^\\ast$ branching ratio are\nmeasured to be $12.4^{+1.3}_{-1.2}\\,\\textrm{pb}$ and\n$0.79^{+0.18}_{-0.16}\\,\\textrm{pb}$, respectively, in agreement with the\nStandard Model predictions. Higgs boson production is further characterised\nthrough measurements of Simplified Template Cross-Sections in a total of\nfifteen kinematic fiducial regions. A new scheme of kinematic fiducial regions\nhas been introduced to enhance the sensitivity to CP-violating effects in Higgs\nboson interactions. Both schemes are used to constrain CP-even and CP-odd\ndimension-six operators in the Standard Model effective field theory.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T12:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.07731v1","title":"Adaptive Robust Unscented Kalman Filter for Dynamic State Estimation of\n  Power System","summary":"Non-Gaussian noise and the uncertainty of noise distribution are the common\nfactors that reduce accuracy in dynamic state estimation of power systems (PS).\nIn addition, the optimal value of the free coefficients in the unscented Kalman\nfilter (UKF) based on information theoretic criteria is also an urgent problem.\nIn this paper, a robust adaptive UKF (AUKF) under generalized minimum mixture\nerror entropy with fiducial points (GMMEEF) over improve Snow Geese algorithm\n(ISGA) (ISGA-GMMEEF-AUKF) is proposed to overcome the above difficulties. The\nestimation process of the proposed algorithm is based on several key steps\nincluding augmented regression error model (AREM) construction, adaptive state\nestimation, and free coefficients optimization. Specifically, an AREM\nconsisting of state prediction and measurement errors is established at the\nfirst step. Then, GMMEEF-AUKF is developed by solving the optimization problem\nbased on GMMEEF, which uses a generalized Gaussian kernel combined with mixture\ncorrentropy to enhance the flexibility further and resolve the data problem\nwith complex attributes and update the noise covariance matrix according to the\nAREM framework. Finally, the ISGA is designed to automatically calculate the\noptimal value of coefficients such as the shape coefficients of the kernel in\nthe GMMEEF criterion, the coefficients selection sigma points in unscented\ntransform, and the update coefficient of the noise covariance matrices fit with\nthe PS model. Simulation results on the IEEE 14, 30, and 57-bus test systems in\ncomplex scenarios have confirmed that the proposed algorithm outperforms the\nMEEF-UKF and UKF by an average efficiency of 26% and 65%, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T13:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.07735v1","title":"$q$-Differential Operators for $q$-Spinor Variables","summary":"In this paper we introduce the $q$-differential operator for $q$-spinor\nvariables. We establish the $q$-spinor chain rule , the new $q$-differential\noperator, the $q$-Dirac differential operators and the $q$-complex spinor\nintegrals. We also define the $q$-spinor differential equation. The suggestions\nfor further work at the end of the paper.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-10T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.07740v1","title":"Zero-Shot Cross-Domain Code Search without Fine-Tuning","summary":"Code search aims to retrieve semantically relevant code snippets for natural\nlanguage queries. While pre-trained language models (PLMs) have shown\nremarkable performance in this task, they struggle in cross-domain scenarios,\noften requiring costly fine-tuning or facing performance drops in zero-shot\nsettings. RAPID, which generates synthetic data for model fine-tuning, is\ncurrently the only effective method for zero-shot cross-domain code search.\nDespite its effectiveness, RAPID demands substantial computational resources\nfor fine-tuning and needs to maintain specialized models for each domain,\nunderscoring the need for a zero-shot, fine-tuning-free approach for\ncross-domain code search.\n  The key to tackling zero-shot cross-domain code search lies in bridging the\ngaps among domains. In this work, we propose to break the query-code matching\nprocess of code search into two simpler tasks: query-comment matching and\ncode-code matching. Our empirical study reveals the strong complementarity\namong the three matching schemas in zero-shot cross-domain settings, i.e.,\nquery-code, query-comment, and code-code matching. Based on the findings, we\npropose CodeBridge, a zero-shot, fine-tuning-free approach for cross-domain\ncode search. Specifically, CodeBridge uses Large Language Models (LLMs) to\ngenerate comments and pseudo-code, then combines query-code, query-comment, and\ncode-code matching via PLM-based similarity scoring and sampling-based fusion.\nExperimental results show that our approach outperforms the state-of-the-art\nPLM-based code search approaches, i.e., CoCoSoDa and UniXcoder, by an average\nof 21.4% and 24.9% in MRR, respectively, across three datasets. Our approach\nalso yields results that are better than or comparable to those of the\nzero-shot cross-domain code search approach RAPID, which requires costly\nfine-tuning.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-10T13:36:37Z"}
{"aid":"http://arxiv.org/abs/2504.07766v1","title":"Realigning Incentives to Build Better Software: a Holistic Approach to\n  Vendor Accountability","summary":"In this paper, we ask the question of why the quality of commercial software,\nin terms of security and safety, does not measure up to that of other (durable)\nconsumer goods we have come to expect. We examine this question through the\nlens of incentives. We argue that the challenge around better quality software\nis due in no small part to a sequence of misaligned incentives, the most\ncritical of which being that the harm caused by software problems is by and\nlarge shouldered by consumers, not developers. This lack of liability means\nsoftware vendors have every incentive to rush low-quality software onto the\nmarket and no incentive to enhance quality control. Within this context, this\npaper outlines a holistic technical and policy framework we believe is needed\nto incentivize better and more secure software development. At the heart of the\nincentive realignment is the concept of software liability. This framework\ntouches on various components, including legal, technical, and financial, that\nare needed for software liability to work in practice; some currently exist,\nsome will need to be re-imagined or established. This is primarily a\nmarket-driven approach that emphasizes voluntary participation but highlights\nthe role appropriate regulation can play. We connect and contrast this with the\nEU legal environment and discuss what this framework means for open-source\nsoftware (OSS) development and emerging AI risks. Moreover, we present a\nCrowdStrike case study complete with a what-if analysis had our proposed\nframework been in effect. Our intention is very much to stimulate a robust\nconversation among both researchers and practitioners.","main_category":"cs.CR","categories":"cs.CR,cs.SE,econ.TH","published":"2025-04-10T14:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.07772v1","title":"Extremum Seeking Boundary Control for Euler-Bernoulli Beam PDEs","summary":"This paper presents the design and analysis of an extremum seeking (ES)\ncontroller for scalar static maps in the context of infinite-dimensional\ndynamics governed by the 1D Euler-Bernoulli (EB) beam Partial Differential\nEquation (PDE). The beam is actuated at one end (using position and moment\nactuators). The map's input is the displacement at the beam's uncontrolled end,\nwhich is subject to a sliding boundary condition. Notably, ES for this class of\nPDEs remains unexplored in the existing literature. To compensate for PDE\nactuation dynamics, we employ a boundary control law via a backstepping\ntransformation and averaging-based estimates for the gradient and Hessian of\nthe static map to be optimized. This compensation controller leverages a\nSchr\\\"odinger equation representation of the EB beam and adapts existing\nbackstepping designs to stabilize the beam. Using the semigroup and averaging\ntheory in infinite dimensions, we prove local exponential convergence to a\nsmall neighborhood of the unknown optimal point. Finally, simulations\nillustrate the effectiveness of the design in optimizing the unknown static\nmap.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T14:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07795v1","title":"Measurement of coincident photon-initiated processes in ultra-peripheral\n  Pb+Pb collisions with the ATLAS detector","summary":"The Lorentz-contracted electromagnetic fields of the ions in\nultra-relativistic heavy-ion collisions generate intense quasi-real photon\nfluxes. These lead to photon-induced interactions that are observed in\nultra-peripheral collisions (UPCs), such as vector meson and lepton-pair\nproduction. The high photon flux also enables the occurrence of multiple\nphoton-induced processes in a single collision. Presented is the first\nmeasurement of the coincident production of $\\gamma\\gamma \\rightarrow\n\\mu^{+}\\mu^{-}$ and $\\gamma+A\\rightarrow\\rho^{0}+A$ in UPC Pb+Pb collisions at\ncentre-of-mass energies of 5.02 TeV and 5.36 TeV with the ATLAS detector at the\nLarge Hadron Collider. The rate of the coincident process relative to the\nexclusive $\\gamma\\gamma \\rightarrow \\mu^{+}\\mu^{-}$ process is measured\ndifferentially in intervals of forward event activity, quantified by the Zero\nDegree Calorimeters. The relative rate, summed over forward event activity, for\nthe coincident $\\rho^{0}$ production is measured to be\n$(9.3\\,\\pm0.4\\,\\mathrm{(stat.)}\\,\\pm0.2\\,\\mathrm{(syst.)})\\times10^{-3}$.\nCorrelations between the dimuon kinematic properties, such as its mass, and the\ncoincident $\\rho^{0}$ meson production rate, are also presented. These\nmeasurements confirm the presence of multi photon-induced processes in UPC\ncollisions, and can provide new insight into the impact parameter dependence of\nphoton-induced vector meson production.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-10T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.07809v1","title":"A Riemannian Gradient Descent Method for the Least Squares Inverse\n  Eigenvalue Problem","summary":"We address an algorithm for the least squares fitting of a subset of the\neigenvalues of an unknown Hermitian matrix lying an an affine subspace, called\nthe Lift and Projection (LP) method, due to Chen and Chu (SIAM Journal on\nNumerical Analysis, 33 (1996), pp.2417-2430). The LP method iteratively `lifts'\nthe current iterate onto the spectral constraint manifold then 'projects' onto\nthe solution's affine subspace. We prove that this is equivalent to a\nRiemannian Gradient Descent with respect to a natural Riemannian metric. This\ninsight allows us to derive a more efficient implementation, analyse more\nprecisely its global convergence properties, and naturally append additional\nconstraints to the problem. We provide several numerical experiments to\ndemonstrate the improvement in computation time, which can be more than an\norder of magnitude if the eigenvalue constraints are on the smallest\neigenvalues, the largest eigenvalues, or the eigenvalues closest to a given\nnumber. These experiments include an inverse eigenvalue problem arising in\nInelastic Neutron Scattering of Manganese-6, which requires the least squares\nfitting of 16 experimentally observed eigenvalues of a $32400\\times32400$\nsparse matrix from a 5-dimensional subspace of spin Hamiltonian matrices.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T14:47:16Z"}
{"aid":"http://arxiv.org/abs/2504.07811v1","title":"The ISC Creator: Human-Centered Design of Learning Analytics Interactive\n  Indicator Specification Cards","summary":"Emerging research on human-centered learning analytics (HCLA) has\ndemonstrated the importance of involving diverse stakeholders in co-designing\nlearning analytics (LA) systems. However, there is still a demand for effective\nand efficient methods to co-design LA dashboards and indicators. Indicator\nSpecification Cards (ISCs) have been introduced recently to facilitate the\nsystematic co-design of indicators by different LA stakeholders. In this paper,\nwe strive to enhance the user experience and usefulness of the ISC-based\nindicator design process. Towards this end, we present the systematic design,\nimplementation, and evaluation details of the ISC Creator, an interactive LA\ntool that allows low-cost and flexible design of LA indicators. Our findings\ndemonstrate the importance of carefully considered interactivity and\nrecommendations for orienting and supporting non-expert LA stakeholders to\ndesign custom LA indicators.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-10T14:49:47Z"}
{"aid":"http://arxiv.org/abs/2504.07820v1","title":"Smoothed Distance Kernels for MMDs and Applications in Wasserstein\n  Gradient Flows","summary":"Negative distance kernels $K(x,y) := - \\|x-y\\|$ were used in the definition\nof maximum mean discrepancies (MMDs) in statistics and lead to favorable\nnumerical results in various applications. In particular, so-called slicing\ntechniques for handling high-dimensional kernel summations profit from the\nsimple parameter-free structure of the distance kernel. However, due to its\nnon-smoothness in $x=y$, most of the classical theoretical results, e.g. on\nWasserstein gradient flows of the corresponding MMD functional do not longer\nhold true. In this paper, we propose a new kernel which keeps the favorable\nproperties of the negative distance kernel as being conditionally positive\ndefinite of order one with a nearly linear increase towards infinity and a\nsimple slicing structure, but is Lipschitz differentiable now. Our construction\nis based on a simple 1D smoothing procedure of the absolute value function\nfollowed by a Riemann-Liouville fractional integral transform. Numerical\nresults demonstrate that the new kernel performs similarly well as the negative\ndistance kernel in gradient descent methods, but now with theoretical\nguarantees.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.FA,math.PR","published":"2025-04-10T14:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07824v1","title":"Go Figure: Transparency in neuroscience images preserves context and\n  clarifies interpretation","summary":"Visualizations are vital for communicating scientific results. Historically,\nneuroimaging figures have only depicted regions that surpass a given\nstatistical threshold. This practice substantially biases interpretation of the\nresults and subsequent meta-analyses, particularly towards non-reproducibility.\nHere we advocate for a \"transparent thresholding\" approach that not only\nhighlights statistically significant regions but also includes subthreshold\nlocations, which provide key experimental context. This balances the dual needs\nof distilling modeling results and enabling informed interpretations for modern\nneuroimaging. We present four examples that demonstrate the many benefits of\ntransparent thresholding, including: removing ambiguity, decreasing\nhypersensitivity to non-physiological features, catching potential artifacts,\nimproving cross-study comparisons, reducing non-reproducibility biases, and\nclarifying interpretations. We also demonstrate the many software packages that\nimplement transparent thresholding, several of which were added or streamlined\nrecently as part of this work. A point-counterpoint discussion addresses issues\nwith thresholding raised in real conversations with researchers in the field.\nWe hope that by showing how transparent thresholding can drastically improve\nthe interpretation (and reproducibility) of neuroimaging findings, more\nresearchers will adopt this method.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-10T15:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.07826v1","title":"MuSaRoNews: A Multidomain, Multimodal Satire Dataset from Romanian News\n  Articles","summary":"Satire and fake news can both contribute to the spread of false information,\neven though both have different purposes (one if for amusement, the other is to\nmisinform). However, it is not enough to rely purely on text to detect the\nincongruity between the surface meaning and the actual meaning of the news\narticles, and, often, other sources of information (e.g., visual) provide an\nimportant clue for satire detection. This work introduces a multimodal corpus\nfor satire detection in Romanian news articles named MuSaRoNews. Specifically,\nwe gathered 117,834 public news articles from real and satirical news sources,\ncomposing the first multimodal corpus for satire detection in the Romanian\nlanguage. We conducted experiments and showed that the use of both modalities\nimproves performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T15:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.07830v1","title":"MOSAIC: Modeling Social AI for Content Dissemination and Regulation in\n  Multi-Agent Simulations","summary":"We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SI","published":"2025-04-10T15:06:54Z"}
{"aid":"http://arxiv.org/abs/2504.07834v1","title":"Inverse Design of Block Polymer Materials with Desired Nanoscale\n  Structure and Macroscale Properties","summary":"The rational design of novel polymers with tailored material properties has\nbeen a long-standing challenge in the field due to the large number of possible\npolymer design variables. To accelerate this design process, there is a\ncritical need to develop novel tools to aid in the inverse design process and\nefficiently explore the high-dimensional polymer design space. Optimizing\nmacroscale material properties for polymeric systems is difficult as properties\nare dictated by features on a multitude of length scales, ranging from the\nchosen monomer chemistries to the chain level design to larger-scale domain\nstructures. In this work, we present an efficient high-throughput in-silico\nbased framework to effectively design high-performance polymers with desired\nmulti-scale nanostructure and macroscale properties, which we call RAPSIDY 2.0\n- Rapid Analysis of Polymer Structure and Inverse Design strategY 2.0. This new\nversion of RAPSIDY builds upon our previous work, RAPSIDY 1.0, which focused\npurely on identifying polymer designs that stabilized a desired nanoscale\nmorphology. In RAPSIDY 2.0 we use a combination of molecular dynamics\nsimulations and Bayesian optimization driven active learning to optimally query\nhigh-dimensional polymer design spaces and propose promising design candidates\nthat simultaneously stabilize a selected nanoscale morphology and exhibit\ndesired macroscale material properties. We utilize MD simulations with polymer\nchains preplaced into selected nanoscale morphologies and perform virtual\nexperiments to determine the stability of the chosen polymer design within the\ntarget morphology and calculate the desired macroscale material properties\n(e.g., thermal conductivity). Our methodology directly addresses the unique\nchallenge associated with copolymers, whose macroscale properties are a\nfunction of both their chain design and mesoscale morphology, which are\ncoupled.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.07836v1","title":"AerialVG: A Challenging Benchmark for Aerial Visual Grounding by\n  Exploring Positional Relations","summary":"Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T15:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.07840v1","title":"Understanding Learner-LLM Chatbot Interactions and the Impact of\n  Prompting Guidelines","summary":"Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CL","published":"2025-04-10T15:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.07860v1","title":"Conformally weighted Einstein manifolds: the uniqueness problem","summary":"We discuss smooth metric measure spaces admitting two weighted Einstein\nrepresentatives of the same weighted conformal class. First, we describe the\nlocal geometries of such manifolds in terms of certain Einstein and\nquasi-Einstein warped products. Secondly, a global classification result is\nobtained when one of the underlying metrics is complete, showing that either it\nis a weighted space form, a special Einstein warped product, or a specific\nfamily of quasi-Einstein warped products. As a consequence, it must be a\nweighted sphere in the compact case.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.07862v1","title":"Resummation of Universal Tails in Gravitational Waveforms","summary":"We present a formula for the universal anomalous scaling of the multipole\nmoments of a generic gravitating source in classical general relativity. We\nderive this formula in two independent ways using effective field theory\nmethods. First, we use the absorption of low frequency gravitational waves by a\nblack hole to identify the total multipole scaling dimension as the\nrenormalized angular momentum of black hole perturbation theory. More\ngenerally, we show that the anomalous dimension is determined by phase shifts\nof gravitational waves elastically scattering off generic source multipole\nmoments, which reproduces the renormalized angular momentum in the particular\ncase of black holes. The effective field theory approach thus clarifies the\nrole of the renormalized angular momentum in the multipole expansion. The\nuniversality of the point-particle effective description of compact gravitating\nsystems further allows us to extract the universal part of the anomalous\ndimension, which is the same for any object, including black holes, neutron\nstars, and binary systems. As an application, we propose a novel resummation of\nthe universal short-distance logarithms (``tails'') in the gravitational\nwaveform of binary systems, which may improve the modeling of signals from\ncurrent and future gravitational wave experiments.","main_category":"hep-th","categories":"hep-th,astro-ph.HE,gr-qc,hep-ph","published":"2025-04-10T15:39:05Z"}
{"aid":"http://arxiv.org/abs/2504.07877v1","title":"Gauge and parametrization dependence of Quantum Einstein Gravity within\n  the Proper Time flow","summary":"Proper time functional flow equations have garnered significant attention in\nrecent years, as they are particularly suitable in analyzing non-perturbative\ncontexts. By resorting to this flow, we investigate the regulator and gauge\ndependence in quantum Einstein gravity within the asymptotic safety framework,\nconsidering various regularization schemes. Our findings indicate that some\ndetails of the regulator have minor influence on the critical properties of the\ntheory. In contrast, the selection between linear and exponential\nparametrizations appears to have a more substantial impact on the scaling\nbehavior of the renormalized flow near the non-Gaussian fixed point.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T15:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.07884v1","title":"CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and\n  Categorical Variables","summary":"This study focuses on mixed-variable black-box optimization (MV-BBO),\naddressing continuous, integer, and categorical variables. Many real-world\nMV-BBO problems involve dependencies among these different types of variables,\nrequiring efficient methods to optimize them simultaneously. Recently,\nstochastic optimization methods leveraging the mechanism of the covariance\nmatrix adaptation evolution strategy have shown promising results in\nmixed-integer or mixed-category optimization. However, such methods cannot\nhandle the three types of variables simultaneously. In this study, we propose\nCatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that\njointly optimizes continuous, integer, and categorical variables. CatCMAwM is\ndeveloped by incorporating a novel integer handling into CatCMA, a\nmixed-category black-box optimization method employing a joint distribution of\nmultivariate Gaussian and categorical distributions. The proposed integer\nhandling is carefully designed by reviewing existing integer handlings and\nfollowing the design principles of CatCMA. Even when applied to mixed-integer\nproblems, it stabilizes the marginal probability and improves the convergence\nperformance of continuous variables. Numerical experiments show that CatCMAwM\neffectively handles the three types of variables, outperforming\nstate-of-the-art Bayesian optimization methods and baselines that simply\nincorporate existing integer handlings into CatCMA.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T15:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.07885v1","title":"Self-Evaluated Expertise in experimental physics: a measure of students'\n  physics self-recognition","summary":"We introduce and theoretically justify a new measure of the self-recognition\ncomponent of student physics identity called Self-Evaluated Expertise (SEE).\nThis measure is constructed such that it can be extracted from existing\nresponses to the E-CLASS. In this work, we compare scores from SEE with the\ntraditional measure calculated from the E-CLASS, which probes student views\nabout experimental physics, to show that the SEE score is a quantitatively\ndifferent measure. Consequently, we show that student self-recognition\ndecreases from pre-instruction administration of the E-CLASS to the\npost-instruction administration when averaged across data from 494 courses\nhaving taken place between 2016--2019.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-10T15:59:27Z"}
{"aid":"http://arxiv.org/abs/2504.07888v1","title":"The Role of Buffer Gas in Shaping the D1 Line Spectrum of Potassium\n  Vapour","summary":"In this study, we investigate the effect of buffer gas and magnetic field on\nthe spectral line shapes of the potassium D1 transition using sealed vapour\ncells filled with varying amounts of neon as a buffer gas. Employing a\ndual-temperature control system, we independently manipulate the cell body and\nstem temperatures to explore Doppler and collisional effects on the spectrum.\nOur results show how the Voigt spectral profile changes from Gaussian- to\nLorentzian-dominated forms due to pressure broadening and shifts caused by\ncollisions between potassium atoms and neon. Our measurements are in excellent\nagreement with the literature values for potassium-neon collisions. For the\nfirst time we were able to incorporate the buffer-gas shift and broadening into\nthe modified Voigt profile via the ElecSus code, and found excellent agreement\nbetween the predicted and measured line profiles. We also analyse the potassium\nD1 spectral lines in the hyperfine Paschen-Back regime using strong magnetic\nfields, demonstrating how Zeeman splitting modifies the pressure-broadened line\nshape. This work provides valuable insights into collision-induced broadening\nand shifts, enhancing our understanding of potassium spectroscopy and its\napplication in the development of advanced magneto-optical filters for solar\nphysics and other applications.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.optics","published":"2025-04-10T16:01:57Z"}
{"aid":"http://arxiv.org/abs/2504.07908v1","title":"Majorization for probability distributions, column stochastic matrices\n  and their linear preservers","summary":"In this paper we investigate majorization for probability distributions and\ncolumn stochastic matrices. We show that majorizations in general can be\nreduced to these sets. We characterize linear operators that preserve\nmajorization for probability distributions, and show their equivalence to\noperators preserving vector majorization. Our main result provides a complete\ncharacterization of linear preservers of strong majorization for column\nstochastic matrices, revealing a richer structure of preservers, than in the\nstandard setting. As a prerequisite to this characterization, we solve the\nproblem of characterizing linear preservers of majorization for zero-sum\nvectors, which yields a new structural insight into the classical results of\nAndo and of Li and Poon.","main_category":"math.RA","categories":"math.RA","published":"2025-04-10T16:29:54Z"}
{"aid":"http://arxiv.org/abs/2504.07914v1","title":"Scaling and Predictability in Surface Quasi-Geostrophic Turbulence","summary":"Turbulent flows are strongly chaotic and unpredictable, with a Lyapunov\nexponent that increases with the Reynolds number. Here, we study the chaoticity\nof the Surface Quasi-geostrophic system, a two-dimensional model for\ngeophysical flows that displays a direct cascade similar to that of\nthree-dimensional turbulence. Using high-resolution direct numerical\nsimulations, we investigate the dependence of the Lyapunov exponent on the\nReynolds number and find an anomalous scaling exponent larger than the one\npredicted by dimensional arguments. We also study the finite-time fluctuation\nof the Lyapunov exponent by computing the Cram\\'er function associated with its\nprobability distribution. We find that the Cram\\'er function attains a\nself-similar form at large Re.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-10T17:23:13Z"}
{"aid":"http://arxiv.org/abs/2504.07922v1","title":"Exploring Structure Constants in Planar $\\mathcal{N} = 4$ SYM: From\n  Small Spin to Strong Coupling","summary":"We study the structure constants of two conformal primary operators and one\nspinning operator in planar $\\mathcal{N} = 4$ Super-Yang-Mills theory using the\nhexagon formalism. By analytically continuing in the spin, we derive a formula\nfor computing these structure constants at any coupling in the small-spin\nlimit, up to a normalization factor. This formula allows us to explore their\nanalytical properties at strong coupling. In this regime, using classical\nstring calculations and a suitable ansatz, we extend our analysis to\nfinite-spin operators, verifying recent two-loop results for structure\nconstants in string theory and generalizing them to operators with arbitrary\nR-charges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.07935v1","title":"Stacking-induced ferroelectricity in tetralayer graphene","summary":"Recent studies have reported emergent ferroelectric behavior in twisted or\nmoir\\'e-engineered graphene-based van der Waals heterostructures, yet the\nmicroscopic origin of this effect remains under debate. Pristine mono- or\nfew-layer graphene lacks a permanent dipole due to its centrosymmetric lattice,\nmaking the emergence of ferroelectricity unlikely. However, mixed-stacked\ngraphene, such as the ABCB tetralayer configuration, breaks both inversion and\nmirror symmetry and has been theoretically predicted to support electrically\nswitchable dipoles. ABCB graphene represents the simplest natural graphene\npolytype exhibiting intrinsic out-of-plane polarization, arising from\nasymmetric charge carrier distribution across its layers. Here, we report\nrobust ferroelectric behavior in dual-gated, non-aligned ABCB tetralayer\ngraphene encapsulated in hexagonal boron nitride. The device exhibits\npronounced hysteresis in resistance under both top and bottom gate modulation,\nwith the effect persisting up to room temperature. This hysteresis originates\nfrom reversible layer-polarized charge reordering, driven by gate-induced\ntransitions between ABCB and BCBA stacking configurations -- without requiring\nmoir\\'e superlattices. Our findings establish stacking-order-induced symmetry\nbreaking as a fundamental route to electronic ferroelectricity in graphene and\nopen pathways for non-volatile memory applications based on naturally occurring\nmixed-stacked multilayer graphene.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T17:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.07941v1","title":"Quantum error correction via multi-particle discrete-time quantum walk","summary":"We propose a scheme of quantum error correction that employs a multi-particle\nquantum walk defined on nested squares, each hosting a single particle. In this\nmodel, each particle moves within its own distinct square through iterations of\nthree discrete-time steps. First, a particle updates its two-level internal\n{\\it coin} state. Next, it either moves to an adjacent vertex or stays put,\ndepending on the outcome. Finally, it interacts with another particle if these\nparticles arrive at the nearest-neighbor vertices of the two adjacent squares,\nacquiring a phase factor of $-1$. Because a single particle represents a\nthree-qubit state through its position and coin state, Shor's nine-qubit code\nis implemented using only three particles, with two additional particles for\nsyndrome measurement. Furthermore, by exploiting gauge symmetry, our scheme\nachieves redundant encoding, error correction, and arbitrary operations on the\nencoded information using only nearest-neighbor interactions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T17:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.07942v1","title":"MARS: a Multimodal Alignment and Ranking System for Few-Shot\n  Segmentation","summary":"Current Few Shot Segmentation literature lacks a mask selection method that\ngoes beyond visual similarity between the query and example images, leading to\nsuboptimal predictions. We present MARS, a plug-and-play ranking system that\nleverages multimodal cues to filter and merge mask proposals robustly. Starting\nfrom a set of mask predictions for a single query image, we score, filter, and\nmerge them to improve results. Proposals are evaluated using multimodal scores\ncomputed at local and global levels. Extensive experiments on COCO-20i,\nPascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring\ncomponents is crucial for robust ranking, validating our contribution. As MARS\ncan be effortlessly integrated with various mask proposal systems, we deploy it\nacross a wide range of top-performer methods and achieve new state-of-the-art\nresults on multiple existing benchmarks. Code will be available upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:53:23Z"}
{"aid":"http://arxiv.org/abs/2504.07949v1","title":"InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars\n  with Deformable Gaussians","summary":"With the rising interest from the community in digital avatars coupled with\nthe importance of expressions and gestures in communication, modeling natural\navatar behavior remains an important challenge across many industries such as\nteleconferencing, gaming, and AR/VR. Human hands are the primary tool for\ninteracting with the environment and essential for realistic human behavior\nmodeling, yet existing 3D hand and head avatar models often overlook the\ncrucial aspect of hand-body interactions, such as between hand and face. We\npresent InteracttAvatar, the first model to faithfully capture the\nphotorealistic appearance of dynamic hand and non-rigid hand-face interactions.\nOur novel Dynamic Gaussian Hand model, combining template model and 3D Gaussian\nSplatting as well as a dynamic refinement module, captures pose-dependent\nchange, e.g. the fine wrinkles and complex shadows that occur during\narticulation. Importantly, our hand-face interaction module models the subtle\ngeometry and appearance dynamics that underlie common gestures. Through\nexperiments of novel view synthesis, self reenactment and cross-identity\nreenactment, we demonstrate that InteracttAvatar can reconstruct hand and\nhand-face interactions from monocular or multiview videos with high-fidelity\ndetails and be animated with novel poses.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.09892v1","title":"Vermilion: A Traffic-Aware Reconfigurable Optical Interconnect with\n  Formal Throughput Guarantees","summary":"The increasing gap between datacenter traffic volume and the capacity of\nelectrical switches has driven the development of reconfigurable network\ndesigns utilizing optical circuit switching. Recent advancements, particularly\nthose featuring periodic fixed-duration reconfigurations, have achieved\npractical end-to-end delays of just a few microseconds. However, current\ndesigns rely on multi-hop routing to enhance utilization, which can lead to a\nsignificant reduction in worst-case throughput and added overhead from\ncongestion control and routing complexity. These factors pose significant\noperational challenges for the large-scale deployment of these technologies.\n  We present Vermilion, a reconfigurable optical interconnect that breaks the\nthroughput barrier of existing periodic reconfigurable networks, without the\nneed for multi-hop routing -- thus eliminating congestion control and\nsimplifying routing to direct communication. Vermilion adopts a traffic-aware\napproach while retaining the simplicity of periodic fixed-duration\nreconfigurations, similar to RotorNet. We formally establish throughput bounds\nfor Vermilion, demonstrating that it achieves at least $33\\%$ more throughput\nin the worst-case compared to existing designs. The key innovation of Vermilion\nis its short traffic-aware periodic schedule, derived using a matrix rounding\ntechnique. This schedule is then combined with a traffic-oblivious periodic\nschedule to efficiently manage any residual traffic. Our evaluation results\nsupport our theoretical findings, revealing significant performance gains for\ndatacenter workloads.","main_category":"cs.NI","categories":"cs.NI,cs.DS","published":"2025-04-14T05:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.09893v1","title":"LangPert: Detecting and Handling Task-level Perturbations for Robust\n  Object Rearrangement","summary":"Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T05:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.09927v1","title":"Efficient Task-specific Conditional Diffusion Policies: Shortcut Model\n  Acceleration and SO(3) Optimization","summary":"Imitation learning, particularly Diffusion Policies based methods, has\nrecently gained significant traction in embodied AI as a powerful approach to\naction policy generation. These models efficiently generate action policies by\nlearning to predict noise. However, conventional Diffusion Policy methods rely\non iterative denoising, leading to inefficient inference and slow response\ntimes, which hinder real-time robot control. To address these limitations, we\npropose a Classifier-Free Shortcut Diffusion Policy (CF-SDP) that integrates\nclassifier-free guidance with shortcut-based acceleration, enabling efficient\ntask-specific action generation while significantly improving inference speed.\nFurthermore, we extend diffusion modeling to the SO(3) manifold in shortcut\nmodel, defining the forward and reverse processes in its tangent space with an\nisotropic Gaussian distribution. This ensures stable and accurate rotational\nestimation, enhancing the effectiveness of diffusion-based control. Our\napproach achieves nearly 5x acceleration in diffusion inference compared to\nDDIM-based Diffusion Policy while maintaining task performance. Evaluations\nboth on the RoboTwin simulation platform and real-world scenarios across\nvarious tasks demonstrate the superiority of our method.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T06:37:22Z"}
{"aid":"http://arxiv.org/abs/2504.09936v1","title":"KeepKV: Eliminating Output Perturbation in KV Cache Compression for\n  Efficient LLMs Inference","summary":"Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-14T06:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.09942v1","title":"Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting\n  Loewner-State Model for EM Simulation of Multiport Systems","summary":"This paper employs a fully adaptive and semi-adaptive frequency sweep\nalgorithm using the Loewner matrix-based state model for the electromagnetic\nsimulation. The proposed algorithms use two Loewner matrix models with\ndifferent or the same orders with small frequency perturbation for adaptive\nfrequency selection. The error between the two models is calculated in each\niteration, and the next frequency points are selected to minimize maximum\nerror. With the help of memory, the algorithm terminates when the error between\nthe model and the simulation result is reached within the specified error\ntolerance. In the fully adaptive frequency sweep algorithm, the method starts\nwith the minimum and maximum frequency of simulation. In the semi-adaptive\nalgorithm, a novel approach has been proposed to determine the initial number\nof frequency points necessary for system interpolation based on the electrical\nsize of the structure. The proposed algorithms have been compared with the\nStoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for\nelectromagnetic simulation. Four examples are presented using MATLAB R2024b.\nThe results show that the proposed methods offer better performance in terms of\nspeed, accuracy and the requirement of the minimum number of frequency samples.\nThe proposed method shows remarkable consistency with full-wave simulation\ndata, and the algorithm can be effectively applicable to electromagnetic\nsimulations.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,G.1.1","published":"2025-04-14T07:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.09957v1","title":"Programmable time-frequency mode encoded quantum state generator for\n  silicon-on-insulator platform","summary":"We propose a method for the programmable generation of time-frequency mode\n(TFM) encoded quantum states of light on the silicon-on-insulator (SOI)\nplatform. The state generator consists of an N-tap finite impulse response\nfilter and a Mach-Zehnder interferometer (MZI)-based coupled-ring resonator.\nThrough numerical simulations, its capability of producing TFM-encoded\nmaximally entangled states in two, three, and four dimensions is theoretically\ndemonstrated, with fidelities of 0.950, 0.954, and 0.971, respectively.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T07:54:17Z"}
{"aid":"http://arxiv.org/abs/2504.09968v1","title":"Some memos on Stable Symplectic Structured Space","summary":"In these memos, we define a pregeometry $\\mathcal{T}_{\\mathbb{S}} ^{alg}$ and\na geometry $\\mathcal{G}_{\\mathbb{S}} ^{alg}$ which integrate symplectic\nmanifolds with $E_{\\infty}$-ring sheaves, enabling the construction of\n$\\mathcal{G}_{\\mathbb{S}} ^{alg}$-schemes as structured $\\infty$-topoi. Our\nframework and results establish a profound connection between algebraic\ninvariants and homological properties, opening new pathways for exploring\nsymplectic phenomena through the lens of higher category theory and derived\ngeometry.","main_category":"math.AG","categories":"math.AG,math.SG","published":"2025-04-14T08:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.09982v1","title":"The gravitational index of a small black ring","summary":"Certain supersymmetric elementary string states with angular momentum can be\nviewed as small black rings in a five-dimensional string theory. These black\nrings have zero area event horizon. The 4D-5D connection relates these small\nrings to small black holes without angular momentum in one less dimension.\nRecent works have proposed saddle solutions that compute the supersymmetric\nindex for small black holes using gravitational path integral. In this paper,\nwe propose an analogous saddle solution for a five-dimensional small black\nring. The dominant contribution comes from a black ring saddle that rotates in\nboth independent planes in five dimensions and has a finite area event horizon.\nWe also write the saddle solution as a three-center Bena-Warner solution.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T08:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.10008v1","title":"Time for Timed Monitorability","summary":"Monitoring is an important part of the verification toolbox, in particular in\nsituations where exhaustive verification using, e.g., model-checking, is\ninfeasible. The goal of online monitoring is to determine the satisfaction or\nviolation of a specification during runtime, i.e., based on finite execution\nprefixes. However, not every specification is amenable to monitoring, e.g.,\nproperties for which no finite execution can witness satisfaction or violation.\nMonitorability is the question whether a given specification is amenable to\nmonitoring, and has been extensively studied in discrete time.\n  Here, we study, for the first time, the monitorability problem for real-time\nspecifications. For specifications given by deterministic Timed Muller\nAutomata, we prove decidability while we show that the problem is undecidable\nfor specifications given by nondeterministic Timed B\\\"uchi automata.\nFurthermore, we refine monitorability to also determine bounds on the number of\nevents as well as the time that must pass before monitoring the property may\nyield an informative verdict. We prove that for deterministic Timed Muller\nautomata, such bounds can be effectively computed. In contrast we show that for\nnondeterministic Timed B\\\"uchi automata such bounds are not computable.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-14T09:12:58Z"}
{"aid":"http://arxiv.org/abs/2504.10013v1","title":"Training LLMs on HPC Systems: Best Practices from the OpenGPT-X Project","summary":"The training of large language models (LLMs) requires substantial\ncomputational resources, complex software stacks, and carefully designed\nworkflows to achieve scalability and efficiency. This report presents best\npractices and insights gained from the OpenGPT-X project, a German initiative\nfocused on developing open, multilingual LLMs optimized for European languages.\nWe detail the use of high-performance computing (HPC) systems, primarily JUWELS\nBooster at JSC, for training Teuken-7B, a 7-billion-parameter transformer\nmodel. The report covers system architecture, training infrastructure, software\nchoices, profiling and benchmarking tools, as well as engineering and\noperational challenges.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T09:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.10022v1","title":"Parameters estimation of a Threshold Chan-Karolyi-Longstaff-Sanders\n  process from continuous and discrete observations","summary":"We consider a continuous time process that is self-exciting and ergodic,\ncalled threshold Chan-Karolyi-Longstaff-Sanders (CKLS) process. This process is\na generalization of various models in econometrics, such as Vasicek model,\nCox-Ingersoll-Ross, and Black-Scholes, allowing for the presence of several\nthresholds which determine changes in the dynamics. We study the asymptotic\nbehavior of maximum-likelihood and quasi-maximum-likelihood estimators of the\ndrift parameters in the case of continuous time and discrete time observations.\nWe show that for high frequency observations and infinite horizon the\nestimators satisfy the same asymptotic normality property as in the case of\ncontinuous time observations. We also discuss diffusion coefficient estimation.\nFinally, we apply our estimators to simulated and real data to motivate\nconsidering (multiple) thresholds.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-14T09:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.10025v1","title":"Progressive Transfer Learning for Multi-Pass Fundus Image Restoration","summary":"Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-14T09:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.10077v1","title":"Towards Quantifying Commonsense Reasoning with Mechanistic Insights","summary":"Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T10:21:59Z"}
{"aid":"http://arxiv.org/abs/2504.10134v1","title":"Let's Talk About It: Making Scientific Computational Reproducibility\n  Easy","summary":"Computational reproducibility of scientific results, that is, the execution\nof a computational experiment (e.g., a script) using its original settings\n(data, code, etc.), should always be possible. However, reproducibility has\nbecome a significant challenge, as researchers often face difficulties in\naccurately replicating experiments due to inconsistencies in documentation,\nsetup configurations, and missing data. This lack of reproducibility may\nundermine the credibility of scientific results.\n  To address this issue, we propose a conversational, text-based tool that\nallows researchers to easily reproduce computational experiments (theirs or\nfrom others) and package them in a single file that can be re-executed with\njust a double click on any computer, requiring the installation of a single\nwidely-used software. Researchers interact with the platform in natural\nlanguage, which our tool processes to automatically create a computational\nenvironment able to execute the provided experiment/code.\n  We conducted two studies to evaluate our proposal. In the first study, we\ngathered qualitative data by executing 18 experiments from the literature.\nAlthough in some cases it was not possible to execute the experiment, in most\ninstances, it was necessary to have little or even no interaction for the tool\nto reproduce the results.\n  We also conducted a user study comparing our tool with an enterprise-level\none. During this study, we measured the usability of both tools using the\nSystem Usability Scale (SUS) and participants' workload using the NASA Task\nLoad Index (TLX). The results show a statistically significant difference\nbetween both tools in favor of our proposal, demonstrating that the usability\nand workload of our tool are superior to the current state of the art.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.10167v1","title":"C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination\n  Evaluation","summary":"Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.10180v1","title":"ChartOptimiser: Task-driven Optimisation of Chart Designs","summary":"Effective chart design is essential for satisfying viewers' information\nneeds, such as retrieving values from a chart or comparing two values. However,\ncreating effective charts is challenging and time-consuming due to the large\ndesign space and the inter-dependencies between individual design parameters.\nTo address this challenge, we propose ChartOptimiser -- a Bayesian approach for\ntask-driven optimisation of charts, such as bar charts. At the core of\nChartOptimiser is a novel objective function to automatically optimise an\neight-dimensional design space combining four perceptual metrics: visual\nsaliency, text legibility, colour preference, and white space ratio. Through\nempirical evaluation on 12 bar charts and four common analytical tasks --\nfinding the extreme value, retrieving a value, comparing two values, and\ncomputing a derived value -- we show that ChartOptimiser outperforms existing\ndesign baselines concerning task-solving ease, visual aesthetics, and chart\nclarity. We also discuss two practical applications of ChartOptimiser:\ngenerating charts for accessibility and content localisation. Taken together,\nChartOptimiser opens up an exciting new research direction in automated chart\ndesign where charts are optimised for users' information needs, preferences,\nand contexts.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.10181v1","title":"A New Paradigm in IBR Modeling for Power Flow and Short Circuit Analysis","summary":"The fault characteristics of inverter-based resources (IBRs) are different\nfrom conventional synchronous generators. The fault response of IBRs is\nnon-linear due to saturation states and mainly determined by fault ride through\n(FRT) strategies of the associated voltage source converter (VSC). This results\nin prohibitively large solution times for power flows considering these short\ncircuit characteristics, especially when the power system states change fast\ndue to uncertainty in IBR generations. To overcome this, a phasor-domain steady\nstate (SS) short circuit (SC) solver for IBR dominated power systems is\nproposed in this paper, and subsequently the developed IBR models are\nincorporated with a novel Jacobian-based Power Flow (PF) solver. In this\nmultiphase PF solver, any power system components can be modeled by considering\ntheir original non-linear or linear mathematical representations. Moreover, two\nnovel FRT strategies are proposed to fully utilize the converter capacity and\nto comply with IEEE-2800 2022 std and German grid code. The results are\ncompared with the Electromagnetic Transient (EMT) simulation on the IEEE 34\ntest network and the 120 kV EPRI benchmark system. The developed IBR sequence\ndomain PF model demonstrates more accurate behavior compared to the classical\nIBR generator model. The error in calculating the short circuit current with\nthe proposed SC solver is less than 3%, while achieving significant speed\nimprovements of three order of magnitudes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T12:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.10194v1","title":"Black Hole Singularities from Holographic Complexity","summary":"Using a second law of complexity, we prove a black hole singularity theorem.\nBy introducing the notion of trapped extremal surfaces, we show that their\nexistence implies null geodesic incompleteness inside globally hyperbolic black\nholes. We also demonstrate that the vanishing of the growth rate of the volume\nof extremal surfaces provides a sharp diagnostic of the black hole singularity.\nIn static, uncharged, spherically symmetric spacetimes, this corresponds to the\ngrowth rate of spacelike extremal surfaces going to zero at the singularity. In\ncharged or rotating spacetimes, such as the Reissner-Nordstr\\\"om and Kerr black\nholes, we identify novel timelike extremal surfaces that exhibit the same\nbehavior at the timelike singularity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T12:56:04Z"}
{"aid":"http://arxiv.org/abs/2504.10208v1","title":"From Prompting to Alignment: A Generative Framework for Query\n  Recommendation","summary":"In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-14T13:21:29Z"}
{"aid":"http://arxiv.org/abs/2504.10215v1","title":"Public Health Insurance of Children and Maternal Labor Market Outcomes","summary":"This paper exploits variation resulting from a series of federal and state\nMedicaid expansions between 1977 and 2017 to estimate the effects of children's\nincreased access to public health insurance on the labor market outcomes of\ntheir mothers. The results imply that the extended Medicaid eligibility of\nchildren leads to positive labor supply responses at the extensive and\nintensive margins of single mothers and to negative labor supply responses at\nthe extensive margin of married mothers. The analysis of mechanisms suggests\nthat extended children's Medicaid eligibility positively affects take-up of\nMedicaid and health of children.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T13:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.10219v1","title":"Inverse design of multiresonance filters via quasi-normal mode theory","summary":"We present a practical methodology for inverse design of compact\nhigh-order/multiresonance filters in linear passive 2-port wave-scattering\nsystems, targeting any desired transmission spectrum (such as standard\npass/stop-band filters). Our formulation allows for both large-scale topology\noptimization and few-variable parametrized-geometry optimization. It is an\nextension of a quasi-normal mode theory and analytical filter-design criteria\n(on the system resonances and background response) derived in our previous\nwork. Our new optimization-oriented formulation relies solely on a scattering\nsolver and imposes these design criteria as equality constraints with easily\ncalculated (via the adjoint method) derivatives, so that our algorithm is\nnumerically tractable, robust, and well-suited for large-scale inverse design.\nWe demonstrate its effectiveness by designing 3rd- and 4th-order elliptic and\nChebyshev filters for photonic metasurfaces, multilayer films, and electrical\nLC-ladder circuits.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.optics","published":"2025-04-14T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.10251v1","title":"Global stability of the Lengyel-Epstein systems","summary":"We study the global (asymptotic) stability of the Lengyel-Epstein\ndifferential systems, sometimes called Belousov-Zhabotinsky differential\nsystems. Such systems are topologically equivalent to a two-parameter family of\ncubic systems in the plane. We show that for each pair of admissible parameters\nthe unique equilibrium point of the corresponding system is not globally\n(asymptotically) stable. On the other hand, we provide explicit conditions for\nthis unique equilibrium point to be asymptotically stable and we study its\nbasin of attraction. We also study the generic and degenerate Hopf bifurcations\nand highlight a subset of the set of admissible parameters for which the phase\nportraits of the systems have two limit cycles.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10269v1","title":"Multiple solutions to asymptotically linear problems driven by\n  superposition operators","summary":"In this paper, we investigate the existence and multiplicity of weak\nsolutions to problems involving a superposition operator of the type\n$$\\int_{[0, 1]}(- \\Delta)^s u d \\mu(s),$$ for a signed measure $\\mu$ on the\ninterval of fractional exponents $[0,1]$, when the nonlinearity is subcritical\nand asymptotically linear at infinity; thus, we deal with a perturbation of the\neigenvalue problem for the superposition operator. We use variational tools,\nextending to this setting well-known results for the classical and the\nfractional Laplace operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.10299v1","title":"IRR-Based AS Type of Relationship Inference","summary":"The Internet comprises tens of thousands of autonomous systems (ASes) whose\ncommercial relationships are not publicly announced. The classification of the\nType of Relationship (ToR) between ASes has been extensively studied over the\npast two decades due to its relevance in network routing management and\nsecurity.\n  This paper presents a new approach to ToR classification, leveraging publicly\navailable BGP data from the Internet Routing Registry (IRR). We show how the\nIRR can be mined and the results refined to achieve a large and accurate ToR\ndatabase. Using a ground truth database with hundreds of entries we show that\nwe indeed manage to obtain high accuracy. About two-thirds of our ToRs are new,\nnamely, they were not obtained by previous works, which means that we enrich\nour ToR knowledge with links that are otherwise missed.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T15:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.10321v1","title":"Indecomposable bundles on Cartesian products of odd projective spaces","summary":"In this paper we construct indecomposable vector bundles associated to monads\non Cartesian products of odd dimension projective spaces. Specifically we\nestablish the existence of monads on\n$(\\mathbb{P}^1)^{l_1}\\times\\cdots\\times(\\mathbb{P}^{2n+1})^{l_m}$. We prove\nstability of the kernel bundle and prove that the cohomology bundle is simple.\nWe also prove the same for monads on\n$(\\mathbb{P}^n)^2\\times(\\mathbb{P}^m)^2\\times(\\mathbb{P}^l)^2$ for an ample\nline bundle\n$\\mathscr{L}=\\mathcal{O}_X(\\alpha,\\alpha,\\beta,\\beta,\\gamma,\\gamma)$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.10345v1","title":"AraOS: Analyzing the Impact of Virtual Memory Management on Vector Unit\n  Performance","summary":"Vector processor architectures offer an efficient solution for accelerating\ndata-parallel workloads (e.g., ML, AI), reducing instruction count, and\nenhancing processing efficiency. This is evidenced by the increasing adoption\nof vector ISAs, such as Arm's SVE/SVE2 and RISC-V's RVV, not only in\nhigh-performance computers but also in embedded systems. The open-source nature\nof RVV has particularly encouraged the development of numerous vector processor\ndesigns across industry and academia. However, despite the growing number of\nopen-source RVV processors, there is a lack of published data on their\nperformance in a complex application environment hosted by a full-fledged\noperating system (Linux). In this work, we add OS support to the open-source\nbare-metal Ara2 vector processor (AraOS) by sharing the MMU of CVA6, the scalar\ncore used for instruction dispatch to Ara2, and integrate AraOS into the\nopen-source Cheshire SoC platform. We evaluate the performance overhead of\nvirtual-to-physical address translation by benchmarking matrix multiplication\nkernels across several problem sizes and translation lookaside buffer (TLB)\nconfigurations in CVA6's shared MMU, providing insights into vector performance\nin a full-system environment with virtual memory. With at least 16 TLB entries,\nthe virtual memory overhead remains below 3.5%. Finally, we benchmark a 2-lane\nAraOS instance with the open-source RiVEC benchmark suite for RVV\narchitectures, with peak average speedups of 3.2x against scalar-only\nexecution.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T15:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.10384v1","title":"A 10.8mW Mixed-Signal Simulated Bifurcation Ising Solver using SRAM\n  Compute-In-Memory with 0.6us Time-to-Solution","summary":"Combinatorial optimization problems are funda- mental for various fields\nranging from finance to wireless net- works. This work presents a simulated\nbifurcation (SB) Ising solver in CMOS for NP-hard optimization problems. Analog\ndomain computing led to a superior implementation of this algorithm as inherent\nand injected noise is required in SB Ising solvers. The architecture novelties\ninclude the use of SRAM compute-in-memory (CIM) to accelerate bifurcation as\nwell as the generation and injection of optimal decaying noise in the analog\ndomain. We propose a novel 10-T SRAM cell capable of performing ternary\nmultiplication. When measured with 60- node, 50% density, random, binary MAXCUT\ngraphs, this all- to-all connected Ising solver reliably achieves above 93% of\nthe ground state solution in 0.6us with 10.8mW average power in TSMC 180nm\nCMOS. Our chip achieves an order of magnitude improvement in time-to-solution\nand power compared to previously proposed Ising solvers in CMOS and other\nplatforms.","main_category":"eess.SY","categories":"eess.SY,cs.CL,cs.SY","published":"2025-04-14T16:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.10416v1","title":"Region Based SLAM-Aware Exploration: Efficient and Robust Autonomous\n  Mapping Strategy That Can Scale","summary":"Autonomous exploration for mapping unknown large scale environments is a\nfundamental challenge in robotics, with efficiency in time, stability against\nmap corruption and computational resources being crucial. This paper presents a\nnovel approach to indoor exploration that addresses these key issues in\nexisting methods. We introduce a Simultaneous Localization and Mapping\n(SLAM)-aware region-based exploration strategy that partitions the environment\ninto discrete regions, allowing the robot to incrementally explore and\nstabilize each region before moving to the next one. This approach\nsignificantly reduces redundant exploration and improves overall efficiency. As\nthe device finishes exploring a region and stabilizes it, we also perform SLAM\nkeyframe marginalization, a technique which reduces problem complexity by\neliminating variables, while preserving their essential information. To\nimproves robustness and further enhance efficiency, we develop a check- point\nsystem that enables the robot to resume exploration from the last stable region\nin case of failures, eliminating the need for complete re-exploration. Our\nmethod, tested in real homes, office and simulations, outperforms\nstate-of-the-art approaches. The improvements demonstrate substantial\nenhancements in various real world environments, with significant reductions in\nkeyframe usage (85%), submap usage (50% office, 32% home), pose graph\noptimization time (78-80%), and exploration duration (10-15%). This\nregion-based strategy with keyframe marginalization offers an efficient\nsolution for autonomous robotic mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.10417v1","title":"Silent Self-Stabilizing Ranking: Time Optimal and Space Efficient","summary":"We present a silent, self-stabilizing ranking protocol for the population\nprotocol model of distributed computing, where agents interact in randomly\nchosen pairs to solve a common task. We are given $n$ anonymous agents, and the\ngoal is to assign each agent a unique rank in $\\{1, \\dots, n\\}$. Given unique\nranks, it is straightforward to select a designated leader. Thus, our protocol\nis a self-stabilizing leader election protocol as well. Ranking requires at\nleast $n$ states per agent; hence, the goal is to minimize the additional\nnumber of states, called overhead states. The core of our protocol is a\nspace-efficient but non-self-stabilizing ranking protocol that requires only $n\n+ O(\\log n)$ states. Our protocol stabilizes in $O(n^2\\log n)$ interactions\nw.h.p.\\ and in expectation, using $n + O(\\log^2 n)$ states in total. Our\nstabilization time is asymptotically optimal (see Burman et al., PODC'21). In\ncomparison to the currently best known ranking protocol by Burman et al., which\nrequires $n + \\Omega(n)$ states, our result exponentially improves the number\nof overhead states.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T17:04:19Z"}
{"aid":"http://arxiv.org/abs/2504.10427v1","title":"On roots of normal operators and extensions of Ando's Theorem","summary":"In this paper, we extend Ando's theorem on paranormal operators, which states\nthat if $ T \\in \\mathfrak{B}(\\mathcal{H}) $ is a paranormal operator and there\nexists $ n \\in \\mathbb{N} $ such that $ T^n $ is normal, then $ T $ is normal.\nWe generalize this result to the broader classes of $ k $-paranormal operators\nand absolute-$ k $-paranormal operators. Furthermore, in the case of a\nseparable Hilbert space $\\mathcal{H}$, we show that if $ T \\in\n\\mathfrak{B}(\\mathcal{H}) $ is a $ k $-quasi-paranormal operator for some $ k\n\\in \\mathbb{N} $, and there exists $ n \\in \\mathbb{N} $ such that $ T^n $ is\nnormal, then $ T $ decomposes as $ T = T' \\oplus T'' $, where $ T' $ is normal\nand $ T'' $ is nilpotent of nil-index at most $ \\min\\{n,k+1\\} $, with either\nsummand potentially absent.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T17:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.10430v1","title":"LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety\n  in Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.HC","published":"2025-04-14T17:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.10434v1","title":"Anchor Token Matching: Implicit Structure Locking for Training-free AR\n  Image Editing","summary":"Text-to-image generation has seen groundbreaking advancements with diffusion\nmodels, enabling high-fidelity synthesis and precise image editing through\ncross-attention manipulation. Recently, autoregressive (AR) models have\nre-emerged as powerful alternatives, leveraging next-token generation to match\ndiffusion models. However, existing editing techniques designed for diffusion\nmodels fail to translate directly to AR models due to fundamental differences\nin structural control. Specifically, AR models suffer from spatial poverty of\nattention maps and sequential accumulation of structural errors during image\nediting, which disrupt object layouts and global consistency. In this work, we\nintroduce Implicit Structure Locking (ISLock), the first training-free editing\nstrategy for AR visual models. Rather than relying on explicit attention\nmanipulation or fine-tuning, ISLock preserves structural blueprints by\ndynamically aligning self-attention patterns with reference images through the\nAnchor Token Matching (ATM) protocol. By implicitly enforcing structural\nconsistency in latent space, our method ISLock enables structure-aware editing\nwhile maintaining generative autonomy. Extensive experiments demonstrate that\nISLock achieves high-quality, structure-consistent edits without additional\ntraining and is superior or comparable to conventional editing techniques. Our\nfindings pioneer the way for efficient and flexible AR-based image editing,\nfurther bridging the performance gap between diffusion and autoregressive\ngenerative models. The code will be publicly available at\nhttps://github.com/hutaiHang/ATM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.10440v1","title":"HybridCollab: Unifying In-Person and Remote Collaboration for\n  Cardiovascular Surgical Planning in Mobile Augmented Reality","summary":"Surgical planning for congenital heart disease traditionally relies on\ncollaborative group examinations of a patient's 3D-printed heart model, a\nprocess that lacks flexibility and accessibility. While mobile augmented\nreality (AR) offers a promising alternative with its portability and familiar\ninteraction gestures, existing solutions limit collaboration to users in the\nsame physical space. We developed HybridCollab, the first iOS AR application\nthat introduces a novel paradigm that enables both in-person and remote medical\nteams to interact with a shared AR heart model in a single surgical planning\nsession. For example, a team of two doctors in one hospital room can\ncollaborate in real time with another team in a different hospital.Our approach\nis the first to leverage Apple's GameKit service for surgical planning,\nensuring an identical collaborative experience for all participants, regardless\nof location. Additionally, co-located users can interact with the same anchored\nheart model in their shared physical space. By bridging the gap between remote\nand in-person collaboration across medical teams, HybridCollab has the\npotential for significant real-world impact, streamlining communication and\nenhancing the effectiveness of surgical planning. Watch the demo:\nhttps://youtu.be/hElqJYDuvLM.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T17:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10446v1","title":"Evolution equations on co-evolving graphs: long-time behaviour and the\n  graph continuity equation","summary":"We focus on evolution equations on co-evolving, infinite, graphs and\nestablish a rigorous link with a class of nonlinear continuity equations, whose\nvector fields depend on the graphs considered. More precisely, weak solutions\nof the so-called graph-continuity equation are shown to be the push-forward of\ntheir initial datum through the flow map solving the associated\ncharacteristics' equation, which depends on the co-evolving graph considered.\nThis connection can be used to prove contractions in a suitable distance,\nalthough the flow on the graphs requires a too limiting assumption on the\noverall flux. Therefore, we consider upwinding dynamics on graphs with\npointwise and monotonic velocity and prove long-time convergence of the\nsolutions towards the uniform mass distribution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T17:36:55Z"}
{"aid":"http://arxiv.org/abs/2504.10448v1","title":"A High-Precision, Fast, Robust, and Cost-Effective Muon Detector Concept\n  for the FCC-ee","summary":"We propose a high-precision, fast, robust and cost-effective muon detector\nconcept for an FCC-ee experiment. This design combines precision drift tubes\nwith fast plastic scintillator strips to enable both spatial and timing\nmeasurements. The drift tubes deliver two-dimensional position measurements\nperpendicular to the tubes with a resolution around 100~$\\mu$m. Meanwhile, the\nscintillator strips, read out with the wavelength-shifting fibers and silicon\nphotomultipliers, provide fast timing information with a precision of 200~ps or\nbetter and measure the third coordinate along the tubes with a resolution of\nabout 1~mm.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-14T17:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.10459v1","title":"The Price of Competitive Information Disclosure","summary":"In many decision-making scenarios, individuals strategically choose what\ninformation to disclose to optimize their own outcomes. It is unclear whether\nsuch strategic information disclosure can lead to good societal outcomes. To\naddress this question, we consider a competitive Bayesian persuasion model in\nwhich multiple agents selectively disclose information about their qualities to\na principal, who aims to choose the candidates with the highest qualities.\nUsing the price-of-anarchy framework, we quantify the inefficiency of such\nstrategic disclosure. We show that the price of anarchy is at most a constant\nwhen the agents have independent quality distributions, even if their utility\nfunctions are heterogeneous. This result provides the first theoretical\nguarantee on the limits of inefficiency in Bayesian persuasion with competitive\ninformation disclosure.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-14T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.10464v1","title":"Implications of distance duality violation for the $H_0$ tension and\n  evolving dark energy","summary":"We investigate whether a violation of the distance duality relation (DDR),\n$D_L(z) = (1+z)^2 D_A(z)$, connecting the angular diameter and luminosity\ndistances, can explain the Hubble tension and alter the evidence for dynamical\ndark energy in recent cosmological observations. We constrain five\nphenomenological parameterisations of DDR violation using Baryon Acoustic\nOscillation measurements from the DESI survey calibrated with the sound horizon\nderived from \\textit{Planck} Cosmic Microwave Background data and the Pantheon+\nType Ia supernova (SNIa) catalogue calibrated with the supernova absolute\nmagnitude from S$H_0$ES. We find that two toy models can resolve the tension: a\nconstant offset in the DDR (equivalent to a shift in the calibration of the\nSNIa data), $D_L(z)/D_A(z)\\simeq 0.925(1+z)^2$, which leaves the hint for\nevolving dark energy unaffected; or a change in the power-law\nredshift-dependence of the DDR, restricted to $z\\lesssim 1$,\n$D_L(z)/D_A(z)\\simeq(1+z)^{1.866}$, together with a {\\it constant} phantom dark\nenergy equation of state $w\\sim -1.155$. The Bayesian evidence slightly favours\nthe latter model. Our phenomenological approach motivates the investigation of\nphysical models of DDR violation as a novel way to explain the Hubble tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-14T17:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.10467v1","title":"De-excitation of $K$-shell hollow atoms with $12 \\le Z \\le 20$:\n  transition rates and branching ratios","summary":"Investigating $K$-shell hollow atom spectra enhances our understanding of\nfemtosecond phenomena in atomic physics, chemistry, and biology. Synchrotron\nmeasurements of two-electron one-photon (TEOP) transitions in low-$Z$ atoms\nhave revealed discrepancies between experimental results and theoretical\npredictions of TEOP relative intensities. These discrepancies appear to\noriginate from an incomplete description of an atom's response to the strong\nperturbation caused by $K$-shell double photoionization (DPI). The\nmulticonfiguration Dirac-Hartree-Fock relativistic configuration interaction\nmethod has been applied for studying the TEOP spectra of Mg, Al, Si, S, Ar, and\nCa atoms. The results show that branching ratios can be accurately reproduced\nby accounting for the effects of core and valence electron correlations, as\nwell as the outer-shell ionization and excitation processes following $K$-shell\nDPI.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-14T17:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10470v1","title":"Online Advanced Labs in Physics","summary":"At Arizona State University we have built the first and only fully online\nBachelor of Science degree in Physics, with a complete curriculum, including\nlabs. The upper division Advanced Lab courses present a special challenge for\nonline delivery. We address that using a set of custom-built simulator modules\nthat replicate all the imperfections (noise, background, etc) inherent in\nreal-world data. The set of experiments duplicates those of the in-person\nclasses. In this paper, we present an overview of these labs and discuss the\nadvantages and challenges of delivering them online. We assert that these labs\nprovide a valid and rigorous component for the fully online degree. The entire\nset of labs is available as Open Source Supplemental Materials and is shared\nfor others to use in part or in whole, with suitable attribution.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-14T17:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10483v1","title":"REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion\n  Transformers","summary":"In this paper we tackle a fundamental question: \"Can we train latent\ndiffusion models together with the variational auto-encoder (VAE) tokenizer in\nan end-to-end manner?\" Traditional deep-learning wisdom dictates that\nend-to-end training is often preferable when possible. However, for latent\ndiffusion transformers, it is observed that end-to-end training both VAE and\ndiffusion-model using standard diffusion-loss is ineffective, even causing a\ndegradation in final performance. We show that while diffusion loss is\nineffective, end-to-end training can be unlocked through the\nrepresentation-alignment (REPA) loss -- allowing both VAE and diffusion model\nto be jointly tuned during the training process. Despite its simplicity, the\nproposed training recipe (REPA-E) shows remarkable performance; speeding up\ndiffusion model training by over 17x and 45x over REPA and vanilla training\nrecipes, respectively. Interestingly, we observe that end-to-end tuning with\nREPA-E also improves the VAE itself; leading to improved latent space structure\nand downstream generation performance. In terms of final performance, our\napproach sets a new state-of-the-art; achieving FID of 1.26 and 1.83 with and\nwithout classifier-free guidance on ImageNet 256 x 256. Code is available at\nhttps://end2end-diffusion.github.io.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.10831v1","title":"Hallucination-Aware Generative Pretrained Transformer for Cooperative\n  Aerial Mobility Control","summary":"This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-15T03:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.10832v1","title":"Unlimited Vector Processing for Wireless Baseband Based on RISC-V\n  Extension","summary":"Wireless baseband processing (WBP) serves as an ideal scenario for utilizing\nvector processing, which excels in managing data-parallel operations due to its\nparallel structure. However, conventional vector architectures face certain\nconstraints such as limited vector register sizes, reliance on power-of-two\nvector length multipliers, and vector permutation capabilities tied to specific\narchitectures. To address these challenges, we have introduced an instruction\nset extension (ISE) based on RISC-V known as unlimited vector processing (UVP).\nThis extension enhances both the flexibility and efficiency of vector\ncomputations. UVP employs a novel programming model that supports\nnon-power-of-two register groupings and hardware strip-mining, thus enabling\nsmooth handling of vectors of varying lengths while reducing the software\nstrip-mining burden. Vector instructions are categorized into symmetric and\nasymmetric classes, complemented by specialized load/store strategies to\noptimize execution. Moreover, we present a hardware implementation of UVP\nfeaturing sophisticated hazard detection mechanisms, optimized pipelines for\nsymmetric tasks such as fixed-point multiplication and division, and a robust\npermutation engine for effective asymmetric operations. Comprehensive\nevaluations demonstrate that UVP significantly enhances performance, achieving\nup to 3.0$\\times$ and 2.1$\\times$ speedups in matrix multiplication and fast\nFourier transform (FFT) tasks, respectively, when measured against lane-based\nvector architectures. Our synthesized RTL for a 16-lane configuration using\nSMIC 40nm technology spans 0.94 mm$^2$ and achieves an area efficiency of 21.2\nGOPS/mm$^2$.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-15T03:23:02Z"}
{"aid":"http://arxiv.org/abs/2504.10860v1","title":"Bell-Mermin-Klyshko Inequalities and One-way Information Deficit of\n  Dirac Fields in Noninertial Frames","summary":"We investigate the Bell-Mermin-Klyshko inequalities and the one-way\ninformation deficit of Dirac fields in noninertial frames, where the quantum\ncorrelations are shared between inertial and accelerated observers due to the\nUnruh effect. We derive partial analytical results for specific quantum states\nusing the one-way information deficit. Additionally, we present numerical\nresults for the Bell-Mermin-Klyshko inequalities. The study reveals the\npresence of Bell nonlocality and the significance of the one-way information\ndeficit in relativistic quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T04:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.10864v1","title":"Automata for the commutative closure of regular sets","summary":"Consider $ A^* $, the free monoid generated by the finite alphabet $A$ with\nthe concatenation operation. Two words have the same commutative image when one\nis a permutation of the symbols of the other. The commutative closure of a set\n$ L \\subseteq A^* $ is the set $ {C}(L) \\subseteq A^* $ of words whose\ncommutative image coincides with that of some word in $ L $. We provide an\nalgorithm that, given a regular set $ L $, produces a finite state automaton\nthat accepts the commutative closure $ {C}(L) $, provided that this closure set\nis regular. The problem of deciding whether $ {C}(L) $ is regular was solved by\nGinsburg and Spanier in 1966 using the decidability of Presburger sentences,\nand by Gohon in 1985 via formal power series. The problem of constructing an\nautomaton that accepts $ {C}(L) $ has already been studied in the literature.\nWe give a simpler algorithm using an algebraic approach.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-15T04:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.10882v1","title":"A Quantum Advantage in Localizing Transmission Loss Change in Optical\n  Networks","summary":"The ability to localize transmission loss change to a subset of links in\noptical networks is crucial for maintaining network reliability, performance\nand security. \\emph{Quantum probes}, implemented by sending blocks of $n$\ncoherent-state pulses augmented with continuous-variable (CV) squeezing ($n=1$)\nor weak temporal-mode entanglement ($n>1$) over a lossy channel to a receiver\nwith homodyne detection capabilities, are known to be more sensitive than their\nquasi-classical counterparts in detecting a sudden increase in channel loss.\nThe enhanced sensitivity can be characterized by the increased Kullback-Leibler\n(KL) divergence of the homodyne output, before and after the loss change\noccurs. When combined with the theory of quickest change detection (QCD), the\nincrease in KL divergence translates into a decrease in detection latency.\n  In this work, we first revisit quantum probes over a channel, generalizing\nprevious results on $n=1$ (CV squeezed states) to arbitrary values of $n$.\nAssuming a subset of nodes in an optical network is capable of sending and\nreceiving such probes through intermediate nodes with all-optical switching\ncapabilities, we present a scheme for quickly detecting the links that have\nsuffered a sudden drop in transmissivity. Since quantum probes lose their\nsensitivity with increasing loss in the channel, we first propose a probe\nconstruction algorithm that makes the set of links suffering transmission loss\nchange identifiable, while minimizing the longest distance a probe traverses.\nWe then introduce new cumulative sum (CUSUM) statistics with a stopping rule,\nwhich allows us to run the CUSUM algorithm to quickly localize the lossy links\nusing our constructed probes. Finally, we show that the proposed scheme\nachieves a quantum advantage in decreasing the detection delay.","main_category":"quant-ph","categories":"quant-ph,cs.NI","published":"2025-04-15T05:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.10883v1","title":"Bringing together invertible UNets with invertible attention modules for\n  memory-efficient diffusion models","summary":"Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.10901v1","title":"Design and Verification of a Synchronus First In First Out (FIFO)","summary":"This project focuses on designing and verifying a synchronous FIFO First In\nFirst Out (FIFO) memory, a critical component in digital systems for temporary\ndata storage and seamless data transfer. The FIFO operates under a single clock\ndomain, ensuring synchronized read and write operations, making it suitable for\nsystems requiring high-speed, reliable data buffering. This design includes\nFIFO's key features, such as read and write operations, full and empty flag\ngeneration, and pointer management for memory control. The FIFO was implemented\nusing Verilog to define the Register Transfer Level (RTL) design, ensuring\nfunctionality and timing requirements were met. For verification, three\napproaches were employed: (1) UVM-based Verification: A Universal Verification\nMethodology (UVM) testbench was developed to test the FIFO design rigorously.\nThe testbench includes components like interface, sequence item, driver,\nmonitor, scoreboard, agent, and environment. Directed and random tests were\nperformed to verify corner cases, such as simultaneous reads and writes, full\nand empty conditions, and overflow and underflow scenarios; (2) Traditional\nVerilog Testbench: A standalone Verilog testbench was also used to validate the\nfunctionality of the FIFO through directed test scenarios and waveform\nanalysis; (3) FPGA implementation: Additionally, the design was implemented on\nan FPGA for real-time testing to verify its functionality and timing behavior\nin hardware. FPGA-based verification ensured the design performed as expected\nunder practical conditions. The results confirmed the correct operation of the\nFIFO, including accurate data transfer, flag behavior, and timing\nsynchronization. The project successfully demonstrated the robustness and\nreliability of the synchronous FIFO design, highlighting its importance in\nmodern digital systems for efficient data handling and buffering.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-15T06:23:09Z"}
{"aid":"http://arxiv.org/abs/2504.10906v1","title":"Understanding LLMs' Cross-Lingual Context Retrieval: How Good It Is And\n  Where It Comes From","summary":"The ability of cross-lingual context retrieval is a fundamental aspect of\ncross-lingual alignment of large language models (LLMs), where the model\nextracts context information in one language based on requests in another\nlanguage. Despite its importance in real-life applications, this ability has\nnot been adequately investigated for state-of-the-art models. In this paper, we\nevaluate the cross-lingual context retrieval ability of over 40 LLMs across 12\nlanguages to understand the source of this ability, using cross-lingual machine\nreading comprehension (xMRC) as a representative scenario. Our results show\nthat several small, post-trained open LLMs show strong cross-lingual context\nretrieval ability, comparable to closed-source LLMs such as GPT-4o, and their\nestimated oracle performances greatly improve after post-training. Our\ninterpretability analysis shows that the cross-lingual context retrieval\nprocess can be divided into two main phases: question encoding and answer\nretrieval, which are formed in pre-training and post-training, respectively.\nThe phasing stability correlates with xMRC performance, and the xMRC bottleneck\nlies at the last model layers in the second phase, where the effect of\npost-training can be evidently observed. Our results also indicate that\nlarger-scale pretraining cannot improve the xMRC performance. Instead, larger\nLLMs need further multilingual post-training to fully unlock their\ncross-lingual context retrieval potential. Our code and is available at\nhttps://github.com/NJUNLP/Cross-Lingual-Context-Retrieval","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T06:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.10910v1","title":"Full Cooperation in Repeated Multi-Player Games on Hypergraphs","summary":"Nearly all living systems, especially humans, depend on collective\ncooperation for survival and prosperity. However, the mechanisms driving the\nevolution of cooperative behavior remain poorly understood, particularly in the\ncontext of simultaneous interactions involving multiple individuals, repeated\nencounters, and complex interaction structures. Here, we introduce a novel\nframework for studying repeated multi-player interactions in structured\npopulations -- repeated multi-player games on hypergraphs -- where multiple\nindividuals within each hyperedge engage in a repeated game, and each player\ncan simultaneously participate in many games. We focus on public goods games,\nwhere individuals differ in their initial endowments, their allocation of\nendowments across games, and their productivity, which determines the impact of\ntheir contributions. Through Nash equilibrium analysis, we reveal the intricate\ninterplay between full cooperation (all individuals contribute their entire\nendowments, maximizing collective benefits) and key factors such as initial\nendowments, productivity, contribution strategies, and interaction structure.\nNotably, while equal endowments are most effective in promoting full\ncooperation in homogeneous hypergraphs, they can hinder cooperation in\nheterogeneous hypergraphs, suggesting that equal endowments are not universally\noptimal. To address this, we propose two optimization strategies: one for\npolicymakers to adjust endowment distributions and another for players to\nmodify their contribution strategies. Both approaches successfully promote full\ncooperation across all studied hypergraphs. Our findings provide novel insights\ninto the emergence of full cooperation, offering valuable guidance for both\nplayers and policymakers in fostering collective cooperation.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T06:45:15Z"}
{"aid":"http://arxiv.org/abs/2504.10914v1","title":"Breaking the Trend: How to Avoid Cherry-Picked Signals","summary":"Our empirical results, illustrated in Fig.5, show an impressive fit with the\npretty complex theoritical Sharpe formula of a Trend following strategy\ndepending on the parameter of the signal, which was derived by Grebenkov and\nSerror (2014). That empirical fit convinces us that a mean-reversion process\nwith only one time scale is enough to model, in a pretty precise way, the\nreality of the trend-following mechanism at the average scale of CTAs and as a\nconsequence, using only one simple EMA, appears optimal to capture the trend.\nAs a consequence, using a complex basket of different complex indicators as\nsignal, do not seem to be so rational or optimal and exposes to the risk of\ncherry-picking.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-15T06:51:27Z"}
{"aid":"http://arxiv.org/abs/2504.10925v1","title":"Transfer Learning for Temporal Link Prediction","summary":"Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T07:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.10944v1","title":"Cartesian Merkle Tree","summary":"This paper introduces the Cartesian Merkle Tree, a deterministic data\nstructure that combines the properties of a Binary Search Tree, a Heap, and a\nMerkle tree. The Cartesian Merkle Tree supports insertions, updates, and\nremovals of elements in $O(\\log n)$ time, requires $n$ space, and enables\nmembership and non-membership proofs via Merkle-based authentication paths.\nThis structure is particularly suitable for zero-knowledge applications,\nblockchain systems, and other protocols that require efficient and verifiable\ndata structures.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T07:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.10945v1","title":"Tighter Bounds on Non-clairvoyant Parallel Machine Scheduling with\n  Prediction to Minimize Makespan","summary":"This paper investigates the non-clairvoyant parallel machine scheduling\nproblem with prediction, with the objective of minimizing the makespan.\nImproved lower bounds for the problem and competitive ratios of online\nalgorithms with respect to the prediction error are presented for both the\nnon-preemptive and preemptive cases on m identical machines.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T07:48:14Z"}
{"aid":"http://arxiv.org/abs/2504.10951v1","title":"Convergence rate for a semidiscrete approximation of scalar conservation\n  laws","summary":"We propose a semidiscrete scheme for approximation of entropy solutions of\none-dimensional scalar conservation laws with nonnegative initial data. The\nscheme is based on the concept of particle paths for conservation laws and can\nbe interpreted as a finite-particle discretization. A convergence rate of order\n$1/2$ with respect to initial particle spacing is proved. As a special case,\nthis covers the convergence of the Follow--the--Leader model to the\nLighthill--Whitham--Richards model for traffic flow.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA","published":"2025-04-15T07:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.10966v1","title":"Non-uniqueness of mild solutions for 2d-heat equations with singular\n  initial data","summary":"In a recent article by the authors [15] it was shown that wide classes of\nsemilinear elliptic equations with exponential type nonlinearities admit\nsingular radial solutions $U$ on the punctured disc in $\\mathbb R^2$ which are\nalso distributional solutions on the whole disc. We show here that these\nsolutions, taken as initial data of the associated heat equation, give rise to\nnon-uniqueness of mild solutions: ${u_s}(t,x) \\equiv U(x)$ is a stationary\nsolution, and there exists also a solution ${u_r}(t,x)$ departing from $U$\nwhich is bounded for $t > 0$. While such non-uniqueness results have been known\nin higher dimensions by Ni--Sacks [33], Terraneo [40] and Galaktionov--Vazquez\n[16], only two very specific results have recently been obtained in two\ndimensions by Ioku--Ruf--Terraneo [22] and Ibrahim--Kikuchi--Nakanishi--Wei\n[21].","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T08:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.10972v1","title":"AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained\n  Representation in Radiographic Images","summary":"Current self-supervised methods, such as contrastive learning, predominantly\nfocus on global discrimination, neglecting the critical fine-grained anatomical\ndetails required for accurate radiographic analysis. To address this challenge,\nwe propose an Anatomy-driven self-supervised framework for enhancing\nFine-grained Representation in radiographic image analysis (AFiRe). The core\nidea of AFiRe is to align the anatomical consistency with the unique\ntoken-processing characteristics of Vision Transformer. Specifically, AFiRe\nsynergistically performs two self-supervised schemes: (i) Token-wise\nanatomy-guided contrastive learning, which aligns image tokens based on\nstructural and categorical consistency, thereby enhancing fine-grained\nspatial-anatomical discrimination; (ii) Pixel-level anomaly-removal\nrestoration, which particularly focuses on local anomalies, thereby refining\nthe learned discrimination with detailed geometrical information. Additionally,\nwe propose Synthetic Lesion Mask to enhance anatomical diversity while\npreserving intra-consistency, which is typically corrupted by traditional data\naugmentations, such as Cropping and Affine transformations. Experimental\nresults show that AFiRe: (i) provides robust anatomical discrimination,\nachieving more cohesive feature clusters compared to state-of-the-art\ncontrastive learning methods; (ii) demonstrates superior generalization,\nsurpassing 7 radiography-specific self-supervised methods in multi-label\nclassification tasks with limited labeling; and (iii) integrates fine-grained\ninformation, enabling precise anomaly detection using only image-level\nannotations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:29:54Z"}
{"aid":"http://arxiv.org/abs/2504.10976v1","title":"Adaptive Decision Boundary for Few-Shot Class-Incremental Learning","summary":"Few-Shot Class-Incremental Learning (FSCIL) aims to continuously learn new\nclasses from a limited set of training samples without forgetting knowledge of\npreviously learned classes. Conventional FSCIL methods typically build a robust\nfeature extractor during the base training session with abundant training\nsamples and subsequently freeze this extractor, only fine-tuning the classifier\nin subsequent incremental phases. However, current strategies primarily focus\non preventing catastrophic forgetting, considering only the relationship\nbetween novel and base classes, without paying attention to the specific\ndecision spaces of each class. To address this challenge, we propose a\nplug-and-play Adaptive Decision Boundary Strategy (ADBS), which is compatible\nwith most FSCIL methods. Specifically, we assign a specific decision boundary\nto each class and adaptively adjust these boundaries during training to\noptimally refine the decision spaces for the classes in each session.\nFurthermore, to amplify the distinctiveness between classes, we employ a novel\ninter-class constraint loss that optimizes the decision boundaries and\nprototypes for each class. Extensive experiments on three benchmarks, namely\nCIFAR100, miniImageNet, and CUB200, demonstrate that incorporating our ADBS\nmethod with existing FSCIL techniques significantly improves performance,\nachieving overall state-of-the-art results.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:37:24Z"}
{"aid":"http://arxiv.org/abs/2504.11030v1","title":"Sobolev homeomorphisms and composition operators on homogeneous Lie\n  groups","summary":"In this article we study Sobolev homeomorphisms and composition operators on\nhomogeneous Lie groups. We prove, that a measurable homeomorphism $\\varphi:\n\\Omega \\to\\widetilde{\\Omega}$ belongs to the Sobolev space $L^{1}_{q}(\\Omega;\n\\widetilde{\\Omega})$, $1\\leq q < \\infty$, if and only if $\\varphi$ generates a\nbounded composition operator on Sobolev spaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T09:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.11040v1","title":"Infinite topological entropy, positive mean dimension, and factors of\n  subshifts","summary":"We study dynamical systems with the property that all the nontrivial factors\nhave infinite topological entropy (or, positive mean dimension). We establish\nan ``if and only if'' condition for this property among a typical class of\ndynamical systems, the subshifts of block type in the Hilbert cube. This in\nparticular leads to a large class of concrete (and new) examples of dynamical\nsystems having this property.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T10:05:29Z"}
{"aid":"http://arxiv.org/abs/2504.11096v1","title":"A fully variational numerical method for structural topology\n  optimization based on a Cahn-Hilliard model","summary":"We formulate a novel numerical method suitable for the solution of topology\noptimization problems in solid mechanics. The most salient feature of the new\napproach is that the space and time discrete equations of the numerical method\ncan be obtained as the optimality conditions of a single incremental potential.\nThe governing equations define a gradient flow of the mass in the domain that\nmaximizes the stiffness of the proposed solid, while exactly preserving the\nmass of the allocated material. Moreover, we propose a change of variables in\nthe model equations that constrains the value of the density within admissible\nbounds and a continuation strategy that speeds up the evolution of the flow.\nThe proposed strategy results in a robust and efficient topology optimization\nmethod that is exactly mass-preserving, does not employ Lagrange multipliers,\nand is fully variational.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MP","published":"2025-04-15T11:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.11098v1","title":"Electron-transverse acoustic phonon couplings in three-dimensional\n  pentatellurides","summary":"Transverse acoustic (TA) phonon waves are analogous to electromagnetic waves\nand can carry a certain angular momentum. In this paper, we study the\nelectron-TA phonon couplings in three-dimensional pentatellurides and explore\nthe conditions under which the TA phonon condensation is stable. We analyze the\nLindhard response function, phonon softening, mean-field parameters, and\nrenormalized dispersions, on the basis of which the phase diagrams of the\nelectron-phonon couplings in ZrTe$_5$ and HfTe$_5$ are calculated. The phase\ndiagrams show that, if the chemical potential lies near the Weyl nodes, the TA\nphonon condensation will dominate and lead to the shear strain wave phase. We\nfurther reveal that when the wave vector of the particular phonon mode is\nsmaller, the critical coupling strength will be weaker for the phonon\ncondensation, which thus favors the condensation phase.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T11:44:40Z"}
{"aid":"http://arxiv.org/abs/2504.11102v1","title":"Origin of Reactor Antineutrino Anomaly","summary":"The reactor antineutrino anomaly, discovered in 2011, means a noticeable\ndifference between the observed rate of inverse beta decays and the expected\n(theoretical) rate of such processes based on the measurement of the spectra of\nelectrons in beta decay of $^{235}$U, $^{239}$Pu, $^{241}$Pu, and $^{238}$U\nnuclei and their subsequent conversion into right-handed antineutrino spectra.\nThis paper provides a rationale for the fact that both right-handed and\nleft-handed antineutrinos are produced in beta decays of nuclei. But the\nconversion procedure in any case assigns a right-handed antineutrino to each\nelectron, which leads to the superiority of the theoretical rate of inverse\nbeta decays over the experimental one. The right-handed antineutrino is\nproduced in the mode of beta decay of the nucleus due to the standard\nelectroweak interaction. The left-handed antineutrino appears in the mode\ncaused by the existence of a interaction, the carrier of which is a massless\npseudoscalar boson having a Yukawa coupling with the electron neutrino and\nnucleons. The emission of such a boson from a virtual right-handed antineutrino\nconverts it into a free left-handed antineutrino.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-15T11:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.11117v1","title":"Spatial Sign based Direct Sparse Linear Discriminant Analysis for High\n  Dimensional Data","summary":"This paper investigates the robust linear discriminant analysis (LDA) problem\nwith elliptical distributions in high-dimensional data. We propose a robust\nclassification method, named SSLDA, that is intended to withstand heavy-tailed\ndistributions. We demonstrate that SSLDA achieves an optimal convergence rate\nin terms of both misclassification rate and estimate error. Our theoretical\nresults are further confirmed by extensive numerical experiments on both\nsimulated and real datasets. Compared with current approaches, the SSLDA method\noffers superior improved finite sample performance and notable robustness\nagainst heavy-tailed distributions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T12:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.11121v1","title":"$B$ meson decays to vector charmonium(like) states and a $K$ meson: the\n  role of final-state interactions","summary":"A series of vector charmonium(like) states, accompanied by a $K$ meson, have\nbeen observed in the decays of $B$ meson. These processes are color-suppressed\nat the quark level, as inferred from topological diagram analysis. In this\nwork, we calculate the branching fractions of the decays $B \\to \\psi K$, where\n$\\psi$ denotes the charmonium(like) states $\\psi(1S)$, $\\psi(2S)$,\n$\\psi(4040)$, $\\psi(3770)$, and $\\psi(4160)$. Our analysis incorporates both\nshort-distance (naive factorization approach) and long-distance (final-state\ninteractions) contributions. Within reasonable parameters, our results align\nwith experimental data except for the $ \\psi(4160)$, suggesting its possible\nexotic nature. Furthermore, we find that long-distance contributions dominate\nthese decay processes, highlighting the crucial role of final-state\ninteractions in the productions of charmonium(like) states in $B$ decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T12:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.11124v1","title":"A Unified Hardware Accelerator for Fast Fourier Transform and Number\n  Theoretic Transform","summary":"The Number Theoretic Transform (NTT) is an indispensable tool for computing\nefficient polynomial multiplications in post-quantum lattice-based\ncryptography. It has strong resemblance with the Fast Fourier Transform (FFT),\nwhich is the most widely used algorithm in digital signal processing. In this\nwork, we demonstrate a unified hardware accelerator supporting both 512-point\ncomplex FFT as well as 256-point NTT for the recently standardized NIST\npost-quantum key encapsulation and digital signature algorithms ML-KEM and\nML-DSA respectively. Our proposed architecture effectively utilizes the\narithmetic circuitry required for complex FFT, and the only additional circuits\nrequired are for modular reduction along with modifications in the control\nlogic. Our implementation achieves performance comparable to state-of-the-art\nML-KEM / ML-DSA NTT accelerators on FPGA, thus demonstrating how an FFT\naccelerator can be augmented to support NTT and the unified hardware can be\nused for both digital signal processing and post-quantum lattice-based\ncryptography applications.","main_category":"cs.CR","categories":"cs.CR,eess.SP","published":"2025-04-15T12:13:05Z"}
{"aid":"http://arxiv.org/abs/2504.11130v1","title":"Divergence of Empirical Neural Tangent Kernel in Classification Problems","summary":"This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-15T12:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.11152v1","title":"The imprints of QCD cascades in hadron multiplicity distribution","summary":"The relation between parton and hadron multiplicity distributions is\ndiscussed. To obtain parton multiplicity distribution we propose decomposition\nof the multiplicity distributions of final state hadrons. Such procedure offers\nhope for experimental testing of physical probes of quantum complexity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T12:53:12Z"}
{"aid":"http://arxiv.org/abs/2504.11158v1","title":"More fields are different: Stochastic view of multi-field inflationary\n  scenario","summary":"High-energy physics often motivates multi-field inflationary scenarios where\nstochastic effects play a crucial role. Peculiar to multi-field models, the\nnoise-induced centrifugal force results in a longer duration of inflation\ndepending on the number of fields, even when the stochastic noises themselves\nare small. We show that, in such small-noise regimes, the number of fields\ngenerically discriminates whether inflation successfully terminates or lasts\nforever. Our results indicate that inflation with an extremely large number of\nfields may fail to realise our observable Universe.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-15T13:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11159v1","title":"C-SHAP for time series: An approach to high-level temporal explanations","summary":"Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T13:06:32Z"}
{"aid":"http://arxiv.org/abs/2504.11161v1","title":"Refinements of the Blanco-Koldobsky-Turnšek Theorem","summary":"We refine the well-known Blanco-Koldobsky-Turn\\v{s}ek Theorem which states\nthat a norm one linear operator defined on a Banach space is an isometry if and\nonly if it preserves orthogonality at every element of the space. We improve\nthe result for Banach spaces in which the set of all smooth points forms a\ndense $G_{\\delta}$-set by proving that a norm one linear operator that\npreserves orthogonality on a dense subset of the space is an isometry. We\nfurther demonstrate that if such an operator preserves orthogonality on a\nhyperplane not passing through the origin then it is an isometry. In the\ncontext of finite-dimensional Banach spaces, we prove that preserving\northogonality on the set all extreme points of the unit ball forces the\noperator to be an isometry, which substantially refines\nBlanco-Koldobsky-Turn\\v{s}ek theorem. Finally, for finite-dimensional\npolyhedral spaces, we establish the significance of the set of all $k$-smooth\npoints for any possible $k,$ in the study of isometric theory.","main_category":"math.FA","categories":"math.FA","published":"2025-04-15T13:10:43Z"}
{"aid":"http://arxiv.org/abs/2504.11213v1","title":"Characterizing High Schmidt Number Witnesses in Arbitrary Dimensions\n  System","summary":"A profound comprehension of quantum entanglement is crucial for the\nprogression of quantum technologies. The degree of entanglement can be assessed\nby enumerating the entangled degrees of freedom, leading to the determination\nof a parameter known as the Schmidt number. In this paper, we develop an\nefficient analytical tool for characterizing high Schmidt number witnesses for\nbipartite quantum states in arbitrary dimensions. Our methods not only offer\nviable mathematical methods for constructing high-dimensional Schmidt number\nwitnesses in theory but also simplify the quantification of entanglement and\ndimensionality. Most notably, we develop high-dimensional Schmidt number\nwitnesses within arbitrary-dimensional systems, with our Schmidt witness\ncoefficients relying solely on the operator Schmidt coefficient. Subsequently,\nwe demonstrate our theoretical advancements and computational superiority by\nconstructing Schmidt number witnesses in arbitrary dimensional bipartite\nquantum systems with Schmidt numbers four and five.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math-ph,math.MP,math.NA,math.SP","published":"2025-04-15T14:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.11215v1","title":"Observational Study of Recurrent Jets: Evolution of Magnetic Flux,\n  Current, and Helicity","summary":"We observed three recurrent blowout jets in an active regio with Atmospheric\nImaging Assembly (AIA) aboard the Solar Dynamics Observatory (SDO). Using\nHelioseismic Magnetic Imager (HMI) data. We found that the magnetic flux of an\nemerging negative pole increases steadily before declining just as the jets\nerupt. Certain physical quantities, like the total unsigned vertical current,\nalign with the periodicity of the jets. The differential affine velocity of the\nvector magnetograms reveals strong shear around the negative pole. The Doppler\nvelocity map, calculated from the H$\\alpha$ spectra observed by the Chinese\nH$\\alpha$ Solar Explorer (CHASE), shows upflows with large initial velocity\nbefore it can be observed by AIA. The magnetic field derived from the nonlinear\nforce-free field (NLFFF) model suggests a topology akin to fan-spine structure,\nconsistent with AIA images. We calculated the evolution of volumetric helicity\nratio using the NLFFF model and found its phase aligns with the jet flux in AIA\n171 \\AA. These results suggest that recurrent jets may be triggered by the\naccumulation and release of energy and helicity, driven by emergence, shearing\nand cancellation of photospheric magnetic field.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T14:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.11222v1","title":"Fusion research in a Deuterium-Tritium tokamak","summary":"The recent ITER re-baselining calls for new fusion-relevant research best\ncarried out in a DT-capable tokamak device with similar characteristics. The\npresent paper describes key issues that could be addressed in a Suitably\nEnhanced DT-capable Tokamak (SET), with tungsten plasma facing components,\nboronization systems, and 10 MW of ECRH, based on characteristics and\nknowledgebase of JET. We discuss hardware options, and show that\nfusion-relevant operational scenarios could be achieved. Notably, development,\nvalidation and testing of fusion and nuclear diagnostics, to be used in next\ngeneration devices, would require a D-T capable tokamak as described.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,nucl-ex","published":"2025-04-15T14:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.11237v1","title":"Periodic table for highly charged ions","summary":"Mendeleev's periodic table successfully groups atomic elements according to\ntheir chemical and spectroscopic properties. However, it becomes less\nsufficient in describing the electronic properties of highly charged ions\n(HCIs) in which many of the outermost electrons are ionized. In this work, we\nput forward a periodic table particularly suitable for HCIs. It is constructed\npurely based on the successive electron occupation of relativistic orbitals.\nWhile providing a much-simplified description of the level structure of highly\ncharged isoelectronic ions -- essential for laboratory and astrophysical plasma\nspectroscopies, such a periodic table predicts a large family of highly\nforbidden transitions suitable for the development of next-generation optical\natomic clocks. Furthermore, we also identify universal linear $Z$ scaling laws\n($Z$ is the nuclear charge) in the so-called ``Coulomb splittings'' between\nangular momentum multiplets along isoelectronic sequences, complementing the\nphysics of electron-electron interactions in multielectron atomic systems.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.optics,physics.plasm-ph,quant-ph","published":"2025-04-15T14:39:09Z"}
{"aid":"http://arxiv.org/abs/2504.11271v1","title":"Distillation-Supervised Convolutional Low-Rank Adaptation for Efficient\n  Image Super-Resolution","summary":"Convolutional neural networks (CNNs) have been widely used in efficient image\nsuper-resolution. However, for CNN-based methods, performance gains often\nrequire deeper networks and larger feature maps, which increase complexity and\ninference costs. Inspired by LoRA's success in fine-tuning large language\nmodels, we explore its application to lightweight models and propose\nDistillation-Supervised Convolutional Low-Rank Adaptation (DSCLoRA), which\nimproves model performance without increasing architectural complexity or\ninference costs. Specifically, we integrate ConvLoRA into the efficient SR\nnetwork SPAN by replacing the SPAB module with the proposed SConvLB module and\nincorporating ConvLoRA layers into both the pixel shuffle block and its\npreceding convolutional layer. DSCLoRA leverages low-rank decomposition for\nparameter updates and employs a spatial feature affinity-based knowledge\ndistillation strategy to transfer second-order statistical information from\nteacher models (pre-trained SPAN) to student models (ours). This method\npreserves the core knowledge of lightweight models and facilitates optimal\nsolution discovery under certain conditions. Experiments on benchmark datasets\nshow that DSCLoRA improves PSNR and SSIM over SPAN while maintaining its\nefficiency and competitive image quality. Notably, DSCLoRA ranked first in the\nOverall Performance Track of the NTIRE 2025 Efficient Super-Resolution\nChallenge. Our code and models are made publicly available at\nhttps://github.com/Yaozzz666/DSCF-SR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:12:57Z"}
{"aid":"http://arxiv.org/abs/2504.11284v1","title":"Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation","summary":"Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-15T15:25:27Z"}
{"aid":"http://arxiv.org/abs/2504.11294v1","title":"Transforming Resonance Fluorescence into Maximally Entangled Photon\n  Pairs Using Minimal Resources","summary":"Entanglement is a fundamental concept in quantum mechanics, describing two or\nmore quantum systems that exhibit strong correlations beyond the classical\nlimits at the expense of losing their individual properties. More recently, it\nhas become a cornerstone of quantum technologies, promising revolutionary\nadvancements in fields like quantum communication, sensing, and computation.\nFor these reasons, the generation of technologically useful entangled states is\nkey to progress in these fields. Here, we experimentally demonstrate that\nresonance fluorescence from a weakly coupled two-level emitter can be\ntransformed, using beam splitters, delay lines, and post-selection only, into a\nstream of pairs of photons that are maximally entangled in the time-bin basis.\nWe verify the entanglement via a CHSH-type Bell inequality test, yielding an\nS-parameter of 2.80 \\pm 0.19, i.e., a clear 4{\\sigma} violation of the\nclassical bound. Our results pave the way for realising efficient sources of\nbandwidth-limited time-bin entangled photon pairs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11300v1","title":"Multi-Orbiter Continuous Lunar Beaming","summary":"In this work, free-space optics-based continuous wireless power transmission\nbetween multiple low lunar orbit satellites and a solar panel on the lunar\nrover located at the lunar south pole are investigated based on the\ntime-varying harvested power and overall system efficiency metrics. The\nperformances are compared between a solar panel with the tracking ability and a\nfixed solar panel that induces \\textit{the cosine effect} due to the\ntime-dependent angle of incidence (AoI). In our work, the Systems Tool Kit\n(STK) high-precision orbit propagator, which calculates the ephemeris data\nprecisely, is utilized. Interestingly, orbiter deployments in constellations\nchange significantly during a Moon revolution; thus, short-duration simulations\ncannot be used straightforwardly. In our work, many satellite configurations\nare assessed to be able to find a Cislunar constellation that establishes a\ncontinuous line-of-sight (LoS) between the solar panel and at least a single\nLLO satellite. It is found that 40-satellite schemes enable the establishment\nof a continuous WPT system model. Besides, a satellite selection method (SSM)\nis introduced so that only the best LoS link among multiple simultaneous links\nfrom multiple satellites will be active for optimum efficiency. Our benchmark\nsystem of a 40-satellite quadruple orbit scheme is compared with 30-satellite\nand a single satellite schemes based on the average harvested powers and\noverall system efficiencies 27.3 days so the trade-off options can be assessed\nfrom the multiple Cislunar models. The outcomes show that the average system\nefficiencies of single, 30-satellite, and 40-satellite schemes are 2.84%,\n32.33%, and 33.29%, respectively, for the tracking panel and 0.97%, 18.33%, and\n20.44%, respectively, for the fixed solar panel case.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T15:43:39Z"}
{"aid":"http://arxiv.org/abs/2504.11301v1","title":"Learning to Be A Doctor: Searching for Effective Medical Agent\n  Architectures","summary":"Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T15:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.11325v1","title":"Crystal nucleation and growth in high-entropy alloys revealed by atomic\n  electron tomography","summary":"High-entropy alloys (HEAs) balance mixing entropy and intermetallic phase\nformation enthalpy, creating a vast compositional space for structural and\nfunctional materials (1-6). They exhibit exceptional strength-ductility\ntrade-offs in metallurgy (4-10) and near-continuum adsorbate binding energies\nin catalysis (11-16). A deep understanding of crystal nucleation and growth in\nHEAs is essential for controlling their formation and optimizing their\nstructural and functional properties. However, atomic-scale nucleation in HEAs\nchallenges traditional theories based on one or two principal elements (17-23).\nThe intricate interplay of structural and chemical orders among multiple\nprincipal elements further obscures our understanding of nucleation pathways\n(5,24-27). Due to the lack of direct three-dimensional (3D) atomic-scale\nobservations, previous studies have relied on simulations and indirect\nmeasurements (28-32), leaving HEA nucleation and growth fundamentally elusive.\nHere, we advance atomic electron tomography (33,34) to resolve the 3D atomic\nstructure and chemical composition of 7,662 HEA and 498 medium-entropy alloy\nnuclei at different nucleation stages. We observe local structural order that\ndecreases from core to boundary, correlating with local chemical order. As\nnuclei grow, structural order improves. At later stages, most nuclei coalesce\nwithout misorientation, while some form coherent twin boundaries. To explain\nthese experimental observations, we propose the gradient nucleation pathways\nmodel, in which the nucleation energy barrier progressively increases through\nmultiple evolving intermediate states. We expect these findings to not only\nprovide fundamental insights into crystal nucleation and growth in HEAs, but\nalso offer a general framework for understanding nucleation mechanisms in other\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.soft","published":"2025-04-15T16:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.11340v1","title":"Organisation and dynamics of individual DNA segments in topologically\n  complex genomes","summary":"Capturing the physical organisation and dynamics of genomic regions is one of\nthe major open challenges in biology. The kinetoplast DNA (kDNA) is a\ntopologically complex genome, made by thousands of DNA (mini and maxi) circles\ninterlinked into a two-dimensional Olympic network. The organisation and\ndynamics of these DNA circles are poorly understood. In this paper, we show\nthat dCas9 linked to Quantum Dots can efficiently label different classes of\nDNA minicircles in kDNA. We use this method to study the distribution and\ndynamics of different classes of DNA minicircles within the network. We\ndiscover that maxicircles display a preference to localise at the periphery of\nthe network and that they undergo subdiffusive dynamics. From the latter, we\ncan also quantify the effective network stiffness, confirming previous indirect\nestimations via AFM. Our method could be used more generally, to quantify the\nlocation, dynamics and material properties of genomic regions in other complex\ngenomes, such as that of bacteria, and to study their behaviour in the presence\nof DNA-binding proteins.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-15T16:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.11358v1","title":"DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks","summary":"LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-15T16:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.11385v1","title":"GLL-type Nonmonotone Descent Methods Revisited under\n  Kurdyka-Łojasiewicz Property","summary":"The purpose of this paper is to extend the full convergence results of the\nclassic GLL-type (Grippo-Lampariello-Lucidi) nonmonotone methods to nonconvex\nand nonsmooth optimization. We propose a novel iterative framework for the\nminimization of a proper and lower semicontinuous function $\\Phi$. The\nframework consists of the GLL-type nonmonotone decrease condition for a\nsequence, a relative error condition for its augmented sequence with respect to\na Kurdyka-{\\L}ojasiewicz (KL) function $\\Theta$, and a relative gap condition\nfor the partial maximum objective value sequence. The last condition is shown\nto be a product of the prox-regularity of $\\Phi$ on the set of cluster points,\nand to hold automatically under a mild condition on the objective value\nsequence. We prove that for any sequence and its bounded augmented sequence\ntogether falling within the framework, the sequence itself is convergent.\nFurthermore, when $\\Theta$ is a KL function of exponent $\\theta\\in(0, 1)$, the\nconvergence admits a linear rate if $\\theta\\in(0, 1/2]$ and a sublinear rate if\n$\\theta\\in(1/2, 1)$. As applications, we prove, for the first time, that the\ntwo existing algorithms, namely the nonmonotone proximal gradient (NPG) method\nwith majorization and NPG with extrapolation both enjoy the full convergence of\nthe iterate sequences for nonconvex and nonsmooth KL composite optimization\nproblems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T16:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.11419v1","title":"Embodied World Models Emerge from Navigational Task in Open-Ended\n  Environments","summary":"Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI,cs.NE","published":"2025-04-15T17:35:13Z"}
{"aid":"http://arxiv.org/abs/2504.11436v1","title":"Shifting Work Patterns with Generative AI","summary":"We present evidence on how generative AI changes the work patterns of\nknowledge workers using data from a 6-month-long, cross-industry, randomized\nfield experiment. Half of the 6,000 workers in the study received access to a\ngenerative AI tool integrated into the applications they already used for\nemails, document creation, and meetings. We find that access to the AI tool\nduring the first year of its release primarily impacted behaviors that could be\nchanged independently and not behaviors that required coordination to change:\nworkers who used the tool spent 3 fewer hours, or 25% less time on email each\nweek (intent to treat estimate is 1.4 hours) and seemed to complete documents\nmoderately faster, but did not significantly change time spent in meetings.","main_category":"econ.GN","categories":"econ.GN,cs.LG,q-fin.EC","published":"2025-04-15T17:52:00Z"}
{"aid":"http://arxiv.org/abs/2504.11451v1","title":"PARTFIELD: Learning 3D Feature Fields for Part Segmentation and Beyond","summary":"We propose PartField, a feedforward approach for learning part-based 3D\nfeatures, which captures the general concept of parts and their hierarchy\nwithout relying on predefined templates or text-based names, and can be applied\nto open-world 3D shapes across various modalities. PartField requires only a 3D\nfeedforward pass at inference time, significantly improving runtime and\nrobustness compared to prior approaches. Our model is trained by distilling 2D\nand 3D part proposals from a mix of labeled datasets and image segmentations on\nlarge unsupervised datasets, via a contrastive learning formulation. It\nproduces a continuous feature field which can be clustered to yield a\nhierarchical part decomposition. Comparisons show that PartField is up to 20%\nmore accurate and often orders of magnitude faster than other recent\nclass-agnostic part-segmentation methods. Beyond single-shape part\ndecomposition, consistency in the learned field emerges across shapes, enabling\ntasks such as co-segmentation and correspondence, which we demonstrate in\nseveral applications of these general-purpose, hierarchical, and consistent 3D\nfeature fields. Check our Webpage!\nhttps://research.nvidia.com/labs/toronto-ai/partfield-release/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:58:16Z"}
{"aid":"http://arxiv.org/abs/2504.11751v1","title":"Wandering Flows on the Plane","summary":"We study planar flows without non-wandering points and prove several\nproperties of these flows in relation with their prolongational relation. The\nmain results of this article are that a planar (regular) wandering flow has no\ngeneralized recurrence and has only two topological invariants: the space of\nits orbits and its prolongational relation (or, equivalently, its smallest\nstream). As a byproduct, our results show that, even in absence of any type of\nrecurrence, the stream of a flow contains fundamental information on its\nbehavior.","main_category":"math.DS","categories":"math.DS,math.GN","published":"2025-04-16T04:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.11764v1","title":"Probing the Abyss of the Quantum Vacuum: A Quest for Fluctuation-Free\n  Domains","summary":"The modification of electromagnetic vacuum fluctuations by boundary\nconditions is a fundamental prediction of quantum electrodynamics (QED).\nHowever, direct experimental verification in the optical regime is hindered by\nthe need for sub-wavelength spatial resolution. Here, we present a novel\napproach to indirectly probe the spatial distribution of vacuum fluctuations by\nleveraging radio-frequency (RF) measurements of thermal noise. At RF\nfrequencies, thermal noise, which occupies the same electromagnetic modes as\nvacuum fluctuations and is similarly shaped by boundary conditions, dominates\nthe single-photon energy. By precisely characterizing the spatial distribution\nof thermal noise near a conducting boundary, we infer the corresponding\nmodification of vacuum modes and, consequently, the vacuum fluctuations\nthemselves. Our experimental setup, employing coaxial cables and RF splitters\nto mimic optical mirrors and beam splitters, enables controlled manipulation of\nboundary conditions and precise thermal noise measurements. We observe a\nreduction in thermal noise near the conducting boundary, providing indirect\nevidence for the theoretically predicted suppression of vacuum fluctuations.\nThis work establishes a new experimental framework for investigating QED\neffects in constrained environments, with potential implications for\nquantum-limited precision measurements, such as gravitational wave detection\nand intensity-stabilized light sources. This RF approach circumvents the\nlimitations of optical techniques and opens new avenues for exploring\nfundamental quantum phenomena.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T04:59:14Z"}
{"aid":"http://arxiv.org/abs/2504.11765v1","title":"Shared Disk KV Cache Management for Efficient Multi-Instance Inference\n  in RAG-Powered LLMs","summary":"Recent large language models (LLMs) face increasing inference latency as\ninput context length and model size continue to grow. In particular, the\nretrieval-augmented generation (RAG) technique, which enhances LLM responses by\nincorporating external knowledge, exacerbates this issue by significantly\nincreasing the number of input tokens. This expansion in token length leads to\na substantial rise in computational overhead, particularly during the prefill\nstage, resulting in prolonged time-to-first-token (TTFT). To address this\nissue, this paper proposes a method to reduce TTFT by leveraging a disk-based\nkey-value (KV) cache to lessen the computational burden during the prefill\nstage. We also introduce a disk-based shared KV cache management system, called\nShared RAG-DCache, for multi-instance LLM RAG service environments. This\nsystem, together with an optimal system configuration, improves both throughput\nand latency under given resource constraints. Shared RAG-DCache exploits the\nlocality of documents related to user queries in RAG, as well as the queueing\ndelay in LLM inference services. It proactively generates and stores disk KV\ncaches for query-related documents and shares them across multiple LLM\ninstances to enhance inference performance. In experiments on a single host\nequipped with 2 GPUs and 1 CPU, Shared RAG-DCache achieved a 15~71% increase in\nthroughput and up to a 12~65% reduction in latency, depending on the resource\nconfiguration.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T04:59:18Z"}
{"aid":"http://arxiv.org/abs/2504.11777v1","title":"Bridging the Semantic Gaps: Improving Medical VQA Consistency with\n  LLM-Augmented Question Sets","summary":"Medical Visual Question Answering (MVQA) systems can interpret medical images\nin response to natural language queries. However, linguistic variability in\nquestion phrasing often undermines the consistency of these systems. To address\nthis challenge, we propose a Semantically Equivalent Question Augmentation\n(SEQA) framework, which leverages large language models (LLMs) to generate\ndiverse yet semantically equivalent rephrasings of questions. Specifically,\nthis approach enriches linguistic diversity while preserving semantic meaning.\nWe further introduce an evaluation metric, Total Agreement Rate with\nSemantically Equivalent Input and Correct Answer (TAR-SC), which assesses a\nmodel's capability to generate consistent and correct responses to semantically\nequivalent linguistic variations. In addition, we also propose three other\ndiversity metrics - average number of QA items per image (ANQI), average number\nof questions per image with the same answer (ANQA), and average number of\nopen-ended questions per image with the same semantics (ANQS). Using the SEQA\nframework, we augmented the benchmarked MVQA public datasets of SLAKE, VQA-RAD,\nand PathVQA. As a result, all three datasets achieved significant improvements\nby incorporating more semantically equivalent questions: ANQI increased by an\naverage of 86.1, ANQA by 85.1, and ANQS by 46. Subsequent experiments evaluate\nthree MVQA models (M2I2, MUMC, and BiomedGPT) under both zero-shot and\nfine-tuning settings on the enhanced datasets. Experimental results in MVQA\ndatasets show that fine-tuned models achieve an average accuracy improvement of\n19.35%, while our proposed TAR-SC metric shows an average improvement of 11.\n61%, indicating a substantial enhancement in model consistency.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T05:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.11781v1","title":"ACMamba: Fast Unsupervised Anomaly Detection via An Asymmetrical\n  Consensus State Space Model","summary":"Unsupervised anomaly detection in hyperspectral images (HSI), aiming to\ndetect unknown targets from backgrounds, is challenging for earth surface\nmonitoring. However, current studies are hindered by steep computational costs\ndue to the high-dimensional property of HSI and dense sampling-based training\nparadigm, constraining their rapid deployment. Our key observation is that,\nduring training, not all samples within the same homogeneous area are\nindispensable, whereas ingenious sampling can provide a powerful substitute for\nreducing costs. Motivated by this, we propose an Asymmetrical Consensus State\nSpace Model (ACMamba) to significantly reduce computational costs without\ncompromising accuracy. Specifically, we design an asymmetrical anomaly\ndetection paradigm that utilizes region-level instances as an efficient\nalternative to dense pixel-level samples. In this paradigm, a low-cost\nMamba-based module is introduced to discover global contextual attributes of\nregions that are essential for HSI reconstruction. Additionally, we develop a\nconsensus learning strategy from the optimization perspective to simultaneously\nfacilitate background reconstruction and anomaly compression, further\nalleviating the negative impact of anomaly reconstruction. Theoretical analysis\nand extensive experiments across eight benchmarks verify the superiority of\nACMamba, demonstrating a faster speed and stronger performance over the\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T05:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.11794v1","title":"Fast Baryonic Field Painting for Sunyaev-Zel'dovich Analyses: Transfer\n  Function vs. Hybrid Effective Field Theory","summary":"We present two approaches for \"painting\" baryonic properties relevant to the\nSunyaev-Zel'dovich (SZ) effect - optical depth and Compton-$y$ - onto\n3-dimensional $N$-body simulations, using the MillenniumTNG suite as a\nbenchmark. The goal of these methods is to produce fast and accurate\nreconstruction methods to aid future analyses of baryonic feedback using the SZ\neffect. The first approach employs a Gaussian Process emulator to model the SZ\nquantities via a transfer function, while the second utilizes Hybrid Effective\nField Theory (HEFT) to reproduce these quantities within the simulation. Our\nanalysis involves comparing both methods to the true MillenniumTNG optical\ndepth and Compton-$y$ fields using several metrics, including the\ncross-correlation coefficient, power spectrum, and power spectrum error.\nAdditionally, we assess how well the reconstructed fields correlate with dark\nmatter haloes across various mass thresholds. The results indicate that the\ntransfer function method yields more accurate reconstructions for fields with\ninitially high correlations ($r \\approx 1$), such as between the optical depth\nand dark matter fields. Conversely, the HEFT-based approach proves more\neffective in enhancing correlations for fields with weaker initial correlations\n($r \\sim 0.5$), such as between the Compton-$y$ and dark matter fields. Lastly,\nwe discuss extensions of our methods to improve the reconstruction performance\nat the field level.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-16T06:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.11804v1","title":"Advanced MST3 Encryption scheme based on generalized Suzuki 2-groups","summary":"This article presents a method for enhancing the encryption algorithm in the\nMST3 cryptosystem for generalized Suzuki 2-groups. The conventional MST\ncryptosystem based on Suzuki groups utilizes logarithmic signatures (LS)\nrestricted to the center of the group, resulting in an expansive array of\nlogarithmic signatures. We propose an encryption scheme based on\nmulti-parameter non-commutative groups, specifically selecting multi-parameter\ngeneralized Suzuki 2-groups as the group construction framework. In our\napproach, the logarithmic signature extends across the entire group, with\ncipher security dependent on the group order. This design enables the\ndevelopment of encryption optimized for implementation efficiency determined by\nlogarithmic signature size while maintaining robust security through\nappropriate key sizes and the finite field of group representation. The primary\ninnovation in our encryption implementation lies in the sequential\nde-encapsulation of keys from ciphertext using logarithmic signatures and\nassociated keys. The security evaluation of the cipher relies on attack\ncomplexity analysis, which is quantified through comprehensive key enumeration\nmethodologies.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-16T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11806v1","title":"Phase Separation in Active Binary Mixtures With Chemical Reaction","summary":"We study motility-induced phase separation~(MIPS) in active AB binary\nmixtures undergoing the chemical reaction $A \\rightleftharpoons B$. Starting\nfrom the evolution equations for the density fields $\\rho_i(\\vec r, t)$\ndescribing MIPS, we phenomenologically incorporate the effects of the reaction\nthrough the reaction rate $\\Gamma$ into the equations. The steady-state domain\nmorphologies depend on $\\Gamma$ and the relative activity of the species,\n$\\Delta$. For a sufficiently large $\\Gamma$ and $\\Delta\\ne 1$, the more active\ncomponent of the mixture forms a droplet morphology. We characterize the\nmorphology of domains by calculating the equal-time correlation function $C(r,\nt)$ and the structure factor $S(k, t)$, exhibiting scaling violation. The\naverage domain size, $L(t)$, follows a diffusive growth as $L(t)\\sim t^{1/3}$\nbefore reaching the steady state domain size, $L_{\\rm ss}$. Additionally,\n$L_{\\rm ss}$ shows the scaling relation $L_{\\rm ss}\\sim\\Gamma^{-1/4}$,\nindependent of $\\Delta$.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-16T06:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.11835v1","title":"Particle Data Cloning for Complex Ordinary Differential Equations","summary":"Ordinary differential equations (ODEs) are fundamental tools for modeling\ncomplex dynamic systems across scientific disciplines. However, parameter\nestimation in ODE models is challenging due to the multimodal nature of the\nlikelihood function, which can lead to local optima and unstable inference. In\nthis paper, we propose particle data cloning (PDC), a novel approach that\nenhances global optimization by leveraging data cloning and annealed sequential\nMonte Carlo (ASMC). PDC mitigates multimodality by refining the likelihood\nthrough data clones and progressively extracting information from the sharpened\nposterior. Compared to standard data cloning, PDC provides more reliable\nfrequentist inference and demonstrates superior global optimization\nperformance. We offer practical guidelines for efficient implementation and\nillustrate the method through simulation studies and an application to a\nprey-predator ODE model. Our implementation is available at\nhttps://github.com/SONDONGHUI/PDC.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T07:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.11842v1","title":"Bloch phonon-polaritons with anomalous dispersion in polaritonic Fourier\n  crystals","summary":"The recently suggested concept of a polaritonic Fourier crystal (PFC) is\nbased on a harmonically-corrugated mirror substrate for a thin pristine\npolaritonic crystal layer. The propagating polaritons in PFC experience a\nharmonic and mode-selective momentum modulation leading to a manifestation of\nBloch modes with practically zero inter-mode scattering. PFC was first\ndemonstrated for the hyperbolic phonon-polaritons in hexagonal boron nitride\n(hBN) within its Type II Reststrahlen band (RB-II) where the in-plane\ncomponents of the dielectric permittivity tensor are isotropic and negative,\nwhile the out-of-plane component is positive. By contrast, a Type I\nReststrahlen band (RB-I) is characterized by negative out-of-plane and positive\nin-plane permittivity components, and consequently, the inversion of field\nsymmetry of phonon-polaritons compared to RB-II. Behavior of such RB-I modes in\na polaritonic crystal is yet to be explored. Here, we employ a biaxial crystal\nalpha-phase molybdenum trioxide ({\\alpha}-MoO3) and near-field imaging to study\npolaritonic Bloch modes in a one-dimensional PFC within the RB-I where the\nmid-infrared phonon-polaritons in {\\alpha}-MoO3 have anomalous dispersion and\nnegative phase velocity. Surprisingly, we observe a manifestation of Bloch\nwaves as a dispersionless near-field pattern across the first Brillouin zone,\nin contrast to RB-II case demonstrated with in-plane isotropic hBN. We\nattribute this difference to the opposite field symmetry of the lowest-order\nphonon-polariton mode in the two RBs, leading to a different momentum\nmodulation regime in the polaritonic Fourier crystal. Our results reveal the\nimportance of mode symmetry for polaritonic crystals in general and for the\nemerging field of Fourier crystals in particular, which promise new ways to\nmanipulate the nanolight.","main_category":"physics.optics","categories":"physics.optics,cond-mat.other,physics.app-ph","published":"2025-04-16T08:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.11844v1","title":"Evaluating the Goal-Directedness of Large Language Models","summary":"To what extent do LLMs use their capabilities towards their given goal? We\ntake this as a measure of their goal-directedness. We evaluate\ngoal-directedness on tasks that require information gathering, cognitive\neffort, and plan execution, where we use subtasks to infer each model's\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\nand Anthropic show that goal-directedness is relatively consistent across\ntasks, differs from task performance, and is only moderately sensitive to\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\nour goal-directedness evaluations will enable better monitoring of LLM\nprogress, and enable more deliberate design choices of agentic properties in\nLLMs.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-16T08:07:08Z"}
{"aid":"http://arxiv.org/abs/2504.11854v1","title":"Less-excludable Mechanism for DAOs in Public Good Auctions","summary":"With the rise of smart contracts, decentralized autonomous organizations\n(DAOs) have emerged in public good auctions, allowing \"small\" bidders to gather\ntogether and enlarge their influence in high-valued auctions. However, models\nand mechanisms in the existing research literature do not guarantee\nnon-excludability, which is a main property of public goods. As such, some\nmembers of the winning DAO may be explicitly prevented from accessing the\npublic good. This side effect leads to regrouping of small bidders within the\nDAO to have a larger say in the final outcome. In particular, we provide a\npolynomial-time algorithm to compute the best regrouping of bidders that\nmaximizes the total bidding power of a DAO. We also prove that such a\nregrouping is less-excludable, better aligning the needs of the entire DAO and\nthe nature of public goods. Next, notice that members of a DAO in public good\nauctions often have a positive externality among themselves. Thus we introduce\na collective factor into the members' utility functions. We further extend the\nmechanism's allocation for each member to allow for partial access to the\npublic good. Under the new model, we propose a mechanism that is incentive\ncompatible in generic games and achieves higher social welfare as well as\nless-excludable allocations.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-16T08:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.11862v1","title":"Twist Grain Boundary phases in proper ferroelectric liquid crystals\n  realm","summary":"The twist-grain-boundary (TGB) phases, characterized by a periodic, helical\narrangement of blocks made of polar smectic phases, SmAF and SmCF, have been\ndiscovered. They have been observed for rod-like molecules with a strong\nlongitudinal dipole moment, featuring an (S)-2-methylbutyl end group having\nonly weak twisting power, and emerge below the antiferroelectric SmAAF phase,\nwhere the lamellar structure is already well established. It is suggested that\nthe structure is governed by electrostatic interactions amplified by weak\nchiral forces, in striking contrast to the mechanism of TGB phase formation\nfound in non-polar materials. The TGB phases exhibit light selective reflection\nin the visible range, while the value of electric polarization confirms an\nalmost perfectly ordered dipole alignment.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-16T08:36:48Z"}
{"aid":"http://arxiv.org/abs/2504.11872v1","title":"A Category-Fragment Segmentation Framework for Pelvic Fracture\n  Segmentation in X-ray Images","summary":"Pelvic fractures, often caused by high-impact trauma, frequently require\nsurgical intervention. Imaging techniques such as CT and 2D X-ray imaging are\nused to transfer the surgical plan to the operating room through image\nregistration, enabling quick intraoperative adjustments. Specifically,\nsegmenting pelvic fractures from 2D X-ray imaging can assist in accurately\npositioning bone fragments and guiding the placement of screws or metal plates.\nIn this study, we propose a novel deep learning-based category and fragment\nsegmentation (CFS) framework for the automatic segmentation of pelvic bone\nfragments in 2D X-ray images. The framework consists of three consecutive\nsteps: category segmentation, fragment segmentation, and post-processing. Our\nbest model achieves an IoU of 0.91 for anatomical structures and 0.78 for\nfracture segmentation. Results demonstrate that the CFS framework is effective\nand accurate.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.11883v1","title":"Quantum Optical Spanner: Twisting Superconductors with Vortex Beam via\n  Higgs Mode","summary":"Light carrying orbital angular momentum (OAM)--known as vortex beams--has\nbroadened the scope of understanding and applications of light's angular\nmomentum. Optical tweezers using OAM, often referred to as optical spanners,\nhave significantly expanded the tunability of optical manipulation. A key\nfrontier now lies in understanding how vortex beams interact with quantum\nstates of matter. In this work, we numerically investigate the dynamics of a\nsuperconductor under vortex beam illumination and demonstrate the transfer of\nangular momentum from light to the superconducting collective mode, resulting\nin mechanical rotation. Our findings open a pathway for optical manipulation in\nthe quantum regime, which we term the quantum optical spanner.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,physics.optics","published":"2025-04-16T09:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.11887v1","title":"Coherent States in Classical Field Theory","summary":"We illustrate the emergence of classical analogue of coherent state and its\ngeneralisation in a purely classical field theoretical setting. Our algebraic\napproach makes use of the Poisson bracket and symmetries of the underlying\nfield theory, in a complete parallel to the quantum construction. The classical\nphase space picture is found to play a key role in this construction.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-16T09:14:20Z"}
{"aid":"http://arxiv.org/abs/2504.11890v1","title":"A Novel Jet Model for the Novikov-Thorne Disk and its Observable Impact","summary":"Recent high-resolution observations have established a strong link between\nblack hole jets and accretion disk structures, particularly in the 3.5 mm\nwavelength band [Nature. 616, 686 (2023)]. In this work, we propose a\n``jet-modified Novikov-Thorne disk model'' that explicitly incorporates jet\nluminosity into the accretion disk radiation framework. By integrating\nsynchrotron radiation from relativistic electrons in the jet, we derive a\nmodified luminosity function that accounts for both the accretion disk and jet\ncontributions. Our analysis demonstrates that the inclusion of jet luminosity\nenhances the total accretion disk luminosity by approximately 33.5\\%, as\nderived from the integration of radiative flux. Furthermore, we compare our\nmodified model with the standard Novikov-Thorne model and find that the jet\ncontribution remains significant across different observational inclinations.\nThese results highlight the necessity of incorporating jet effects when\nestimating the observable flux of black hole accretion systems, which has\ndirect implications for future astronomical observations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T09:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11899v1","title":"Variational Quantum Optimization Benchmark Suite for Airline Crew\n  Pairing and More","summary":"We introduce a set of open-source packages that form a highly extensible\nframework for quantum optimization. One design goal of the system is the\ninclusion of a command line based configuration system for setting up\nexperiments. The possible options are derived using well-known Python packages\nand presented to the user intuitively, allowing the configuration of repeatable\nvariational quantum optimization experiments. We give an example of using the\nsystem through the Airline Crew Pairing problem, a highly relevant industrial\nproblem, and the MaxCut problem, for which instances of manageable size are\nreadily available.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.11909v1","title":"Deflection of Light due to Kerr Sen Black Hole in Heterotic String\n  Theory using Material Medium Approach","summary":"The deflection of light in the gravitational field of a massive body can be\nanalyzed through diverse theoretical approaches. The null geodesic approach is\ncommonly employed to calculate light deflection within strong and weak field\nlimits. Alternatively, several studies have explored the gravitational\ndeflection of light using the material medium approach. For a static,\nnon-rotating spherical mass, the deflection in a Schwarzschild field can be\ndetermined by expressing the metric in an isotropic form and evaluating the\nrefractive index to trace the light ray's trajectory. In this study, we extend\nthe above-mentioned approach to the Kerr-Sen black hole spacetime in heterotic\nstring theory, a solution representing a rotating, charged solution in\nheterotic string theory. The frame-dragging effects inherent to the Kerr-Sen\ngeometry are incorporated to compute the velocity of light rays, enabling the\nderivation of the refractive index in this field. Considering the far-field\napproximation, we calculate the deflection of light in the Kerr-Sen spacetime\nand compare our results with those obtained for the Kerr and Schwarzschild\nblack hole solution in GR.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T09:40:01Z"}
{"aid":"http://arxiv.org/abs/2504.11915v1","title":"Starting the study of outer length billiards","summary":"We focus on the outer length billiard dynamics, acting on the exterior of a\nstrictly-convex planar domain. We first show that ellipses are totally\nintegrable. We then provide an explicit representation of first order terms for\nthe formal Taylor expansion of the corresponding Mather's $\\beta$-function.\nFinally, we provide explicit Lazutkin coordinates up to order 4.","main_category":"math.DS","categories":"math.DS","published":"2025-04-16T09:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.11924v1","title":"Topological Analysis of Mixer Activities in the Bitcoin Network","summary":"Cryptocurrency users increasingly rely on obfuscation techniques such as\nmixers, swappers, and decentralised or no-KYC exchanges to protect their\nanonymity. However, at the same time, these services are exploited by criminals\nto conceal and launder illicit funds. Among obfuscation services, mixers remain\none of the most challenging entities to tackle. This is because their owners\nare often unwilling to cooperate with Law Enforcement Agencies, and\ntechnically, they operate as 'black boxes'. To better understand their\nfunctionalities, this paper proposes an approach to analyse the operations of\nmixers by examining their address-transaction graphs and identifying\ntopological similarities to uncover common patterns that can define the mixer's\nmodus operandi. The approach utilises community detection algorithms to extract\ndense topological structures and clustering algorithms to group similar\ncommunities. The analysis is further enriched by incorporating data from\nexternal sources related to known Exchanges, in order to understand their role\nin mixer operations. The approach is applied to dissect the Blender.io mixer\nactivities within the Bitcoin blockchain, revealing: i) consistent structural\npatterns across address-transaction graphs; ii) that Exchanges play a key role,\nfollowing a well-established pattern, which raises several concerns about their\nAML/KYC policies. This paper represents an initial step toward dissecting and\nunderstanding the complex nature of mixer operations in cryptocurrency networks\nand extracting their modus operandi.","main_category":"cs.CR","categories":"cs.CR,cs.CE,cs.SI","published":"2025-04-16T09:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.11961v1","title":"zkFuzz: Foundation and Framework for Effective Fuzzing of Zero-Knowledge\n  Circuits","summary":"Zero-knowledge (ZK) circuits enable privacy-preserving computations and are\ncentral to many cryptographic protocols. Systems like Circom simplify ZK\ndevelopment by combining witness computation and circuit constraints in one\nprogram. However, even small errors can compromise security of ZK programs\n--under-constrained circuits may accept invalid witnesses, while\nover-constrained ones may reject valid ones. Static analyzers are often\nimprecise with high false positives, and formal tools struggle with real-world\ncircuit scale. Additionally, existing tools overlook several critical\nbehaviors, such as intermediate computations and program aborts, and thus miss\nmany vulnerabilities.\n  Our theoretical contribution is the Trace-Constraint Consistency Test (TCCT),\na foundational language-independent formulation of ZK circuit bugs that defines\nbugs as discrepancies between the execution traces of the computation and the\ncircuit constraints. TCCT captures both intermediate computations and program\naborts, detecting bugs that elude prior tools.\n  Our systems contribution is zkFuzz, a novel program mutation-based fuzzing\nframework for detecting TCCT violations. zkFuzz systematically mutates the\ncomputational logic of Zk programs guided by a novel fitness function, and\ninjects carefully crafted inputs using tailored heuristics to expose bugs. We\nevaluated zkFuzz on 354 real-world ZK circuits written in Circom, a leading\nprogramming system for ZK development. zkFuzz successfully identified 66 bugs,\nincluding 38 zero-days --18 of which were confirmed by developers and 6 fixed,\nearning bug bounties.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-16T10:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11980v1","title":"Characterizing physical and logical errors in a transversal CNOT via\n  cycle error reconstruction","summary":"The development of prototype quantum information processors has progressed to\na stage where small instances of logical qubit systems perform better than the\nbest of their physical constituents. Advancing towards fault-tolerant quantum\ncomputing will require an understanding of the underlying error mechanisms in\nlogical primitives as they relate to the performance of quantum error\ncorrection. In this work we demonstrate the novel capability to characterize\nthe physical error properties relevant to fault-tolerant operations via cycle\nerror reconstruction. We illustrate this diagnostic capability for a\ntransversal CNOT, a prototypical component of quantum logical operations, in a\n16-qubit register of a trapped-ion quantum computer. Our error characterization\ntechnique offers three key capabilities: (i) identifying context-dependent\nphysical layer errors, enabling their mitigation; (ii) contextualizing\ncomponent gates in the environment of logical operators, validating the\nperformance differences in terms of characterized component-level physics, and\n(iii) providing a scalable method for predicting quantum error correction\nperformance using pertinent error terms, differentiating correctable versus\nuncorrectable physical layer errors. The methods with which our results are\nobtained have scalable resource requirements that can be extended with moderate\noverhead to capture overall logical performance in increasingly large and\ncomplex systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T11:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.12012v1","title":"Purposefully Induced Psychosis (PIP): Embracing Hallucination as\n  Imagination in Large Language Models","summary":"Hallucinations in Large Language Models (LLMs) are widely regarded as errors\n- outputs that deviate from factual accuracy. However, in creative or\nexploratory contexts, these \"mistakes\" may represent unexpected avenues for\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\nHerman Melville's Moby-Dick, where Pip's \"madness\" reveals profound insight, we\nreframe hallucinations as a source of computational imagination rather than a\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\nsurreal outputs - hallucinations that are useful when factual accuracy is not\nthe chief objective. Inspired by the consensual illusions of theater and stage\nmagic, PIP situates these creative missteps in contexts where users willingly\nsuspend disbelief, thereby transforming \"errors\" into catalysts for new ways of\nthinking. We discuss potential applications, design principles for ensuring\nuser consent, preliminary observations, and implications for broader AI ethics\nand human-AI collaboration.","main_category":"cs.AI","categories":"cs.AI,cs.HC","published":"2025-04-16T12:13:02Z"}
{"aid":"http://arxiv.org/abs/2504.12019v1","title":"Computational Aspects of the Short Resolution","summary":"Let $R:= \\Bbbk[x_1,\\ldots,x_{n}]$ be a polynomial ring over a field $\\Bbbk$,\n$I \\subset R$ be a homogeneous ideal with respect to a weight vector $\\omega =\n(\\omega_1,\\ldots,\\omega_n) \\in (\\mathbb{Z}^+)^n$, and denote by $d$ the Krull\ndimension of $R/I$. In this paper we study graded free resolutions of $R/I$ as\n$A$-module whenever $A :=\\Bbbk[x_{n-d+1},\\ldots,x_n]$ is a Noether\nnormalization of $R/I$. We exhibit a Schreyer-like method to compute a\n(non-necessarily minimal) graded free resolution of $R/I$ as $A$-module. When\n$R/I$ is a $3$-dimensional simplicial toric ring, we describe how to prune the\nprevious resolution to obtain a minimal one. We finally provide an example of a\n$6$-dimensional simplicial toric ring whose Betti numbers, both as $R$-module\nand as $A$-module, depend on the characteristic of $\\Bbbk$.","main_category":"math.AC","categories":"math.AC,math.AG","published":"2025-04-16T12:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.12026v1","title":"Neumaier graphs from cyclotomy with small coherent rank","summary":"Using cyclotomy, we construct a new infinite family of Neumaier graphs that\nincludes infinitely many strongly regular graphs. Notably, this family\nconjecturally contains infinitely many graphs with coherent rank $6$. Our\nconstruction also provides the first known examples that answer a question\nposed by Evans, Goryainov, and Panasenko regarding the existence of Neumaier\ngraphs whose nexus is not a power of $2$. In addition, we show that a\nconstruction of Greaves and Koolen yields an infinite family of Neumaier graphs\nwith coherent rank $6$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T12:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12029v1","title":"Object Placement for Anything","summary":"Object placement aims to determine the appropriate placement (\\emph{e.g.},\nlocation and size) of a foreground object when placing it on the background\nimage. Most previous works are limited by small-scale labeled dataset, which\nhinders the real-world application of object placement. In this work, we devise\na semi-supervised framework which can exploit large-scale unlabeled dataset to\npromote the generalization ability of discriminative object placement models.\nThe discriminative models predict the rationality label for each foreground\nplacement given a foreground-background pair. To better leverage the labeled\ndata, under the semi-supervised framework, we further propose to transfer the\nknowledge of rationality variation, \\emph{i.e.}, whether the change of\nforeground placement would result in the change of rationality label, from\nlabeled data to unlabeled data. Extensive experiments demonstrate that our\nframework can effectively enhance the generalization ability of discriminative\nobject placement models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:39:00Z"}
{"aid":"http://arxiv.org/abs/2504.12030v1","title":"Planetary albedo is limited by the above-cloud atmosphere: Implications\n  for sub-Neptune climate","summary":"Energy limits that delineate the `habitable zone' for exoplanets depend on a\ngiven exoplanet's net planetary albedo (or `Bond albedo'). We here demonstrate\nthat the planetary albedo of an observed exoplanet is limited by the\nabove-cloud atmosphere - the region of the atmosphere that is probed in remote\nobservation. We derive an analytic model to explore how the maximum planetary\nalbedo depends on the above-cloud optical depth and scattering versus absorbing\nproperties, even in the limit of a perfectly reflective grey cloud layer. We\napply this framework to sub-Neptune K2-18b, for which a high planetary albedo\nhas recently been invoked to argue for the possibility of maintaining a liquid\nwater ocean surface, despite K2-18b receiving an energy flux from its host star\nthat places it inside of its estimated `habitable zone' inner edge. We use a\nnumerical multiple-scattering line-by-line radiative transfer model to retrieve\nthe albedo of K2-18b based on the observational constraints from the\nabove-cloud atmosphere. Our results demonstrate that K2-18b's observed\ntransmission spectrum already restricts its possible planetary albedo to values\nbelow the threshold required to be potentially habitable, with the data\nfavouring a median planetary albedo of 0.17-0.18. Our results thus reveal that\ncurrently characteriseable sub-Neptunes are likely to be magma-ocean or\ngas-dwarf worlds. The methods that we present are generally applicable to\nconstrain the planetary albedo of any exoplanet with measurements of its\nobservable atmosphere, enabling the quantification of potential exoplanet\nhabitability with current observational capabilities.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T12:39:54Z"}
{"aid":"http://arxiv.org/abs/2504.12035v1","title":"Enhancement of primordial curvature perturbations in $R^3$-corrected\n  Starobinsky-Higgs inflation","summary":"We provide a systematic study of the Starobinsky-Higgs inflation model in the\npresence of an additional cubic term of the Ricci scalar. We investigate, in\nparticular, the effects of the cubic term on the spectral index $n_s$ and the\ntensor-to-scalar ratio $r$. Through both analytical and numerical analyses, we\nshow that the $R^3$-corrected Starobinsky-Higgs model can achieve compatibility\nwith cosmic microwave background observations while producing distinct\nobservational signatures with different frequency ranges. In addition, we\ndiscuss the complementarity between different observational probes, including\nthe scalar-induced gravitational waves and spectral distortions, offering an\nindependent probe of the enhanced curvature perturbations. Detection prospects\nare also discussed.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-16T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.12058v1","title":"ProvSQL: A General System for Keeping Track of the Provenance and\n  Probability of Data","summary":"We present the data model, design choices, and performance of ProvSQL, a\ngeneral and easy-to-deploy provenance tracking and probabilistic database\nsystem implemented as a PostgreSQL extension. ProvSQL's data and query models\nclosely reflect that of a large core of SQL, including multiset semantics, the\nfull relational algebra, and terminal aggregation. A key part of its\nimplementation relies on generic provenance circuits stored in memory-mapped\nfiles. We propose benchmarks to measure the overhead of provenance and\nprobabilistic evaluation and demonstrate its scalability and competitiveness\nwith respect to other state-of-the-art systems.","main_category":"cs.DB","categories":"cs.DB,H.2.4","published":"2025-04-16T13:11:07Z"}
{"aid":"http://arxiv.org/abs/2504.12080v1","title":"DC-SAM: In-Context Segment Anything in Images and Videos via Dual\n  Consistency","summary":"Given a single labeled example, in-context segmentation aims to segment\ncorresponding objects. This setting, known as one-shot segmentation in few-shot\nlearning, explores the segmentation model's generalization ability and has been\napplied to various vision tasks, including scene understanding and image/video\nediting. While recent Segment Anything Models have achieved state-of-the-art\nresults in interactive segmentation, these approaches are not directly\napplicable to in-context segmentation. In this work, we propose the Dual\nConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2\nfor in-context segmentation of both images and videos. Our key insights are to\nenhance the features of the SAM's prompt encoder in segmentation by providing\nhigh-quality visual prompts. When generating a mask prior, we fuse the SAM\nfeatures to better align the prompt encoder. Then, we design a cycle-consistent\ncross-attention on fused features and initial visual prompts. Next, a\ndual-branch design is provided by using the discriminative positive and\nnegative prompts in the prompt encoder. Furthermore, we design a simple\nmask-tube training strategy to adopt our proposed dual consistency method into\nthe mask tube. Although the proposed DC-SAM is primarily designed for images,\nit can be seamlessly extended to the video domain with the support of SAM2.\nGiven the absence of in-context segmentation in the video domain, we manually\ncurate and construct the first benchmark from existing video segmentation\ndatasets, named In-Context Video Object Segmentation (IC-VOS), to better assess\nthe in-context capability of the model. Extensive experiments demonstrate that\nour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on\nPASCAL-5i, and a J&F score of 71.52 on the proposed IC-VOS benchmark. Our\nsource code and benchmark are available at https://github.com/zaplm/DC-SAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T13:41:59Z"}
{"aid":"http://arxiv.org/abs/2504.12089v1","title":"Accelerating MCMC with Quantum Walks: Design, Implementation, and\n  Results","summary":"Markov Chain Monte Carlo (MCMC) methods are algorithms for sampling\nprobability distributions, often applied to the Boltzmann distribution in\nphysical and chemical models, such as protein folding and the Ising model.\nThese methods enable the study of such systems by sampling their most probable\nstates. However, sampling multidimensional and multimodal distributions with\nMCMC demands significant computational resources, leading to the development of\ntechniques aimed at improving sampling efficiency. In this context, quantum\ncomputing, with its potential to accelerate classical methods, emerges as a\npromising solution to the sampling problem. In this work, we present the design\nand implementation of a novel MCMC algorithm (QMCMC) based on the Discrete\nQuantum Walk (DQW) algorithm. We test several Gaussian distributions, including\nmixtures and demonstrate that it effectively captures the structure of the\ntarget distribution by leveraging quantum superposition. In addition, we\nintroduce a circuit extension that significantly improves convergence speed,\nwhich in turn enhances the scalability of the algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.12102v1","title":"Successive-Cancellation Flip and Perturbation Decoder of Polar Codes","summary":"In this paper, two decoding algorithms based on Successive Cancellation (SC)\nare proposed to improve the error-correction performance of cyclic redundancy\ncheck (CRC)-aided polar codes while aiming for a low-complexity implementation.\nComparisons with Dynamic SC Flip (DSCF) and SC Perturbation (SCP) are carried\nout since the proposed DSCF and Perturbation (DSCFP) and Perturbed DSCF (PDSCF)\nalgorithms combine both methods. The analysis includes comparisons with several\ncode lengths $N$ and various number of decoding attempts $T_{max}$. For\n$N=1024$ and the coding rate $R=\\frac{1}{2}$, the DSCFP and the SCP algorithms\nwith $T_{max}=17$ are bested by approximately $0.1$\\,dB at block error rate\n(BLER) of $0.001$. At $\\text{BLER}=10^{-6}$ and for $T_{max}=64$, the gain is\nof $0.375$ dB and $>0.5$ dB with respect to DSCF and SCP, respectively. At high\nsignal-to-noise ratio, the average computational complexity of the proposed\nalgorithms is virtually equivalent to that of SC.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T14:08:25Z"}
{"aid":"http://arxiv.org/abs/2504.12105v1","title":"Can asteroid-mass PBHDM be compatible with catalyzed phase transition\n  interpretation of PTA?","summary":"Primordial black holes (PBHs) can catalyze first-order phase transitions\n(FOPTs) in their vicinity, potentially modifying the gravitational wave (GW)\nsignals from PTs. In this study, we present the first comprehensive analysis of\nthis catalytic effect during supercooled PTs within the high PBH number density\nregime. Applying the analytical model with envelope approximation, we derive\nthe general expressions of GW spectrum in the presence of PBHs. We find that at\nrelatively small PBH number densities, the GW signals are amplified due to the\nlarge-size bubbles. While higher PBH number densities suppress GW signals,\nsince the accelerated PT progresses too rapidly. We further extend our findings\nto the bulk flow model and to scalar-induced GWs (SIGWs) generated during PTs.\nBy conducting data fitting with the NANOGrav 15-year dataset, we find that the\nPBH catalytic effect significantly alters the estimation of PT parameters.\nNotably, our analysis of the bubble collision GWs reveals that, the\nasteroid-mass PBHs ($10^{-16} - 10^{-12} M_\\odot$) as the whole dark matter is\nincompatible with the PT interpretation of pulsar timing array signals.\nHowever, incorporating SIGWs can reduce this incompatibility for PBHs in the\nmass range $10^{-14} - 10^{-12} M_\\odot$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-16T14:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.12112v1","title":"A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image\n  Reconstruction","summary":"Remote sensing imagery is essential for environmental monitoring,\nagricultural management, and disaster response. However, data loss due to cloud\ncover, sensor failures, or incomplete acquisition-especially in high-resolution\nand high-frequency tasks-severely limits satellite imagery's effectiveness.\nTraditional interpolation methods struggle with large missing areas and complex\nstructures. Remote sensing imagery consists of multiple bands, each with\ndistinct meanings, and ensuring consistency across bands is critical to avoid\nanomalies in the combined images. This paper proposes SatelliteMaker, a\ndiffusion-based method that reconstructs missing data across varying levels of\ndata loss while maintaining spatial, spectral, and temporal consistency. We\nalso propose Digital Elevation Model (DEM) as a conditioning input and use\ntailored prompts to generate realistic images, making diffusion models\napplicable to quantitative remote sensing tasks. Additionally, we propose a\nVGG-Adapter module based on Distribution Loss, which reduces distribution\ndiscrepancy and ensures style consistency. Extensive experiments show that\nSatelliteMaker achieves state-of-the-art performance across multiple tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.12125v1","title":"EmoACT: a Framework to Embed Emotions into Artificial Agents Based on\n  Affect Control Theory","summary":"As robots and artificial agents become increasingly integrated into daily\nlife, enhancing their ability to interact with humans is essential. Emotions,\nwhich play a crucial role in human interactions, can improve the naturalness\nand transparency of human-robot interactions (HRI) when embodied in artificial\nagents. This study aims to employ Affect Control Theory (ACT), a psychological\nmodel of emotions deeply rooted in interaction, for the generation of synthetic\nemotions. A platform-agnostic framework inspired by ACT was developed and\nimplemented in a humanoid robot to assess its impact on human perception.\nResults show that the frequency of emotional displays impacts how users\nperceive the robot. Moreover, appropriate emotional expressions seem to enhance\nthe robot's perceived emotional and cognitive agency. The findings suggest that\nACT can be successfully employed to embed synthetic emotions into robots,\nresulting in effective human-robot interactions, where the robot is perceived\nmore as a social agent than merely a machine.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.12160v1","title":"On the counting function of cubic function fields","summary":"We study the counting function for cubic function fields, extending results\nof Zhao, who proved the existence of a secondary term in this counting\nfunction. Specifically, we improve the error term in the estimate for this\ncounting function to $\\mathcal{O}\\big(X^{2/3+\\epsilon}\\big)$, which matches the\nbest-known result, due to Bhargava, Taniguchi and Thorne, over $\\mathbb{Q}$.\nFurthermore, we obtain estimates for the refined counting function, where one\nspecifies the splitting behaviour of finitely many primes. Also in this case,\nour error term matches what is known for number fields. However, in the\nfunction field setting, the secondary term becomes more difficult to write down\nexplicitly.\n  Our proof uses geometry of numbers methods, which are especially effective\nfor function fields. In particular, we obtain an exact formula for the number\nof orbits of cubic forms with fixed absolute discriminant. Moreover, by\nstudying the one-level density of a family of Artin $L$-functions associated to\nthese cubic fields, we prove an unconditional lower bound on the error term in\nthe estimate for the refined counting function. This generalises a conditional\nresult over $\\mathbb{Q}$, due to Cho, Fiorilli, Lee and S\\\"odergren.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T15:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.12178v1","title":"Search for additional scalar bosons within the Inert Doublet Model in a\n  final state with two leptons at the FCC-ee","summary":"In this work, we investigate the discovery reach of a new physics model, the\nInert Doublet Model, at an $e^+e^-$ machine with centre-of-mass energies\n$\\sqrt{s}$ of 240 and 365 GeV. Within this model, four additional scalar bosons\n($H$, $A$, $H^+$ and $H^-$) are predicted. Due to an additional symmetry, the\nlightest new scalar, here chosen to be $H$, is stable and provides an adequate\ndark matter candidate. The search for pair production of the new scalars is\ninvestigated in final states with two electrons or two muons, in the context of\nthe future circular collider proposal, FCC-ee. Building on previous studies in\nthe context of the CLIC proposal, this analysis extends the search to\ndetector-level objects, using a parametric neural network to enhance the signal\ncontributions over the Standard Model backgrounds, and sets limits in the\n$m_A-m_H$ vs $m_H$ plane. With a total integrated luminosity of 10.8 (2.7)\nab$^{-1}$ for $\\sqrt{s}=240$ (365) GeV, almost the entire phase-space available\nin the $m_A-m_H$ vs $m_H$ plane is expected to be excluded at 95% CL, reaching\nup to $m_H=110$ (165) GeV. The discovery reach is also explored, reaching $m_H=\n108$ (157) GeV for $m_A-m_H=15$ GeV at $\\sqrt{s}=240$ (365) GeV.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-16T15:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.12180v1","title":"Trusting CHATGPT: how minor tweaks in the prompts lead to major\n  differences in sentiment classification","summary":"One fundamental question for the social sciences today is: how much can we\ntrust highly complex predictive models like ChatGPT? This study tests the\nhypothesis that subtle changes in the structure of prompts do not produce\nsignificant variations in the classification results of sentiment polarity\nanalysis generated by the Large Language Model GPT-4o mini. Using a dataset of\n100.000 comments in Spanish on four Latin American presidents, the model\nclassified the comments as positive, negative, or neutral on 10 occasions,\nvarying the prompts slightly each time. The experimental methodology included\nexploratory and confirmatory analyses to identify significant discrepancies\namong classifications.\n  The results reveal that even minor modifications to prompts such as lexical,\nsyntactic, or modal changes, or even their lack of structure impact the\nclassifications. In certain cases, the model produced inconsistent responses,\nsuch as mixing categories, providing unsolicited explanations, or using\nlanguages other than Spanish. Statistical analysis using Chi-square tests\nconfirmed significant differences in most comparisons between prompts, except\nin one case where linguistic structures were highly similar.\n  These findings challenge the robustness and trust of Large Language Models\nfor classification tasks, highlighting their vulnerability to variations in\ninstructions. Moreover, it was evident that the lack of structured grammar in\nprompts increases the frequency of hallucinations. The discussion underscores\nthat trust in Large Language Models is based not only on technical performance\nbut also on the social and institutional relationships underpinning their use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.12212v1","title":"Idempotent compatible maps and discrete integrable systems on the\n  triangular lattice","summary":"We present three equivalence classes of rational non-invertible\nmultidimensional compatible maps. These maps turns out to be idempotent and by\nconstruction they admit birational partial inverses (companion maps) which are\nYang-Baxter maps. The maps in question can be reinterpreted as systems of\ndifference equations defined on the edges of the $\\mathbb{Z}^2$ graph. Finally,\nwe associate these compatible systems of difference equations with integrable\ndifference equations defined on the triangular lattice $Q(A2)$.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-16T15:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.12228v1","title":"Data Assimilation for Robust UQ Within Agent-Based Simulation on HPC\n  Systems","summary":"Agent-based simulation provides a powerful tool for in silico system\nmodeling. However, these simulations do not provide built-in methods for\nuncertainty quantification (UQ). Within these types of models a typical\napproach to UQ is to run multiple realizations of the model then compute\naggregate statistics. This approach is limited due to the compute time required\nfor a solution. When faced with an emerging biothreat, public health decisions\nneed to be made quickly and solutions for integrating near real-time data with\nanalytic tools are needed.\n  We propose an integrated Bayesian UQ framework for agent-based models based\non sequential Monte Carlo sampling. Given streaming or static data about the\nevolution of an emerging pathogen, this Bayesian framework provides a\ndistribution over the parameters governing the spread of a disease through a\npopulation. These estimates of the spread of a disease may be provided to\npublic health agencies seeking to abate the spread.\n  By coupling agent-based simulations with Bayesian modeling in a data\nassimilation, our proposed framework provides a powerful tool for modeling\ndynamical systems in silico. We propose a method which reduces model error and\nprovides a range of realistic possible outcomes. Moreover, our method addresses\ntwo primary limitations of ABMs: the lack of UQ and an inability to assimilate\ndata. Our proposed framework combines the flexibility of an agent-based model\nwith UQ provided by the Bayesian paradigm in a workflow which scales well to\nHPC systems. We provide algorithmic details and results on a simulated outbreak\nwith both static and streaming data.","main_category":"stat.AP","categories":"stat.AP,stat.CO","published":"2025-04-16T16:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.12252v1","title":"Electric field tunable spin-orbit gap in a bilayer graphene/WSe$_{2}$\n  quantum dot","summary":"We report on the investigation of proximity-induced spin-orbit coupling (SOC)\nin a heterostructure of bilayer graphene (BLG) and tungsten diselenide\n(WSe$_2$). A BLG quantum dot (QD) in the few-particle regime acts as a\nsensitive probe for induced SOC. Finite bias and magnetotransport spectroscopy\nmeasurements reveal a significantly enhanced SOC that decreases with the\napplied displacement field, distinguishing it from pristine BLG. We attribute\nthis tunability to an increased layer localization of the QD states on the BLG\nlayer distant to the WSe$_2$. Furthermore, our measurements demonstrate a\nreduced valley $g$-factor at larger displacement fields, consistent with a\nweaker lateral confinement of the QD. Our findings show evidence of the\ninfluence of WSe$_2$ across BLG layers, driven by reduced real-space\nconfinement and increased layer localization at higher displacement fields.\nThis study demonstrates the electrostatic tunability of spin-orbit gap in\nBLG/WSe$_2$ heterostructures, which is especially relevant for the field of\nspintronics and future spin qubit control in BLG QDs.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-16T16:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.12288v1","title":"The underlap coefficient as a measure of a biomarker's discriminatory\n  ability","summary":"The first step in evaluating a potential diagnostic biomarker is to examine\nthe variation in its values across different disease groups. In a three-class\ndisease setting, the volume under the receiver operating characteristic surface\nand the three-class Youden index are commonly used summary measures of a\nbiomarker's discriminatory ability. However, these measures rely on a\nstochastic ordering assumption for the distributions of biomarker outcomes\nacross the three groups. This assumption can be restrictive, particularly when\ncovariates are involved, and its violation may lead to incorrect conclusions\nabout a biomarker's ability to distinguish between the three disease classes.\nEven when a stochastic ordering exists, the order may vary across different\nbiomarkers in discovery studies involving dozens or even thousands of candidate\nbiomarkers, complicating automated ranking. To address these challenges and\ncomplement existing measures, we propose the underlap coefficient, a novel\nsummary index of a biomarker's ability to distinguish between three (or more)\ndisease groups, and study its properties. Additionally, we introduce Bayesian\nnonparametric estimators for both the unconditional underlap coefficient and\nits covariate-specific counterpart. These estimators are broadly applicable to\na wide range of biomarkers and populations. A simulation study reveals a good\nperformance of the proposed estimators across a range of conceivable scenarios.\nWe illustrate the proposed approach through an application to an Alzheimer's\ndisease (AD) dataset aimed to assess how four potential AD biomarkers\ndistinguish between individuals with normal cognition, mild impairment, and\ndementia, and how and if age and gender impact this discriminatory ability.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T17:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.12299v1","title":"Adapting a World Model for Trajectory Following in a 3D Game","summary":"Imitation learning is a powerful tool for training agents by leveraging\nexpert knowledge, and being able to replicate a given trajectory is an integral\npart of it. In complex environments, like modern 3D video games, distribution\nshift and stochasticity necessitate robust approaches beyond simple action\nreplay. In this study, we apply Inverse Dynamics Models (IDM) with different\nencoders and policy heads to trajectory following in a modern 3D video game --\nBleeding Edge. Additionally, we investigate several future alignment strategies\nthat address the distribution shift caused by the aleatoric uncertainty and\nimperfections of the agent. We measure both the trajectory deviation distance\nand the first significant deviation point between the reference and the agent's\ntrajectory and show that the optimal configuration depends on the chosen\nsetting. Our results show that in a diverse data setting, a GPT-style policy\nhead with an encoder trained from scratch performs the best, DINOv2 encoder\nwith the GPT-style policy head gives the best results in the low data regime,\nand both GPT-style and MLP-style policy heads had comparable results when\npre-trained on a diverse setting and fine-tuned for a specific behaviour\nsetting.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-16T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.12614v1","title":"From Regulation to Support: Centering Humans in Technology-Mediated\n  Emotion Intervention in Care Contexts","summary":"Enhancing emotional well-being has become a significant focus in HCI and\nCSCW, with technologies increasingly designed to track, visualize, and manage\nemotions. However, these approaches have faced criticism for potentially\nsuppressing certain emotional experiences. Through a scoping review of 53\nempirical studies from ACM proceedings implementing Technology-Mediated Emotion\nIntervention (TMEI), we critically examine current practices through lenses\ndrawn from HCI critical theories. Our analysis reveals emotion intervention\nmechanisms that extend beyond traditional emotion regulation paradigms,\nidentifying care-centered goals that prioritize non-judgmental emotional\nsupport and preserve users' identities. The findings demonstrate how\nresearchers design technologies for generating artificial care, intervening in\npower dynamics, and nudging behavioral changes. We contribute the concept of\n\"emotion support\" as an alternative approach to \"emotion regulation,\"\nemphasizing human-centered approaches to emotional well-being. This work\nadvances the understanding of diverse human emotional needs beyond individual\nand cognitive perspectives, offering design implications that critically\nreimagine how technologies can honor emotional complexity, preserve human\nagency, and transform power dynamics in care contexts.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T03:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.12623v1","title":"Privacy-Preserving CNN Training with Transfer Learning: Two Hidden\n  Layers","summary":"In this paper, we present the demonstration of training a four-layer neural\nnetwork entirely using fully homomorphic encryption (FHE), supporting both\nsingle-output and multi-output classification tasks in a non-interactive\nsetting. A key contribution of our work is identifying that replacing\n\\textit{Softmax} with \\textit{Sigmoid}, in conjunction with the Binary\nCross-Entropy (BCE) loss function, provides an effective and scalable solution\nfor homomorphic classification. Moreover, we show that the BCE loss function,\noriginally designed for multi-output tasks, naturally extends to the\nmulti-class setting, thereby enabling broader applicability. We also highlight\nthe limitations of prior loss functions such as the SLE loss and the one\nproposed in the 2019 CVPR Workshop, both of which suffer from vanishing\ngradients as network depth increases. To address the challenges posed by\nlarge-scale encrypted data, we further introduce an improved version of the\npreviously proposed data encoding scheme, \\textit{Double Volley Revolver},\nwhich achieves a better trade-off between computational and memory efficiency,\nmaking FHE-based neural network training more practical. The complete, runnable\nC++ code to implement our work can be found at:\n\\href{https://github.com/petitioner/ML.NNtraining}{$\\texttt{https://github.com/petitioner/ML.NNtraining}$}.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T03:58:23Z"}
{"aid":"http://arxiv.org/abs/2504.12634v1","title":"Toponium: Implementation of a toponium model in FeynRules","summary":"Toponium -- a bound state of the top-antitop pair ($t\\bar{t}$) -- emerges as\nthe smallest and simplest hadronic system in QCD, with an ultrashort lifetime\n($\\tau_t \\sim 2.5\\times 10^{-25}$~s) and a femtometer-scale Bohr radius\n($r_{\\text{Bohr}} \\sim 7\\times 10^{-18}$~m). We present a computational\nframework extending the Standard Model (SM) with two S-wave toponium states: a\nspin-singlet $\\eta_t$ ($J^{PC}=0^{-+}$) and a spin-triplet $J_t$\n($J^{PC}=1^{--}$). Using nonrelativistic QCD (NRQCD) and a Coulomb potential,\nwe derived couplings to SM particles (gluons, electroweak bosons, Higgs boson,\nand fermion pairs) and implemented the Lagrangian in FeynRules, generating\nFeynArts, MadGraph, and WHIZARD models for collider simulations. Key results\ninclude dominant decay channels ($\\eta_t \\to gg/ZH$, $J_t \\to W^+W^-/b\\bar{b}$)\nand leading order (LO) cross sections for $pp \\to \\eta_t(nS) \\to {\\rm\nnon-}t\\bar{t}$ ({66 fb} at 13 TeV). The model avoids double-counting artifacts\nby excluding direct $t\\bar{t}$ couplings, thereby ensuring consistency with\nperturbative QCD. This work establishes a complete pipeline for precision\ntoponium studies, bridging NRQCD, collider phenomenology, and tests of SM\nvalidity at future lepton colliders (e.g., CEPC, FCC-ee, muon colliders) and\nthe LHC. This provides the first publicly available UFO model for toponium,\nenabling direct integration with MadGraph and WHIZARD for simulations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T04:31:54Z"}
{"aid":"http://arxiv.org/abs/2504.12637v1","title":"Scaling Instruction-Tuned LLMs to Million-Token Contexts via\n  Hierarchical Synthetic Data Generation","summary":"Large Language Models (LLMs) struggle with long-context reasoning, not only\ndue to the quadratic scaling of computational complexity with sequence length\nbut also because of the scarcity and expense of annotating long-context data.\nThere has been barely any open-source work that systematically ablates\nlong-context data, nor is there any openly available instruction tuning dataset\nwith contexts surpassing 100K tokens. To bridge this gap, we introduce a novel\npost-training synthetic data generation strategy designed to efficiently extend\nthe context window of LLMs while preserving their general task performance. Our\napproach scalably extends to arbitrarily long context lengths, unconstrained by\nthe length of available real-world data, which effectively addresses the\nscarcity of raw long-context data. Through a step-by-step rotary position\nembedding (RoPE) scaling training strategy, we demonstrate that our model, with\na context length of up to 1M tokens, performs well on the RULER benchmark and\nInfiniteBench and maintains robust performance on general language tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T04:46:57Z"}
{"aid":"http://arxiv.org/abs/2504.12671v1","title":"Generalized Legendrian racks: Classification, tensors, and knot coloring\n  invariants","summary":"Generalized Legendrian racks are nonassociative algebraic structures based on\nthe Legendrian Reidemeister moves. We study algebraic aspects of GL-racks and\ncoloring invariants of Legendrian links.\n  We answer an open question characterizing the group of GL-structures on a\ngiven rack. As applications, we classify several infinite families of GL-racks.\nWe also compute automorphism groups of dihedral GL-quandles and the categorical\ncenter of GL-racks.\n  Then we construct an equivalence of categories between racks and GL-quandles.\n  We also study tensor products of racks and GL-racks coming from universal\nalgebra. Surprisingly, the categories of racks and GL-racks have tensor units.\nThe induced symmetric monoidal structure on medial racks is closed, and\nsimilarly for medial GL-racks.\n  Answering another open question, we use GL-racks to distinguish Legendrian\nknots whose classical invariants are identical. In particular, we complete the\nclassification of Legendrian $8_{13}$ knots.\n  Finally, we use exhaustive search algorithms to classify GL-racks up to order\n8.","main_category":"math.GT","categories":"math.GT,math.GR,math.QA","published":"2025-04-17T06:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.12685v1","title":"High Breakdown Electric Field (> 5 MV/cm) in UWBG AlGaN Transistors","summary":"We report on the design and demonstration of ultra-wide bandgap (UWBG)\nAlGaN-channel metal-insulator heterostructure field effect transistors (HEFTs)\nfor high-power, high-frequency applications. We find that the integration of\ngate dielectrics and field plates greatly improves the breakdown field in these\ndevices, with state-of-art average breakdown field of 5.3 MV/cm (breakdown\nvoltage > 260 V) with an associated maximum current density of 342 mA/mm, and\ncut-off frequency of 9.1 GHz. Furthermore, low trap-related impact was observed\nfrom minimal gate and drain lag estimated from pulsed I-V characteristics. The\nreported results provide the potential of UWBG AlGaN HEFTs for the next\ngeneration high-power radio frequency applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-17T06:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.12694v1","title":"$D \\bar D_1(2420)$ and $D^* \\bar D^*(2400)$ molecular states: Probing\n  their electromagnetic fingerprints","summary":"As in previous decades, a comprehensive understanding of the intricate\ninternal configuration of hadrons continues to be a central objective within\nboth experimental and theoretical hadron physics. This pursuit plays a pivotal\nrole in advancing our knowledge of QCD and critically evaluating the robustness\nand accuracy of the theoretical models developed to date. Furthermore,\ndeciphering the underlying mechanisms of exotic states, both those currently\nobserved and those anticipated in future experiments, remains a pressing and\nunresolved challenge. Motivated by this, in the present study, we investigate\nthe electromagnetic properties of the $D \\bar D_1(2420)$ and $D^* \\bar\nD^*(2400)$ molecular tetraquark states with quantum numbers $J^{PC} = 1^{--}$,\nusing the QCD light-cone sum rule method. These states are analyzed within a\nhadronic molecular framework, where their magnetic and quadrupole moments are\ncomputed to probe internal structure and geometric deformation. Our results\nreveal distinct electromagnetic signatures, with the magnetic moments primarily\ndominated by light-quark contributions, and the quadrupole moments suggesting\nan oblate charge distribution. The findings are compared with prior studies\nassuming compact tetraquark configurations, emphasizing the sensitivity of\nelectromagnetic observables to the underlying hadronic structure. This analysis\nprovides critical insights into the nature of exotic hadrons and contributes to\nthe broader understanding of QCD dynamics in the non-perturbative regime.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat","published":"2025-04-17T06:41:44Z"}
{"aid":"http://arxiv.org/abs/2504.12708v1","title":"Ultrafast dynamics of vibronically dressed core-excitons in graphite: a\n  femtosecond RIXS perspective","summary":"This study demonstrates one of the first implementations of time-resolved\nresonant inelastic X-ray scattering (tr-RIXS), marking a seminal extension of\nRIXS spectroscopy into the ultrafast time domain. By investigating the\nultrafast dynamics of vibronically dressed core excitons in graphite using\nfemtosecond X-ray pulses from a Free Electron Laser, we reveal previously\ninaccessible insights into the transient coupling between core excitons and\nspecific optical phonon modes. Our approach establishes tr-RIXS as a powerful,\ntransformative tool capable of elucidating the intricate interplay between\nelectronic and lattice dynamics, opening new avenues in ultrafast materials\nresearch.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T07:25:38Z"}
{"aid":"http://arxiv.org/abs/2504.12723v1","title":"KODIS: A Multicultural Dispute Resolution Dialogue Corpus","summary":"We present KODIS, a dyadic dispute resolution corpus containing thousands of\ndialogues from over 75 countries. Motivated by a theoretical model of culture\nand conflict, participants engage in a typical customer service dispute\ndesigned by experts to evoke strong emotions and conflict. The corpus contains\na rich set of dispositional, process, and outcome measures. The initial\nanalysis supports theories of how anger expressions lead to escalatory spirals\nand highlights cultural differences in emotional expression. We make this\ncorpus and data collection framework available to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T07:57:31Z"}
{"aid":"http://arxiv.org/abs/2504.12732v1","title":"Validating LLM-Generated Relevance Labels for Educational Resource\n  Search","summary":"Manual relevance judgements in Information Retrieval are costly and require\nexpertise, driving interest in using Large Language Models (LLMs) for automatic\nassessment. While LLMs have shown promise in general web search scenarios,\ntheir effectiveness for evaluating domain-specific search results, such as\neducational resources, remains unexplored. To investigate different ways of\nincluding domain-specific criteria in LLM prompts for relevance judgement, we\ncollected and released a dataset of 401 human relevance judgements from a user\nstudy involving teaching professionals performing search tasks related to\nlesson planning. We compared three approaches to structuring these prompts: a\nsimple two-aspect evaluation baseline from prior work on using LLMs as\nrelevance judges, a comprehensive 12-dimensional rubric derived from\neducational literature, and criteria directly informed by the study\nparticipants. Using domain-specific frameworks, LLMs achieved strong agreement\nwith human judgements (Cohen's $\\kappa$ up to 0.650), significantly\noutperforming the baseline approach. The participant-derived framework proved\nparticularly robust, with GPT-3.5 achieving $\\kappa$ scores of 0.639 and 0.613\nfor 10-dimension and 5-dimension versions respectively. System-level evaluation\nshowed that LLM judgements reliably identified top-performing retrieval\napproaches (RBO scores 0.71-0.76) while maintaining reasonable discrimination\nbetween systems (RBO 0.52-0.56). These findings suggest that LLMs can\neffectively evaluate educational resources when prompted with domain-specific\ncriteria, though performance varies with framework complexity and input\nstructure.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-17T08:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.12744v1","title":"Biasing the Driving Style of an Artificial Race Driver for Online\n  Time-Optimal Maneuver Planning","summary":"In this work, we present a novel approach to bias the driving style of an\nartificial race driver (ARD) for online time-optimal trajectory planning. Our\nmethod leverages a nonlinear model predictive control (MPC) framework that\ncombines time minimization with exit speed maximization at the end of the\nplanning horizon. We introduce a new MPC terminal cost formulation based on the\ntrajectory planned in the previous MPC step, enabling ARD to adapt its driving\nstyle from early to late apex maneuvers in real-time. Our approach is\ncomputationally efficient, allowing for low replan times and long planning\nhorizons. We validate our method through simulations, comparing the results\nagainst offline minimum-lap-time (MLT) optimal control and online minimum-time\nMPC solutions. The results demonstrate that our new terminal cost enables ARD\nto bias its driving style, and achieve online lap times close to the MLT\nsolution and faster than the minimum-time MPC solution. Our approach paves the\nway for a better understanding of the reasons behind human drivers' choice of\nearly or late apex maneuvers.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T08:35:28Z"}
{"aid":"http://arxiv.org/abs/2504.12751v1","title":"Optimisation of integrated luminosity in a circular collider with\n  application to the LHC Run 2","summary":"Circular collider designs are tailored to maximise luminosity delivered to\nexperimental detectors, effectively utilising the charged beams that have been\naccelerated for collisions. In reality, the key metric for the effective\noperation of a circular collider is the integrated luminosity provided to the\nexperiments, which can significantly differ from the theoretical capability\nregarding instantaneous luminosity of the accelerator. Several factors\ninfluence the collection of integrated luminosity, with the most critical being\nthe duration of each physics fill. This paper presents and examines strategies\nfor determining optimal fill durations based on actual fill conditions,\napplying these methods to public luminosity data measured by the ATLAS detector\nduring the LHC Run~2, covering the physics runs from 2016 to 2018.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-17T08:44:43Z"}
{"aid":"http://arxiv.org/abs/2504.12756v1","title":"Ultrafast laser high-aspect-ratio extreme nanostructuring of glass\n  beyond λ/100","summary":"The ultimate feature size is key in ultrafast laser material processing. A\ncapacity to signiicantly exceed optical limits and to structure below 100nm is\nessential to advance ultrafast processing into the field of metamaterials. Such\nachievement requires to combine the control of optical near-fields and of\nmaterial reactions, while preserving the exibility of long working distances,\ncompatible with a mature laser process. Using sub-ps and ps non-diffractive\nBessel beams, we demonstrate unprecedented feature sizes below a hundredth of\nthe incident 1$\\mu$m wavelength over an extended focus depth of tens of $\\mu$m.\nRecord features sizes, down to 7nm, result from self-generated near-field light\ncomponents initiated by cavities induced by far-field radiation in a\nback-surface illumination geometry. This sustains the generation of more\nconfined near-field evanescent components along the laser scan with nm pitch,\nperpendicular to the incident field direction, driving by local thermal\nablation a super-resolved laser structuring process. The near-field pattern is\nreplicated with high robustness, advancing towards a 10nm nanoscribing tool\nwith a $\\mu$m-sized laser pen. The process is controllable by the field\norientation. The non-diffractive irradiation develops evanescent fields over\nthe focusing length, resulting in a high aspect ratio trenching with nm section\nand $\\mu$m depth. Higher energy doses trigger the self-organization of\nquasi-periodic patterns seeded by spatially modulated scattering, similarly to\noptical modelocking. A predictive multipulse simulation method validates the\nfar-field-induced near-field electromagnetic scenario of void nanochannel\ngrowth and replication, indicating the processing range and resolution on the\nsurface and in the depth.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-17T08:48:58Z"}
{"aid":"http://arxiv.org/abs/2504.12793v1","title":"Nonlocal diffusion and pulse intervention in a faecal-oral model with\n  moving infected fronts","summary":"How individual dispersal patterns and human intervention behaviours affect\nthe spread of infectious diseases constitutes a central problem in\nepidemiological research. This paper develops an impulsive nonlocal faecal-oral\nmodel with free boundaries, where pulses are introduced to capture a periodic\nspraying of disinfectant, and nonlocal diffusion describes the long-range\ndispersal of individuals, and free boundaries represent moving infected fronts.\nWe first check that the model has a unique nonnegative global classical\nsolution. Then, the principal eigenvalue, which depends on the infected region,\nthe impulse intensity, and the kernel functions for nonlocal diffusion, is\nexamined by using the theory of resolvent positive operators and their\nperturbations. Based on this value, this paper obtains that the diseases are\neither vanishing or spreading, and provides criteria for determining when\nvanishing and spreading occur. At the end, a numerical example is presented in\norder to corroborate the theoretical findings and to gain further understanding\nof the effect of the pulse intervention. This work shows that the pulsed\nintervention is beneficial in combating the diseases, but the effect of the\nnonlocal diffusion depends on the choice of the kernel functions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T09:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.12798v1","title":"Relative Serre duality for Hecke categories","summary":"We prove a conjecture of Gorsky, Hogancamp, Mellit, and Nakagane in the Weyl\ngroup case. Namely, we show that the left and right adjoints of the parabolic\ninduction functor between the associated Hecke categories of Soergel bimodules\ndiffer by the relative full twist.","main_category":"math.RT","categories":"math.RT,math.AG","published":"2025-04-17T09:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.12801v1","title":"Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch","summary":"The performance gap between training sparse neural networks from scratch\n(PaI) and dense-to-sparse training presents a major roadblock for efficient\ndeep learning. According to the Lottery Ticket Hypothesis, PaI hinges on\nfinding a problem specific parameter initialization. As we show, to this end,\ndetermining correct parameter signs is sufficient. Yet, they remain elusive to\nPaI. To address this issue, we propose Sign-In, which employs a dynamic\nreparameterization that provably induces sign flips. Such sign flips are\ncomplementary to the ones that dense-to-sparse training can accomplish,\nrendering Sign-In as an orthogonal method. While our experiments and theory\nsuggest performance improvements of PaI, they also carve out the main open\nchallenge to close the gap between PaI and dense-to-sparse training.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-17T10:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.12826v1","title":"UncAD: Towards Safe End-to-end Autonomous Driving via Online Map\n  Uncertainty","summary":"End-to-end autonomous driving aims to produce planning trajectories from raw\nsensors directly. Currently, most approaches integrate perception, prediction,\nand planning modules into a fully differentiable network, promising great\nscalability. However, these methods typically rely on deterministic modeling of\nonline maps in the perception module for guiding or constraining vehicle\nplanning, which may incorporate erroneous perception information and further\ncompromise planning safety. To address this issue, we delve into the importance\nof online map uncertainty for enhancing autonomous driving safety and propose a\nnovel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty\nof the online map in the perception module. It then leverages the uncertainty\nto guide motion prediction and planning modules to produce multi-modal\ntrajectories. Finally, to achieve safer autonomous driving, UncAD proposes an\nuncertainty-collision-aware planning selection strategy according to the online\nmap uncertainty to evaluate and select the best trajectory. In this study, we\nincorporate UncAD into various state-of-the-art (SOTA) end-to-end methods.\nExperiments on the nuScenes dataset show that integrating UncAD, with only a\n1.9% increase in parameters, can reduce collision rates by up to 26% and\ndrivable area conflict rate by up to 42%. Codes, pre-trained models, and demo\nvideos can be accessed at https://github.com/pengxuanyang/UncAD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-17T10:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.12839v1","title":"Whitney Approximation: domains and bounds","summary":"We investigate properties of holomorphic extensions in the one-variable case\nof Whitney's Approximation Theorem on intervals. Improving a result of\nGauthier-Kienzle, we construct tangentially approximating functions which\nextend holomorphically to domains of optimal size. For approximands on\nunbounded closed intervals, we also bound the growth of holomorphic extensions,\nin the spirit of Arakelyan, Bernstein, Keldych, and Kober.","main_category":"math.CV","categories":"math.CV,math.CA","published":"2025-04-17T10:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.12840v1","title":"Note on conserved currents in static Conformal Killing Gravity","summary":"Conserved currents are discussed for static Conformal Killing Gravity, with\nexplicit expressions in static spherical symmetry with anisotropic matter fluid\nor coupled to (non)linear electromagnetism. They are found in the reformulation\nof the third order equations by Harada as Einstein equations with sources\nsupplemented by a divergence-free anisotropic conformal Killing tensor.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T10:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.12850v1","title":"iHHO-SMOTe: A Cleansed Approach for Handling Outliers and Reducing Noise\n  to Improve Imbalanced Data Classification","summary":"Classifying imbalanced datasets remains a significant challenge in machine\nlearning, particularly with big data where instances are unevenly distributed\namong classes, leading to class imbalance issues that impact classifier\nperformance. While Synthetic Minority Over-sampling Technique (SMOTE) addresses\nthis challenge by generating new instances for the under-represented minority\nclass, it faces obstacles in the form of noise and outliers during the creation\nof new samples. In this paper, a proposed approach, iHHO-SMOTe, which addresses\nthe limitations of SMOTE by first cleansing the data from noise points. This\nprocess involves employing feature selection using a random forest to identify\nthe most valuable features, followed by applying the Density-Based Spatial\nClustering of Applications with Noise (DBSCAN) algorithm to detect outliers\nbased on the selected features. The identified outliers from the minority\nclasses are then removed, creating a refined dataset for subsequent\noversampling using the hybrid approach called iHHO-SMOTe. The comprehensive\nexperiments across diverse datasets demonstrate the exceptional performance of\nthe proposed model, with an AUC score exceeding 0.99, a high G-means score of\n0.99 highlighting its robustness, and an outstanding F1-score consistently\nexceeding 0.967. These findings collectively establish Cleansed iHHO-SMOTe as a\nformidable contender in addressing imbalanced datasets, focusing on noise\nreduction and outlier handling for improved classification models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T11:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.12882v1","title":"ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection\n  in Videos","summary":"The growing influence of video content as a medium for communication and\nmisinformation underscores the urgent need for effective tools to analyze\nclaims in multilingual and multi-topic settings. Existing efforts in\nmisinformation detection largely focus on written text, leaving a significant\ngap in addressing the complexity of spoken text in video transcripts. We\nintroduce ViClaim, a dataset of 1,798 annotated video transcripts across three\nlanguages (English, German, Spanish) and six topics. Each sentence in the\ntranscripts is labeled with three claim-related categories: fact-check-worthy,\nfact-non-check-worthy, or opinion. We developed a custom annotation tool to\nfacilitate the highly complex annotation process. Experiments with\nstate-of-the-art multilingual language models demonstrate strong performance in\ncross-validation (macro F1 up to 0.896) but reveal challenges in generalization\nto unseen topics, particularly for distinct domains. Our findings highlight the\ncomplexity of claim detection in video transcripts. ViClaim offers a robust\nfoundation for advancing misinformation detection in video-based communication,\naddressing a critical gap in multimodal analysis.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T12:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.12883v1","title":"Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?","summary":"Implicit bias plays an important role in explaining how overparameterized\nmodels generalize well. Explicit regularization like weight decay is often\nemployed in addition to prevent overfitting. While both concepts have been\nstudied separately, in practice, they often act in tandem. Understanding their\ninterplay is key to controlling the shape and strength of implicit bias, as it\ncan be modified by explicit regularization. To this end, we incorporate\nexplicit regularization into the mirror flow framework and analyze its lasting\neffects on the geometry of the training dynamics, covering three distinct\neffects: positional bias, type of bias, and range shrinking. Our analytical\napproach encompasses a broad class of problems, including sparse coding, matrix\nsensing, single-layer attention, and LoRA, for which we demonstrate the utility\nof our insights. To exploit the lasting effect of regularization and highlight\nthe potential benefit of dynamic weight decay schedules, we propose to switch\noff weight decay during training, which can improve generalization, as we\ndemonstrate in experiments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T12:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.12890v1","title":"Euclidean Thermodynamics and Lyapunov Exponents of\n  Einstein-Power-Yang-Mills AdS Black Holes","summary":"We study the thermodynamics of Einstein-Power-Yang-Mills AdS black holes via\nthe Euclidean path integral method, incorporating appropriate boundary and\ncounterterms. By analyzing unstable timelike and null circular geodesics, we\ndemonstrate that their Lyapunov exponents reflect the thermodynamic phase\nstructure obtained from the Euclidean action. Specifically, the small-large\nblack hole phase transition, analogous to a van der Waals fluid, is signaled by\na discontinuity in the Lyapunov exponent. Treating this discontinuity as an\norder parameter, we observe a universal critical exponent of $1/2$, consistent\nwith mean-field theory. These results extend previous insights from black hole\nspacetimes with Abelian charges to scenarios involving nonlinear, non-Abelian\ngauge fields, highlighting the interplay between black hole thermodynamics and\nchaotic dynamics.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T12:31:32Z"}
{"aid":"http://arxiv.org/abs/2504.12894v1","title":"Homeomorphism type of the non-negative part of a complete toric variety","summary":"In this note we show that the nonnegative part of a proper complex toric\nvariety has the homeomorphism type of a sphere, and consequently that the\nnonnegative part has a natural structure of a cell complex. This extends\nprevious results of Ehlers and Jurkiewicz. The proof also provides a simplicial\ndecomposition of the nonnegative part, and a parameterization of each maximal\nsimplex.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12897v1","title":"OntoPortal-Astro, a Semantic Artefact Catalogue for Astronomy","summary":"The astronomy communities are widely recognised as mature communities for\ntheir open science practices. However, while their data ecosystems are rather\nadvanced and permit efficient data interoperability, there are still gaps\nbetween these ecosystems. Semantic artefacts (e.g., ontologies, thesauri,\nvocabularies or metadata schemas) are a means to bridge that gap as they allow\nto semantically described the data and map the underlying concepts. The\nincreasing use of semantic artefacts in astronomy presents challenges in\ndescription, selection, evaluation, trust, and mappings. The landscape remains\nfragmented, with semantic artefacts scattered across various registries in\ndiverse formats and structures -- not yet fully developed or encoded with rich\nsemantic web standards like OWL or SKOS -- and often with overlapping scopes.\nEnhancing data semantic interoperability requires common platforms to catalog,\nalign, and facilitate the sharing of FAIR semantic artefacts. In the frame of\nthe FAIR-IMPACT project, we prototyped a semantic artefact catalogue for\nastronomy, heliophysics and planetary sciences. This exercise resulted in\nimproved vocabulary and ontology management in the communities, and is now\npaving the way for better interdisciplinary data discovery and reuse. This\narticle presents current practices in our discipline, reviews candidate SAs for\nsuch a catalogue, presents driving use cases and the perspective of a real\nproduction service for the astronomy community based on the OntoPortal\ntechnology, that will be called OntoPortal-Astro.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.DL","published":"2025-04-17T12:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.12909v1","title":"Real-time High-fidelity Gaussian Human Avatars with Position-based\n  Interpolation of Spatially Distributed MLPs","summary":"Many works have succeeded in reconstructing Gaussian human avatars from\nmulti-view videos. However, they either struggle to capture pose-dependent\nappearance details with a single MLP, or rely on a computationally intensive\nneural network to reconstruct high-fidelity appearance but with rendering\nperformance degraded to non-real-time. We propose a novel Gaussian human avatar\nrepresentation that can reconstruct high-fidelity pose-dependence appearance\nwith details and meanwhile can be rendered in real time. Our Gaussian avatar is\nempowered by spatially distributed MLPs which are explicitly located on\ndifferent positions on human body. The parameters stored in each Gaussian are\nobtained by interpolating from the outputs of its nearby MLPs based on their\ndistances. To avoid undesired smooth Gaussian property changing during\ninterpolation, for each Gaussian we define a set of Gaussian offset basis, and\na linear combination of basis represents the Gaussian property offsets relative\nto the neutral properties. Then we propose to let the MLPs output a set of\ncoefficients corresponding to the basis. In this way, although Gaussian\ncoefficients are derived from interpolation and change smoothly, the Gaussian\noffset basis is learned freely without constraints. The smoothly varying\ncoefficients combined with freely learned basis can still produce distinctly\ndifferent Gaussian property offsets, allowing the ability to learn\nhigh-frequency spatial signals. We further use control points to constrain the\nGaussians distributed on a surface layer rather than allowing them to be\nirregularly distributed inside the body, to help the human avatar generalize\nbetter when animated under novel poses. Compared to the state-of-the-art\nmethod, our method achieves better appearance quality with finer details while\nthe rendering speed is significantly faster under novel views and novel poses.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T12:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12927v1","title":"Dynamics of Geometric Invariants in the Asymptotically Hyperboloidal\n  Setting: Energy and Linear Momentum","summary":"We investigate the evolution of geometric invariants, as defined by Michel\n\\cite{Michel}, in the context of asymptotically hyperboloidal initial data\nsets. Our focus lies on the charges of energy and linear momentum, and we study\ntheir behavior under the Einstein evolution equations. We construct foliations\ndescribing the evolution of asymptotically hyperboloidal initial data sets\nusing hyperboloidal time function. We define E-P chargeability as a property of\nthe initial data set, and we show that it is preserved under the evolution for\nour choice of time function. This ensures that the charges are well-defined\nalong the evolution, which is crucial for our approach. Along such foliations,\nwe recover the same energy-loss and linear momentum-loss formulae as those\nderived by Bondi, Sachs, and Metzner \\cite{Bondi-vanderBurg-Metzner} while\noperating under weaker asymptotic assumptions. Our approach is distinct from\nprevious work as we do not utilize conformal compactifications and work\ndirectly at the level of the initial data set.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T13:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.12947v1","title":"Unraveling the thermodynamics and mechanism behind the lowering of\n  reduction temperatures in oxide mixtures","summary":"Hydrogen-based direct reduction offers a sustainable pathway to decarbonize\nthe metal production industry. However, stable metal oxides, like Cr$_2$O$_3$,\nare notoriously difficult to reduce, requiring extremely high temperatures\n(above 1300 $^\\circ$C). Herein, we show how reducing mixed oxides can be\nleveraged to lower hydrogen-based reduction temperatures of stable oxides and\nproduce alloys in a single process. Using a newly developed thermodynamic\nframework, we predict the precise conditions (oxygen partial pressure,\ntemperature, and oxide composition) needed for co-reduction. We showcase this\napproach by reducing Cr$_2$O$_3$ mixed with Fe$_2$O$_3$ at 1100 $^\\circ$C,\nsignificantly lowering reduction temperatures (by $\\geq$200 $^\\circ$C). Our\nmodel and post-reduction atom probe tomography analysis elucidate that the\ntemperature-lowering effect is driven by the lower chemical activity of Cr in\nthe metallic phase. This strategy achieves low-temperature co-reduction of\nmixed oxides, dramatically reducing energy consumption and CO$_2$ emissions,\nwhile unlocking transformative pathways toward sustainable alloy design.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T13:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.12971v1","title":"Transferrable Surrogates in Expressive Neural Architecture Search Spaces","summary":"Neural architecture search (NAS) faces a challenge in balancing the\nexploration of expressive, broad search spaces that enable architectural\ninnovation with the need for efficient evaluation of architectures to\neffectively search such spaces. We investigate surrogate model training for\nimproving search in highly expressive NAS search spaces based on context-free\ngrammars. We show that i) surrogate models trained either using zero-cost-proxy\nmetrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM\nhave high predictive power for the performance of architectures both within and\nacross datasets, ii) these surrogates can be used to filter out bad\narchitectures when searching on novel datasets, thereby significantly speeding\nup search and achieving better final performances, and iii) the surrogates can\nbe further used directly as the search objective for huge speed-ups.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-17T14:22:28Z"}
{"aid":"http://arxiv.org/abs/2504.12990v1","title":"Maximum Information Extraction From Noisy Data Via Shannon Entropy\n  Minimization","summary":"Granting maximum information extraction in the analysis of noisy data is\nnon-trivial. We introduce a general, data-driven approach that employs Shannon\nentropy as a transferable metric to quantify the maximum information\nextractable from noisy data via their clustering into statistically-relevant\nmicro-domains. We demonstrate the method's efficiency by analyzing, as a\nrepresentative example, time-series data extracted from molecular dynamics\nsimulations of water and ice coexisting at the solid/liquid transition\ntemperature. The method allows quantifying the information contained in the\ndata distributions (time-independent component) and the additional information\ngain attainable by analyzing data as time-series (i.e., accounting for the\ninformation contained in data time-correlations). The approach is also highly\neffective for high-dimensional datasets, providing clear demonstrations of how\nconsidering components/data that may be little informative but noisy may be not\nonly useless but even detrimental to maximum information extraction. This\nprovides a general and robust parameter-free approach and quantitative metrics\nfor data-analysis, and for the study of any type of system from its data.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-04-17T14:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.13002v1","title":"The Role of Empathy in Software Engineering -- A Socio-Technical\n  Grounded Theory","summary":"Empathy, defined as the ability to understand and share others' perspectives\nand emotions, is essential in software engineering (SE), where developers often\ncollaborate with diverse stakeholders. It is also considered as a vital\ncompetency in many professional fields such as medicine, healthcare, nursing,\nanimal science, education, marketing, and project management. Despite its\nimportance, empathy remains under-researched in SE. To further explore this, we\nconducted a socio-technical grounded theory (STGT) study through in-depth\nsemi-structured interviews with 22 software developers and stakeholders. Our\nstudy explored the role of empathy in SE and how SE activities and processes\ncan be improved by considering empathy. Through applying the systematic steps\nof STGT data analysis and theory development, we developed a theory that\nexplains the role of empathy in SE. Our theory details the contexts in which\nempathy arises, the conditions that shape it, the causes and consequences of\nits presence and absence. We also identified contingencies for enhancing\nempathy or overcoming barriers to its expression. Our findings provide\npractical implications for SE practitioners and researchers, offering a deeper\nunderstanding of how to effectively integrate empathy into SE processes.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.13008v1","title":"Reconstruction and Performance Evaluation of FASER's Emulsion Detector\n  at the LHC","summary":"This paper presents the reconstruction and performance evaluation of the\nFASER$\\nu$ emulsion detector, which aims to measure interactions from neutrinos\nproduced in the forward direction of proton-proton collisions at the CERN Large\nHadron Collider. The detector, composed of tungsten plates interleaved with\nemulsion films, records charged particles with sub-micron precision. A key\nchallenge arises from the extremely high track density environment, reaching\n$\\mathcal{O}(10^5)$ tracks per cm$^2$. To address this, dedicated alignment\ntechniques and track reconstruction algorithms have been developed, building on\ntechniques from previous experiments and introducing further optimizations. The\nperformance of the detector is studied by evaluating the single-film\nefficiency, position and angular resolution, and the impact parameter\ndistribution of reconstructed vertices. The results demonstrate that an\nalignment precision of 0.3 micrometers and robust track and vertex\nreconstruction are achieved, enabling accurate neutrino measurements in the TeV\nenergy range.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T15:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.13014v1","title":"Extended scalar sectors from all angles (in 15 minutes)","summary":"In this proceedings contribution, I briefly summarize various aspects that\nare important in the discussions of new physics searches with novel scalar\nstates, at current and future colliders. In particular, I give a brief glance\non the status of two Higgs doublet models, and discuss multi-scalar production\nas well as interference effects in Di-Higgs searches. I also mention searches\nof new scalar final states at possible Higgs factories.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T15:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.13015v1","title":"Hierarchical Feature Learning for Medical Point Clouds via State Space\n  Model","summary":"Deep learning-based point cloud modeling has been widely investigated as an\nindispensable component of general shape analysis. Recently, transformer and\nstate space model (SSM) have shown promising capacities in point cloud\nlearning. However, limited research has been conducted on medical point clouds,\nwhich have great potential in disease diagnosis and treatment. This paper\npresents an SSM-based hierarchical feature learning framework for medical point\ncloud understanding. Specifically, we down-sample input into multiple levels\nthrough the farthest point sampling. At each level, we perform a series of\nk-nearest neighbor (KNN) queries to aggregate multi-scale structural\ninformation. To assist SSM in processing point clouds, we introduce\ncoordinate-order and inside-out scanning strategies for efficient serialization\nof irregular points. Point features are calculated progressively from short\nneighbor sequences and long point sequences through vanilla and group Point SSM\nblocks, to capture both local patterns and long-range dependencies. To evaluate\nthe proposed method, we build a large-scale medical point cloud dataset named\nMedPointS for anatomy classification, completion, and segmentation. Extensive\nexperiments conducted on MedPointS demonstrate that our method achieves\nsuperior performance across all tasks. The dataset is available at\nhttps://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to\na public medical imaging platform: https://github.com/wlsdzyzl/flemme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:22:31Z"}
{"aid":"http://arxiv.org/abs/2504.13040v1","title":"Quantum-gas microscopy of the Bose-glass phase","summary":"Disordered potentials fundamentally alter the transport properties and\ncoherence of quantum systems. They give rise to phenomena such as Anderson\nlocalization in non-interacting systems, inhibiting transport. When\ninteractions are introduced, the interplay with disorder becomes significantly\nmore complex, and the conditions under which localization can be observed\nremain an open question. In interacting bosonic systems, a Bose glass is\nexpected to emerge at low energies as an insulating yet compressible state\nwithout long-range phase coherence. While originally predicted to occur as a\nground-state phase, more recent studies indicate that it exists at finite\ntemperature. A key open challenge has been the direct observation of reduced\nphase coherence in the Bose-glass regime. In this study, we utilize ultracold\nbosonic atoms in a quantum-gas microscope to probe the emergence of the\nBose-glass phase in a two-dimensional square lattice with a site-resolved,\nreproducible disordered potential. We identify the phase through in-situ\ndistribution and particle fluctuations, via a local measurement of the\nEdwards-Anderson parameter. To measure the short-range phase coherence in the\nBose glass, we employ Talbot interferometry in combination with\nsingle-atom-resolved detection. Finally, by driving the system in and out of\nthe Bose-glass phase, we observe signatures for non-ergodic behavior.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.dis-nn,physics.atom-ph,quant-ph","published":"2025-04-17T15:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.13048v1","title":"Design Topological Materials by Reinforcement Fine-Tuned Generative\n  Model","summary":"Topological insulators (TIs) and topological crystalline insulators (TCIs)\nare materials with unconventional electronic properties, making their discovery\nhighly valuable for practical applications. However, such materials,\nparticularly those with a full band gap, remain scarce. Given the limitations\nof traditional approaches that scan known materials for candidates, we focus on\nthe generation of new topological materials through a generative model.\nSpecifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained\ngenerative model, thereby aligning the model's objectives with our material\ndesign goals. We demonstrate that ReFT is effective in enhancing the model's\nability to generate TIs and TCIs, with minimal compromise on the stability of\nthe generated materials. Using the fine-tuned model, we successfully identify a\nlarge number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a\nrepresentative example--a TI with a full band gap of 0.26 eV, ranking among the\nlargest known in this category.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.AI","published":"2025-04-17T16:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.13052v1","title":"GraphAttack: Exploiting Representational Blindspots in LLM Safety\n  Mechanisms","summary":"Large Language Models (LLMs) have been equipped with safety mechanisms to\nprevent harmful outputs, but these guardrails can often be bypassed through\n\"jailbreak\" prompts. This paper introduces a novel graph-based approach to\nsystematically generate jailbreak prompts through semantic transformations. We\nrepresent malicious prompts as nodes in a graph structure with edges denoting\ndifferent transformations, leveraging Abstract Meaning Representation (AMR) and\nResource Description Framework (RDF) to parse user goals into semantic\ncomponents that can be manipulated to evade safety filters. We demonstrate a\nparticularly effective exploitation vector by instructing LLMs to generate code\nthat realizes the intent described in these semantic graphs, achieving success\nrates of up to 87% against leading commercial LLMs. Our analysis reveals that\ncontextual framing and abstraction are particularly effective at circumventing\nsafety measures, highlighting critical gaps in current safety alignment\ntechniques that focus primarily on surface-level patterns. These findings\nprovide insights for developing more robust safeguards against structured\nsemantic attacks. Our research contributes both a theoretical framework and\npractical methodology for systematically stress-testing LLM safety mechanisms.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T16:09:12Z"}
{"aid":"http://arxiv.org/abs/2504.13074v1","title":"SkyReels-V2: Infinite-length Film Generative Model","summary":"Recent advances in video generation have been driven by diffusion models and\nautoregressive frameworks, yet critical challenges persist in harmonizing\nprompt adherence, visual quality, motion dynamics, and duration: compromises in\nmotion dynamics to enhance temporal visual quality, constrained video duration\n(5-10 seconds) to prioritize resolution, and inadequate shot-aware generation\nstemming from general-purpose MLLMs' inability to interpret cinematic grammar,\nsuch as shot composition, actor expressions, and camera motions. These\nintertwined limitations hinder realistic long-form synthesis and professional\nfilm-style generation. To address these limitations, we propose SkyReels-V2, an\nInfinite-length Film Generative Model, that synergizes Multi-modal Large\nLanguage Model (MLLM), Multi-stage Pretraining, Reinforcement Learning, and\nDiffusion Forcing Framework. Firstly, we design a comprehensive structural\nrepresentation of video that combines the general descriptions by the\nMulti-modal LLM and the detailed shot language by sub-expert models. Aided with\nhuman annotation, we then train a unified Video Captioner, named\nSkyCaptioner-V1, to efficiently label the video data. Secondly, we establish\nprogressive-resolution pretraining for the fundamental video generation,\nfollowed by a four-stage post-training enhancement: Initial concept-balanced\nSupervised Fine-Tuning (SFT) improves baseline quality; Motion-specific\nReinforcement Learning (RL) training with human-annotated and synthetic\ndistortion data addresses dynamic artifacts; Our diffusion forcing framework\nwith non-decreasing noise schedules enables long-video synthesis in an\nefficient search space; Final high-quality SFT refines visual fidelity. All the\ncode and models are available at https://github.com/SkyworkAI/SkyReels-V2.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.13090v1","title":"Quadratic gravity with propagating torsion and asymptotic freedom","summary":"We consider a class of metric-affine gravitational theories with action\nquadratic in curvature and torsion tensors. Using the heat kernel technique, we\ncompute the torsion contributions to the one-loop counterterms in the\nultraviolet limit. It is found that vectorial and axial components of torsion\npreserve the qualitative picture of the renormalization group flow of the\nmetric sector. However, there exists a specific nonminimal kinetic term for the\npure tensorial (hook-antisymmetric traceless) component of torsion that renders\nthe gravitational couplings asymptotically free in the absence of tachyons.","main_category":"hep-th","categories":"hep-th","published":"2025-04-17T16:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.13116v1","title":"Predicting BVD Re-emergence in Irish Cattle From Highly Imbalanced\n  Herd-Level Data Using Machine Learning Algorithms","summary":"Bovine Viral Diarrhoea (BVD) has been the focus of a successful eradication\nprogramme in Ireland, with the herd-level prevalence declining from 11.3% in\n2013 to just 0.2% in 2023. As the country moves toward BVD freedom, the\ndevelopment of predictive models for targeted surveillance becomes increasingly\nimportant to mitigate the risk of disease re-emergence. In this study, we\nevaluate the performance of a range of machine learning algorithms, including\nbinary classification and anomaly detection techniques, for predicting\nBVD-positive herds using highly imbalanced herd-level data. We conduct an\nextensive simulation study to assess model performance across varying sample\nsizes and class imbalance ratios, incorporating resampling, class weighting,\nand appropriate evaluation metrics (sensitivity, positive predictive value,\nF1-score and AUC values). Random forests and XGBoost models consistently\noutperformed other methods, with the random forest model achieving the highest\nsensitivity and AUC across scenarios, including real-world prediction of 2023\nherd status, correctly identifying 219 of 250 positive herds while halving the\nnumber of herds that require compared to a blanket-testing strategy.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-17T17:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.13117v1","title":"Tunable Entangling and Steering of Ferrimagnetic Magnons via an\n  OptoMagnoMechanical Ring","summary":"Recently, magnomechanical systems have emerged as promising platforms for\nquantum technologies, exploiting magnon-photon-phonon interactions to store\nhigh-fidelity quantum information. In this paper, we propose a scheme to\nentangle two spatially separated ferrimagnetic YIG crystals by injecting a\nmicrowave field into an optomagnonic ring cavity. The proposed\noptomagnomechanical configuration utilizes the coupling between\nmagnetostriction-induced mechanical displacements and the optical cavity via\nradiation pressure. Magnons - collective spin excitations in macroscopic\nferromagnets - are directly driven by an electromagnetic field. We demonstrate\nthe generation of macroscopic magnon entanglement by exciting the optical\ncavity with a red detuned microwave field and the YIG crystals with a blue\ndetuned field. Our analysis reveals that magnon entanglement vanishes for\nidentical magnomechanical couplings but remains robust against thermal\nfluctuations. The magnon modes entangled in two ferrimagnetic crystals\nrepresent genuine macroscopic quantum states with potential applications in the\nstudy of macroscopic quantum mechanics and quantum information processing based\non magnonics. The configuration is based on experimentally accessible\nparameters, providing a feasible route of quantum technologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:36:37Z"}
{"aid":"http://arxiv.org/abs/2504.13126v1","title":"A hybrid U-Net and Fourier neural operator framework for the large-eddy\n  simulation of turbulent flows over periodic hills","summary":"Accurate and efficient predictions of three-dimensional (3D) turbulent flows\nare of significant importance in the fields of science and engineering. In the\ncurrent work, we propose a hybrid U-Net and Fourier neural operator (HUFNO)\nmethod, tailored for mixed periodic and non-periodic boundary conditions which\nare often encountered in complex turbulence problems. The HUFNO model is tested\nin the large-eddy simulation (LES) of 3D periodic hill turbulence featuring\nstrong flow separations. Compared to the original Fourier neural operator (FNO)\nand the convolutional neural network (CNN)-based U-Net framework, the HUFNO\nmodel has a higher accuracy in the predictions of the velocity field and\nReynolds stresses. Further numerical experiments in the LES show that the HUFNO\nframework outperforms the traditional Smagorinsky (SMAG) model and the\nwall-adapted local eddy-viscosity (WALE) model in the predictions of the\nturbulence statistics, the energy spectrum, the wall stresses and the flow\nseparation structures, with much lower computational cost. Importantly, the\naccuracy and efficiency are transferable to unseen initial conditions and hill\nshapes, underscoring its great potentials for the fast prediction of strongly\nseparated turbulent flows over curved boundaries.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-17T17:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.13146v1","title":"Antidistillation Sampling","summary":"Frontier models that generate extended reasoning traces inadvertently produce\nrich token sequences that can facilitate model distillation. Recognizing this\nvulnerability, model owners may seek sampling strategies that limit the\neffectiveness of distillation without compromising model performance.\n\\emph{Antidistillation sampling} provides exactly this capability. By\nstrategically modifying a model's next-token probability distribution,\nantidistillation sampling poisons reasoning traces, rendering them\nsignificantly less effective for distillation while preserving the model's\npractical utility. For further details, see https://antidistillation.com.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-17T17:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.13159v1","title":"Digital Twin Generation from Visual Data: A Survey","summary":"This survey explores recent developments in generating digital twins from\nvideos. Such digital twins can be used for robotics application, media content\ncreation, or design and construction works. We analyze various approaches,\nincluding 3D Gaussian Splatting, generative in-painting, semantic segmentation,\nand foundation models highlighting their advantages and limitations.\nAdditionally, we discuss challenges such as occlusions, lighting variations,\nand scalability, as well as potential future research directions. This survey\naims to provide a comprehensive overview of state-of-the-art methodologies and\ntheir implications for real-world applications. Awesome list:\nhttps://github.com/ndrwmlnk/awesome-digital-twins","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.13170v1","title":"A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal\n  Control with Time Scaling","summary":"We introduce a semidefinite relaxation for optimal control of linear systems\nwith time scaling. These problems are inherently nonconvex, since the system\ndynamics involves bilinear products between the discretization time step and\nthe system state and controls. The proposed relaxation is closely related to\nthe standard second-order semidefinite relaxation for quadratic constraints,\nbut we carefully select a subset of the possible bilinear terms and apply a\nchange of variables to achieve empirically tight relaxations while keeping the\ncomputational load light. We further extend our method to handle\npiecewise-affine (PWA) systems by formulating the PWA optimal-control problem\nas a shortest-path problem in a graph of convex sets (GCS). In this GCS,\ndifferent paths represent different mode sequences for the PWA system, and the\nconvex sets model the relaxed dynamics within each mode. By combining a tight\nconvex relaxation of the GCS problem with our semidefinite relaxation with time\nscaling, we can solve PWA optimal-control problems through a single\nsemidefinite program.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY,math.OC","published":"2025-04-17T17:59:23Z"}
{"aid":"http://arxiv.org/abs/2504.13174v1","title":"Quantum algorithm for solving nonlinear differential equations based on\n  physics-informed effective Hamiltonians","summary":"We propose a distinct approach to solving linear and nonlinear differential\nequations (DEs) on quantum computers by encoding the problem into ground states\nof effective Hamiltonian operators. Our algorithm relies on constructing such\noperators in the Chebyshev space, where an effective Hamiltonian is a sum of\nglobal differential and data constraints. Once the effective Hamiltonian is\nformed, solutions of differential equations can be obtained using the ground\nstate preparation techniques (e.g. imaginary-time evolution and quantum\nsingular value transformation), bypassing variational search. Unlike approaches\nbased on discrete grids, the algorithm enables evaluation of solutions beyond\nfixed grid points and implements constraints in the physics-informed way. Our\nproposal inherits the best traits from quantum machine learning-based DE\nsolving (compact basis representation, automatic differentiation, nonlinearity)\nand quantum linear algebra-based approaches (fine-grid encoding, provable\nspeed-up for state preparation), offering a robust strategy for quantum\nscientific computing in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.14824v1","title":"An Enhanced Dual-Currency VCG Auction Mechanism for Resource Allocation\n  in IoV: A Value of Information Perspective","summary":"The Internet of Vehicles (IoV) is undergoing a transformative evolution,\nenabled by advancements in future 6G network technologies, to support\nintelligent, highly reliable, and low-latency vehicular services. However, the\nenhanced capabilities of loV have heightened the demands for efficient network\nresource allocation while simultaneously giving rise to diverse vehicular\nservice requirements. For network service providers (NSPs), meeting the\ncustomized resource-slicing requirements of vehicle service providers (VSPs)\nwhile maximizing social welfare has become a significant challenge. This paper\nproposes an innovative solution by integrating a mean-field multi-agent\nreinforcement learning (MFMARL) framework with an enhanced\nVickrey-Clarke-Groves (VCG) auction mechanism to address the problem of social\nwelfare maximization under the condition of unknown VSP utility functions. The\ncore of this solution is introducing the ``value of information\" as a novel\nmonetary metric to estimate the expected benefits of VSPs, thereby ensuring the\neffective execution of the VCG auction mechanism. MFMARL is employed to\noptimize resource allocation for social welfare maximization while adapting to\nthe intelligent and dynamic requirements of IoV. The proposed enhanced VCG\nauction mechanism not only protects the privacy of VSPs but also reduces the\nlikelihood of collusion among VSPs, and it is theoretically proven to be\ndominant-strategy incentive compatible (DSIC). The simulation results\ndemonstrate that, compared to the VCG mechanism implemented using quantization\nmethods, the proposed mechanism exhibits significant advantages in convergence\nspeed, social welfare maximization, and resistance to collusion, providing new\ninsights into resource allocation in intelligent 6G networks.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-21T03:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.14826v1","title":"Distribution-aware Dataset Distillation for Efficient Image Restoration","summary":"With the exponential increase in image data, training an image restoration\nmodel is laborious. Dataset distillation is a potential solution to this\nproblem, yet current distillation techniques are a blank canvas in the field of\nimage restoration. To fill this gap, we propose the Distribution-aware Dataset\nDistillation method (TripleD), a new framework that extends the principles of\ndataset distillation to image restoration. Specifically, TripleD uses a\npre-trained vision Transformer to extract features from images for complexity\nevaluation, and the subset (the number of samples is much smaller than the\noriginal training set) is selected based on complexity. The selected subset is\nthen fed through a lightweight CNN that fine-tunes the image distribution to\nalign with the distribution of the original dataset at the feature level. To\nefficiently condense knowledge, the training is divided into two stages. Early\nstages focus on simpler, low-complexity samples to build foundational\nknowledge, while later stages select more complex and uncertain samples as the\nmodel matures. Our method achieves promising performance on multiple image\nrestoration tasks, including multi-task image restoration, all-in-one image\nrestoration, and ultra-high-definition image restoration tasks. Note that we\ncan train a state-of-the-art image restoration model on an\nultra-high-definition (4K resolution) dataset using only one consumer-grade GPU\nin less than 8 hours (500 savings in computing resources and immeasurable\ntraining time).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T03:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.14834v1","title":"Output regulation for a reaction-diffusion system with input delay and\n  unknown frequency","summary":"This study solves the output regulation problem for a reaction-diffusion\nsystem confronting concurrent input delay and fully unidentified disturbances\n(encompassing both unknown frequencies and amplitudes) across all channels. The\nprincipal innovation emerges from a novel adaptive control architecture that\nsynergizes the modal decomposition technique with a dual-observer mechanism,\nenabling real-time concurrent estimation of unmeasurable system states and\ndisturbances through a state observer and an adaptive disturbance estimator.\nUnlike existing approaches limited to either delay compensation or partial\ndisturbance rejection, our methodology overcomes the technical barrier of\ncoordinating these two requirements through a rigorously constructed\ntracking-error-based controller, achieving exponential convergence of system\noutput to reference signals. Numerical simulations are presented to validate\nthe effectiveness of the proposed output feedback control strategy.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T03:29:09Z"}
{"aid":"http://arxiv.org/abs/2504.14842v1","title":"A Short Proof of Coding Theorems for Reed-Muller Codes","summary":"In this paper, we present a short proof that ReedMuller (RM) codes are\nentropy-achieving as source coding for Bernoulli sources and capacity-achieving\nas channel coding for binary memoryless symmetric (BMS) channels, also known as\nmemoryless binary-input output-symmetric (BIOS) channels, in terms of bit error\nrate (BER) under maximum-likelihood (ML) decoding.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T03:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.14846v1","title":"Converting $PT$-Symmetric Topological Classes by Floquet Engineering","summary":"Going beyond the conventional classification rule of Altland-Zirnbauer\nsymmetry classes, $PT$ symmetric topological phases are classified by\n$(PT)^2=1$ or $-1$. The interconversion between the two $PT$-symmetric\ntopological classes is generally difficult due to the constraint of $(PT)^2$.\nHere, we propose a scheme to control and interconvert the $PT$-symmetric\ntopological classes by Floquet engineering. We find that it is the breakdown of\nthe $\\mathbb{Z}_2$ gauge, induced by the $\\pi$ phase difference between\ndifferent hopping rates, by the periodic driving that leads to such an\ninterconversion. Relaxing the system from the constraint of $(PT)^2$, rich\nexotic topological phases, e.g., the coexisting $PT$-symmetric first-order real\nChern insulator and second-order topological insulators not only in different\nquasienergy gaps, but also in one single gap, are generated. In contrast to\nconventional Floquet topological phases, our result provides a way to realize\nexotic topological phases without changing symmetries. It enriches the family\nof topological phases and gives an insightful guidance for the development of\nmultifunctional quantum devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-21T03:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.14856v1","title":"Transparentize the Internal and External Knowledge Utilization in LLMs\n  with Trustworthy Citation","summary":"While hallucinations of large language models could been alleviated through\nretrieval-augmented generation and citation generation, how the model utilizes\ninternal knowledge is still opaque, and the trustworthiness of its generated\nanswers remains questionable. In this work, we introduce Context-Prior\nAugmented Citation Generation task, requiring models to generate citations\nconsidering both external and internal knowledge while providing trustworthy\nreferences, with 5 evaluation metrics focusing on 3 aspects: answer\nhelpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the\nparadigm for our task, and also design INTRALIGN, an integrated method\ncontaining customary data generation and an alignment algorithm. Our\nexperimental results show that our method achieves a better cross-scenario\nperformance with regard to other baselines. Our extended experiments further\nreveal that retrieval quality, question types, and model knowledge have\nconsiderable influence on the trustworthiness in citation generation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T04:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.14869v1","title":"X-ray Polarization of the BL Lac Type Blazar H 1426+428","summary":"We report the X-ray polarization properties of the high-synchrotron-peaked BL\nLac H 1426+428, based on two-epoch observational data from the Imaging X-ray\nPolarimetry Explorer (IXPE). For the first observation, only an upper limit of\npolarization degree ($\\Pi_{\\rm X}$), $\\Pi_{\\rm X}<19.5\\%$, at the 99\\%\nconfidence level (C.L.) is determined. In contrast, for the second observation,\nwe derive $\\Pi_{\\rm X}=20.6\\%\\pm2.9\\%$ with a polarization angle ($\\psi_{\\rm\nX}$) of $\\psi_{\\rm X}=116.1^{\\circ}\\pm4.1^{\\circ}$ at a C.L. of 7.1 $\\sigma$.\nThe time-resolved and energy-resolved polarization analysis reveals no\nsignificant variation in $\\psi_{\\rm X}$ and no detectable polarization within\nnarrower energy bins for the first observation, while the polarization during\nthe second observation is predominantly dominated by low-energy photons.\nFurthermore, the X-rays during the second observation are found to be in a\nhigher flux state with a harder spectrum compared to that observed during the\nfirst observation, consistent with a {\\it harder-when-brighter} behavior. We\npropose that the plasma responsible for the X-ray emission during the first\nobservation propagates downstream and encounters a shock, leading to electron\nacceleration and more ordered of the magnetic fields. The enhanced X-ray\nemission observed during the second observation is produced by\nshock-accelerated electrons within an ordered magnetic field region via\nsynchrotron radiation. No significant detection of polarization during the\nfirst IXPE observation may be due to the limited number of detected photons.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-21T05:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.14892v1","title":"A level set topology optimization theory based on Hamilton's principle","summary":"In this paper, we present a novel framework for deriving the evolution\nequation of the level set function in topology optimization, departing from\nconventional Hamilton-Jacobi based formulations. The key idea is the\nintroduction of an auxiliary domain, geometrically identical to the physical\ndesign domain, occupied by fictitious matter which is dynamically excited by\nthe conditions prevailing in the design domain. By assigning kinetic and\npotential energy to this matter and interpreting the level set function as the\ngeneralized coordinate to describe its deformation, the governing equation of\nmotion is determined via Hamilton's principle, yielding a modified wave\nequation. Appropriate combinations of model parameters enable the recovery of\nclassical physical behaviors, including the standard and biharmonic wave\nequations. The evolution problem is formulated in weak form using variational\nmethods and implemented in the software environment FreeFEM++. The influence of\nthe numerical parameters is analyzed on the example of minimum mean compliance.\nThe results demonstrate that topological complexity and strut design can be\neffectively controlled by the respective parameters. In addition, the method\nallows for the nucleation of new holes and eliminates the need for\nre-initializing the level set function. The inclusion of a damping term further\nenhances numerical stability. To showcase the versatility and robustness of our\nmethod, we also apply it to compliant mechanism design and a bi-objective\noptimization problem involving self-weight and compliance minimization under\nlocal stress constraints.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T06:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.14897v1","title":"Physics-Aware Compression of Plasma Distribution Functions with\n  GPU-Accelerated Gaussian Mixture Models","summary":"Data compression is a critical technology for large-scale plasma simulations.\nStoring complete particle information requires Terabyte-scale data storage, and\nanalysis requires ad-hoc scalable post-processing tools. We propose a\nphysics-aware in-situ compression method using Gaussian Mixture Models (GMMs)\nto approximate electron and ion velocity distribution functions with a number\nof Gaussian components. This GMM-based method allows us to capture plasma\nfeatures such as mean velocity and temperature, and it enables us to identify\nheating processes and generate beams. We first construct a histogram to reduce\ncomputational overhead and apply GPU-accelerated, in-situ GMM fitting within\n\\texttt{iPIC3D}, a large-scale implicit Particle-in-Cell simulator, ensuring\nreal-time compression. The compressed representation is stored using the\n\\texttt{ADIOS 2} library, thus optimizing the I/O process. The GPU and\nhistogramming implementation provides a significant speed-up with respect to\nGMM on particles (both in time and required memory at run-time), enabling\nreal-time compression. Compared to algorithms like SZ, MGARD, and BLOSC2, our\nGMM-based method has a physics-based approach, retaining the physical\ninterpretation of plasma phenomena such as beam formation, acceleration, and\nheating mechanisms. Our GMM algorithm achieves a compression ratio of up to\n$10^4$, requiring a processing time comparable to, or even lower than, standard\ncompression engines.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-21T07:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.14923v1","title":"Maximum Entropy Production Principle of Thermodynamics for the Birth and\n  Evolution of Life","summary":"Research on the birth and evolution of life are reviewed with reference to\nthe maximum entropy production principle (MEPP). It has been shown that this\nprinciple is essential for consistent understanding of the birth and evolution\nof life. First, a recent work for the birth of a self-replicative system as\npre-RNA life is reviewed in relation to the MEPP. A critical condition of\npolymer concentration in a local system is reported by a dynamical system\napproach, above which, an exponential increase of entropy production is\nguaranteed. Secondly, research works of early stage of evolutions are reviewed;\nexperimental research for the numbers of cells necessary for forming a\nmulti-cellular organization, and numerical research of differentiation of a\nmodel system and its relation with MEPP. It is suggested by this review article\nthat the late stage of evolution is characterized by formation of society and\nexternal entropy production. A hypothesis on the general route of evolution is\ndiscussed from the birth to the present life which follows the MEPP. Some\nexamples of life which happened to face poor thermodynamic condition are\npresented with thermodynamic discussion. It is observed through this review\nthat MEPP is consistently useful for thermodynamic understanding of birth and\nevolution of life, subject to a thermodynamic condition far from equilibrium.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.stat-mech,nlin.AO,physics.chem-ph","published":"2025-04-21T07:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.14975v1","title":"Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency\n  Regularization","summary":"Despite the remarkable progress of 3D generation, achieving controllability,\ni.e., ensuring consistency between generated 3D content and input conditions\nlike edge and depth, remains a significant challenge. Existing methods often\nstruggle to maintain accurate alignment, leading to noticeable discrepancies.\nTo address this issue, we propose \\name{}, a new framework that enhances\ncontrollable 3D generation by explicitly encouraging cyclic consistency between\nthe second-order 3D content, generated based on extracted signals from the\nfirst-order generation, and its original input controls. Specifically, we\nemploy an efficient feed-forward backbone that can generate a 3D object from an\ninput condition and a text prompt. Given an initial viewpoint and a control\nsignal, a novel view is rendered from the generated 3D content, from which the\nextracted condition is used to regenerate the 3D content. This re-generated\noutput is then rendered back to the initial viewpoint, followed by another\nround of control signal extraction, forming a cyclic process with two\nconsistency constraints. \\emph{View consistency} ensures coherence between the\ntwo generated 3D objects, measured by semantic similarity to accommodate\ngenerative diversity. \\emph{Condition consistency} aligns the final extracted\nsignal with the original input control, preserving structural or geometric\ndetails throughout the process. Extensive experiments on popular benchmarks\ndemonstrate that \\name{} significantly improves controllability, especially for\nfine-grained details, outperforming existing methods across various conditions\n(e.g., +14.17\\% PSNR for edge, +6.26\\% PSNR for sketch).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:05:52Z"}
{"aid":"http://arxiv.org/abs/2504.14983v1","title":"The Effect of Hydration and Dynamics on the Mass Density of Single\n  Proteins","summary":"The density of a protein molecule is a key property within a variety of\nexperimental techniques. We present a computational method for determining\nprotein mass density that explicitly incorporates hydration effects. Our\napproach uses molecular dynamics simulations to quantify the volume of solvent\nexcluded by a protein. Applied to a dataset of 260 soluble proteins, this\nyields an average density of 1.296 g cm-3, notably lower than the widely cited\nvalue of 1.35 g cm-3. Contrary to previous suggestions, we find no correlation\nbetween protein density and molecular weight. We instead find correlations with\nresidue composition, particularly with hydrophobic amino acid content. Using\nthese correlations, we train a regressor capable of accurately predicting\nprotein density from sequence-derived features alone. Examining the effect of\nincorporating water molecules on the measured density, we find that water\nmolecules buried in internal cavities have a negligible effect, whereas those\nat the surface have a profound impact. Furthermore, by calculating the density\nof a titin domain and of the Bovine Pancreatic Trypsin over molecular dynamics\ntrajectories, we show that individual proteins can occupy states with close but\ndistinguishable densities. Finally, we analyse the density of water in the\nvicinity of proteins, showing that the first two hydration shells exhibit\nhigher density than bulk water. When included in cumulative density\ncalculations, these hydration layers contribute to a net increase in local\nsolvent density. Overall, we find that proteins are less dense than previously\nreported, which is offset by their ability to induce a higher density of water\nin their vicinity.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-21T09:23:05Z"}
{"aid":"http://arxiv.org/abs/2504.14990v1","title":"Normalization of Quaternionic Polynomials in Coordinate-Free\n  Quaternionic Variables in Conjugate-Alternating Order","summary":"Quaternionic polynomials occur naturally in applications of quaternions in\nscience and engineering, and normalization of quaternionic polynomials is a\nbasic manipulation. Once a Groebner basis is certified for the defining ideal I\nof the quaternionic polynomial algebra, the normal form of a quaternionic\npolynomial can be computed by routine top reduction with respect to the\nGroebner basis. In the literature, a Groebner basis under the\nconjugate-alternating order of quaternionic variables was conjectured for I in\n2013, but no readable and convincing proof was found.\n  In this paper, we present the first readable certification of the conjectured\nGroebner basis. The certification is based on several novel techniques for\nreduction in free associative algebras, which enables to not only make\nreduction to S-polynomials more efficiently, but also reduce the number of\nS-polynomials needed for the certification.","main_category":"cs.SC","categories":"cs.SC","published":"2025-04-21T09:41:01Z"}
{"aid":"http://arxiv.org/abs/2504.15013v1","title":"Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation\n  with LLMs","summary":"The process of creating educational materials is both time-consuming and\ndemanding for educators. This research explores the potential of Large Language\nModels (LLMs) to streamline this task by automating the generation of extended\nreading materials and relevant course suggestions. Using the TED-Ed Dig Deeper\nsections as an initial exploration, we investigate how supplementary articles\ncan be enriched with contextual knowledge and connected to additional learning\nresources. Our method begins by generating extended articles from video\ntranscripts, leveraging LLMs to include historical insights, cultural examples,\nand illustrative anecdotes. A recommendation system employing semantic\nsimilarity ranking identifies related courses, followed by an LLM-based\nrefinement process to enhance relevance. The final articles are tailored to\nseamlessly integrate these recommendations, ensuring they remain cohesive and\ninformative. Experimental evaluations demonstrate that our model produces\nhigh-quality content and accurate course suggestions, assessed through metrics\nsuch as Hit Rate, semantic similarity, and coherence. Our experimental analysis\nhighlight the nuanced differences between the generated and existing materials,\nunderscoring the model's capacity to offer more engaging and accessible\nlearning experiences. This study showcases how LLMs can bridge the gap between\ncore content and supplementary learning, providing students with additional\nrecommended resources while also assisting teachers in designing educational\nmaterials.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T10:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.15017v1","title":"Identity Dilemma in Immigrant Consumers: a discourse analysis of\n  diaspora marketing","summary":"Purpose - Diasporas of a country of origin are groups interested in\ncountry-of-origin scattered in host countries and familiar with markets of host\ncountries. This paper aims to discourse analysis of diaspora marketing\nresearches. Methodology - In judgmental sampling using selected keywords 24\nresearches in two eras before and after 2010 are selected for discourse\nanalysis. Faircloughs critical discourse analysis model is used to analyze\nresearch data. Findings- Two different discourses can be distinguished in\ndiaspora marketing researches. The diaspora niche marketing discourse is\nfocused on penetrating into diaspora niche market. The diaspora marketing\nstrategy discourse is focused on developing into international market using\ndiaspora leverage. Research limitations and implications - Judgmental sampling\nand lived experience of researchers in a developing country which is usually\nconsidered as a diasporas country of origin rather than a diasporas host\ncountry limit the generalizability of research results. Practical implications\n- Understanding the extensions of diaspora marketing concept and diaspora\nmarketing discourses is helpful for designing appropriate strategies for\nentering and developing in the international market. Originality - this paper\ninvestigates extensions of diaspora concept in previous research identifies\ndiaspora marketing discourses and compares dominant diaspora marketing\ndiscourse with global marketing discourse.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-21T10:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.15040v1","title":"The PHD/CPHD filter for Multiple Extended Target Tracking with\n  Trajectory Set Theory and Explicit Shape Estimation","summary":"In this paper, we propose two methods for tracking multiple extended targets\nor unresolved group targets with elliptical extent shape. These two methods are\ndeduced from the famous Probability Hypothesis Density (PHD) filter and the\nCardinality-PHD (CPHD) filter, respectively. In these two methods, Trajectory\nSet Theory (TST) is combined to establish the target trajectory estimates.\nMoreover, by employing a decoupled shape estimation model, the proposed methods\ncan explicitly provide the shape estimation of the target, such as the\norientation of the ellipse extension and the length of its two axes. We derived\nthe closed Bayesian recursive of these two methods with stable trajectory\ngeneration and accurate extent estimation, resulting in the TPHD-E filter and\nthe TCPHD-E filter. In addition, Gaussian mixture implementations of our\nmethods are provided, which are further referred to as the GM-TPHD-E filter and\nthe GM-TCPHD-E filters. We illustrate the ability of these methods through\nsimulations and experiments with real data. These experiments demonstrate that\nthe two proposed algorithms have advantages over existing algorithms in target\nshape estimation, as well as in the completeness and accuracy of target\ntrajectory generation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.15048v1","title":"Neumann Data and Second Variation Formula of Renormalized Area for\n  Conformally Compact Static Spaces","summary":"In this paper, we derive the first and second variation formulas for the\nrenormalized area for static Einstein spaces along a specific direction,\ndemonstrating that the negativity of the Neumann data implies instability.\nConsequently, we obtain a rigidity result for the case when the conformal\nboundary is a warped product torus, which strengthens the result presented in\n\\cite{GSW}.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.15064v1","title":"Matrix Representations of Derivations for Low-Dimensional Mock-Lie\n  Algebras","summary":"In this work, we study the matrix representation of derivations for Mock-Lie\nalgebras with dimensions up to four. Using matrix methods, we examine their\nstructure and properties, showing how these derivations help us better\nunderstand the algebraic nature of Mock-Lie algebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-21T12:49:13Z"}
{"aid":"http://arxiv.org/abs/2504.15067v1","title":"Ordering and association of patchy particles in narrow channels","summary":"We show that the formalism of Wertheim's first order thermodynamic\nperturbation theory can be generalised for the fluid of anisotropic sticky\nparticles confined to a quasi-one-dimensional channel. Using the transfer\nmatrix method, we prove that the theory is exact if the hard body interaction\nis additive, only the first neighbors interact and the particles can stick\ntogether only along the channel. We show that the most convenient treatment of\nassociation in narrow channels is to work in NPT ensemble, where all structural\nand thermodynamic quantities can be expressed as a function of pressure and\nfraction of sites unbonded.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-21T12:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.15073v1","title":"Hermitian Quaternion Toeplitz Matrices by Quaternion-valued Generating\n  Functions","summary":"In this paper, we study Hermitian quaternion Toeplitz matrices generated by\nquaternion-valued functions. We show that such generating function must be the\nsum of a real-valued function and an odd function with imaginary component.\nThis setting is different from the case of Hermitian complex Toeplitz matrices\ngenerated by real-valued functions only. By using of 2-by-2 block complex\nrepresentation of quaternion matrices, we give a quaternion version of\nGrenander-Szeg\\\"{o} theorem stating the distribution of eigenvalues of\nHermitian quaternion Toeplitz matrices in terms of its generating function. As\nan application, we investigate Strang's circulant preconditioners for Hermitian\nquaternion Toeplitz linear systems arising from quaternion signal processing.\nWe show that Strang's circulant preconditioners can be diagionalized by\ndiscrete quaternion Fourier transform matrices whereas general quaternion\ncirculant matrices cannot be diagonalized by them. Also we verify the\ntheoretical and numerical convergence results of Strang's circulant\npreconditioned conjugate gradient method for solving Hermitian quaternion\nToeplitz systems.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T13:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.15079v1","title":"Generative Artificial Intelligence for Beamforming in Low-Altitude\n  Economy","summary":"The growth of low-altitude economy (LAE) has driven a rising demand for\nefficient and secure communication. However, conventional beamforming\noptimization techniques struggle in the complex LAE environments. In this\ncontext, generative artificial intelligence (GenAI) methods provide a promising\nsolution. In this article, we first introduce the core concepts of LAE and the\nroles of beamforming in advanced communication technologies for LAE. We then\nexamine their interrelation, followed by an analysis of the limitations of\nconventional beamforming methods. Next, we provide an overview of how GenAI\nmethods enhance the process of beamforming, with a focus on its applications in\nLAE. Furthermore, we present a case study using a generative diffusion model\n(GDM)-based algorithm to enhance the performance of aerial collaborative\nbeamforming-enabled remote secure communications in LAE and simulation results\nverified the effectiveness of the proposed algorithms. Finally, promising\nresearch opportunities are identified.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T13:09:15Z"}
{"aid":"http://arxiv.org/abs/2504.15099v1","title":"Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training\n  of GAN","summary":"Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T13:41:09Z"}
{"aid":"http://arxiv.org/abs/2504.15122v1","title":"MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry\n  Monocular Video","summary":"We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS)\nframework capable of reconstructing sharp and high-quality novel\nspatio-temporal views from blurry monocular videos in an end-to-end manner.\nExisting dynamic novel view synthesis (NVS) methods are highly sensitive to\nmotion blur in casually captured videos, resulting in significant degradation\nof rendering quality. While recent approaches address motion-blurred inputs for\nNVS, they primarily focus on static scene reconstruction and lack dedicated\nmotion modeling for dynamic objects. To overcome these limitations, our MoBGS\nintroduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for\neffective latent camera trajectory estimation, improving global camera motion\ndeblurring. In addition, we propose a physically-inspired Latent Camera-induced\nExposure Estimation (LCEE) method to ensure consistent deblurring of both\nglobal camera and local object motion. Our MoBGS framework ensures the temporal\nconsistency of unseen latent timestamps and robust motion decomposition of\nstatic and dynamic regions. Extensive experiments on the Stereo Blur dataset\nand real-world blurry videos show that our MoBGS significantly outperforms the\nvery recent advanced methods (DyBluRF and Deblur4DGS), achieving\nstate-of-the-art performance for dynamic NVS under motion blur.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.15127v1","title":"Reconstructing the redshift evolution of Type Ia supernovae absolute\n  magnitude","summary":"This work investigates a potential time dependence of the absolute magnitude\nof Type Ia Supernovae (SN Ia). Employing the Gaussian Process approach, we\nobtain the SN Ia absolute magnitude and its derivative as a function of\nredshift. The data set considered in the analysis comprises measurements of\napparent magnitude from SN Ia, Hubble rate from cosmic chronometers, and the\nratio between angular and radial distances from Large-Scale Structure data (BAO\nand voids). Our findings reveal good compatibility between the reconstructed SN\nIa absolute magnitudes and a constant value. However, the mean value obtained\nfrom the Gaussian Process reconstruction is $M=-19.456\\pm 0.059$, which is\n$3.2\\sigma$ apart from local measurements by Pantheon+SH0ES. This\nincompatibility may be directly associated to the $\\Lambda$CDM model and local\ndata, as it does not appear in either model-dependent or model-independent\nestimates of the absolute magnitude based on early universe data. Furthermore,\nwe assess the implications of a variable $M$ within the context of modified\ngravity theories. Considering the local estimate of the absolute magnitude, we\nfind $\\sim3\\sigma$ tension supporting departures from General Relativity in\nanalyzing scenarios involving modified gravity theories with variations in\nPlanck mass through Newton's constant.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:22:41Z"}
{"aid":"http://arxiv.org/abs/2504.15130v1","title":"Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning","summary":"Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-21T14:25:32Z"}
{"aid":"http://arxiv.org/abs/2504.15133v1","title":"EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language\n  Models","summary":"In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CV,cs.HC,cs.LG","published":"2025-04-21T14:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.15141v1","title":"Breaking Down Quantum Compilation: Profiling and Identifying Costly\n  Passes","summary":"With the increasing capabilities of quantum systems, the efficient, practical\nexecution of quantum programs is becoming more critical. Each execution\nincludes compilation time, which accounts for substantial overhead of the\noverall program runtime. To address this challenge, proposals that leverage\nprecompilation techniques have emerged, whereby entire circuits or select\ncomponents are precompiled to mitigate the compilation time spent during\nexecution. Considering the impact of compilation time on quantum program\nexecution, identifying the contribution of each individual compilation task to\nthe execution time is necessary in directing the community's research efforts\ntowards the development of an efficient compilation and execution pipeline. In\nthis work, we perform a preliminary analysis of the quantum circuit compilation\nprocess in Qiskit, examining the cumulative runtime of each individual\ncompilation task and identifying the tasks that most strongly impact the\noverall compilation time. Our results indicate that, as the desired level of\noptimization increases, circuit optimization and gate synthesis passes become\nthe dominant tasks in compiling a Quantum Fourier Transform, with individual\npasses consuming up to 87% of the total compilation time. Mapping passes\nrequire the most compilation time for a GHZ state preparation circuit,\naccounting for over 99% of total compilation time.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-21T14:45:01Z"}
{"aid":"http://arxiv.org/abs/2504.15153v1","title":"Distribution Testing Meets Sum Estimation","summary":"We study the problem of estimating the sum of $n$ elements, each with weight\n$w(i)$, in a structured universe. Our goal is to estimate $W = \\sum_{i=1}^n\nw(i)$ within a $(1 \\pm \\epsilon)$ factor using a sublinear number of samples,\nassuming weights are non-increasing, i.e., $w(1) \\geq w(2) \\geq \\dots \\geq\nw(n)$. The sum estimation problem is well-studied under different access models\nto the universe $U$. However, to the best of our knowledge, nothing is known\nabout the sum estimation problem using non-adaptive conditional sampling. In\nthis work, we explore the sum estimation problem using non-adaptive conditional\nweighted and non-adaptive conditional uniform samples, assuming that the\nunderlying distribution ($D(i)=w(i)/W$) is monotone. We also extend our\napproach to to the case where the underlying distribution of $U$ is unimodal.\nAdditionally, we consider support size estimation when $w(i) = 0$ or $w(i) \\geq\nW/n$, using hybrid sampling (both weighted and uniform) to access $U$. We\npropose an algorithm to estimate $W$ under the non-increasing weight\nassumption, using $O(\\frac{1}{\\epsilon^3} \\log{n} + \\frac{1}{\\epsilon^6})$\nnon-adaptive weighted conditional samples and $O(\\frac{1}{\\epsilon^3} \\log{n})$\nuniform conditional samples. Our algorithm matches the $\\Omega(\\log{n})$ lower\nbound by \\cite{ACK15}. For unimodal distributions, the sample complexity\nremains similar, with an additional $O(\\log{n})$ evaluation queries to locate\nthe minimum weighted point in the domain. For estimating the support size $k$\nof $U$, where weights are either $0$ or at least $W/n$, our algorithm uses\n$O\\big( \\frac{\\log^3(n/\\epsilon)}{\\epsilon^8} \\cdot \\log^4\n\\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ uniform samples and $O\\big(\n\\frac{\\log(n/\\epsilon)}{\\epsilon^2} \\cdot \\log\n\\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ weighted samples to output $\\hat{k}$\nsatisfying $k - 2\\epsilon n \\leq \\hat{k} \\leq k + \\epsilon n$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-21T14:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.15160v1","title":"The Synthetic Imputation Approach: Generating Optimal Synthetic Texts\n  For Underrepresented Categories In Supervised Classification Tasks","summary":"Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa,\nrequire that all categories in an annotation task be sufficiently represented\nin the training data for optimal performance. However, it is often difficult to\nfind sufficient examples for all categories in a task when building a\nhigh-quality training set. In this article, I describe this problem and propose\na solution, the synthetic imputation approach. Leveraging a generative LLM\n(GPT-4o), this approach generates synthetic texts based on careful prompting\nand five original examples drawn randomly with replacement from the sample.\nThis approach ensures that new synthetic texts are sufficiently different from\nthe original texts to reduce overfitting, but retain the underlying substantive\nmeaning of the examples to maximize out-of-sample performance. With 75 original\nexamples or more, synthetic imputation's performance is on par with a full\nsample of original texts, and overfitting remains low, predictable and\ncorrectable with 50 original samples. The synthetic imputation approach\nprovides a novel role for generative LLMs in research and allows applied\nresearchers to balance their datasets for best performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.15187v1","title":"Method for simulating open-system dynamics using mid-circuit\n  measurements on a quantum computer","summary":"We present a method for simulating the dynamics of an open electronic system\non a quantum computer. This approach entails mid-circuit measurements and\nresets to simulate the addition or removal of fermions from the system and\nprovides a way to apply non-reversible operations to a quantum computer. Using\nthis method, we simulate the dynamics of an open electronic system consisting\nof a fermionic chain positioned between two conductive leads on the\n$ibm\\_torino$ quantum computer.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T15:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15190v1","title":"Physical vs phantom dark energy after DESI: thawing quintessence in a\n  curved background","summary":"Recent data from DESI, in combination with other data, provide moderate\nevidence of dynamical dark energy, $w\\neq-1$. In the $w_0, w_a$ parametrization\nof $w$, there is a preference for a phantom crossing, $w<-1$, at redshift\n$z\\sim0.5$. In general relativity, the phantom equation of state is unphysical.\nThus it is important to check whether phantom crossing is present in other\nphysically self-consistent models of dark energy that have equivalent evidence\nto the $w_0, w_a$ parametrization. We find that thawing quintessence with\nnonzero cosmic curvature can fit the recent data slightly better than $w_0,\nw_a$ in a flat background. The phantom crossing may be a spurious artifact of a\nparametrization that is not based on a physical model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-21T16:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.15192v1","title":"Breast density in MRI: an AI-based quantification and relationship to\n  assessment in mammography","summary":"Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T16:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.15221v1","title":"On Walker and para-Hermite Einstein spaces","summary":"A special class of (complex) para-Hermite Einstein spaces is analyzed. For\nthis class of spaces the self-dual Weyl tensor is type-[D] in the\nPetrov-Penrose classification. The anti-self-dual Weyl tensor is algebraically\ndegenerate, equivalently, there exists an anti-self-dual congruence of null\nstrings. It is assumed that this congruence is parallely propagated. Thus, the\nspaces are not only para-Hermite but also Walker. A classification of the\nspaces according to three criteria is given. Finally, explicit metrics of all\nadmitted Petrov-Penrose types are found.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-21T16:47:54Z"}
{"aid":"http://arxiv.org/abs/2504.15256v1","title":"Impulsive pattern recognition of a myoelectric hand via Dynamic Time\n  Warping","summary":"Although myoelectric prosthetic hands provide amputees with intuitive\ncontrol, their reliance on many EMG sensors limits accessibility and makes them\ncomplex and expensive. To address this problem, this work presents a different\nperspective that makes use of a single EMG sensor and brief impulse signals in\nconjunction with Dynamic Time Warping (DTW) for accurate pattern detection.\nConventional techniques rely on real-time data from multiple sensors, which can\nbe costly and bulky. The method presents high accuracy while lowering hardware\ncomplexity and expense. A DTW-based system that reliably identifies muscle\nactivation patterns from short EMG signals was created and tested. Results show\nthat this single-sensor approach obtained an accuracy rate of 92%, which is\nsimilar to that of conventional multi-sensor systems. This research provides a\nmore straightforward and economical approach that can be used to obtain\nenhanced myoelectric control. These findings provide a different perspective on\nmore easily accessible and user-friendly prosthetic devices, which will be\nespecially helpful in disaster-affected areas where quick deployment is\nessential. Future improvements would investigate this system's dependability\nover time and wider implementations in real situations, to take prosthetic\ntechnology one step further.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-21T17:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.15261v1","title":"Leveraging Language Models for Automated Patient Record Linkage","summary":"Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-21T17:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.15269v1","title":"Scalable and robust regression models for continuous proportional data","summary":"Beta regression is used routinely for continuous proportional data, but it\noften encounters practical issues such as a lack of robustness of regression\nparameter estimates to misspecification of the beta distribution. We develop an\nimproved class of generalized linear models starting with the continuous\nbinomial (cobin) distribution and further extending to dispersion mixtures of\ncobin distributions (micobin). The proposed cobin regression and micobin\nregression models have attractive robustness, computation, and flexibility\nproperties. A key innovation is the Kolmogorov-Gamma data augmentation scheme,\nwhich facilitates Gibbs sampling for Bayesian computation, including in\nhierarchical cases involving nested, longitudinal, or spatial data. We\ndemonstrate robustness, ability to handle responses exactly at the boundary (0\nor 1), and computational efficiency relative to beta regression in simulation\nexperiments and through analysis of the benthic macroinvertebrate multimetric\nindex of US lakes using lake watershed covariates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-21T17:55:00Z"}
{"aid":"http://arxiv.org/abs/2504.15279v1","title":"VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal\n  Large Language Models","summary":"Visual reasoning is a core component of human intelligence and a critical\ncapability for advanced multimodal models. Yet current reasoning evaluations of\nmultimodal large language models (MLLMs) often rely on text descriptions and\nallow language-based reasoning shortcuts, failing to measure genuine\nvision-centric reasoning. To address this, we introduce VisuLogic: a benchmark\nof 1,000 human-verified problems across six categories (e.g., quantitative\nshifts, spatial relations, attribute comparisons). These various types of\nquestions can be evaluated to assess the visual reasoning capabilities of MLLMs\nfrom multiple perspectives. We evaluate leading MLLMs on this benchmark and\nanalyze their results to identify common failure modes. Most models score below\n30% accuracy-only slightly above the 25% random baseline and far below the\n51.4% achieved by humans-revealing significant gaps in visual reasoning.\nFurthermore, we provide a supplementary training dataset and a\nreinforcement-learning baseline to support further progress.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.15552v1","title":"A Multi-Agent Framework for Automated Qinqiang Opera Script Generation\n  Using Large Language Models","summary":"This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T03:14:29Z"}
{"aid":"http://arxiv.org/abs/2504.15557v1","title":"Asymptotics of higher-order conditional tail moments for\n  convolution-equivalently distributed losses","summary":"This paper investigates the asymptotic behavior of higher-order conditional\ntail moments, which quantify the contribution of individual losses in the event\nof systemic collapse. The study is conducted within a framework comprising two\ninvestment portfolios experiencing dependent losses that follow\nconvolution-equivalent distributions. The main results are encapsulated in two\ntheorems: one addressing light-tailed losses with convolution-equivalent\ndistributions and the other focusing on heavy-tailed losses with regularly\nvarying distributions. Both results reveal that the asymptotic behavior remains\nrobust regardless of the strength of dependence. Additionally, numerical\nsimulations are performed under specific scenarios to validate the theoretical\nresults.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T03:24:07Z"}
{"aid":"http://arxiv.org/abs/2504.15575v1","title":"Exploring the User Experience of AI-Assisted Sound Searching Systems for\n  Creative Workflows","summary":"Locating the right sound effect efficiently is an important yet challenging\ntopic for audio production. Most current sound-searching systems rely on\npre-annotated audio labels created by humans, which can be time-consuming to\nproduce and prone to inaccuracies, limiting the efficiency of audio production.\nFollowing the recent advancement of contrastive language-audio pre-training\n(CLAP) models, we explore an alternative CLAP-based sound-searching system\n(CLAP-UI) that does not rely on human annotations. To evaluate the\neffectiveness of CLAP-UI, we conducted comparative experiments with a widely\nused sound effect searching platform, the BBC Sound Effect Library. Our study\nevaluates user performance, cognitive load, and satisfaction through\necologically valid tasks based on professional sound-searching workflows. Our\nresult shows that CLAP-UI demonstrated significantly enhanced productivity and\nreduced frustration while maintaining comparable cognitive demands. We also\nqualitatively analyzed the participants' feedback, which offered valuable\nperspectives on the design of future AI-assisted sound search systems.","main_category":"eess.AS","categories":"eess.AS,cs.SD","published":"2025-04-22T04:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.15576v1","title":"Reply to Comment on 'Product states and Schmidt rank of mutually\n  unbiased bases in dimension six'","summary":"Daniel McNulty $et.al$ \\cite{commentMUB} voiced suspicions to the Lemma 11(v)\nPart 6 in \\cite{Chen2017Product} and three theorems derived in later\npublications \\cite{Liang2019,lma2020,xyc}. For these suspicions, we reprove\nthat any $6\\times 6$ complex Hadamard matrix whose number of real elements more\nthan 22 does not belong to a set of four mutually unbiased bases. We show that\nthe number of $2\\times 2$ complex Hadamard submatrices of any $H_2$-reducible\nmatrix is not $10,...,16,18$. We also put forward some possible directions for\nfurther development.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T04:20:58Z"}
{"aid":"http://arxiv.org/abs/2504.15582v1","title":"Smooth Calibration and Decision Making","summary":"Calibration requires predictor outputs to be consistent with their Bayesian\nposteriors. For machine learning predictors that do not distinguish between\nsmall perturbations, calibration errors are continuous in predictions, e.g.,\nsmooth calibration error (Foster and Hart, 2018), Distance to Calibration\n(Blasiok et al., 2023a). On the contrary, decision-makers who use predictions\nmake optimal decisions discontinuously in probabilistic space, experiencing\nloss from miscalibration discontinuously. Calibration errors for\ndecision-making are thus discontinuous, e.g., Expected Calibration Error\n(Foster and Vohra, 1997), and Calibration Decision Loss (Hu and Wu, 2024).\nThus, predictors with a low calibration error for machine learning may suffer a\nhigh calibration error for decision-making, i.e., they may not be trustworthy\nfor decision-makers optimizing assuming their predictions are correct. It is\nnatural to ask if post-processing a predictor with a low calibration error for\nmachine learning is without loss to achieve a low calibration error for\ndecision-making. In our paper, we show that post-processing an online predictor\nwith $\\epsilon$ distance to calibration achieves $O(\\sqrt{\\epsilon})$ ECE and\nCDL, which is asymptotically optimal. The post-processing algorithm adds noise\nto make predictions differentially private. The optimal bound from low distance\nto calibration predictors from post-processing is non-optimal compared with\nexisting online calibration algorithms that directly optimize for ECE and CDL.","main_category":"cs.LG","categories":"cs.LG,cs.DS,stat.ML","published":"2025-04-22T04:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.15591v1","title":"Reconciling the Waiting Time Peaks Variations of Repeating FRBs with an\n  Eccentric Neutron Star--White Dwarf Binary","summary":"Fast radio bursts (FRBs) are luminous radio transients with millisecond\nduration. For some active repeaters, such as FRBs 20121102A and 20201124A, more\nthan a thousand bursts have been detected by the Five-hundred-meter Aperture\nSpherical radio Telescope (FAST). The waiting time (WT) distributions of both\nrepeaters, defined as the time intervals between adjacent (detected) bursts,\nexhibit a bimodal structure well-fitted by two log-normal functions. Notably,\nthe time scales of the long-duration WT peaks for both repeaters show a\ndecreasing trend over time. These similar burst features suggest that there may\nbe a common physical mechanism for FRBs~20121102A and 20201124A. In this paper,\nwe {revisit} the neutron star (NS)--white dwarf (WD) binary model with an\neccentric orbit to account for the observed changes in the long-duration WT\npeaks. According to our model, the shortening of the WT peaks corresponds to\nthe orbital period decay of the NS-WD binary. We consider two mass transfer\nmodes, namely, stable and unstable mass transfer, to examine how the orbital\nperiod evolves. Our findings reveal distinct evolutionary pathways for the two\nrepeaters: for FRB~20121102A, the NS-WD binary likely undergoes a combination\nof common envelope (CE) ejection and Roche lobe overflow, whereas for\nFRB~20201124A the system may experience multiple CE ejections. These findings\nwarrant further validation through follow-up observations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-22T05:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.15607v1","title":"Coupled Instantons In A Four-Well Potential With Application To The\n  Tunneling Of A Composite Particle","summary":"Coupled instantons are introduced by generalizing the double well potential\nto multiple mutually coupled wells. Physically this corresponds to the\nsimultaneous tunneling of multiple degrees of freedom. A system with four equal\nminima is examined in detail. It has three instanton types or flavors with\ndistinct actions. For weak coupling and subject to there being a single large\n(or small) parameter, the interactive system can be handled perturbatively. The\nzero mode problem arising from time translation symmetry is handled via the\nFadeev-Popov procedure. A diagrammatic procedure allows corrections to the\nfluctuation determinant to be calculated systematically. Independent instanton\ncontributions are summed over by extending the dilute gas approximation to\nthree flavors and energy splittings of the lowest four states is calculated.\nAll tunneling amplitudes are concisely expressed in terms of elementary\nfunctions. While the model is possibly useful for a variety of physical\nsystems, an application is made here to the tunneling of a composite particle\nin one dimension.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP,nucl-th","published":"2025-04-22T05:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.15623v1","title":"RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model\n  for Multi-Path Aware Radio Map Construction","summary":"In this paper, we propose a novel physics-informed generative learning\napproach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient\nmultipath-aware radio map (RM) construction. As wireless communication evolves\ntowards environment-aware paradigms, driven by the increasing demand for\nintelligent and proactive optimization in sixth-generation (6G) networks,\naccurate construction of RMs becomes crucial yet highly challenging.\nConventional electromagnetic (EM)-based methods, such as full-wave solvers and\nray-tracing approaches, exhibit substantial computational overhead and limited\nadaptability to dynamic scenarios. Although, existing neural network (NN)\napproaches have efficient inferencing speed, they lack sufficient consideration\nof the underlying physics of EM wave propagation, limiting their effectiveness\nin accurately modeling critical EM singularities induced by complex multipath\nenvironments. To address these fundamental limitations, we propose a novel\nphysics-inspired RM construction method guided explicitly by the Helmholtz\nequation, which inherently governs EM wave propagation. Specifically, we\ntheoretically establish a direct correspondence between EM singularities, which\ncorrespond to the critical spatial features influencing wireless propagation,\nand regions defined by negative wave numbers in the Helmholtz equation. Based\non this insight, we design an innovative dual generative diffusion model (DM)\nframework comprising one DM dedicated to accurately inferring EM singularities\nand another DM responsible for reconstructing the complete RM using these\nsingularities along with environmental contextual information. Our\nphysics-informed approach uniquely combines the efficiency advantages of\ndata-driven methods with rigorous physics-based EM modeling, significantly\nenhancing RM accuracy, particularly in complex propagation environments\ndominated by multipath effects.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-22T06:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.15628v1","title":"Joint Security-Latency Design for Short Packet-Based Low-Altitude\n  Communications","summary":"In this article, a joint security and latency analysis of short packet-based\nlow-altitude communications when the eavesdropper is close to the receiver is\naddressed. To reveal the impacts of the signal-to-noise ratio (SNR) and\nblock-length on latency in communications, we propose a new metric named secure\nlatency (SL) and derive the expressions for the effective secure probability\n(ESP) and the average SL. To minimize the average SL, different transmission\ndesigns are analyzed, in which the optimal solutions of SNR and block-length\nare provided. Numerical results validate our analysis and reveal the trade-off\nbetween reliability and security and the impacts of the block-length, SNR, and\npacket-generating rate on average SL, of which SNR and the block-length account\nfor main factors. In addition, we find that the performance of SL can be\nenhanced by allocating less SNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-22T06:40:28Z"}
{"aid":"http://arxiv.org/abs/2504.15636v1","title":"Contracting elements and conjugacy growth in Coxeter groups, graph\n  products, and further groups","summary":"In this article we construct contracting elements in the standard Cayley\ngraphs of the so-called periagroups, a family of groups introduced by the\nsecond-named author which include Coxeter groups, graph products, and Dyer\ngroups. As a consequence, we deduce that, unless they virtually split as direct\nproducts, periagroups are acylindrically hyperbolic and their conjugacy growth\nseries, with respect to standard generating sets, are transcendental.","main_category":"math.GR","categories":"math.GR,math.CO,math.MG","published":"2025-04-22T06:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.15651v1","title":"Atomically-Thin Transition Metal Dichalcogenide Nanolasers: Challenges\n  and Opportunities","summary":"Low energy consumption nanolasers are crucial for advancing on-chip\nintegrated optical interconnects and photonic integrated circuits. Monolayer\ntransition metal dichalcogenides (TMDs) have emerged as an energy-efficient\nalternative to traditional semiconductor materials for nanolaser optical gain\nmedium, promising ultralow lasing threshold powers. While several studies\nsuggest that TMDs meet the criteria for lasing, whether true lasing has been\nachieved remains a topic of heavy debate within the scientific community. In\nthis perspective, we offer an overview of the field, outlining the key\ncharacteristics of laser light and methods for testing these properties in\nTMD-based devices. We then conduct a thorough review of recent reports claiming\nlasing, assessing the findings against established criteria for laser light\nemission. Finally, we discuss future research directions and applications,\nhighlighting the key challenges that must be addressed to realize practical\nTMD-based nanolasers.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-22T07:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.15672v1","title":"Comparative Analysis of Evolutionary Algorithms for Energy-Aware\n  Production Scheduling","summary":"The energy transition is driving rapid growth in renewable energy generation,\ncreating the need to balance energy supply and demand with energy price\nawareness. One such approach for manufacturers to balance their energy demand\nwith available energy is energyaware production planning. Through energy-aware\nproduction planning, manufacturers can align their energy demand with dynamic\ngrid conditions, supporting renewable energy integration while benefiting from\nlower prices and reduced emissions. Energy-aware production planning can be\nmodeled as a multi-criteria scheduling problem, where the objectives extend\nbeyond traditional metrics like makespan or required workers to also include\nminimizing energy costs and emissions. Due to market dynamics and the NP-hard\nmulti-objective nature of the problem, evolutionary algorithms are widely used\nfor energy-aware scheduling. However, existing research focuses on the design\nand analysis of single algorithms, with limited comparisons between different\napproaches. In this study, we adapt NSGA-III, HypE, and $\\theta$-DEA as memetic\nmetaheuristics for energy-aware scheduling to minimize makespan, energy costs,\nemissions, and the number of workers, within a real-time energy market context.\nThese adapted metaheuristics present different approaches for environmental\nselection. In a comparative analysis, we explore differences in solution\nefficiency and quality across various scenarios which are based on benchmark\ninstances from the literature and real-world energy market data. Additionally,\nwe estimate upper bounds on the distance between objective values obtained with\nour memetic metaheuristics and reference sets obtained via an exact solver.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-22T07:54:05Z"}
{"aid":"http://arxiv.org/abs/2504.15697v1","title":"Uniqueness of $v$-adic Gamma Functions in the Gross-Koblitz-Thakur\n  Formulas","summary":"In this paper, we determine all continuous non-vanishing functions satisfying\nGross-Koblitz-Thakur formulas in positive characteristic.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T08:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.15705v1","title":"Spin and energy diffusion vs. subdiffusion in disordered spin chains","summary":"While the high-temperature spin diffusion in spin chains with random local\nfields has been the subject of numerous studies concerning the phenomenon of\nmany-body localization (MBL), the energy diffusion in the same models has been\nmuch less explored. We show that energy diffusion is faster at weak random\nfields but becomes essentially equal at strong fields; hence, both diffusions\ndetermine the slowest relaxation time scale (Thouless time) in the system.\nNumerically reachable finite-size systems reveal the anomalously large\ndistribution of diffusion constants with respect to actual field\nconfigurations. Despite the exponential-like dependence of diffusion on field\nstrength, results for the sensitivity to twisted boundary conditions are\nincompatible with the Thouless criterion for localization and the presumable\ntransition to MBL, at least for numerically reachable sizes. In contrast, we\nfind indications for the scenario of subdiffusive transport, in particular in\nthe dynamical diffusivity response.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.str-el","published":"2025-04-22T08:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.15708v1","title":"Domain-wall driven suppression of thermal conductivity in a\n  ferroelectric polycrystal","summary":"A common strategy for reducing thermal conductivity of polycrystalline\nsystems is to increase the number of grain boundaries. Indeed, grain boundaries\nenhance the probability of phonon scattering events, which has been applied to\ncontrol the thermal transport in a wide range of materials, including hard\nmetals, diamond, oxides and 2D systems such as graphene. Here, we report the\nopposite behavior in improper ferroelectric ErMnO3 polycrystals, where the\nthermal conductivity decreases with increasing grain size. We attribute this\nunusual relationship between heat transport and microstructure to phonon\nscattering at ferroelectric domain walls. The domain walls are more densely\npacked in larger grains, leading to an inversion of the classical\ngrain-boundary-dominated transport behavior. Our findings open additional\navenues for microstructural engineering of materials for thermoelectric and\nthermal management applications, enabling simultaneous control over mechanical,\nelectronic, and thermal properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T08:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.15714v1","title":"Autonomous Control of Redundant Hydraulic Manipulator Using\n  Reinforcement Learning with Action Feedback","summary":"This article presents an entirely data-driven approach for autonomous control\nof redundant manipulators with hydraulic actuation. The approach only requires\nminimal system information, which is inherited from a simulation model. The\nnon-linear hydraulic actuation dynamics are modeled using actuator networks\nfrom the data gathered during the manual operation of the manipulator to\neffectively emulate the real system in a simulation environment. A neural\nnetwork control policy for autonomous control, based on end-effector (EE)\nposition tracking is then learned using Reinforcement Learning (RL) with\nOrnstein-Uhlenbeck process noise (OUNoise) for efficient exploration. The RL\nagent also receives feedback based on supervised learning of the forward\nkinematics which facilitates selecting the best suitable action from\nexploration. The control policy directly provides the joint variables as\noutputs based on provided target EE position while taking into account the\nsystem dynamics. The joint variables are then mapped to the hydraulic valve\ncommands, which are then fed to the system without further modifications. The\nproposed approach is implemented on a scaled hydraulic forwarder crane with\nthree revolute and one prismatic joint to track the desired position of the EE\nin 3-Dimensional (3D) space. With the emulated dynamics and extensive learning\nin simulation, the results demonstrate the feasibility of deploying the learned\ncontroller directly on the real system.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T08:55:28Z"}
{"aid":"http://arxiv.org/abs/2504.15718v1","title":"Riesz transform, function spaces and their applications on infinite\n  dimensional compact groups","summary":"On a compact connected group $G$, consider the infinitesimal generator $-L$\nof a central symmetric Gaussian convolution semigroup $(\\mu_t)_{t>0}$. We\nestablish several regularity results of the solution to the Poisson equation\n$LU=F$, both in strong and weak senses. To this end, we introduce two classes\nof Lipschitz spaces for $1\\le p\\le \\infty$: $\\Lambda_{\\theta}^p$, defined via\nthe associated Markov semigroup, and $\\mathrm L_{\\theta}^p$, defined via the\nintrinsic distance. In the strong sense, we prove a priori Sobolev regularity\nand Lipschitz regularity in the class of $\\Lambda_{\\theta}^p$ space. In the\ndistributional sense, we further show local regularity in the class of $\\mathrm\nL_{\\theta}^{\\infty}$ space. These results require some strong assumptions on\n$-L$. Our main techniques build on the differentiability of the associated\nsemigroup, explicit dimension-free $L^p$ ($1<p<\\infty$) boundedness of first\nand second order Riesz transforms, and a comparison between the two Lipschitz\nnorms.","main_category":"math.AP","categories":"math.AP,math.FA,math.PR","published":"2025-04-22T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.15722v1","title":"From predictions to confidence intervals: an empirical study of\n  conformal prediction methods for in-context learning","summary":"Transformers have become a standard architecture in machine learning,\ndemonstrating strong in-context learning (ICL) abilities that allow them to\nlearn from the prompt at inference time. However, uncertainty quantification\nfor ICL remains an open challenge, particularly in noisy regression tasks. This\npaper investigates whether ICL can be leveraged for distribution-free\nuncertainty estimation, proposing a method based on conformal prediction to\nconstruct prediction intervals with guaranteed coverage. While traditional\nconformal methods are computationally expensive due to repeated model fitting,\nwe exploit ICL to efficiently generate confidence intervals in a single forward\npass. Our empirical analysis compares this approach against ridge\nregression-based conformal methods, showing that conformal prediction with\nin-context learning (CP with ICL) achieves robust and scalable uncertainty\nestimates. Additionally, we evaluate its performance under distribution shifts\nand establish scaling laws to guide model training. These findings bridge ICL\nand conformal prediction, providing a theoretically grounded and new framework\nfor uncertainty quantification in transformer-based models.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T09:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15729v1","title":"Strong discrete Morse theory","summary":"The purpose of this work is to develop a version of Forman's discrete Morse\ntheory for simplicial complexes, based on internal strong collapses. Classical\ndiscrete Morse theory can be viewed as a generalization of Whitehead's\ncollapses, where each Morse function on a simplicial complex $K$ defines a\nsequence of elementary internal collapses. This reduction guarantees the\nexistence of a CW-complex that is homotopy equivalent to $K$, with cells\ncorresponding to the critical simplices of the Morse function. However, this\napproach lacks an explicit combinatorial description of the attaching maps,\nwhich limits the reconstruction of the homotopy type of $K$. By restricting\ndiscrete Morse functions to those induced by total orders on the vertices, we\ndevelop a strong discrete Morse theory, generalizing the strong collapses\nintroduced by Barmak and Minian. We show that, in this setting, the resulting\nreduced CW-complex is regular, enabling us to recover its homotopy type\ncombinatorially. We also provide an algorithm to compute this reduction and\napply it to obtain efficient structures for complexes in the library of\ntriangulations by Benedetti and Lutz.","main_category":"math.AT","categories":"math.AT","published":"2025-04-22T09:23:45Z"}
{"aid":"http://arxiv.org/abs/2504.15744v1","title":"Existence and Spectrality of random measures generated by infinite\n  convolutions","summary":"In this paper, we construct a class of random measures $\\mu^{\\mathbf{n}}$ by\ninfinite convolutions. Given infinitely many admissible pairs $\\{(N_{k},\nB_{k})\\}_{k=1}^{\\infty}$ and a positive integral sequence\n$\\boldsymbol{n}=\\{n_{k}\\}_{k=1}^{\\infty}$, for every $\\boldsymbol{\\omega}\\in\n\\mathbb{N}^{\\mathbb{N}}$, we write $\\mu^{\\mathbf{n}}(\\boldsymbol{\\omega}) =\n\\delta_{N_{\\omega_{1}}^{-n_{1}}B_{\\omega_{1}}} *\n\\delta_{N_{\\omega_{1}}^{-n_{1}}N_{\\omega_{2}}^{-n_{2}}B_{\\omega_{2}}} *\n\\cdots$. If $n_{k}=1$ for $k\\geq 1$, write\n$\\mu(\\boldsymbol{\\omega})=\\mu^{\\mathbf{n}}(\\boldsymbol{\\omega})$.\n  First, we show that the mapping $\\mu^{\\mathbf{n}}: (\\boldsymbol{\\omega}, B)\n\\mapsto \\mu^{\\mathbf{n}}(\\boldsymbol{\\omega})(B)$ is a random measure if the\nfamily of Borel probability measures $\\{\\mu(\\boldsymbol{\\omega}) :\n\\boldsymbol{\\omega} \\in \\mathbb{N}^{\\mathbb{N}}\\}$ is tight. Then, for every\nBernoulli measure $\\mathbb{P}$ on $\\mathbb{N}^{\\mathbb{N}}$, the random measure\n$\\mu^{\\mathbf{n}}$ is also a spectral measure $\\mathbb{P}$-a.e.. If the\npositive integral sequence $\\boldsymbol{n}$ is unbounded, the random measure\n$\\mu^{\\mathbf{n}}$ is a spectral measure regardless of the measures on the\nsequence space $\\mathbb{N}^{\\mathbb{N}}$. Moreover, we provide some sufficient\nconditions for the existence of the random measure $\\mu^{\\boldsymbol{n}}$.\nFinally, we verify that random measures have the intermediate-value property.","main_category":"math.FA","categories":"math.FA","published":"2025-04-22T09:46:31Z"}
{"aid":"http://arxiv.org/abs/2504.15746v1","title":"Enhancing Tennis Training with Real-Time Swing Data Visualisation in\n  Immersive Virtual Reality","summary":"Recent advances in immersive technology have opened new possibilities in\nsports training, especially for activities requiring precise motor skills, such\nas tennis. In this paper, we present a virtual reality (VR) tennis training\nsystem integrating real-time performance feedback through a wearable sensor\ndevice. Ten participants wore the sensor on their dominant hand to capture\nmotion data, including swing speed and swing power, while engaging in a VR\ntennis environment. Initially, participants performed baseline tests without\naccess to performance metrics. In subsequent tests, participants executed\nsimilar routines with their swing data displayed in real-time via a VR overlay.\nQualitative and quantitative results indicated that real-time visual feedback\nled to improved performance behaviors and enhanced situational awareness. Some\nparticipants exhibited increased swing consistency and strategic\ndecision-making, though improvements in accuracy varied individually.\nAdditionally, subjective feedback highlighted that the immersive experience,\ncombined with instantaneous performance metrics, enhanced player engagement and\nmotivation. These findings illustrate the effectiveness of VR-based data\nvisualisation in sports training, suggesting broader applicability in\nperformance enhancement.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T09:48:40Z"}
{"aid":"http://arxiv.org/abs/2504.15750v1","title":"Unique Bernoulli Gibbs states and g-measures","summary":"A sufficient condition for the Gibbs states of a shift-invariant\nspecification on a one-dimensional lattice to be the $g$-chains for some\ncontinuous function $g$ is obtained. This is then used to derive criteria under\nwhich there is a unique Gibbs state, which is also shift-invariant and\nBernoulli.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T09:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.15751v1","title":"GADS: A Super Lightweight Model for Head Pose Estimation","summary":"In human-computer interaction, head pose estimation profoundly influences\napplication functionality. Although utilizing facial landmarks is valuable for\nthis purpose, existing landmark-based methods prioritize precision over\nsimplicity and model size, limiting their deployment on edge devices and in\ncompute-poor environments. To bridge this gap, we propose \\textbf{Grouped\nAttention Deep Sets (GADS)}, a novel architecture based on the Deep Set\nframework. By grouping landmarks into regions and employing small Deep Set\nlayers, we reduce computational complexity. Our multihead attention mechanism\nextracts and combines inter-group information, resulting in a model that is\n$7.5\\times$ smaller and executes $25\\times$ faster than the current lightest\nstate-of-the-art model. Notably, our method achieves an impressive reduction,\nbeing $4321\\times$ smaller than the best-performing model. We introduce vanilla\nGADS and Hybrid-GADS (landmarks + RGB) and evaluate our models on three\nbenchmark datasets -- AFLW2000, BIWI, and 300W-LP. We envision our architecture\nas a robust baseline for resource-constrained head pose estimation methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:53:25Z"}
{"aid":"http://arxiv.org/abs/2504.15757v1","title":"Retrieving day- and nightside atmospheric properties of the ultra-hot\n  Jupiter TOI-2109b. Detection of Fe and CO emission lines and evidence for\n  inefficient heat transport","summary":"The ultra-hot Jupiter (UHJ) TOI-2109b marks the lower edge of the equilibrium\ntemperature gap between 3500 K and 4500 K, an unexplored thermal regime that\nseparates KELT-9b, the hottest planet yet discovered, from all other currently\nknown gas giants. To study the structure of TOI-2109b's atmosphere, we obtained\nhigh-resolution emission spectra of both the planetary day- and nightsides with\nCARMENES and CRIRES$^+$. By applying the cross-correlation technique, we\nidentified the emission signatures of Fe I and CO, as well as a thermal\ninversion layer in the dayside atmosphere; no significant H$_2$O signal was\ndetected from the dayside. None of the analyzed species were detectable from\nthe nightside atmosphere. We applied a Bayesian retrieval framework that\ncombines high-resolution spectroscopy with photometric measurements to\nconstrain the dayside atmospheric parameters and derive upper limits for the\nnightside hemisphere. The dayside thermal inversion extends from 3200 K to 4600\nK, with an atmospheric metallicity consistent with that of the host star (0.36\ndex). Only weak constraints could be placed on the C/O ratio ($>$ 0.15). The\nretrieved spectral line broadening is consistent with tidally locked rotation,\nindicating the absence of strong dynamical processes. An upper temperature\nlimit of 2400 K and a maximum atmospheric temperature gradient of 700 K/log bar\ncould be derived for the nightside. Comparison of the retrieved dayside T-p\nprofile with theoretical models, the absence of strong atmospheric dynamics,\nand significant differences in the thermal constraints between the day- and\nnightside hemispheres suggest a limited heat transport efficiency across the\nplanetary atmosphere. Overall, our results place TOI-2109b in a transitional\nregime between the UHJs below the thermal gap, which show both CO and H$_2$O\nemission lines, and KELT-9b, where molecular features are largely absent.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-22T10:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.15795v1","title":"Spontaneous stochasticity and the Armstrong-Vicol passive scalar","summary":"Spontaneous stochasticity refers to the emergence of intrinsic randomness in\ndeterministic systems under singular limits, a phenomenon conjectured to be\nfundamental in turbulence. Armstrong and Vicol \\citep{AV23,AV24} recently\nconstructed a deterministic, divergence-free multiscale vector field\narbitrarily close to a weak Euler solution, proving that a passive scalar\ntransported by this field exhibits anomalous dissipation and lacks a selection\nprinciple in the vanishing diffusivity limit.\n  {\\it This work aims to explain why this passive scalar exhibits both\nLagrangian and Eulerian spontaneous stochasticity.}\n  Part I provides a historical overview of spontaneous stochasticity, details\nthe Armstrong-Vicol passive scalar model, and presents numerical evidence of\nanomalous diffusion, along with a refined description of the Lagrangian flow\nmap.\n  In Part II, we develop a theoretical framework for Eulerian spontaneous\nstochasticity. We define it mathematically, linking it to ill-posedness and\nfinite-time trajectory splitting, and explore its measure-theoretic properties\nand the connection to RG formalism. This leads us to a well-defined {\\it\nmeasure selection principle} in the inviscid limit. This approach allows us to\nrigorously classify universality classes based on the ergodic properties of\nregularisations. To complement our analysis, we provide simple yet insightful\nnumerical examples.\n  Finally, we show that the absence of a selection principle in the\nArmstrong-Vicol model corresponds to Eulerian spontaneous stochasticity of the\npassive scalar. We also numerically compute the probability density of the\neffective renormalised diffusivity in the inviscid limit. We argue that the\nlack of a selection principle should be understood as a measure selection\nprinciple over weak solutions of the inviscid system.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T11:15:21Z"}
{"aid":"http://arxiv.org/abs/2504.15796v1","title":"Locating and Mitigating Gradient Conflicts in Point Cloud Domain\n  Adaptation via Saliency Map Skewness","summary":"Object classification models utilizing point cloud data are fundamental for\n3D media understanding, yet they often struggle with unseen or\nout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain\nadaptation (UDA) methods typically employ a multi-task learning (MTL) framework\nthat combines primary classification tasks with auxiliary self-supervision\ntasks to bridge the gap between cross-domain feature distributions. However,\nour further experiments demonstrate that not all gradients from\nself-supervision tasks are beneficial and some may negatively impact the\nclassification performance. In this paper, we propose a novel solution, termed\nSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient\nconflicts. Specifically, our method designs a new scoring mechanism based on\nthe skewness of 3D saliency maps to estimate gradient conflicts without\nrequiring target labels. Leveraging this, we develop a sample selection\nstrategy that dynamically filters out samples whose self-supervision gradients\nare not beneficial for the classification. Our approach is scalable,\nintroducing modest computational overhead, and can be integrated into all the\npoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that our\nmethod outperforms state-of-the-art approaches. In addition, we provide a new\nperspective on understanding the UDA problem through back-propagation analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-22T11:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.15798v1","title":"Quantum Entanglement Autodistillation in Baryon Pair Decays","summary":"We study the spin-entangled mixed state of a spin-1/2 baryon-antibaryon pair\nproduced in the process e+e- to J/psi, psi(2S) to BBbar. We demonstrate that\nthe spin entanglement of the system can increase following the decays B to b +\nM and Bbar to bbar + Mbar, where b and bbar are spin-1/2 baryons and M, Mbar\nare spin-0 mesons. This phenomenon, known as entanglement autodistillation,\nrepresents a probabilistic amplification of entanglement during the decay\nprocess. We analyze the underlying mechanism and show that it depends only on\nthe initial state of the BBbar system and the decay parameter alphaD, but not\non the phase parameter phiD.","main_category":"hep-ph","categories":"hep-ph,hep-ex,quant-ph","published":"2025-04-22T11:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.15816v1","title":"Toward optimal-scaling DFT: stochastic Hartree theory in the\n  thermodynamic and complete basis set limits at arbitrary temperature","summary":"We present the first mathematical analysis of stochastic density functional\ntheory (DFT) in the context of the Hartree approximation. We motivate our\nanalysis via the notion of nearly-optimal or $\\tilde{O}(n)$ scaling with\nrespect to the number $n$ of computational degrees of freedom, independent of\nthe number of electrons, in both the thermodynamic and complete basis set\nlimits. Indeed, the promise of such scaling is the primary motivation for\nstochastic DFT relative to conventional orbital-based approaches, as well as\ndeterministic orbital-free alternatives. We highlight three key targets for\nmathematical attention, which are synthesized in our algorithm and analysis.\nFirst, we identify a particular stochastic estimator for the Hartree potential\nwhose sample complexity is essentially independent of the discretization size.\nSecond, we reformulate the self-consistent field iteration as a stochastic\nmirror descent method where the Fermi-Dirac entropy plays the role of the\nBregman potential, and we prove a nearly discretization-independent bound on\nthe number of iterations needed to reach fixed accuracy. Third, motivated by\nthe estimator, we introduce a novel pole expansion scheme for the square-root\nFermi-Dirac operator, preserving $\\tilde{O}(n)$ cost per mirror descent\niteration even in the complete basis set limit. Combining these ingredients, we\nestablish nearly-optimal scaling in both limits of interest under reasonable\nassumptions on the basis sets chosen for discretization. Extensive numerical\nexperiments on problems with as many as $10^{6}$ degrees of freedom validate\nour algorithm and support the theory of nearly-optimal scaling.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T11:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.15819v1","title":"Delayed Keen Model with Inflation","summary":"Keen's model describes the dynamics between wage share, employment rate and\ndebt ratio. In literature, the model was extended to represent the effects of\ninflation and also the speculative money flow. Based on the inflationary model,\nwe take into account a time delay in the inflation term which stands for the\nperiod before the effects of inflation are seen. We observe that, the delayed\nsystem may experience a Hopf bifurcation and exhibit cyclic behavior around an\nequilibrium point, although the non-delayed model is stable under the same\nconditions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T12:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.15866v1","title":"On the projective structures given by theta","summary":"Given a compact Riemann surface $C$, the line in $H^0(J_C,\\, 2\\Theta)$\northogonal to the sections vanishing at $0$ produces a natural projective\nstructure on $C$. We investigate the properties of this projective structure.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T13:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.15875v1","title":"Identifying eclipsing binary stars with TESS data based on a new hybrid\n  deep learning model","summary":"Eclipsing binary systems (EBs), as foundational objects in stellar\nastrophysics, have garnered significant attention in recent years. These\nsystems exhibit periodic decreases in light intensity when one star obscures\nthe other from the observer's perspective, producing characteristic light\ncurves (LCs). With the advent of the Transiting Exoplanet Survey Satellite\n(TESS), a vast repository of stellar LCs has become available, offering\nunprecedented opportunities for discovering new EBs. To efficiently identify\nsuch systems, we propose a novel method that combines LC data and generalized\nLomb-Scargle periodograms (GLS) data to classify EBs. At the core of this\nmethod is CNN Attention LSTM Net (CALNet), a hybrid deep learning model\nintegrating Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM)\nnetworks, and an Attention Mechanism based on the Convolutional Block Attention\nModule (CBAM). We collected 4,225 EB samples, utilizing their 2-minute cadence\nLCs for model training and validation. CALNet achieved a recall rate of 99.1%,\ndemonstrating its robustness and effectiveness. Applying it to TESS 2-minute\nLCs from Sectors 1 to 74, we identified 9,351 new EBs after manual visual\ninspection, significantly expanding the known sample size. This work highlights\nthe potential of advanced deep-learning techniques in large-scale astronomical\nsurveys and provides a valuable resource for further studies on EBs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-22T13:22:33Z"}
{"aid":"http://arxiv.org/abs/2504.15903v1","title":"Impact of Noise on LLM-Models Performance in Abstraction and Reasoning\n  Corpus (ARC) Tasks with Model Temperature Considerations","summary":"Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T13:43:58Z"}
{"aid":"http://arxiv.org/abs/2504.15906v1","title":"Restricted Repetitive Behaviors in Adolescent Males with Autism:\n  Volatility in Brain Functional Connectivities","summary":"This paper studies subtypes of restricted, repetitive and stereotypical\nbehaviors (RRBs) in adolescent males with autism spectrum disorder (ASD) from\nthe viewpoint of the dynamics of brain functional connectivities (FCs). Data\nfrom the ABIDE-II repository and Repetitive Behavior Scale-Revised (RBS-R)\nmetrics are used to form two ASD groups with tightly controlled demographics;\none comprises subjects with scores above threshold for the self-injurious\nbehaviors (SIBs) subscale, and the other subjects with scores below threshold\nfor SIBs, but above threshold for at least one of the other subscales\n(stereotyped, compulsive, ritualistic, insistence on sameness, restricted\ninterests). The dynamics of the coherence for FCs across distinct frequency\nbands are compared against matched controls, using a novel volatility measure\ncomputed in time-frequency space. We find statistically significant\ndifferences, on average, in the volatility of a relatively small set of FCs,\nmost mapping to either the default mode network or the cerebellum, in the mid-\nand high-frequency bands, and yielding higher volatility in subjects with high\nlevels of SIBs. Results suggest a distinct underlying profile for SIBs\ninvolving multiple brain regions associated with rewards and emotions\nprocessing. The work contributes to the identification of neural substrates\npotentially underlying behavioral subtypes, and may help target interventions.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-22T13:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.15910v1","title":"Consistency between Bulk and Boundary Causalities in Asymptotically\n  Anti-de Sitter Spacetimes","summary":"We investigate the consistency between bulk and boundary causalities in\nstatic, spherically symmetric, asymptotically anti-de Sitter (AdS) spacetimes.\nWe derive a general formula that provides sufficient conditions for time\nadvance, where bulk propagation arrives earlier than any boundary propagation.\nAs an application, we show that in Reissner--Nordstr\\\"{o}m--anti de Sitter\nspacetime, no geodesic satisfies the sufficient conditions for time advance\neven in the super-extremal case. Furthermore, we demonstrate that the\nEinstein--Euler--Heisenberg theory exhibits time advance when one or a linear\ncombination of the coupling constants is positive and below an upper bound\ndetermined by the AdS length scale.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-22T13:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.15913v1","title":"A Massive Gas Outflow Outside the Line-of-Sight: Imaging Polarimetry of\n  the Blue Excess Hot Dust Obscured Galaxy W0204-0506","summary":"(Aims) Hot Dust Obscured Galaxies (Hot DOGs) are a population of\nhyper-luminous, heavily obscured quasars. Although nuclear obscurations close\nto Compton-thick are typical, a fraction show blue UV spectral energy\ndistributions consistent with unobscured quasar activity, albeit two orders of\nmagnitude fainter than expected from their mid-IR luminosity. The origin of the\nUV emission in these Blue excess Hot DOGs (BHDs) has been linked to scattered\nlight from the central engine. Here we study the properties of the UV emission\nin the BHD WISE J020446.13-050640.8 (W0204-0506). (Methods) We use imaging\npolarization observations in the $R_{\\rm Special}$ band obtained with the FORS2\ninstrument at VLT. We compare these data with radiative transfer simulations to\nconstrain the characteristics of the scattering material. (Results) We find a\nspatially integrated polarization fraction of $24.7\\pm 0.7$%, confirming the\nscattered-light nature of the UV emission of W0204-0506. The source is\nspatially resolved in the observations and we find a gradient in polarization\nfraction and angle that is aligned with the extended morphology of the source\nfound in HST/WFC3 imaging. A dusty, conical polar outflow starting at the AGN\nsublimation radius with a half-opening angle $\\lesssim 50~\\rm deg$ viewed at an\ninclination $\\gtrsim 45~\\rm deg$ can reproduce the observed polarization\nfraction if the dust is graphite-rich. We find that the gas mass and outflow\nvelocity are consistent with the range of values found for [OIII] outflows\nthrough spectroscopy in other Hot DOGs, though it is unclear whether the\noutflow is energetic enough to affect the long-term evolution of the host\ngalaxy. Our study highlights the unique potential for polarization imaging to\nstudy dusty quasar outflows, providing complementary constraints to those\nobtained through traditional spectroscopic studies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-22T14:00:11Z"}
{"aid":"http://arxiv.org/abs/2504.15920v1","title":"ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order\n  Neighboring Feature Fusion","summary":"Graph Neural Networks (GNNs) have demonstrated strong performance across\nvarious graph-based tasks by effectively capturing relational information\nbetween nodes. These models rely on iterative message passing to propagate node\nfeatures, enabling nodes to aggregate information from their neighbors. Recent\nresearch has significantly improved the message-passing mechanism, enhancing\nGNN scalability on large-scale graphs. However, GNNs still face two main\nchallenges: over-smoothing, where excessive message passing results in\nindistinguishable node representations, especially in deep networks\nincorporating high-order neighbors; and scalability issues, as traditional\narchitectures suffer from high model complexity and increased inference time\ndue to redundant information aggregation. This paper proposes a novel framework\nfor large-scale graphs named ScaleGNN that simultaneously addresses both\nchallenges by adaptively fusing multi-level graph features. We first construct\nneighbor matrices for each order, learning their relative information through\ntrainable weights through an adaptive high-order feature fusion module. This\nallows the model to selectively emphasize informative high-order neighbors\nwhile reducing unnecessary computational costs. Additionally, we introduce a\nHigh-order redundant feature masking mechanism based on a Local Contribution\nScore (LCS), which enables the model to retain only the most relevant neighbors\nat each order, preventing redundant information propagation. Furthermore,\nlow-order enhanced feature aggregation adaptively integrates low-order and\nhigh-order features based on task relevance, ensuring effective capture of both\nlocal and global structural information without excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that our approach consistently\noutperforms state-of-the-art GNN models in both accuracy and computational\nefficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.15930v1","title":"StreamRL: Scalable, Heterogeneous, and Elastic RL for LLMs with\n  Disaggregated Stream Generation","summary":"Reinforcement learning (RL) has become the core post-training technique for\nlarge language models (LLMs). RL for LLMs involves two stages: generation and\ntraining. The LLM first generates samples online, which are then used to derive\nrewards for training. The conventional view holds that the colocated\narchitecture, where the two stages share resources via temporal multiplexing,\noutperforms the disaggregated architecture, in which dedicated resources are\nassigned to each stage. However, in real-world deployments, we observe that the\ncolocated architecture suffers from resource coupling, where the two stages are\nconstrained to use the same resources. This coupling compromises the\nscalability and cost-efficiency of colocated RL in large-scale training. In\ncontrast, the disaggregated architecture allows for flexible resource\nallocation, supports heterogeneous training setups, and facilitates\ncross-datacenter deployment.\n  StreamRL is designed with disaggregation from first principles and fully\nunlocks its potential by addressing two types of performance bottlenecks in\nexisting disaggregated RL frameworks: pipeline bubbles, caused by stage\ndependencies, and skewness bubbles, resulting from long-tail output length\ndistributions. To address pipeline bubbles, StreamRL breaks the traditional\nstage boundary in synchronous RL algorithms through stream generation and\nachieves full overlapping in asynchronous RL. To address skewness bubbles,\nStreamRL employs an output-length ranker model to identify long-tail samples\nand reduces generation time via skewness-aware dispatching and scheduling.\nExperiments show that StreamRL improves throughput by up to 2.66x compared to\nexisting state-of-the-art systems, and improves cost-effectiveness by up to\n1.33x in a heterogeneous, cross-datacenter setting.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-22T14:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.15980v1","title":"Construction of Butson matrices using Fourier matrices as input","summary":"Butson matrices are square orthogonal matrices, denoted by $BH(m,n)$, whose\nentries are the complex $m$th roots of unity and satisfy the condition\\\\\n$BH(m,n)\\cdot{BH(m,n)}^*=nI_n$, where ${BH(m,n)}^*$ is the conjugate transpose\nof $BH(m,n)$ and $I_n$ is the identity matrix. In this work, we propose\nconstructions for $BH(m,(n-1)n)$ then $BH(m,(\\frac{n}{2}-1)n)$, when $n$ and\n$m$ are even numbers, using the existing $BH(m,n)$. For each case, we provide\ntwo construction methods: one uses a single input Butson matrix, and another\nuses two input Butson matrices. Moreover, we present some results about the\nconstruction of Hadamard matrices.","main_category":"math.CO","categories":"math.CO","published":"2025-04-22T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.15981v1","title":"Differential modules: a perspective on Bass' question","summary":"Guided by the $Q$-shaped derived category framework introduced by Holm and\nJorgensen, we provide a differential module analogue of a classical result that\ncharacterises when a finitely generated module over a local commutative\nnoetherian ring has finite injective dimension. As an application, we\ncharacterise local Cohen-Macaulay rings using the homological algebra of\ndifferential modules.","main_category":"math.RT","categories":"math.RT,math.AC","published":"2025-04-22T15:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.15984v1","title":"Neuroadaptive Haptics: Comparing Reinforcement Learning from Explicit\n  Ratings and Neural Signals for Adaptive XR Systems","summary":"Neuroadaptive haptics offers a path to more immersive extended reality (XR)\nexperiences by dynamically tuning multisensory feedback to user preferences. We\npresent a neuroadaptive haptics system that adapts XR feedback through\nreinforcement learning (RL) from explicit user ratings and brain-decoded neural\nsignals. In a user study, participants interacted with virtual objects in VR\nwhile Electroencephalography (EEG) data were recorded. An RL agent adjusted\nhaptic feedback based either on explicit ratings or on outputs from a neural\ndecoder. Results show that the RL agent's performance was comparable across\nfeedback sources, suggesting that implicit neural feedback can effectively\nguide personalization without requiring active user input. The EEG-based neural\ndecoder achieved a mean F1 score of 0.8, supporting reliable classification of\nuser experience. These findings demonstrate the feasibility of combining\nbrain-computer interfaces (BCI) and RL to autonomously adapt XR interactions,\nreducing cognitive load and enhancing immersion.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T15:34:19Z"}
{"aid":"http://arxiv.org/abs/2504.16001v1","title":"Approximation of Invariant Solutions to the Nonlinear Filtration\n  Equation by Modified Pade Approximants","summary":"This paper deals with a mathematical model for oil filtration in a porous\nmedium and its self-similar and traveling wave regimes. The model consists of\nthe equation for conservation mass and dependencies for porosity, permeability,\nand oil density on pressure. The oil viscosity is considered to be the\nexperimentally expired parabolic relationship on pressure. To close the model,\ntwo types of Darcy law are used: the classic one and the dynamic one describing\nthe relaxation processes during filtration. In the former case, self-similar\nsolutions are studied, while in the latter case, traveling wave solutions are\nthe focus. Using the invariant solutions, the initial model is reduced to the\nnonlinear ordinary differential equations possessing the trajectories vanishing\nat infinity and representing the moving liquid fronts in porous media. To\napproximate these solutions, we elaborate the semi-analytic procedure based on\nmodified Pade approximants. In fact, we calculate sequentially Pade\napproximants up to 3d order for a two-point boundary value problem on the\nsemi-infinite domain. A good agreement of evaluated Pade approximants and\nnumerical solutions is observed. The approach provides relatively simple\nquasi-rational expressions of solutions and can be easily adapted for other\ntypes of model's nonlinearity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-22T16:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.16002v1","title":"A logarithmic analogue of Alladi's formula","summary":"Let $\\mu(n)$ be the M\\\"{o}bius function. Let $P^-(n)$ denote the smallest\nprime factor of an integer $n$. In 1977, Alladi established the following\nformula related to the prime number theorem for arithmetic progressions \\[\n  -\\sum_{\\substack{n\\geq 2\\\\ P^-(n)\\equiv \\ell ({\\rm\nmod}k)}}\\frac{\\mu(n)}{n}=\\frac1{\\varphi(k)} \\] for positive integers $\\ell,\nk\\ge$ with $(\\ell,k)=1$, where $\\varphi$ is Euler's totient function. In this\nnote, we will show a logarithmic analogue of Alladi's formula in an elementary\nproof.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T16:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.16005v1","title":"CAPO: Cost-Aware Prompt Optimization","summary":"Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.NE,stat.ML","published":"2025-04-22T16:14:31Z"}
{"aid":"http://arxiv.org/abs/2504.16031v1","title":"VR-based Intervention for Perspective Change: A Case to Investigate\n  Virtual Materiality","summary":"This paper addresses the concept of materiality in virtual environments,\nwhich we define as being composed of objects that can influence user experience\nactively. Such virtual materiality is closely related to its physical\ncounterpart, which is discussed in theoretical frameworks such as\nsociomateriality and actor-network theory. They define phenomena in terms of\nthe entanglement of human and non-human elements. We report on an early\ninvestigation of virtual materiality within the context of reflection and\nperspective change in nature-based virtual environments. We considered the case\nof university students reflecting on the planning and management of their\ntheses and major projects. Inspired by nature's known positive cognitive and\naffective effects and repeated questioning processes, we established a virtual\nreflection intervention to demonstrate the environmental mechanisms and\nmaterial characteristics relevant to virtual materiality. Our work is a\npreliminary step toward understanding virtual materiality and its implications\nfor research and the design of virtual environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T16:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.16037v1","title":"Adaptive Fault-tolerant Control of Underwater Vehicles with Thruster\n  Failures","summary":"This paper presents a fault-tolerant control for the trajectory tracking of\nautonomous underwater vehicles (AUVs) against thruster failures. We formulate\nfaults in AUV thrusters as discrete switching events during a UAV mission, and\ndevelop a soft-switching approach in facilitating shift of control strategies\nacross fault scenarios. We mathematically define AUV thruster fault scenarios,\nand develop the fault-tolerant control that captures the fault scenario via\nBayesian approach. Particularly, when the AUV fault type switches from one to\nanother, the developed control captures the fault states and maintains the\ncontrol by a linear quadratic tracking controller. With the captured fault\nstates by Bayesian approach, we derive the control law by aggregating the\ncontrol outputs for individual fault scenarios weighted by their Bayesian\nposterior probability. The developed fault-tolerant control works in an\nadaptive way and guarantees soft-switching across fault scenarios, and requires\nno complicated fault detection dedicated to different type of faults. The\nentailed soft-switching ensures stable AUV trajectory tracking when fault type\nshifts, which otherwise leads to reduced control under hard-switching control\nstrategies. We conduct numerical simulations with diverse AUV thruster fault\nsettings. The results demonstrate that the proposed control can provide smooth\ntransition across thruster failures, and effectively sustain AUV trajectory\ntracking control in case of thruster failures and failure shifts.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-22T17:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.16413v1","title":"Hierarchical Distributed Architecture for the Least Allan Variance\n  Atomic Timing","summary":"In this paper, we propose a hierarchical distributed timing architecture\nbased on an ensemble of miniature atomic clocks. The goal is to ensure\nsynchronized and accurate timing in a normal operating mode where Global\nNavigation Satellite System (GNSS) signals are available, as well as in an\nemergency operating mode during GNSS failures. At the lower level, the\nminiature atomic clocks employ a distributed control strategy that uses only\nlocal information to ensure synchronization in both modes. The resulting\nsynchronized time or generated time scale has the best frequency stability, as\nmeasured by the Allan variance, over the short control period. In the upper\nlayer, a supervisor controls the long-term behavior of the generated time\nscale. In the normal operating mode, the supervisor periodically anchors the\ngenerated time scale to the standard time based on GNSS signals, while in the\nemergency operating mode, it applies optimal floating control to reduce the\ndivergence rate of the generated time scale, which is not observable from the\nmeasurable time difference between the miniature atomic clocks. This floating\ncontrol aims to explicitly control the generated time scale to have the least\nAllan variance over the long control period. Finally, numerical examples are\nprovided to demonstrate the effectiveness and feasibility of the architecture\nin high-precision, GNSS-resilient atomic timing.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:35:33Z"}
{"aid":"http://arxiv.org/abs/2504.16459v1","title":"Insect-Computer Hybrid Speaker: Speaker using Chirp of the Cicada\n  Controlled by Electrical Muscle Stimulation","summary":"We propose \"Insect-Computer Hybrid Speaker\", which enables us to make musics\nmade from combinations of computer and insects. Lots of studies have proposed\nmethods and interfaces for controlling insects and obtaining feedback. However,\nthere have been less research on the use of insects for interaction with third\nparties. In this paper, we propose a method in which cicadas are used as\nspeakers triggered by using Electrical Muscle Stimulation (EMS). We explored\nand investigated the suitable waveform of chirp to be controlled, the\nappropriate voltage range, and the maximum pitch at which cicadas can chirp.","main_category":"cs.HC","categories":"cs.HC,cs.AR,cs.ET,cs.RO,cs.SD","published":"2025-04-23T07:04:37Z"}
{"aid":"http://arxiv.org/abs/2504.16467v1","title":"MTSGL: Multi-Task Structure Guided Learning for Robust and Interpretable\n  SAR Aircraft Recognition","summary":"Aircraft recognition in synthetic aperture radar (SAR) imagery is a\nfundamental mission in both military and civilian applications. Recently deep\nlearning (DL) has emerged a dominant paradigm for its explosive performance on\nextracting discriminative features. However, current classification algorithms\nfocus primarily on learning decision hyperplane without enough comprehension on\naircraft structural knowledge. Inspired by the fined aircraft annotation\nmethods for optical remote sensing images (RSI), we first introduce a\nstructure-based SAR aircraft annotations approach to provide structural and\ncompositional supplement information. On this basis, we propose a multi-task\nstructure guided learning (MTSGL) network for robust and interpretable SAR\naircraft recognition. Besides the classification task, MTSGL includes a\nstructural semantic awareness (SSA) module and a structural consistency\nregularization (SCR) module. The SSA is designed to capture structure semantic\ninformation, which is conducive to gain human-like comprehension of aircraft\nknowledge. The SCR helps maintain the geometric consistency between the\naircraft structure in SAR imagery and the proposed annotation. In this process,\nthe structural attribute can be disentangled in a geometrically meaningful\nmanner. In conclusion, the MTSGL is presented with the expert-level aircraft\nprior knowledge and structure guided learning paradigm, aiming to comprehend\nthe aircraft concept in a way analogous to the human cognitive process.\nExtensive experiments are conducted on a self-constructed multi-task SAR\naircraft recognition dataset (MT-SARD) and the effective results illustrate the\nsuperiority of robustness and interpretation ability of the proposed MTSGL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:27:08Z"}
{"aid":"http://arxiv.org/abs/2504.16488v1","title":"A strategy for the enhancement of barocaloric performance in plastic\n  crystal solid solutions","summary":"The drive for solid-state heating and cooling technologies is fuelled by\ntheir potential for enhanced sustainability and environmental impact compared\nto traditional vapour compression devices. The recent discovery of colossal\nbarocaloric (BC) effects in the plastic crystal (PC) neopentyl glycol (NPG) has\nhighlighted PCs as promising candidates for future solid-state thermal\nmanagement. However, achieving optimal operational temperatures, low-pressure\nrequirements, and substantial entropy changes in a single material remains\nchallenging. Here, we demonstrate a strategy to address these constraints by\nforming a ternary solid solution of neopentyl PCs: NPG, pentaglycerine (PG) and\npentaerythritol (PE). Notably, by including only a small quantity (2%) of the\nthird component, we observe a seven-fold increase in reversible isothermal\nentropy change (|{\\Delta}Sit,rev| = 13.4 J kg-1 K-1) and twenty-fold increase\nin operational temperature span ({\\Delta}Tspan = 18 K) at pressures of 1 kbar,\ncompared to pure NPG. The origin of these enhancements is revealed by\nquasielastic neutron scattering and synchrotron powder x-ray diffraction. We\nfind a reduction in the activation energies of the rotational modes associated\nwith the main entropic component of the BC effect, linked to a weakening of the\nintermolecular hydrogen bond network. This is proposed to improve the phase\ntransition reversibility and operational temperature span by facilitating a\nbroadened first-order phase transition, characterised by a significant phase\nco-existence region. These findings suggest an effective strategy for\npracticable molecular BCs, which is to design solid solutions that exploit the\nlarge compositional phase space of multi-component molecular systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-23T08:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.16505v1","title":"TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand\n  Urban Scenes and Provide Travel Assistance","summary":"Tourism and travel planning increasingly rely on digital assistance, yet\nexisting multimodal AI systems often lack specialized knowledge and contextual\nunderstanding of urban environments. We present TraveLLaMA, a specialized\nmultimodal language model designed for urban scene understanding and travel\nassistance. Our work addresses the fundamental challenge of developing\npractical AI travel assistants through a novel large-scale dataset of 220k\nquestion-answer pairs. This comprehensive dataset uniquely combines 130k text\nQA pairs meticulously curated from authentic travel forums with GPT-enhanced\nresponses, alongside 90k vision-language QA pairs specifically focused on map\nunderstanding and scene comprehension. Through extensive fine-tuning\nexperiments on state-of-the-art vision-language models (LLaVA, Qwen-VL,\nShikra), we demonstrate significant performance improvements ranging from\n6.5\\%-9.4\\% in both pure text travel understanding and visual question\nanswering tasks. Our model exhibits exceptional capabilities in providing\ncontextual travel recommendations, interpreting map locations, and\nunderstanding place-specific imagery while offering practical information such\nas operating hours and visitor reviews. Comparative evaluations show TraveLLaMA\nsignificantly outperforms general-purpose models in travel-specific tasks,\nestablishing a new benchmark for multi-modal travel assistance systems.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-23T08:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.16524v1","title":"Modality Reliability Guided Multimodal Recommendation","summary":"Multimodal recommendation faces an issue of the performance degradation that\nthe uni-modal recommendation sometimes achieves the better performance. A\npossible reason is that the unreliable item modality data hurts the fusion\nresult. Several existing studies have introduced weights for different\nmodalities to reduce the contribution of the unreliable modality data in\npredicting the final user rating. However, they fail to provide appropriate\nsupervisions for learning the modality weights, making the learned weights\nimprecise. Therefore, we propose a modality reliability guided multimodal\nrecommendation framework that uniquely learns the modality weights supervised\nby the modality reliability. Considering that there is no explicit label\nprovided for modality reliability, we resort to automatically identify it\nthrough the BPR recommendation objective. In particular, we define a modality\nreliability vector as the supervision label by the difference between\nmodality-specific user ratings to positive and negative items, where a larger\ndifference indicates a higher reliability of the modality as the BPR objective\nis better satisfied. Furthermore, to enhance the effectiveness of the\nsupervision, we calculate the confidence level for the modality reliability\nvector, which dynamically adjusts the supervision strength and eliminates the\nharmful supervision. Extensive experiments on three real-world datasets show\nthe effectiveness of the proposed method.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.16537v1","title":"Transformers for Complex Query Answering over Knowledge Hypergraphs","summary":"Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T09:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.16564v1","title":"SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral\n  Adaptive Information Propagation","summary":"Semantic segmentation of remote sensing imagery demands precise spatial\nboundaries and robust intra-class consistency, challenging conventional\nhierarchical models. To address limitations arising from spatial domain feature\nfusion and insufficient receptive fields, this paper introduces SAIP-Net, a\nnovel frequency-aware segmentation framework that leverages Spectral Adaptive\nInformation Propagation. SAIP-Net employs adaptive frequency filtering and\nmulti-scale receptive field enhancement to effectively suppress intra-class\nfeature inconsistencies and sharpen boundary lines. Comprehensive experiments\ndemonstrate significant performance improvements over state-of-the-art methods,\nhighlighting the effectiveness of spectral-adaptive strategies combined with\nexpanded receptive fields for remote sensing image segmentation.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-04-23T09:43:58Z"}
{"aid":"http://arxiv.org/abs/2504.16593v1","title":"$R_{\\rm e}$. II. Understanding (IC 3475)-type galaxy, aka ultra-diffuse\n  galaxy, structural scaling relations","summary":"It is explained why ultra-diffuse galaxies (UDGs), a subset of (IC 3475)-type\ngalaxies, do not have unexpectedly large sizes but large sizes that are in line\nwith expectations from the curved size-luminosity relation defined by brighter\nearly-type galaxies (ETGs). UDGs extend the faint end of the (absolute\nmagnitude, $\\mathfrak{M}$)-log(S\\'ersic index, $n$) and $\\mathfrak{M}$-(central\nsurface brightness, $\\mu_{\\rm 0}$) relations defined by ETGs, leading to the\nlarge effective half-light radii, $R_{\\rm e}$, in UDGs. It is detailed how the\nscatter in $\\mu_{\\rm 0}$, at a given $\\mathfrak{M}$, relates to variations in\nthe galaxies' values of $n$ and effective surface brightness, $\\mu_{\\rm e}$.\nThese variations map into changes in $R_{\\rm e}$ and produce the scatter about\nthe $\\mathfrak{M}$-$R_{\\rm e}$ relation at fixed $\\mathfrak{M}$. Similarly, the\nscatter in $\\mathfrak{M}$, at fixed $\\mu_{\\rm 0}$ and $n$, can be mapped into\nchanges in $R_{\\rm e}$. The increased scatter about the faint end of the\n$\\mathfrak{M}$-$R_{\\rm e}$ relation and the smaller scatter about\n$\\mathfrak{M}$-(isophotal radii, $R_{\\rm iso}$) relations are explained.\nArtificial and potentially misleading size-luminosity relations for UDGs are\nalso addressed. The suggestion that there may be two types of UDG appears\nill-founded, arising from the scatter about the $\\mathfrak{M}$-$\\mu_{\\rm 0}$\nrelation, which persists at all magnitudes. Hopefully, the understanding\npresented here will prove helpful for interpreting the many low surface\nbrightness galaxies that the Large Synoptic Survey Telescope will detect.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T10:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.16602v1","title":"The Balmer spectrum and telescope conjecture for infinite groups","summary":"We determine the Balmer spectrum of dualisable objects in the stable module\ncategory for $\\mathrm{H}_1\\mathfrak{F}$ groups of type $\\mathrm{FP}_{\\infty}$\nand show that the telescope conjecture holds for these categories. We also\ndetermine the spectrum of dualisable objects for certain infinite free products\nof finite groups. Using this, we give examples where the stable category is not\nstratified by the spectrum of dualisable objects and where the telescope\nconjecture does not hold.","main_category":"math.RT","categories":"math.RT,math.CT","published":"2025-04-23T10:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.16611v1","title":"Forms of Nice Functions","summary":"You can invent striking and challenging problems with unique solution by\nbuilding some symmetry into functional equations. Some are suitable for high\nschool; others could generate college-level projects involving computer\nalgebra. The problems are functional equations with group actions in the\nbackground. Interesting examples arise even from small finite groups. Whether a\ngiven problem ``works\" with a given choice of constant coefficients depends on\nwhether a related multilinear form is nonzero. These forms are essentially the\nclassical group determinants studied by Frobenius in the nineteenth century.","main_category":"math.GR","categories":"math.GR","published":"2025-04-23T10:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.16634v1","title":"Quantum algorithm for reducing amplitudes in order to search and filter\n  data","summary":"The method is introduced for fast data processing by reducing the probability\namplitudes of undesirable elements. The algorithm has a mathematical\ndescription and circuit implementation on a quantum processor. The idea is to\nmake a quick decision (down to a single iteration) based on the correspondence\nbetween the data and the desired result, with a probability proportionate to\nthis correspondence. Our approach allows one to calibrate the circuit to\ncontrol specified proportions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T11:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.16640v1","title":"SSLR: A Semi-Supervised Learning Method for Isolated Sign Language\n  Recognition","summary":"Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T11:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.16657v1","title":"A new characterization of Sobolev spaces on Lipschitz differentiability\n  spaces","summary":"We prove a new characterization of metric Sobolev spaces, in the spirit of\nBrezis--Van Schaftingen--Yung's asymptotic formula. A new feature of our work\nis that we do not need Poincar\\'e inequality which is a common tool in the\nliterature. Another new feature is that we find a direct link between\nBrezis--Van Schaftingen--Yung's asymptotic formula and Cheeger's Lipschitz\ndifferentiability.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-04-23T12:24:33Z"}
{"aid":"http://arxiv.org/abs/2504.16671v1","title":"LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative\n  Analysis","summary":"The use of large language models (LLMs) in qualitative analysis offers\nenhanced efficiency but raises questions about their alignment with the\ncontextual nature of research for design (RfD). This research examines the\ntrustworthiness of LLM-driven design insights, using qualitative coding as a\ncase study to explore the interpretive processes central to RfD. We introduce\nLLMCode, an open-source tool integrating two metrics, namely Intersection over\nUnion (IoU) and Modified Hausdorff Distance, to assess the alignment between\nhuman and LLM-generated insights. Across two studies involving 26 designers, we\nfind that while the model performs well with deductive coding, its ability to\nemulate a designer's deeper interpretive lens over the data is limited,\nemphasising the importance of human-AI collaboration. Our results highlight a\nreciprocal dynamic where users refine LLM outputs and adapt their own\nperspectives based on the model's suggestions. These findings underscore the\nimportance of fostering appropriate reliance on LLMs by designing tools that\npreserve interpretive depth while facilitating intuitive collaboration between\ndesigners and AI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T12:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.16688v1","title":"A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation\n  for 6G: MLR, ANOVA, and Residual Distribution Analysis","summary":"Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models with one to five components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-04-23T13:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.16707v1","title":"Hochschild (Co)homology of D-modules on rigid analytic spaces I","summary":"We introduce a formalism of Hochschild (co)-homology for $\\mathcal{D}$-cap\nmodules on smooth rigid analytic spaces based on the homological tools of\nInd-Banach $\\mathcal{D}$-cap modules. We introduce several categories of\n$\\mathcal{D}$-cap bimodules for which this theory is well-behaved. Among these,\nthe most important example is the category of diagonal $\\mathcal{C}$-complexes.\nWe give an explicit calculation of the Hochschild complex for diagonal\n$\\mathcal{C}$-complexes, and show that the Hochschild complex of\n$\\mathcal{D}$-cap is canonically isomorphic to the de Rham complex of $X$. In\nparticular, we obtain a Hodge-de Rham spectral sequence converging to the\nHochschild cohomology groups of $\\mathcal{D}$-cap. We obtain explicit formulas\nrelating the Hochschild cohomology and homology of a given diagonal\n$\\mathcal{C}$-complex.","main_category":"math.NT","categories":"math.NT,math.AG,math.RA,math.RT","published":"2025-04-23T13:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.16717v1","title":"Random walks on random networks of cliques: Inferring the network\n  structure","summary":"We study the properties of discrete-time random walks on networks formed by\nrandomly interconnected cliques, namely, random networks of cliques. Our\npurpose is to derive the parameters that define the network structure --\nspecifically, the distribution of clique size and the abundance of inter-clique\nlinks -- from the observation of selected statistical features along the random\nwalk. To this end, we apply a Bayesian approach based on recording the times\nspent by the walker inside successively visited cliques. The procedure is\nillustrated with some numerical examples of diverse complexity, where the\nrelevant structural parameters are successfully recovered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-23T13:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.16727v1","title":"V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental\n  Visual Variations","summary":"Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.16752v1","title":"Adversarial Knapsack for Sequential Competitive Resource Allocation","summary":"This work addresses competitive resource allocation in a sequential setting,\nwhere two players allocate resources across objects or locations of shared\ninterest. Departing from the simultaneous Colonel Blotto game, our framework\nintroduces a sequential decision-making dynamic, where players act with partial\nor complete knowledge of previous moves. Unlike traditional approaches that\nrely on complex mixed strategies, we focus on deterministic pure strategies,\nstreamlining computation while preserving strategic depth. Additionally, we\nextend the payoff structure to accommodate fractional allocations and payoffs,\nmoving beyond the binary, all-or-nothing paradigm to allow more granular\noutcomes. We model this problem as an adversarial knapsack game, formulating it\nas a bilevel optimization problem that integrates the leader's objective with\nthe follower's best-response. This knapsack-based approach is novel in the\ncontext of competitive resource allocation, with prior work only partially\nleveraging it for follower analysis. Our contributions include: (1) proposing\nan adversarial knapsack formulation for the sequential resource allocation\nproblem, (2) developing efficient heuristics for fractional allocation\nscenarios, and (3) analyzing the 0-1 knapsack case, providing a computational\nhardness result alongside a heuristic solution.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T14:24:17Z"}
{"aid":"http://arxiv.org/abs/2504.16753v1","title":"ViMoTest: A Tool to Specify ViewModel-Based GUI Test Scenarios using\n  Projectional Editing","summary":"Automated GUI testing is crucial in ensuring that presentation logic behaves\nas expected. However, existing tools often apply end-to-end approaches and face\nchallenges such as high specification efforts, maintenance difficulties, and\nflaky tests while coupling to GUI framework specifics. To address these\nchallenges, we introduce the ViMoTest tool, which leverages Behavior-driven\nDevelopment, the ViewModel architectural pattern, and projectional\nDomain-specific Languages (DSLs) to isolate and test presentation logic\nindependently of GUI frameworks. We demonstrate the tool with a small\nJavaFX-based task manager example and generate executable code.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.16771v1","title":"Projective Variety Recovery from Unknown Linear Projections","summary":"We study how a smooth irreducible algebraic variety $X$ of dimension $n$\nembedded in $\\mathbb{C} \\mathbb{P}^{m}$ (with $m \\geq n+2$), which degree is\n$d$, can be recovered using two projections from unknown points onto unknown\nhyperplanes. The centers and the hyperplanes of projection are unknown: the\nonly input is the defining equations of each projected varieties. We show how\nboth the projection operators and the variety in $\\mathbb{C} \\mathbb{P}^{m}$\ncan be recovered modulo some action of the group of projective transformations\nof $\\mathbb{C} \\mathbb{P}^{m}$. This configuration generalizes results obtained\nin the context of curves embedded in $\\mathbb{C} \\mathbb{P}^3$ and results\nconcerning surfaces embedded in $\\mathbb{C} \\mathbb{P}^4$.\n  We show how in a generic situation, a characteristic matrix of the pair of\nprojections can be recovered. In the process we address dimensional issues and\nas a result establish a necessary condition, as well as a sufficient condition\nto compute this characteristic matrix up to a finite-fold ambiguity. These\nconditions are expressed as minimal values of the degree of the dual variety.\n  Then we use this matrix to recover the class of the couple of projections and\nas a consequence to recover the variety. For a generic situation, two\nprojections define a variety with two irreducible components. One component has\ndegree $d(d-1)$ and the other has degree $d$, being the original variety.","main_category":"math.AG","categories":"math.AG,cs.SC","published":"2025-04-23T14:42:43Z"}
{"aid":"http://arxiv.org/abs/2504.16788v1","title":"Towards Explainable AI: Multi-Modal Transformer for Video-based Image\n  Description Generation","summary":"Understanding and analyzing video actions are essential for producing\ninsightful and contextualized descriptions, especially for video-based\napplications like intelligent monitoring and autonomous systems. The proposed\nwork introduces a novel framework for generating natural language descriptions\nfrom video datasets by combining textual and visual modalities. The suggested\narchitecture makes use of ResNet50 to extract visual features from video frames\nthat are taken from the Microsoft Research Video Description Corpus (MSVD), and\nBerkeley DeepDrive eXplanation (BDD-X) datasets. The extracted visual\ncharacteristics are converted into patch embeddings and then run through an\nencoder-decoder model based on Generative Pre-trained Transformer-2 (GPT-2). In\norder to align textual and visual representations and guarantee high-quality\ndescription production, the system uses multi-head self-attention and\ncross-attention techniques. The model's efficacy is demonstrated by performance\nevaluation using BLEU (1-4), CIDEr, METEOR, and ROUGE-L. The suggested\nframework outperforms traditional methods with BLEU-4 scores of 0.755 (BDD-X)\nand 0.778 (MSVD), CIDEr scores of 1.235 (BDD-X) and 1.315 (MSVD), METEOR scores\nof 0.312 (BDD-X) and 0.329 (MSVD), and ROUGE-L scores of 0.782 (BDD-X) and\n0.795 (MSVD). By producing human-like, contextually relevant descriptions,\nstrengthening interpretability, and improving real-world applications, this\nresearch advances explainable AI.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T15:03:37Z"}
{"aid":"http://arxiv.org/abs/2504.16808v1","title":"Desingularization of double covers of regular surfaces","summary":"Let $Z$ be a noetherian integral excellent regular scheme of dimension $2$.\nLet $Y$ be an integral normal scheme endowed with a finite flat morphism $Y\\to\nZ$ of degree $2$. We give a description of Lipman's desingularization of $Y$ by\nexplicit equations, leading to a desingularization algorithm for $Y$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-23T15:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.16812v1","title":"The rigidity statement in the Horowitz-Myers conjecture","summary":"In this paper, we give an alternative proof of the Horowitz-Myers conjecture\nin dimension $3 \\leq N \\leq 7$. Moreover, we show that a metric that achieves\nequality in the Horowitz-Myers conjecture is locally isometric to a\nHorowitz-Myers metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-23T15:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.16822v1","title":"Supersymmetric Warped Solutions from Type IIB Orientifold Reduction","summary":"We construct a family of supersymmetric solutions in Type IIB supergravity of\nthe form ${\\rm WAdS}_3\\times {\\rm WS}^3\\times T^4$, where ${\\rm WAdS}_3$ and\n${\\rm WS^3}$ denote a warped anti-de Sitter spacetime and a warped 3-sphere,\nrespectively, while $T^4$ denotes an internal 4-torus. These backgrounds are\nconstructed by uplifting corresponding solutions in the $D=6$,\n$\\mathcal{N}=(1,1)$ ungauged supergravity resulting from the compactification\nof Type IIB supergravity on a $T^4/\\mathbb{Z}_2$-orientifold. More\nspecifically, the supersymmetric solutions are ${\\rm WAdS}_3\\times {\\rm\nWS}^3\\times T^4$ with lightlike warped AdS$_3$ and ${\\rm WAdS}_3\\times {\\rm\nS}^3\\times T^4$ in which the warping of AdS$_3$ is generic. Moreover, we also\nconstruct solutions in the form of a warped product\n$\\mathrm{LM}^3_{\\zeta,\\omega}\\times_{{\\rm w}} \\mathrm{S}^3\\times T^4$ of a\n2-parameter deformation $\\mathrm{LM}^3_{\\zeta,\\omega}$ of ${\\rm AdS}_3$ and a\nthree-sphere. We discuss the relation of these backgrounds to known solutions.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-23T15:39:19Z"}
{"aid":"http://arxiv.org/abs/2504.16831v1","title":"Evaluating Autoencoders for Parametric and Invertible Multidimensional\n  Projections","summary":"Recently, neural networks have gained attention for creating parametric and\ninvertible multidimensional data projections. Parametric projections allow for\nembedding previously unseen data without recomputing the projection as a whole,\nwhile invertible projections enable the generation of new data points. However,\nthese properties have never been explored simultaneously for arbitrary\nprojection methods. We evaluate three autoencoder (AE) architectures for\ncreating parametric and invertible projections. Based on a given projection, we\ntrain AEs to learn a mapping into 2D space and an inverse mapping into the\noriginal space. We perform a quantitative and qualitative comparison on four\ndatasets of varying dimensionality and pattern complexity using t-SNE. Our\nresults indicate that AEs with a customized loss function can create smoother\nparametric and inverse projections than feed-forward neural networks while\ngiving users control over the strength of the smoothing effect.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T15:47:20Z"}
{"aid":"http://arxiv.org/abs/2504.16859v1","title":"$SO(4)$ gauged $O(5)$ Skyrmion on $\\mathbb{R}^4$","summary":"We have studied an $SO(4)$ gauged $O(5)$ Skyrmion on $\\mathbb{R}^4$ which can\nbe seen as a static soliton in $4+1$ dimension. This is a sequel of the known\n$SO(D)$ gauged $O(D+1)$ Skyrmions on $\\mathbb{R}^D$ in $D=2$ and in $D=3$, with\nboth of which its properties are compared. Two families of solutions are found,\nof these only one possessing a gauge decoupling limit. The curvatures of both\nof these solutions decay as $r^{-3}$, are bounded below by the topological\ncharge, and are localised to an absolute scale. As such, they may have the\npotential of being interpreted as instantons.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T16:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.16861v1","title":"Long-time dynamics for the Kelvin-Helmholtz equations close to circular\n  vortex sheets","summary":"We consider the Kelvin-Helmholtz system describing the evolution of a\nvortex-sheet near the circular stationary solution. Answering previous\nnumerical conjectures in the 90s physics literature, we prove an almost global\nexistence result for small-amplitude solutions. We first establish the\nexistence of a linear stability threshold for the Weber number, which\nrepresents the ratio between the square of the background velocity jump and the\nsurface tension. Then, we prove that for almost all values of the Weber number\nbelow this threshold any small solution lives for almost all times, remaining\nclose to the equilibrium. Our analysis reveals a remarkable stabilization\nphenomenon: the presence of both non-zero background velocity jump and\ncapillarity effects enables to prevent nonlinear instability phenomena, despite\nthe inherently unstable nature of the classical Kelvin-Helmholtz problem. This\nlong-time existence would not be achievable in a setting where capillarity\nalone provides linear stabilization, without the richer modulation induced by\nthe velocity jump. Our proof exploits the Hamiltonian nature of the equations.\nSpecifically, we employ Hamiltonian Birkhoff normal form techniques for\nquasi-linear systems together with a general approach for paralinearization of\nnon-linear singular integral operators. This approach allows us to control\nresonances and quasi-resonances at arbitrary order, ensuring the desired\nlong-time stability result.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T16:29:09Z"}
{"aid":"http://arxiv.org/abs/2504.16867v1","title":"A Bayesian Update Method for Exponential Family Projection Filters with\n  Non-Conjugate Likelihoods","summary":"The projection filter is one of the approximations to the solution of the\noptimal filtering problem. It approximates the filtering density by projecting\nthe dynamics of the square-root filtering density onto the tangent space of the\nsquare-root parametric densities manifold. While the projection filters for\nexponential and mixture families with continuous measurement processes have\nbeen well studied, the continuous-discrete projection filtering algorithm for\nnon-conjugate priors has received less attention.\n  In this paper, we introduce a simple Riemannian optimization method to be\nused for the Bayesian update step in the continuous-discrete projection filter\nfor exponential families. Specifically, we show that the Bayesian update can be\nformulated as an optimization problem of $\\alpha$-R\\'enyi divergence, where the\ncorresponding Riemannian gradient can be easily computed. We demonstrate the\neffectiveness of the proposed method via two highly non-Gaussian Bayesian\nupdate problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T16:43:57Z"}
{"aid":"http://arxiv.org/abs/2504.16871v1","title":"Exploring How LLMs Capture and Represent Domain-Specific Knowledge","summary":"We study whether Large Language Models (LLMs) inherently capture\ndomain-specific nuances in natural language. Our experiments probe the domain\nsensitivity of LLMs by examining their ability to distinguish queries from\ndifferent domains using hidden states generated during the prefill phase. We\nreveal latent domain-related trajectories that indicate the model's internal\nrecognition of query domains. We also study the robustness of these domain\nrepresentations to variations in prompt styles and sources. Our approach\nleverages these representations for model selection, mapping the LLM that best\nmatches the domain trace of the input query (i.e., the model with the highest\nperformance on similar traces). Our findings show that LLMs can differentiate\nqueries for related domains, and that the fine-tuned model is not always the\nmost accurate. Unlike previous work, our interpretations apply to both closed\nand open-ended generative tasks","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T16:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.16894v1","title":"Spectrometer-Free Electron Spectromicroscopy","summary":"We introduce an approach for performing spectrally resolved electron\nmicroscopy without the need for an electron spectrometer. The method involves\nan electron beam prepared as a coherent superposition of multiple paths, one of\nwhich passes near a laser-irradiated specimen. These paths are subsequently\nrecombined, and their interference is measured as a function of laser frequency\nand beam position. Electron--light scattering introduces inelastic components\ninto the interacting path, thereby disturbing the interference pattern. We\nimplement this concept using two masks placed at conjugate image planes. The\nmasks are complementary and act in tandem to fully suppress electron\ntransmission in the absence of a specimen. However, electron interaction with\nan illuminated specimen perturbs the imaging condition, enabling electron\ntransmission through the system. For a fixed external light intensity, the\ntransmitted electron current is proportional to the strength of the local\noptical response in the material. The proposed technique does not require\nmonochromatic electron beams, dramatically simplifying the design of spectrally\nresolved electron microscopes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T17:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16931v1","title":"Lattice study of $cc\\bar u\\bar s$ tetraquark channel in\n  $D^{(*)}D^{(*)}_s$ scattering","summary":"We present the first lattice QCD determination of coupled $DD_s^*$ and\n$D^*D_s$ scattering amplitudes in the $J^{P}=1^{+}$ channel and elastic $DD_s$\nscattering amplitude in the $J^{P}=0^{+}$ channel.The aim is to investigate\nwhether tetraquarks with flavor $cc\\bar u\\bar s$ exist in the region near\nthreshold. Lattice QCD ensembles from the CLS consortium with $m_{\\pi} \\sim\n280$ MeV, $a\\sim0.09$ fm and $L/a = 24, 32$ are utilized. Finite-volume spectra\nare determined via variational analysis of two-point correlation matrices,\ncomputed using large bases of operators resembling bilocal two-meson structures\nwithin the distillation framework. The scattering matrix for partial wave $l=0$\nis determined using lattice eigenenergies from multiple inertial frames\nfollowing L\\\"uscher's formalism as well as following the solutions of\nLippmann-Schwinger Equation in the finite-volume on a plane-wave basis. We\nobserve small nonzero energy shifts in the simulated spectra from the\nnoninteracting scenario in both the channels studied, which points to rather\nweak nontrivial interactions between the mesons involved. Despite the nonzero\nenergy shifts, the lattice-extracted $S$-wave amplitudes do not carry\nsignatures of any hadron pole features in the physical amplitudes in the energy\nregion near the threshold.","main_category":"hep-lat","categories":"hep-lat,hep-ex,hep-ph","published":"2025-04-23T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.17238v1","title":"Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn\n  Supportive Dialogues","summary":"Cognitive Restructuring (CR) is a psychotherapeutic process aimed at\nidentifying and restructuring an individual's negative thoughts, arising from\nmental health challenges, into more helpful and positive ones via multi-turn\ndialogues. Clinician shortage and stigma urge the development of human-LLM\ninteractive psychotherapy for CR. Yet, existing efforts implement CR via simple\ntext rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to\nalign with the psychotherapeutic process for effective CR. To address this gap,\nwe propose CRDial, a novel framework for CR, which creates multi-turn dialogues\nwith specifically designed identification and restructuring stages of negative\nthoughts, integrates sentence-level supportive conversation strategies, and\nadopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we\ndistill Crisp, a large-scale and high-quality bilingual dialogue dataset, from\nLLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and\n14B scales. Extensive human studies show the superiority of Crispers in\npointwise, pairwise, and intervention evaluations.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-24T04:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.17302v1","title":"Non-integrability of charged three-body problem","summary":"We consider the problem of $n$ points with positive masses interacting\npairwise with forces inversely proportional to the distance between them. In\nparticular, it is the classical gravitational, Coulomb or photo-gravitational\n$n$-body problem. Under this general form of interaction, we investigate the\nintegrability problem of three bodies. We show that the system is not\nintegrable except in one case when two among three interaction constants\nvanish. In our investigation, we used the Morales-Ramis theorem concerning the\nintegrability of a natural Hamiltonian system with a homogeneous potential and\nits generalization.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-24T06:56:06Z"}
{"aid":"http://arxiv.org/abs/2504.17313v1","title":"Tokenizing Stock Prices for Enhanced Multi-Step Forecast and Prediction","summary":"Effective stock price forecasting (estimating future prices) and prediction\n(estimating future price changes) are pivotal for investors, regulatory\nagencies, and policymakers. These tasks enable informed decision-making, risk\nmanagement, strategic planning, and superior portfolio returns. Despite their\nimportance, forecasting and prediction are challenging due to the dynamic\nnature of stock price data, which exhibit significant temporal variations in\ndistribution and statistical properties. Additionally, while both forecasting\nand prediction targets are derived from the same dataset, their statistical\ncharacteristics differ significantly. Forecasting targets typically follow a\nlog-normal distribution, characterized by significant shifts in mean and\nvariance over time, whereas prediction targets adhere to a normal distribution.\nFurthermore, although multi-step forecasting and prediction offer a broader\nperspective and richer information compared to single-step approaches, it is\nmuch more challenging due to factors such as cumulative errors and long-term\ntemporal variance. As a result, many previous works have tackled either\nsingle-step stock price forecasting or prediction instead. To address these\nissues, we introduce a novel model, termed Patched Channel Integration Encoder\n(PCIE), to tackle both stock price forecasting and prediction. In this model,\nwe utilize multiple stock channels that cover both historical prices and price\nchanges, and design a novel tokenization method to effectively embed these\nchannels in a cross-channel and temporally efficient manner. Specifically, the\ntokenization process involves univariate patching and temporal learning with a\nchannel-mixing encoder to reduce cumulative errors. Comprehensive experiments\nvalidate that PCIE outperforms current state-of-the-art models in forecast and\nprediction tasks.","main_category":"cs.CE","categories":"cs.CE,q-fin.CP","published":"2025-04-24T07:15:05Z"}
{"aid":"http://arxiv.org/abs/2504.17323v1","title":"CKMDiff: A Generative Diffusion Model for CKM Construction via Inverse\n  Problems with Learned Priors","summary":"Channel knowledge map (CKM) is a promising technology to enable\nenvironment-aware wireless communications and sensing with greatly enhanced\nperformance, by offering location-specific channel prior information for future\nwireless networks. One fundamental problem for CKM-enabled wireless systems\nlies in how to construct high-quality and complete CKM for all locations of\ninterest, based on only limited and noisy on-site channel knowledge data. This\nproblem resembles the long-standing ill-posed inverse problem, which tries to\ninfer from a set of limited and noisy observations the cause factors that\nproduced them. By utilizing the recent advances of solving inverse problems\nwith learned priors using generative artificial intelligence (AI), we propose\nCKMDiff, a conditional diffusion model that can be applied to perform various\ntasks for CKM constructions such as denoising, inpainting, and\nsuper-resolution, without having to know the physical environment maps or\ntransceiver locations. Furthermore, we propose an environment-aware data\naugmentation mechanism to enhance the model's ability to learn implicit\nrelations between electromagnetic propagation patterns and spatial-geometric\nfeatures. Extensive numerical results are provided based on the CKMImageNet and\nRadioMapSeer datasets, which demonstrate that the proposed CKMDiff achieves\nstate-of-the-art performance, outperforming various benchmark methods.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-24T07:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.17340v1","title":"Defects in unidimensional structures","summary":"In a previous work of the first authors, a non-holonomic model, generalising\nthe micromorphic models and allowing for curvature (disclinations) to arise\nfrom the kinematic values, was presented. In the present paper, a\ngeneralisation of the classical models of Euler-Bernoulli and Timoshenko\nbending beams based on the mentioned work is proposed. The former is still\ncomposed of only one unidimensional scalar field, while the later introduces a\nthird unidimensional scalar field, correcting the second order terms. The\ngeneralised Euler-Bernoulli beam is then shown to exhibit curvature (i.e.\ndisclinations) linked to a third order derivative of the displacement, but no\ntorsion (dislocations). Parallelly, the generalised Timoshenko beam is shown to\nexhibit both curvature and torsion, where the former is linked to the\nnon-holonomy introduced in the generalisation. Lastly, using variational\ncalculus, asymptotic values for the value taken by the curvature in static\nequilibrium are obtained when the second order contribution becomes negligible;\nalong with an equation for the torsion in the generalised Timoshenko beam.","main_category":"math-ph","categories":"math-ph,math.DG,math.MP","published":"2025-04-24T07:57:13Z"}
{"aid":"http://arxiv.org/abs/2504.17352v1","title":"The Riemannian Means Field Classifier for EEG-Based BCI Data","summary":"A substantial amount of research has demonstrated the robustness and accuracy\nof the Riemannian minimum distance to mean (MDM) classifier for all kinds of\nEEG-based brain--computer interfaces (BCIs). This classifier is simple, fully\ndeterministic, robust to noise, computationally efficient, and prone to\ntransfer learning. Its training is very simple, requiring just the computation\nof a geometric mean of a symmetric positive-definite (SPD) matrix per class. We\npropose an improvement of the MDM involving a number of power means of SPD\nmatrices instead of the sole geometric mean. By the analysis of 20 public\ndatabases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCI\nparadigm, comprising 587 individuals in total, we show that the proposed\nclassifier clearly outperforms the MDM, approaching the state-of-the art in\nterms of performance while retaining the simplicity and the deterministic\nbehavior. In order to promote reproducible research, our code will be released\nas open source.","main_category":"cs.HC","categories":"cs.HC,eess.SP","published":"2025-04-24T08:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.17363v1","title":"Sample-Path Large Deviations for Functionals of Poisson Cluster\n  Processes","summary":"We establish sample-path large deviation principles for the centered\ncumulative functional of marked Poisson cluster processes in the Skorokhod\nspace equipped with the M1 topology, under joint regular variation assumptions\non the marks and the offspring distributions governing the propagation\nmechanism. These findings can also be interpreted as hidden regular variation\nof the cluster processes' functionals, extending the results in Dombry et al.\n(2022) to cluster processes with heavy-tailed characteristics, including mixed\nBinomial Poisson cluster processes and Hawkes processes. Notably, by\nrestricting to the adequate subspace of measures on D([0, 1], R+), and applying\nthe correct normalization and scaling to the paths of the centered cumulative\nfunctional, the limit measure concentrates on paths with multiple large jumps.","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T08:26:45Z"}
{"aid":"http://arxiv.org/abs/2504.17376v1","title":"On-Device Qwen2.5: Efficient LLM Inference with Model Compression and\n  Hardware Acceleration","summary":"Transformer-based Large Language Models (LLMs) have significantly advanced AI\ncapabilities but pose considerable challenges for deployment on edge devices\ndue to high computational demands, memory bandwidth constraints, and energy\nconsumption. This paper addresses these challenges by presenting an efficient\nframework for deploying the Qwen2.5-0.5B model on the Xilinx Kria KV260 edge\nplatform, a heterogeneous system integrating an ARM Cortex-A53 CPU with\nreconfigurable FPGA logic. Leveraging Activation-aware Weight Quantization\n(AWQ) with FPGA-accelerated execution pipelines, the proposed approach enhances\nboth model compression rate and system throughput. Additionally, we propose a\nhybrid execution strategy that intelligently offloads compute-intensive\noperations to the FPGA while utilizing the CPU for lighter tasks, effectively\nbalancing the computational workload and maximizing overall performance. Our\nframework achieves a model compression rate of 55.08% compared to the original\nmodel and produces output at a rate of 5.1 tokens per second, outperforming the\nbaseline performance of 2.8 tokens per second.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-24T08:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.17379v1","title":"A Spatially-Aware Multiple Instance Learning Framework for Digital\n  Pathology","summary":"Multiple instance learning (MIL) is a promising approach for weakly\nsupervised classification in pathology using whole slide images (WSIs).\nHowever, conventional MIL methods such as Attention-Based Deep Multiple\nInstance Learning (ABMIL) typically disregard spatial interactions among\npatches that are crucial to pathological diagnosis. Recent advancements, such\nas Transformer based MIL (TransMIL), have incorporated spatial context and\ninter-patch relationships. However, it remains unclear whether explicitly\nmodeling patch relationships yields similar performance gains in ABMIL, which\nrelies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs\nTransformer-based layers, introducing a fundamental architectural shift at the\ncost of substantially increased computational complexity. In this work, we\nenhance the ABMIL framework by integrating interaction-aware representations to\naddress this question. Our proposed model, Global ABMIL (GABMIL), explicitly\ncaptures inter-instance dependencies while preserving computational efficiency.\nExperimental results on two publicly available datasets for tumor subtyping in\nbreast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage\npoint improvement in AUPRC and a 5 percentage point increase in the Kappa score\nover ABMIL, with minimal or no additional computational overhead. These\nfindings underscore the importance of incorporating patch interactions within\nMIL frameworks.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-24T08:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.17386v1","title":"Free Cosmic Density Bispectrum on Small Scales","summary":"We study the asymptotic behaviour of the free, cold-dark matter density\nfluctuation bispectrum in the limit of small scales. From an initially Gaussian\nrandom field, we draw phase-space positions of test particles which then\npropagate along Zel'dovich trajectories. A suitable expansion of the initial\nmomentum auto-correlations of these particles leads to an asymptotic series\nwhose lower-order power-law exponents we calculate. The dominant contribution\nhas an exponent of $-11/2$. For triangle configurations with zero surface area,\nthis exponent is even enhanced to $-9/2$. These power laws can only be revealed\nby a non-perturbative calculation with respect to the initial power spectrum.\nThey are valid for a general class of initial power spectra with a cut-off\nfunction, required to enforce convergence of its moments. We then confirm our\nanalytic results numerically. Finally, we use this asymptotic behaviour to\ninvestigate the shape dependence of the bispectrum in the small-scale limit,\nand to show how different shapes grow over cosmic time. These confirm the usual\nmodel of gravitational collapse within the Zel'dovich picture.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-24T09:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.17405v1","title":"Classical Estimation of the Free Energy and Quantum Gibbs Sampling from\n  the Markov Entropy Decomposition","summary":"We revisit the Markov Entropy Decomposition, a classical convex relaxation\nalgorithm introduced by Poulin and Hastings to approximate the free energy in\nquantum spin lattices. We identify a sufficient condition for its convergence,\nnamely the decay of the effective interaction. We prove that this condition is\nsatisfied for systems in 1D at any temperature as well as in the\nhigh-temperature regime under a certain commutativity condition on the\nHamiltonian. This yields polynomial and quasi-polynomial time approximation\nalgorithms in these settings, respectively. Furthermore, the decay of the\neffective interaction implies the decay of the conditional mutual information\nfor the Gibbs state of the system. We then use this fact to devise a rounding\nscheme that maps the solution of the convex relaxation to a global state and\nshow that the scheme can be efficiently implemented on a quantum computer, thus\nproving efficiency of quantum Gibbs sampling under our assumption of decay of\nthe effective interaction.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-24T09:53:53Z"}
{"aid":"http://arxiv.org/abs/2504.17418v1","title":"Longitudinal Control for Autonomous Racing with Combustion Engine\n  Vehicles","summary":"Usually, a controller for path- or trajectory tracking is employed in\nautonomous driving. Typically, these controllers generate high-level commands\nlike longitudinal acceleration or force. However, vehicles with combustion\nengines expect different actuation inputs. This paper proposes a longitudinal\ncontrol concept that translates high-level trajectory-tracking commands to the\nrequired low-level vehicle commands such as throttle, brake pressure and a\ndesired gear. We chose a modular structure to easily integrate different\ntrajectory-tracking control algorithms and vehicles. The proposed control\nconcept enables a close tracking of the high-level control command. An\nanti-lock braking system, traction control, and brake warmup control also\nensure a safe operation during real-world tests. We provide experimental\nvalidation of our concept using real world data with longitudinal accelerations\nreaching up to $25 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^2}$. The experiments were\nconducted using the EAV24 racecar during the first event of the Abu Dhabi\nAutonomous Racing League on the Yas Marina Formula 1 Circuit.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-24T10:21:28Z"}
{"aid":"http://arxiv.org/abs/2504.17431v1","title":"The resonance parameters of the vector charmonium-like state $G(3900)$","summary":"Motivated by the updated analysis of the $G(3900)$ by the BESIII\ncollaboration, we perform a global analysis of the cross sections of the\n$e^+e^-\\to D\\bar{D}$, $e^+e^-\\to D\\bar{D}^*+c.c.$, $e^+e^-\\to D^*\\bar{D}^*$\nprocesses, especially focusing on the properties of the $G(3900)$. As the\nenergy region of interest is limited by the next opening threshold, i.e. the\n$D_1\\bar{D}$ threshold, we focus on the energy region\n$[3.7,4.25]~\\mathrm{GeV}$, where three charmonia $\\psi(1D)$, $\\psi(3S)$ and\n$\\psi(2D)$ explicitly contribute to the cross sections. By constructing the\n$P$-wave contact interaction between the $(D,D^*)$ doublet and its antiparticle\nin the heavy quark limit, we extract the physical scattering amplitude by\nsolving the Lippmann-Schwinger equation. No matter whether three or two\ncharmonium states are included in our framework, we always find a dynamically\ngenerated state corresponding to the $G(3900)$, which suggests it to be a\n$P$-wave dynamically generated state. We also predict several dynamically\ngenerated states in the corresponding $1^{-+}$ channel. These states can be\nfurther searched for in the electron-positron annihilation process involving\nthe emission of a single photon.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-24T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.17448v1","title":"CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated\n  Active Learning","summary":"Active learning (AL) reduces human annotation costs for machine learning\nsystems by strategically selecting the most informative unlabeled data for\nannotation, but performing it individually may still be insufficient due to\nrestricted data diversity and annotation budget. Federated Active Learning\n(FAL) addresses this by facilitating collaborative data selection and model\ntraining, while preserving the confidentiality of raw data samples. Yet,\nexisting FAL methods fail to account for the heterogeneity of data distribution\nacross clients and the associated fluctuations in global and local model\nparameters, adversely affecting model accuracy. To overcome these challenges,\nwe propose CHASe (Client Heterogeneity-Aware Data Selection), specifically\ndesigned for FAL. CHASe focuses on identifying those unlabeled samples with\nhigh epistemic variations (EVs), which notably oscillate around the decision\nboundaries during training. To achieve both effectiveness and efficiency,\n\\model{} encompasses techniques for 1) tracking EVs by analyzing inference\ninconsistencies across training epochs, 2) calibrating decision boundaries of\ninaccurate models with a new alignment loss, and 3) enhancing data selection\nefficiency via a data freeze and awaken mechanism with subset sampling.\nExperiments show that CHASe surpasses various established baselines in terms of\neffectiveness and efficiency, validated across diverse datasets, model\ncomplexities, and heterogeneous federation settings.","main_category":"cs.LG","categories":"cs.LG,cs.DB,cs.DC","published":"2025-04-24T11:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.17458v1","title":"Boundedness and Separation in the Graph Covering Number Framework","summary":"For a graph class $\\mathcal G$ and a graph $H$, the four $\\mathcal\nG$-covering numbers of $H$, namely global ${\\rm cn}_{g}^{\\mathcal{G}}(H)$,\nunion ${\\rm cn}_{u}^{\\mathcal{G}}(H)$, local ${\\rm cn}_{l}^{\\mathcal{G}}(H)$,\nand folded ${\\rm cn}_{f}^{\\mathcal{G}}(H)$, each measure in a slightly\ndifferent way how well $H$ can be covered with graphs from $\\mathcal G$. For\nevery $\\mathcal G$ and $H$ it holds \\[\n  {\\rm cn}_{g}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{u}^{\\mathcal{G}}(H) \\geq {\\rm\ncn}_{l}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{f}^{\\mathcal{G}}(H) \\] and in general\neach inequality can be arbitrarily far apart. We investigate structural\nproperties of graph classes $\\mathcal G$ and $\\mathcal H$ such that for all\ngraphs $H \\in \\mathcal{H}$, a larger $\\mathcal G$-covering number of $H$ can be\nbounded in terms of a smaller $\\mathcal G$-covering number of $H$. For example,\nwe prove that if $\\mathcal G$ is hereditary and the chromatic number of graphs\nin $\\mathcal H$ is bounded, then there exists a function $f$ (called a binding\nfunction) such that for all $H \\in \\mathcal{H}$ it holds ${\\rm\ncn}_{u}^{\\mathcal{G}}(H) \\leq f({\\rm cn}_{g}^{\\mathcal{G}}(H))$.\n  For $\\mathcal G$ we consider graph classes that are component-closed,\nhereditary, monotone, sparse, or of bounded chromatic number. For $\\mathcal H$\nwe consider graph classes that are sparse, $M$-minor-free, of bounded chromatic\nnumber, or of bounded treewidth. For each combination and every pair of\n$\\mathcal G$-covering numbers, we either give a binding function $f$ or provide\nan example of such $\\mathcal{G},\\mathcal{H}$ for which no binding function\nexists.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-24T11:43:53Z"}
{"aid":"http://arxiv.org/abs/2504.17480v1","title":"Unified Attacks to Large Language Model Watermarks: Spoofing and\n  Scrubbing in Unauthorized Knowledge Distillation","summary":"Watermarking has emerged as a critical technique for combating misinformation\nand protecting intellectual property in large language models (LLMs). A recent\ndiscovery, termed watermark radioactivity, reveals that watermarks embedded in\nteacher models can be inherited by student models through knowledge\ndistillation. On the positive side, this inheritance allows for the detection\nof unauthorized knowledge distillation by identifying watermark traces in\nstudent models. However, the robustness of watermarks against scrubbing attacks\nand their unforgeability in the face of spoofing attacks under unauthorized\nknowledge distillation remain largely unexplored. Existing watermark attack\nmethods either assume access to model internals or fail to simultaneously\nsupport both scrubbing and spoofing attacks. In this work, we propose\nContrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified\nframework that enables bidirectional attacks under unauthorized knowledge\ndistillation. Our approach employs contrastive decoding to extract corrupted or\namplified watermark texts via comparing outputs from the student model and\nweakly watermarked references, followed by bidirectional distillation to train\nnew student models capable of watermark removal and watermark forgery,\nrespectively. Extensive experiments show that CDG-KD effectively performs\nattacks while preserving the general performance of the distilled model. Our\nfindings underscore critical need for developing watermarking schemes that are\nrobust and unforgeable.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T12:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.17487v1","title":"Investigation of student and faculty problem solving: An example from\n  quantum mechanics","summary":"We describe a study focusing on students' and faculty members' reasoning\nabout problems of differing cognitive complexity related to the double-slit\nexperiment (DSE) with single particles. In the first phase of the study,\nstudents in advanced quantum mechanics courses were asked these questions in\nwritten form. Additionally, individual interviews were conducted with ten\nstudents in which they were asked follow-up questions to make their thought\nprocesses explicit on the challenging problems. Students did well on the\nstraightforward problem, showing they had some knowledge of the DSE after\ntraditional instruction, but they struggled on the more complex ones. Even if\nexplicitly asked to do so in interviews, students were often uncomfortable\nperforming calculations or making approximations and simplifications, instead\npreferring to stick with their gut feeling. In the second phase of the study,\nthe problems were broken down into more pointed questions to investigate\nwhether students had knowledge of relevant concepts, whether they would do\ncalculations as part of their solution approach if explicitly asked, and\nwhether they explicitly noted using their gut feeling. While the faculty\nmembers' responses suggest that they could seamlessly move between conceptual\nand quantitative reasoning, most students were unable to combine concepts\nrepresented by different equations to solve the problems quantitatively. We\nconclude with instructional implications.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-24T12:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.17488v1","title":"Microscopic derivation of the stationary Chern-Simons-Schrödinger\n  equation for almost-bosonic anyons","summary":"In this work we consider the $N$-body Hamiltonian describing the microscopic\nstructure of a quantum gas of almost-bosonic anyons. This description includes\nboth extended magnetic flux and spin-orbit/soft-disk interaction between the\nparticles which are confined in a scalar trapping potential. We study a\nphysically well-motivated ansatz for a sequence of trial states, consisting of\nJastrow repulsive short-range correlations and a condensate, with sufficient\nvariational freedom to approximate the ground state (and possibly also\nlow-energy excited states) of the gas. In the limit $N \\to \\infty$, while\ntaking the relative size of the anyons to zero and the total magnetic flux\n$2\\pi\\beta$ to remain finite, we rigorously derive the stationary\nChern-Simons-Schr\\\"odinger/average-field-Pauli effective energy density\nfunctional for the condensate wave function. This includes a scalar\nself-interaction parameter $\\gamma$ which depends both on $\\beta$, the\ndiluteness of the gas, and the spin-orbit coupling strength $g$, but becomes\nindependent of these microscopic details for a particular value of the coupling\n$g=2$ in which supersymmetry is exhibited (on all scales, both microscopic and\nmesoscopic) with $\\gamma=2\\pi|\\beta|$. Our findings confirm and clarify the\npredictions we have found in the physics literature.","main_category":"math-ph","categories":"math-ph,cond-mat.quant-gas,cond-mat.str-el,math.AP,math.MP,quant-ph","published":"2025-04-24T12:29:20Z"}
{"aid":"http://arxiv.org/abs/2504.17517v1","title":"Current phase relation in a planar graphene Josephson junction with\n  spin-orbit coupling","summary":"We study a graphene Josephson junction where the inner graphene layer is\nsubjected to spin-orbit coupling by proximity effect. This could be achieved,\nfor example, by growing the graphene layer on top of a transition metal\ndichalcogenide, such as WS$_2$. Here, we focus on the ballistic, wide, and\nshort junction limits and study the effects of the spin-orbit interaction on\nthe supercurrent. In particular, we analyze the current phase relation using an\nanalytical approach based on the continuum model. We find combinations of types\nof spin-orbit coupling that significantly suppress the supercurrent by opening\na gap in the graphene band structure. At the same time, other combinations\nenhance it, acting as an effective spin-valley resolved chemical potential.\nMoreover, we find that a strong Rashba spin-orbit coupling leads to a junction\nwith a highly voltage tunable harmonic content.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.supr-con,quant-ph","published":"2025-04-24T12:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.17519v1","title":"Replication and Exploration of Generative Retrieval over Dynamic Corpora","summary":"Generative retrieval (GR) has emerged as a promising paradigm in information\nretrieval (IR). However, most existing GR models are developed and evaluated\nusing a static document collection, and their performance in dynamic corpora\nwhere document collections evolve continuously is rarely studied. In this\npaper, we first reproduce and systematically evaluate various representative GR\napproaches over dynamic corpora. Through extensive experiments, we reveal that\nexisting GR models with \\textit{text-based} docids show superior generalization\nto unseen documents. We observe that the more fine-grained the docid design in\nthe GR model, the better its performance over dynamic corpora, surpassing BM25\nand even being comparable to dense retrieval methods. While GR models with\n\\textit{numeric-based} docids show high efficiency, their performance drops\nsignificantly over dynamic corpora. Furthermore, our experiments find that the\nunderperformance of numeric-based docids is partly due to their excessive\ntendency toward the initial document set, which likely results from overfitting\non the training set. We then conduct an in-depth analysis of the\nbest-performing GR methods. We identify three critical advantages of text-based\ndocids in dynamic corpora: (i) Semantic alignment with language models'\npretrained knowledge, (ii) Fine-grained docid design, and (iii) High lexical\ndiversity. Building on these insights, we finally propose a novel multi-docid\ndesign that leverages both the efficiency of numeric-based docids and the\neffectiveness of text-based docids, achieving improved performance in dynamic\ncorpus without requiring additional retraining. Our work offers empirical\nevidence for advancing GR methods over dynamic corpora and paves the way for\ndeveloping more generalized yet efficient GR models in real-world search\nengines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T13:01:23Z"}
{"aid":"http://arxiv.org/abs/2504.17533v1","title":"Relic gravitational waves from cosmological horizon radiation during de\n  Sitter period: as zero-order approximation of inflation","summary":"It is well known that the event horizon of the de Sitter universe can produce\nparticles, and one can get sizable Hawking radiation by considering\ninflationary phases as de Sitter spacetimes with large Hubble rates. In this\ncompact paper, we consider the graviton emission part of these radiations and\nassume that these graviton signals can exist in the current universe in the\nform of gravitational waves. We predict an energy density parameter of\n$\\log_{10}(\\Omega_{\\rm GW} h^2) \\sim \\mathscr{O}(-25) - \\mathscr{O}(-30)$ and\nits associated peak frequency $\\log_{10}(f_{\\rm peak}^0) \\sim\n\\mathscr{O}(6)-\\mathscr{O}(5)$, depending on the reheating temperature. These\nsignals occupy a frequency band below the ultrahigh-frequency regime and\npossess a detectable energy density, offering a promising target for future\ngravitational wave observatories. We believe that the detection of such signals\nwould provide a compelling test of Hawking's radiation theory in a cosmological\ncontext.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-24T13:19:40Z"}
{"aid":"http://arxiv.org/abs/2504.17542v1","title":"Large Language Model-Driven Concolic Execution for Highly Structured\n  Test Input Generation","summary":"How can we perform concolic execution to generate highly structured test\ninputs for systematically testing parsing programs? Existing concolic execution\nengines are significantly restricted by (1) input structure-agnostic path\nconstraint selection, leading to the waste of testing effort or missing\ncoverage; (2) limited constraint-solving capability, yielding many\nsyntactically invalid test inputs; (3) reliance on manual acquisition of highly\nstructured seed inputs, resulting in non-continuous testing.\n  This paper proposes Cottontail, a new Large Language Model (LLM)-driven\nconcolic execution engine, to mitigate the above limitations. A more complete\nprogram path representation, named Expressive Structural Coverage Tree (ESCT),\nis first constructed to select structure-aware path constraints. Later, an\nLLM-driven constraint solver based on a Solve-Complete paradigm is designed to\nsolve the path constraints smartly to get test inputs that are not only\nsatisfiable to the constraints but also valid to the input syntax. Finally, a\nhistory-guided seed acquisition is employed to obtain new highly structured\ntest inputs either before testing starts or after testing is saturated.\n  We implemented Cottontail on top of SymCC and evaluated eight extensively\ntested open-source libraries across four different formats (XML, SQL,\nJavaScript, and JSON). The experimental result is promising: it shows that\nCottontail outperforms state-of-the-art approaches (SymCC and Marco) by 14.15%\nand 14.31% in terms of line coverage. Besides, Cottontail found 6 previously\nunknown vulnerabilities (six new CVEs have been assigned). We have reported\nthese issues to developers, and 4 out of them have been fixed so far.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T13:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.17570v1","title":"Atemporality from Conservation Laws of Physics in Lorentzian-Euclidean\n  Black Hole","summary":"Recent results have shown that singularities can be avoided from the general\nrelativistic standpoint in Lorentzian-Euclidean black holes by means of the\ntransition from a Lorentzian to an Euclidean region where time loses its\nphysical meaning and becomes imaginary. This dynamical mechanism, dubbed\n``atemporality'', prevents the emergence of black hole singularities and the\nviolation of conservation laws. In this paper, the notion of atemporality\ntogether with a detailed discussion of its implications is presented from a\nphilosophical perspective. The main result consists in showing that\natemporality is naturally related to conservation laws.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-24T13:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.17594v1","title":"Tamper-evident Image using JPEG Fixed Points","summary":"An intriguing phenomenon about JPEG compression has been observed since two\ndecades ago- after repeating JPEG compression and decompression, it leads to a\nstable image that does not change anymore, which is a fixed point. In this\nwork, we prove the existence of fixed points in the essential JPEG procedures.\nWe analyze JPEG compression and decompression processes, revealing the\nexistence of fixed points that can be reached within a few iterations. These\nfixed points are diverse and preserve the image's visual quality, ensuring\nminimal distortion. This result is used to develop a method to create a\ntamper-evident image from the original authentic image, which can expose\ntampering operations by showing deviations from the fixed point image.","main_category":"cs.CV","categories":"cs.CV,I.4.7","published":"2025-04-24T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.17599v1","title":"Dynamical gauge invariance of statistical mechanics","summary":"We investigate gauge invariance against phase space shifting in\nnonequilibrium systems, as represented by time-dependent many-body Hamiltonians\nthat drive an initial ensemble out of thermal equilibrium. The theory gives\nrise to gauge correlation functions that characterize spatial and temporal\ninhomogeneity with microscopic resolution on the one-body level. Analyzing the\ndynamical gauge invariance allows one to identify a specific localized shift\ngauge current as a fundamental nonequilibrium observable that characterizes\nparticle-based dynamics. When averaged over the nonequilibrium ensemble, the\nshift current vanishes identically, which constitutes an exact nonequilibrium\nconservation law that generalizes the Yvon-Born-Green equilibrium balance of\nthe vanishing sum of ideal, interparticle, and external forces. Any given\nobservable is associated with a corresponding dynamical hyperforce density and\nhypercurrent correlation function. An exact nonequilibrium sum rule\ninterrelates these one-body functions, in generalization of the recent\nhyperforce balance for equilibrium systems. We demonstrate the physical\nconsequences of the dynamical gauge invariance using both harmonically confined\nideal gas setups, for which we present analytical solutions, and molecular\ndynamics simulations of interacting systems, for which we demonstrate the shift\ncurrent and hypercurrent correlation functions to be accessible both via\nfinite-difference methods and via trajectory-based automatic differentiation.\nWe show that the theory constitutes a starting point for developing\nnonequilibrium reduced-variance sampling algorithms and for investigating\nthermally-activated barrier crossing.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-24T14:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.17601v1","title":"Interpretable non-linear dimensionality reduction using gaussian\n  weighted linear transformation","summary":"Dimensionality reduction techniques are fundamental for analyzing and\nvisualizing high-dimensional data. With established methods like t-SNE and PCA\npresenting a trade-off between representational power and interpretability.\nThis paper introduces a novel approach that bridges this gap by combining the\ninterpretability of linear methods with the expressiveness of non-linear\ntransformations. The proposed algorithm constructs a non-linear mapping between\nhigh-dimensional and low-dimensional spaces through a combination of linear\ntransformations, each weighted by Gaussian functions. This architecture enables\ncomplex non-linear transformations while preserving the interpretability\nadvantages of linear methods, as each transformation can be analyzed\nindependently. The resulting model provides both powerful dimensionality\nreduction and transparent insights into the transformed space. Techniques for\ninterpreting the learned transformations are presented, including methods for\nidentifying suppressed dimensions and how space is expanded and contracted.\nThese tools enable practitioners to understand how the algorithm preserves and\nmodifies geometric relationships during dimensionality reduction. To ensure the\npractical utility of this algorithm, the creation of user-friendly software\npackages is emphasized, facilitating its adoption in both academia and\nindustry.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.17605v1","title":"A Constraint Opinion Model","summary":"This paper introduces a generalised opinion model that extends the standard\nDeGroot model by representing agents' opinions and influences as soft\nconstraints rather than single real values. This allows for modelling scenarios\nbeyond the scope of the DeGroot model, such as agents sharing partial\ninformation and preferences, engaging in discussions on multiple topics\nsimultaneously, and representing opinions with different degrees of\nuncertainty. By considering soft constraints as influences, the proposed model\ncaptures also situations where agents impose conditions on how others' opinions\nare integrated during belief revision. Finally, the flexibility offered by soft\nconstraints allows us to introduce a novel polarisation measure that takes\nadvantage of this generalised framework.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-24T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.17607v1","title":"Time-resolved dynamics of GaN waveguide polaritons","summary":"We implement a new experimental approach to directly measure the lifetime of\nguided polaritons arising from the strong-coupling of GaN excitons and the\nguided photonic modes of a slab waveguide. Using a Fourier imaging setup,\ncombined with spatial filtering of the emission, the emission associated to\npolaritonic modes with well-defined propagation constants can be selectively\nanalyzed in the temporal domain. By directing it to the entrance slit of a\nstreak camera, time-resolved photoluminescence (TRPL) measurements along the\npolariton dispersion branch were performed at 40 K, enabling to assess the time\ndecay of polariton modes. By combining this information with the\nphotonic/excitonic fraction corresponding to each polariton mode, extracted\nfrom a coupled-oscillators model that indicate a Rabi splitting of $\\Omega$ =\n80 meV, we could extract the photon lifetime in the waveguide $\\tau_\\gamma\\,\n=\\, 3\\pm 1$ ps. This corresponds to a record $Q$-factor in the UV of 16 000.\nThe excitonic reservoir lifetime, which contributes to polariton formation, was\ndetermined through TRPL measurements on excitonic luminescence. Finally,\nmeasurements conducted at lower temperature highlight secondary feeding\nmechanisms for the guided polaritonic mode, either via photon recycling from\nthe AlGaN cladding layer or through resonant injection of photons from\ntransitions below the band gap.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T14:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.17611v1","title":"Some Results on Generalized Familywise Error Rate Controlling Procedures\n  under Dependence","summary":"The topic of multiple hypotheses testing now has a potpourri of novel\ntheories and ubiquitous applications in diverse scientific fields. However, the\nuniversal utility of this field often hinders the possibility of having a\ngeneralized theory that accommodates every scenario. This tradeoff is better\nreflected through the lens of dependence, a central piece behind the\ntheoretical and applied developments of multiple testing. Although omnipresent\nin many scientific avenues, the nature and extent of dependence vary\nsubstantially with the context and complexity of the particular scenario.\nPositive dependence is the norm in testing many treatments versus a single\ncontrol or in spatial statistics. On the contrary, negative dependence arises\nnaturally in tests based on split samples and in cyclical, ordered comparisons.\nIn GWAS, the SNP markers are generally considered to be weakly dependent.\nGeneralized familywise error rate (k-FWER) control has been one of the\nprominent frequentist approaches in simultaneous inference. However, the\nperformances of k-FWER controlling procedures are yet unexplored under\ndifferent dependencies. This paper revisits the classical testing problem of\nnormal means in different correlated frameworks. We establish upper bounds on\nthe generalized familywise error rates under each dependence, consequently\ngiving rise to improved testing procedures. Towards this, we present improved\nprobability inequalities, which are of independent theoretical interest","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-04-24T14:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.17617v1","title":"Decentralized Time Series Classification with ROCKET Features","summary":"Time series classification (TSC) is a critical task with applications in\nvarious domains, including healthcare, finance, and industrial monitoring. Due\nto privacy concerns and data regulations, Federated Learning has emerged as a\npromising approach for learning from distributed time series data without\ncentralizing raw information. However, most FL solutions rely on a\nclient-server architecture, which introduces robustness and confidentiality\nrisks related to the distinguished role of the server, which is a single point\nof failure and can observe knowledge extracted from clients. To address these\nchallenges, we propose DROCKS, a fully decentralized FL framework for TSC that\nleverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS,\nthe global model is trained by sequentially traversing a structured path across\nfederation nodes, where each node refines the model and selects the most\neffective local kernels before passing them to the successor. Extensive\nexperiments on the UCR archive demonstrate that DROCKS outperforms\nstate-of-the-art client-server FL approaches while being more resilient to node\nfailures and malicious attacks. Our code is available at\nhttps://anonymous.4open.science/r/DROCKS-7FF3/README.md.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T14:41:50Z"}
{"aid":"http://arxiv.org/abs/2504.17624v1","title":"Deciphering the unique dynamic activation pathway in a G protein-coupled\n  receptor enables unveiling biased signaling and identifying cryptic\n  allosteric sites in conformational intermediates","summary":"Neurotensin receptor 1 (NTSR1), a member of the Class A G protein-coupled\nreceptor superfamily, plays an important role in modulating dopaminergic\nneuronal activity and eliciting opioid-independent analgesia. Recent studies\nsuggest that promoting \\{beta}-arrestin-biased signaling in NTSR1 may diminish\ndrugs of abuse, such as psychostimulants, thereby offering a potential avenue\nfor treating human addiction-related disorders. In this study, we utilized a\nnovel computational and experimental approach that combined nudged elastic\nband-based molecular dynamics simulations, Markov state models, temporal\ncommunication network analysis, site-directed mutagenesis, and conformational\nbiosensors, to explore the intricate mechanisms underlying NTSR1 activation and\nbiased signaling. Our study reveals a dynamic stepwise transition mechanism and\nactivated transmission network associated with NTSR1 activation. It also yields\nvaluable insights into the complex interplay between the unique polar network,\nnon-conserved ion locks, and aromatic clusters in NTSR1 signaling. Moreover, we\nidentified a cryptic allosteric site located in the intracellular region of the\nreceptor that exists in an intermediate state within the activation pathway.\nCollectively, these findings contribute to a more profound understanding of\nNTSR1 activation and biased signaling at the atomic level, thereby providing a\npotential strategy for the development of NTSR1 allosteric modulators in the\nrealm of G protein-coupled receptor biology, biophysics, and medicine.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-24T14:46:20Z"}
{"aid":"http://arxiv.org/abs/2504.17628v1","title":"Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with\n  Self-attention Diffusion Models and the Potential for Text-Guided\n  Customization","summary":"Diabetic foot ulcers (DFUs) pose a significant challenge in healthcare,\nrequiring precise and efficient wound assessment to enhance patient outcomes.\nThis study introduces the Attention Diffusion Zero-shot Unsupervised System\n(ADZUS), a novel text-guided diffusion model that performs wound segmentation\nwithout relying on labeled training data. Unlike conventional deep learning\nmodels, which require extensive annotation, ADZUS leverages zero-shot learning\nto dynamically adapt segmentation based on descriptive prompts, offering\nenhanced flexibility and adaptability in clinical applications. Experimental\nevaluations demonstrate that ADZUS surpasses traditional and state-of-the-art\nsegmentation models, achieving an IoU of 86.68\\% and the highest precision of\n94.69\\% on the chronic wound dataset, outperforming supervised approaches such\nas FUSegNet. Further validation on a custom-curated DFU dataset reinforces its\nrobustness, with ADZUS achieving a median DSC of 75\\%, significantly surpassing\nFUSegNet's 45\\%. The model's text-guided segmentation capability enables\nreal-time customization of segmentation outputs, allowing targeted analysis of\nwound characteristics based on clinical descriptions. Despite its competitive\nperformance, the computational cost of diffusion-based inference and the need\nfor potential fine-tuning remain areas for future improvement. ADZUS represents\na transformative step in wound segmentation, providing a scalable, efficient,\nand adaptable AI-driven solution for medical imaging.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-24T14:50:10Z"}
{"aid":"http://arxiv.org/abs/2504.17639v1","title":"Hot Diggity Dog: A complete analysis of the extreme molecular gas and\n  dust properties at kpc scales in the hyper-luminous hot, dust-obscured galaxy\n  W2246-0526","summary":"Hot dust-obscured galaxies (Hot DOGs), the most infrared (IR) luminous\nobjects selected by the WISE all-sky mid-IR survey, have yielded a sample of\nintrinsically luminous quasars (QSOs) with obscured nuclear activity and hot\ndust temperatures. The molecular gas excitation properties have yet to be\nexamined in detail under such extreme conditions. Here we study the most far-IR\nluminous WISE Hot DOG W2246-0526, focusing on the central host galaxy. Multi-J\nCO transition measurements at J=2-1, 5-4, 7-6, 12-11, and 17-16 provide the\nmost well-sampled CO excitation ladder of any WISE Hot DOG to date, providing\nthe first self-consistent modeling constraints on the molecular gas and dust\nproperties. We implement a state-of-the-art TUrbulent Non-Equilibrium Radiative\ntransfer model (TUNER) that simultaneously models both the line and dust\ncontinuum measurements. Due to a combination of high molecular gas densities\nand high kinetic temperatures, this extreme CO spectral line energy\ndistribution peaks at J = 10 to 12, likely making this the most highly excited\ngalaxy ever reported. We derive the alpha_CO conversion factors and conclude\nthat (J=3-7) CO line luminosities trace the bulk of the molecular gas mass.\nW2246-0526 is a rapidly evolving system, with a high value of the molecular gas\nkinetic temperature versus dust temperature T_k / T_d ~ 3.9, reflecting\npreviously reported shocks and outflows injecting kinetic energy within the\ncentral kpc of this host. This first comprehensive simultaneous modeling of\nboth the molecular gas and dust in any object within the WISE-selected Hot DOG\nsample motivates obtaining well-sampled dust and line spectral energy\ndistributions to better understand the conditions within these short-lived\nepisodes in galaxy evolution that are associated with the most obscured\nsupermassive black hole activity.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T15:10:43Z"}
{"aid":"http://arxiv.org/abs/2504.17640v1","title":"A modular framework for generalized Hurwitz class numbers III","summary":"In $2003$, Pei and Wang introduced higher level analogs of the classical\nCohen--Eisenstein series. In recent joint work with Beckwith, we found a weight\n$\\frac{1}{2}$ sesquiharmonic preimage of their weight $\\frac{3}{2}$ Eisenstein\nseries under $\\xi_{\\frac{1}{2}}$ utilizing a construction from seminal work by\nDuke, Imamo\\={g}lu and T\\'{o}th. In further joint work with Beckwith, when\nrestricting to prime level, we realized our preimage as a regularized Siegel\ntheta lift and evaluated its (regularized) Fourier coefficients explicitly.\nThis relied crucially on work by Bruinier, Funke and Imamo\\={g}lu. In this\npaper, we extend both works to higher weights. That is, we provide a harmonic\npreimage of Pei and Wang's generalized Cohen--Eisenstein series under\n$\\xi_{\\frac{3}{2}-k}$, where $k > 1$. Furthermore, when restricting to prime\nlevel, we realize them as outputs of a regularized Shintani theta lift of a\nhigher level holomorphic Eisenstein series, which builds on recent work by\nAlfes and Schwagenscheidt. Lastly, we evaluate the regularized Millson theta\nlift of a higher level Maass--Eisenstein series, which is known to be connected\nto the Shintani theta lift by a differential equation by earlier work of Alfes\nand Schwagenscheidt.","main_category":"math.NT","categories":"math.NT","published":"2025-04-24T15:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.17647v1","title":"Unifying Complementarity Constraints and Control Barrier Functions for\n  Safe Whole-Body Robot Control","summary":"Safety-critical whole-body robot control demands reactive methods that ensure\ncollision avoidance in real-time. Complementarity constraints and control\nbarrier functions (CBF) have emerged as core tools for ensuring such safety\nconstraints, and each represents a well-developed field. Despite addressing\nsimilar problems, their connection remains largely unexplored. This paper\nbridges this gap by formally proving the equivalence between these two\nmethodologies for sampled-data, first-order systems, considering both single\nand multiple constraint scenarios. By demonstrating this equivalence, we\nprovide a unified perspective on these techniques. This unification has\ntheoretical and practical implications, facilitating the cross-application of\nrobustness guarantees and algorithmic improvements between complementarity and\nCBF frameworks. We discuss these synergistic benefits and motivate future work\nin the comparison of the methods in more general cases.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-24T15:17:26Z"}
{"aid":"http://arxiv.org/abs/2504.17659v1","title":"Programmable glassy dynamics using tunable disorder in tweezer arrays","summary":"We propose a unifying framework for non-equilibrium relaxation dynamics in\nensembles of positionally disordered interacting quantum spins based on the\nstatistical properties, such as mean and variance, of the underlying disorder\ndistribution. Our framework is validated through extensive exact numerical\ncalculations and we use it to disentangle and understand the importance of\ndimensionality and interaction range for the observation of glassy (i.e.,\nsub-exponential) decay dynamics. Leveraging the deterministic control of qubit\npositioning enabled by modern tweezer array architectures, we also introduce a\nmethod (``J-mapping'') that can be used to emulate the relaxation dynamics of a\ndisordered system with arbitrary dimensionality and interaction range in\nbespoke one-dimensional arrays. Our approach paves the way towards tunable\nrelaxation dynamics that can be explored in quantum simulators based on arrays\nof neutral atoms and molecules.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.dis-nn,quant-ph","published":"2025-04-24T15:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.17667v1","title":"Spectral Irradiance Variability in Lyman-Alpha Emission During Solar\n  Flares","summary":"The Lyman-alpha (Ly{\\alpha};1216 {\\AA}) line is the brightest emission line\nin the quiescent solar spectrum and radiates a significant fraction of the\navailable nonthermal energy during flares. Despite its importance, there is a\nlack of detailed studies of Ly{\\alpha} spectral variability during flares.\nRecently, spectrally resolved Ly{\\alpha} flare observations from the\nSORCE/SOLSTICE instrument have become available. This study examines Ly{\\alpha}\nspectral variability and its relationship with HXR emission from nonthermal\nelectrons, using observations of two M-class flares from SORCE/SOLSTICE and\nRHESSI. Imaging observations from STEREO/SECCHI EUVI and SDO/AIA provide\nfurther context. Enhancements across the Ly{\\alpha} line profile were found to\nclosely correlate with bursts of HXR emission, suggesting a primarily\nnonthermal origin. Red enhancement asymmetries at the peak of each flare were\nattributed to chromospheric evaporation, while blue wing enhancement and blue\nasymmetry were linked to a bright filament-eruption seen in SDO/AIA 1600 {\\AA}\nimages. These findings contribute to the understanding of spectral Ly{\\alpha}\nvariability during flares and highlight the need for future studies using a\nhigher quality and quantity of spectral Ly{\\alpha} flare observations. Such\nstudies will further characterise the physical mechanisms driving Ly{\\alpha}\nflare variability.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-24T15:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.17693v1","title":"BIM-Constrained Optimization for Accurate Localization and Deviation\n  Correction in Construction Monitoring","summary":"Augmented reality (AR) applications for construction monitoring rely on\nreal-time environmental tracking to visualize architectural elements. However,\nconstruction sites present significant challenges for traditional tracking\nmethods due to featureless surfaces, dynamic changes, and drift accumulation,\nleading to misalignment between digital models and the physical world. This\npaper proposes a BIM-aware drift correction method to address these challenges.\nInstead of relying solely on SLAM-based localization, we align ``as-built\"\ndetected planes from the real-world environment with ``as-planned\"\narchitectural planes in BIM. Our method performs robust plane matching and\ncomputes a transformation (TF) between SLAM (S) and BIM (B) origin frames using\noptimization techniques, minimizing drift over time. By incorporating BIM as\nprior structural knowledge, we can achieve improved long-term localization and\nenhanced AR visualization accuracy in noisy construction environments. The\nmethod is evaluated through real-world experiments, showing significant\nreductions in drift-induced errors and optimized alignment consistency. On\naverage, our system achieves a reduction of 52.24% in angular deviations and a\nreduction of 60.8% in the distance error of the matched walls compared to the\ninitial manual alignment by the user.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-24T16:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.17701v1","title":"Network Sampling: An Overview and Comparative Analysis","summary":"Network sampling is a crucial technique for analyzing large or partially\nobservable networks. However, the effectiveness of different sampling methods\ncan vary significantly depending on the context. In this study, we empirically\ncompare representative methods from three main categories: node-based,\nedge-based, and exploration-based sampling. We used two real-world datasets for\nour analysis: a scientific collaboration network and a temporal message-sending\nnetwork. Our results indicate that no single sampling method consistently\noutperforms the others in both datasets. Although advanced methods tend to\nprovide better accuracy on static networks, they often perform poorly on\ntemporal networks, where simpler techniques can be more effective. These\nfindings suggest that the best sampling strategy depends not only on the\nstructural characteristics of the network but also on the specific metrics that\nneed to be preserved or analyzed. Our work offers practical insights for\nresearchers in choosing sampling approaches that are tailored to different\ntypes of networks and analytical objectives.","main_category":"cs.SI","categories":"cs.SI,cond-mat.stat-mech,physics.data-an","published":"2025-04-24T16:10:06Z"}
{"aid":"http://arxiv.org/abs/2504.17703v1","title":"Federated Learning: A Survey on Privacy-Preserving Collaborative\n  Intelligence","summary":"Federated Learning (FL) has emerged as a transformative paradigm in the field\nof distributed machine learning, enabling multiple clients such as mobile\ndevices, edge nodes, or organizations to collaboratively train a shared global\nmodel without the need to centralize sensitive data. This decentralized\napproach addresses growing concerns around data privacy, security, and\nregulatory compliance, making it particularly attractive in domains such as\nhealthcare, finance, and smart IoT systems. This survey provides a concise yet\ncomprehensive overview of Federated Learning, beginning with its core\narchitecture and communication protocol. We discuss the standard FL lifecycle,\nincluding local training, model aggregation, and global updates. A particular\nemphasis is placed on key technical challenges such as handling non-IID\n(non-independent and identically distributed) data, mitigating system and\nhardware heterogeneity, reducing communication overhead, and ensuring privacy\nthrough mechanisms like differential privacy and secure aggregation.\nFurthermore, we examine emerging trends in FL research, including personalized\nFL, cross-device versus cross-silo settings, and integration with other\nparadigms such as reinforcement learning and quantum computing. We also\nhighlight real-world applications and summarize benchmark datasets and\nevaluation metrics commonly used in FL research. Finally, we outline open\nresearch problems and future directions to guide the development of scalable,\nefficient, and trustworthy FL systems.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T16:10:29Z"}
{"aid":"http://arxiv.org/abs/2504.17736v1","title":"Design and benchmarking of a two degree of freedom tendon driver unit\n  for cable-driven wearable technologies","summary":"Exosuits have recently been developed as alternatives to rigid exoskeletons\nand are increasingly adopted for both upper and lower limb therapy and\nassistance in clinical and home environments. Many cable-driven exosuits have\nbeen developed but little has been published on their electromechanical designs\nand performance. Therefore, this paper presents a comprehensive design and\nperformance analysis of a two degree of freedom tendon driver unit (TDU) for\ncable-driven wearable exosuits. Detailed methodologies are presented to\nbenchmark the functionality of the TDU. A static torque output test compares\nthe commanded and measured torques. A velocity control test evaluates the\nattenuation and phase shift across velocities. A noise test evaluates how loud\nthe TDU is for the wearer under different speeds. A thermal stress test\ncaptures the cooling performance of the TDU to ensure safe operation at higher\nloads. Finally, a battery endurance test evaluates the runtime of the TDU under\nvarious loading conditions to inform the usable time. To demonstrate these\ntests, a modular TDU system for cable-driven applications is introduced, which\nallows components such as motors, pulleys, and sensors to be adapted based on\nthe requirements of the intended application. By sharing detailed methodologies\nand performance results, this study aims to provide a TDU design that may be\nleveraged by others and resources for researchers and engineers to better\ndocument the capabilities of their TDU designs.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T16:49:21Z"}
{"aid":"http://arxiv.org/abs/2504.17745v1","title":"Asymptotic attraction with algebraic rates toward fronts of\n  dispersive-diffusive Burgers equations","summary":"Burgers equation is a classic model, which arises in numerous applications.\nAt its very core it is a simple conservation law, which serves as a toy model\nfor various dynamics phenomena. In particular, it supports explicit\nheteroclinic solutions, both fronts and backs. Their stability has been studied\nin details. There has been substantial interest in considering dispersive\nand/or diffusive modifications, which present novel dynamical paradigms in such\nsimple setting. More specificaly, the KdV-Burgers model has been showed to\nsupport unique fronts (not all of them monotone!) with fixed values at $\\pm\n\\infty$. Many articles, among which \\cite{Pego}, \\cite{NS1}, \\cite{NS2}, have\nstudied the question of stability of monotone (or close to monotone) fronts.\n  In a breakthrough paper, \\cite{BBHY}, the authors have extended these results\nin several different directions. They have considered a wider range of models.\nThe fronts do not need to be monotone, but are subject of a spectral condition\ninstead. Most importantly the method allows for large perturbations, as long as\nthe heteroclinic conditions at $\\pm \\infty$ are met. That is, there is\nasymptotic attraction to the said fronts or equivalently the limit set consist\nof one point.\n  The purpose of this paper is to extend the results of \\cite{BBHY} by\nproviding explicit algebraic rates of convergence as $t\\to \\infty$. We\nbootstrap these results from the results in \\cite{BBHY} using additional energy\nestimates for two important examples namely KdV-Burgers and the fractional\nBurgers problem. These rates are likely not optimal, but we conjecture that\nthey are algebraic nonetheless.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T17:05:50Z"}
{"aid":"http://arxiv.org/abs/2504.17760v1","title":"WI2easy: warm inflation dynamics made easy","summary":"We present WI2easy, a Mathematica package for high-precision analysis of warm\ninflation (WI) dynamics, enabling efficient computation of both background\nevolution and curvature perturbations. Designed with a user-friendly interface,\nthe tool supports a broad spectrum of inflaton potentials--including\nlarge-field, small-field, and hybrid models--and accommodates arbitrary\ndissipation coefficients dependent on temperature, field amplitude, or both,\nencompassing canonical forms prevalent in WI studies. Users can define custom\nmodels through intuitive commands, generating full dynamical trajectories and\nperturbation spectra in a streamlined workflow. This facilitates rapid\nconfrontation of theoretical predictions with observational constraints,\nempowering systematic exploration of WI parameter spaces. WI2easy bridges the\ngap between theoretical models and observational cosmology, offering a robust,\nadaptable framework for next-generation inflationary analyses.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-24T17:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.17764v1","title":"Orbifolds, higher dagger structures, and idempotents","summary":"The orbifold/condensation completion procedure of defect topological quantum\nfield theories can be seen as carrying out a lattice or state sum model\nconstruction internal to an ambient theory. In this paper, we propose a\nconceptual algebraic description of orbifolds/condensations for arbitrary\ntangential structures in terms of higher dagger structures and higher\nidempotents. In particular, we obtain (oriented) orbifold completion from\n(framed) condensation completion by using a general strictification procedure\nfor higher dagger structures which we describe explicitly in low dimensions; we\nalso discuss the spin and unoriented case. We provide several examples of\nhigher dagger categories, such as those associated to state sum models,\n(orbifolds of) Landau--Ginzburg models, and truncated affine Rozansky--Witten\nmodels. We also explain how their higher dagger structures are naturally\ninduced from rigid symmetric monoidal structures, recontextualizing and\nextending results from the literature.","main_category":"math.QA","categories":"math.QA,hep-th,math-ph,math.CT,math.MP","published":"2025-04-24T17:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.17783v1","title":"Nanoscale infrared and microwave imaging of stacking faults in\n  multilayer graphene","summary":"Graphite occurs in a range of metastable stacking orders characterized by\nboth the number and direction of shifts between adjacent layers by the length\nof a single carbon-carbon bond. At the extremes are Bernal (or ``ABAB...'')\nstacking, where the direction of the interlayer shift alternates with each\nlayer, and rhombohedral (or ``ABCABC...'') stacking order where the shifts are\nalways in the same direction. However, for an N-layer system, there are in\nprinciple $N-1$ unique metastable stacking orders of this type. Recently, it\nhas become clear that stacking order has a strong effect on the low energy\nelectronic band structure with single-layer shifts completely altering the\nelectronic properties. Most experimental work has focused on the extremal\nstacking orders in large part due to the difficulty of isolating and\nidentifying intermediate orders. Motivated by this challenge, here we describe\ntwo atomic force microscopy (AFM) based techniques to unambiguously distinguish\nstacking orders and defects in graphite flakes. Photo-thermal infrared atomic\nforce microscope (AFM-IR) is able to distinguish stacking orders across\nmultiple IR wavelengths and readily provides absolute contrast via IR spectral\nanalysis. Scanning microwave impedance microscopy (sMIM) can distinguish the\nrelative contrast between Bernal, intermediate and rhombohedral domains. We\nshow that both techniques are well suited to characterizing graphite van der\nWaals devices, providing high contrast determination of stacking order,\nsubsurface imaging of graphene flakes buried under a hexagonal boron nitride\n(hBN) dielectric layer, and identifying nanoscale domain walls. Our results\npave the way for the reliable fabrication of graphene multilayer devices of\ndefinite interlayer registry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-24T17:58:30Z"}
{"aid":"http://arxiv.org/abs/2504.17787v1","title":"The Fourth Monocular Depth Estimation Challenge","summary":"This paper presents the results of the fourth edition of the Monocular Depth\nEstimation Challenge (MDEC), which focuses on zero-shot generalization to the\nSYNS-Patches benchmark, a dataset featuring challenging environments in both\nnatural and indoor settings. In this edition, we revised the evaluation\nprotocol to use least-squares alignment with two degrees of freedom to support\ndisparity and affine-invariant predictions. We also revised the baselines and\nincluded popular off-the-shelf methods: Depth Anything v2 and Marigold. The\nchallenge received a total of 24 submissions that outperformed the baselines on\nthe test set; 10 of these included a report describing their approach, with\nmost leading methods relying on affine-invariant predictions. The challenge\nwinners improved the 3D F-Score over the previous edition's best result,\nraising it from 22.58% to 23.05%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:52Z"}
