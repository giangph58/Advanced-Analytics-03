{"aid":"http://arxiv.org/abs/2503.21656v1","title":"Logging the conformal life of Ramanujan's $Ï€$","summary":"In 1914, Ramanujan presented 17 infinite series for $1/\\pi$. We examine the\nphysics origin of these remarkable formulae by connecting them to 2D\nlogarithmic conformal field theories (LCFTs) which arise in various contexts\nsuch as the fractional quantum hall effect, percolation and polymers. In light\nof the LCFT connection, we investigate such infinite series in terms of the\nphysics data, i.e., the operator spectrum and OPE coefficients of the CFT and\nthe conformal block expansion. These considerations lead to novel\napproximations for $1/\\pi$. The rapid convergence of the Ramanujan series\nmotivates us to take advantage of the crossing symmetry of the LCFT correlators\nto find new and efficient representations. To achieve this, we use the\nparametric crossing symmetric dispersion relation which was recently developed\nfor string amplitudes. Quite strikingly, we find remarkable simplifications in\nthe new representations, where, in the Legendre relation, the entire\ncontribution to $1/\\pi$ comes from the logarithmic identity operator, hinting\nat a universal property of LCFTs. Additionally, the dispersive representation\ngives us a new handle on the double-lightcone limit.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-27T16:21:08Z"}
{"aid":"http://arxiv.org/abs/2503.21657v1","title":"Model Assembly Learning with Heterogeneous Layer Weight Merging","summary":"Model merging acquires general capabilities without extra data or training by\ncombining multiple models' parameters. Previous approaches achieve linear mode\nconnectivity by aligning parameters into the same loss basin using permutation\ninvariance. In this paper, we introduce Model Assembly Learning (MAL), a novel\nparadigm for model merging that iteratively integrates parameters from diverse\nmodels in an open-ended model zoo to enhance the base model's capabilities.\nUnlike previous works that require identical architectures, MAL allows the\nmerging of heterogeneous architectures and selective parameters across layers.\nSpecifically, the base model can incorporate parameters from different layers\nof multiple pre-trained models. We systematically investigate the conditions\nand fundamental settings of heterogeneous parameter merging, addressing all\npossible mismatches in layer widths between the base and target models.\nFurthermore, we establish key laws and provide practical guidelines for\neffectively implementing MAL.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-27T16:21:53Z"}
{"aid":"http://arxiv.org/abs/2503.21659v1","title":"InteractionMap: Improving Online Vectorized HDMap Construction with\n  Interaction","summary":"Vectorized high-definition (HD) maps are essential for an autonomous driving\nsystem. Recently, state-of-the-art map vectorization methods are mainly based\non DETR-like framework to generate HD maps in an end-to-end manner. In this\npaper, we propose InteractionMap, which improves previous map vectorization\nmethods by fully leveraging local-to-global information interaction in both\ntime and space. Firstly, we explore enhancing DETR-like detectors by explicit\nposition relation prior from point-level to instance-level, since map elements\ncontain strong shape priors. Secondly, we propose a key-frame-based\nhierarchical temporal fusion module, which interacts temporal information from\nlocal to global. Lastly, the separate classification branch and regression\nbranch lead to the problem of misalignment in the output distribution. We\ninteract semantic information with geometric information by introducing a novel\ngeometric-aware classification loss in optimization and a geometric-aware\nmatching cost in label assignment. InteractionMap achieves state-of-the-art\nperformance on both nuScenes and Argoverse2 benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2503.21665v1","title":"Non-quasicontinuous Newtonian functions and outer capacities based on\n  Banach function spaces","summary":"We construct various examples of Sobolev-type functions, defined via upper\ngradients in metric spaces, that fail to be quasicontinuous or weakly\nquasicontinuous. This is done with quasi-Banach function lattices $X$ as the\nfunction spaces defining the smoothness of the Sobolev-type functions. These\nresults are in contrast to the case $X=L^p$ with $1\\le p<\\infty$, where all\nSobolev-type functions in $N^p$ are known to be quasicontinuous, provided that\nthe underlying metric space $\\mathcal{P}$ is locally complete. In most of our\nexamples, $\\mathcal{P}$ is a compact subset of $\\mathbf{R}^2$ and $X=L^\\infty$.\nFour particular examples are the damped topologist's sine curve, the von Koch\nsnowflake curve, the Cantor ternary set and the Sierpi\\'nski carpet. We also\ndiscuss several related properties, such as whether the Sobolev capacity is an\nouter capacity, and how these properties are related. A fundamental role in\nthese considerations is played by the lack of the Vitali--Carath\\'eodory\nproperty.","main_category":"math.FA","categories":"math.FA","published":"2025-03-27T16:32:52Z"}
{"aid":"http://arxiv.org/abs/2503.21685v1","title":"Extracting Coupling-Mode Spectral Densities with Two-Dimensional\n  Electronic Spectroscopy","summary":"Methods for reconstructing the spectral density of a vibrational environment\nfrom experimental data can yield key insights into the impact of the\nenvironment on molecular function. Although such experimental methods exist,\nthey generally only access vibrational modes that couple diagonally to the\nelectron system. Here we present a method for extracting the spectral density\nof modes that couple to the transition between electronic states, using\ntwo-dimensional electronic spectroscopy. To demonstrate this, we use a\nprocess-tensor method that can simulate two-dimensional electronic spectroscopy\nmeasurements in a numerically exact way. To explain how the extraction works,\nwe also derive an approximate analytical solution, which illustrates that the\nnon-Markovianity of the environment plays an essential role in the existence of\nthe simulated signal.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,quant-ph","published":"2025-03-27T16:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.21699v1","title":"MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX","summary":"Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-03-27T17:04:33Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21713v1","title":"Investigating Experiential Effects in Online Chess using a Hierarchical\n  Bayesian Analysis","summary":"The presence or absence of winner-loser effects is a widely discussed\nphenomenon across both sports and psychology research. Investigation of such\neffects is often hampered by the limited availability of data. Online chess has\nexploded in popularity in recent years and provides vast amounts of data which\ncan be used to explore this question. With a hierarchical Bayesian regression\nmodel, we carefully investigate the presence of such experiential effects in\nonline chess. Using a large quantity of online chess data, we see little\nevidence for experiential effects that are consistent across all players, with\nsome individual players showing some evidence for such effects. Given the\nchallenging temporal nature of this data, we discuss several methods for\nassessing the suitability of our model and carefully check its validity.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-27T17:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.21716v1","title":"Dynamics of Star Cluster Formation: The Effects of Ongoing Star\n  Formation and Stellar Feedback","summary":"We perform a high resolution zoom-in simulation of star cluster assembly\nincluding the merger of two sub-clusters with initial conditions taken from\nprevious large scale giant molecular cloud (GMC) simulations. We couple\nhydrodynamics to N-body dynamics to simulate the individual stars themselves,\nand the gas-rich environment in which they evolve. We include prescriptions for\nstar formation and stellar feedback and compare directly to previous\nsimulations of the same region without these prescriptions to determine their\nrole in shaping the dynamics inherited from the cluster assembly process. The\nstellar mass of the cluster grows through star formation within the cluster and\naccretion of new stars and star forming gas from a nearby filament. This growth\nresults in an enhancement in the cluster's rotation and anisotropic expansion\ncompared to simulations without star formation. We also analyze the internal\nkinematics of the cluster once it has lost most of its gas and find that the\nrotational velocity and the velocity anisotropy profiles are qualitatively\nsimilar to those expected of clusters that have undergone violent relaxation.\nAs well, rotation and anisotropic expansion are still present by the time of\ngas removal. This implies that evolution within the GMC was unable to\ncompletely erase the kinematics inherited by the merger.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.21750v1","title":"Optical control of orbital magnetism in magic angle twisted bilayer\n  graphene","summary":"Flat bands in graphene-based moir\\'e structures host a wide range of emerging\nstrongly correlated and topological phenomena. Optically probing and\ncontrolling them can reveal important information such as symmetry and\ndynamics, but have so far been challenging due to the small energy gap compared\nto optical wavelengths. Here, we report near infrared optical control of\norbital magnetism and associated anomalous Hall effects (AHE) in a magic angle\ntwisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the\nproperties of the AHE, such as hysteresis and amplitude, can be controlled by\nlight near integer moir\\'e fillings, where spontaneous ferromagnetism exists.\nBy modulating the light helicity, we observe periodic modulation of the\ntransverse resistance in a wide range of fillings, indicating light induced\norbital magnetization through a large inverse Faraday effect. At the transition\nbetween metallic and AHE regimes, we also reveal large and random switching of\nthe Hall resistivity, which are attributed to optical control of percolating\ncluster of magnetic domains. Our results open the door to optical manipulation\nof correlation and topology in MATBG and related structures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-03-27T17:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.21774v1","title":"Optimal Stepsize for Diffusion Sampling","summary":"Diffusion models achieve remarkable generation quality but suffer from\ncomputational intensive sampling due to suboptimal step discretization. While\nexisting works focus on optimizing denoising directions, we address the\nprincipled design of stepsize schedules. This paper proposes Optimal Stepsize\nDistillation, a dynamic programming framework that extracts theoretically\noptimal schedules by distilling knowledge from reference trajectories. By\nreformulating stepsize optimization as recursive error minimization, our method\nguarantees global discretization bounds through optimal substructure\nexploitation. Crucially, the distilled schedules demonstrate strong robustness\nacross architectures, ODE solvers, and noise schedules. Experiments show 10x\naccelerated text-to-image generation while preserving 99.4% performance on\nGenEval. Our code is available at https://github.com/bebebe666/OptimalSteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.23681v1","title":"Universality of Shell Effects in Fusion-Fission Mass Distributions","summary":"We present the results of a broad, systematic study of heavy-ion induced\nfission mass distributions for every even-Z compound nucleus ($Z_\\mathrm{CN}$)\nfrom $^{144}$Gd to $^{212}$Th. We find systematic evidence of shell-driven\nstructure in every fission mass distribution. The change in shape of the mass\ndistributions with $Z_\\mathrm{CN}$ is consistent with the results of\nquantitative simultaneous fitting in mass and total kinetic energy,\ndemonstrating that fragment proton shell gaps at $Z_\\mathrm{FF} = 34, 36$ and\n$Z_\\mathrm{FF} = 44, 46$ are \\textit{both} major drivers of fission mass\ndistributions below the actinide region. The mass distributions show enhanced\nyields at mass symmetry for values of $Z_\\mathrm{CN}$ equal to two times these\nfavoured $Z_\\mathrm{FF}$ values. Thus, the same shell gaps that are drivers of\nmass-asymmetric fission also affect mass distributions at and near\nmass-symmetry. For all systems a second, more mass-asymmetric, fission mode is\nrequired to fit the fission mass distributions. If driven by a single shell\ngap, it appears to be in the light fragment around $Z_\\mathrm{FF} = 28, 30$.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T03:02:02Z"}
{"aid":"http://arxiv.org/abs/2503.23686v1","title":"Data-Driven Forecasting of High-Dimensional Transient and Stationary\n  Processes via Space-Time Projection","summary":"Space-Time Projection (STP) is introduced as a data-driven forecasting\napproach for high-dimensional and time-resolved data. The method computes\nextended space-time proper orthogonal modes from training data spanning a\nprediction horizon comprising both hindcast and forecast intervals. Forecasts\nare then generated by projecting the hindcast portion of these modes onto new\ndata, simultaneously leveraging their orthogonality and optimal correlation\nwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)\ntheory, dimensionality reduction and time-delay embedding are intrinsic to the\napproach. For a given ensemble and fixed prediction horizon, the only tunable\nparameter is the truncation rank--no additional hyperparameters are required.\nThe hindcast accuracy serves as a reliable indicator for short-term forecast\naccuracy and establishes a lower bound on forecast errors. The efficacy of the\nmethod is demonstrated using two datasets: transient, highly anisotropic\nsimulations of supernova explosions in a turbulent interstellar medium, and\nexperimental velocity fields of a turbulent high-subsonic engineering flow. In\na comparative study with standard Long Short-Term Memory (LSTM) neural\nnetworks--acknowledging that alternative architectures or training strategies\nmay yield different outcomes--the method consistently provided more accurate\nforecasts. Considering its simplicity and robust performance, STP offers an\ninterpretable and competitive benchmark for forecasting high-dimensional\ntransient and chaotic processes, relying purely on spatiotemporal correlation\ninformation.","main_category":"cs.LG","categories":"cs.LG,astro-ph.GA,nlin.CD,physics.comp-ph,physics.data-an,physics.flu-dyn","published":"2025-03-31T03:36:59Z"}
{"aid":"http://arxiv.org/abs/2503.23697v1","title":"A Low-complexity Structured Neural Network to Realize States of\n  Dynamical Systems","summary":"Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.","main_category":"cs.LG","categories":"cs.LG,math.DS","published":"2025-03-31T03:52:38Z"}
{"aid":"http://arxiv.org/abs/2503.23699v1","title":"Vapor-mediated wetting and imbibition control on micropatterned surfaces","summary":"Wetting of micropatterned surfaces is ubiquitous in nature and key to many\ntechnological applications like spray cooling, inkjet printing, and\nsemiconductor processing. Overcoming the intrinsic, chemistry- and\ntopography-governed wetting behaviors often requires specific materials which\nlimits applicability. Here, we show that spreading and wicking of water\ndroplets on hydrophilic surface patterns can be controlled by the presence of\nthe vapor of another liquid with lower surface tension. We show that delayed\nwicking arises from Marangoni forces due to vapor condensation, competing with\nthe capillary wicking force of the surface topography. Thereby, macroscopic\ndroplets can be brought into an effective apparent wetting behavior, decoupled\nfrom the surface topography, but coexisting with a wicking film, cloaking the\npattern. We demonstrate how modulating the vapor concentration in space and\ntime may guide droplets across patterns and even extract imbibed liquids,\ndevising new strategies for coating, cleaning and drying of functional surface\ndesigns.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-03-31T07:00:45Z"}
{"aid":"http://arxiv.org/abs/2503.23703v1","title":"Minimal solutions of tropical linear differential systems","summary":"We introduce and study minimal (with respect to inclusion) solutions of\nsystems of tropical linear differential equations. We describe the set of all\nminimal solutions for a single equation. It is shown that any tropical linear\ndifferential equation in a single unknown has either a solution or a solution\nat infinity. For a generic system of $n$ tropical linear differential equations\nin $n$ unknowns, upper and lower bounds on the number of minimal solutions are\nestablished. The upper bound involves inversions of a family of permutations\nwhich generalize inversions of a single permutation. For $n=1, 2$, we show that\nthe bounds are sharp.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-03-31T04:00:24Z"}
{"aid":"http://arxiv.org/abs/2503.23715v1","title":"HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video\n  Generation","summary":"Text-to-video (T2V) generation has made tremendous progress in generating\ncomplicated scenes based on texts. However, human-object interaction (HOI)\noften cannot be precisely generated by current T2V models due to the lack of\nlarge-scale videos with accurate captions for HOI. To address this issue, we\nintroduce HOIGen-1M, the first largescale dataset for HOI Generation,\nconsisting of over one million high-quality videos collected from diverse\nsources. In particular, to guarantee the high quality of videos, we first\ndesign an efficient framework to automatically curate HOI videos using the\npowerful multimodal large language models (MLLMs), and then the videos are\nfurther cleaned by human annotators. Moreover, to obtain accurate textual\ncaptions for HOI videos, we design a novel video description method based on a\nMixture-of-Multimodal-Experts (MoME) strategy that not only generates\nexpressive captions but also eliminates the hallucination by individual MLLM.\nFurthermore, due to the lack of an evaluation framework for generated HOI\nvideos, we propose two new metrics to assess the quality of generated videos in\na coarse-to-fine manner. Extensive experiments reveal that current T2V models\nstruggle to generate high-quality HOI videos and confirm that our HOIGen-1M\ndataset is instrumental for improving HOI video generation. Project webpage is\navailable at https://liuqi-creat.github.io/HOIGen.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.23718v1","title":"Detecting Functional Bugs in Smart Contracts through LLM-Powered and\n  Bug-Oriented Composite Analysis","summary":"Smart contracts are fundamental pillars of the blockchain, playing a crucial\nrole in facilitating various business transactions. However, these smart\ncontracts are vulnerable to exploitable bugs that can lead to substantial\nmonetary losses. A recent study reveals that over 80% of these exploitable\nbugs, which are primarily functional bugs, can evade the detection of current\ntools. The primary issue is the significant gap between understanding the\nhigh-level logic of the business model and checking the low-level\nimplementations in smart contracts. Furthermore, identifying deeply rooted\nfunctional bugs in smart contracts requires the automated generation of\neffective detection oracles based on various bug features. To address these\nchallenges, we design and implement PROMFUZZ, an automated and scalable system\nto detect functional bugs, in smart contracts. In PROMFUZZ, we first propose a\nnovel Large Language Model (LLM)-driven analysis framework, which leverages a\ndual-agent prompt engineering strategy to pinpoint potentially vulnerable\nfunctions for further scrutiny. We then implement a dual-stage coupling\napproach, which focuses on generating invariant checkers that leverage logic\ninformation extracted from potentially vulnerable functions. Finally, we design\na bug-oriented fuzzing engine, which maps the logical information from the\nhigh-level business model to the low-level smart contract implementations, and\nperforms the bug-oriented fuzzing on targeted functions. We compare PROMFUZZ\nwith multiple state-of-the-art methods. The results show that PROMFUZZ achieves\n86.96% recall and 93.02% F1-score in detecting functional bugs, marking at\nleast a 50% improvement in both metrics over state-of-the-art methods.\nMoreover, we perform an in-depth analysis on real-world DeFi projects and\ndetect 30 zero-day bugs. Up to now, 24 zero-day bugs have been assigned CVE\nIDs.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-03-31T04:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.23726v1","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with\n  Heterogeneous Data Distribution","summary":"In the paradigm of decentralized learning, a group of agents collaborates to\nlearn a global model using distributed datasets without a central server.\nHowever, due to the heterogeneity of the local data across the different\nagents, learning a robust global model is rather challenging. Moreover, the\ncollaboration of the agents relies on their gradient information exchange,\nwhich poses a risk of privacy leakage. In this paper, to address these issues,\nwe propose PDSL, a novel privacy-preserved decentralized stochastic learning\nalgorithm with heterogeneous data distribution. On one hand, we innovate in\nutilizing the notion of Shapley values such that each agent can precisely\nmeasure the contributions of its heterogeneous neighbors to the global learning\ngoal; on the other hand, we leverage the notion of differential privacy to\nprevent each agent from suffering privacy leakage when it contributes gradient\ninformation to its neighbors. We conduct both solid theoretical analysis and\nextensive experiments to demonstrate the efficacy of our PDSL algorithm in\nterms of privacy preservation and convergence.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T04:58:05Z"}
{"aid":"http://arxiv.org/abs/2503.23750v1","title":"Float Lattice Gas Automata: A connection between Molecular Dynamics and\n  Lattice Boltzmann Method for quantum computers","summary":"Building upon the Integer Lattice Gas Automata framework of Blommel\n\\textit{et al.} \\cite{PhysRevE.97.023310}, we introduce a simplified,\nfluctuation-free variant. This approach relies on floating-point numbers and\nclosely mirrors the Lattice Boltzmann Method (LBM), with the key distinction\nbeing a novel collision operator. This operator, derived from the ensemble\naverage of transition probabilities, generates nonlinear terms. We propose this\nnew Float Lattice Gas Automata (FLGA) collision as a computationally efficient\nalternative to traditional and quantum LBM implementations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:02:16Z"}
{"aid":"http://arxiv.org/abs/2503.23757v1","title":"Time-Series Forecasting via Topological Information Supervised Framework\n  with Efficient Topological Feature Learning","summary":"Topological Data Analysis (TDA) has emerged as a powerful tool for extracting\nmeaningful features from complex data structures, driving significant\nadvancements in fields such as neuroscience, biology, machine learning, and\nfinancial modeling. Despite its success, the integration of TDA with\ntime-series prediction remains underexplored due to three primary challenges:\nthe limited utilization of temporal dependencies within topological features,\ncomputational bottlenecks associated with persistent homology, and the\ndeterministic nature of TDA pipelines restricting generalized feature learning.\nThis study addresses these challenges by proposing the Topological Information\nSupervised (TIS) Prediction framework, which leverages neural networks and\nConditional Generative Adversarial Networks (CGANs) to generate synthetic\ntopological features, preserving their distribution while significantly\nreducing computational time. We propose a novel training strategy that\nintegrates topological consistency loss to improve the predictive accuracy of\ndeep learning models. Specifically, we introduce two state-of-the-art models,\nTIS-BiGRU and TIS-Informer, designed to capture short-term and long-term\ntemporal dependencies, respectively. Comparative experimental results\ndemonstrate the superior performance of TIS models over conventional\npredictors, validating the effectiveness of integrating topological\ninformation. This work not only advances TDA-based time-series prediction but\nalso opens new avenues for utilizing topological features in deep learning\narchitectures.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:16:19Z"}
{"aid":"http://arxiv.org/abs/2503.23764v1","title":"WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation\n  for Efficient Medical Image Segmentation","summary":"Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limi- tations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual rep- resentation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architec- ture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency de- tails while replacing heavy upsampling layers\nwith efficient wavelet-based summarization and reconstruction. This\nsignificantly reduces the number of parameters, which is critical for\nreal-world deployment where compu- tational resources and training times are\nconstrained. Furthermore, the model is generic and easily adaptable to diverse\napplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrate\nperformance on par with state-of-the-art methods while offering substantially\nlower computational complexity.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T06:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23778v1","title":"Efficient defect healing of single-walled cabron nanotubes through $\n  \\mathrm{C}_{2}\\mathrm{H}_{2} $-assisted multiple-cycle treatment with air\n  exposure","summary":"Defects in single-walled carbon nanotubes (SWCNTs) degrade their\nmechanical,electrical, and thermal properties, limiting their potential\napplications. To realize the diverse applications of SWCNTs, it is essential to\nenhance their crystallinity through effective defect healing. However,\ntraditional thermal treatments typically require temperatures above\n1800{\\deg}C, which can alter the nanotube structure. Previously, defect healing\nof SWCNTs was achieved at a relatively low temperature of 1100{\\deg}C, using\nC$_{2}$H$_{2}$ assistance, but the efficiency was limited. In this study, we\ndeveloped a C$_{2}$H$_{2}$-assisted multiple-cycle process at an even lower\ntemperature of 1000{\\deg}C combined with air exposure, achieving highly\nefficient defect healing while preserving the nanotube structure. The\ncombination of multiple-cycle treatment and air exposure between cycles was\nfound to promote defect activation, suppress the formation of amorphous carbon,\nand enhance the effectiveness of defect healing. Additionally, we successfully\nhealed commercially available bulk-scale SWCNTs (super-growth SWCNTs), noting\nthat their healing behavior differed from lab-grown SWCNTs with smaller\ndiameters synthesized from nanodiamond. The efficient and structure-preserved\nhealing process developed in this study broadens the potential applications of\nhigh-quality SWCNTs, including flexible electronics, high-performance\ncomposites, and energy storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T06:53:11Z"}
{"aid":"http://arxiv.org/abs/2503.23785v1","title":"ObfusQate: Unveiling the First Quantum Program Obfuscation Framework","summary":"This paper introduces ObfusQate, a novel tool that conducts obfuscations\nusing quantum primitives to enhance the security of both classical and quantum\nprograms. We have designed and implemented two primary categories of\nobfuscations: quantum circuit level obfuscation and code level obfuscation,\nencompassing a total of eight distinct methods. Quantum circuit-level\nobfuscation leverages on quantum gates and circuits, utilizing strategies such\nas quantum gate hiding and identity matrices to construct complex,\nnon-intuitive circuits that effectively obscure core functionalities and resist\nreverse engineering, making the underlying code difficult to interpret.\nMeanwhile, code-level obfuscation manipulates the logical sequence of program\noperations through quantum-based opaque predicates, obfuscating execution paths\nand rendering program behavior more unpredictable and challenging to analyze.\nAdditionally, ObfusQate can be used to obfuscate malicious code segments,\nmaking them harder to detect and analyze. These advancements establish a\nfoundational framework for further exploration into the potential and\nlimitations of quantum-based obfuscation techniques, positioning ObfusQate as a\nvaluable tool for future developers to enhance code security in the evolving\nlandscape of software development. To the best of our knowledge, ObfusQate\nrepresents the pioneering work in developing an automated framework for\nimplementing obfuscations leveraging quantum primitives. Security evaluations\nshow that obfuscations by ObfusQate maintain code behavior with polynomial\noverheads in space and time complexities. We have also demonstrated an\noffensive use case by embedding a keylogger into Shor's algorithm and\nobfuscating it using ObfusQate. Our results show that current Large language\nmodels like GPT 4o, GPT o3 mini and Grok 3 were not able to identify the\nmalicious keylogger after obfuscation.","main_category":"cs.CR","categories":"cs.CR,cs.ET","published":"2025-03-31T07:02:25Z"}
{"aid":"http://arxiv.org/abs/2503.23787v1","title":"A rational cohomology which including that of a spin hyperelliptic\n  mapping class group","summary":"Let $\\mathfrak{G}=\\mathfrak{S}_{q} \\overleftrightarrow{\\times}\n\\mathfrak{S}_q$ be the $\\mathbb{Z}/2$-extension of the product of two symmetric\ngroups $\\mathfrak{S}_{q} \\times \\mathfrak{S}_q$. In this paper, we compute the\n$\\mathfrak{G}$-invariant part of the rational cohomology of the pure braid\ngroup $P_{n}$, where $n=2q$, denoted by $H^{*}(P_n)^{\\mathfrak{G}}$. As is\nknown classically, $H^{*}(P_n)^{\\mathfrak{G}}$ includes the rational cohomology\nof a spin hyperelliptic mapping class group, denoted by\n$H^*(\\mathcal{S}(\\Sigma_{g};c))$, where $2g+2=n=2q$.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T07:02:36Z"}
{"aid":"http://arxiv.org/abs/2503.23792v1","title":"When do firms sell high durability products? The case of light bulb\n  industry","summary":"This study empirically investigates firms' incentives on the choice of\nproduct durability, and its social optimality, by developing a dynamic\nstructural model of durable goods with forward-looking consumers and\noligopolistic multi-product firms. Based on the observations of the light bulb\nmarket, it specifies a model where firms produce multiple products with\ndifferent durability levels and set product prices based on dynamic incentives.\nIt proposes and applies novel estimation algorithms that alleviate the\ncomputational burden and data requirement for estimating demand and marginal\ncost parameters of dynamic demand models. Using light bulb market data in\nJapan, structural parameters are estimated. This study obtains the following\nresults. First, large firms have incentives to collude to eliminate high\ndurability incandescent lamps, though it is profitable to sell them for each\nfirm. In contrast, when they can collude on prices, they don't have incentives\nto eliminate high durability bulbs. Second, eliminating high durability\nincandescent lamps leads to larger producer and total surplus, though it leads\nto lower consumer surplus.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T07:13:44Z"}
{"aid":"http://arxiv.org/abs/2503.23802v1","title":"Herscovici Conjecture on Pebbling","summary":"Consider a configuration of pebbles on the vertices of a connected graph. A\npebbling move is to remove two pebbles from a vertex and to place one pebble at\nthe neighbouring vertex of the vertex from which the pebbles are removed.\n  For a positive integer $t$, with every configuration of $\\pi_t(G)$(least\npositive integer) pebbles, if we can transfer $t$ pebbles to any target through\na number of pebbling moves then $\\pi_t(G)$ is called the $t$-pebbling number of\n$G$.\n  We discuss the computation of the $t$-pebbling number, the $2t-$ pebbling\nproperty and Herscovici conjecture considering total graphs.\n  \\bigskip \\noindent Keywords: pebbling moves, $t$- pebbling number,\n$2t$-pebbling property, Herscovici conjecture, total graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2503.23803v1","title":"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\n  Scaling Test-Time Compute","summary":"Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T07:31:32Z"}
{"aid":"http://arxiv.org/abs/2503.23811v1","title":"Did ChatGPT or Copilot use alter the style of internet news headlines? A\n  time series regression analysis","summary":"The release of advanced Large Language Models (LLMs) such as ChatGPT and\nCopilot is changing the way text is created and may influence the content that\nwe find on the web. This study investigated whether the release of these two\npopular LLMs coincided with a change in writing style in headlines and links on\nworldwide news websites. 175 NLP features were obtained for each text in a\ndataset of 451 million headlines/links. An interrupted time series analysis was\napplied for each of the 175 NLP features to evaluate whether there were any\nstatistically significant sustained changes after the release dates of ChatGPT\nand/or Copilot. There were a total of 44 features that did not appear to have\nany significant sustained change after the release of ChatGPT/Copilot. A total\nof 91 other features did show significant change with ChatGPT and/or Copilot\nalthough significance with earlier control LLM release dates (GPT-1/2/3,\nGopher) removed them from consideration. This initial analysis suggests these\nlanguage models may have had a limited impact on the style of individual news\nheadlines/links, with respect to only some NLP measures.","main_category":"cs.CL","categories":"cs.CL,cs.SI","published":"2025-03-31T07:44:26Z"}
{"aid":"http://arxiv.org/abs/2503.23817v1","title":"MVDRAM: Enabling GeMV Execution in Unmodified DRAM for Low-Bit LLM\n  Acceleration","summary":"General matrix-vector multiplication (GeMV) remains a critical latency\nbottleneck in large language model (LLM) inference, even with quantized low-bit\nmodels. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has\nthe potential to repurpose on-device DRAM as a GeMV engine, offering additional\nhigh-throughput processing capabilities to widespread consumer devices without\nDRAM modifications. However, applying PUD to GeMV operations in the LLM\ninference pipeline incurs significant overheads $\\textit{before}$ and\n$\\textit{after}$ in-DRAM computation, diminishing the benefits of its\nhigh-throughput processing capabilities.\n  This paper presents MVDRAM, the first practical system to accelerate GeMV\noperations for low-bit LLM inference using unmodified DRAM. By leveraging the\ndata sharing patterns and mathematical linearity in GeMV operations, MVDRAM\norchestrates the processor and DRAM to eliminate the costs associated with\npre-arranging inputs and bit-transposition of outputs required in conventional\nPUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows\nthat MVDRAM achieves comparable or even better inference speed than the\nprocessor-based implementation for GeMV operations in low-bit (under 4-bit)\nLLM. In particular, MVDRAM achieves up to 7.29$\\times$ speedup and 30.5$\\times$\nenergy efficiency for low-bit GeMV operations. For end-to-end LLM inference,\nMVDRAM achieves 2.18$\\times$ and 1.31$\\times$ throughput improvements, along\nwith 3.04$\\times$ and 2.35$\\times$ energy efficiency, for 2-bit and 4-bit\nquantized low-bit models, respectively. MVDRAM has the potential to redefine\nthe AI hardware landscape by demonstrating the feasibility of standard DRAM as\nan LLM accelerator.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-03-31T07:54:59Z"}
{"aid":"http://arxiv.org/abs/2503.23830v1","title":"OrchMLLM: Orchestrate Multimodal Data with Batch Post-Balancing to\n  Accelerate Multimodal Large Language Model Training","summary":"Multimodal large language models (MLLMs), such as GPT-4o, are garnering\nsignificant attention. During the exploration of MLLM training, we identified\nModality Composition Incoherence, a phenomenon that the proportion of a certain\nmodality varies dramatically across different examples. It exacerbates the\nchallenges of addressing mini-batch imbalances, which lead to uneven GPU\nutilization between Data Parallel (DP) instances and severely degrades the\nefficiency and scalability of MLLM training, ultimately affecting training\nspeed and hindering further research on MLLMs.\n  To address these challenges, we introduce OrchMLLM, a comprehensive framework\ndesigned to mitigate the inefficiencies in MLLM training caused by Modality\nComposition Incoherence. First, we propose Batch Post-Balancing Dispatcher, a\ntechnique that efficiently eliminates mini-batch imbalances in sequential data.\nAdditionally, we integrate MLLM Global Orchestrator into the training framework\nto orchestrate multimodal data and tackle the issues arising from Modality\nComposition Incoherence. We evaluate OrchMLLM across various MLLM sizes,\ndemonstrating its efficiency and scalability. Experimental results reveal that\nOrchMLLM achieves a Model FLOPs Utilization (MFU) of $41.6\\%$ when training an\n84B MLLM with three modalities on $2560$ H100 GPUs, outperforming Megatron-LM\nby up to $3.1\\times$ in throughput.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-03-31T08:24:23Z"}
{"aid":"http://arxiv.org/abs/2503.23851v1","title":"Revealing quantum phase string effect in doped Mott-insulator: a tensor\n  network state approach","summary":"We apply the fermionic tensor network (TN) state method to understand the\nstrongly correlated nature in a doped Mott insulator. We conduct a comparative\nstudy of the $\\sigma t$-$J$ model, in which the no-double-occupancy constraint\nremains unchanged but the quantum phase string effect associated with doped\nholes is precisely switched off. Thus, the ground state of the $\\sigma t$-$J$\nmodel can serve as a well-controlled reference state of the standard $t$-$J$\nmodel. In the absence of phase string, the spin long-range antiferromagnetic\n(AFM) order is found to be essentially decoupled from the doped holes, and the\nlatter contribute to a Fermi-liquid-like compressibility and a coherent\nsingle-particle propagation with a markedly reduced pairing tendency. In\ncontrast, our TN calculations of the $t$-$J$ model indicate that the AFM order\ndecreases much faster with doping and the single-particle propagation of doped\nholes gets substantially suppressed, concurrently with a much stronger charge\ncompressibility at small doping and a significantly amplified Cooper pairing\ntendencies. These findings demonstrate that quantum many-body interference from\nphase strings plays a pivotal role in the $t$-$J$ model, mediating long-range\nentanglement between spin and charge degrees of freedom.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T08:55:55Z"}
{"aid":"http://arxiv.org/abs/2503.23878v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud II: Predictions from rapid binary evolution","summary":"Massive star evolution plays a crucial role in astrophysics but bares large\nuncertainties. This problem becomes more severe by the majority of massive\nstars being born in close binary systems, whose evolution is affected by the\ninteraction of their components. We want to constrain major uncertainties in\nmassive binary star evolution, in particular the efficiency and the stability\nof the first mass transfer phase. We use the rapid population synthesis code\nComBinE to generate synthetic populations of post-interaction binaries,\nassuming constant mass-transfer efficiency. We employ a new merger criterion\nthat adjusts self-consistently to any prescribed mass-transfer efficiency. We\ntailor our synthetic populations to be comparable to the expected binary\npopulations in the Small Magellanic Cloud (SMC). We find that the observed\npopulations of evolved massive binaries can not be reproduced with a single\nmass-transfer efficiency. Instead, a rather high efficiency (>50%) is needed to\nreproduce the number of Be stars and Be/X-ray binaries in the SMC, while a low\nefficiency (~10%) leads to a better agreement with the observed number of\nWolf-Rayet stars. We construct a corresponding mass-dependent mass-transfer\nefficiency recipe to produce our fiducial synthetic SMC post-interaction binary\npopulation. It reproduces the observed number and properties of the Be/X-ray\nand WR-binaries rather well, and is not in stark disagreement with the observed\nOBe star population. It further predicts two large, yet unobserved populations\nof OB+BH binaries, that is ~100 OB+BH systems with rather small orbital periods\n(<20 days) and ~40 longer period OBe+BH systems.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:27:04Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23882v1","title":"GLane3D : Detecting Lanes with Graph of 3D Keypoints","summary":"Accurate and efficient lane detection in 3D space is essential for autonomous\ndriving systems, where robust generalization is the foremost requirement for 3D\nlane detection algorithms. Considering the extensive variation in lane\nstructures worldwide, achieving high generalization capacity is particularly\nchallenging, as algorithms must accurately identify a wide variety of lane\npatterns worldwide. Traditional top-down approaches rely heavily on learning\nlane characteristics from training datasets, often struggling with lanes\nexhibiting previously unseen attributes. To address this generalization\nlimitation, we propose a method that detects keypoints of lanes and\nsubsequently predicts sequential connections between them to construct complete\n3D lanes. Each key point is essential for maintaining lane continuity, and we\npredict multiple proposals per keypoint by allowing adjacent grids to predict\nthe same keypoint using an offset mechanism. PointNMS is employed to eliminate\noverlapping proposal keypoints, reducing redundancy in the estimated BEV graph\nand minimizing computational overhead from connection estimations. Our model\nsurpasses previous state-of-the-art methods on both the Apollo and OpenLane\ndatasets, demonstrating superior F1 scores and a strong generalization capacity\nwhen models trained on OpenLane are evaluated on the Apollo dataset, compared\nto prior approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:26Z"}
{"aid":"http://arxiv.org/abs/2503.23884v1","title":"Sampled-data and event-triggered control of globally Lipschitz\n  infinite-dimensional systems","summary":"We show that if a linear infinite-dimensional system is exponentially\nstabilizable by compact feedback, it is also stabilizable by means of a\nsampled-data feedback that is fed through a globally Lipschitz nonlinearity,\nprovided that the sector bound for the nonlinearity and the sampling time is\nsmall enough. Next we develop a switching-based event-triggered control scheme\nstabilizing the system with a reduced number of switching events. We\ndemonstrate our results on an example of finite-dimensional stabilization of a\nSturm-Liouville parabolic system.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T09:37:08Z"}
{"aid":"http://arxiv.org/abs/2503.23897v1","title":"Training-Free Text-Guided Image Editing with Visual Autoregressive Model","summary":"Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:46:56Z"}
{"aid":"http://arxiv.org/abs/2503.23900v1","title":"Convergence of CalderÃ³n residuals","summary":"In this paper, we describe a framework to compute expected convergence rates\nfor residuals based on the Calder\\'on identities for general second order\ndifferential operators for which fundamental solutions are known. The idea is\nthat these rates could be used to validate implementations of boundary integral\noperators and allow to test operators separately by choosing solutions where\nparts of the Calder\\'on identities vanish. Our estimates rely on simple vector\nnorms, and thus avoid the use of hard-to-compute norms and the residual\ncomputation can be easily implemented in existing boundary element codes. We\ntest the proposed Calder\\'on residuals as debugging tool by introducing\nartificial errors into the Galerkin matrices of some of the boundary integral\noperators for the Laplacian and time-harmonic Maxwell's equations. From this,\nwe learn that our estimates are not sharp enough to always detect errors, but\nstill provide a simple and useful debugging tool in many situations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T09:49:19Z"}
{"aid":"http://arxiv.org/abs/2503.23922v1","title":"Distributionally Robust Model Order Reduction for Linear Systems","summary":"In this paper, we investigate distributionally robust model order reduction\nfor linear, discrete-time, time-invariant systems. The external input is\nassumed to follow an uncertain distribution within a Wasserstein ambiguity set.\nWe begin by considering the case where the distribution is certain and\nformulate an optimization problem to obtain the reduced model. When the\ndistribution is uncertain, the interaction between the reduced-order model and\nthe distribution is modeled by a Stackelberg game. To ensure solvability, we\nfirst introduce the Gelbrich distance and demonstrate that the Stackelberg game\nwithin a Wasserstein ambiguity set is equivalent to that within a Gelbrich\nambiguity set. Then, we propose a nested optimization problem to solve the\nStackelberg game. Furthermore, the nested optimization problem is relaxed into\na nested convex optimization problem, ensuring computational feasibility.\nFinally, a simulation is presented to illustrate the effectiveness of the\nproposed method.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T10:13:12Z"}
{"aid":"http://arxiv.org/abs/2503.23928v1","title":"Superconducting Spin-Singlet QuBit in a Triangulene Spin Chain","summary":"Chains of triangular nanographene (triangulene), recently identified as\nrealizing the valence-bond solid phase of a spin-$1$ chain, offer a promising\nplatform for quantum information processing. We propose a superconducting\nspin-singlet qubit based on these chains grown on a superconducting substrate.\nUsing the numerical renormalization group (NRG), we find a manifold of two\nlowest-lying, isolated spin-singlet states that undergo an avoided crossing. A\nqubit utilizing these states is thus protected from random-field noise and\nquasi-particle poisoning. We also introduce a mesoscopic device architecture,\nbased on a triple quantum dot coupled to a superconducting junction, that\nquantum simulates the spin chain and enables control and readout of the qubit.\nAn effective two-level description of the device is validated using\ntime-dependent NRG.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-03-31T10:23:17Z"}
{"aid":"http://arxiv.org/abs/2503.23935v1","title":"Nonparametric function-on-scalar regression using deep neural networks","summary":"We focus on nonlinear Function-on-Scalar regression, where the predictors are\nscalar variables, and the responses are functional data. Most existing studies\napproximate the hidden nonlinear relationships using linear combinations of\nbasis functions, such as splines. However, in classical nonparametric\nregression, it is known that these approaches lack adaptivity, particularly\nwhen the true function exhibits high spatial inhomogeneity or anisotropic\nsmoothness. To capture the complex structure behind data adaptively, we propose\na simple adaptive estimator based on a deep neural network model. The proposed\nestimator is straightforward to implement using existing deep learning\nlibraries, making it accessible for practical applications. Moreover, we derive\nthe convergence rates of the proposed estimator for the anisotropic Besov\nspaces, which consist of functions with varying smoothness across dimensions.\nOur theoretical analysis shows that the proposed estimator mitigates the curse\nof dimensionality when the true function has high anisotropic smoothness, as\nshown in the classical nonparametric regression. Numerical experiments\ndemonstrate the superior adaptivity of the proposed estimator, outperforming\nexisting methods across various challenging settings. Moreover, the proposed\nmethod is applied to analyze ground reaction force data in the field of sports\nmedicine, demonstrating more efficient estimation compared to existing\napproaches.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T10:34:50Z"}
{"aid":"http://arxiv.org/abs/2503.23938v1","title":"New results about aggregation functions of quasi-pseudometric modulars","summary":"In recent studies, Bibiloni-Femenias, Mi\\~{n}ana and Valero characterized the\nfunctions that aggregate a family of (quasi-)(pseudo)metric modulars defined\nover a fixed set $X$ into a single one. In this paper, we adopt a related but\ndifferent approach to examine those functions that allow us to define a\n(quasi-)(pseudo)metric modular in the Cartesian product of\n(quasi-)(pseudo)metric modular spaces. We base our research on the recent\ndevelopment of a general theory of aggregation functions between quantales.\nThis enables to shed light between the two different ways of aggregation\n(quasi-)(pseudo)metric modulars.","main_category":"math.GN","categories":"math.GN","published":"2025-03-31T10:38:24Z"}
{"aid":"http://arxiv.org/abs/2503.23940v1","title":"Operator limit of Wigner matrices I","summary":"We consider the Wigner matrix $W_{n}$ of dimension $n \\times n$ as $n \\to\n\\infty$. The objective of this paper is two folds: first we construct an\noperator $\\mathcal{W}$ on a suitable Hilbert space $\\mathcal{H}$ and then\ndefine a suitable notion of convergence such that the matrices $W_{n}$ converge\nin that notion of convergence to $\\mathcal{W}$. We further investigate some\nproperties of $\\mathcal{W}$ and $\\mathcal{H}$. We show that $\\mathcal{H}$ is a\nnontrivial extension of $L^{2}[0,1]$ with respect to the Lebesgue measure and\nthe spectral measure of $\\mathcal{W}$ at any function $f \\in L^{2}[0,1]$ is\nalmost surely the semicircular law.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP,math.ST,stat.TH","published":"2025-03-31T10:45:01Z"}
{"aid":"http://arxiv.org/abs/2503.23947v1","title":"Spectral-Adaptive Modulation Networks for Visual Perception","summary":"Recent studies have shown that 2D convolution and self-attention exhibit\ndistinct spectral behaviors, and optimizing their spectral properties can\nenhance vision model performance. However, theoretical analyses remain limited\nin explaining why 2D convolution is more effective in high-pass filtering than\nself-attention and why larger kernels favor shape bias, akin to self-attention.\nIn this paper, we employ graph spectral analysis to theoretically simulate and\ncompare the frequency responses of 2D convolution and self-attention within a\nunified framework. Our results corroborate previous empirical findings and\nreveal that node connectivity, modulated by window size, is a key factor in\nshaping spectral functions. Leveraging this insight, we introduce a\n\\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visual\nfeatures in a spectral-adaptive manner using multi-scale convolutional kernels\nand a spectral re-scaling mechanism to refine spectral components. Based on\nSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experiments\ndemonstrate that SPANetV2 outperforms state-of-the-art models across multiple\nvision tasks, including ImageNet-1K classification, COCO object detection, and\nADE20K semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2503.23957v1","title":"Written in the Stars: How your (pens and) papers decide the fate of the\n  arXiverse","summary":"We all love the ecstasy that comes with submitting papers to journals or\narXiv. Some have described it as yeeting their back-breaking products of labor\ninto the void, wishing they could never deal with them ever again. The very act\nof yeeting papers onto arXiv contributes to the expansion of the arXiverse;\nhowever, we have yet to quantify our contribution to the cause. In this work, I\ninvestigate the expansion of the arXiverse using the arXiv astro-ph submission\ndata from 1992 to date. I coin the term \"the arXiverse constant\", $a_0$, to\nquantify the rate of expansion of the arXiverse. I find that astro-ph as a\nwhole has a positive $a_0$, but this does not always hold true for the six\nsubcategories of astro-ph. I then investigate the temporal changes in $a_0$ for\nthe astro-ph subcategories and astro-ph as a whole, from which I infer the fate\nof the arXiverse.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.EP,astro-ph.GA,astro-ph.HE,astro-ph.IM,astro-ph.SR","published":"2025-03-31T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.23975v1","title":"A Reactive Framework for Whole-Body Motion Planning of Mobile\n  Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic\n  Programmi","summary":"As an important branch of embodied artificial intelligence, mobile\nmanipulators are increasingly applied in intelligent services, but their\nredundant degrees of freedom also limit efficient motion planning in cluttered\nenvironments. To address this issue, this paper proposes a hybrid learning and\noptimization framework for reactive whole-body motion planning of mobile\nmanipulators. We develop the Bayesian distributional soft actor-critic\n(Bayes-DSAC) algorithm to improve the quality of value estimation and the\nconvergence performance of the learning. Additionally, we introduce a quadratic\nprogramming method constrained by the signed distance field to enhance the\nsafety of the obstacle avoidance motion. We conduct experiments and make\ncomparison with standard benchmark. The experimental results verify that our\nproposed framework significantly improves the efficiency of reactive whole-body\nmotion planning, reduces the planning time, and improves the success rate of\nmotion planning. Additionally, the proposed reinforcement learning method\nensures a rapid learning process in the whole-body planning task. The novel\nframework allows mobile manipulators to adapt to complex environments more\nsafely and efficiently.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T11:37:02Z"}
{"aid":"http://arxiv.org/abs/2503.24002v1","title":"A Simple BER Expression for FSO Systems with Weak Turbulence and\n  Pointing Errors","summary":"We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T12:27:24Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24012v1","title":"Tree-Guided $L_1$-Convex Clustering","summary":"Convex clustering is a modern clustering framework that guarantees globally\noptimal solutions and performs comparably to other advanced clustering methods.\nHowever, obtaining a complete dendrogram (clusterpath) for large-scale datasets\nremains computationally challenging due to the extensive costs associated with\niterative optimization approaches. To address this limitation, we develop a\nnovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering\n(TGCC). We first focus on the fact that the loss function of $L_1$-convex\nclustering with tree-structured weights can be efficiently optimized using a\ndynamic programming approach. We then develop an efficient cluster fusion\nalgorithm that utilizes the tree structure of the weights to accelerate the\noptimization process and eliminate the issue of cluster splits commonly\nobserved in convex clustering. By combining the dynamic programming approach\nwith the cluster fusion algorithm, the TGCC algorithm achieves superior\ncomputational efficiency without sacrificing clustering performance.\nRemarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$\npoints in $\\mathbb{R}^2$ within 15 seconds on a standard laptop without the\nneed for parallel or distributed computing frameworks. Moreover, we extend the\nTGCC algorithm to develop biclustering and sparse convex clustering algorithms.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-03-31T12:39:48Z"}
{"aid":"http://arxiv.org/abs/2503.24014v1","title":"Optimization of Layer Skipping and Frequency Scaling for Convolutional\n  Neural Networks under Latency Constraint","summary":"The energy consumption of Convolutional Neural Networks (CNNs) is a critical\nfactor in deploying deep learning models on resource-limited equipment such as\nmobile devices and autonomous vehicles. We propose an approach involving\nProportional Layer Skipping (PLS) and Frequency Scaling (FS). Layer skipping\nreduces computational complexity by selectively bypassing network layers,\nwhereas frequency scaling adjusts the frequency of the processor to optimize\nenergy use under latency constraints. Experiments of PLS and FS on ResNet-152\nwith the CIFAR-10 dataset demonstrated significant reductions in computational\ndemands and energy consumption with minimal accuracy loss. This study offers\npractical solutions for improving real-time processing in resource-limited\nsettings and provides insights into balancing computational efficiency and\nmodel performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:40:11Z"}
{"aid":"http://arxiv.org/abs/2503.24021v1","title":"IntelliCircos: A Data-driven and AI-powered Authoring Tool for Circos\n  Plots","summary":"Genomics data is essential in biological and medical domains, and\nbioinformatics analysts often manually create circos plots to analyze the data\nand extract valuable insights. However, creating circos plots is complex, as it\nrequires careful design for multiple track attributes and positional\nrelationships between them. Typically, analysts often seek inspiration from\nexisting circos plots, and they have to iteratively adjust and refine the plot\nto achieve a satisfactory final design, making the process both tedious and\ntime-intensive. To address these challenges, we propose IntelliCircos, an\nAI-powered interactive authoring tool that streamlines the process from initial\nvisual design to the final implementation of circos plots. Specifically, we\nbuild a new dataset containing 4396 circos plots with corresponding annotations\nand configurations, which are extracted and labeled from published papers. With\nthe dataset, we further identify track combination patterns, and utilize Large\nLanguage Model (LLM) to provide domain-specific design recommendations and\nconfiguration references to navigate the design of circos plots. We conduct a\nuser study with 8 bioinformatics analysts to evaluate IntelliCircos, and the\nresults demonstrate its usability and effectiveness in authoring circos plots.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T12:48:39Z"}
{"aid":"http://arxiv.org/abs/2503.24027v1","title":"Crossing Boundaries: Leveraging Semantic Divergences to Explore Cultural\n  Novelty in Cooking Recipes","summary":"Novelty modeling and detection is a core topic in Natural Language Processing\n(NLP), central to numerous tasks such as recommender systems and automatic\nsummarization. It involves identifying pieces of text that deviate in some way\nfrom previously known information. However, novelty is also a crucial\ndeterminant of the unique perception of relevance and quality of an experience,\nas it rests upon each individual's understanding of the world. Social factors,\nparticularly cultural background, profoundly influence perceptions of novelty\nand innovation. Cultural novelty arises from differences in salience and\nnovelty as shaped by the distance between distinct communities. While cultural\ndiversity has garnered increasing attention in artificial intelligence (AI),\nthe lack of robust metrics for quantifying cultural novelty hinders a deeper\nunderstanding of these divergences. This gap limits quantifying and\nunderstanding cultural differences within computational frameworks. To address\nthis, we propose an interdisciplinary framework that integrates knowledge from\nsociology and management. Central to our approach is GlobalFusion, a novel\ndataset comprising 500 dishes and approximately 100,000 cooking recipes\ncapturing cultural adaptation from over 150 countries. By introducing a set of\nJensen-Shannon Divergence metrics for novelty, we leverage this dataset to\nanalyze textual divergences when recipes from one community are modified by\nanother with a different cultural background. The results reveal significant\ncorrelations between our cultural novelty metrics and established cultural\nmeasures based on linguistic, religious, and geographical distances. Our\nfindings highlight the potential of our framework to advance the understanding\nand measurement of cultural diversity in AI.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:52:52Z"}
{"aid":"http://arxiv.org/abs/2503.24038v1","title":"Giant counter-rotating oscillations on the attosecond timescale","summary":"We predict an unexplored type of ultrastrong coupling between atoms and\nintense ultraviolet light that leads to giant population oscillations on the\nattosecond timescale. These counter-rotating oscillations can be of similar\namplitude as the elementary femtosecond Rabi oscillations between the two\nstrongly coupled states. The effect, which is beyond the two-level atom, is\nnon-reciprocal: It only affects the excited state, while the ground state is\nunaffected. We propose that two-photon Rabi oscillations (1s$^2$-1s3d) in\nhelium is suitable for the generation of this type of ultrastrong coupling with\nrealistic pulses. We use a combination of Floquet theory and effective\nHamiltonian theory to test our predictions against ab initio simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24055v1","title":"Effective Dynamics and Blow Up in a Model of Magnetic Relaxation","summary":"In this article we study a one dimensional model for Magnetic Relaxation.\nThis model was introduced by Moffatt and describes a low resistivity viscous\nplasma, in which the pressure and the inercia are much smaller than the\nmagnetic pressure. In the limit of resistivity $\\varepsilon\\rightarrow 0$, we\nprove the existence of two time scales for the evolution of the magnetic field:\na fast one for times of order $\\log(\\varepsilon^{-1})$ in which the resistivity\nplays no role and the energy is dissipated only via viscosity; and a slow one\nfor times of order $\\varepsilon^{-1}$ characterized by the influence of the\nresistivity. We show that in this second time scale, as $\\varepsilon\\rightarrow\n0$, the modulus of magnetic field approaches a function that depends only on\ntime. We also prove that, in this regime, the magnetic field\n$b_\\varepsilon(t,x)$ can be approximated as $\\varepsilon \\rightarrow 0$ by the\nsolution of a PDE whose solutions exhibit blow up for some choices of initial\ndata.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,physics.plasm-ph","published":"2025-03-31T13:15:22Z"}
{"aid":"http://arxiv.org/abs/2503.24078v1","title":"A Complete Epistemic Temporal Logic for Intelligent Agent","summary":"In this paper, we present a complete epistemic temporal logic, called BPICTL,\nwhich generalizes CTL by introducing epistemic modalities. A sound and complete\ninference system of BPICTL is given. We prove the finite model property of\nBPICTL. Furthermore, we present a model checking algorithm for BPICTL.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T13:33:30Z"}
{"aid":"http://arxiv.org/abs/2503.24086v1","title":"Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale\n  Problems","summary":"This paper introduces a novel distributed optimization framework for\nlarge-scale AC Optimal Power Flow (OPF) problems, offering both theoretical\nconvergence guarantees and rapid convergence in practice. By integrating\nsmoothing techniques and the Schur complement, the proposed approach addresses\nthe scalability challenges and reduces communication overhead in distributed AC\nOPF. Additionally, optimal network decomposition enables efficient parallel\nprocessing under the single program multiple data (SPMD) paradigm. Extensive\nsimulations on large-scale benchmarks across various operating scenarios\nindicate that the proposed framework outperforms the state-of-the-art\ncentralized solver IPOPT on modest hardware. This paves the way for more\nscalable and efficient distributed optimization in future power system\napplications.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T13:40:12Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24157v1","title":"LLM4FS: Leveraging Large Language Models for Feature Selection and How\n  to Improve It","summary":"Recent advances in large language models (LLMs) have provided new\nopportunities for decision-making, particularly in the task of automated\nfeature selection. In this paper, we first comprehensively evaluate LLM-based\nfeature selection methods, covering the state-of-the-art DeepSeek-R1,\nGPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called\nLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,\ninput data samples into LLMs, and directly call traditional data-driven\ntechniques such as random forest and forward sequential selection. Notably, our\nanalysis reveals that the hybrid strategy leverages the contextual\nunderstanding of LLMs and the high statistical reliability of traditional\ndata-driven methods to achieve excellent feature selection performance, even\nsurpassing LLMs and traditional data-driven methods. Finally, we point out the\nlimitations of its application in decision-making.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:40:31Z"}
{"aid":"http://arxiv.org/abs/2503.24171v1","title":"Hamiltonian Dynamics Learning: A Scalable Approach to Quantum Process\n  Characterization","summary":"Quantum process characterization is a fundamental task in quantum information\nprocessing, yet conventional methods, such as quantum process tomography,\nrequire prohibitive resources and lack scalability. Here, we introduce an\nefficient quantum process learning method specifically designed for short-time\nHamiltonian dynamics. Our approach reconstructs an equivalent quantum circuit\nrepresentation from measurement data of unknown Hamiltonian evolution without\nrequiring additional assumptions and achieves polynomial sample and\ncomputational efficiency. Our results have broad applications in various\ndirections. We demonstrate applications in quantum machine learning, where our\nprotocol enables efficient training of variational quantum neural networks by\ndirectly learning unitary transformations. Additionally, it facilitates the\nprediction of quantum expectation values with provable efficiency and provides\na robust framework for verifying quantum computations and benchmarking\nrealistic noisy quantum hardware. This work establishes a new theoretical\nfoundation for practical quantum dynamics learning, paving the way for scalable\nquantum process characterization in both near-term and fault-tolerant quantum\ncomputing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T14:50:00Z"}
{"aid":"http://arxiv.org/abs/2503.24196v1","title":"Fermilab's Transition to Token Authentication","summary":"Fermilab is the first High Energy Physics institution to transition from\nX.509 user certificates to authentication tokens in production systems. All the\nexperiments that Fermilab hosts are now using JSON Web Token (JWT) access\ntokens in their grid jobs. Many software components have been either updated or\ncreated for this transition, and most of the software is available to others as\nopen source. The tokens are defined using the WLCG Common JWT Profile. Token\nattributes for all the tokens are stored in the Fermilab FERRY system which\ngenerates the configuration for the CILogon token issuer. High security-value\nrefresh tokens are stored in Hashicorp Vault configured by htvault-config, and\nJWT access tokens are requested by the htgettoken client through its\nintegration with HTCondor. The Fermilab job submission system jobsub was\nredesigned to be a lightweight wrapper around HTCondor. The grid workload\nmanagement system GlideinWMS which is also based on HTCondor was updated to use\ntokens for pilot job submission. For automated job submissions a managed tokens\nservice was created to reduce duplication of effort and knowledge of how to\nsecurely keep tokens active. The existing Fermilab file transfer tool ifdh was\nupdated to work seamlessly with tokens, as well as the Fermilab POMS\n(Production Operations Management System) which is used to manage automatic job\nsubmission and the RCDS (Rapid Code Distribution System) which is used to\ndistribute analysis code via the CernVM FileSystem. The dCache storage system\nwas reconfigured to accept tokens for authentication in place of X.509 proxy\ncertificates. As some services and sites have not yet implemented token\nsupport, proxy certificates are still sent with jobs for backwards\ncompatibility, but some experiments are beginning to transition to stop using\nthem.","main_category":"cs.DC","categories":"cs.DC","published":"2025-03-31T15:14:29Z"}
{"aid":"http://arxiv.org/abs/2503.24210v1","title":"DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D\n  Gaussian Splatting","summary":"Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-03-31T15:27:07Z"}
{"aid":"http://arxiv.org/abs/2503.24224v1","title":"Simplified Cofactor Conditions for Cubic to Tetragonal, Orthorhombic,\n  and Monoclinic Phase Transformations","summary":"Cofactor Conditions (CCs) are geometric compatibility conditions\nmathematically derived from the crystallographic theory of martensitic phase\ntransformation. The CCs guarantee compatible interfaces between the austenite\nand the parallelled twin of the martensite with any volume fraction, yielding a\nwide range of microstructures during phase transformation. In recent times, CCs\nhave demonstrated tremendous applications in the rational design of low\nhysteresis/fatigue shape memory alloys and shape memory ceramics. In this\npaper, we present a simplified form of the CCs for Type I/II twins using the\neigenspace of transformation stretch tensor and twin axes. We further show the\nexplicit forms and visualizations of the simplified CCs for Cubic to\nTetragonal, Cubic to Orthorhombic, and Cubic to Monoclinic I/II phase\ntransformations. The simplified form has revealed a more straightforward\ncorrelation between the lattice parameters and the CCs, and thus provides a\nmore convenient tool for the rational design of phase-transforming materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T15:38:23Z"}
{"aid":"http://arxiv.org/abs/2503.24234v1","title":"Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear\n  Inverse Modeling","summary":"The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T15:46:06Z"}
{"aid":"http://arxiv.org/abs/2503.24235v1","title":"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large\n  Language Models","summary":"As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T15:46:15Z"}
{"aid":"http://arxiv.org/abs/2503.24247v1","title":"Unitary and non-unitary operators leverage perfect and imperfect single\n  qutrit teleportation","summary":"Teleportation, a novel scheme, initially posited by Bennett \\textit{et.al},\nhas been studied here in the context of sending a single qutrit from Alice to\nBob using two qutrit entangled channels as resources. In this paper we have\nconsidered two special two qutrit entangled states, which belong to $SU(3)$\ngroup, as useful resources for teleportation. For the successful teleportation,\nthese entangled states have been chosen as quantum channels shared between\nAlice and Bob. Another entangled basis of two qutrit states have been used as\nauxiliary states, which would help Alice to manipulate with her channel so that\nthe single qutrit she holds can be successfully teleported to Bob. Bob's\nchoices of measurement operators influence the retrieval of Alice's single\nqutrit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2503.24263v1","title":"The Physics of Conformal Cyclic Cosmology","summary":"According to conformal cyclic cosmology (CCC), the currently conventional\ndescription of the entire history of the universe (but without an initial\ninflationary phase) provides but one cosmic aeon of an unending sequence of\nsuch aeons, where the future conformal infinity of each aeon joins essentially\nsmoothly to the conformally stretched big bang of the next, across a spacelike\n3-surface, referred to as a crossover 3-surface. Whereas in previous accounts\nof CCC a detailed description of the physics of crossover had been somewhat\nproblematic, a novel idea is introduced here to show how crossover takes place\nnaturally during a temporal period of the universe that is dominated by\ngravitational waves referred to here as a gravitational wave epoch (GWE).\nAccordingly, the geometry at the crossover surface is conformally smooth,\nexcept at a discrete set of points, referred to as Hawking points, each\nrepresenting the final Hawking evaporation of the dominant black hole of a\ngalactic cluster in the earlier aeon. It is shown here (using 2-spinor and\ntwistor techniques) that there is a mass-energy conservation law that holds\nacross the crossover surface, showing that the rise of temperature within such\nHawking spots should be effectively determined by the total mass of the\npre-crossover galactic cluster involved. This rise of temperature on the CMB\nmap within Hawking spots is found to be in quantitative agreement with the\nmasses of the largest galactic clusters observed in our own aeon what suggests\nthat the physics in the previous aeon was, at least in the gravitational\nsector, similar to ours. A second observational feature, the actual angular\ndiameter of the Hawking spots seen in our CMB, which is about twice what should\nhave been expected, is associated to the presence of GWE just after the\ncrossover and before the start of the usual cosmological epochs.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T16:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.24264v1","title":"Extended signatures and link concordance","summary":"The Levine-Tristram signature admits an n-variable extension for n-component\nlinks: it was first defined as an integer valued function on\n$(S^1\\setminus\\{1\\})^n$, and recently extended to the full torus $T^n$. The aim\nof the present article is to study and use this extended signature. First, we\nshow that it is constant on the connected components of the complement of the\nzero-locus of some renormalized Alexander polynomial. Then, we prove that the\nextended signature is a concordance invariant on an explicit dense subset of\n$T^n$. Finally, as an application, we present an infinite family of 3-component\nlinks with the following property: these links are not concordant to their\nmirror image, a fact that can be detected neither by the non-extended\nsignatures, nor by the multivariable Alexander polynomial, nor by the Milnor\ntriple linking number.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T16:10:21Z"}
{"aid":"http://arxiv.org/abs/2503.24267v1","title":"FakeScope: Large Multimodal Expert Model for Transparent AI-Generated\n  Image Forensics","summary":"The rapid and unrestrained advancement of generative artificial intelligence\n(AI) presents a double-edged sword: while enabling unprecedented creativity, it\nalso facilitates the generation of highly convincing deceptive content,\nundermining societal trust. As image generation techniques become increasingly\nsophisticated, detecting synthetic images is no longer just a binary task: it\nnecessitates interpretable, context-aware methodologies that enhance\ntrustworthiness and transparency. However, existing detection models primarily\nfocus on classification, offering limited explanatory insights into image\nauthenticity. In this work, we propose FakeScope, an expert multimodal model\n(LMM) tailored for AI-generated image forensics, which not only identifies\nAI-synthetic images with high accuracy but also provides rich, interpretable,\nand query-driven forensic insights. We first construct FakeChain dataset that\ncontains linguistic authenticity reasoning based on visual trace evidence,\ndeveloped through a novel human-machine collaborative framework. Building upon\nit, we further present FakeInstruct, the largest multimodal instruction tuning\ndataset containing 2 million visual instructions tailored to enhance forensic\nawareness in LMMs. FakeScope achieves state-of-the-art performance in both\nclosed-ended and open-ended forensic scenarios. It can distinguish synthetic\nimages with high accuracy while offering coherent and insightful explanations,\nfree-form discussions on fine-grained forgery attributes, and actionable\nenhancement strategies. Notably, despite being trained exclusively on\nqualitative hard labels, FakeScope demonstrates remarkable zero-shot\nquantitative capability on detection, enabled by our proposed token-based\nprobability estimation strategy. Furthermore, FakeScope exhibits strong\ngeneralization and in-the-wild ability, ensuring its applicability in\nreal-world scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:12:48Z"}
{"aid":"http://arxiv.org/abs/2503.24271v1","title":"Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion\n  Model Approach","summary":"The spatial properties of the solar magnetic field are crucial to decoding\nthe physical processes in the solar interior and their interplanetary effects.\nHowever, observations from older instruments, such as the Michelson Doppler\nImager (MDI), have limited spatial or temporal resolution, which hinders the\nability to study small-scale solar features in detail. Super resolving these\nolder datasets is essential for uniform analysis across different solar cycles,\nenabling better characterization of solar flares, active regions, and magnetic\nnetwork dynamics. In this work, we introduce a novel diffusion model approach\nfor Super-Resolution and we apply it to MDI magnetograms to match the\nhigher-resolution capabilities of the Helioseismic and Magnetic Imager (HMI).\nBy training a Latent Diffusion Model (LDM) with residuals on downscaled HMI\ndata and fine-tuning it with paired MDI/HMI data, we can enhance the resolution\nof MDI observations from 2\"/pixel to 0.5\"/pixel. We evaluate the quality of the\nreconstructed images by means of classical metrics (e.g., PSNR, SSIM, FID and\nLPIPS) and we check if physical properties, such as the unsigned magnetic flux\nor the size of an active region, are preserved. We compare our model with\ndifferent variations of LDM and Denoising Diffusion Probabilistic models\n(DDPMs), but also with two deterministic architectures already used in the past\nfor performing the Super-Resolution task. Furthermore, we show with an analysis\nin the Fourier domain that the LDM with residuals can resolve features smaller\nthan 2\", and due to the probabilistic nature of the LDM, we can asses their\nreliability, in contrast with the deterministic models. Future studies aim to\nsuper-resolve the temporal scale of the solar MDI instrument so that we can\nalso have a better overview of the dynamics of the old events.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG","published":"2025-03-31T16:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.24326v1","title":"Self-Supervised Pretraining for Aerial Road Extraction","summary":"Deep neural networks for aerial image segmentation require large amounts of\nlabeled data, but high-quality aerial datasets with precise annotations are\nscarce and costly to produce. To address this limitation, we propose a\nself-supervised pretraining method that improves segmentation performance while\nreducing reliance on labeled data. Our approach uses inpainting-based\npretraining, where the model learns to reconstruct missing regions in aerial\nimages, capturing their inherent structure before being fine-tuned for road\nextraction. This method improves generalization, enhances robustness to domain\nshifts, and is invariant to model architecture and dataset choice. Experiments\nshow that our pretraining significantly boosts segmentation accuracy,\nespecially in low-data regimes, making it a scalable solution for aerial image\nanalysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2503.24328v1","title":"Contextual Preference Collaborative Measure Framework Based on Belief\n  System","summary":"To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-03-31T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24343v1","title":"Early time solution as an alternative to the late time evolving dark\n  energy with DESI DR2 BAO","summary":"Recently the Dark Energy Spectroscopic Instrument (DESI) provided constraints\non the expansion history from their Data Release 2 (DR2). The DESI baryon\nacoustic oscillation (BAO) measurements are well described by a flat\n$\\Lambda$CDM model, but the preferred parameters are in mild ($2.3\\sigma$)\ntension with those determined from the cosmic microwave background (CMB). The\nDESI collaboration has already explored a variety of solutions to this tension\nrelying on variations in the late-time evolution of dark energy. Here we test\nan alternative -- the introduction of an ``early dark energy'' (EDE) component.\nWe find that EDE models can alleviate the tension, though they lead to\ndifferences in other cosmological parameters that have observational\nimplications. Particularly the EDE models that fit the acoustic datasets prefer\nlower $\\Omega_m$, higher $H_0$, $n_s$ and $\\sigma_8$ in contrast to the\nlate-time solutions. We discuss the current status and near-future prospects\nfor distinguishing amongst these solutions.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-31T17:26:10Z"}
{"aid":"http://arxiv.org/abs/2503.24347v1","title":"Entanglement Distribution in Lossy Quantum Networks","summary":"Entanglement distribution is essential for unlocking the potential of\ndistributed quantum information processing. We consider an $N$-partite network\nwhere entanglement is distributed via a central source over lossy channels, and\nnetwork participants cooperate to establish entanglement between any two chosen\nparties under local operations and classical communication (LOCC) constraints.\nWe develop a general mathematical framework to assess the optimal average\nbipartite entanglement shared in a lossy distribution, and introduce a\ntractable lower bound by optimizing over a subset of single-parameter LOCC\ntransformations. Our results show that probabilistically extracting Bell pairs\nfrom W states is more advantageous than deterministically extracting them from\nGHZ-like states in lossy networks, with this advantage increasing with network\nsize. We further extend our analysis analytically, proving that W states remain\nmore effective in large-scale networks. These findings offer valuable insights\ninto the practical deployment of near-term networks, revealing a fundamental\ntrade-off between deterministic entanglement distribution protocols and\nloss-sensitive resources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:32:18Z"}
{"aid":"http://arxiv.org/abs/2503.24361v1","title":"Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic\n  Manipulation","summary":"Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-03-31T17:39:38Z"}
{"aid":"http://arxiv.org/abs/2503.24372v1","title":"A criterion on the free energy for log-Sobolev inequalities in\n  mean-field particle systems","summary":"For a class of mean-field particle systems, we formulate a criterion in terms\nof the free energy that implies uniform bounds on the log-Sobolev constant of\nthe associated Langevin dynamics. For certain double-well potentials with\nquadratic interaction, the criterion holds up to the critical temperature of\nthe model, and we also obtain precise asymptotics on the decay of the\nlog-Sobolev constant when approaching the critical point. The criterion also\napplies to ``diluted'' mean-field models defined on sufficiently dense,\npossibly random graphs. We further generalize the criterion to non-quadratic\ninteractions that admit a mode decomposition. The mode decomposition is\ndifferent from the scale decomposition of the Polchinski flow we used for\nshort-range spin systems.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24374v1","title":"ERUPT: Efficient Rendering with Unposed Patch Transformer","summary":"This work addresses the problem of novel view synthesis in diverse scenes\nfrom small collections of RGB images. We propose ERUPT (Efficient Rendering\nwith Unposed Patch Transformer) a state-of-the-art scene reconstruction model\ncapable of efficient scene rendering using unposed imagery. We introduce\npatch-based querying, in contrast to existing pixel-based queries, to reduce\nthe compute required to render a target view. This makes our model highly\nefficient both during training and at inference, capable of rendering at 600\nfps on commercial hardware. Notably, our model is designed to use a learned\nlatent camera pose which allows for training using unposed targets in datasets\nwith sparse or inaccurate ground truth camera pose. We show that our approach\ncan generalize on large real-world data and introduce a new benchmark dataset\n(MSVS-1M) for latent view synthesis using street-view imagery collected from\nMapillary. In contrast to NeRF and Gaussian Splatting, which require dense\nimagery and precise metadata, ERUPT can render novel views of arbitrary scenes\nwith as few as five unposed input images. ERUPT achieves better rendered image\nquality than current state-of-the-art methods for unposed image synthesis\ntasks, reduces labeled data requirements by ~95\\% and decreases computational\nrequirements by an order of magnitude, providing efficient novel view synthesis\nfor diverse real-world scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2503.24380v1","title":"The fundamental localization phases in quasiperiodic systems: A unified\n  framework and exact results","summary":"The disordered quantum systems host three types of quantum states, the\nextended, localized, and critical, which bring up various distinct fundamental\nphases, including the pure phases and coexisting ones with mobility edges. The\nquantum phases involving critical states are of particular importance, but are\nless understood compared with the other ones, and the different phases have\nbeen separately studied in different quasiperiodic models. Here we propose a\nunified framework based on a spinful quasiperiodic system which unifies the\nrealizations of all the fundamental Anderson phases, %with or without mobility\nedges, with the exact and universal results being obtained for these distinct\nphases. Through the duality transformation and renormalization group method, we\nshow that the pure phases are obtained when the (emergent) chiral symmetry\npreserves in the proposed spin-1/2 quasiperiodic model, which provides a\ncriteria for the emergence of the pure phases or the coexisting ones with\nmobility edges. Further, we uncover a new universal mechanism for the critical\nstates that the emergence of such states is protected by the generalized\nincommensurate matrix element zeros in the spinful quasiperiodic model, as a\nnovel generalization of the quasiperiodic hopping zeros in the spinless\nsystems. We also show with the Avila's global theory the criteria of exact\nsolvability for the present unified quasiperiodic system, with which we\nidentify several new quasiperiodic models derived from the spinful system\nhosting exactly solvable Anderson phases. In particular, we reach a single\nmodel that hosts all the seven fundamental phases of Anderson localization.\nFinally, an experimental scheme is proposed to realize these models using\nquasiperiodic optical Raman lattices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-03-31T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.01328v1","title":"Slow-Fast Architecture for Video Multi-Modal Large Language Models","summary":"Balancing temporal resolution and spatial detail under limited compute budget\nremains a key challenge for video-based multi-modal large language models\n(MLLMs). Existing methods typically compress video representations using\npredefined rules before feeding them into the LLM, resulting in irreversible\ninformation loss and often ignoring input instructions. To address this, we\npropose a novel slow-fast architecture that naturally circumvents this\ntrade-off, enabling the use of more input frames while preserving spatial\ndetails. Inspired by how humans first skim a video before focusing on relevant\nparts, our slow-fast design employs a dual-token strategy: 1) \"fast\" visual\ntokens -- a compact set of compressed video features -- are fed into the LLM\nalongside text embeddings to provide a quick overview; 2) \"slow\" visual tokens\n-- uncompressed video features -- are cross-attended by text embeddings through\nspecially designed hybrid decoder layers, enabling instruction-aware extraction\nof relevant visual details with linear complexity. We conduct systematic\nexploration to optimize both the overall architecture and key components.\nExperiments show that our model significantly outperforms self-attention-only\nbaselines, extending the input capacity from 16 to 128 frames with just a 3%\nincrease in computation, and achieving a 16% average performance improvement\nacross five video understanding benchmarks. Our 7B model achieves\nstate-of-the-art performance among models of similar size. Furthermore, our\nslow-fast architecture is a plug-and-play design that can be integrated into\nother video MLLMs to improve efficiency and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T03:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.01338v1","title":"FlowMotion: Target-Predictive Flow Matching for Realistic Text-Driven\n  Human Motion Generation","summary":"Achieving highly diverse and perceptually consistent 3D character animations\nwith natural motion and low computational costs remains a challenge in computer\nanimation. Existing methods often struggle to provide the nuanced complexity of\nhuman movement, resulting in perceptual inconsistencies and motion artifacts.\nTo tackle these issues, we introduce FlowMotion, a novel approach that\nleverages Conditional Flow Matching (CFM) for improved motion synthesis.\nFlowMotion incorporates an innovative training objective that more accurately\npredicts target motion, reducing the inherent jitter associated with CFM while\nenhancing stability, realism, and computational efficiency in generating\nanimations. This direct prediction approach enhances the perceptual quality of\nanimations by reducing erratic motion and aligning the training more closely\nwith the dynamic characteristics of human movement. Our experimental results\ndemonstrate that FlowMotion achieves higher balance between motion smoothness\nand generalization capability while maintaining the computational efficiency\ninherent in flow matching compared to state-of-the-art methods.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T03:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.01340v1","title":"Local conformal symmetry and anomalies with antisymmetric tensor field","summary":"We consider the trace anomaly, which results from the integration of the\nmassless conformal fermion field with the background of metric and\nantisymmetric tensor fields. The non-local terms in the anomaly-induced\neffective action do not depend on the scheme of quantum calculations. On the\nother hand, total derivative terms in the anomaly and the corresponding local\npart of the induced action manifest scheme dependence and multiplicative\nanomaly.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-02T04:10:12Z"}
{"aid":"http://arxiv.org/abs/2504.01363v1","title":"Embedding Higman-Thompson groups of unfolding trees into the Leavitt\n  path algebras","summary":"The isomorphism problem of regular Higman-Thompson groups was solved in\narXiv:1006.1759, via embedding it into the Leavitt algebra. In this paper, we\nwill expand these results to embed the Higman-Thompson groups of unfolding\ntrees of directed graphs into the Leavitt path algebra. This embedding allows\nus to show that any isomorphism of rooted Leavitt path algebras induces an\nisomorphism between Higman-Thompson groups.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-02T05:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.01383v1","title":"v-CLR: View-Consistent Learning for Open-World Instance Segmentation","summary":"In this paper, we address the challenging problem of open-world instance\nsegmentation. Existing works have shown that vanilla visual networks are biased\ntoward learning appearance information, \\eg texture, to recognize objects. This\nimplicit bias causes the model to fail in detecting novel objects with unseen\ntextures in the open-world setting. To address this challenge, we propose a\nlearning framework, called view-Consistent LeaRning (v-CLR), which aims to\nenforce the model to learn appearance-invariant representations for robust\ninstance segmentation. In v-CLR, we first introduce additional views for each\nimage, where the texture undergoes significant alterations while preserving the\nimage's underlying structure. We then encourage the model to learn the\nappearance-invariant representation by enforcing the consistency between object\nfeatures across different views, for which we obtain class-agnostic object\nproposals using off-the-shelf unsupervised models that possess strong\nobject-awareness. These proposals enable cross-view object feature matching,\ngreatly reducing the appearance dependency while enhancing the\nobject-awareness. We thoroughly evaluate our method on public benchmarks under\nboth cross-class and cross-dataset settings, achieving state-of-the-art\nperformance. Project page: https://visual-ai.github.io/vclr","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:52:30Z"}
{"aid":"http://arxiv.org/abs/2504.01398v1","title":"Cause or Trigger? From Philosophy to Causal Modeling","summary":"Not much has been written about the role of triggers in the literature on\ncausal reasoning, causal modeling, or philosophy. In this paper, we focus on\ndescribing triggers and causes in the metaphysical sense and on\ncharacterizations that differentiate them from each other. We carry out a\nphilosophical analysis of these differences. From this, we formulate a\ndefinition that clearly differentiates triggers from causes and can be used for\ncausal reasoning in natural sciences. We propose a mathematical model and the\nCause-Trigger algorithm, which, based on given data to observable processes, is\nable to determine whether a process is a cause or a trigger of an effect. The\npossibility to distinguish triggers from causes directly from data makes the\nalgorithm a useful tool in natural sciences using observational data, but also\nfor real-world scenarios. For example, knowing the processes that trigger\ncauses of a tropical storm could give politicians time to develop actions such\nas evacuation the population. Similarly, knowing the triggers of processes that\ncause global warming could help politicians focus on effective actions. We\ndemonstrate our algorithm on the climatological data of two recent cyclones,\nFreddy and Zazu. The Cause-Trigger algorithm detects processes that trigger\nhigh wind speed in both storms during their cyclogenesis. The findings obtained\nagree with expert knowledge.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-02T06:37:48Z"}
{"aid":"http://arxiv.org/abs/2504.01410v1","title":"The Interstellar Medium","summary":"The interstellar medium (ISM) is the material that fills the space between\nthe stars in all galaxies; it is a multi-phase medium in pressure equilibrium,\nwith densities and temperatures covering over 6 orders of magnitude. Although\naccounting for only a small fraction of the mass of any given galaxy, it is a\nvital component, since it holds the material responsible for galaxy growth\nthrough star formation. Studying the ISM requires careful observations at all\nwavelengths of the electromagnetic spectrum. This article describes the\nmulti-phase nature of the ISM, and then puts it in the context of galaxy\nevolution models, emphasising the importance of the cycling of baryons in and\nout of galaxies. Within this framework, the ISM plays a central role: it\nconnects the physical processes operating on very large physical- and\ntime-scales which control the accretion of gas onto galaxies, and the small\nscale processes that regulate star formation.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T06:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01425v1","title":"Asymptotic stability and exponential stability for a class of impulsive\n  neutral differential equations with discrete and distributed delays","summary":"In this paper, we present sufficient conditions for asymptotic stability and\nexponential stability of a class of impulsive neutral differential equations\nwith discrete and distributed delays. Our approaches are based on the method\nusing fixed point theory, which do not resort to any Lyapunov functions or\nLyapunov functionals. Our conditions do not require the differentiability of\ndelays, nor do they ask for a fixed sign on the coefficient functions. Our\nresults improve some previous ones in the literature. Examples are given to\nillustrate our main results.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T07:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01448v1","title":"LLM-VPRF: Large Language Model Based Vector Pseudo Relevance Feedback","summary":"Vector Pseudo Relevance Feedback (VPRF) has shown promising results in\nimproving BERT-based dense retrieval systems through iterative refinement of\nquery representations. This paper investigates the generalizability of VPRF to\nLarge Language Model (LLM) based dense retrievers. We introduce LLM-VPRF and\nevaluate its effectiveness across multiple benchmark datasets, analyzing how\ndifferent LLMs impact the feedback mechanism. Our results demonstrate that\nVPRF's benefits successfully extend to LLM architectures, establishing it as a\nrobust technique for enhancing dense retrieval performance regardless of the\nunderlying models. This work bridges the gap between VPRF with traditional\nBERT-based dense retrievers and modern LLMs, while providing insights into\ntheir future directions.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-02T08:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01453v1","title":"Tinnitus, lucid dreaming and awakening. An online survey and theoretical\n  implications","summary":"(1) Background: Tinnitus is the perception of phantom sound in the absence of\na corresponding external source. Previous studies reported that the presence of\ntinnitus is notably absent during dreams. This study aimed at replicating\nprevious findings regarding tinnitus-free dreams, while also gaining a deeper\nunderstanding of tinnitus manifestations during dreams and after awakening. (2)\nMethods: For this observational study, 195 tinnitus patients answered an online\nsurvey on the mutual-help community Siopi. (3) Results: 160 patients could\nrecall their dreams. Among them, 92.5% state they do not hear their tinnitus\nwhile dreaming. The rest (7.5%) report higher tinnitus burden, higher stress\nand more often exhibit objective tinnitus and/or tinnitus related to peripheral\nauditory pathology and/or drug intake. 13% of the participants frequently\nexperience lucid dreams. Among them, 36% could perceive their tinnitus during\nlucid dreams, and this was strongly associated with the concomitant perception\nof external sounds during lucid dreaming. While the majority of patients report\nperceiving their tinnitus instantly upon awakening, during nocturnal\nawakenings, 18% declared they could be awakened by their tinnitus and 9.8%\nmentioned that their tinnitus can temporarily cease. (4) Conclusions: Our\nfindings confirm the previous findings: tinnitus is rarely perceived during\ndreams. Remarkably, our study is the first to document the case of tinnitus\nduring lucid dreaming. 64% of these patients gain higher-order consciousness\nattributes while still experiencing a tinnitus-free state. Our observations\nsuggest that the presence or absence of gating of external auditory information\nduring dreams acts as a tinnitus on-off switch, refining the previously\nproposed integrative model of auditory phantom perception.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-02T08:06:00Z"}
{"aid":"http://arxiv.org/abs/2504.01476v1","title":"Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction","summary":"Cross-modal 3D retrieval is a critical yet challenging task, aiming to\nachieve bi-directional retrieval between 3D and text modalities. Current\nmethods predominantly rely on a certain 3D representation (e.g., point cloud),\nwith few exploiting the 2D-3D consistency and complementary relationships,\nwhich constrains their performance. To bridge this gap, we propose to adopt\nmulti-view images and point clouds to jointly represent 3D shapes, facilitating\ntri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3D\nretrieval. Notably, we introduce tri-modal reconstruction to improve the\ngeneralization ability of encoders. Given point features, we reconstruct image\nfeatures under the guidance of text features, and vice versa. With well-aligned\npoint cloud and multi-view image features, we aggregate them as multimodal\nembeddings through fine-grained 2D-3D fusion to enhance geometric and semantic\nunderstanding. Recognizing the significant noise in current datasets where many\n3D shapes and texts share similar semantics, we employ hard negative\ncontrastive training to emphasize harder negatives with greater significance,\nleading to robust discriminative embeddings. Extensive experiments on the\nText2Shape dataset demonstrate that our method significantly outperforms\nprevious state-of-the-art methods in both shape-to-text and text-to-shape\nretrieval tasks by a substantial margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.01535v1","title":"On Robust Empirical Likelihood for Nonparametric Regression with\n  Application to Regression Discontinuity Designs","summary":"Empirical likelihood serves as a powerful tool for constructing confidence\nintervals in nonparametric regression and regression discontinuity designs\n(RDD). The original empirical likelihood framework can be naturally extended to\nthese settings using local linear smoothers, with Wilks' theorem holding only\nwhen an undersmoothed bandwidth is selected. However, the generalization of\nbias-corrected versions of empirical likelihood under more realistic conditions\nis non-trivial and has remained an open challenge in the literature. This paper\nprovides a satisfactory solution by proposing a novel approach, referred to as\nrobust empirical likelihood, designed for nonparametric regression and RDD. The\ncore idea is to construct robust weights which simultaneously achieve bias\ncorrection and account for the additional variability introduced by the\nestimated bias, thereby enabling valid confidence interval construction without\nextra estimation steps involved. We demonstrate that the Wilks' phenomenon\nstill holds under weaker conditions in nonparametric regression, sharp and\nfuzzy RDD settings. Extensive simulation studies confirm the effectiveness of\nour proposed approach, showing superior performance over existing methods in\nterms of coverage probabilities and interval lengths. Moreover, the proposed\nprocedure exhibits robustness to bandwidth selection, making it a flexible and\nreliable tool for empirical analyses. The practical usefulness is further\nillustrated through applications to two real datasets.","main_category":"math.ST","categories":"math.ST,econ.EM,stat.ME,stat.TH","published":"2025-04-02T09:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01541v1","title":"Hyperbolic Diffusion Recommender Model","summary":"Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-02T09:27:40Z"}
{"aid":"http://arxiv.org/abs/2504.01546v1","title":"From indirect to direct taxis by fast reaction limit","summary":"Many ecological population models consider taxis as the directed movement of\nanimals in response to a stimulus. The taxis is named direct if the animals are\nguided by the density gradient of some other population or indirect if they are\nguided by the density of a chemical secreted by individuals of the other\npopulation. Let $u$ and $v$ denote the densities of two populations and $w$ the\ndensity of the chemical secreted by individuals in the $v$ population. We\nconsider a bounded, open set $\\Omega \\subset \\mathbb{R}^N$ with regular\nboundary and prove that for the space dimension $N\\leq 2$ the solution to the\nLotka-Volterra competition model with repulsive indirect taxis and homogeneous\nNeumann boundary conditions\n  $$u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla w +\\mu_1u(1-u-a_1v)\\,,$$\n  $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,,$$\n  $$\\varepsilon ( w_t - d_w\\Delta w )= v- w\\, , $$ converges to the solution of\nrepulsive direct-taxis model: $$ u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla\nv +\\mu_1u(1-u-a_1v)\\,,$$ $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,$$ when\n$\\varepsilon\\longrightarrow 0$. For space dimension $N\\geq 3$ we use the\ncompactness argument to show that the result holds in some weak sense. A\nsimilar result is also proved for a typical prey-predator model with prey taxis\nand logistic growth of predators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.01558v1","title":"Scalable Equivalence Checking and Verification of Shallow Quantum\n  Circuits","summary":"This paper concerns the problem of checking if two shallow (i.e.,\nconstant-depth) quantum circuits perform equivalent computations. Equivalence\nchecking is a fundamental correctness question -- needed, e.g., for ensuring\nthat transformations applied to a quantum circuit do not alter its behavior.\nFor quantum circuits, the problem is challenging because a straightforward\nrepresentation on a classical computer of each circuit's quantum state can\nrequire time and space that are exponential in the number of qubits $n$.\n  The paper presents decision procedures for two variants of the\nequivalence-checking problem. Both can be carried out on a classical computer\nin time and space that, for any fixed depth, is linear in $n$. Our critical\ninsight is that local projections are precise enough to completely characterize\nthe output state of a shallow quantum circuit. Instead of explicitly computing\nthe output state of a circuit, we generate a set of local projections that\nserve as constraints on the output state. Moreover, the circuit's output state\nis the unique quantum state that satisfies all the constraints.\n  Beyond equivalence checking, we show how to use the constraint representation\nto check a class of assertions, both statically and at run time. Our\nassertion-checking methods are sound and complete for assertions expressed as\nconjunctions of local projections.\n  Our experiments show that on a server equipped with 2 x\nIntel\\textsuperscript{\\textregistered} Xeon\\textsuperscript{\\textregistered}\nGold 6338 CPUs (128 threads total) and 1.0~TiB of RAM, running Ubuntu 20.04.6\nLTS, the constraint representation of a random 100-qubit circuit of depth 6 can\nbe computed in 19.8 seconds. For fixed inputs $\\ket{0}^{\\otimes 100}$,\nequivalence checking of {random} 100-qubit circuits of depth 3 takes 4.46\nseconds; for arbitrary inputs, it takes no more than 31.96 seconds.","main_category":"quant-ph","categories":"quant-ph,cs.PL","published":"2025-04-02T09:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.01571v1","title":"Pro-DG: Procedural Diffusion Guidance for Architectural Facade\n  Generation","summary":"We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG","published":"2025-04-02T10:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.01595v1","title":"JWST MIRI reveals the diversity of nuclear mid-infrared spectra of\n  nearby type-2 quasars","summary":"Type-2 quasars (QSO2s) are active galactic nuclei (AGN) seen through a\nsignificant amount of dust and gas that obscures the central supermassive black\nhole and the broad line region. Here we present new mid-infrared spectra of the\ncentral kiloparsec of five optically-selected QSO2s at redshift z~0.1 obtained\nwith JWST/MIRI/MRS. These QSO2s belong to the QSOFEED sample and they have log\nLbol=45.5-46.0 erg/s, global SFRs that place them above the main sequence, and\npractically identical optical spectral shape and [OIII] luminosity, but their\nnuclear mid-infrared spectra exhibit an unexpected diversity of both continua\nand features. They show: 1) 9.7 micron silicate features going from emission\n(strength of S9.7=0.5) to relatively strong absorption (S9.7=-1.0) and 18 and\n23 micron silicates either in emission or flat. In addition, two of the QSO2s\nshow absorption bands of CO, H2O, and aliphatic grains, indicating different\nlevels of nuclear obscuration across the sample. 2) [NeV]/[NeII] ratios ranging\nfrom 0.1 to 2.1 and [NeIII]/[NeII] from 1.0 to 3.5, indicating different\ncoronal line and ionizing continuum strengths. 3) Warm molecular gas masses of\n1-4x10^7 Msun and warm-to-cold gas mass ratios of 1-2%, with molecular gas\nexcitation likely due to jet-induced shocks in J1430+1339, and to UV heating\nand/or turbulence in J1509+0434. 4) PAH emission features with equivalent\nwidths ranging from <0.002 to 0.075 micron, from which we measure a larger\ncontribution from neutral molecules (PAH 11.3/6.2=1.3-3.4) and SFRs<3-7\nMsun/yr. This unprecedented dataset allowed us to start exploring the role of\nvarious AGN and galaxy properties including ionizing continuum, obscuration,\nelectron density, and jet-ISM interactions on some of the spectral differences\nlisted above, but larger samples are now required to fully understand the\ndiversity of QSO2s' nuclear mid-infrared spectra.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T11:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01606v1","title":"Vers une modÃ©lisation de la confiance dans le renseignement sur les\n  menaces cyber","summary":"Cyber threat intelligence (CTI) is essential for effective system defense.\nCTI is a collection of information about current or past threats to a computer\nsystem. This information is gathered by an agent through observation, or based\non a set of sources. Building intelligence only makes sense if you have\nconfidence in it. To achieve this, it is necessary to estimate the confidence\nin each piece of information gathered, taking into account the different\ndimensions that can make it up: reliability of the source, competence,\nplausibility of the information, credibility of the information, for example.\nThe information gathered must then be combined with other information to\nconsolidate an agent's knowledge. Recent advances have been made in the theory\nunderlying the modeling of trust for decision-making based on uncertain\ninformation, notably by using multivalued logic. This approach makes it\npossible to deal with unknown values of trust-building parameters, or to easily\nintegrate dimensions. In this article we present the problem of CTI and CTI\ninformation sharing, and the reasons that led us to use a logic-based solution\nfor an initial implementation.","main_category":"cs.CR","categories":"cs.CR,cs.LO","published":"2025-04-02T11:17:26Z"}
{"aid":"http://arxiv.org/abs/2504.01630v1","title":"On the performance of the Euler-Maruyama scheme for multidimensional\n  SDEs with discontinuous drift coefficient","summary":"We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-02T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.01635v1","title":"Control of Andreev Reflection via a Single-Molecule Orbital","summary":"Charge transport across a single-molecule junction fabricated from a\nnormal-metal tip, a phthalocyanine, and a conventional superconductor in a\nscanning tunneling microscope is explored as a function of the gradually closed\nvacuum gap. The phthalocyanine (2H-Pc) molecule and its\npyrrolichydrogen-abstracted derivative (Pc) exhibit vastly different behavior.\nAndreev reflection across the 2H-Pc contact exhibits a temporary enhancement\nthat diminishes with increasing conductance. The hybridization of 2H-Pc with\nthe tip at contact formation gives rise to a Kondo-screened molecular magnetic\nmoment. In contrast, the single-Pc junction lacks Andreev reflection in the\nsame conductance range. Spectroscopies and supporting nonequilibrium Green\nfunction calculations highlight the importance of a molecular orbital close to\nthe Fermi energy for Andreev reflection.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-02T11:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.01636v1","title":"Dataset and Methodology for Material Identification and virtual s-SNOM\n  Using AFM Phase Approach Curves","summary":"Atomic force microscopy (AFM) phase approach-curves have significant\npotential for nanoscale material characterization, however, the availability of\nrobust datasets and automated analysis tools has been limited. In this paper,\nwe introduce a novel methodology for material identification using a\nhigh-dimensional dataset consisting of AFM phase approach-curves collected from\nfive distinct materials: silicon, silicon dioxide, platinum, silver, and gold.\nEach measurement comprises 50 phase values obtained at progressively increasing\ntip-sample distances, resulting in 50x50x50 voxel images that represent phase\nvariations at different depths. Using this dataset, we compare k-nearest\nneighbors (KNN), random forest (RF), and feedforward neural network (FNN)\nmethods for material segmentation. Our results indicate that the FNN provides\nthe highest accuracy and F1 score, outperforming more traditional approaches.\nFinally, we demonstrate the practical value of these segmented maps by\ngenerating virtual scattering-type scanning near-field optical microscopy\n(s-SNOM) images, highlighting how AFM phase approach-curves can be leveraged to\nproduce detailed, predictive tools for nanoscale optical analysis.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:42:03Z"}
{"aid":"http://arxiv.org/abs/2504.01645v1","title":"How to write competitive proposals and job applications","summary":"Writing proposals and job applications is arguably one of the most important\ntasks in the career of a scientist. The proposed ideas must be scientifically\ncompelling, but how a proposal is planned, written, and presented can make an\nenormous difference. This Perspective is the third in a series aimed at\ntraining the writing skills of professional astronomers. In the first two\npapers we concentrated on the writing of papers, here we concentrate on how\nproposals and job applications can be optimally written and presented. We\ndiscuss how to select where to propose or apply, how to optimise your writing,\nand add notes on the potential use of artificial intelligence tools. This guide\nis aimed primarily at more junior researchers, but we hope that our\nobservations and suggestions may also be helpful for more experienced\napplicants, as well as for reviewers and funding agencies.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ed-ph","published":"2025-04-02T11:53:45Z"}
{"aid":"http://arxiv.org/abs/2504.01651v1","title":"Nonlinear electrodynamic black holes and their role in testing modified\n  theories of gravity","summary":"The nature of black holes (BHs) and potential deviations from General\nRelativity (GR) remain key questions in astrophysics. Nonlinear electrodynamics\n(NED) offers a mechanism for constructing regular BHs that evade singularities.\nWe perform a geometrical and observational analysis of NED-inspired BHs,\nconstraining the magnetic parameter via Bayesian inference using EHT data,\nobtaining \\( q = 0.98^{+0.09}_{-0.08} \\) for M87* and \\( q = 1.10\\pm0.10 \\) for\nSgr A*. Deviations from Schwarzschild BHs manifest in horizon structure, shadow\nproperties, and lensing effects. We analyze BH shadows under plasma conditions,\nidentifying imprints of NED on strong-field processes. Future observations from\nLISA, next-generation X-ray telescopes, and EHT will further constrain these\ndeviations and provide tests for alternative gravity theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T12:00:35Z"}
{"aid":"http://arxiv.org/abs/2504.01667v1","title":"Testing Low-Resource Language Support in LLMs Using Language Proficiency\n  Exams: the Case of Luxembourgish","summary":"Large Language Models (LLMs) have become an increasingly important tool in\nresearch and society at large. While LLMs are regularly used all over the world\nby experts and lay-people alike, they are predominantly developed with\nEnglish-speaking users in mind, performing well in English and other\nwide-spread languages while less-resourced languages such as Luxembourgish are\nseen as a lower priority. This lack of attention is also reflected in the\nsparsity of available evaluation tools and datasets. In this study, we\ninvestigate the viability of language proficiency exams as such evaluation\ntools for the Luxembourgish language. We find that large models such as\nChatGPT, Claude and DeepSeek-R1 typically achieve high scores, while smaller\nmodels show weak performances. We also find that the performances in such\nlanguage exams can be used to predict performances in other NLP tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T12:16:14Z"}
{"aid":"http://arxiv.org/abs/2504.01670v1","title":"Introduction to dimensional reduction of fermions","summary":"We present a comprehensive pedagogical introduction to the dimensional\nreduction protocol (DRP), a versatile framework for analyzing instabilities and\ncritical points in interacting fermionic systems. The DRP simplifies the study\nof many-body problems by systematically reducing their effective spatial\ndimension while retaining essential physics. This method works for electron\ngases in a diverse array of settings: in any number of spatial dimensions, in\nthe presence of Zeeman fields, with spin-orbit coupling, including repulsive or\nattractive interactions. Focusing on two-point correlation functions, the DRP\nidentifies a minimal subspace relevant for capturing analytic properties,\nfacilitating efficient computation of critical phenomena in electronic systems.\nThis work outlines the assumptions, proof, and applications of the DRP,\nemphasizing its simplicity and broad applicability for future studies in\ncorrelated electron physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T12:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.01689v1","title":"InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse\n  Problems","summary":"Diffusion Models have demonstrated remarkable capabilities in handling\ninverse problems, offering high-quality posterior-sampling-based solutions.\nDespite significant advances, a fundamental trade-off persists, regarding the\nway the conditioned synthesis is employed: Training-based methods achieve high\nquality results, while zero-shot approaches trade this with flexibility. This\nwork introduces a framework that combines the best of both worlds -- the strong\nperformance of supervised approaches and the flexibility of zero-shot methods.\nThis is achieved through a novel architectural design that seamlessly\nintegrates the degradation operator directly into the denoiser. In each block,\nour proposed architecture applies the degradation operator on the network\nactivations and conditions the output using the attention mechanism, enabling\nadaptation to diverse degradation scenarios while maintaining high performance.\nOur work demonstrates the versatility of the proposed architecture, operating\nas a general MMSE estimator, a posterior sampler, or a Neural Posterior\nPrincipal Component estimator. This flexibility enables a wide range of\ndownstream tasks, highlighting the broad applicability of our framework. The\nproposed modification of the denoiser network offers a versatile, accurate, and\ncomputationally efficient solution, demonstrating the advantages of dedicated\nnetwork architectures for complex inverse problems. Experimental results on the\nFFHQ and ImageNet datasets demonstrate state-of-the-art posterior-sampling\nperformance, surpassing both training-based and zero-shot alternatives.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01741v1","title":"Quantum Quintom Cosmology","summary":"This work applies the principles of quantum cosmology to examine models\nincorporating a quintom field. Specifically, three distinct models are\nanalyzed: a simplified toy model, a model featuring an exponential quintom\npotential, and one where the quintom field is coupled with a negative\ncosmological constant. For each case, we study the classical trajectories\nwithin the configuration space, present solutions to the Wheeler-DeWitt\nequation in quantum cosmology, and discuss physical interpretations and\nconsequences. A key focus is the behavior of wave packets in the minisuperspace\nframework. Notably, the correspondence principle (connection between classical\nand quantum solutions) is also demonstrated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.01746v1","title":"Spans of quantum-inequality projections","summary":"A hereditarily atomic von Neumann algebra $A$ is a $W^*$ product of matrix\nalgebras, regarded as the underlying function algebra of a quantum set.\nProjections in $A\\overline{\\otimes}A^{\\circ}$ are interpreted as quantum binary\nrelations on $A$, with the supremum of all $p\\otimes (1-p)$ representing\nquantum inequality. We prove that the symmetrized weak$^*$-closed linear span\nof all such quantum-inequality projections is precisely the symmetric summand\nof the joint kernel of multiplication and opposite multiplication, a result\nvalid without the symmetrization qualification for plain matrix algebras. The\nproof exploits the symmetries of the spaces involved under the compact unitary\ngroup of $A$, and related results include a classification of those von Neumann\nalgebras (hereditarily atomic or not) for which the unitary group operates\njointly continuously with respect to the weak$^*$ topology.","main_category":"math.OA","categories":"math.OA,math.FA,math.QA,math.RA,math.RT","published":"2025-04-02T13:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.01750v1","title":"Probing the Distance Duality Relation with Machine Learning and Recent\n  Data","summary":"The distance duality relation (DDR) relates two independent ways of measuring\ncosmological distances, namely the angular diameter distance and the luminosity\ndistance. These can be measured with baryon acoustic oscillations (BAO) and\nType Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1,\nPantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We\nemploy a parametrised approach and also use model-independent Generic\nAlgorithms (GA), which are a machine learning method where functions evolve\nloosely based on biological evolution. When we use DESI and Pantheon+ data\nwithout Cepheid calibration or big bang nucleosynthesis (BBN), there is a\n$2\\sigma$ violation of the DDR in the parametrised approach. Then, we add\nhigh-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This\nreflects the Hubble tension since both data sets are in tension in the standard\ncosmological model $\\Lambda$CDM. In this case, we find a significant violation\nof the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe\nIa data by DES-SN5YR, we find similar results. For the model-independent\napproach, we find no deviation in the uncalibrated case and a small deviation\nwith BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of\nconsidering model-independent approaches for the DDR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T14:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.01755v1","title":"Bridge the Gap between SNN and ANN for Image Restoration","summary":"Models of dense prediction based on traditional Artificial Neural Networks\n(ANNs) require a lot of energy, especially for image restoration tasks.\nCurrently, neural networks based on the SNN (Spiking Neural Network) framework\nare beginning to make their mark in the field of image restoration, especially\nas they typically use less than 10\\% of the energy of ANNs with the same\narchitecture. However, training an SNN is much more expensive than training an\nANN, due to the use of the heuristic gradient descent strategy. In other words,\nthe process of SNN's potential membrane signal changing from sparse to dense is\nvery slow, which affects the convergence of the whole model.To tackle this\nproblem, we propose a novel distillation technique, called asymmetric framework\n(ANN-SNN) distillation, in which the teacher is an ANN and the student is an\nSNN. Specifically, we leverage the intermediate features (feature maps) learned\nby the ANN as hints to guide the training process of the SNN. This approach not\nonly accelerates the convergence of the SNN but also improves its final\nperformance, effectively bridging the gap between the efficiency of the SNN and\nthe superior learning capabilities of ANN. Extensive experimental results show\nthat our designed SNN-based image restoration model, which has only 1/300 the\nnumber of parameters of the teacher network and 1/50 the energy consumption of\nthe teacher network, is as good as the teacher network in some denoising tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:12:06Z"}
{"aid":"http://arxiv.org/abs/2504.01759v1","title":"Hidden Markov Model Filtering with Equal Exit Probabilities","summary":"Hidden Markov Models (HMMs) provide a rigorous framework for inference in\ndynamic environments. In this work, we study the alpha-HMM algorithm motivated\nby the optimal online filtering formulation in settings where the true state\nevolves as a Markov chain with equal exit probabilities. We quantify the\ndynamics of the algorithm in stationary environments, revealing a trade-off\nbetween inference and adaptation, showing how key parameters and the quality of\nobservations affect performance. Comprehensive theoretical analysis on the\nnonlinear dynamical system that governs the evolution of the log-belief ratio\nover time and numerical experiments demonstrate that the proposed approach\neffectively balances adaptation and inference performance.","main_category":"eess.SY","categories":"eess.SY,cs.SY,stat.AP","published":"2025-04-02T14:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.01761v1","title":"Non-parametric Quantile Regression and Uniform Inference with Unknown\n  Error Distribution","summary":"This paper studies the non-parametric estimation and uniform inference for\nthe conditional quantile regression function (CQRF) with covariates exposed to\nmeasurement errors. We consider the case that the distribution of the\nmeasurement error is unknown and allowed to be either ordinary or super smooth.\nWe estimate the density of the measurement error by the repeated measurements\nand propose the deconvolution kernel estimator for the CQRF. We derive the\nuniform Bahadur representation of the proposed estimator and construct the\nuniform confidence bands for the CQRF, uniformly in the sense for all\ncovariates and a set of quantile indices, and establish the theoretical\nvalidity of the proposed inference. A data-driven approach for selecting the\ntuning parameter is also included. Monte Carlo simulations and a real data\napplication demonstrate the usefulness of the proposed method.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-02T14:16:39Z"}
{"aid":"http://arxiv.org/abs/2504.01762v1","title":"A First-Order Linear Energy Stable Scheme for the Cahn-Hilliard Equation\n  with Dynamic Boundary Conditions under the Effect of Hyperbolic Relaxation","summary":"In this paper we focus on the Cahn-Hilliard equation with dynamic boundary\nconditions, by adding two hyperbolic relaxation terms to the system. We verify\nthat the energy of the total system is decreasing with time. By adding two\nstabilization terms, we have constructed a first-order temporal accuracy\nnumerical scheme, which is linear and energy stable. Then we prove that the\nscheme is of first-order in time by the error estimates. At last we carry out\nenough numerical results to validate the the temporal convergence and the\nenergy stability of such scheme. Moreover, we have present the differences of\nthe numerical results with and without the hyperbolic terms, which show that\nthe hyperbolic terms can help the total energy decreasing slowly.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T14:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.01763v1","title":"Fully-gapped superconductivity with rotational symmetry breaking in\n  pressurized kagome metal CsV$_3$Sb$_5$","summary":"The discovery of the kagome metal CsV$_3$Sb$_5$ has generated significant\ninterest in its complex physical properties, particularly its superconducting\nbehavior under different pressures, though its nature remains debated. Here, we\nperformed low-temperature, high-pressure $^{121/123}$Sb nuclear quadrupole\nresonance (NQR) measurements to explore the superconducting pairing symmetry in\nCsV$_3$Sb$_5$. At ambient pressure, we found that the spin-lattice relaxation\nrate 1/$T_1$ exhibits a kink at $T \\sim$ 0.4 $T_\\textrm{c}$ within the\nsuperconducting state and follows a $T^3$ variation as temperature further\ndecreases. This suggests the presence of two superconducting gaps with line\nnodes in the smaller one. As pressure increases beyond $P_{\\rm c} \\sim 1.85$\nGPa, where the charge-density wave phase is completely suppressed, 1/$T_1$\nshows no Hebel-Slichter peak just below $T_\\textrm{c}$, and decreases rapidly,\neven faster than $T^5$, indicating that the gap is fully opened for pressures\nabove $P_{\\rm c}$. In this high pressure region, the angular dependence of the\nin-plane upper critical magnetic field $H_{\\rm c2}$ breaks the $C_6$ rotational\nsymmetry. We propose the $s+id$ pairing at $P > P_{\\rm c}$ which explains both\nthe 1/$T_1$ and $H_{\\rm c2}$ behaviors. Our findings indicate that\nCsV$_3$Sb$_5$ is an unconventional superconductor and its superconducting state\nis even more exotic at high pressures.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-02T14:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.01764v1","title":"Dual-stream Transformer-GCN Model with Contextualized Representations\n  Learning for Monocular 3D Human Pose Estimation","summary":"This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.01770v1","title":"$\\mathbf{Î³^{(*)} + N(940)\\frac{1}{2}^+ \\to N(1520)\\frac{3}{2}^{-}}$\n  helicity amplitudes and transition form factors","summary":"We recently reported new results on the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+\n\\to \\Delta(1700)\\frac{3}{2}^{-}$ transition form factors using a\nsymmetry-preserving treatment of a vector$\\,\\otimes\\,$vector contact\ninteraction (SCI) within a coupled formalism based on the Dyson-Schwinger,\nBethe-Salpeter, and Faddeev equations. In this work, we extend our\ninvestigation to the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+ \\to\nN(1520)\\frac{3}{2}^{-}$ transition. Our computed transition form factors show\nreasonable agreement with experimental data at large photon virtualities.\nHowever, deviations emerge at low $Q^2$, where experimental results exhibit a\nsharper variation than theoretical predictions. This discrepancy is expected,\nas these continuum QCD analyses account only for the quark-core of baryons,\nwhile low photon virtualities are dominated by meson cloud effects. We\nanticipate that these analytical predictions, based on the simplified SCI\nframework, will serve as a valuable benchmark for more refined studies and\nQCD-based truncations that incorporate quark angular momentum and the\ncontributions of scalar and vector diquarks.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th,nucl-th","published":"2025-04-02T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.01780v1","title":"Finiteness and duality of cohomology of $(\\varphi,Î“)$-modules and\n  the 6-functor formalism of locally analytic representations","summary":"Finiteness and duality of cohomology of families of\n$(\\varphi,\\Gamma)$-modules were proved by Kedlaya-Pottharst-Xiao. In this\npaper, we study solid locally analytic representations introduced by Rodrigues\nJacinto-Rodr\\'iguez Camargo in terms of analytic stacks and 6-functor\nformalisms, which are developed by Clausen-Scholze, Heyer-Mann, respectively.\nBy using this, we will provide a generalization of the result of\nKedlaya-Pottharst-Xiao, giving a new proof for cases already proved there.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T14:45:45Z"}
{"aid":"http://arxiv.org/abs/2504.01786v1","title":"BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing","summary":"3D graphics editing is crucial in applications like movie production and game\ndesign, yet it remains a time-consuming process that demands highly specialized\ndomain expertise. Automating this process is challenging because graphical\nediting requires performing a variety of tasks, each requiring distinct skill\nsets. Recently, vision-language models (VLMs) have emerged as a powerful\nframework for automating the editing process, but their development and\nevaluation are bottlenecked by the lack of a comprehensive benchmark that\nrequires human-level perception and presents real-world editing complexity. In\nthis work, we present BlenderGym, the first comprehensive VLM system benchmark\nfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D\nreconstruction tasks. We evaluate closed- and open-source VLM systems and\nobserve that even the state-of-the-art VLM system struggles with tasks\nrelatively easy for human Blender users. Enabled by BlenderGym, we study how\ninference scaling techniques impact VLM's performance on graphics editing\ntasks. Notably, our findings reveal that the verifier used to guide the scaling\nof generation can itself be improved through inference scaling, complementing\nrecent insights on inference scaling of LLM generation in coding and math\ntasks. We further show that inference compute is not uniformly effective and\ncan be optimized by strategically distributing it between generation and\nverification.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.01799v1","title":"A discussion on the origin of the sub-PeV Galactic gamma-ray emission","summary":"Galactic diffuse gamma-ray flux measured by the Tibet AS{\\gamma} experiment\nand the total Galactic gamma-ray flux measured by Large High Altitude Air\nShower Observatory (LHAASO) are found to be consistent, within the statistical\nand systematic uncertainties, for the inner Galactic Plane region in the\nsub-PeV energy range (E > 10^14 eV). The result suggests that the sub-PeV\nGalactic gamma-ray flux is dominated by the diffuse emission. On the other\nhand, the LHAASO observations suggest that the sub-PeV gamma-ray sources\npresented in the first LHAASO catalog possibly give a significant contribution\nto the total sub-PeV Galactic gamma-ray emission ($\\approx$ 60%). However, the\nestimate must be regarded as a conservative upper limit. In fact, current\ngamma-ray observations imply that many of the sub-PeV gamma-ray sources\ndetected by LHAASO have a cutoff or significant softening in their energy\nspectra in the several tens of TeV energy range, and the resolved-source\ncontribution to the total sub-PeV Galactic gamma-ray emission should be much\nlower than the above estimate. More sophisticated discussion about the origin\nof the sub-PeV Galactic gamma-ray emission requires detailed spectral studies\nof the individual gamma-ray sources and an accurate estimate of the\ncontamination of the source fluxes from the diffuse emission.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-02T15:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.01829v1","title":"Revealed Bayesian Persuasion","summary":"When is random choice generated by a decision maker (DM) who is\nBayesian-persuaded by a sender? In this paper, I consider a DM whose\nstate-dependent preferences are known to an analyst, yet chooses stochastically\nas a function of the state. I provide necessary and sufficient conditions for\nthe dataset to be consistent with the DM being Bayesian persuaded by an\nunobserved sender who generates a distribution of signals to ex-ante optimize\nthe sender's expected payoff.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T15:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.01841v1","title":"Garbage Collection for Rust: The Finalizer Frontier","summary":"Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes\nexpressing data-structures that require shared ownership awkward, inefficient,\nor both. In this paper we explore a new design for, and implementation of, GC\nin Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy maps\nexisting Rust destructors to finalizers: this makes GC in Rust natural to use\nbut introduces surprising soundness, performance, and ergonomic problems. Alloy\nprovides solutions for each of these problems.","main_category":"cs.PL","categories":"cs.PL,D.3","published":"2025-04-02T15:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.01858v1","title":"Investigating the Variable Continuum Lags in PG 2130+099","summary":"Broadband photometric reverberation mapping (RM) provides a measure of the\nsize of the continuum-emitting region in active galactic nuclei (AGN). Previous\nmonitoring campaigns of PG 2130+099 disagree as to whether the continuum\nemitting region size is consistent with that predicted for a standard optically\nthick geometrically thin accretion disk. We present $\\sim$6 months of\nobservations from several robotic telescopes, providing the highest cadence and\nwidest wavelength coverage photometric RM study of PG 2130+099 to date. Our\nresults indicate that inferred size of the continuum-emitting region in PG\n2130+099, like many recently observed AGN, is larger than the simplest\npredictions for an irradiated geometrically thin, optically thick accretion\ndisk. We also perform a flux-flux analysis, finding a variable spectrum broadly\nconsistent with a disk, and a constant component with enhanced\n$\\textit{i}$-band emission, potentially due to H$\\alpha$. We find some evidence\nof increasing lag with luminosity, but previous lag measurements are too\nuncertain to be definitive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-02T16:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.01864v1","title":"On the $W$-entropy and Shannon entropy power on RCD$(K, N)$ and RCD$(K,\n  n, N)$ spaces","summary":"In this paper, we prove the $W$-entropy formula and its monotonicity for the\nheat flow on RCD$(K, N)$ and RCD$(K, n, N)$ spaces $(X, d, \\mu)$, where $K\\in\n\\mathbb{R}$, $n$ is the geometric dimension of $(X, d, \\mu)$ and $N\\geq n$. We\nalso prove the $K$-concavity of the Shannon entropy power on RCD$(K, N)$\nspaces. As an application, we derive the Shannon entropy isoperimetric\ninequality and the Stam logarithmic Sobolev inequality on RCD$(0, N)$ spaces\nwith maximal volume growth condition. Finally, we prove the rigidity theorem\nfor the Stam logarithmic Sobolev inequality with sharp constant on\nnoncollapsing RCD$(0, N)$ spaces.","main_category":"math.FA","categories":"math.FA,math.MG,math.PR","published":"2025-04-02T16:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.01876v1","title":"The TELOS Collaboration Approach to Reproducibility and Open Science","summary":"The TELOS Collaboration is committed to producing and analysing lattice data\nreproducibly, and sharing its research openly. In this document, we set out the\nways that we make this happen, where there is scope for improvement, and how we\nplan to achieve this. This is intended to work both as a statement of policy,\nand a guide to practice for those beginning to work with us. Some details and\nrecommendations are specific to the context in which the Collaboration works\n(such as references to requirements imposed by funders in the United Kingdom);\nhowever, most recommendations may serve as a template for other collaborations\nlooking to make their own work reproducible. Full tutorials on every aspect of\nreproducibility are beyond the scope of this document, but we refer to other\nresources for further information.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T16:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.01897v1","title":"Threshold for Fault-tolerant Quantum Advantage with the Quantum\n  Approximate Optimization Algorithm","summary":"Optimization is often cited as a promising application of quantum computers.\nHowever, the low degree of provable quantum speedups has led prior rigorous\nend-to-end resource analyses to conclude that a quantum computer is unlikely to\nsurpass classical state-of-the-art on optimization problems under realistic\nassumptions. In this work, we compile and analyze the Quantum Approximate\nOptimization Algorithm (QAOA) combined with Amplitude Amplification (AA)\napplied to random 8-SAT at the satisfiability threshold. Our compilation\ninvolves careful optimization of circuits for Hamiltonian simulation, which may\nbe of independent interest. We use the analytical scaling of the\ntime-to-solution for QAOA identified by PRX Quantum 5, 030348 (2024) and find\nthat with QAOA depth $p=623$, QAOA+AA achieves a crossover with\nstate-of-the-art classical heuristics at 179 variables and 14.99 hours of\nruntime when executed on a surface-code-based fault-tolerant quantum computer\nwith 73.91 million physical qubits, a physical error rate of $10^{-3}$, and a\n$1~\\mu$s code cycle time. Notably, we allow the classical solver to be\nparallelized as long as its total energy consumption is equal to that required\nfor decoding in the surface code. We further show that this restriction on\nclassical solver energy consumption can be relaxed given optimistic but\nplausible reductions in physical error rates and fault-tolerance overheads,\nenabling a crossover of 2.94 hours using 8.88 million physical qubits against a\nclassical solver running on a supercomputer with $725,760$ CPU cores. These\nfindings support the hypothesis that large-scale fault-tolerant quantum\ncomputers will be useful for optimization.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T16:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01899v1","title":"Recovery Reductions in the Random Noise Model via Group Theory: Insights\n  into NP-Complete and Fine-Grained Problems","summary":"We introduce and initiate the study of a new model of reductions called the\nrandom noise model. In this model, the truth table $T_f$ of the function $f$ is\ncorrupted on a randomly chosen $\\delta$-fraction of instances. A randomized\nalgorithm $A$ is a $\\left(t, \\delta, 1-\\varepsilon\\right)$-recovery reduction\nfor $f$ if:\n  1. With probability $1-\\varepsilon$ over the choice of $\\delta$-fraction\ncorruptions, given access to the corrupted truth table, the algorithm $A$\ncomputes $f(\\phi)$ correctly with probability at least $2/3$ on every input\n$\\phi$.\n  2. The algorithm $A$ runs in time $O(t)$.\n  We believe this model, which is a natural relaxation of average-case\ncomplexity, both has practical motivations and is mathematically interesting.\n  Pointing towards this, we show the existence of robust deterministic\npolynomial-time recovery reductions with the highest tolerable noise level for\nmany of the canonical NP-complete problems - SAT, kSAT, kCSP, CLIQUE and more.\nOur recovery reductions are optimal for non-adaptive algorithms under\ncomplexity-theoretic assumptions. Notably, all our recovery reductions follow\nas corollaries of one black box algorithm based on group theory and permutation\ngroup algorithms. This suggests that recovery reductions in the random noise\nmodel are important to the study of the structure of NP-completeness.\n  Furthermore, we establish recovery reductions with optimal parameters for\nOrthogonal Vectors and Parity $k$-Clique problems. These problems exhibit\nstructural similarities to NP-complete problems, with Orthogonal Vectors\nadmitting a $2^{0.5n}$-time reduction from kSAT on $n$ variables and Parity\n$k$-Clique, a subexponential-time reduction from 3SAT. This further highlights\nthe relevance of our model to the study of NP-completeness.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-02T16:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01926v1","title":"Pairing Anderson motives via formal residues in the Frobenius\n  endomorphism","summary":"Anderson modules form a generalization of Drinfeld modules and are commonly\nunderstood as the counterpart of abelian varieties but with function field\ncoefficients. In an attempt to study their ``motivic theory'', two objects of\nsemilinear algebra are attached to an Anderson module: its motive and its dual\nmotive. While the former is better suited to follow the analogy with\nGrothendieck motives, the latter has proven much useful in the study of\ntranscendence questions in positive characteristic. Despite sharing similar\ndefinitions, the relationship between motives and dual motives has remained\nnebulous. Over perfect fields, it was only proved recently by the second author\nthat the finite generation of the motive is equivalent to the finite generation\nof the dual motive, answering a long-standing open question in function field\narithmetic (the ``abelian equals $A$-finite'' theorem). This work constructs a\nperfect pairing among the motive and the dual motive of an Anderson module,\nwith values in a module of differentials, thus answering a question raised by\nHartl and Juschka. Our construction involves taking the residue of certain\nformal power series in the Frobenius endomorphism. Although it may seem\npeculiar, this pairing is natural and compatible with base change. It also\ncomes with several new consequences in function field arithmetic; for example,\nwe generalize the ``abelian equals A-finite'' theorem to a large class of\nalgebras, including fields, perfect algebras and noetherian regular domains.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T17:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.01947v1","title":"Efficient Federated Learning Tiny Language Models for Mobile Network\n  Feature Prediction","summary":"In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,eess.SP","published":"2025-04-02T17:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.01961v1","title":"Learning from Streaming Video with Orthogonal Gradients","summary":"We address the challenge of representation learning from a continuous stream\nof video as input, in a self-supervised manner. This differs from the standard\napproaches to video learning where videos are chopped and shuffled during\ntraining in order to create a non-redundant batch that satisfies the\nindependently and identically distributed (IID) sample assumption expected by\nconventional training paradigms. When videos are only available as a continuous\nstream of input, the IID assumption is evidently broken, leading to poor\nperformance. We demonstrate the drop in performance when moving from shuffled\nto sequential learning on three tasks: the one-video representation learning\nmethod DoRA, standard VideoMAE on multi-video datasets, and the task of future\nvideo prediction. To address this drop, we propose a geometric modification to\nstandard optimizers, to decorrelate batches by utilising orthogonal gradients\nduring training. The proposed modification can be applied to any optimizer --\nwe demonstrate it with Stochastic Gradient Descent (SGD) and AdamW. Our\nproposed orthogonal optimizer allows models trained from streaming videos to\nalleviate the drop in representation learning performance, as evaluated on\ndownstream tasks. On three scenarios (DoRA, VideoMAE, future prediction), we\nshow our orthogonal optimizer outperforms the strong AdamW in all three\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02227v1","title":"VEGAS: Towards Visually Explainable and Grounded Artificial Social\n  Intelligence","summary":"Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T02:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.02250v1","title":"Designing Effective Human-Swarm Interaction Interfaces: Insights from a\n  User Study on Task Performance","summary":"In this paper, we present a systematic method of design for human-swarm\ninteraction interfaces, combining theoretical insights with empirical\nevaluation. We first derive ten design principles from existing literature,\napply them to key information dimensions identified through goal-directed task\nanalysis and developed a tablet-based interface for a target search task. We\nthen conducted a user study with 31 participants where humans were required to\nguide a robotic swarm to a target in the presence of three types of hazards\nthat pose a risk to the robots: Distributed, Moving, and Spreading. Performance\nwas measured based on the proximity of the robots to the target and the number\nof deactivated robots at the end of the task. Results indicate that at least\none robot was bought closer to the target in 98% of tasks, demonstrating the\ninterface's success fulfilling the primary objective of the task. Additionally,\nin nearly 67% of tasks, more than 50% of the robots reached the target.\nMoreover, particularly better performance was noted in moving hazards.\nAdditionally, the interface appeared to help minimize robot deactivation, as\nevidenced by nearly 94% of tasks where participants managed to keep more than\n50% of the robots active, ensuring that most of the swarm remained operational.\nHowever, its effectiveness varied across hazards, with robot deactivation being\nlowest in distributed hazard scenarios, suggesting that the interface provided\nthe most support in these conditions.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-03T03:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.02275v1","title":"Enhancing Customer Contact Efficiency with Graph Neural Networks in\n  Credit Card Fraud Detection Workflow","summary":"Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:50:45Z"}
{"aid":"http://arxiv.org/abs/2504.02292v1","title":"Unifying Different Theories of Conformal Prediction","summary":"This paper presents a unified framework for understanding the methodology and\ntheory behind several different methods in the conformal prediction literature,\nwhich includes standard conformal prediction (CP), weighted conformal\nprediction (WCP), nonexchangeable conformal prediction (NexCP), and\nrandomly-localized conformal prediction (RLCP), among others. At the crux of\nour framework is the idea that conformal methods are based on revealing partial\ninformation about the data at hand, and positing a conditional distribution for\nthe data given the partial information. Different methods arise from different\nchoices of partial information, and of the corresponding (approximate)\nconditional distribution. In addition to recovering and unifying existing\nresults, our framework leads to both new theoretical guarantees for existing\nmethods, and new extensions of the conformal methodology.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T05:46:26Z"}
{"aid":"http://arxiv.org/abs/2504.02299v1","title":"Asymmetric graph alignment and the phase transition for asymmetric tree\n  correlation testing","summary":"Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-03T06:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.02321v1","title":"On shallow feedforward neural networks with inputs from a topological\n  space","summary":"We study feedforward neural networks with inputs from a topological space\n(TFNNs). We prove a universal approximation theorem for shallow TFNNs, which\ndemonstrates their capacity to approximate any continuous function defined on\nthis topological space. As an application, we obtain an approximative version\nof Kolmogorov's superposition theorem for compact metric spaces.","main_category":"cs.LG","categories":"cs.LG,math.FA","published":"2025-04-03T06:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.02335v1","title":"Evaluating and Enhancing Segmentation Model Robustness with Metamorphic\n  Testing","summary":"Image segmentation is critical for applications such as medical imaging,\naugmented reality, and video surveillance. However, segmentation models often\nlack robustness, making them vulnerable to adversarial perturbations from\nsubtle image distortions. In this work, we propose SegRMT, a metamorphic\ntesting approach that leverages genetic algorithms (GA) to optimize sequences\nof spatial and spectral transformations while preserving image fidelity via a\npredefined PSNR threshold. Using the Cityscapes dataset, our method generates\nadversarial examples that effectively challenge the DeepLabV3 segmentation\nmodel. Our experiments show that SegRMT reduces DeepLabV3's mean Intersection\nover Union (mIoU) to 6.4%, outperforming other adversarial baselines that\ndecrease mIoU to between 8.5% and 21.7%. Furthermore, when used for adversarial\ntraining, SegRMT boosts model performance, achieving mIoU improvements up to\n73% on dedicated adversarial datasets and increasing cross-adversarial mIoU to\n53.8%, compared to only 2%-10% for other methods. These findings demonstrate\nthat SegRMT not only simulates realistic image distortions but also enhances\nthe robustness of segmentation models, making it a valuable tool for ensuring\nreliable performance in safety-critical applications.","main_category":"cs.CV","categories":"cs.CV,cs.SE","published":"2025-04-03T07:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.02338v1","title":"Coronal and chromospheric activity of Teegarden's star","summary":"Teegarden's star is a late-type M-dwarf planet host, typically showing only\nrather low levels of activity. In this paper we present an extensive\ncharacterisation of this activity at photospheric, chromospheric, and coronal\nlevels. We specifically investigated TESS observations of Teegarden's star,\nwhich showed two very large flares with an estimated flare fluence between\n10$^{29}$ and 10$^{32}$\\,erg comparable to the largest solar flares. We\nfurthermore analysed nearly 300 CARMENES spectra and 11 ESPRESSO spectra\ncovering all the usually used chromospheric lines in the optical from the\n\\ion{Ca}{ii} H \\& K lines at 3930\\,\\AA\\, to the \\ion{He}{i} infrared triplet at\n10830\\,\\AA. These lines show different behaviour: The \\ion{He}{i} infrared\ntriplet is the only one absent in all spectra, some lines show up only during\nflares, and others are always present and highly variable. Specifically, the\nH$\\alpha$ line is more or less filled in during quiescence; however, the higher\nBalmer lines are still observed in emission. Many chromospheric lines show a\ncorrelation with H$\\alpha$ variability, which, in addition to stochastic\nbehaviour, also shows systematic behaviour on different timescales including\nthe rotation period. Moreover, we found several flares and also report hints of\nan erupting prominence, which may have led to a coronal mass ejection. Finally,\nwe present X-ray observations of Teegarden's star (i.e. a discovery pointing\nobtained with the \\emph{Chandra} observatory) and an extensive study with the\n\\emph{XMM-Newton} observatory; when these two large flares were observed, one\nof them showed clear signatures of the Neupert effect, suggesting the\nproduction of hard X-rays in the system.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T07:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.02341v1","title":"Bergman spaces on algebraic curves","summary":"A theorem of Wiegerinck asserts that the Bergman space of an open subset of\nthe complex numbers is either infinite-dimensional or trivial. Recently, this\nhas been generalized to holomorphic vector bundles over the projective line by\nthe third author and later to vector bundles over any compact Riemann surface\nby Gallagher, Gupta and Vivas.\n  In the present paper we extend the above results to the case of certain\nsingular metrics associated to divisors on a Riemann surface. As corollaries we\nobtain versions of Wiegerinck's theorem for both projective and affine\nalgebraic curves.","main_category":"math.CV","categories":"math.CV","published":"2025-04-03T07:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.02346v1","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing\n  Platforms: A Mean Field Game Approach","summary":"The on-demand ride-hailing industry has experienced rapid growth,\ntransforming transportation norms worldwide. Despite improvements in efficiency\nover traditional taxi services, significant challenges remain, including\ndrivers' strategic repositioning behavior, customer abandonment, and\ninefficiencies in dispatch algorithms. To address these issues, we introduce a\ncomprehensive mean field game model that systematically analyzes the dynamics\nof ride-hailing platforms by incorporating driver repositioning across multiple\nregions, customer abandonment behavior, and platform dispatch algorithms. Using\nthis framework, we identify all possible mean field equilibria as the\nKarush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our\nanalysis reveals the emergence of multiple equilibria, including the\ninefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant\nrequests, leading to suboptimal system performance. To mitigate these\ninefficiencies, we propose a novel two-matching-radius nearest-neighbor\ndispatch algorithm that eliminates undesirable equilibria and ensures a unique\nmean field equilibrium for multi-region systems. The algorithm dynamically\nadjusts matching radii based on driver supply rates, optimizing pick-up times\nand waiting times for drivers while maximizing request completion rates.\nNumerical experiments and simulation results show that our proposed algorithm\nreduces customer abandonment, minimizes waiting times for both customers and\ndrivers, and improves overall platform efficiency.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-03T07:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.02358v1","title":"Interference trapping of populations in a semi-infinite\n  coupled-resonator waveguide","summary":"We study the energy structure and dynamics of a two-level emitter (2LE)\nlocally coupled to a semi-infinite one-dimensional (1D) coupled-resonator array\n(CRA). The energy spectrum in the single-excitation subspace features a\ncontinuous band with scattering states, discrete levels with bound states, and\na quantum phase transition characterized by the change of the number of bound\nstates. The number of bound states is revealed by the behavior of the\nexcited-state population at long times with quantum beat, residual oscillation,\na constant with either non-zero or zero.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T07:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.02359v1","title":"First observation of ultra-long-range azimuthal correlations in low\n  multiplicity pp and p-Pb collisions at the LHC","summary":"This study presents the first observation of ultra-long-range two-particle\nazimuthal correlations with pseudorapidity separation of ($|\\Delta \\eta| >\n5.0$) in proton-proton (pp) and ($|\\Delta \\eta| > 6.5$) in proton-lead (p-Pb)\ncollisions at the LHC, down to and below the minimum-bias multiplicity.\nTwo-particle correlation coefficients (${V}_{2\\Delta}$) are measured after\nremoving non-flow (jets and resonance decays) contributions using the\ntemplate-fit method across various multiplicity classes, providing novel\ninsights into the origin of long-range correlations in small systems.\nComparisons with the 3D-Glauber + MUSIC + UrQMD hydrodynamic model reveal\nsignificant discrepancies at low multiplicities, indicating possible dynamics\nbeyond typical hydrodynamic behavior. Initial-state models based on the Color\nGlass Condensate framework generate only short-range correlations, while PYTHIA\nsimulations implemented with the string-shoving mechanism also fail to describe\nthese ultra-long-range correlations. The results challenge existing paradigms\nand question the underlying mechanisms in low-multiplicity pp and p-Pb\ncollisions. The findings impose significant constraints on models describing\ncollective phenomena in small collision systems and advance the understanding\nof origin of long-range correlations at Large Hadron Collider (LHC) energies.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T07:46:09Z"}
{"aid":"http://arxiv.org/abs/2504.02361v1","title":"MG-Gen: Single Image to Motion Graphics Generation with Layer\n  Decomposition","summary":"General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that \\ours{} generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.02371v1","title":"Schur roots and tilting modules of acyclic quivers over commutative\n  rings","summary":"Let $Q$ be a finite acyclic quiver and $A_Q$ the cluster algebra of $Q$. It\nis well-known that for each field $k$, the additive equivalence classes of\nsupport tilting $kQ$-modules correspond bijectively with the clusters of $A_Q$.\nThe aim of this paper is to generalize this result to any ring indecomposable\ncommutative Noetherian ring $R$, that is, the additive equivalence classes of\n2-term silting complexes of $RQ$ correspond bijectively with the clusters of\n$A_Q$. As an application, for a Dynkin quiver $Q$, we prove that the torsion\nclasses of $\\mathrm{mod} RQ$ corresponds bijectively with the order preserving\nmaps from $\\mathrm{Spec} R$ to the set of clusters.","main_category":"math.RT","categories":"math.RT,math.AC,math.RA","published":"2025-04-03T08:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.02375v1","title":"A Comparative Study of MINLP and MPVC Formulations for Solving Complex\n  Nonlinear Decision-Making Problems in Aerospace Applications","summary":"High-level decision-making for dynamical systems often involves performance\nand safety specifications that are activated or deactivated depending on\nconditions related to the system state and commands. Such decision-making\nproblems can be naturally formulated as optimization problems where these\nconditional activations are regulated by discrete variables. However, solving\nthese problems can be challenging numerically, even on powerful computing\nplatforms, especially when the dynamics are nonlinear. In this work, we\nconsider decision-making for nonlinear systems where certain constraints, as\nwell as possible terms in the cost function, are activated or deactivated\ndepending on the system state and commands. We show that these problems can be\nformulated either as mixed-integer nonlinear programs (MINLPs) or as\nmathematical programs with vanishing constraints (MPVCs), where the former\nformulation involves discrete decision variables, whereas the latter relies on\ncontinuous variables subject to structured nonconvex constraints. We discuss\nthe different solution methods available for both formulations and demonstrate\nthem on optimal trajectory planning problems in various aerospace applications.\nFinally, we compare the strengths and weaknesses of the MINLP and MPVC\napproaches through a focused case study on powered descent guidance with\ndivert-feasible regions.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-03T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.02393v1","title":"Revealing the microscopic mechanism of deuteron formation at the LHC","summary":"The formation of light (anti)nuclei with mass number A of a few units (e.g.,\nd, $^3$He, and $^4$He) in high-energy hadronic collisions presents a\nlongstanding mystery in nuclear physics [1,2]. It is not clear how nuclei bound\nby a few MeV can emerge in environments characterized by temperatures above 100\nMeV [3-5], about 100,000 times hotter than the center of the Sun. Despite\nextensive studies, this question remained unanswered. The ALICE Collaboration\nnow addresses it with a novel approach using deuteron-pion momentum\ncorrelations in proton-proton (pp) collisions at the Large Hadron Collider\n(LHC). Our results provide model-independent evidence that about 80% of the\nobserved (anti)deuterons are produced in nuclear fusion reactions [6] following\nthe decay of short-lived resonances, such as the $\\Delta (1232)$. These\nfindings resolve a crucial gap in our understanding of nucleosynthesis in\nhadronic collisions. Beyond answering the fundamental question on how nuclei\nare formed in hadronic collisions, the results can be employed in the modeling\nof the production of light and heavy nuclei in cosmic rays [7] and dark matter\ndecays [8,9].","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T08:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.02411v1","title":"Adapting Large Language Models for Multi-Domain\n  Retrieval-Augmented-Generation","summary":"Retrieval-Augmented Generation (RAG) enhances LLM factuality, but\nmulti-domain applications face challenges like lack of diverse benchmarks and\npoor out-of-domain generalization. The first contribution of this work is to\nintroduce a diverse benchmark comprising a variety of question-answering tasks\nfrom 8 sources and covering 13 domains. Our second contribution consists in\nsystematically testing out-of-domain generalization for typical RAG tuning\nstrategies. While our findings reveal that standard fine-tuning fails to\ngeneralize effectively, we show that sequence-level distillation with\nteacher-generated labels improves out-of-domain performance by providing more\ncoherent supervision. Our findings highlight key strategies for improving\nmulti-domain RAG robustness.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T09:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.02412v1","title":"Bridging the Theoretical Gap in Randomized Smoothing","summary":"Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T09:05:49Z"}
{"aid":"http://arxiv.org/abs/2504.02429v1","title":"A Multi-Level Sentiment Analysis Framework for Financial Texts","summary":"Existing financial sentiment analysis methods often fail to capture the\nmulti-faceted nature of risk in bond markets due to their single-level approach\nand neglect of temporal dynamics. We propose Multi-Level Sentiment Analysis\nbased on pre-trained language models (PLMs) and large language models (LLMs), a\nnovel framework that systematically integrates firm-specific micro-level\nsentiment, industry-specific meso-level sentiment, and duration-aware smoothing\nto model the latency and persistence of textual impact. Applying our framework\nto the comprehensive Chinese bond market corpus constructed by us (2013-2023,\n1.39M texts), we extracted a daily composite sentiment index. Empirical results\nshow statistically measurable improvements in credit spread forecasting when\nincorporating sentiment (3.25% MAE and 10.96% MAPE reduction), with sentiment\nshifts closely correlating with major social risk events and firm-specific\ncrises. This framework provides a more nuanced understanding of sentiment\nacross different market levels while accounting for the temporal evolution of\nsentiment effects.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T09:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.02443v1","title":"Language-Integrated Recursive Queries","summary":"Performance-critical industrial applications, including large-scale program,\nnetwork, and distributed system analyses, rely on fixed-point computations. The\nintroduction of recursive common table expressions (CTEs) using the WITH\nRECURSIVE keyword in SQL:1999 extended the ability of relational database\nsystems to handle fixed-point computations, unlocking significant performance\nadvantages by allowing computation to move closer to the data. Yet with\nrecursion, SQL becomes a Turing-complete programming language and, with that,\nunrecoverable safety and correctness risks. SQL itself lacks a fixed semantics,\nas the SQL specification is written in natural language, full of ambiguities\nthat database vendors resolve in divergent ways. As a result, reasoning about\nthe correctness of recursive SQL programs must rely on isolated mathematical\nproperties of queries rather than wrestling a unified formal model out of a\nlanguage with notoriously inconsistent semantics. To address these challenges,\nwe propose a calculus that automatically derives mathematical properties from\nembedded recursive queries and, depending on the database backend, rejects\nqueries that may lead to the three classes of recursive query errors - database\nerrors, incorrect results, and non-termination. We introduce TyQL, a practical\nimplementation in Scala for safe, recursive language-integrated query. Using\nNamed-Tuples and type-level pattern matching, TyQL ensures query portability\nand safety, showing no performance penalty compared to raw SQL strings while\nunlocking a three-orders-of-magnitude speedup over non-recursive SQL queries.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T09:58:52Z"}
{"aid":"http://arxiv.org/abs/2504.02470v1","title":"Impact of Global Warming on Extreme Rainfall in Taiwan","summary":"The relationship between global warming and extreme rainfalls in Taiwan was\nexamined in this study. Taiwan rainfall data from TCCIP, a project led by MOST,\nwere analyzed. North Hemisphere reference temperature data from NCEI led by\nNOAA. The yearly maximum of daily rainfall was focused on and the PGEV model,\nas proposed by Olafsdottir et al. \\citep{olafsdottir2021extreme}, was used to\nfit the extreme values and make inferences. The PGEV model integrates the\nGeneral Extreme Value (GEV) and Peak over Threshold (PoT) approaches, which are\ncommonly used to analyze extreme data. Relative intensity and return value were\nused to show the connection between temperature and extreme rainfall.\n  Results indicated that the intensity of extreme rainfall in Taiwan increases\nas the temperature rises. However, the effects of global warming on the\nfrequency and intensity of extreme rainfalls varied by region. In the north and\nsouth regions, the frequency of extreme rainfalls changed, while in the center\nand east regions, the intensity of extreme rainfalls changed. Furthermore,\naccording to the return value analysis, extreme rainfalls are likely to occur\nmore frequently in the future.\n  To account for differences between locations, Gaussian Process was used to\nsmooth the results obtained using the PGEV model. In addition, simulations\nusing the Gaussian copula and Gaussian Process were conducted to determine the\nquantile confidence intervals for each PGEV model. The simulations showed that\nall tests comparing with models with and without covariates are significant.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T10:44:32Z"}
{"aid":"http://arxiv.org/abs/2504.02478v1","title":"MG-MotionLLM: A Unified Framework for Motion Comprehension and\n  Generation across Multiple Granularities","summary":"Recent motion-aware large language models have demonstrated promising\npotential in unifying motion comprehension and generation. However, existing\napproaches primarily focus on coarse-grained motion-text modeling, where text\ndescribes the overall semantics of an entire motion sequence in just a few\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\nsuch as understanding and controlling the movements of specific body parts. To\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\nmodel for multi-granular motion comprehension and generation. We further\nintroduce a comprehensive multi-granularity training scheme by incorporating a\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\nsegments via detailed text as well as motion detailed captioning, to facilitate\nmutual reinforcement for motion-text modeling across various levels of\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\npotential in novel fine-grained motion comprehension and editing tasks. Project\npage: CVI-SZU/MG-MotionLLM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02494v1","title":"Semiconductor Wafer Map Defect Classification with Tiny Vision\n  Transformers","summary":"Semiconductor wafer defect classification is critical for ensuring high\nprecision and yield in manufacturing. Traditional CNN-based models often\nstruggle with class imbalances and recognition of the multiple overlapping\ndefect types in wafer maps. To address these challenges, we propose ViT-Tiny, a\nlightweight Vision Transformer (ViT) framework optimized for wafer defect\nclassification. Trained on the WM-38k dataset. ViT-Tiny outperforms its\nViT-Base counterpart and state-of-the-art (SOTA) models, such as MSF-Trans and\nCNN-based architectures. Through extensive ablation studies, we determine that\na patch size of 16 provides optimal performance. ViT-Tiny achieves an F1-score\nof 98.4%, surpassing MSF-Trans by 2.94% in four-defect classification,\nimproving recall by 2.86% in two-defect classification, and increasing\nprecision by 3.13% in three-defect classification. Additionally, it\ndemonstrates enhanced robustness under limited labeled data conditions, making\nit a computationally efficient and reliable solution for real-world\nsemiconductor defect detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T11:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.02506v1","title":"Secrecy Performance of a Keyhole-based Multi-user System with Multiple\n  Eavesdroppers","summary":"This paper investigates the secrecy performance of a keyhole-aided multi-user\ncommunication network in the presence of multiple eavesdroppers. The\ncommunication happens through the same keyhole for legitimate users and\neavesdroppers. In this context, the secrecy performance is evaluated for a user\nscheduling technique by obtaining the exact closed-form expression of secrecy\noutage probability (SOP). Further, a simplified asymptotic SOP expression is\nderived assuming high signal-to-noise ratio (SNR) scenario for a better\nunderstanding of the impact of system parameters. The effect of the keyhole\nparameters, number of users, number of eavesdroppers, and threshold secrecy\nrate on the SOP performance are also investigated for the considered system\nmodel. In the high-SNR regime, the asymptotic SOP saturates to a constant value\nand does not depend on the keyhole parameter and the channel parameter of the\nsource-to-keyhole channel.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-03T11:38:08Z"}
{"aid":"http://arxiv.org/abs/2504.02526v1","title":"Improving User Experience with FAICO: Towards a Framework for AI\n  Communication in Human-AI Co-Creativity","summary":"How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-03T12:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.02530v1","title":"Statistical parameter identification of mixed-mode patterns from a\n  single experimental snapshot","summary":"Parameter identification in pattern formation models from a single\nexperimental snapshot is challenging, as traditional methods often require\nknowledge of initial conditions or transient dynamics -- data that are\nfrequently unavailable in experimental settings. In this study, we extend the\nrecently developed statistical approach, Correlation Integral Likelihood (CIL)\nmethod to enable robust parameter identification from a single snapshot of an\nexperimental pattern. Using the chlorite-iodite-malonic acid (CIMA) reaction --\na well-studied system that produces Turing patterns -- as a test case, we\naddress key experimental challenges such as measurement noise, model-data\ndiscrepancies, and the presence of mixed-mode patterns, where different spatial\nstructures (e.g., coexisting stripes and dots) emerge under the same\nconditions. Numerical experiments demonstrate that our method accurately\nestimates model parameters, even with incomplete or noisy data. This approach\nlays the groundwork for future applications in developmental biology, chemical\nreaction modelling, and other systems with heterogeneous output.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T12:33:56Z"}
{"aid":"http://arxiv.org/abs/2504.02537v1","title":"Blockchain and Distributed Ledger Technologies for Cyberthreat\n  Intelligence Sharing","summary":"Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and\nit is essential to understand its definition, objectives, benefits, and impact\non society. Blockchain and Distributed Ledger Technology (DLT) are emerging\ntechnologies that have the potential to transform intelligence sharing. This\npaper aims to provide a comprehensive understanding of intelligence sharing and\nthe role of blockchain and DLT in enhancing it. The paper addresses questions\nrelated to the definition, objectives, benefits, and impact of intelligence\nsharing and provides a review of the existing literature. Additionally, the\npaper explores the challenges associated with blockchain and DLT and their\npotential impact on security and privacy. The paper also discusses the use of\nDLT and blockchain in security and intelligence sharing and highlights the\nassociated challenges and risks. Furthermore, the paper examines the potential\nimpact of a National Cybersecurity Strategy on addressing cybersecurity risks.\nFinally, the paper explores the experimental set up required for implementing\nblockchain and DLT for intelligence sharing and discusses the curricular\nramifications of intelligence sharing.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02550v1","title":"Enhanced Permeability Estimation in Microporous Rocks Using a Hybrid\n  Macropore-Darcy Approach","summary":"This study presents a novel workflow for constructing hybrid macropore-Darcy\nmodels from micro-CT images of microporous rocks. In our approach, macropore\nnetworks are extracted using established methods, while the microporosity is\ncharacterised through segmented phase classification and incorporated into the\nmodel as Darcy cells. Effectively, Darcy cells capture the micro scale\nconnectivity variations that are missing in the macroscopic networks. This dual\nentity model thus incorporates both the conventional macroscopic pore structure\nand the critical flow pathways present in the under-resolved microporous\nregions. The proposed workflow is rigorously validated by comparing the\npermeability estimates with direct numerical simulation (DNS) results and\nexperimental measurements. Our findings demonstrate that this hybrid approach\nreliably reproduces fluid flow behaviour in complex porous media while\nsignificantly reducing computational demands, offering a promising tool for\nadvanced groundwater modelling and water resource management.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T13:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.02581v1","title":"Quantitative assessment of biological dynamics with aggregate data","summary":"We develop and apply a learning framework for parameter estimation in initial\nvalue problems that are assessed only indirectly via aggregate data such as\nsample means and/or variances. Our comprehensive framework follows Bayesian\nprinciples and consists of specialized Markov chain Monte Carlo computational\nschemes that rely on modified Hamiltonian Monte Carlo to align with summary\nstatistic constraints and a novel elliptical slice sampler adapted to the\nparameters of biological models. We benchmark our methods with synthetic data\non microbial growth in batch culture and test them on real growth curve data\nfrom laboratory replication experiments on $\\textit{Prochlorococcus}$ microbes.\nThe results indicate that our learning framework can utilize experimental or\nhistorical data and lead to robust parameter estimation and data assimilation\nin ODE models of biological dynamics that outperform least-squares fitting.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-03T13:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.02587v1","title":"Rethinking RL Scaling for Vision Language Models: A Transparent,\n  From-Scratch Framework and Comprehensive Evaluation Scheme","summary":"Reinforcement learning (RL) has recently shown strong potential in improving\nthe reasoning capabilities of large language models and is now being actively\nextended to vision-language models (VLMs). However, existing RL applications in\nVLMs often rely on heavily engineered frameworks that hinder reproducibility\nand accessibility, while lacking standardized evaluation protocols, making it\ndifficult to compare results or interpret training dynamics. This work\nintroduces a transparent, from-scratch framework for RL in VLMs, offering a\nminimal yet functional four-step pipeline validated across multiple models and\ndatasets. In addition, a standardized evaluation scheme is proposed to assess\ntraining dynamics and reflective behaviors. Extensive experiments on visual\nreasoning tasks uncover key empirical findings: response length is sensitive to\nrandom seeds, reflection correlates with output length, and RL consistently\noutperforms supervised fine-tuning (SFT) in generalization, even with\nhigh-quality data. These findings, together with the proposed framework, aim to\nestablish a reproducible baseline and support broader engagement in RL-based\nVLM research.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-03T13:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.02591v1","title":"State-Space Model Inspired Multiple-Input Multiple-Output Spiking\n  Neurons","summary":"In spiking neural networks (SNNs), the main unit of information processing is\nthe neuron with an internal state. The internal state generates an output spike\nbased on its component associated with the membrane potential. This spike is\nthen communicated to other neurons in the network. Here, we propose a general\nmultiple-input multiple-output (MIMO) spiking neuron model that goes beyond\nthis traditional single-input single-output (SISO) model in the SNN literature.\nOur proposed framework is based on interpreting the neurons as state-space\nmodels (SSMs) with linear state evolutions and non-linear spiking activation\nfunctions. We illustrate the trade-offs among various parameters of the\nproposed SSM-inspired neuron model, such as the number of hidden neuron states,\nthe number of input and output channels, including single-input multiple-output\n(SIMO) and multiple-input single-output (MISO) models. We show that for SNNs\nwith a small number of neurons with large internal state spaces, significant\nperformance gains may be obtained by increasing the number of output channels\nof a neuron. In particular, a network with spiking neurons with multiple-output\nchannels may achieve the same level of accuracy with the baseline with the\ncontinuous-valued communications on the same reference network architecture.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T13:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.02603v1","title":"Plasmonic Su-Schrieffer-Heeger chains with strong coupling amplitudes","summary":"Plasmonic many-particle systems with precisely tuned resonances and coupling\nstrengths can exhibit emergent collective properties governed by universal\nprinciples. In one-dimensional chains with alternating couplings, known as\nSu-Schrieffer-Heeger (SSH) systems, this includes the formation of\ntopologically protected mid-gap modes whose intensities localize at the chain's\nends. This subwavelength localization at optical frequencies is crucial for\nachieving strong coupling of mid-gap modes to two-level systems under ambient\nconditions, extending topological protection to hybrid light-matter states.\nHere, we have fabricated SSH chains from plasmonic nanoslit resonators with\nstrong inter-resonator coupling. The alternating distance between the nanoslit\nresonators is controlled with sub-nanometer precision, enabling accurate\nprediction and experimental observation of topologically protected mid-gap\nmodes via photoemission electron microscopy (PEEM). Our results open the path\ntowards experimental realizations of two-dimensional photonic metasurfaces\nexhibiting higher-order topological modes that can be strongly coupled to\nsingle emitters and quantum materials at ambient conditions.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-03T14:05:17Z"}
{"aid":"http://arxiv.org/abs/2504.02612v1","title":"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation","summary":"Recent advances in text-to-image generative models have enabled numerous\npractical applications, including subject-driven generation, which fine-tunes\npretrained models to capture subject semantics from only a few examples. While\ndiffusion-based models produce high-quality images, their extensive denoising\nsteps result in significant computational overhead, limiting real-world\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\ntokens rather than spatially adjacent ones, offer significantly faster\ninference suitable for practical deployment. In this paper, we propose the\nfirst VAR-based approach for subject-driven generation. However, na\\\"{\\i}ve\nfine-tuning VAR leads to computational overhead, language drift, and reduced\ndiversity. To address these challenges, we introduce selective layer tuning to\nreduce complexity and prior distillation to mitigate language drift.\nAdditionally, we found that the early stages have a greater influence on the\ngeneration of subject than the latter stages, which merely synthesize local\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\nprioritizes coarser resolutions for promoting the model to focus on the\nsubject-relevant information instead of local details. Extensive experiments\nvalidate that our method significantly outperforms diffusion-based baselines\nacross various metrics and demonstrates its practical usage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.02627v1","title":"Incorporating the ChEES Criterion into Sequential Monte Carlo Samplers","summary":"Markov chain Monte Carlo (MCMC) methods are a powerful but computationally\nexpensive way of performing non-parametric Bayesian inference. MCMC proposals\nwhich utilise gradients, such as Hamiltonian Monte Carlo (HMC), can better\nexplore the parameter space of interest if the additional hyper-parameters are\nchosen well. The No-U-Turn Sampler (NUTS) is a variant of HMC which is\nextremely effective at selecting these hyper-parameters but is slow to run and\nis not suited to GPU architectures. An alternative to NUTS, Change in the\nEstimator of the Expected Square HMC (ChEES-HMC) was shown not only to run\nfaster than NUTS on GPU but also sample from posteriors more efficiently.\nSequential Monte Carlo (SMC) samplers are another sampling method which instead\noutput weighted samples from the posterior. They are very amenable to\nparallelisation and therefore being run on GPUs while having additional\nflexibility in their choice of proposal over MCMC. We incorporate (ChEEs-HMC)\nas a proposal into SMC samplers and demonstrate competitive but faster\nperformance than NUTS on a number of tasks.","main_category":"stat.CO","categories":"stat.CO,cs.LG,cs.SY,eess.SY,stat.ML","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02628v1","title":"Towards Computation- and Communication-efficient Computational Pathology","summary":"Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAGA) mechanism, which employs self-supervised learning to bridge\nthe information gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAGA framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAGA-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02654v1","title":"SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based\n  Reinforcement Learning","summary":"We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.","main_category":"cs.AI","categories":"cs.AI,cs.LO,cs.NE,I.2.6","published":"2025-04-03T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.02656v1","title":"Covering spiky annuli by planks","summary":"Answering Tarski's plank problem, Bang showed in 1951 that it is impossible\nto cover a convex body $K$ by planks whose total width is less than the minimal\nwidth $w(K)$ of $K$. In 2003, A. Bezdek asked whether the same statement holds\nif one is required to cover only the annulus obtained from $K$ by removing a\nhomothetic copy contained within. He showed that if $K$ is the unit square,\nthen saving width in a plank covering is not possible, provided that the\nhomothety factor is sufficiently small. White and Wisewell in 2006\ncharacterized polygons that possess this property. We generalize their\nconstructive result by showing that if $K$ is a convex disc or a convex body in\n3-space that is spiky in a minimal width direction, then for every $\\varepsilon\n\\in (0,1)$ it is possible to cut a homothetic copy $\\varepsilon K$ from the\ninterior of $K$ so that the remaining annulus can be covered by planks whose\ntotal width is strictly less than $w(K)$.","main_category":"math.MG","categories":"math.MG","published":"2025-04-03T14:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.02657v1","title":"Backward DVCS in a Sullivan process","summary":"Mesons' internal structure and dynamics may be accessed through hard\nexclusive electroproduction processes such as deeply virtual Compton scattering\nin both near forward and near backward kinematics. With the help of the\nSullivan process which allows us to use a nucleon target as a quasi-real $\\pi$\nmeson emitter, we study backward scattering in the framework of collinear QCD\nfactorization where pion-to-photon transition distribution amplitudes describe\nthe photon content of the $\\pi$ meson. We present a model of these TDAs based\non the overlap of lightfront wave functions primarily developed for generalized\nparton distributions, using a previously developed pion lightfront wave\nfunction and deriving a new model for the lightfront wave functions of the\nphoton. This leads us to an estimate of the cross-sections for JLab energies.\nWe conclude that deeply virtual $ep\\rightarrow e\\gamma M n$ processes, in\nbackward kinematics, may be experimentally discovered in the near future.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T14:52:59Z"}
{"aid":"http://arxiv.org/abs/2504.02659v1","title":"Spectropolarimetry for Discerning Geometry and Structure in\n  Circumstellar Media of Hot Massive Stars","summary":"Spectropolarimetric techniques are a mainstay of astrophysical inquiry,\nranging from Solar System objects to the Cosmic Background Radiation. This\nreview highlights applications of stellar polarimetry for massive hot stars,\nparticularly in the context of ultraviolet (UV) spaceborne missions. The\nprevalence of binarity in the massive star population and uncertainties\nregarding the degree of rotational criticality among hot stars raises important\nquestions about stellar interactions, interior structure, and even the\nlifetimes of evolutionary phases. These uncertainties have consequences for\nstellar population synthesis calculations. Spectropolarimetry is a key tool for\nextracting information about stellar and binary geometries. We review\nmethodologies involving electron scattering in circumstellar envelopes; gravity\ndarkening from rapid rotation; spectral line effects including the (a) \"line\neffect\", (b) Ohman effect, and (c) Hanle effect; and the imprint of\ninterstellar polarization on measurements. Finally, we describe the Polstar UV\nspectropolarimetric SMEX mission concept as one means for employing these\ndiagnostics to clarify the state of high rotation and its impacts for massive\nstars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-03T14:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02663v1","title":"Development of Automated Data Quality Assessment and Evaluation Indices\n  by Analytical Experience","summary":"The societal need to leverage third-party data has driven the\ndata-distribution market and increased the importance of data quality\nassessment (DQA) in data transactions between organizations. However, DQA\nrequires expert knowledge of raw data and related data attributes, which\nhinders consensus-building in data purchasing. This study focused on the\ndifferences in DQAs between experienced and inexperienced data handlers. We\nperformed two experiments: The first was a questionnaire survey involving 41\nparticipants with varying levels of data-handling experience, who evaluated 12\ndata samples using 10 predefined indices with and without quality metadata\ngenerated by the automated tool. The second was an eye-tracking experiment to\nreveal the viewing behavior of participants during data evaluation. It was\nrevealed that using quality metadata generated by the automated tool can reduce\nmisrecognition in DQA. While experienced data handlers rated the quality\nmetadata highly, semi-experienced users gave it the lowest ratings. This study\ncontributes to enhancing data understanding within organizations and promoting\nthe distribution of valuable data by proposing an automated tool to support\nDQAs.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.02665v1","title":"Finite groups whose maximal subgroups have almost odd index","summary":"A recurring theme in finite group theory is understanding how the structure\nof a finite group is determined by the arithmetic properties of group\ninvariants. There are results in the literature determining the structure of\nfinite groups whose irreducible character degrees, conjugacy class sizes or\nindices of maximal subgroups are odd. These results have been extended to\ninclude those finite groups whose character degrees or conjugacy class sizes\nare not divisible by $4$. In this paper, we determine the structure of finite\ngroups whose maximal subgroups have index not divisible by $4$. As a\nconsequence, we obtain some new $2$-nilpotency criteria.","main_category":"math.GR","categories":"math.GR","published":"2025-04-03T15:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.02668v1","title":"Two-Stage nnU-Net for Automatic Multi-class Bi-Atrial Segmentation from\n  LGE-MRIs","summary":"Late gadolinium enhancement magnetic resonance imaging (LGE-MRI) is used to\nvisualise atrial fibrosis and scars, providing important information for\npersonalised atrial fibrillation (AF) treatments. Since manual analysis and\ndelineations of these images can be both labour-intensive and subject to\nvariability, we develop an automatic pipeline to perform segmentation of the\nleft atrial (LA) cavity, the right atrial (RA) cavity, and the wall of both\natria on LGE-MRI. Our method is based on a two-stage nnU-Net architecture,\ncombining 2D and 3D convolutional networks, and incorporates adaptive histogram\nequalisation to improve tissue contrast in the input images and morphological\noperations on the output segmentation maps. We achieve Dice similarity\ncoefficients of 0.92 +/- 0.03, 0.93 +/- 0.03, 0.71 +/- 0.05 and 95% Hausdorff\ndistances of (3.89 +/- 6.67) mm, (4.42 +/- 1.66) mm and (3.94 +/- 1.83) mm for\nLA, RA, and wall, respectively. The accurate delineation of the LA, RA and the\nmyocardial wall is the first step in analysing atrial structure in\ncardiovascular patients, especially those with AF. This can allow clinicians to\nprovide adequate and personalised treatment plans in a timely manner.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T15:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.02670v1","title":"Affordable AI Assistants with Knowledge Graph of Thoughts","summary":"Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-03T15:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.02686v1","title":"Degrees and prime power order zeros of characters of symmetric and\n  alternating groups","summary":"We show that the $p$-part of the degree of an irreducible character of a\nsymmetric group is completely determined by the set of vanishing elements of\n$p$-power order. As a corollary we deduce that the set of zeros of prime power\norder controls the degree of such a character. The same problem is analysed for\nalternating groups, where we show that when $p=2$ this data can only be\ndetermined up to two possibilities. We prove analogous statements for the\ndefect of the $p$-block containing the character and for the $p$-height of the\ncharacter.","main_category":"math.RT","categories":"math.RT,math.GR","published":"2025-04-03T15:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.02703v1","title":"Uncovering shifts in the history of Physics education: a systematic,\n  NLP-based, thematic analysis of articles from The Physics Teacher and Physics\n  Education journals (1966-2019)","summary":"This study explores the thematic evolution of articles in The Physics Teacher\nand Physics Education journals, over a critical period in modern history, from\nthe Cold War era to the pre-pandemic world (1966 - 2019). Using an NLP-based\ninductive topic modeling approach, we identify recurring themes that have\nshaped the physics education literature, including content-based topics,\nteaching methodologies, laboratory practices, curriculum development, and the\ninfluence of Physics Education Research (PER). Our findings reveal both\noverarching trends and distinct thematic preferences between the journals.\nPhysics Education has historically emphasized curriculum structures, social\naspects of education, and interdisciplinary connections, whereas The Physics\nTeacher has focused more on pedagogical strategies, demonstrations, and\npractical teaching tools. Over the past three decades, both journals have\nincreasingly incorporated discussions on technology, computation, and\nPER-driven instructional practices. By tracing these developments over five\ndecades, this study provides a broader perspective on how physics education has\nresponded to changing educational priorities, technological advancements, and\nresearch developments.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T15:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.02704v1","title":"EvoChain: A Framework for Tracking and Visualizing Smart Contract\n  Evolution","summary":"Tracking the evolution of smart contracts is challenging due to their\nimmutable nature and complex upgrade mechanisms. We introduce EvoChain, a\ncomprehensive framework and dataset designed to track and visualize smart\ncontract evolution. Building upon data from our previous empirical study,\nEvoChain models contract relationships using a Neo4j graph database and\nprovides an interactive web interface for exploration. The framework consists\nof a data layer, an API layer, and a user interface layer. EvoChain allows\nstakeholders to analyze contract histories, upgrade paths, and associated\nvulnerabilities by leveraging these components. Our dataset encompasses\napproximately 1.3 million upgradeable proxies and nearly 15,000 historical\nversions, enhancing transparency and trust in blockchain ecosystems by\nproviding an accessible platform for understanding smart contract evolution.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T15:41:48Z"}
{"aid":"http://arxiv.org/abs/2504.02706v1","title":"Learning quantum Gibbs states locally and efficiently","summary":"Learning the Hamiltonian underlying a quantum many-body system in thermal\nequilibrium is a fundamental task in quantum learning theory and experimental\nsciences. To learn the Gibbs state of local Hamiltonians at any inverse\ntemperature $\\beta$, the state-of-the-art provable algorithms fall short of the\noptimal sample and computational complexity, in sharp contrast with the\nlocality and simplicity in the classical cases. In this work, we present a\nlearning algorithm that learns each local term of a $n$-qubit $D$-dimensional\nHamiltonian to an additive error $\\epsilon$ with sample complexity\n$\\tilde{O}\\left(\\frac{e^{\\mathrm{poly}(\\beta)}}{\\beta^2\\epsilon^2}\\right)\\log(n)$.\nThe protocol uses parallelizable local quantum measurements that act within\nbounded regions of the lattice and near-linear-time classical post-processing.\nThus, our complexity is near optimal with respect to $n,\\epsilon$ and is\npolynomially tight with respect to $\\beta$. We also give a learning algorithm\nfor Hamiltonians with bounded interaction degree with sample and time\ncomplexities of similar scaling on $n$ but worse on $\\beta, \\epsilon$. At the\nheart of our algorithm is the interplay between locality, the\nKubo-Martin-Schwinger condition, and the operator Fourier transform at\narbitrary temperatures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-03T15:42:23Z"}
{"aid":"http://arxiv.org/abs/2504.02727v1","title":"Effect of new healthy and live food supplement on Anemia disease in\n  Wistar rats","summary":"Anemia is a decrease in hemoglobin and red blood cells and due to a decrease\nin hemoglobin, oxygen carrying capacity reduce. In this disease, the red blood\ncell the amount and volume decrease. In this research, healthy and live food\npowder were synthesized by a green route. This organic biomaterial was named\nNBS. The NBS healthy and live food powder has various vitamins, macro and micro\nmolecules, and ingredients. Twenty Wistar rats were randomly divided into 4\nequal groups, including control and treatment groups 1, 2 and 3. Nutritional\nsupplements for healthy living were administered orally via gavage to rats in\ngroups 1, 2, and 3 at 12.5, 25, and 50 mg/ kg, respectively, and within a\nperiod of 20 days, one day in between. There was no intervention in the control\ngroup in order to reach baseline blood factors. At the end of the study, blood\nsamples were taken from the heart, including blood-red blood cells, hemoglobin,\nhematocrit and platelets using a fully automated blood cell counting machine.\nThe results showed that the new dietary supplement reduced the level of\nhematocrit and platelets in the studied rats. The healthy and live food\nsupplement at a concentration of 50 mg / kg increased blood levels compared to\nthe control group. The results of this study showed that the use of healthy and\nlive food supplement increased blood factors compared to the control group.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-03T16:11:14Z"}
{"aid":"http://arxiv.org/abs/2504.02758v1","title":"ALMA uncovers optically thin and multi-component CO gas in the\n  outflowing circumnuclear disk of NGC1068","summary":"Active galactic nuclei (AGNs) influence their host galaxies through winds and\njets that can drive molecular outflows, traceable with CO line emissions using\nthe Atacama Large Millimeter Array (ALMA). Recent studies leveraging ALMA data\nhave proposed a three-dimensional outflow geometry in the nearby Seyfert II\ngalaxy NGC 1068, a key target for AGN unification theories. Using ALMA\nobservations of CO(2-1), CO(3-2), and CO(6-5) transitions at roughly 0.1\narcseconds (approximately 7 parsecs) resolution, we analyzed the temperature,\ndensity, and kinematics of NGC 1068's circumnuclear disk (CND), focusing on the\nmolecular outflow. Through local thermodynamic equilibrium (LTE) analysis, we\nderived column densities and rotational temperatures, indicating optically thin\ngas and CO-to-H2 (XCO) conversion factors between 4.8 and 9.6 times smaller\nthan the Milky Way value. The inferred molecular mass outflow rate is mostly\nbelow 5.5 solar masses per year, with the dominant contribution northeast of\nthe AGN. After subtracting the rotation curve of the CND, we modeled averaged\nline profiles in each region using single and multi-component Gaussian fits.\nSeveral profiles within or near the AGN wind bicone required multiple\ncomponents with significant velocity shifts, suggesting multi-component complex\noutflow kinematics. We observe lateral variation in CO kinematics along the AGN\nwind bicone and a misalignment between the molecular and ionized outflow\ndirections. These results imply that the dynamic impact of the ionized AGN wind\non the molecular gas in the CND may be limited. However, the molecular outflow\nshows a complex, asymmetric structure.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.02760v1","title":"Topological groupoids with involution and real algebraic stacks","summary":"To a topological groupoid endowed with an involution, we associate a\ntopological groupoid of fixed points, generalizing the fixed-point subspace of\na topological space with involution. We prove that when the topological\ngroupoid with involution arises from a Deligne-Mumford stack over $\\mathbb{R}$,\nthis fixed locus coincides with the real locus of the stack. This provides a\ntopological framework to study real algebraic stacks, and in particular real\nmoduli spaces. Finally, we propose a Smith-Thom type conjecture in this\nsetting, generalizing the Smith-Thom inequality for topological spaces endowed\nwith an involution.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.02766v1","title":"On Composable and Parametric Uncertainty in Systems Co-Design","summary":"Optimizing the design of complex systems requires navigating interdependent\ndecisions, heterogeneous components, and multiple objectives. Our monotone\ntheory of co-design offers a compositional framework for addressing this\nchallenge, modeling systems as Design Problems (DPs), representing trade-offs\nbetween functionalities and resources within partially ordered sets. While\ncurrent approaches model uncertainty using intervals, capturing worst- and\nbest-case bounds, they fail to express probabilistic notions such as risk and\nconfidence. These limitations hinder the applicability of co-design in domains\nwhere uncertainty plays a critical role. In this paper, we introduce a unified\nframework for composable uncertainty in co-design, capturing intervals,\ndistributions, and parametrized models. This extension enables reasoning about\nrisk-performance trade-offs and supports advanced queries such as experiment\ndesign, learning, and multi-stage decision making. We demonstrate the\nexpressiveness and utility of the framework via a numerical case study on the\nuncertainty-aware co-design of task-driven Unmanned Aerial Vehicle (UAV).","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-03T17:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.02775v1","title":"TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly\n  Detection","summary":"We aim to solve unsupervised anomaly detection in a practical challenging\nenvironment where the normal dataset is both contaminated with defective\nregions and its product class distribution is tailed but unknown. We observe\nthat existing models suffer from tail-versus-noise trade-off where if a model\nis robust against pixel noise, then its performance deteriorates on tail class\nsamples, and vice versa. To mitigate the issue, we handle the tail class and\nnoise samples independently. To this end, we propose TailSampler, a novel class\nsize predictor that estimates the class cardinality of samples based on a\nsymmetric assumption on the class-wise distribution of embedding similarities.\nTailSampler can be utilized to sample the tail class samples exclusively,\nallowing to handle them separately. Based on these facets, we build a\nmemory-based anomaly detection model TailedCore, whose memory both well\ncaptures tail class information and is noise-robust. We extensively validate\nthe effectiveness of TailedCore on the unsupervised long-tail noisy anomaly\ndetection setting, and show that TailedCore outperforms the state-of-the-art in\nmost settings.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T17:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.02813v1","title":"Regularity and bounded $t$-structures for algebraic stacks","summary":"Our work shows (the expected) cohomological characterization for regularity\nof (Noetherian) algebraic stacks; such a stack is regular if and only if all\ncomplexes with bounded and coherent cohomology are perfect. This naturally\nenables us to extend various statements known for schemes to algebraic stacks.\nIn particular, the conjectures by Antieau--Gepner--Heller and Bondal--Van den\nBergh, both resolved for schemes by Neeman, are proven for suitable algebraic\nstacks.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-03T17:55:36Z"}
{"aid":"http://arxiv.org/abs/2504.02815v1","title":"Logarithmic entanglement lightcone from eigenstate correlations in the\n  many-body localised phase","summary":"We investigate the operator entanglement of the time-evolution operator\nthrough the framework of eigenstate correlations. Focusing on strongly\ndisordered quantum many-body systems in the many-body localised (MBL) regime,\nwe analyse the operator entanglement across various spatiotemporal cuts,\nrevealing the logarithmic lightcone of entanglement spreading. We demonstrate\nthat this logarithmic lightcone arises directly from a hierarchy of\nenergyscales and lengthscales encoded in eigenstate correlations. By\ncharacterising the statistics of these hierarchical scales, we develop a\nmicroscopic theory for the spatiotemporal structure of entanglement spreading\nin MBL systems -- without invoking phenomenological constructs such as\n$\\ell$-bits. This approach reveals the fundamental connection between\neigenstate correlations and the emergent entanglement structure in MBL systems.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.quant-gas,cond-mat.stat-mech,quant-ph","published":"2025-04-03T17:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.02821v1","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language\n  Models","summary":"Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.04725v1","title":"Prethermalization in Fermi-Pasta-Ulam-Tsingou chains","summary":"The observation of the Fermi-Pasta-Ulam-Tsingou (FPUT) paradox, namely the\nlack of equipartition in the evolution of a normal mode in a nonlinear chain on\nunexpectedly long times, is arguably the most famous numerical experiment in\nthe history of physics. Since seventy years after its publication, most studies\nin FPUT chains still focus on long wavelength initial states similar to the\noriginal paper. It is shown here that all characteristic features of the FPUT\nparadox are rendered even more striking if short(er) wavelength modes are\nevolved instead. Since not every normal mode leads to equipartition, we also\nprovide a simple technique to predict which modes, and in what order, are\nexcited starting from an initial mode (root) in $\\alpha$-FPUT chains. The\nexcitation sequences associated with a root are then shown to spread energy at\ndifferent speeds, leading to prethermalization regimes that become longer as a\nfunction of mode excitation number. This effect is visible in observables such\nas mode energies and spectral entropies and, surprisingly, also in the time\nevolution of invariant quantities such as Lyapunov times and Kolmogorov-Sinai\nentropies. Our findings generalize the original FPUT experiment, provide an\noriginal look at the paradox's source, and enrich the vast literature dedicated\nto studying equipartition in classical many-body systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,nlin.CD","published":"2025-04-07T04:36:42Z"}
{"aid":"http://arxiv.org/abs/2504.04727v1","title":"Regression Model for Measurement of Wound Dimensions by Webcam Scanners\n  and Time-of-Flight Sensors","summary":"One use of image processing is for medical equipment such as wound\nidentification. This technology is carried out non-invasively by taking images\nso as to avoid direct touch with the wound thereby reducing the possibility of\ninfection. The images obtained using the RGB camera will be used for color\nsegmentation which will measure the wound dimensions. However, the image data\nis in the form of a raster, the distance will affect the pixel size. Therefore,\nit is necessary to consider the distance of the camera measurement to the\nobject. The time-of-flight (ToF) method with a lidar sensor is used to\ncalculate the distance of the camera to the object. It is necessary to\ncalculate the ratio of the distance to the number of pixels obtained so that\nthe value is always consistent. This study analyzed the use of appropriate\nratios and regression systems on a webcam and a lidar sensor for measuring\nwound dimensions. The results of the study show that there is a regression\nmodel with a second-order polynomial relationship for the distance and number\nof pixels obtained consistently with an error value of less than 5% which shows\nvery good results","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.ins-det","published":"2025-04-07T04:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.04734v1","title":"Teaching Data Science Students to Sketch Privacy Designs through\n  Heuristics (Extended Technical Report)","summary":"Recent studies reveal that experienced data practitioners often draw sketches\nto facilitate communication around privacy design concepts. However, there is\nlimited understanding of how we can help novice students develop such\ncommunication skills. This paper studies methods for lowering novice data\nscience students' barriers to creating high-quality privacy sketches. We first\nconducted a need-finding study (N=12) to identify barriers students face when\nsketching privacy designs. We then used a human-centered design approach to\nguide the method development, culminating in three simple, text-based\nheuristics. Our user studies with 24 data science students revealed that simply\npresenting three heuristics to the participants at the beginning of the study\ncan enhance the coverage of privacy-related design decisions in sketches,\nreduce the mental effort required for creating sketches, and improve the\nreadability of the final sketches.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-04-07T05:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.04739v1","title":"MedGNN: Capturing the Links Between Urban Characteristics and Medical\n  Prescriptions","summary":"Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-07T05:35:16Z"}
{"aid":"http://arxiv.org/abs/2504.04744v1","title":"Grounding 3D Object Affordance with Language Instructions, Visual\n  Observations and Interactions","summary":"Grounding 3D object affordance is a task that locates objects in 3D space\nwhere they can be manipulated, which links perception and action for embodied\nintelligence. For example, for an intelligent robot, it is necessary to\naccurately ground the affordance of an object and grasp it according to human\ninstructions. In this paper, we introduce a novel task that grounds 3D object\naffordance based on language instructions, visual observations and\ninteractions, which is inspired by cognitive science. We collect an Affordance\nGrounding dataset with Points, Images and Language instructions (AGPIL) to\nsupport the proposed task. In the 3D physical world, due to observation\norientation, object rotation, or spatial occlusion, we can only get a partial\nobservation of the object. So this dataset includes affordance estimations of\nobjects from full-view, partial-view, and rotation-view perspectives. To\naccomplish this task, we propose LMAffordance3D, the first multi-modal,\nlanguage-guided 3D affordance grounding network, which applies a\nvision-language model to fuse 2D and 3D spatial features with semantic\nfeatures. Comprehensive experiments on AGPIL demonstrate the effectiveness and\nsuperiority of our method on this task, even in unseen experimental settings.\nOur project is available at https://sites.google.com/view/lmaffordance3d.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-07T05:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.04751v1","title":"Unsupervised Estimation of Nonlinear Audio Effects: Comparing\n  Diffusion-Based and Adversarial approaches","summary":"Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-07T05:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.04757v1","title":"The Complexity of Maximal Common Subsequence Enumeration","summary":"Frequent pattern mining is widely used to find ``important'' or\n``interesting'' patterns in data. While it is not easy to mathematically define\nsuch patterns, maximal frequent patterns are promising candidates, as frequency\nis a natural indicator of relevance and maximality helps to summarize the\noutput. As such, their mining has been studied on various data types, including\nitemsets, graphs, and strings. The complexity of mining maximal frequent\nitemsets and subtrees has been thoroughly investigated (e.g., [Boros et al.,\n2003], [Uno et al., 2004]) in the literature. On the other hand, while the idea\nof mining frequent subsequences in sequential data was already introduced in\nthe seminal paper [Agrawal et al., 1995], the complexity of the problem is\nstill open.\n  In this paper, we investigate the complexity of the maximal common\nsubsequence enumeration problem, which is both an important special case of\nmaximal frequent subsequence mining and a generalization of the classic longest\ncommon subsequence (LCS) problem. We show the hardness of enumerating maximal\ncommon subsequences between multiple strings, ruling out the possibility of an\n\\emph{output-polynomial time} enumeration algorithm under $P \\neq NP$, that is,\nan algorithm that runs in time ${\\rm poly}(|\\mathcal I| + N)$, where $|\\mathcal\nI|$ and $N$ are the size of the input and number of output solutions,\nrespectively. To circumvent this intractability, we also investigate the\nparameterized complexity of the problem, and show several results when the\nalphabet size, the number of strings, and the length of a string are taken into\naccount as parameters.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-07T06:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.04760v1","title":"The spin measurement of the black hole SLX 1746-331 using Insight-HXMT\n  observations","summary":"We present an X-ray spectral analysis of a black hole X-ray binary SLX\n1746-331 during the 2023 outburst using five \\textit{Insight}-HXMT\nobservations. We jointly use the reflection model \\texttt{relxillcp} and the\ngeneral relativistic thermal thin disk model \\texttt{kerrbb} to fit the spectra\nfrom 2 - 100 keV. By jointly fitting the five spectra, we constrained the black\nhole mass to be $M=5.8\\pm 0.3 M_{\\odot}$ and dimensionless spin parameter to be\n$a_{*}=0.88^{+0.01}_{-0.02}$ (90 percent statistical confidence). The\nreflection model shows that SLX 1746-331 is a high-inclination system with the\ninclination angle $i=63.7^{+1.3}_{-1.0}$ degrees, the accretion disk has a\ndensity $\\rm{log}N\\sim 16 ~\\rm cm^{-3}$. In addition, with the different\nreflection model \\texttt{relxilllp}, which assumes a lamp-post geometry corona,\nwe still give similar results.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.04764v1","title":"Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model","summary":"Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T06:31:38Z"}
{"aid":"http://arxiv.org/abs/2504.04788v1","title":"Parametrically driven Kerr temporal soliton crystals","summary":"We theoretically investigate the excitation, dynamics of parametrically\ndriven soliton crystals and their resulting frequency combs in doubly resonant\ncavities with quadratic and cubic nonlinearities. We demonstrate that soliton\ncrystal states act as strong attractors, where pump depletion and pump phase\nplay crucial roles in their stabilization by ensuring equal soliton spacing and\ncoherence. The number of solitons is primarily determined by driving strength.\nAdditionally, we identify a novel nonlinear state in parametric soliton\ncrystals in which circulating solitons periodically alternate their intensities\nand group velocities, a phenomenon we term the soliton-pursuing states.\nFurthermore, due to the phase-selective nature of the optical parametric\nprocess, we show how different configurations of soliton phases influence the\noptical frequency combs, which may enable generating odd harmonic combs.","main_category":"physics.optics","categories":"physics.optics,nlin.PS","published":"2025-04-07T07:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.04793v1","title":"X-class flare on Dec 31, 2023, observed by the Solar Ultraviolet Imaging\n  Telescope on board Aditya-L1","summary":"We present the multi-wavelength study of the ejection of a plasma blob from\nthe limb flare SOL2023-12-31T21:36:00 from NOAA 13536 observed by the Solar\nUltraviolet Imaging Telescope (SUIT) on board Aditya-L1. We use SUIT\nobservations along with those from Atmospheric Imaging Assembly (AIA) on board\nSDO and Spectrometer/Telescope for Imaging X-rays (STIX) on board Solar Orbiter\nto infer the kinematics and thermal nature of the ejected blob and its\nconnection to the associated flare. The observations show that the flare was\ncomprised of two eruptions. The blob was ejected during the first eruption and\nlater accelerated to velocities over 1500 km/s measured at a maximum projected\nheight of ~ 178 Mm from the Sun's surface. The acceleration of the ejected\nplasma blob is co-temporal with the bursty appearance of the hard X-ray light\ncurve recorded by STIX. Radio spectrogram observations from STEREO-A/WAVES and\nRSTN reveal type III bursts at the same time, indicative of magnetic\nreconnection. DEM analysis using AIA observations suggests the plasma blob is\ncomprised of cooler and denser plasma in comparison to the ambient corona. To\nthe best of our knowledge, this is the first observation of such a plasma blob\nin the NUV, providing crucial measurements for eruption thermodynamics.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-07T07:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.04794v1","title":"Enhancing Trust in AI Marketplaces: Evaluating On-Chain Verification of\n  Personalized AI models using zk-SNARKs","summary":"The rapid advancement of artificial intelligence (AI) has brought about\nsophisticated models capable of various tasks ranging from image recognition to\nnatural language processing. As these models continue to grow in complexity,\nensuring their trustworthiness and transparency becomes critical, particularly\nin decentralized environments where traditional trust mechanisms are absent.\nThis paper addresses the challenge of verifying personalized AI models in such\nenvironments, focusing on their integrity and privacy. We propose a novel\nframework that integrates zero-knowledge succinct non-interactive arguments of\nknowledge (zk-SNARKs) with Chainlink decentralized oracles to verify AI model\nperformance claims on blockchain platforms. Our key contribution lies in\nintegrating zk-SNARKs with Chainlink oracles to securely fetch and verify\nexternal data to enable trustless verification of AI models on a blockchain.\nOur approach addresses the limitations of using unverified external data for AI\nverification on the blockchain while preserving sensitive information of AI\nmodels and enhancing transparency. We demonstrate our methodology with a linear\nregression model predicting Bitcoin prices using on-chain data verified on the\nSepolia testnet. Our results indicate the framework's efficacy, with key\nmetrics including proof generation taking an average of 233.63 seconds and\nverification time of 61.50 seconds. This research paves the way for transparent\nand trustless verification processes in blockchain-enabled AI ecosystems,\naddressing key challenges such as model integrity and model privacy protection.\nThe proposed framework, while exemplified with linear regression, is designed\nfor broader applicability across more complex AI models, setting the stage for\nfuture advancements in transparent AI verification.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-07T07:38:29Z"}
{"aid":"http://arxiv.org/abs/2504.04818v1","title":"SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection\n  Enhancement","summary":"Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.04821v1","title":"A Customized SAT-based Solver for Graph Coloring","summary":"We introduce ZykovColor, a novel SAT-based algorithm to solve the graph\ncoloring problem working on top of an encoding that mimics the Zykov tree. Our\nmethod is based on an approach of H\\'ebrard and Katsirelos (2020) that employs\na propagator to enforce transitivity constraints, incorporate lower bounds for\nsearch tree pruning, and enable inferred propagations. We leverage the recently\nintroduced IPASIR-UP interface for CaDiCal to implement these techniques with a\nSAT solver. Furthermore, we propose new features that take advantage of the\nunderlying SAT solver. These include modifying the integrated decision strategy\nwith vertex domination hints and using incremental bottom-up search that allows\nto reuse learned clauses from previous calls. Additionally, we integrate a more\nefficient clique computation to improve the lower bounds during the search. We\nvalidate the effectiveness of each new feature through an experimental\nanalysis. ZykovColor outperforms other state-of-the-art graph coloring\nimplementations on the DIMACS benchmark set. Further experiments on random\nErd\\H{o}s-R\\'enyi graphs show that our new approach dominates state-of-the-art\nSAT-based methods for both very sparse and highly dense graphs.","main_category":"cs.DM","categories":"cs.DM,cs.AI,cs.DS,cs.LO,G.2.2","published":"2025-04-07T08:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.04848v1","title":"Some remarks on almost locally uniformly rotund points","summary":"We study the relations between different notions of almost locally uniformly\nrotund points that appear in literature. We show that every non-reflexive\nBanach space admits an equivalent norm having a point in the corresponding unit\nsphere which is not almost locally uniformly rotund, and which is strongly\nexposed by all its supporting functionals. This result is in contrast with a\ncharacterization due to P. Bandyopadhyay, D. Huang, and B.-L. Lin from 2004. We\nalso show that such a characterization remains true in reflexive Banach spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-07T09:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04851v1","title":"Nonlinear Phase Gates as Airy Transforms of the Wigner Function","summary":"Low-order nonlinear phase gates allow the construction of versatile\nhigher-order nonlinearities for bosonic systems and grant access to continuous\nvariable quantum simulations of many unexplored aspects of nonlinear quantum\ndynamics. The resulting nonlinear transformations produce, even with small\nstrength, multiple regions of negativity in the Wigner function and thus show\nan immediate departure from classical phase space. Towards the development of\nrealistic, bounded versions of these gates we show that the action of a\nquartic-bounded cubic gate on an arbitrary multimode quantum state in phase\nspace can be understood as an Airy transform of the Wigner function. This\ntoolbox generalises the symplectic transformations associated with Gaussian\noperations and allows for the practical calculation, analysis and\ninterpretation of explicit Wigner functions and the quantum non-Gaussian\nphenomena resulting from bounded nonlinear potentials.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T09:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04890v1","title":"Stellar isotropic model in the symmetric teleparallel equivalent of\n  general relativity theory","summary":"Recently, the theory of symmetric teleparallel equivalent of general\nrelativity (STEGR) has gained much interest in the cosmology and astrophysics\ncommunity. Within this theory, we discuss the method of deriving a stellar\nisotropic model. In this respect, we implement the equations of motion of STEGR\ntheory to a spacetime that is symmetric in a spherical manner, resulting in a\nset of nonlinear differential equations with more unknowns than equations. To\nsolve this issue, we assume a special form of $g_{tt}$, and suppose a null\nvalue of the anisotropy to obtain the form of $g_{rr}$. We then investigate the\npossibility of obtaining an isotropic stellar model consistent with\nobservational data. To test the stability of our model, we apply the adiabatic\nindex and the Tolman-Oppenheimer-Volkoff equation. Furthermore, we examine our\nmodel using different observed values of radii and masses of pulsars, showing\nthat all of them fit in a consistent way.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-07T09:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.04892v1","title":"Recent progress on second-order elliptic and parabolic equations in\n  double divergence form","summary":"This article presents a comprehensive overview and supplement to recent\ndevelopments in second-order elliptic partial differential equations formulated\nin double divergence form, along with an exploration of their parabolic\ncounterparts.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T10:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.04917v1","title":"Modeling the circumstellar interaction around SN 2004gq","summary":"The relationship between the mass-loss history and final evolutionary stage\nof massive stars and the properties of the observable supernova (SN) is still\nunder debate. This is especially true for stripped-envelope (Type Ib/c) SNe,\nwhere the progenitor ejects a considerably large amount of material during its\nevolution, which can lead to a circumstellar medium relatively close to the\nexploding star. Moreover, when the star explodes as a SN, this matter may\ncontribute significantly to the generated luminosity because of the\ninteraction. However, the trace of this circumstellar interaction can only be\ninvestigated for a couple of Type Ib/c SNe, and the nature of a close (within\naround $10^{15}$ cm) circumstellar matter (CSM) has also been largely\nunexplored for these objects.\n  Here, we present the results of our radio and bolometric light curve (LC)\nanalysis related to SN 2004gq. We describe a combined model that explains the\nunusual LC properties of this event and supports the circumstellar interaction\nscenario. For that, we computed the quasi-bolometric LC of the SN and fit this\nwith a multicomponent model to gain information on the progenitor and the\nsurrounding circumstellar medium. We also analyzed the available radio LCs\n(taken at 1.4,\\ 4.9 and 8.5 GHz) of SN 2004gq to verify our estimated average\nmass-loss rate, which is one of the most crucial physical properties related to\nCSM models.\n  We infer reasonable parameters for SN 2004gq using radioactive decay and\nmagnetar energy input. To power the entire LC, we must also add an extra energy\nsource related to the CSM. We determine the most essential parameter of this\nmedium: the average mass-loss rate from both LC and radio data fitting. We find\nthat the suggested hidden circumstellar interaction is a viable mechanism that\nprovides the required energy deficiency and that it can be estimated using a\nsimple semi-analytic model.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T10:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.04918v1","title":"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B","summary":"As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04919v1","title":"Distorted Sounds: Unlocking the Physics of Modern Music","summary":"In the production of modern music, the musical characteristics of the guitar\nor keyboard amplifier play an integral role in the creative process. This\narticle explores the physics of music with an emphasis on the role of\ndistortion in the amplification. In particular, we derive and illustrate how a\ndistorted amplifier creates new musical notes that are not played by the\nmusician, greatly simplifying the playing technique. In providing a\ncomprehensive understanding, we commence with a discussion of the physics of\nmusic, highlighting the harmonic series and its relation to pleasing harmonies.\nThis is placed in the context of the standard music notation of intervals and\ntheir relation to note frequency ratios. We then discuss the problems of tuning\nan instrument and why the equal temperament of standard guitar tuners is\nincompatible with good sounding music when amplifier distortion is involved.\nDrawing on the basic trigonometric identities for angle sums and differences,\nwe show how the nonlinear amplification of a distorted amplifier, generates new\nnotes not played by the musician. Here the importance of setting your guitar\ntuner aside and using your ear to tune is emphasised. We close with a\ndiscussion of how humans decipher musical notes and why some highly distorted\nguitar chords give the impression of low notes that are not actually there.\nThis article will be of assistance to students interested in the physics of\nmusic and lecturers seeking fascinating and relevant applications of\nmathematical trigonometric relations and physics to capture the attention of\ntheir students.","main_category":"physics.pop-ph","categories":"physics.pop-ph","published":"2025-04-07T11:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.04921v1","title":"Expectations vs Reality -- A Secondary Study on AI Adoption in Software\n  Testing","summary":"In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-07T11:03:54Z"}
{"aid":"http://arxiv.org/abs/2504.04922v1","title":"Real-time tuneable bright bonding plasmonic modes in Ga nanostructures","summary":"The precise control of nanogaps is crucial for plasmonic nanoassemblies,\nwhere plasmon hybridization is highly sensitive to gap size and geometry. This\nsensitivity enables fine-tuning of the resonance wavelength and near-field\nenhancement, offering the potential for advanced optical applications. However,\nconventional lithographic techniques for gap modulation are constrained to\ndiscrete values and face challenges in achieving nanometer order of\nseparations. Such limitations hinder the comprehensive study of plasmon\ncoupling across varying interaction regimes. Overcoming these challenges is\nessential for advancing nanoplasmonic research and its practical applications.\nHerein, we demonstrate a tuneable plasmonic device in which real-time\ntunability of this hybridization mode is achieved via manipulation of the\ninter-droplet gap of liquid metal nanoparticles by macroscopic physical\ndeformation. In particular, we show that the optical spectra obtained from the\nsample shift towards higher energy on the application of a linear strain,\nresulting in an increase of inter-droplet gaps leading to a direct probing of\nthe bright modes in situ. Our method thus offers a novel means of exploring the\nfundamental concept of real-time tuneable plasmon hybridization as well as\ntuning of nanoparticle assembly with any desired gap in a controlled manner.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T11:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.04926v1","title":"Coupling of AlfvÃ©n and magnetosonic waves in rotating Hall\n  magnetoplasmas","summary":"We study the linear theory of magnetohydrodynamic (MHD) waves, namely the\nAlfv{\\'e}n and the fast and slow magnetosonic modes in a rotating Hall-MHD\nplasma with the effects of the obliqueness of the external magnetic field and\nthe Coriolis force and show that these waves can be coupled either by the\ninfluence of the Coriolis force or the Hall effects. To this end, we derive a\ngeneral form of the linear dispersion relation for these coupled modes by the\ncombined influence of the Coriolis force and the Hall effects and analyze\nnumerically their characteristics in three different plasma-$\\beta$ regimes:\n$\\beta\\sim1$, $\\beta>1$, and $\\beta<1$, including some particular cases. We\nshow that while the coupling between the Alfv{\\'e}n and the fast magnetosonic\nmodes is strong in the low-$\\beta$ $(\\beta\\lesssim1)$ regime and the wave\ndispersion appears in the form of a thumb curve, in the high-$\\beta~(\\beta>1)$\nregime, the strong coupling can occur between the Alfv{\\'e}n and the slow\nmagnetosonic modes and the dispersion appears in the form of a teardrop curve.\nSwitching of the coupling in the regime of $\\beta\\sim1$ can occur, i.e.,\ninstead of a thumb curve, a teardrop curve appears when the obliqueness of\npropagation and rotational angle are close to $70^\\circ$ or more (but less than\n$90^\\circ$). Implications of our results to solar and fusion plasmas are\nbriefly discussed.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T11:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.04933v1","title":"Deformation of the Heisenberg-Weyl algebra and the Lie superalgebra\n  $\\mathfrak{osp}\\left( {1|2} \\right)$: exact solution for the quantum harmonic\n  oscillator with a position-dependent mass","summary":"We propose a new deformation of the quantum harmonic oscillator\nHeisenberg-Weyl algebra with a parameter $a>-1$. This parameter is introduced\nthrough the replacement of the homogeneous mass $m_0$ in the definition of the\nmomentum operator $\\hat p_x$ as well as in the creation-annihilation operators\n$\\hat a^\\pm$ with a mass varying with position $x$. The realization of such a\ndeformation is shown through the exact solution of the corresponding\nSchr\\\"odinger equation for the non-relativistic quantum harmonic oscillator\nwithin the canonical approach. The obtained analytical expression of the energy\nspectrum consists of an infinite number of equidistant levels, whereas the\nwavefunctions of the stationary states of the problem under construction are\nexpressed through the Hermite polynomials. Then, the Heisenberg-Weyl algebra\ndeformation is generalized to the case of the Lie superalgebra\n$\\mathfrak{osp}\\left( {1|2} \\right)$. It is shown that the realization of such\na generalized superalgebra can be performed for the parabose quantum harmonic\noscillator problem, the mass of which possesses a behavior completely\noverlapping with the position-dependent mass of the canonically deformed\nharmonic oscillator problem. This problem is solved exactly for both even and\nodd stationary states. It is shown that the energy spectrum of the deformed\nparabose oscillator is still equidistant, however, both even and odd state\nwavefunctions are now expressed through the Laguerre polynomials. Some basic\nlimit relations recovering the canonical harmonic oscillator with constant mass\nare also discussed briefly.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-07T11:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.04944v1","title":"Multiobjective Optimization under Uncertainties using Conditional Pareto\n  Fronts","summary":"In this work, we propose a novel method to tackle the problem of\nmultiobjective optimization under parameteric uncertainties, by considering the\nConditional Pareto Sets and Conditional Pareto Fronts. Based on those\nquantities we can define the probability of coverage of the Conditional Pareto\nSet which can be interpreted as the probability for a design to be optimal in\nthe Pareto sense. Due to the computational cost of such an approach, we\nintroduce an Active Learning method based on Gaussian Process Regression in\norder to improve the estimation of this probability, which relies on a\nreformulation of the EHVI. We illustrate those methods on a few toy problems of\nmoderate dimension, and on the problem of designing a cabin to highlight the\ndifferences in solutions brought by different formulations of the problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T11:30:53Z"}
{"aid":"http://arxiv.org/abs/2504.04947v1","title":"Phase transitions in swarm optimization algorithms","summary":"Natural systems often exhibit chaotic behavior in their space-time evolution.\nSystems transiting between chaos and order manifest a potential to compute, as\nshown with cellular automata and artificial neural networks. We demonstrate\nthat swarms optimisation algorithms also exhibit transitions from chaos,\nanalogous to motion of gas molecules, when particles explore solution space\ndisorderly, to order, when particles follow a leader, similar to molecules\npropagating along diffusion gradients in liquid solutions of reagents. We\nanalyse these `phase-like' transitions in swarm optimization algorithms using\nrecurrence quantification analysis and Lempel-Ziv complexity estimation. We\ndemonstrate that converging and non-converging iterations of the optimization\nalgorithms are statistically different in a view of applied chaos, complexity\nand predictability estimating indicators.","main_category":"physics.comp-ph","categories":"physics.comp-ph,nlin.CD,physics.data-an","published":"2025-04-07T11:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.04954v1","title":"GOTHAM: Graph Class Incremental Learning Framework under Weak\n  Supervision","summary":"Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.04955v1","title":"The Short-spacing Interferometer Array for Global 21-cm Signal Detection\n  (SIGMA): Design of the Antennas and Layout","summary":"Numerous experiments have been designed to investigate the Cosmic Dawn (CD)\nand Epoch of Reionization (EoR) by examining redshifted 21-cm emissions from\nneutral hydrogen. Detecting the global spectrum of redshifted 21-cm signals is\ntypically achieved through single-antenna experiments. However, this global\n21-cm signal is deeply embedded in foreground emissions, which are about four\norders of magnitude stronger. Extracting this faint signal is a significant\nchallenge, requiring highly precise instrumental calibration. Additionally,\naccurately modelling receiver noise in single-antenna experiments is inherently\ncomplex. An alternative approach using a short-spacing interferometer is\nexpected to alleviate these difficulties because the noise in different\nreceivers is uncorrelated and averages to zero upon cross-correlation. The\nShort-spacing Interferometer array for Global 21-cm Signal detection (SIGMA) is\nan upcoming experiment aimed at detecting the global CD/EoR signal using this\napproach. We describe the SIGMA system with a focus on optimal antenna design\nand layout, and propose a framework to address cross-talk between antennas in\nfuture calibrations. The SIGMA system is intended to serve as a prototype to\ngain a better understanding of the system's instrumental effects and to\noptimize its performance further.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-07T11:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.04975v1","title":"Geometric quantization of generalized Hirzebruch fibrations","summary":"Hirzebruch surfaces, defined as the projectivization of line bundles over\n$\\C\\mathbb{P}^1$, support a toric action and thus represent an infinite class\nof symplectic toric manifolds of complex dimension 2. In this paper, an\ninfinite class of toric manifolds given as projective bundles over\n$\\mathbb{C}\\mathbb{P}^d$ will be constructed for every complex dimension $d$\nand it will be shown that each manifold supports a symplectic structure. With\nthe toric and symplectic structure of the manifolds at our disposal, we then\nstudy their geometric quantization and how it relates to different values of\nthe twisting parameter of the fibrations.","main_category":"math.SG","categories":"math.SG","published":"2025-04-07T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.04996v1","title":"Laplacian eigenvalues for large negative Robin parameters on domains\n  with outward peaks","summary":"We study the asymptotic behavior of individual eigenvalues of the Laplacian\nin domains with outward peaks for large negative Robin parameters. A large\nclass of cross-sections is allowed, and the resulting asymptotic expansions\nreflect both the sharpness of the peak and the geometric shape of its\ncross-section. The results are an extension of previous works dealing with\npeaks whose cross-sections are balls.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-07T12:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.05042v1","title":"Lattice packing of spheres in high dimensions using a stochastically\n  evolving ellipsoid","summary":"We prove that in any dimension $n$ there exists an origin-symmetric ellipsoid\n${\\mathcal{E}} \\subset {\\mathbb{R}}^n$ of volume $ c n^2 $ that contains no\npoints of ${\\mathbb{Z}}^n$ other than the origin, where $c > 0$ is a universal\nconstant. Equivalently, there exists a lattice sphere packing in\n${\\mathbb{R}}^n$ whose density is at least $cn^2 \\cdot 2^{-n}$. Previously\nknown constructions of sphere packings in ${\\mathbb{R}}^n$ had densities of the\norder of magnitude of $n \\cdot 2^{-n}$, up to logarithmic factors. Our proof\nutilizes a stochastically evolving ellipsoid that accumulates at least $c n^2$\nlattice points on its boundary, while containing no lattice points in its\ninterior except for the origin.","main_category":"math.MG","categories":"math.MG,math.NT,math.PR","published":"2025-04-07T13:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.05048v1","title":"Secure Communications for All Users in Low-Resolution IRS-aided Systems\n  Under Imperfect and Unknown CSI","summary":"Provisioning secrecy for all users, given the heterogeneity and uncertainty\nof their channel conditions, locations, and the unknown location of the\nattacker/eavesdropper, is challenging and not always feasible. This work takes\nthe first step to guarantee secrecy for all users where a low resolution\nintelligent reflecting surfaces (IRS) is used to enhance legitimate users'\nreception and thwart the potential eavesdropper (Eve) from intercepting. In\nreal-life scenarios, due to hardware limitations of the IRS' passive reflective\nelements (PREs), the use of a full-resolution (continuous) phase shift (CPS) is\nimpractical. In this paper, we thus consider a more practical case where the\nphase shift (PS) is modeled by a low-resolution (quantized) phase shift (QPS)\nwhile addressing the phase shift error (PSE) induced by the imperfect channel\nstate information (CSI). To that end, we aim to maximize the minimum secrecy\nrate (SR) among all users by jointly optimizing the transmitter's beamforming\nvector and the IRS's passive reflective elements (PREs) under\nperfect/imperfect/unknown CSI. The resulting optimization problem is non-convex\nand even more complicated under imperfect/unknown CSI.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T13:18:03Z"}
{"aid":"http://arxiv.org/abs/2504.05084v1","title":"Speech-to-Trajectory: Learning Human-Like Verbal Guidance for Robot\n  Motion","summary":"Full integration of robots into real-life applications necessitates their\nability to interpret and execute natural language directives from untrained\nusers. Given the inherent variability in human language, equivalent directives\nmay be phrased differently, yet require consistent robot behavior. While Large\nLanguage Models (LLMs) have advanced language understanding, they often falter\nin handling user phrasing variability, rely on predefined commands, and exhibit\nunpredictable outputs. This letter introduces the Directive Language Model\n(DLM), a novel speech-to-trajectory framework that directly maps verbal\ncommands to executable motion trajectories, bypassing predefined phrases. DLM\nutilizes Behavior Cloning (BC) on simulated demonstrations of human-guided\nrobot motion. To enhance generalization, GPT-based semantic augmentation\ngenerates diverse paraphrases of training commands, labeled with the same\nmotion trajectory. DLM further incorporates a diffusion policy-based trajectory\ngeneration for adaptive motion refinement and stochastic sampling. In contrast\nto LLM-based methods, DLM ensures consistent, predictable motion without\nextensive prompt engineering, facilitating real-time robotic guidance. As DLM\nlearns from trajectory data, it is embodiment-agnostic, enabling deployment\nacross diverse robotic platforms. Experimental results demonstrate DLM's\nimproved command generalization, reduced dependence on structured phrasing, and\nachievement of human-like motion.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T13:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.05097v1","title":"State Tuning: State-based Test-Time Scaling on RWKV-7","summary":"Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T14:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05098v1","title":"Shelling and Sinking Graphs on the Sphere","summary":"We describe a promising approach to efficiently morph spherical graphs,\nextending earlier approaches of Awartani and Henderson [Trans. AMS 1987] and\nKobourov and Landis [JGAA 2006]. Specifically, we describe two methods to morph\nshortest-path triangulations of the sphere by moving their vertices along\nlongitudes into the southern hemisphere; we call a triangulation sinkable if\nsuch a morph exists. Our first method generalizes a longitudinal shelling\nconstruction of Awartani and Henderson; a triangulation is sinkable if a\nspecific orientation of its dual graph is acyclic. We describe a simple\npolynomial-time algorithm to find a longitudinally shellable rotation of a\ngiven spherical triangulation, if one exists; we also construct a spherical\ntriangulation that has no longitudinally shellable rotation. Our second method\nis based on a linear-programming characterization of sinkability. By\nidentifying its optimal basis, we show that this linear program can be solved\nin $O(n^{\\omega/2})$ time, where $\\omega$ is the matrix-multiplication\nexponent, assuming the underlying linear system is non-singular. Finally, we\npose several conjectures and describe experimental results that support them.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-07T14:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.05104v1","title":"AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for\n  Early Warning System Investments","summary":"Tracking financial investments in climate adaptation is a complex and\nexpertise-intensive task, particularly for Early Warning Systems (EWS), which\nlack standardized financial reporting across multilateral development banks\n(MDBs) and funds. To address this challenge, we introduce an LLM-based agentic\nAI system that integrates contextual retrieval, fine-tuning, and multi-step\nreasoning to extract relevant financial data, classify investments, and ensure\ncompliance with funding guidelines. Our study focuses on a real-world\napplication: tracking EWS investments in the Climate Risk and Early Warning\nSystems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple\nAI-driven classification methods, including zero-shot and few-shot learning,\nfine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and\nan agent-based retrieval-augmented generation (RAG) approach. Our results show\nthat the agent-based RAG approach significantly outperforms other methods,\nachieving 87\\% accuracy, 89\\% precision, and 83\\% recall. Additionally, we\ncontribute a benchmark dataset and expert-annotated corpus, providing a\nvaluable resource for future research in AI-driven financial tracking and\nclimate finance transparency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.05119v1","title":"Balancing Robustness and Efficiency in Embedded DNNs Through Activation\n  Function Selection","summary":"Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR,cs.CV,eess.IV","published":"2025-04-07T14:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.05127v1","title":"Transitivity of the pure Hurwitz classes of quadratic post-critically\n  finite polynomials","summary":"We prove that for two post-critically finite quadratic polynomials $f,g$,\nthere is a mapping class $\\phi$ of the sphere with finitely many marked points\nsuch that $f\\phi$ and $g$ are pure Hurwitz equivalent.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-07T14:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.05140v1","title":"Unifying Physics- and Data-Driven Modeling via Novel Causal\n  Spatiotemporal Graph Neural Network for Interpretable Epidemic Forecasting","summary":"Accurate epidemic forecasting is crucial for effective disease control and\nprevention. Traditional compartmental models often struggle to estimate\ntemporally and spatially varying epidemiological parameters, while deep\nlearning models typically overlook disease transmission dynamics and lack\ninterpretability in the epidemiological context. To address these limitations,\nwe propose a novel Causal Spatiotemporal Graph Neural Network (CSTGNN), a\nhybrid framework that integrates a Spatio-Contact SIR model with Graph Neural\nNetworks (GNNs) to capture the spatiotemporal propagation of epidemics.\nInter-regional human mobility exhibits continuous and smooth spatiotemporal\npatterns, leading to adjacent graph structures that share underlying mobility\ndynamics. To model these dynamics, we employ an adaptive static connectivity\ngraph to represent the stable components of human mobility and utilize a\ntemporal dynamics model to capture fluctuations within these patterns. By\nintegrating the adaptive static connectivity graph with the temporal dynamics\ngraph, we construct a dynamic graph that encapsulates the comprehensive\nproperties of human mobility networks. Additionally, to capture temporal trends\nand variations in infectious disease spread, we introduce a temporal\ndecomposition model to handle temporal dependence. This model is then\nintegrated with a dynamic graph convolutional network for epidemic forecasting.\nWe validate our model using real-world datasets at the provincial level in\nChina and the state level in Germany. Extensive studies demonstrate that our\nmethod effectively models the spatiotemporal dynamics of infectious diseases,\nproviding a valuable tool for forecasting and intervention strategies.\nFurthermore, analysis of the learned parameters offers insights into disease\ntransmission mechanisms, enhancing the interpretability and practical\napplicability of our model.","main_category":"cs.LG","categories":"cs.LG,physics.soc-ph,q-bio.QM,stat.ML","published":"2025-04-07T14:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.05141v1","title":"EffOWT: Transfer Visual Language Models to Open-World Tracking\n  Efficiently and Effectively","summary":"Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T14:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.05142v1","title":"Discrete-to-continuum limits of semilinear stochastic evolution\n  equations in Banach spaces","summary":"We study the convergence of semilinear parabolic stochastic evolution\nequations, posed on a sequence of Banach spaces approximating a limiting space\nand driven by additive white noise projected onto the former spaces. Under\nappropriate uniformity and convergence conditions on the linear operators,\nnonlinear drifts and initial data, we establish convergence of the associated\nmild solution processes when lifted to a common state space. Our framework is\napplied to the case where the limiting problem is a stochastic partial\ndifferential equation whose linear part is a generalized Whittle-Mat\\'ern\noperator on a manifold $\\mathcal{M}$, discretized by a sequence of graphs\nconstructed from a point cloud. In this setting, we obtain\ndiscrete-to-continuum convergence of solutions lifted to the spaces\n$L^q(\\mathcal{M})$ for $q \\in [2,\\infty]$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-07T14:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.05155v1","title":"Phonon properties and unconventional heat transfer in quasi-2D\n  $Bi_2O_2Se$ crystal","summary":"Bi2O2Se belongs to a group of quasi-2D semiconductors that can replace\nsilicon in future high-speed/low-power electronics. However, the correlation\nbetween crystal/band structure and other physical properties still eludes\nunderstanding: carrier mobility increases non-intuitively with carrier\nconcentration; the observed $T^2$ temperature dependence of resistivity lacks\nexplanation. Moreover, a very high relative out-of-plane permittivity of about\n150 has been reported in the literature. A proper explanation for such a high\npermittivity is still lacking. We have performed infrared (IR) reflectivity and\nRaman scattering experiments on a large perfect single crystal with defined\nmosaicity, carrier concentration and mobility. Five of the eight phonons\nallowed by factor group theory have been observed and their symmetries\ndetermined. The IR spectra show that the permittivity measured in the\ntetragonal plane is as high as ${\\epsilon}_r{\\approx}500$, and this high value\nis due to a strong polar phonon with a low frequency of ~34 $cm^{-1}$ (~1 THz).\nSuch an unusually high permittivity allows the screening of charge defects,\nleading to the observation of high electron mobility at low temperatures. It\nalso allows effective modulation doping providing a platform for high\nperformance 2D electronics. DFT calculations suggest the existence of a very\nlow frequency acoustic phonon ~14 $cm^{-1}$ (~0.4 THz). Both the low frequency\nphonons cause anomalous phonon DOS, which is reflected in the unconventional\ntemperature dependence of the heat capacity, $c_M{\\approx}T^{3.5}$. The\ntemperature-dependent, two-component group velocity is proposed to explains the\nunusual temperature dependence of the thermal conductivity,\n${\\kappa}{\\approx}T^{1.5}$","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T14:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05160v1","title":"Some new functionals related to free boundary minimal submanifolds","summary":"The metrics induced on free boundary minimal surfaces in geodesic balls in\nthe upper unit hemisphere and hyperbolic space can be characterized as critical\nmetrics for the functionals $\\Theta_{r,i}$ and $\\Omega_{r,i}$, introduced\nrecently by Lima, Menezes and the second author. In this paper, we generalize\nthis characterization to free boundary minimal submanifolds of higher dimension\nin the same spaces. We also introduce some functionals of the form different\nfrom $\\Theta_{r,i}$ and show that the critical metrics for them are the metrics\ninduced by free boundary minimal immersions into a geodesic ball in the upper\nunit hemisphere. In the case of surfaces, these functionals are bounded from\nabove and not bounded from below. Moreover, the canonical metric on a geodesic\ndisk in a 3-ball in the upper unit hemisphere is maximal for this functional on\nthe set of all Riemannian metric of the topological disk.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T15:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.05172v1","title":"Attention-Based Multi-Scale Temporal Fusion Network for Uncertain-Mode\n  Fault Diagnosis in Multimode Processes","summary":"Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multi-scale temporal fusion network. The multi-scale\ndepthwise convolution and gated recurrent unit are employed to extract\nmulti-scale contextual local features and long-short-term features. A temporal\nattention mechanism is designed to focus on critical time points with higher\ncross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:16:22Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05189v1","title":"Influence of pore-confined water on the thermal expansion of a\n  zinc-based metal-organic framework","summary":"Understanding the reversible intercalation of guest molecules into\nmetal-organic frameworks is crucial for advancing their design for practical\napplications. In this work, we explore the impact of H$_{\\mathrm{2}}\\!$O as a\nguest molecule on the thermal expansion of the zinc-based metal-organic\nframework GUT-2. Dehydration is achieved by thermal treatment of hydrated\nGUT-2. Rietveld refinement performed on temperature-dependent X-ray powder\ndiffraction data confirms the reversible structural transformation.\nAdditionally, it allows the determination of anisotropic thermal expansion\ncoefficients for both phases. The hydrated form exhibits near-zero thermal\nexpansion along the polymer chain direction, moderate expansion In the\ndirection of predominantly hydrogen bonds, and the highest expansion in the\ndirection with only Van der Waals bonding. Upon activation, the removal of\nH$_{\\mathrm{2}}\\!$O molecules triggers a doubling of the thermal expansion\ncoefficient in the direction, where the hydrogen bonds have been removed.\nRegarding the dynamics of the process, thermal activation in air occurs within\n6 hours at a temperature of 50{\\deg}C and takes only 30 minutes when heating to\n90{\\deg}C. In contrast, full rehydration under standard lab conditions (30 %\nrelative humidity) requires two days. During the activation/dehydration\nprocesses no change of the widths of the X-ray diffraction peaks is observed,\nwhich shows that the underlying crystal structures remains fully intact during\nthe transition processes. Fitting the transformations by the Avrami equation\nreveals a quasi one-dimensional evolution of the dehydrated areas for the\nactivation process and a more intricate, predominantly two-dimensional\nmechanism for the rehydration.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T15:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.05199v1","title":"Equivalence Theorems and Double-Copy Structure in Scattering Amplitudes\n  of Massive Kaluza-Klein States with Matter Interactions","summary":"We investigate the scattering amplitudes of massive Kaluza-Klein (KK) states\nin compactified five-dimensional warped gauge and gravity theories. Focusing on\ntree-level $2\\to2$ processes, we analyze the leading-order amplitudes involving\nbulk KK matter fields and KK gauge/gravitational Goldstone bosons. By imposing\nthe gauge theory equivalence theorem (GAET) and the gravitational equivalence\ntheorem (GRET) within warped KK theories, we systematically reconstruct the\nleading-order amplitudes for physical KK gauge bosons and gravitons, thereby\ncircumventing the intricate energy cancellations inherent in physical\namplitudes. Within this framework, the correspondence between GAET and GRET\narises as a direct manifestation of the leading-order double-copy relation in\nthe high-energy expansion. This connection provides a foundation for extending\nthe BCJ double-copy construction to four-point amplitudes involving bulk KK\nmatter fields, allowing for a systematic derivation of the corresponding\ngravitational amplitudes while consistently incorporating KK matter fields at\nleading order.","main_category":"hep-th","categories":"hep-th","published":"2025-04-07T15:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05215v1","title":"Quasinormal modes and absorption cross-section of a Bardeen black hole\n  surrounded by perfect fluid dark matter in four dimensions","summary":"In this paper we study quasinormal modes and absorption cross sections for\nthe $(1+3)$-dimensional Bardeen black hole surrounded by perfect fluid dark\nmatter. Studies of the massless scalar field is already done in\n\\cite{Sun:2023slzl}. Hence, in this paper we will focus on the massive scalar\nfield perturbations and massless Dirac field perturbations. To compute the\nquasinormal modes we use the semi-analytical 3rd-order WKB method, which has\nbeen shown to be one of the best approaches when the effective potential is\nadequate and when $n < \\ell$ and $n < \\lambda$. We have also utilized the\nP\\\"oschl-Teller method to compare the valus obtained using the WKB approach. We\nhave computed quasinormal frequencies by varying various parameters of the\ntheory such as the mass of the scalar field $\\mu$, dark matter parameter\n$\\alpha$ and the magnetic charge $g$. We have summarized our solutions in\ntables and figures for clarity. As for the absorption cross section, we used\nthird order WKB approach to compute reflection, transmission coefficients and\npartial absorption cross sections. Graphs are presented to demonstrate the\nbehavior of the above quantities when the dark matter parameter and mass of the\nmassive scalar field are varied.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-th","published":"2025-04-07T16:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.05219v1","title":"An ensemble deep learning approach to detect tumors on Mohs micrographic\n  surgery slides","summary":"Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.05220v1","title":"Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort\n  for Retrieval and RAG","summary":"Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-07T16:05:52Z"}
{"aid":"http://arxiv.org/abs/2504.05228v1","title":"NoveltyBench: Evaluating Creativity and Diversity in Language Models","summary":"Language models have demonstrated remarkable capabilities on standard\nbenchmarks, yet they struggle increasingly from mode collapse, the inability to\ngenerate diverse and novel outputs. Our work introduces NoveltyBench, a\nbenchmark specifically designed to evaluate the ability of language models to\nproduce multiple distinct and high-quality outputs. NoveltyBench utilizes\nprompts curated to elicit diverse answers and filtered real-world user queries.\nEvaluating 20 leading language models, we find that current state-of-the-art\nsystems generate significantly less diversity than human writers. Notably,\nlarger models within a family often exhibit less diversity than their smaller\ncounterparts, challenging the notion that capability on standard benchmarks\ntranslates directly to generative utility. While prompting strategies like\nin-context regeneration can elicit diversity, our findings highlight a\nfundamental lack of distributional diversity in current models, reducing their\nutility for users seeking varied responses and suggesting the need for new\ntraining and evaluation paradigms that prioritize creativity alongside quality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.05253v1","title":"Contour Integration Underlies Human-Like Vision","summary":"Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.05266v1","title":"Differential forms: Lagrange interpolation, sampling and approximation\n  on polynomial admissible integral k-meshes","summary":"In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T17:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.05268v1","title":"Performance and Complexity Analysis of Terahertz-Band MIMO Detection","summary":"Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T17:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05297v1","title":"Eigenvalue-Based Randomness Test for Residual Diagnostics in Panel Data\n  Models","summary":"This paper introduces the Eigenvalue-Based Randomness (EBR) test - a novel\napproach rooted in the Tracy-Widom law from random matrix theory - and applies\nit to the context of residual analysis in panel data models. Unlike traditional\nmethods, which target specific issues like cross-sectional dependence or\nautocorrelation, the EBR test simultaneously examines multiple assumptions by\nanalyzing the largest eigenvalue of a symmetrized residual matrix. Monte Carlo\nsimulations demonstrate that the EBR test is particularly robust in detecting\nnot only standard violations such as autocorrelation and linear cross-sectional\ndependence (CSD) but also more intricate non-linear and non-monotonic\ndependencies, making it a comprehensive and highly flexible tool for enhancing\nthe reliability of panel data analyses.","main_category":"stat.ME","categories":"stat.ME,econ.EM,stat.AP,stat.CO","published":"2025-04-07T17:52:36Z"}
{"aid":"http://arxiv.org/abs/2504.05632v1","title":"Reasoning Towards Fairness: Mitigating Bias in Language Models through\n  Reasoning-Guided Fine-Tuning","summary":"Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T03:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.05641v1","title":"Testing black holes in a perfect fluid dark matter environment using\n  quasinormal modes","summary":"This research explores the quasinormal modes (QNMs) characteristics of\ncharged black holes in a perfect fluid dark matter (PFDM) environment. Based on\nthe Event Horizon Telescope (EHT) observations of the M87* black hole shadow,\nwe implemented necessary constraints on the parameter\nspace($a/M$,$\\lambda/M$).We found that for lower values of the magnetic charge\nparameter, the effective range of the PFDM parameter is approximately between\n-0.2 and 0, while as the magnetic charge parameter increases, this effective\nrange gradually extends toward more negative values. Then through sixth-order\nWKB method and time-domain method, we systematically analyzed the quasinormal\noscillation spectra under scalar field and electromagnetic field perturbations.\nThe results reveal that: the magnetic charge $a$ and PFDM parameters $\\lambda$\nmodulate the effective potential barrier of black hole spacetime, profoundly\ninfluencing the response frequency and energy dissipation characteristics of\nexternal perturbations. The consistently negative imaginary part of QNMs across\nthe entire physical parameter domain substantiates the dynamical stability of\nthe investigated system. Moreover, we discovered differences in the parameter\nvariation sensitivity between scalar field and electromagnetic field\nperturbations, providing a theoretical basis for distinguishing different field\ndisturbances. These results not only unveil the modulation mechanisms of\nelectromagnetic interactions and dark matter distribution on black hole\nspacetime structures but also offer potential observational evidence for future\ngravitational wave detection and black hole environment identification.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.05642v1","title":"Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using\n  Large Language Models","summary":"We propose a novel three-step prompt-tuning method for Bengali Grammatical\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\nidentifying and categorizing grammatical errors in Bengali sentences,\ngenerating corrected versions of the sentences, and providing natural language\nexplanations for each identified error. We evaluate the performance of our BGEE\nsystem using both automated evaluation metrics and human evaluation conducted\nby experienced Bengali language experts. Our proposed prompt-tuning approach\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\nimprovement in exact match. Furthermore, compared to the previous baseline,\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\n26.27% in wrong error explanation. However, the results still lag behind the\nhuman baseline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T03:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05661v1","title":"Online Bernstein-von Mises theorem","summary":"Online learning is an inferential paradigm in which parameters are updated\nincrementally from sequentially available data, in contrast to batch learning,\nwhere the entire dataset is processed at once. In this paper, we assume that\nmini-batches from the full dataset become available sequentially. The Bayesian\nframework, which updates beliefs about unknown parameters after observing each\nmini-batch, is naturally suited for online learning. At each step, we update\nthe posterior distribution using the current prior and new observations, with\nthe updated posterior serving as the prior for the next step. However, this\nrecursive Bayesian updating is rarely computationally tractable unless the\nmodel and prior are conjugate. When the model is regular, the updated posterior\ncan be approximated by a normal distribution, as justified by the Bernstein-von\nMises theorem. We adopt a variational approximation at each step and\ninvestigate the frequentist properties of the final posterior obtained through\nthis sequential procedure. Under mild assumptions, we show that the accumulated\napproximation error becomes negligible once the mini-batch size exceeds a\nthreshold depending on the parameter dimension. As a result, the sequentially\nupdated posterior is asymptotically indistinguishable from the full posterior.","main_category":"math.ST","categories":"math.ST,stat.TH,G.3","published":"2025-04-08T04:22:56Z"}
{"aid":"http://arxiv.org/abs/2504.05666v1","title":"Contraction and concentration of measures with applications to\n  theoretical neuroscience","summary":"We investigate the asymptotic behavior of probability measures associated\nwith stochastic dynamical systems featuring either globally contracting or\n$B_{r}$-contracting drift terms. While classical results often assume constant\ndiffusion and gradient-based drifts, we extend the analysis to spatially\ninhomogeneous diffusion and non-integrable vector fields. We establish\nsufficient conditions for the existence and uniqueness of stationary measures\nunder global contraction, showing that convergence is preserved when the\ncontraction rate dominates diffusion inhomogeneity. For systems contracting\nonly outside of a compact set and with constant diffusion, we demonstrate mass\nconcentration near the minima of an associated non-convex potential, like in\nmultistable regimes. The theoretical findings are illustrated through Hopfield\nnetworks, highlighting implications for memory retrieval dynamics in noisy\nenvironments.","main_category":"math.DS","categories":"math.DS,math-ph,math.AP,math.MP","published":"2025-04-08T04:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.05670v1","title":"Dual Boost-Driven Graph-Level Clustering Network","summary":"Graph-level clustering remains a pivotal yet formidable challenge in graph\nlearning. Recently, the integration of deep learning with representation\nlearning has demonstrated notable advancements, yielding performance\nenhancements to a certain degree. However, existing methods suffer from at\nleast one of the following issues: 1. the original graph structure has noise,\nand 2. during feature propagation and pooling processes, noise is gradually\naggregated into the graph-level embeddings through information propagation.\nConsequently, these two limitations mask clustering-friendly information,\nleading to suboptimal graph-level clustering performance. To this end, we\npropose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) to\nalternately promote graph-level clustering and filtering out interference\ninformation in a unified framework. Specifically, in the pooling step, we\nevaluate the contribution of features at the global and optimize them using a\nlearnable transformation matrix to obtain high-quality graph-level\nrepresentation, such that the model's reasoning capability can be improved.\nMoreover, to enable reliable graph-level clustering, we first identify and\nsuppress information detrimental to clustering by evaluating similarities\nbetween graph-level representations, providing more accurate guidance for\nmulti-view fusion. Extensive experiments demonstrated that DBGCN outperforms\nthe state-of-the-art graph-level clustering methods on six benchmark datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T04:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.05689v1","title":"Separator Injection Attack: Uncovering Dialogue Biases in Large Language\n  Models Caused by Role Separators","summary":"Conversational large language models (LLMs) have gained widespread attention\ndue to their instruction-following capabilities. To ensure conversational LLMs\nfollow instructions, role separators are employed to distinguish between\ndifferent participants in a conversation. However, incorporating role\nseparators introduces potential vulnerabilities. Misusing roles can lead to\nprompt injection attacks, which can easily misalign the model's behavior with\nthe user's intentions, raising significant security concerns. Although various\nprompt injection attacks have been proposed, recent research has largely\noverlooked the impact of role separators on safety. This highlights the\ncritical need to thoroughly understand the systemic weaknesses in dialogue\nsystems caused by role separators. This paper identifies modeling weaknesses\ncaused by role separators. Specifically, we observe a strong positional bias\nassociated with role separators, which is inherent in the format of dialogue\nmodeling and can be triggered by the insertion of role separators. We further\ndevelop the Separators Injection Attack (SIA), a new orthometric attack based\non role separators. The experiment results show that SIA is efficient and\nextensive in manipulating model behavior with an average gain of 18.2% for\nmanual methods and enhances the attack success rate to 100% with automatic\nmethods.","main_category":"cs.CL","categories":"cs.CL,cs.CR","published":"2025-04-08T05:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.05706v1","title":"SEVERE++: Evaluating Benchmark Sensitivity in Generalization of Video\n  Representation Learning","summary":"Continued advances in self-supervised learning have led to significant\nprogress in video representation learning, offering a scalable alternative to\nsupervised approaches by removing the need for manual annotations. Despite\nstrong performance on standard action recognition benchmarks, video\nself-supervised learning methods are largely evaluated under narrow protocols,\ntypically pretraining on Kinetics-400 and fine-tuning on similar datasets,\nlimiting our understanding of their generalization in real world scenarios. In\nthis work, we present a comprehensive evaluation of modern video\nself-supervised models, focusing on generalization across four key downstream\nfactors: domain shift, sample efficiency, action granularity, and task\ndiversity. Building on our prior work analyzing benchmark sensitivity in\nCNN-based contrastive learning, we extend the study to cover state-of-the-art\ntransformer-based video-only and video-text models. Specifically, we benchmark\n12 transformer-based methods (7 video-only, 5 video-text) and compare them to\n10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7\ndownstream tasks. Our analysis shows that, despite architectural advances,\ntransformer-based models remain sensitive to downstream conditions. No method\ngeneralizes consistently across all factors, video-only transformers perform\nbetter under domain shifts, CNNs outperform for fine-grained tasks, and\nvideo-text models often underperform despite large scale pretraining. We also\nfind that recent transformer models do not consistently outperform earlier\napproaches. Our findings provide a detailed view of the strengths and\nlimitations of current video SSL methods and offer a unified benchmark for\nevaluating generalization in video representation learning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T06:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05708v1","title":"Thermodynamic supercriticality and complex phase diagram for the AdS\n  black hole","summary":"In this study, we extend the application of the Lee-Yang phase transition\ntheorem to the realm of AdS black hole thermodynamics, thereby deriving a\ncomprehensive complex phase diagram for such systems. Our research augments\nextant studies on black hole thermodynamic phase diagrams, particularly in the\nregime above the critical point, by delineating the Widom line of AdS black\nholes. This boundary segregates the supercritical domain of the phase diagram\ninto two disparate zones. As the system traverses the thermodynamic crossover\nwithin the supercritical region, it undergoes a transition from one\nsupercritical phase to another, while maintaining the continuity of its\nthermodynamic state functions. This behavior is fundamentally different from\nthat below the critical point, where crossing the coexistence line results in\ndiscontinuities of thermodynamic state functions. The Widom line enables a\nthermodynamic crossover between single-phase states without traversing the\nspinodal that emerges in the critical region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-08T06:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.05716v1","title":"Single-Agent vs. Multi-Agent LLM Strategies for Automated Student\n  Reflection Assessment","summary":"We explore the use of Large Language Models (LLMs) for automated assessment\nof open-text student reflections and prediction of academic performance.\nTraditional methods for evaluating reflections are time-consuming and may not\nscale effectively in educational settings. In this work, we employ LLMs to\ntransform student reflections into quantitative scores using two assessment\nstrategies (single-agent and multi-agent) and two prompting techniques\n(zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278\nreflections from 377 students over three academic terms, demonstrate that the\nsingle-agent with few-shot strategy achieves the highest match rate with human\nevaluations. Furthermore, models utilizing LLM-assessed reflection scores\noutperform baselines in both at-risk student identification and grade\nprediction tasks. These findings suggest that LLMs can effectively automate\nreflection assessment, reduce educators' workload, and enable timely support\nfor students who may need additional assistance. Our work emphasizes the\npotential of integrating advanced generative AI technologies into educational\npractices to enhance student engagement and academic success.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-08T06:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.05744v1","title":"Influence of doping on non-equilibrium carrier dynamics in graphene","summary":"Controlling doping is key to optimizing graphene for high-speed electronic\nand optoelectronic devices. However, its impact on non-equilibrium carrier\nlifetimes remains debated. Here, we systematically tune the doping level of\nquasi-freestanding epitaxial graphene on SiC(0001) via potassium deposition and\nprobe its ultrafast carrier dynamics directly in the band structure using time-\nand angle-resolved photoemission spectroscopy (trARPES). We find that increased\ndoping lowers both the peak electronic temperature and the cooling rate of\nDirac carriers, which we attribute to higher electronic heat capacity and\nreduced phonon emission phase space. Comparing quasi-freestanding graphene with\ngraphene on a carbon buffer layer reveals faster relaxation in the latter,\nlikely due to additional phonon modes being available for heat dissipation.\nThese findings offer new insights for optimizing graphene in electronic and\nphotonic technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-08T07:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.05768v1","title":"Temporal Dynamic Embedding for Irregularly Sampled Time Series","summary":"In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T07:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.05776v1","title":"Quantifying uncertainty in inverse scattering problems set in layered\n  environments","summary":"The attempt to solve inverse scattering problems often leads to optimization\nand sampling problems that require handling moderate to large amounts of\npartial differential equations acting as constraints. We focus here on\ndetermining inclusions in a layered medium from the measurement of wave fields\non the surface, while quantifying uncertainty and addressing the effect of wave\nsolver quality. Inclusions are characterized by a few parameters describing\ntheir material properties and shapes. We devise algorithms to estimate the most\nlikely configurations by optimizing cost functionals with Bayesian\nregularizations and wave constraints. In particular, we design an automatic\nLevenberg-Marquardt-Fletcher type scheme based on the use of algorithmic\ndifferentiation and adaptive finite element meshes for time dependent wave\nequation constraints with changing inclusions. In synthetic tests with a single\nfrequency, this scheme converges in few iterations for increasing noise levels.\nTo attain a global view of other possible high probability configurations and\nasymmetry effects we resort to parallelizable affine invariant Markov Chain\nMonte Carlo methods, at the cost of solving a few million wave problems. This\nforces the use of prefixed meshes. While the optimal configurations remain\nsimilar, we encounter additional high probability inclusions influenced by the\nprior information, the noise level and the layered structure, effect that can\nbe reduced by considering more frequencies. We analyze the effect on the\ncalculations of working with adaptive and fixed meshes, under a simple choice\nof non-reflecting boundary conditions in truncated layered domains for which we\nestablish wellposedness and convergence results.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC,physics.comp-ph,physics.data-an,physics.geo-ph","published":"2025-04-08T07:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.05779v1","title":"FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency\n  Priors","summary":"Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.05802v1","title":"Mass-Spring Models for Passive Keyword Spotting: A Springtronics\n  Approach","summary":"Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.","main_category":"cs.SD","categories":"cs.SD,cond-mat.dis-nn,eess.AS","published":"2025-04-08T08:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05805v1","title":"Why is Normalization Necessary for Linear Recommenders?","summary":"Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.05845v1","title":"Eikonal boundary condition for level set method","summary":"In this paper, we propose to use the eikonal equation as a boundary condition\nwhen advective or normal flow equations in the level set formulation are solved\nnumerically on polyhedral meshes in the three-dimensional domain. Since the\nlevel set method can use a signed distance function as an initial condition,\nthe eikonal equation on the boundary is a suitable choice at the initial time.\nEnforcing the eikonal equation on the boundary for later times can eliminate\nthe need for inflow boundary conditions, which are typically required for\ntransport equations. In selected examples where exact solutions are available,\nwe compare the proposed method with the method using the exact Dirichlet\nboundary condition. The numerical results confirm that the use of the eikonal\nboundary condition provides comparable accuracy and robustness in surface\nevolution compared to the use of the exact Dirichlet boundary condition, which\nis generally not available. We also present numerical results of evolving a\ngeneral closed surface.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T09:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.05851v1","title":"Identifying and Replicating Code Patterns Driving Performance\n  Regressions in Software Systems","summary":"Context: Performance regressions negatively impact execution time and memory\nusage of software systems. Nevertheless, there is a lack of systematic methods\nto evaluate the effectiveness of performance test suites. Performance mutation\ntesting, which introduces intentional defects (mutants) to measure and enhance\nfault-detection capabilities, is promising but underexplored. A key challenge\nis understanding if generated mutants accurately reflect real-world performance\nissues. Goal: This study evaluates and extends mutation operators for\nperformance testing. Its objectives include (i) collecting existing performance\nmutation operators, (ii) introducing new operators from real-world code changes\nthat impact performance, and (iii) evaluating these operators on real-world\nsystems to see if they effectively degrade performance. Method: To this aim, we\nwill (i) review the literature to identify performance mutation operators, (ii)\nconduct a mining study to extract patterns of code changes linked to\nperformance regressions, (iii) propose new mutation operators based on these\npatterns, and (iv) apply and evaluate the operators to assess their\neffectiveness in exposing performance degradations. Expected Outcomes: We aim\nto provide an enriched set of mutation operators for performance testing,\nhelping developers and researchers identify harmful coding practices and design\nbetter strategies to detect and prevent performance regressions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T09:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.05855v1","title":"Enhancing Coreference Resolution with Pretrained Language Models:\n  Bridging the Gap Between Syntax and Semantics","summary":"Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T09:33:09Z"}
{"aid":"http://arxiv.org/abs/2504.05861v1","title":"Sparse Bounded Hop-Spanners for Geometric Intersection Graphs","summary":"We present new results on $2$- and $3$-hop spanners for geometric\nintersection graphs. These include improved upper and lower bounds for $2$- and\n$3$-hop spanners for many geometric intersection graphs in $\\mathbb{R}^d$. For\nexample, we show that the intersection graph of $n$ balls in $\\mathbb{R}^d$\nadmits a $2$-hop spanner of size $O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2\\lfloor\nd/2\\rfloor +1)}}\\right)$ and the intersection graph of $n$ fat axis-parallel\nboxes in $\\mathbb{R}^d$ admits a $2$-hop spanner of size $O(n \\log^{d+1}n)$.\n  Furthermore, we show that the intersection graph of general semi-algebraic\nobjects in $\\mathbb{R}^d$ admits a $3$-hop spanner of size\n$O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2D-1)}}\\right)$, where $D$ is a parameter\nassociated with the description complexity of the objects. For such families\n(or more specifically, for tetrahedra in $\\mathbb{R}^3$), we provide a lower\nbound of $\\Omega(n^{\\frac{4}{3}})$. For $3$-hop and axis-parallel boxes in\n$\\mathbb{R}^d$, we provide the upper bound $O(n \\log ^{d-1}n)$ and lower bound\n$\\Omega\\left(n (\\frac{\\log n}{\\log \\log n})^{d-2}\\right)$.","main_category":"cs.CG","categories":"cs.CG,cs.DM","published":"2025-04-08T09:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.05864v1","title":"Tunable spin-orbit splitting in bilayer graphene/WSe$_2$ quantum devices","summary":"Bilayer graphene (BLG)-based quantum devices represent a promising platform\nfor emerging technologies such as quantum computing and spintronics. However,\ntheir intrinsically weak spin-orbit coupling (SOC) presents a challenge for\nspin and valley manipulation, as these applications operate more efficiently in\nthe presence of strong SOC. Integrating BLG with transition metal\ndichalcogenides (TMDs) significantly enhances SOC via proximity effects. While\nthis enhancement has been experimentally demonstrated in 2D-layered structures,\n1D and 0D-nanostructures in BLG/TMD remain unrealized, with open questions\nregarding device quality, SOC strength, and tunability. In this work, we\ninvestigate quantum point contacts and quantum dots in two BLG/WSe$_2$\nheterostructures with different stacking orders. Across multiple devices, we\ndemonstrate a reproducible enhancement of spin-orbit splitting\n($\\Delta_\\mathrm{SO}$) reaching values of up to $1.5\\mathrm{meV}$ - more than\none order of magnitude higher than in pristine bilayer graphene\n($\\Delta_\\mathrm{SO}=40-80\\mu\\mathrm{eV}$). Furthermore, we show that the\ninduced SOC can be tuned in situ from its maximum value to near-complete\nsuppression by varying the perpendicular electric field, thereby controlling\nlayer polarization. This enhancement and in situ tunability establish SOC as an\nefficient control mechanism for dynamic spin and valley manipulation.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T09:44:16Z"}
{"aid":"http://arxiv.org/abs/2504.05871v1","title":"Agent Guide: A Simple Agent Behavioral Watermarking Framework","summary":"The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.","main_category":"cs.AI","categories":"cs.AI,K.6.5","published":"2025-04-08T09:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.05874v1","title":"Systematic Parameter Decision in Approximate Model Counting","summary":"This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T09:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05881v1","title":"Actuarial Learning for Pension Fund Mortality Forecasting","summary":"For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-08T10:09:41Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05914v1","title":"High-Resource Translation:Turning Abundance into Accessibility","summary":"This paper presents a novel approach to constructing an English-to-Telugu\ntranslation model by leveraging transfer learning techniques and addressing the\nchallenges associated with low-resource languages. Utilizing the Bharat\nParallel Corpus Collection (BPCC) as the primary dataset, the model\nincorporates iterative backtranslation to generate synthetic parallel data,\neffectively augmenting the training dataset and enhancing the model's\ntranslation capabilities. The research focuses on a comprehensive strategy for\nimproving model performance through data augmentation, optimization of training\nparameters, and the effective use of pre-trained models. These methodologies\naim to create a robust translation system that can handle diverse sentence\nstructures and linguistic nuances in both English and Telugu. This work\nhighlights the significance of innovative data handling techniques and the\npotential of transfer learning in overcoming limitations posed by sparse\ndatasets in low-resource languages. The study contributes to the field of\nmachine translation and seeks to improve communication between English and\nTelugu speakers in practical contexts.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T11:09:51Z"}
{"aid":"http://arxiv.org/abs/2504.05920v1","title":"Local Thermal Non-Equilibrium Models in Porous Media: A Comparative\n  Study of Conduction Effects","summary":"Instantaneous heat transfer between different phases is a common assumption\nfor modeling heat transfer in porous media, known as Local Thermal Equilibrium\n(LTE). This assumption may not hold in certain technical and environmental\napplications, especially in systems with large temperature gradients, large\ndifferences in thermal properties, or high velocities. Local Thermal\nNon-Equilibrium (LTNE) models aim to describe heat transfer processes when the\nLTE assumption may fail. In this work, we compare three continuum-scale models\nfrom the pore to the representative elementary volume (REV) scale.\nSpecifically, dual-network and REV-scale models are evaluated against a\npore-resolved model, which we perceive as a reference in the absence of\nexperimental results. Different effective models are used to obtain upscaled\nproperties on the REV scale and to compare resulting temperature profiles. The\nsystems investigated are fully saturated, consisting of one fluid and one solid\nphase. This study focuses on purely conductive systems without significant\ndifferences in thermal properties. Results show that LTE holds then for low\ninterfacial resistances. However, for large interfacial resistances, solid and\nfluid temperatures differ. The REV-scale model with effective parameters\nobtained by homogenization leads to similar results as the pore-resolved model,\nwhereas the dual-network model shows greater deviation due to its fixed spatial\nresolution. Among the evaluated effective parameter formulations for the\nREV-scale model, only the homogenization-based approach captures the LTNE\nbehavior, as it incorporates the interfacial heat transfer coefficient.\nConvection is relevant for most practical applications, and its impact will be\naddressed in a follow-up article.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T11:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.05929v1","title":"Cohomology and deformations of restricted Lie algebras and their\n  morphisms in positive characteristic","summary":"The main purpose of this paper is to study cohomology and develop a\ndeformation theory of restricted Lie algebras in positive characteristic $p>0$.\nIn the case $p\\geq3$, it is shown that the deformations of restricted Lie\nalgebras are controlled by the restricted cohomology introduced by Evans and\nFuchs. Moreover, we introduce a new cohomology that controls the deformations\nof restricted morphisms of restricted Lie algebras. In the case $p=2$, we\nprovide a full restricted cohomology complex with values in a restricted module\nand investigate its connections with formal deformations. Furthermore, we\nintroduce a full deformation cohomology that controls deformations of\nrestricted morphisms of restricted Lie algebras in characteristic $2$. As\nexample, we discuss restricted cohomology with adjoint coefficients of\nrestricted Heisenberg Lie algebras in characteristic $p\\geq 2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.05931v1","title":"A stability phenomenon in Kazhdan-Lusztig combinatorics","summary":"We prove that, when $n$ goes to infinity, the expression, with respect to the\ndual Kazhdan-Lusztig basis, of the product\n$\\hat{\\underline{H}}_x\\underline{H}_y$ of elements of the dual and the usual\nKazhdan-Lusztig bases in the Hecke algebra of the symmetric group $S_n$\nstabilizes. As an application, we define the action of projective functors on\nthe principal block of category $\\mathcal{O}$ for $\\mathfrak{sl}_\\infty$ and\nshow that the subcategory of finite length objects is stable under this action.\nAs a bonus, we also prove that this latter block is Koszul, answering, for this\nblock, a question from \\cite{CP}.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.05941v1","title":"Self-sustained oscillations in discrete-time relay feedback systems","summary":"We study the problem of determining self-sustained oscillations in\ndiscrete-time linear time-invariant relay feedback systems. Concretely, we are\ninterested in predicting when such a system admits unimodal oscillations, i.e.,\nwhen the output has a single-peaked period. Under the assumption that the\nlinear system is stable and has an impulse response that is strictly\nmonotonically decreasing on its infinite support, we take a novel approach in\nusing the framework of total positivity to address our main question. It is\nshown that unimodal self-oscillations can only exist if the number of positive\nand negative elements in a period coincides. Based on this result, we derive\nconditions for the existence of such oscillations, determine bounds on their\nperiods, and address the question of uniqueness.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-08T11:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.05944v1","title":"Laminar chaos in systems with random and chaotically time-varying delay","summary":"A type of chaos called laminar chaos was found in singularly perturbed\ndynamical systems with periodically [Phys. Rev. Lett. 120, 084102 (2018)] and\nquasiperiodically [Phys. Rev. E 107, 014205 (2023)] time-varying delay.\nCompared to high-dimensional turbulent chaos that is typically found in such\nsystems with large constant delay, laminar chaos is a very low-dimensional\nphenomenon. It is characterized by a time series with nearly constant laminar\nphases that are interrupted by irregular bursts, where the intensity level of\nthe laminar phases varies chaotically from phase to phase. In this paper, we\ndemonstrate that laminar chaos, and its generalizations, can also be observed\nin systems with random and chaotically time-varying delay. Moreover, while for\nperiodic and quasiperiodic delays the appearance of (generalized) laminar chaos\nand turbulent chaos depends in a fractal manner on the delay parameters, it\nturns out that short-time correlated random and chaotic delays lead to\n(generalized) laminar chaos in almost the whole delay parameter space, where\nthe properties of circle maps with quenched disorder play a crucial role. It\nfollows that introducing such a delay variation typically leads to a drastic\nreduction of the dimension of the chaotic attractor of the considered systems.\nWe investigate the dynamical properties and generalize the known methods for\ndetecting laminar chaos in experimental time series to random and chaotically\ntime-varying delay.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05952v1","title":"Contrasting magnetism in VPS3 and CrI3 monolayers with the common\n  honeycomb S = 3/2 spin lattice","summary":"Two-dimensional (2D) magnetic materials are promising candidates for\nspintronics and quantum technologies. One extensively studied example is the\nferromagnetic (FM) CrI$_3$ monolayer with the honeycomb Cr$^{3+}$ ($t_{2g}^3$,\n$S$ = 3/2) spin lattice, while VPS$_3$ has a same honeycomb $S$ = 3/2 spin\nlattice (V$^{2+}$, $t_{2g}^3$) but displays N$\\acute{e}$el antiferromagnetism\n(AFM). In this work, we study the electronic structure and particularly the\ncontrasting magnetism of VPS$_3$ and CrI$_3$ monolayers. We find that VPS$_3$\nis a Mott-Hubbard insulator but CrI$_3$ is a charge-transfer insulator, and\ntherefore their magnetic exchange mechanisms are essentially different. The\nfirst nearest-neighbor (1NN) direct $d$-$d$ exchange dominates in VPS$_3$, thus\nleading to a strong antiferromagnetic (AF) coupling. However, the formation of\nvanadium vacancies, associated with instability of the low-valence V$^{2+}$\nions, suppresses the AF coupling and thus strongly reduces the N$\\acute{e}$el\ntemperature ($T_{\\text{N}}$) in line with the experimental observation. In\ncontrast, our results reveal that the major 1NN $d$-$p$-$d$ superexchanges in\nCrI$_3$ via different channels give rise to competing FM and AF couplings,\nultimately resulting in a weak FM coupling as observed experimentally. After\nrevisiting several important superexchange channels reported in the literature,\nbased on our MLWFs and tight-binding analyses, we note that some antiphase\ncontributions must be subtly and simultaneously considered, and thus we provide\na deeper insight into the FM coupling of CrI$_3$. Moreover, we identify and\ncompare the major contributions to the magnetic anisotropy, i.e., a weak shape\nanisotropy in VPS$_3$ and a relatively strong exchange anisotropy in CrI$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T12:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05976v1","title":"A Knowledge Base for Arts and Inclusion -- The Dataverse data archival\n  platform as a knowledge base management system enabling multimodal\n  accessibility","summary":"Creating an inclusive art environment requires engaging multiple senses for a\nfully immersive experience. Culture is inherently synesthetic, enriched by all\nsenses within a shared time and space. In an optimal synesthetic setting,\npeople of all abilities can connect meaningfully; when one sense is\ncompromised, other channels can be enhanced to compensate. This is the power of\nmultimodality. Digital technology is increasingly able to capture aspects of\nmultimodality. To document multimodality aspects of cultural practices and\nproducts for the long-term remains a challenge. Many artistic products from the\nperforming arts tend to be multimodal, and are often immersive, so only a\nmultimodal repository can offer a platform for this work. To our knowledge\nthere is no single, comprehensive repository with a knowledge base to serve\narts and disability. By knowledge base, we mean classifications, taxonomies, or\nontologies (in short, knowledge organisation systems). This paper presents\ninnovative ways to develop a knowledge base which capture multimodal features\nof archived representations of cultural assets, but also indicate various forms\nhow to interact with them including machine-readable description. We will\ndemonstrate how back-end and front-end applications, in a combined effort, can\nsupport accessible archiving and data management for complex digital objects\nborn out of artistic practices and make them available for wider audiences.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-08T12:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.05980v1","title":"Langevin dynamics with generalized time-reversal symmetry","summary":"When analyzing the equilibrium properties of a stochastic process,\nidentifying the parity of the variables under time-reversal is imperative. This\ninitial step is required to assess the presence of detailed balance, and to\ncompute the entropy production rate, which is, otherwise, ambiguously defined.\nIn this work we deal with stochastic processes whose underlying time-reversal\nsymmetry cannot be reduced to the usual parity rules (namely, flip of the\nmomentum sign). We provide a systematic method to build equilibrium Langevin\ndynamics starting from their reversible deterministic counterparts: this\nstrategy can be applied, in particular, to all stable one-dimensional\nHamiltonian dynamics, exploiting the time-reversal symmetry unveiled in the\naction-angle framework. The case of the Lotka-Volterra model is discussed as an\nexample. We also show that other stochastic versions of this system violate\ntime-reversal symmetry and are, therefore, intrinsically out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T12:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05993v1","title":"Strong Evidence That Abiogenesis Is a Rapid Process on Earth Analogs","summary":"The early start to life naively suggests that abiogenesis is a rapid process\non Earth-like planets. However, if evolution typically takes ~4Gyr to produce\nintelligent life-forms like us, then the limited lifespan of Earth's biosphere\n(~5-6Gyr) necessitates an early (and possibly highly atypical) start to our\nemergence - an example of the weak anthropic principle. Our previously proposed\nobjective Bayesian analysis of Earth's chronology culminated in a formula for\nthe minimum odds ratio between the fast and slow abiogenesis scenarios\n(relative to Earth's lifespan). Timing from microfossils (3.7Gya) yields 3:1\nodds in favor of rapid abiogenesis, whereas evidence from carbon isotopes\n(4.1Gya) gives 9:1, both below the canonical threshold of \"strong evidence\"\n(10:1). However, the recent result of a 4.2Gya LUCA pushes the odds over the\nthreshold for the first time (nominally 13:1). In fact, the odds ratio is >10:1\nfor all possible values of the biosphere's ultimate lifespan and speculative\nhypotheses of ancient civilizations. For the first time, we have formally\nstrong evidence that favors the hypothesis that life rapidly emerges in\nEarth-like conditions (although such environments may themselves be rare).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-08T12:55:50Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06003v1","title":"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\n  Gaussians","summary":"The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.06008v1","title":"Impact of newly measured $Î²$\\nobreakdash-delayed neutron emitters\n  around \\myisoSimp{78}{Ni} on light element nucleosynthesis in the\n  neutrino-wind following a neutron star merger","summary":"Neutron emission probabilities and half-lives of 37 beta-delayed neutron\nemitters from 75Ni to 92Br were measured at the RIKEN Nishina Center in Japan,\nincluding 11 one-neutron and 13 two-neutron emission probabilities and 6\nhalf-lives measured for the first time, which supersede theoretical estimates.\nThese nuclei lie in the path of the weak r-process occurring in neutrino-driven\nwinds from the accretion disk formed after the merger of two neutron stars,\nsynthesizing elements in the A~80 abundance peak. The presence of such elements\ndominates the accompanying kilonova emission over the first few days and has\nbeen identified in the AT2017gfo event, associated with the gravitational wave\ndetection GW170817.\n  Abundance calculations based on over 17000 simulated trajectories describing\nthe evolution of matter properties in the merger outflows show that the new\ndata lead to an increase of 50-70 percent in the abundance of Y, Zr, Nb, and\nMo. This enhancement is large compared to the scatter of relative abundances\nobserved in old very metal-poor stars and is therefore significant in the\ncomparison with other possible astrophysical processes contributing to\nlight-element production.\n  These results underline the importance of including experimental decay data\nfor very neutron-rich beta-delayed neutron emitters into r-process models.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-08T13:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06021v1","title":"Memory-Modular Classification: Learning to Generalize with Memory\n  Replacement","summary":"We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06034v1","title":"Distance to M87 as the Mode of the Modulus Distribution","summary":"de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87\nfrom the literature published in the last 100 years. They reported the\narithmetic mean of the three most stable tracers (Cepheids, tip of the red\ngiant branch, and surface brightness fluctuations). The arithmetic mean is one\nof the measures of central tendency of a distribution; others are the median\nand mode. The three do not align for asymmetric distributions, which is the\ncase for the distance moduli $\\mu_0$ to M87. I construct a kernel density\ndistribution of the set of $\\mu_0$ and estimate the recommended distance to M87\nas its mode, obtaining $\\mu_0 =\n\\left(31.06~\\pm~0.001\\,\\textrm{(statistical)}\\,^{+0.04}_{-0.06}\\,\\textrm{(systematic)}\\right)$~mag,\ncorresponding to \\linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields\nuncertainties smaller than those associated with the mean and median.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T13:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.06037v1","title":"Confidence Regularized Masked Language Modeling using Text Length","summary":"Masked language modeling, which is a task to predict a randomly masked word\nin the input text, is an efficient language representation learning method.\nMasked language modeling ignores various words which people can think of for\nfilling in the masked position and calculates the loss with a single word.\nEspecially when the input text is short, the entropy of the word distribution\nthat can fill in the masked position can be high. This may cause the model to\nbe overconfident in the single answer. To address this issue, we propose a\nnovel confidence regularizer that controls regularizing strength dynamically by\nthe input text length. Experiments with GLUE and SQuAD datasets showed that our\nmethod achieves better accuracy and lower expected calibration error.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T13:37:08Z"}
{"aid":"http://arxiv.org/abs/2504.06043v1","title":"Hadronic molecules and multiquark states","summary":"In this text different theoretical approaches towards multi-quark states are\nintroduced, namely hadrocharmonia, compact tetraquarks and hadronic molecules.\nThe predictions derived from either of them are contrasted with current and\npossible future observations. The focus is on doubly heavy systems, but singly\nheavy and light systems are mentioned briefly as well.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T13:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.06060v1","title":"Fast summation of fermionic Feynman diagrams beyond Bravais Lattices and\n  on-site Hubbard interactions","summary":"We designed new algorithms for summing bold-line Feynman diagrams in\narbitrary channels, where it can be readily modified for bare interaction\nseries as well. When applied to magnetic channel bold-line series with on-site\nHubbard interactions, the algorithm achieves competitive performance compared\nwith the state-of-art RPADet. We then generalize it beyond square lattice and\non-site Hubbard interactions and achieve better scaling in the number of sites\nwithin a unit cell, while there is substantial increase when there are more\ntypes of interactions. This work paves the way of diagrammatic Monte Carlo\nsimulations for real materials, holding the premise for a robust replacement of\nstate-of-art simulation tools in the thermodynamical limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T14:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.06066v1","title":"The Quantum Double of Hopf Algebras Realized via Partial Dualization and\n  the Tensor Category of Its Representations","summary":"In this paper, we aim to study the (generalized) quantum double\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ determined by a (skew) pairing between\nfinite-dimensional Hopf algebras $K^{\\ast\\mathrm{cop}}$ and $H$, especially the\ntensor category $\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ of its\nfinite-dimensional representations. Specifically, we show that\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ is a left partially dualized\n(quasi-)Hopf algebra of $K^\\mathrm{op}\\otimes H$, and use this formulation to\nestablish tensor equivalences from\n$\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ to the categories\n${}^K_K\\mathcal{M}^K_H$ and ${}^{K^\\ast}_{K^\\ast}\\mathcal{M}^{H^\\ast}_{K^\\ast}$\nof two-sided two-cosided relative Hopf modules, as well as the category\n${}_H\\mathfrak{YD}^K$ of relative Yetter-Drinfeld modules.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA","published":"2025-04-08T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.06093v1","title":"Coupling approaches with non-matching grids for classical linear\n  elasticity and bond-based peridynamic models in 1D","summary":"Local-nonlocal coupling approaches provide a means to combine the\ncomputational efficiency of local models and the accuracy of nonlocal models.\nTo facilitate the coupling of the two models, non-matching grids are often\ndesirable as nonlocal grids usually require a finer resolution than local\ngrids. In that case, it is often convenient to resort to interpolation\noperators so that models can exchange information in the overlap regions when\nnodes from the two grids do not coincide. This paper studies three existing\ncoupling approaches, namely 1) a method that enforces matching displacements in\nan overlap region, 2) a variant that enforces a constraint on the stresses\ninstead, and 3) a method that considers a variable horizon in the vicinity of\nthe interfaces. The effect of the interpolation order and of the grid ratio on\nthe performance of the three coupling methods with non-matching grids is\ncarefully studied on one-dimensional examples using polynomial manufactured\nsolutions. The numerical results show that the degree of the interpolants\nshould be chosen with care to avoid introducing additional modeling errors, or\nsimply minimize these errors, in the coupling approach.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-08T14:35:06Z"}
{"aid":"http://arxiv.org/abs/2504.06095v1","title":"Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for\n  Scaled-up LLM Training","summary":"LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-08T14:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.06105v1","title":"Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle\n  Sideslip Angle Estimation","summary":"Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-08T14:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.06120v1","title":"Hyperbolic Category Discovery","summary":"Generalized Category Discovery (GCD) is an intriguing open-world problem that\nhas garnered increasing attention. Given a dataset that includes both labelled\nand unlabelled images, GCD aims to categorize all images in the unlabelled\nsubset, regardless of whether they belong to known or unknown classes. In GCD,\nthe common practice typically involves applying a spherical projection operator\nat the end of the self-supervised pretrained backbone, operating within\nEuclidean or spherical space. However, both of these spaces have been shown to\nbe suboptimal for encoding samples that possesses hierarchical structures. In\ncontrast, hyperbolic space exhibits exponential volume growth relative to\nradius, making it inherently strong at capturing the hierarchical structure of\nsamples from both seen and unseen categories. Therefore, we propose to tackle\nthe category discovery challenge in the hyperbolic space. We introduce HypCD, a\nsimple \\underline{Hyp}erbolic framework for learning hierarchy-aware\nrepresentations and classifiers for generalized \\underline{C}ategory\n\\underline{D}iscovery. HypCD first transforms the Euclidean embedding space of\nthe backbone network into hyperbolic space, facilitating subsequent\nrepresentation and classification learning by considering both hyperbolic\ndistance and the angle between samples. This approach is particularly helpful\nfor knowledge transfer from known to unknown categories in GCD. We thoroughly\nevaluate HypCD on public GCD benchmarks, by applying it to various baseline and\nstate-of-the-art methods, consistently achieving significant improvements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:12:33Z"}
{"aid":"http://arxiv.org/abs/2504.06146v1","title":"Symmetry breaking in chaotic many-body quantum systems at finite\n  temperature","summary":"Recent work has shown that the entanglement of finite-temperature eigenstates\nin chaotic quantum many-body local Hamiltonians can be accurately described by\nan ensemble of random states with an internal $U(1)$ symmetry. We build upon\nthis result to investigate the universal symmetry-breaking properties of such\neigenstates. As a probe of symmetry breaking, we employ the entanglement\nasymmetry, a quantum information observable that quantifies the extent to which\nsymmetry is broken in a subsystem. This measure enables us to explore the finer\nstructure of finite-temperature eigenstates in terms of the $U(1)$-symmetric\nrandom state ensemble; in particular, the relation between the Hamiltonian and\nthe effective conserved charge in the ensemble. Our analysis is supported by\nanalytical calculations for the symmetric random states, as well as exact\nnumerical results for the Mixed-Field Ising spin-$1/2$ chain, a paradigmatic\nmodel of quantum chaoticity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-08T15:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.06147v1","title":"Noncommutative resolutions and CICY quotients from a non-abelian GLSM","summary":"We discuss a one-parameter non-abelian GLSM with gauge group $(U(1)\\times\nU(1)\\times U(1))\\rtimes\\mathbb{Z}_3$ and its associated Calabi-Yau phases. The\nlarge volume phase is a free $\\mathbb{Z}_3$-quotient of a codimension $3$\ncomplete intersection of degree-$(1,1,1)$ hypersurfaces in\n$\\mathbb{P}^2\\times\\mathbb{P}^2\\times\\mathbb{P}^2$. The associated Calabi-Yau\ndifferential operator has a second point of maximal unipotent monodromy,\nleading to the expectation that the other GLSM phase is geometric as well.\nHowever, the associated GLSM phase appears to be a hybrid model with continuous\nunbroken gauge symmetry and cubic superpotential, together with a Coulomb\nbranch. Using techniques from topological string theory and mirror symmetry we\ncollect evidence that the phase should correspond to a non-commutative\nresolution, in the sense of Katz-Klemm-Schimannek-Sharpe, of a codimension two\ncomplete intersection in weighted projective space with $63$ nodal points, for\nwhich a resolution has $\\mathbb{Z}_3$-torsion. We compute the associated\nGopakumar-Vafa invariants up to genus $11$, incorporating their torsion\nrefinement. We identify two integral symplectic bases constructed from\ntopological data of the mirror geometries in either phase.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:42:39Z"}
{"aid":"http://arxiv.org/abs/2504.06150v1","title":"Direct measurement of broken time-reversal symmetry in centrosymmetric\n  and non-centrosymmetric atomically thin crystals with nonlinear Kerr rotation","summary":"Time-reversal symmetry, together with space-inversion symmetry, is one of the\ndefining properties of crystals, underlying phenomena such as magnetism,\ntopology and non-trivial spin textures. Transition metal dichalcogenides (TMDs)\nprovide an excellent tunable model system to study the interplay between\ntime-reversal and space-inversion symmetry, since both can be engineered on\ndemand by tuning the number of layers and via all-optical bandgap modulation.\nIn this work, we modulate and study time-reversal symmetry using third harmonic\nKerr rotation in mono- and bilayer TMDs. By illuminating the samples with\nelliptically polarized light, we achieve spin-selective bandgap modulation and\nconsequent breaking of time-reversal symmetry. The reduced symmetry modifies\nthe nonlinear susceptibility tensor, causing a rotation of the emitted third\nharmonic polarization. With this method, we are able to probe broken\ntime-reversal symmetry in both non-centrosymmetric (monolayer) and\ncentrosymmetric (bilayer) crystals. Furthermore, we discuss how the detected\nthird harmonic rotation angle directly links to the spin-valley locking in\nmonolayer TMDs and to the spin-valley-layer locking in bilayer TMDs. Thus, our\nresults define a powerful approach to study broken time-reversal symmetry in\ncrystals regardless of space-inversion symmetry, and shed light on the spin,\nvalley and layer coupling of atomically thin semiconductors.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-08T15:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.06158v1","title":"Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation\n  with Attention Mechanisms and Multiscale Feature Fusion","summary":"Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T15:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.06159v1","title":"Enhancing Primary Teacher Training through Academic Portfolios in\n  Advanced Mathematics Courses","summary":"The gap between theory and practice in mathematics education, particularly in\nprimary-teacher education, necessitates innovative teaching methodologies. This\npaper explores the implementation of academic portfolios as a teaching\ninnovation in Algebra and Number Systems I and II courses within the primary\nteacher education programme at Pontificia Universidad Cat\\'olica de Chile. The\nmethodology involved integrating academic portfolios to align course content\nwith essential learning outcomes for future teaching roles. Implementation\nbegins with a negotiation between students and teachers to establish a learning\ncontract, followed by an overview of course rules, content, objectives,\nmaterials, and grading rubrics. Preliminary findings indicate that this\ninnovative method enhances engagement with mathematical concepts, improves\nassessment efficacy in teacher training, and may contribute to enhanced\npreparation of primary mathematics teachers. The study highlights the role of\nportfolios in making students active participants in their learning,\nsignificantly enhancing the educational experience of teacher candidates. These\nfindings suggest a promising avenue for future educational assessments and\nmethodologies in mathematics, indicating that academic portfolios can bridge\nthe gap between theoretical knowledge and practical applications in mathematics\nteacher education, potentially enhancing teacher preparation. While this study\nshows promising results, further research with larger samples and longer\ntimeframes would be beneficial to establish causality and long-term impacts.","main_category":"math.HO","categories":"math.HO","published":"2025-04-08T15:55:33Z"}
{"aid":"http://arxiv.org/abs/2504.06164v1","title":"Functional ItÃ´-formula and Taylor expansions for non-anticipative maps\n  of cÃ dlÃ g rough paths","summary":"We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).","main_category":"math.PR","categories":"math.PR,math.CA,q-fin.MF","published":"2025-04-08T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.06168v1","title":"Differential diffusion effects and super-adiabatic local temperature in\n  lean hydrogen-air turbulent flames","summary":"Analyzed in this paper are three-dimensional Direct Numerical Simulation\n(DNS) data obtained from seven statistically planar and one-dimensional, lean\ncomplex-chemistry hydrogen-air flames propagating in a box with forced\nturbulence. The simulation conditions cover a wide range of non-dimensional\nturbulent combustion characteristics. Specifically, root-mean-square turbulent\nvelocity is varied from 2.2 to 54 laminar flame speeds, integral length scale\nof turbulence is varied from 0.5 to 2.2 laminar flame thicknesses, Damk\\\"ohler\nand Karlovitz number are varied from 0.01 to 0.53 and from 10 to 1315,\nrespectively. Two equivalence ratios, 0.5 and 0.35, are explored. Turbulent\nburning velocities are evaluated for these seven low Lewis number flames and\nequidiffusion counterparts to six of them. Moreover, conditioned profiles of\ntemperature, fuel consumption and heat release rates and probabilities of\nfinding superadiabatic temperature are sampled from all seven low Lewis number\nflames. Analyses of obtained results show that both magnitude of superadiabatic\ntemperature and probability of finding it are decreased with increasing\nKarlovitz number Ka. However, significant influence of differential diffusion\neffects on local structure of flame reaction zones and bulk burning velocity is\nwell pronounced in all cases, even at Ka as high as 1315. Therefore, a decrease\nin magnitude of superadiabatic local temperature with increasing Karlovitz\nnumber or even negligible probability of finding such a high temperature at\nhigh Ka is not an evidence that differential diffusion effects play a minor\nrole under such conditions. The simulated mitigation of phenomenon of\nsuperadiabatic temperature at high Ka is attributed to intensification of\nturbulent mixing in local flame oxidation zones, rather than weakening\ndifferential diffusion effects in local flame reaction zones.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T16:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.06171v1","title":"Generalized Ridge Regression: Applications to Nonorthogonal Linear\n  Regression Models","summary":"This paper analyzes the possibilities of using the generalized ridge\nregression to mitigate multicollinearity in a multiple linear regression model.\nFor this purpose, we obtain the expressions for the estimated variance, the\ncoefficient of variation, the coefficient of correlation, the variance\ninflation factor and the condition number. The results obtained are illustrated\nwith two numerical examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T16:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.06173v1","title":"Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles\n  Using Deep Learning","summary":"Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.ET,cs.LG,eess.SP","published":"2025-04-08T16:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.06175v1","title":"Basic distillation with realistic noise","summary":"Entanglement distillation is a key component of modular quantum computing and\nlong-range quantum communications. However, this powerful tool to reduce noise\nin entangled states is difficult to realize in practice for two main reasons.\nFirst, operations used to carry out distillation inject noise they seek to\nremove. Second, the extent to which distillation can work under realistic\ndevice noise is less well-studied. In this work, we both simulate distillation\nusing a variety of device noise models and perform distillation experiments on\nfixed-frequency IBM devices. We find reasonable agreement between experimental\ndata and simulation done using Pauli and non-Pauli noise models. In our data we\nfind broad improvement when the metric of success for distillation is to\nimprove average Bell fidelity under effective global depolarizing noise, or\nremove coherent errors, or improve the Bell fidelity of mildly degraded Bell\npairs. We pave the way to obtain broad improvement from distillation under a\nstricter, but practically relevant, metric: distill non-local Bell pairs with\nhigher fidelity than possible to obtain with other available methods. Our\nresults also help understand metrics and requirements for quantum devices to\nuse entanglement distillation as a primitive for modular computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T16:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06197v1","title":"Orthogonal polynomials with complex densities and quantum minimal\n  surfaces","summary":"We show that the discrete Painlev\\'e-type equations arising from quantum\nminimal surfaces are equations for recurrence coefficients of orthogonal\npolynomials for indefinite hermitian products. As a consequence we obtain an\nexplicit formula for the initial conditions leading to positive solutions.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-08T16:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.06204v1","title":"Spin Squeezing via One-Axis Twisting in a Quadrupolar NMR system under\n  relaxation effects","summary":"This study investigates spin squeezed states in nuclear magnetic resonance\n(NMR) quadrupolar systems with spins I = 3/2 and I = 7/2 at room temperature,\ntaking into account the effects of relaxation on the dynamics. The origin of\nspin squeezing is attributed to the interaction between the nuclear quadrupole\nmoment and the electric field gradients in the molecular environment. The\nformal description of the nonlinear operators responsible for spin squeezing is\nachieved using the spin angular momentum representation via the one-axis\ntwisting mechanism. This approach provides a framework for quantum control and\nmetrology over the spin squeezing process while accounting for the influence of\nrelaxation phenomena. Non-Cartesian angular momentum operators are proposed,\nwith their variance products catching the quantum effects during the dynamics.\nAn upper bound for the squeezing parameter and the Heisenberg uncertainty at\nthermal equilibrium are also predicted for any spin quantum number.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T16:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.06215v1","title":"Randomization Inference in Two-Sided Market Experiments","summary":"Randomized experiments are increasingly employed in two-sided markets, such\nas buyer-seller platforms, to evaluate treatment effects from marketplace\ninterventions. These experiments must reflect the underlying two-sided market\nstructure in their design (e.g., sellers and buyers), making them particularly\nchallenging to analyze. In this paper, we propose a randomization inference\nframework to analyze outcomes from such two-sided experiments. Our approach is\nfinite-sample valid under sharp null hypotheses for any test statistic and\nmaintains asymptotic validity under weak null hypotheses through\nstudentization. Moreover, we provide heuristic guidance for choosing among\nmultiple valid randomization tests to enhance statistical power, which we\ndemonstrate empirically. Finally, we demonstrate the performance of our\nmethodology through a series of simulation studies.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-08T17:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.06225v1","title":"Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via\n  Adaptation","summary":"While decoder-only large language models (LLMs) have shown impressive\nresults, encoder-decoder models are still widely adopted in real-world\napplications for their inference efficiency and richer encoder representation.\nIn this paper, we study a novel problem: adapting pretrained decoder-only LLMs\nto encoder-decoder, with the goal of leveraging the strengths of both\napproaches to achieve a more favorable quality-efficiency trade-off. We argue\nthat adaptation not only enables inheriting the capability of decoder-only LLMs\nbut also reduces the demand for computation compared to pretraining from\nscratch. We rigorously explore different pretraining objectives and parameter\ninitialization/optimization techniques. Through extensive experiments based on\nGemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to\n1.6B), we demonstrate the effectiveness of adaptation and the advantage of\nencoder-decoder LLMs. Under similar inference budget, encoder-decoder LLMs\nachieve comparable (often better) pretraining performance but substantially\nbetter finetuning performance than their decoder-only counterpart. For example,\nGemma 2B-2B outperforms Gemma 2B by $\\sim$7\\% after instruction tuning.\nEncoder-decoder adaptation also allows for flexible combination of\ndifferent-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B\nby $>$3\\%. The adapted encoder representation also yields better results on\nSuperGLUE. We will release our checkpoints to facilitate future research.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T17:13:41Z"}
{"aid":"http://arxiv.org/abs/2504.06226v1","title":"Signatures of Candidate States of $Î½=12/5$ in Shot Noise","summary":"Fractional quantum Hall (FQH) states are highly sought after because of their\nability to host non-abelian anyons, whose braiding statistics make them\nexcellent candidates for qubits in topological quantum computing. Multiple\ntheoretical studies on the $\\nu=\\frac{12}{5}$ FQH state predict various\nquasi-particle states hosted by the $\\frac{12}{5}$ plateau, which include\n$\\mathbb Z_3$ parafermions and Majorana modes. In this work, we provide a\nsystematic protocol to distinguish among four possible candidate wavefunctions\nof the $\\frac{12}{5}$ plateau using zero-frequency short noise experiments on a\nfilter-geometry. Qualitative comparisons of Fano-Factors provide a robust way\nto predict the candidate state across both the full and partial thermal\nequilibration regimes without prior knowledge of the experimental information,\nlike thermal equilibration length, to allow for more realistic experiments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-08T17:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.06233v1","title":"On the homology of special unitary groups over polynomial rings","summary":"In this work, we answer the homotopy invariance question for the ''smallest''\nnon-isotrivial group-scheme over $\\mathbb{P}^1$, obtaining a result, which is\nnot contained in previous works due to Knudson and Wendt. More explicitly, let\n$\\mathcal{G}=\\mathrm{SU}_{3,\\mathbb{P}^1}$ be the (non-isotrivial) non-split\ngroup-scheme over $\\mathbb{P}^1$ defined from the standard (isotropic)\nhermitian form in three variables. In this article, we prove that there exists\na natural homomorphism $\\mathrm{PGL}_2(F) \\to \\mathcal{G}(F[t])$ that induces\nisomorphisms $H_*(\\mathrm{PGL}_2(F), \\mathbb{Z}) \\to H_*(\\mathcal{G}(F[t]),\n\\mathbb{Z})$. Then we study the rational homology of\n$\\mathcal{G}(F[t,t^{-1}])$, by previously describing suitable fundamental\ndomains for certain arithmetic subgroups of $\\mathcal{G}$.","main_category":"math.KT","categories":"math.KT,math.GR,math.NT","published":"2025-04-08T17:30:56Z"}
{"aid":"http://arxiv.org/abs/2504.06240v1","title":"Dictionary-free Koopman Predictive Control for Autonomous Vehicles in\n  Mixed Traffic","summary":"Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control\n(DeePC) use linear models to approximate nonlinear systems and integrate them\nwith predictive control. Both approaches have recently demonstrated promising\nperformance in controlling Connected and Autonomous Vehicles (CAVs) in mixed\ntraffic. However, selecting appropriate lifting functions for the Koopman\noperator in KMPC is challenging, while the data-driven representation from\nWillems' fundamental lemma in DeePC must be updated to approximate the local\nlinearization when the equilibrium traffic state changes. In this paper, we\npropose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV\ncontrol. In particular, we first introduce a behavioral perspective to identify\nthe optimal dictionary-free Koopman linear model. We then utilize an iterative\nalgorithm to compute a data-driven approximation of the dictionary-free Koopman\nrepresentation. Integrating this data-driven linear representation with\npredictive control leads to our DF-KMPC, which eliminates the need to select\nlifting functions and update the traffic equilibrium state. Nonlinear traffic\nsimulations show that DF-KMPC effectively mitigates traffic waves and improves\ntracking performance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-08T17:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06244v1","title":"The distinction between Ice phases VII, VIII and X","summary":"Ice phases VII, VIII and X are all based on a body-centered cubic arrangement\nof molecules, the differences coming from molecular orientation. There is some\ndebate as to whether these should even be considered distinct phases. The\nstandard definition of a transition between distinct phases involves a\ndiscontinuity in any derivative of the free energy. This can be hard to prove\nexperimentally, and most previous theoretical works have been based on models\nwhich either have continuously differentiable free energies, or no\nstraightforward way to determine the free energy. Here we build a free energy\nmodel based on the common definitions of the phases ; ordered ice-VIII,\norientationally disordered ice VII and proton-disordered ice X. All transitions\nin this model might or might not be associated with a discontinuity in the\nspecific heat, depending on paramaterization. By comparing with data, we find\nthat a VII-X transition line exists, but it ends in a critical point hidden\nwithin the stability field of phase VIII. If the model is correct, there is a\ndiscontinuity between VII and X, so they are separate phases. We propose that\nthe hidden phase boundary might be demonstrated experimentally by compression\nof supercooled ice VII.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.mtrl-sci","published":"2025-04-08T17:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.06253v1","title":"Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut","summary":"The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm\nthat finds approximate solutions to problems in combinatorial optimization,\nespecially those that can be formulated as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem. In prior work, researchers have considered various\nways of \"warm-starting\" QAOA by constructing an initial quantum state using\nclassically-obtained solutions or information; these warm-starts typically\ncause QAOA to yield better approximation ratios at much lower circuit depths.\nFor the Max-Cut problem, one warm-start approaches constructs the initial state\nusing the high-dimensional vectors that are output from an SDP relaxation of\nthe corresponding Max-Cut problem. This work leverages these semidefinite\nwarmstarts for a broader class of problem instances by using a standard\nreduction that transforms any QUBO instance into a Max-Cut instance. We\nempirically compare this approach to a \"QUBO-relaxation\" approach that relaxes\nthe QUBO directly. Our results consider a variety of QUBO instances ranging\nfrom randomly generated QUBOs to QUBOs corresponding to specific problems such\nas the traveling salesman problem, maximum independent set, and portfolio\noptimization. We find that the best choice of warmstart approach is strongly\ndependent on the problem type.","main_category":"quant-ph","categories":"quant-ph,cs.DM,math.OC","published":"2025-04-08T17:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06546v1","title":"Several new infinite families of NMDS codes with arbitrary dimensions\n  supporting $t$-designs","summary":"Near maximum distance separable (NMDS) codes, where both the code and its\ndual are almost maximum distance separable, play pivotal roles in combinatorial\ndesign theory and cryptographic applications. Despite progress in fixed\ndimensions (e.g., dimension 4 codes by Ding and Tang \\cite{Ding2020}),\nconstructing NMDS codes with arbitrary dimensions supporting $t$-designs\n($t\\geq 2$) has remained open. In this paper, we construct two infinite\nfamilies of NMDS codes over $\\mathbb{F}_q$ for any prime power $q$ with\nflexible dimensions and determine their weight distributions. Further, two\nadditional families with arbitrary dimensions over $\\mathbb{F}_{2^m}$\nsupporting $2$-designs and $3$-designs, and their weight distributions are\nobtained. Our results fully generalize prior fixed-dimension\nworks~\\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the\nHeng-Wang conjecture \\cite{Heng2023} on the existence of NMDS codes with\nflexible parameters supporting $2$-designs.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T03:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.06576v1","title":"Theoretical analysis for non-linear effects of magnetic fields on\n  unsteady boundary layer flows","summary":"This study investigates unsteady boundary layer phenomena in electrically\nconducting fluids subjected to static magnetic fields. Using a semi-explicit\nsimilarity transformation method, the momentum equation associated with the\nStokes stream function is solved. The nonlinear closed analytical solutions for\nboth stagnation flow and converging flow are derived. The results demonstrate\nthat the boundary layer structure incorporates similar shock and solitary wave\ncomponents which are promoted by Lorentz force. Under extreme magnetic fields,\nthe flow exhibits sine and cosine wave patterns, which are motivated by the\nstrong Lorentz force. An in-depth asymptotic analysis establishes the square\nroot scaling laws that quantify the growth of friction and flux with increasing\nmagnetic field strength. The boundary layer thickness scales inversely with the\nHartmann number, a consequence of dominant Lorentz force, which differs from\nthe conclusion of duct flow (Hunt 1965). These findings elucidate the physical\nmechanisms governing the nonlinear coupling between magnetic fields and the\ndynamics of the boundary layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T04:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.06582v1","title":"Harmful information spreading and its impact on vaccination campaigns\n  modeled through fractal-fractional operators","summary":"Despite the huge efforts to develop and administer vaccines worldwide to cope\nwith the COVID-19 pandemic, misinformation spreading through fake news in media\nand social networks about vaccination safety, make that people refuse to be\nvaccinated, which harms not only these people but also the whole population.\n  In this work, we model the effects of harmful information spreading in\nimmunization acquisition through vaccination. Our model is posed for several\nfractional derivative operators. We have conducted a comprehensive foundation\nanalysis of this model for the different fractional derivatives. Additionally,\nwe have incorporated a strength parameter that shows the combined impact of\nnonlinear and linear components within an epidemiological model. We have used\nthe second derivative of the Lyapunov function to ascertain the detection of\nwave patterns within the vaccination dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T05:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.06583v1","title":"Aplicando diferencias finitas para resolver ecuaciones y sistemas de\n  ecuaciones diferenciales parciales sobre dominios planos irregulares\n  simplemente conexos y no conexos","summary":"Using exhaustion method and finite differences a new method to solve system\nof partial differential equations and is presented. This method allows design\nalgorithm to solve linear and nonlinear systems in irregular domains. Applying\nthis method to solve linear and nonlinear problems with prescribed conditions\nDirichlet over two-dimensional irregular domains are analyzed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T05:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.06603v1","title":"Asymptotic Variance in the Central Limit Theorem for Multilevel\n  Markovian Stochastic Approximation","summary":"In this note we consider the finite-dimensional parameter estimation problem\nassociated to inverse problems. In such scenarios, one seeks to maximize the\nmarginal likelihood associated to a Bayesian model. This latter model is\nconnected to the solution of partial or ordinary differential equation. As\nsuch, there are two primary difficulties in maximizing the marginal likelihood\n(i) that the solution of differential equation is not always analytically\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\nwith using a numerical solution of the differential equation, leading to a\nnumerical bias and (ii) has been well studied in the literature using, for\ninstance, Markovian stochastic approximation. It is well-known that to reduce\nthe computational effort to obtain the maximal value of the parameter, one can\nuse a hierarchy of solutions of the differential equation and combine with\nstochastic gradient methods. Several approaches do exactly this. In this paper\nwe consider the asymptotic variance in the central limit theorem, associated to\nknown estimates and find bounds on the asymptotic variance in terms of the\nprecision of the solution of the differential equation. The significance of\nthese bounds are the that they provide missing theoretical guidelines on how to\nset simulation parameters; that is, these appear to be the first mathematical\nresults which help to run the methods efficiently in practice.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.CO","published":"2025-04-09T05:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.06614v1","title":"AgentFM: Role-Aware Failure Management for Distributed Databases with\n  LLM-Driven Multi-Agents","summary":"Distributed databases are critical infrastructures for today's large-scale\nsoftware systems, making effective failure management essential to ensure\nsoftware availability. However, existing approaches often overlook the role\ndistinctions within distributed databases and rely on small-scale models with\nlimited generalization capabilities. In this paper, we conduct a preliminary\nempirical study to emphasize the unique significance of different roles.\nBuilding on this insight, we propose AgentFM, a role-aware failure management\nframework for distributed databases powered by LLM-driven multi-agents. AgentFM\naddresses failure management by considering system roles, data roles, and task\nroles, with a meta-agent orchestrating these components. Preliminary\nevaluations using Apache IoTDB demonstrate the effectiveness of AgentFM and\nopen new directions for further research.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T06:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.06619v1","title":"Sufficient conditions for a graph with minimum degree to have a\n  component factor","summary":"Let $\\mathcal{T}_{\\frac{k}{r}}$ denote the set of trees $T$ such that\n$i(T-S)\\leq\\frac{k}{r}|S|$ for any $S\\subset V(T)$ and for any $e\\in E(T)$\nthere exists a set $S^{*}\\subset V(T)$ with\n$i((T-e)-S^{*})>\\frac{k}{r}|S^{*}|$, where $r<k$ are two positive integers. A\n$\\{C_{2i+1},T:1\\leq i<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor of\na graph $G$ is a spanning subgraph of $G$, in which every component is\nisomorphic to an element in $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$. Let $A(G)$ and $Q(G)$ denote\nthe adjacency matrix and the signless Laplacian matrix of $G$, respectively.\nThe adjacency spectral radius and the signless Laplacian spectral radius of\n$G$, denoted by $\\rho(G)$ and $q(G)$, are the largest eigenvalues of $A(G)$ and\n$Q(G)$, respectively. In this paper, we study the connections between the\nspectral radius and the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. We first\nestablish a tight sufficient condition involving the adjacency spectral radius\nto guarantee the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. Then we\npropose a tight signless Laplacian spectral radius condition for the existence\nof a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:35:29Z"}
{"aid":"http://arxiv.org/abs/2504.06628v1","title":"Entropy Production in Non-Gaussian Active Matter: A Unified Fluctuation\n  Theorem and Deep Learning Framework","summary":"We present a general framework for deriving entropy production rates in\nactive matter systems driven by non-Gaussian active fluctuations. Employing the\nprobability flow equivalence technique, we rigorously derive an entropy\nproduction decomposition formula and demonstrate that the entropy production,\n$\\Delta s_\\mathrm{tot}$, satisfies the integral fluctuation theorem $\\langle\n\\exp[ -\\Delta s_\\mathrm{tot} + B_\\mathrm{act}] \\rangle = 1$ and the generalized\nsecond law of thermodynamics $\\langle \\Delta s_\\mathrm{tot}\\rangle \\geq\\langle\nB_\\mathrm{act}\\rangle$, where $B_\\mathrm{act}$ is a path-dependent random\nvariable associated with the active fluctuations. Our result holds generally\nfor arbitrary initial conditions, encompassing both steady-state and transient\nfinite-time regimes. In the limiting case where active fluctuations are absent\n(i.e., $B_\\mathrm{act} \\equiv 0$), the theorem reduces to the well-established\nresults in stochastic thermodynamics. Building on the theoretical foundation,\nwe propose a deep learning-based methodology to efficiently compute the entropy\nproduction, utilizing the L\\'{e}vy score function we proposed. To illustrate\nthe validity of this approach, we apply it to two representative systems: a\nBrownian particle in a periodic active bath and an active polymer system\nconsisting of an active Brownian particle cross-linker interacting with passive\nBrownian beads. Our results provide a unified framework for analyzing entropy\nproduction in active matter systems while offering practical computational\ntools for investigating complex nonequilibrium behaviors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-09T07:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.06629v1","title":"Rethinking LayerNorm in Image Restoration Transformers","summary":"This work investigates abnormal feature behaviors observed in image\nrestoration (IR) Transformers. Specifically, we identify two critical issues:\nfeature entropy becoming excessively small and feature magnitudes diverging up\nto a million-fold scale. We pinpoint the root cause to the per-token\nnormalization aspect of conventional LayerNorm, which disrupts essential\nspatial correlations and internal feature statistics. To address this, we\npropose a simple normalization strategy tailored for IR Transformers. Our\napproach applies normalization across the entire spatio-channel dimension,\neffectively preserving spatial correlations. Additionally, we introduce an\ninput-adaptive rescaling method that aligns feature statistics to the unique\nstatistical requirements of each input. Experimental results verify that this\ncombined strategy effectively resolves feature divergence, significantly\nenhancing both the stability and performance of IR Transformers across various\nIR tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.06653v1","title":"Hunting axion dark matter signatures in low-frequency terrestrial\n  magnetic fields","summary":"We show that Earth's natural environment can serve as a powerful probe for\nultralight axion dark matter. In the presence of global geomagnetic fields, the\naxions with masses ranging from $10^{-15}\\,{\\rm eV}-10^{-13}\\,{\\rm eV}$ induce\nelectromagnetic waves in the (sub-) extremely low-frequency band ($0.3-30\\,{\\rm\nHz}$) through the axion-photon coupling. We predict the amplitude of induced\nmagnetic fields in the Earth-ionosphere cavity, taking the finite conductivity\nof the atmosphere into account. This allows us to constrain the axion-photon\ncoupling parameter, $g_{\\rm a\\gamma}$, from the long-term monitoring data of\nthe low-frequency magnetic fields, resulting in a significant improvement from\nthe previous constraints down to $g_{\\rm a\\gamma} \\lesssim\n4\\times10^{-13}\\,{\\rm GeV}^{-1}$ for axion mass $\\sim 3 \\times 10^{-14}\\,{\\rm\neV}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-09T07:42:28Z"}
{"aid":"http://arxiv.org/abs/2504.06665v1","title":"Rational points of bounded height on entire curves","summary":"Let $X$ be an affine or a projective variety defined over a number field $K$\nand $\\varphi:{\\bf C}\\to X({\\bf C})$ be a holomorphic map with Zariski dense\nimage. We estimate the number of rational points of height bounded by $H$ in\nthe image of a disk of radius $r$ in terms of the the Nevanlinna characteristic\nfunction of $\\varphi$ and $H$ in a way which generalize the classical\nBombieri--Pila estimate to expanding domains. In general this bound is\nexponential but we show that for many values of $H$ and $r$, the bound is\npolynomial.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T07:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06689v1","title":"Les Houches 2023 -- Physics at TeV Colliders: Report on the Standard\n  Model Precision Wishlist","summary":"Les Houches returned to an in-person format in 2023 and the bi-yearly\ntradition of updating the standard model precision wishlist has continued. In\nthis work we review recent progress (since Les Houches 2021) in fixed-order\ncomputations for LHC applications. In addition, necessary ingredients for such\ncalculations such as parton distribution functions, amplitudes, and subtraction\nmethods are discussed. Finally, we indicate processes and missing higher-order\ncorrections that are required to reach the theoretical accuracy that matches\nthe anticipated experimental precision.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-09T08:50:05Z"}
{"aid":"http://arxiv.org/abs/2504.06722v1","title":"Plastic tensor networks for interpretable generative modeling","summary":"A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech","published":"2025-04-09T09:23:11Z"}
{"aid":"http://arxiv.org/abs/2504.06725v1","title":"Using theory-driven Integrated Population Models to evaluate competitive\n  outcomes in stage-structured systems","summary":"Predicting competitive outcomes typically requires fitting dynamical models\nto data, from which interaction strengths and coexistence indicators such as\ninvasion criteria can be produced. Methods that allow to propagate parameter\nuncertainty are particularly indicated. These should ideally allow for\ncompetition between and within species at various life-stages, and make the\nbest out of multiple data sources, each of which can be relatively scarce by\nstatistical standards. Here, we embed a mathematical model of stage-structured\ncompetition between two species, producing analytical invasion criteria, into a\ntwo-species Integrated Population Model. The community-level IPM allows to\ncombine counts, capture-recapture, and fecundity data into a single statistical\nframework, and the Bayesian formulation of the IPM fully propagates parameter\nuncertainty into invasion criteria. Model fitting demonstrates that we can\ncorrectly predict coexistence through reciprocal invasion when present, but\nthat interaction strengths are not always estimable, depending on the prior\nchosen. Our competitive exclusion scenario is shown to be harder to identify,\nalthough our model allows to at least flag this scenario as uncertain rather\nthan mistakenly present it as coexistence. Our results confirm the importance\nof accounting for uncertainty in the prediction of competitive outcomes.","main_category":"q-bio.PE","categories":"q-bio.PE,stat.AP,stat.ME","published":"2025-04-09T09:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.06734v1","title":"Locally Repairable Convertible Codes: Improved Lower Bound and General\n  Construction","summary":"In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T09:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.06749v1","title":"Evidence of star cluster migration and merger in dwarf galaxies","summary":"Nuclear star clusters (NSCs) are the densest stellar systems in the Universe.\nThey can be found at the center of all galaxy types, but tend to favor galaxies\nof intermediate stellar mass around 10$^9\\,$M$_{\\odot}$[1, 2]. Currently, two\nmain processes are under debate to explain their formation: in-situ\nstar-formation from gas infall[3] and migration and merging of globular\nclusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar\npopulations suggest that the former predominates in massive galaxies, the\nlatter prevails in dwarf galaxies, and both contribute equally at intermediate\nmass. However, up to now, no ongoing merger of GCs has yet been observed to\nconfirm this scenario. Here we report the serendipitous discovery of five dwarf\ngalaxies with complex nuclear regions, characterized by multiple nuclei and\ntidal tails, using high resolution images from the Hubble Space Telescope.\nThese structures have been reproduced in complementary N-body simulations,\nsupporting the interpretation that they result from migrating and merging of\nstar clusters. The small detection rate and short simulated timescales (below\n100 Myr) of this process may explain why this has not been observed previously.\nThis study highlights the need of large surveys with high resolution to fully\nmap the migration scenario steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T10:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.06753v1","title":"Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced\n  Auditory Perception","summary":"The rapid advancement of audio generation technologies has escalated the\nrisks of malicious deepfake audio across speech, sound, singing voice, and\nmusic, threatening multimedia security and trust. While existing\ncountermeasures (CMs) perform well in single-type audio deepfake detection\n(ADD), their performance declines in cross-type scenarios. This paper is\ndedicated to studying the alltype ADD task. We are the first to comprehensively\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\ncross-type deepfake detection across speech, sound, singing voice, and music.\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\nConsidering the auditory perception of different audio types,we propose the\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\ndeepfake information from the frequency domain without requiring additional\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\nbest performance, with an average EER of 3.58% across all evaluation sets. The\ncode is available online.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-09T10:18:45Z"}
{"aid":"http://arxiv.org/abs/2504.06756v1","title":"Preservation of notion of C sets near zero over reals","summary":"There are several notions of largeness in a semigroup. N. Hindman and D.\nStrauss established that if $u,v \\in \\mathbb{N}$, $A$ is a $u \\times v$ matrix\nwith entries from $\\mathbb{Q}$ and $\\psi$ is a notion of a large set in\n$\\mathbb{N}$, then $\\{\\vec{x} \\in \\mathbb{N}^v: A\\vec{x} \\in \\psi^u \\}$ is\nlarge in $\\mathbb{N}^v$. Among the several notions of largeness, C sets\noccupies an important place of study because they exhibit strong combinatorial\nproperties. The analogous notion of C set appears for a dense subsemigroup $S$\nof $((0, \\infty),+)$ called a C-set near zero. These sets also have very rich\ncombinatorial structure. In this article, we investigate the above result for C\nsets near zero in $\\mathbb{R}^+$ when the matrix has real entries. We also\ndevelop a new characterisation of C-sets near zero in $\\mathbb{R}^+$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T10:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.06762v1","title":"Matching and Edge Cover in Temporal Graphs","summary":"Temporal graphs are a special class of graphs for which a temporal component\nis added to edges, that is, each edge possesses a set of times at which it is\navailable and can be traversed. Many classical problems on graphs can be\ntranslated to temporal graphs, and the results may differ. In this paper, we\ndefine the Temporal Edge Cover and Temporal Matching problems and show that\nthey are NP-complete even when fixing the lifetime or when the underlying graph\nis a tree. We then describe two FPT algorithms, with parameters lifetime and\ntreewidth, that solve the two problems. We also find lower bounds for the\napproximation of the two problems and give two approximation algorithms which\nmatch these bounds. Finally, we discuss the differences between the problems in\nthe temporal and the static framework.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-09T10:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.06763v1","title":"Convergence of a continuous Galerkin method for the Biot-Allard\n  poroelasticity system","summary":"We study a space-time finite element method for a system of poromechanics\nwith memory effects that are modeled by a convolution integral. In the\nliterature, the system is referred to as the Biot-Allard model. We recast the\nmodel as a first-order system in time, where the memory effects are transformed\ninto an auxiliary differential equation. This allows for a computationally\nefficient numerical scheme. The system is discretized by continuous Galerkin\nmethods in time and equal-order finite element methods in space. An optimal\norder error estimate is proved for the norm of the first-order energy of the\nunknowns of the system. The estimate is confirmed by numerical experiments.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06788v1","title":"FOREVER22: Insights into star formation and clustering properties of\n  protoclusters from simulations and JWST","summary":"Using cosmological hydrodynamic simulations with radiative transfer, we\ninvestigate star formation and overdensity ($\\delta$) in Coma-type cluster\nprogenitors from $z=14$ to 6. Our simulations reproduce observed $M_{\\rm\nstar}$-SFR relations and $\\delta$ at these redshifts. We find: (1) protocluster\n(PC) and mean-density field (MF) galaxies show similar $M_{\\rm star}$-SFR\nrelations, with PC galaxies extending to higher $M_{\\rm star}$ and SFR. (2)\nUV-bright PC galaxies ($M_{\\rm UV}\\lesssim -20$~mag) have $>2$ mag higher UV\nattenuation and shallower UV slopes than MF galaxies. (3) $\\delta$ increases\nwith redshift, depending on observational parameters (e.g., $\\delta\\sim50$ at\n$z=14$ to $\\delta\\sim3$ at $z=6$ for a search volume of $\\sim3000$~cMpc$^3$ and\na limiting magnitude of $M_{\\rm UV}=-17$~mag). These results indicate that\nenhanced star formation in PCs is driven by massive galaxy overdensity, not\nanomalously high specific SFR. While simulated $\\delta$ agrees with observed PC\ncandidates (potential Coma progenitors), some MF galaxies show comparable\n$\\delta$. We propose a robust PC identification method using both $\\delta$ and\n$M_{\\rm star}$ of the most massive member. Critical $M_{\\rm star}$ thresholds\nfor Coma progenitors are estimated ($10^{7.1}$ to $10^{10.2}$ M$_\\odot$ from\n$z=14$ to 6). Comparison with JWST observations suggests GS-z14-0 and GS-z14-1,\nthe current highest redshift holders, are likely progenitors of Coma-type\nclusters.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-09T11:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.06790v1","title":"Analog Computing with Microwave Networks","summary":"Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-09T11:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.06791v1","title":"Beware of \"Explanations\" of AI","summary":"Understanding the decisions made and actions taken by increasingly complex AI\nsystem remains a key challenge. This has led to an expanding field of research\nin explainable artificial intelligence (XAI), highlighting the potential of\nexplanations to enhance trust, support adoption, and meet regulatory standards.\nHowever, the question of what constitutes a \"good\" explanation is dependent on\nthe goals, stakeholders, and context. At a high level, psychological insights\nsuch as the concept of mental model alignment can offer guidance, but success\nin practice is challenging due to social and technical factors. As a result of\nthis ill-defined nature of the problem, explanations can be of poor quality\n(e.g. unfaithful, irrelevant, or incoherent), potentially leading to\nsubstantial risks. Instead of fostering trust and safety, poorly designed\nexplanations can actually cause harm, including wrong decisions, privacy\nviolations, manipulation, and even reduced AI adoption. Therefore, we caution\nstakeholders to beware of explanations of AI: while they can be vital, they are\nnot automatically a remedy for transparency or responsible AI adoption, and\ntheir misuse or limitations can exacerbate harm. Attention to these caveats can\nhelp guide future research to improve the quality and impact of AI\nexplanations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.06805v1","title":"Robust Classification with Noisy Labels Based on Posterior Maximization","summary":"Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.06828v1","title":"New physics particles mixing with mesons: production in the\n  fragmentation chain","summary":"A class of extensions to the Standard Model adds hypothetical long-lived\nparticles (LLPs) that have mass- or kinetic-mixing with neutral mesons, such as\npions or rho mesons. The mixing can contribute significantly to the production\nof LLPs at proton accelerator experiments, and no consistent description of\nthese production modes exists in the literature. In this paper, we develop a\nframework for studying different LLPs - dark photons, vector mediators coupled\nto the baryon current, and axion-like particles with different coupling\npatterns. In particular, we implement the production mechanisms in\n\\texttt{PYTHIA8}, study how the overall flux and kinematic distributions depend\non the LLP's mass, and compare various sub-processes where the mixing\ncontributes - proton bremsstrahlung, meson decay, and production in the\nfragmentation chain. We find that our new description of LLP production\npredicts an integrated flux that differs from current approaches by one to two\norders of magnitude, and highlight the unavoidable theoretical uncertainties\ncoming from poor knowledge of the properties of heavy mesons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T12:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.06829v1","title":"Adaptive Locally Linear Embedding","summary":"Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T12:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.06837v1","title":"Discrete-to-continuum limit for nonlinear reaction-diffusion systems via\n  EDP convergence for gradient systems","summary":"We investigate the convergence of spatial discretizations for\nreaction-diffusion systems with mass-action law satisfying a detailed balance\ncondition. Considering systems on the d-dimensional torus, we construct\nappropriate space-discrete processes and show convergence not only on the level\nof solutions, but also on the level of the gradient systems governing the\nevolutions. As an important step, we prove chain rule inequalities for the\nreaction-diffusion systems as well as their discretizations, featuring a\nnon-convex dissipation functional. The convergence is then obtained with\nvariational methods by building on the recently introduced notion of gradient\nsystems in continuity equation format.","main_category":"math.AP","categories":"math.AP,cs.NA,math-ph,math.DS,math.MP,math.NA","published":"2025-04-09T12:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.06853v1","title":"Magnetic ground state discrimination of a Polyradical Nanog-raphene\n  using Nickelocene-Functionalized Tips","summary":"Molecular magnets are a promising class of materials with exciting properties\nand applications. However, a profound understanding and application of such\nmaterials depends on the accurate detection of their electronic and magnetic\nproperties. Despite the availability of experimental techniques that can sense\nthe magnetic signal, the exact determination of the spin ground states and\nspatial distribution of exchange interaction of strongly correlated\nsingle-molecule magnets remains challenging. Here, we demonstrate that scanning\nprobe microscopy with a nickelocene-functionalized probe can distinguish\nbetween nearly degenerate multireference ground states of single-molecule\n{\\pi}-magnets and map their spatial distribution of the exchange interaction.\nThis method expands the already outstanding imaging capabilities of scanning\nprobe microscopy for characterizing the chemical and electronic structures of\nindividual molecules, paving the way for the study of strongly correlated\nmolecular magnets with unprecedented spatial resolution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-09T13:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.06855v1","title":"Compactified moduli spaces and Hecke correspondences for elliptic curves\n  with a prescribed $N$-torsion scheme","summary":"Given an integer $N \\geq 3$, we prove that for any ring $R$ and any finite\nlocally free $R$-group scheme $G$ which is fppf-locally (over $R$) isomorphic\nthe $N$-torsion subscheme of some elliptic curve $E/R$, there is a smooth\naffine curve $Y_G(N)$ parametrizing elliptic curves over $R$-schemes whose\n$N$-torsion subscheme is isomorphic to $G$. We also describe compactifications\n$X_G(N)$ of these curves when $R$ is a regular excellent Noetherian ring in\nwhich $N$ is invertible, as well as construct the Hecke correspondences they\nare endowed with. As an application, we show that the equations for $X_G(N)$\nfound over base fields for $N=7,8,9,11,13$ (by Halberstadt--Kraus,\nPoonen--Schaefer--Stoll, Chen and Fisher) are in fact valid over regular\nexcellent Noetherian bases that are $\\mathbb{Q}$-algebras. Finally, we describe\nin detail the equivalence of this construction with the point of view of Galois\ntwists that these authors use.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T13:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.06860v1","title":"Machine Learning (ML) based Reduced Order Modeling (ROM) for linear and\n  non-linear solid and structural mechanics","summary":"Multiple model reduction techniques have been proposed to tackle linear and\nnon linear problems. Intrusive model order reduction techniques exhibit high\naccuracy levels, however, they are rarely used as a standalone industrial tool,\nbecause of the required high level knowledge involved in the construction and\nusage of these techniques. Moreover, the computation time benefit is\ncompromised for highly nonlinear problems. On the other hand, non-intrusive\nmethods often struggle with accuracy in nonlinear cases, typically requiring a\nlarge design of experiment and a large number of snapshots achieve a reliable\nperformance. However, generating the stiffness matrix in a non-intrusive\napproach presents an optimal way to align accuracy with efficiency, allying the\nadvantages of both intrusive and non-intrusive methods.This work introduces a\nlightly intrusive model order reduction technique that employs machine learning\nwithin a Proper Orthogonal Decomposition framework to achieve this alliance. By\nleveraging outputs from commercial full-order models, this method constructs a\nreduced-order model that operates effectively without requiring expert user\nintervention. The proposed technique has the possibility to approximate linear\nnon affine as well as non linear terms. It is showcased for linear and\nnonlinear structural mechanics problems.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-09T13:11:05Z"}
{"aid":"http://arxiv.org/abs/2504.06869v1","title":"Grouping Strategies on Two-Phase Methods for Bi-objective Combinatorial\n  Optimization","summary":"Two-phase methods are commonly used to solve bi-objective combinatorial\noptimization problems. In the first phase, all extreme supported nondominated\npoints are generated through a dichotomic search. This phase also allows the\nidentification of search zones that may contain other nondominated points. The\nsecond phase focuses on exploring these search zones to locate the remaining\npoints, which typically accounts for most of the computational cost. Ranking\nalgorithms are frequently employed to explore each zone individually, but this\napproach leads to redundancies, causing multiple visits to the same solutions.\nTo mitigate these redundancies, we propose several strategies that group\nadjacent zones, allowing a single run of the ranking algorithm for the entire\ngroup. Additionally, we explore an implicit grouping approach based on a new\nconcept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem\ndemonstrate the beneficial impact of these grouping strategies when combined\nwith coverage.","main_category":"cs.DS","categories":"cs.DS,cs.DM","published":"2025-04-09T13:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.06876v1","title":"Anomalous transport models for fluid classification: insights from an\n  experimentally driven approach","summary":"In recent years, research and development in nanoscale science and technology\nhave grown significantly, with electrical transport playing a key role. A\nnatural challenge for its description is to shed light on anomalous behaviours\nobserved in a variety of low-dimensional systems. We use a synergistic\ncombination of experimental and mathematical modelling to explore the transport\nproperties of the electrical discharge observed within a micro-gap based sensor\nimmersed in fluids with different insulating properties. Data from laboratory\nexperiments are collected and used to inform and calibrate four mathematical\nmodels that comprise partial differential equations describing different kinds\nof transport, including anomalous diffusion: the Gaussian Model with Time\nDependent Diffusion Coefficient, the Porous Medium Equation, the\nKardar-Parisi-Zhang Equation and the Telegrapher Equation. Performance analysis\nof the models through data fitting reveals that the Gaussian Model with a\nTime-Dependent Diffusion Coefficient most effectively describes the observed\nphenomena. This model proves particularly valuable in characterizing the\ntransport properties of electrical discharges when the micro-electrodes are\nimmersed in a wide range of insulating as well as conductive fluids. Indeed, it\ncan suitably reproduce a range of behaviours spanning from clogging to bursts,\nallowing accurate and quite general fluid classification. Finally, we apply the\ndata-driven mathematical modeling approach to ethanol-water mixtures. The\nresults show the model's potential for accurate prediction, making it a\npromising method for analyzing and classifying fluids with unknown insulating\nproperties.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.flu-dyn","published":"2025-04-09T13:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06895v1","title":"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization\n  Through Separating Utilities","summary":"Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.06899v1","title":"SVTest: general purpose software for testing weakly random sources with\n  exemplary application to seismic data analysis enabling quantum amplification","summary":"Generating private randomness is essential for numerous applications ranging\nfrom security proofs to online banking. Consequently, the capacity of quantum\ndevices to amplify the privacy of a weak source of randomness, in cases\nunattainable by classical methods, constitutes a practical advantage. One of\nthe theoretical models of such weak sources are the so-called Santha-Vazirani\n(SV) sources; however, finding natural sources satisfying the SV model is a\nparamount challenge. In this article, we take three significant steps on the\nway to simplify this hard task. We begin with an in-depth analysis of the\nmathematical background for estimating the quality of a weak randomness source\nby providing a set of axioms that systematize the possible approaches to such\nestimation. We then develop software (SVTest) to estimate the parameter\ncharacterizing the source's randomness. The software is general-purpose, i.e.,\nit can test the randomness of any target sequence of bits. Later, we apply the\nsoftware to test seismic events (earthquakes and local noise) as potential\nsources of randomness. Our results demonstrate that seismic phenomena are\npossible sources of randomness, depending on the choice of discretization.\nTherefore, our work provides strong evidence of the potential of geophysical\nphenomena as a source of cryptographic resources, building an unprecedented\nbridge between both fields.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.06915v1","title":"An Analysis of Temporal Dropout in Earth Observation Time Series for\n  Regression Tasks","summary":"Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-09T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.06933v1","title":"Well-posedness of half-harmonic map heat flows for rough initial data","summary":"We adopt the Koch-Tataru theory for the Navier-Stokes equations, based on\nCarleson measure estimates, to develop a scaling-critical low-regularity\nframework for half-harmonic map heat flows. This nonlocal variant of the\nharmonic map heat flow has been studied recently in connection with free\nboundary minimal surfaces. We introduce a new class of initial data for the\nflow, broader than the conventional energy or Sobolev spaces considered in\nprevious work, for which we establish existence, uniqueness, and continuous\ndependence.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06937v1","title":"Finite Field Multiple Access III: from 2-ary to p-ary","summary":"This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.06941v1","title":"Proofs of two conjectures on congruences of overcubic partition triples","summary":"Let $\\overline{bt}(n)$ denote the number of overcubic partition triples of\n$n$. Nayaka, Dharmendra and Kumar proved some congruences modulo 8, 16 and 32\nfor $\\overline{bt}(n)$. Recently, Saikia and Sarma established some congruences\nmodulo 64 for $\\overline{bt}(n)$ by using both elementary techniques and the\ntheory of modular forms. In their paper, they also posed two conjectures on\ninfinite families of congruences modulo 64 and 128 for $\\overline{bt}(n)$. In\nthis paper, we confirm the two conjectures.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.06945v1","title":"Generic deformation channels for critical Fermi surfaces including the\n  impact of collisions","summary":"This paper constitutes a sequel to our theoretical efforts to determine the\nnature of the generic low-energy deformations of the Fermi surface of a\nquantum-critical metal, which arises at the stable non-Fermi liquid (NFL) fixed\npoint of a quantum phase transition. The emergent critical Fermi surface,\narising right at the Ising-nematic quantum critical point (QCP), is a\nparadigmatic example where an NFL behaviour is induced by the strong\ninteractions of the fermionic degrees of freedom with those of the bosonic\norder parameter. It is an artifact of the bosonic modes becoming massless at\nthe QCP, thus undergoing Landau damping at the level of one-loop self-energy.\nWe resort to the well-tested formalism of the quantum Boltzmann equations\n(QBEs)for identifying the excitations. While in our earlier works, we have\nfocussed on the collisionless regime by neglecting the collision integral and\nassuming the bosons to be in equilibrium, here we embark on a full analysis. In\nparticular, we take into account the bosonic part of the QBEs. The final\nresults show that that the emergent modes are long-lived and robust against the\ndamping effects brought about the collision integral(s), exhibiting the same\nqualitative features as obtained from the no-collision approximations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,hep-th","published":"2025-04-09T14:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06949v1","title":"Adaptive Computation Pruning for the Forgetting Transformer","summary":"The recently proposed Forgetting Transformer (FoX) incorporates a forget gate\ninto softmax attention and has shown consistently better or on-par performance\ncompared to the standard RoPE-based Transformer. Notably, many attention heads\nin FoX tend to forget quickly, causing their output at each timestep to rely\nprimarily on the local context. Based on this observation, we propose Adaptive\nComputation Pruning (ACP) for FoX, a method that dynamically prunes\ncomputations involving input-output dependencies that are strongly decayed by\nthe forget gate. This is achieved using a dynamically set pruning threshold\nthat ensures that the pruned attention weights remain negligible. We apply ACP\nto language model pretraining with FoX and show it consistently reduces the\nnumber of FLOPs in softmax attention by around 70% across different model sizes\nand context lengths, resulting in a roughly 10% to 35% improvement in training\nthroughput. Furthermore, longer context lengths yield greater computational\nsavings. All these speed improvements are achieved without any performance\ndegradation. We also perform several analyses to provide deeper insights into\nour method, such as examining the pruning patterns and analyzing the\ndistribution of FLOP savings across different attention heads. Our code is\navailable at https://github.com/zhixuan-lin/arctic-fox.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T14:57:55Z"}
{"aid":"http://arxiv.org/abs/2504.06960v1","title":"Higher-Order Color Voronoi Diagrams and the Colorful Clarkson-Shor\n  Framework","summary":"Given a set $S$ of $n$ colored sites, each $s\\in S$ associated with a\ndistance-to-site function $\\delta_s \\colon \\mathbb{R}^2 \\to \\mathbb{R}$, we\nconsider two distance-to-color functions for each color: one takes the minimum\nof $\\delta_s$ for sites $s\\in S$ in that color and the other takes the maximum.\nThese two sets of distance functions induce two families of higher-order\nVoronoi diagrams for colors in the plane, namely, the minimal and maximal\norder-$k$ color Voronoi diagrams, which include various well-studied Voronoi\ndiagrams as special cases. In this paper, we derive an exact upper bound\n$4k(n-k)-2n$ on the total number of vertices in both the minimal and maximal\norder-$k$ color diagrams for a wide class of distance functions $\\delta_s$ that\nsatisfy certain conditions, including the case of point sites $S$ under convex\ndistance functions and the $L_p$ metric for any $1\\leq p \\leq\\infty$. For the\n$L_1$ (or, $L_\\infty$) metric, and other convex polygonal metrics, we show that\nthe order-$k$ minimal diagram of point sites has $O(\\min\\{k(n-k), (n-k)^2\\})$\ncomplexity, while its maximal counterpart has $O(\\min\\{k(n-k), k^2\\})$\ncomplexity. To obtain these combinatorial results, we extend the Clarkson--Shor\nframework to colored objects, and demonstrate its application to several\nfundamental geometric structures, including higher-order color Voronoi\ndiagrams, colored $j$-facets, and levels in the arrangements of piecewise\nlinear/algebraic curves/surfaces. We also present an iterative approach to\ncompute higher-order color Voronoi diagrams.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-09T15:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06972v1","title":"Signatures of unconventional superconductivity near reentrant and\n  fractional quantum anomalous Hall insulators","summary":"Two-dimensional moir\\'e Chern bands provide an exceptional platform for\nexploring a variety of many-body electronic liquid and solid phases at zero\nmagnetic field within a lattice system. One particular intriguing possibility\nis that flat Chern bands can, in principle, support exotic superconducting\nphases together with fractional topological phases. Here, we report the\nobservation of integer and fractional quantum anomalous Hall effects, the\nreentrant quantum anomalous Hall effect, and superconductivity within the first\nmoir\\'e Chern band of twisted bilayer MoTe2. The superconducting phase emerges\nfrom a normal state exhibiting anomalous Hall effects and sustains an large\nperpendicular critical magnetic field. Our results present the first example of\nsuperconductivity emerging within a flat Chern band that simultaneously hosts\nfractional quantum anomalous effects, a phenomenon never observed in any other\nsystems. Our work expands the understanding of emergent quantum phenomena in\nmoir\\'e Chern bands, and offers a nearly ideal platform for engineering\nMajorana and parafermion zero modes in gate-controlled hybrid devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-09T15:27:56Z"}
{"aid":"http://arxiv.org/abs/2504.06977v1","title":"Probing dipolar interactions between Rydberg atoms and ultracold polar\n  molecules","summary":"We probe resonant dipolar interactions between ultracold $^{40}$K$^{87}$Rb\nmolecules and Rydberg $^{87}$Rb atoms in an optically trapped ensemble. Through\nstate-selective ionization detection of the KRb molecules, we observe resonant\nenergy transfer at 2.227 GHz from Rydberg atoms to molecules under a tunable\nexternal electric field. We measure a broadening up to 3.5 MHz, for the Rb\nRydberg excitation spectrum, which matches a Monte Carlo simulation that\ndescribes a Rydberg atom and neighboring molecules evolving under a\ndipole-dipole interacting Hamiltonian. The demonstrated interspecies dipolar\ninteraction is a key ingredient for hybrid Rydberg-polar molecule systems,\nwhere the advantages of each system can be leveraged and combined.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-09T15:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.06985v1","title":"M-theory boundaries beyond supersymmetry","summary":"The chiral worldvolume theory of an M-theory boundary (the so-called M9\nbrane) is uniquely determined by supersymmetry and anomaly inflow. In this\nbrief note we investigate whether alternative chiral boundary field contents\nmay be allowed by anomaly cancellation once supersymmetry is dropped. Even\nthen, anomaly inflow places stringent constraints on the gauge group $G$ and\nmatter content of the boundary worldvolume theory, which we determine\nexplicitly. We find the most general solution to these constraints in the case\nwhere all matter fields are of the same chirality, for all simple Lie algebras\nexcept $\\mathfrak{sp}_2$, $\\mathfrak{su}_{n\\leq5}$, and $\\mathfrak{so}_{n}$\nwith $7\\leq n\\leq 12$, and find no solutions other than the supersymmetric\n$E_8$ boundary of Ho\\v{r}ava and Witten. However, when we extend our search to\nallow for any chirality in the matter fields, we find one minimal solution with\ngauge group $G_2$, charged matter in the $\\mathsf{14}$, $\\mathsf{27}$ and\n$\\mathsf{77}$ representations, which satisfies all constraints in a non-trivial\nway. Therefore, it could in principle describe the low-energy theory of a novel\nnonsupersymmetric M-theory boundary condition, different from the\nHo\\v{r}ava-Witten proposal. We briefly discuss some consequences if this was\nindeed the case, such as the existence of a non-supersymmetric, exotic\n\"$G_2$-string\" CFT in 6d, and a novel, non-perturbative, heterotic-like 10d\nstring with gauge group $G_2\\times G_2$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-09T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06987v1","title":"Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and\n  Counterfactuals","summary":"Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T15:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.06992v1","title":"Constraining the $z \\sim 1$ IMF with {\\it HST} and {\\it JWST} lensed\n  stars in MACS J0416.1-2403","summary":"The understanding of galaxy properties and evolution is contingent on knowing\nthe initial mass function (IMF), and yet to date, the IMF is constrained only\nto local galaxies. Individual stars are now becoming routinely detected at\ncosmological distances, where luminous stars such as supergiants in background\ngalaxies critically lensed by galaxy clusters are temporarily further magnified\nby huge factors up to $10^{4}$ by intra-cluster stars, thus being detected as\ntransients. The detection rate of these events depends on the abundance of\nluminous stars in the background galaxy and is thus sensitive to the IMF and\nthe star formation history (SFH), especially for the blue supergiants detected\nas transients in the rest-frame UV/optical filters. As a proof of concept, we\nuse simple SFH and IMF models constrained by spectral energy distribution (SED)\nto see how well we can predict the {\\it HST} and {\\it JWST} transient detection\nrate in a lensed arc dubbed ``Spock'' ($z = 1.0054$). We find that demanding a\nsimultaneously fit of SED and rest-frame UV/optical transient detection rate\nplaces constraints on the IMF, independent of the assumed simple SFH model. We\nconclude our Bayesian likelihood analysis indicates that the data definitively\nprefer the ``Spock'' galaxy to have a Salpeter IMF ($\\alpha = 2.35$) rather\nthan a Top-heavy IMF ($\\alpha = 1$) -- what is thought to be the case in the\nearly universe -- given our methodology and assumptions with no clear excess of\nsupergiants above the standard IMF.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T15:58:36Z"}
{"aid":"http://arxiv.org/abs/2504.06997v1","title":"Cerebral blood flow monitoring using a deep learning implementation of\n  the two-layer DCS analytical model with a 512 512 SPAD array","summary":"Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function\nof photons scattered by red blood cells, enabling non-invasive, continuous\nmeasurement of deep tissue blood flow at the bedside. Multi-layer DCS models\n(two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and\nmitigate interference from extracerebral tissues. However, these models require\nmultiple predefined parameters and are computationally intensive, making them\nimpractical for real-time bedside monitoring. To address this challenge, we\nintegrate a single-photon avalanche diode (SPAD) array with a deep learning\n(DL)-based approach trained on data generated by the two-layer analytical\nmodel. This method bypasses traditional model fitting, enabling real-time CBFi\nmonitoring while minimizing superficial tissue contamination. We first validate\nour approach using Monte Carlo-simulated test datasets, demonstrating superior\naccuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional\nfitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our\nmethod effectively isolates shallow blood flow changes and 750-fold faster than\nsingle-exponential fitting in a realistic scenario. We further evaluate the\nsystem in a healthy adult, achieving real-time CBFi monitoring and pulsatile\nwaveform recovery during a brain activity test using a 512 512 SPAD array\nsensor. These results highlight the potential of our approach for real-time\nbrain activity monitoring.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07019v1","title":"Non-Hermitian Numerical Renormalization Group: Solution of the\n  non-Hermitian Kondo model","summary":"Non-Hermitian (NH) Hamiltonians describe open quantum systems, nonequilibrium\ndynamics, and dissipative processes. Although a rich range of single-particle\nNH physics has been uncovered, many-body phenomena in strongly correlated NH\nsystems have been far less well studied. The Kondo effect, an important\nparadigm for strong correlation physics, has recently been considered in the NH\nsetting. Here we develop a NH generalization of the numerical renormalization\ngroup (NRG) and use it to solve the NH Kondo model. Our non-perturbative\nsolution applies beyond weak coupling, and we uncover a nontrivial phase\ndiagram. The method is showcased by application to the NH pseudogap Kondo\nmodel, which we show supports a completely novel phase with a genuine NH stable\nfixed point and complex eigenspectrum. Our NH-NRG code, which can be used in\nregimes and for models inaccessible to, e.g., perturbative scaling and Bethe\nansatz, is provided open source.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-09T16:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.07030v1","title":"Decoherence effects in entangled fermion pairs at colliders","summary":"Recent measurements at the Large Hadron Collider have observed entanglement\nin the spins of $t\\bar t$ pairs. The effects of radiation, which are expected\nto lead to quantum decoherence and a reduction of entanglement, are generally\nneglected in such measurements. In this letter we calculate the effects of\ndecoherence from various different types of radiation for a maximally entangled\npair of fermions -- a bipartite system of qubits in a Bell state. We identify\nthe Kraus operators describing the evolution of the open quantum system with\nthe integrated Altarelli-Parisi splitting functions.","main_category":"quant-ph","categories":"quant-ph,hep-ex,hep-ph","published":"2025-04-09T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07047v1","title":"Hydrogen-Mediated Control of Phase Formation and Microstructure\n  Evolution","summary":"Hydrogen is key in reducing greenhouse gas emissions in materials production.\nAt the same time, it significantly affects mechanical properties, often causing\nunwanted embrittlement. However, rather than solely addressing these\ndisadvantages, hydrogens inevitable role in sustainable metallurgy should be\nleveraged to create new and potentially superior materials. Here, we show that\nusing hydrogen in the form of metal hydrides introduces a barrier to mechanical\nalloying, stabilizing otherwise unattainable microstructures. Severe plastic\ndeformation of a composite of the high entropy alloy (HEA) TiVZrNbHf and Cu\nleads to amorphization while substituting the HEA by its hydride preserves the\ntwo-phase structure. Monte Carlo simulations confirm that the significantly\ndifferent hydrogen affinities, together with the restricted dislocation motion\nin the hydride, create a barrier to mechanical alloying. This hydride route\nenables new microstructural states, even in well-studied material systems. It\nopens an additional dimension in designing materials with diverging hydrogen\naffinities, offering tighter control over mechanical alloying.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2504.07071v1","title":"ASASSN-14dx: A cataclysmic variable harbouring a massive pulsating white\n  dwarf","summary":"We present the results of our study of ASASSN-14dx, a previously known but\npoorly characterised cataclysmic variable (CV). The source was observed as part\nof an ongoing high-time-resolution photometric survey of CVs, which revealed\nthat, in addition to the known 82.8min orbital period, it also exhibits other\ntransient periods, the strongest of which around 4 and 14 min. Here, we report\nour findings resulting from a multifaceted follow-up programme consisting of\noptical spectroscopy, spectropolarimetry, imaging polarimetry, and multicolour\nfast photometry. We find that the source displays complex optical variability,\nwhich is best explained by the presence of a massive white dwarf exhibiting\nnon-radial pulsations. An intermediate polar-like scenario involving a spinning\nmagnetic white dwarf can be ruled out based on the detected changes in the\nobserved periods. Based on our optical spectroscopy, we can constrain the mass\nand effective temperature of the white dwarf to be ~1.1 Msol and 16 100 K,\nrespectively. The overall intrinsic flux level of the source is unusually high,\nsuggesting that there remains significant residual emission from the accretion\ndisc and/or the white dwarf even ten years after the 2014 outburst. Finally, we\ncannot detect any spectroscopic signatures from the donor star, making\nASASSN-14dx a possible period bouncer system evolving towards a longer orbital\nperiod.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T17:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.07073v1","title":"New empirical mass-loss recipe for UV radiation line-driven winds of hot\n  stars across various metallicities","summary":"The winds of massive stars remove a significant fraction of their mass,\nstrongly impacting their evolution. As a star evolves, the rate at which it\nloses mass changes. In stellar evolution codes, different mass-loss recipes are\nemployed for different evolutionary stages. The choice of the recipes is\nuser-dependent and the conditions for switching between them are poorly\ndefined. Focusing on hot stars, we aim to produce a physically motivated,\nempirically calibrated mass-loss recipe suitable for a wide range of\nmetallicities. We want to provide a ready-to-use universal recipe that\neliminates the need for switching between recipes for hot stars during stellar\nevolution calculations. We compile a sample of hot stars with reliable stellar\nand wind parameters in the Galaxy and the Magellanic Clouds. The sample is used\nto determine the dependence of the mass-loss rate on the basic stellar\nparameters. We find that independent of evolutionary stage and temperature, the\nwind mass-loss rate is a function of the electron-scattering Eddington\nparameter ($\\Gamma_e$) and metallicity (Z), being in line with expectations of\nradiation-driven wind theory. Our derived scaling relation provides an adequate\n($\\Delta$log($\\dot{M}$/(M$_\\odot$/yr)) = 0.43) and broadly applicable mass-loss\nrecipe for hot stars. The newly derived mass-loss recipe covers nearly the\nentire parameter space of hot stars with UV radiation-driven winds and\neliminates the need for interpolation between mass-loss formulae at different\nevolutionary stages when applied in stellar evolution models. Examples of\nstellar evolution calculations using our new recipe reveal that the predictions\non the ionizing fluxes and final fates of massive stars, especially at low\nmetallicity, differ significantly from models that use the standard mass-loss\nrates, impacting our understanding of stellar populations at low metallicity\nand in the young Universe.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.07415v1","title":"Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report\n  Generation via Key Phrase Extraction","summary":"Automated radiology report generation (RRG) holds potential to reduce\nradiologists' workload, especially as recent advancements in large language\nmodels (LLMs) enable the development of multimodal models for chest X-ray (CXR)\nreport generation. However, multimodal LLMs (MLLMs) are resource-intensive,\nrequiring vast datasets and substantial computational cost for training. To\naddress these challenges, we propose a retrieval-augmented generation approach\nthat leverages multimodal retrieval and LLMs to generate radiology reports\nwhile mitigating hallucinations and reducing computational demands. Our method\nuses LLMs to extract key phrases from radiology reports, effectively focusing\non essential diagnostic information. Through exploring effective training\nstrategies, including image encoder structure search, adding noise to text\nembeddings, and additional training objectives, we combine complementary\npre-trained image encoders and adopt contrastive learning between text and\nsemantic image embeddings. We evaluate our approach on MIMIC-CXR dataset,\nachieving state-of-the-art results on CheXbert metrics and competitive RadGraph\nF1 metric alongside MLLMs, without requiring LLM fine-tuning. Our method\ndemonstrates robust generalization for multi-view RRG, making it suitable for\ncomprehensive clinical applications.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.07419v1","title":"Exploring Vulnerabilities and Concerns in Solana Smart Contracts","summary":"The Solana blockchain was created by Anatoly Yakovenko of Solana Labs and was\nintroduced in 2017, employing a novel transaction verification method. However,\nat the same time, the innovation process introduced some new security issues.\nThe frequent security incidents in smart contracts have not only caused\nenormous economic losses, but also undermined the credit system based on the\nblockchain. The security and reliability of smart contracts have become a new\nfocus of research both domestically and abroad. This paper studies the current\nstatus of security analysis of Solana by researching Solana smart contract\nsecurity analysis tools. This paper systematically sorts out the\nvulnerabilities existing in Solana smart contracts and gives examples of some\nvulnerabilities, summarizes the principles of security analysis tools, and\ncomprehensively summarizes and details the security analysis tools in Solana\nsmart contracts. The data of Solana smart contract security analysis tools are\ncollected and compared with Ethereum, and the differences are analyzed and some\ntools are selected for practical testing.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.07420v1","title":"Emergency Communication: OTFS-Based Semantic Transmission with Diffusion\n  Noise Suppression","summary":"Due to their flexibility and dynamic coverage capabilities, Unmanned Aerial\nVehicles (UAVs) have emerged as vital platforms for emergency communication in\ndisaster-stricken areas. However, the complex channel conditions in high-speed\nmobile scenarios significantly impact the reliability and efficiency of\ntraditional communication systems. This paper presents an intelligent emergency\ncommunication framework that integrates Orthogonal Time Frequency Space (OTFS)\nmodulation, semantic communication, and a diffusion-based denoising module to\naddress these challenges. OTFS ensures robust communication under dynamic\nchannel conditions due to its superior anti-fading characteristics and\nadaptability to rapidly changing environments. Semantic communication further\nenhances transmission efficiency by focusing on key information extraction and\nreducing data redundancy. Moreover, a diffusion-based channel denoising module\nis proposed to leverage the gradual noise reduction process and statistical\nnoise modeling, optimizing the accuracy of semantic information recovery.\nExperimental results demonstrate that the proposed solution significantly\nimproves link stability and transmission performance in high-mobility UAV\nscenarios, achieving at least a 3dB SNR gain over existing methods.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T03:25:56Z"}
{"aid":"http://arxiv.org/abs/2504.07428v1","title":"Task-oriented Age of Information for Remote Inference with Hybrid\n  Language Models","summary":"Large Language Models (LLMs) have revolutionized the field of artificial\nintelligence (AI) through their advanced reasoning capabilities, but their\nextensive parameter sets introduce significant inference latency, posing a\nchallenge to ensure the timeliness of inference results. While Small Language\nModels (SLMs) offer faster inference speeds with fewer parameters, they often\ncompromise accuracy on complex tasks. This study proposes a novel remote\ninference system comprising a user, a sensor, and an edge server that\nintegrates both model types alongside a decision maker. The system dynamically\ndetermines the resolution of images transmitted by the sensor and routes\ninference tasks to either an SLM or LLM to optimize performance. The key\nobjective is to minimize the Task-oriented Age of Information (TAoI) by jointly\nconsidering the accuracy and timeliness of the inference task. Due to the\nnon-uniform transmission time and inference time, we formulate this problem as\na Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent\nMarkov decision process, we prove that the optimal control policy follows a\nthreshold-based structure. We further develop a relative policy iteration\nalgorithm leveraging this threshold property. Simulation results demonstrate\nthat our proposed optimal policy significantly outperforms baseline approaches\nin managing the accuracy-timeliness trade-off.","main_category":"cs.IT","categories":"cs.IT,cs.NI,math.IT","published":"2025-04-10T03:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.07444v1","title":"Lorentz-Drude dipoles in the radiative limit and their modeling in\n  finite-difference time-domain methods","summary":"The Lorentz-Drude model for electric dipoles is a classical framework widely\nused in the study of dipole dynamics and light-matter interactions. Here we\nfocus on the behaviors of Lorentz-Drude dipoles when their radiative rate\ndominates their energy loss. We show that dipole radiation losses do not count\ntoward phenomenological dipole losses if the driving field is interpreted as\nthe total field at the dipole. In particular, if the dipole does not contain\nnon-radiative losses, then the Lorentz-Drude damping term should be removed.\nThis is verified by self-consistent implementations of point dipoles in\nfinite-difference time-domain simulations, which also provide a method to\ndirectly compute the transport properties of light when dipoles are present.","main_category":"physics.optics","categories":"physics.optics,physics.class-ph","published":"2025-04-10T04:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07445v1","title":"$L^p$ estimates for joint quasimodes of two pseudodifferential operators\n  whose characteristic sets have $k$-th order contact","summary":"On a smooth, compact, $n$-dimensional Riemannian manifold, we consider\nfunctions $u_h$ that are joint quasimodes of two semiclassical\npseudodifferential operators $p_1(x,hD)$ and $p_2(x,hD)$. We develop $L^p$\nestimates for $u_h$ when the characteristic sets of $p_1$ and $p_2$ meet with\n$k$-th order contact. This paper is the natural extension of the\ntwo-dimensional results from arXiv:1909.12559 to $n$ dimensions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T04:30:45Z"}
{"aid":"http://arxiv.org/abs/2504.07450v1","title":"Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected\n  PET for Whole-Body PET Attenuation Correction","summary":"Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-10T04:49:41Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07482v1","title":"Tame categorical local Langlands correspondence","summary":"In one of our previous articles, we outlined the formulation of a version of\nthe categorical arithmetic local Langlands conjecture. The aims of this article\nare threefold. First, we provide a detailed account of one component of this\nconjecture: the local Langlands category. Second, we aim to prove this\nconjecture in the tame case for quasi-split unramified reductive groups.\nFinally, we will explore the first applications of such categorical\nequivalence.","main_category":"math.RT","categories":"math.RT,math.AG","published":"2025-04-10T06:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07509v1","title":"Coexistence of topologically trivial and non-trivial Yu-Shiba-Rusinov\n  bands in magnetic atomic chains on a superconductor","summary":"Majorana zero modes (MZMs) have been proposed as a promising basis for\nMajorana qubits offering great potential for topological quantum computation.\nSuch modes may form at the ends of a magnetic atomic chain on a superconductor.\nTypically only a single MZM may be present at one end of the chain, but\nsymmetry may protect multiple MZMs at the same end. Here, we study the\ntopological properties of Yu-Shiba-Rusinov (YSR) bands of excitations in Mn\nchains constructed on a Nb(110) and on a Ta(110) substrate using\nfirst-principles calculations and scanning tunneling microscopy and\nspectroscopy experiments. We demonstrate that even and odd YSR states with\nrespect to mirroring on the symmetry plane containing the chain have different\ndispersions, and both of them may give rise to MZMs separately. Although the\nspin-orbit coupling leads to a hybridization between the bands, multiple MZMs\nmay still exist due to the mirror symmetry. These findings highlight the\ninfluence of symmetries on interpreting the spectroscopic signatures of\ncandidates for MZMs.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-10T07:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07523v1","title":"Lifetime-limited Gigahertz-frequency Mechanical Oscillators with\n  Millisecond Coherence Times","summary":"High-frequency mechanical oscillators with long coherence times are essential\nto realizing a variety of high-fidelity quantum sensors, transducers, and\nmemories. However, the unprecedented coherence times needed for quantum\napplications require exquisitely sensitive new techniques to probe the material\norigins of phonon decoherence and new strategies to mitigate decoherence in\nmechanical oscillators. Here, we combine non-invasive laser spectroscopy\ntechniques with materials analysis to identify key sources of phonon\ndecoherence in crystalline media. Using micro-fabricated high-overtone bulk\nacoustic-wave resonators ($\\mu$HBARs) as an experimental testbed, we identify\nphonon-surface interactions as the dominant source of phonon decoherence in\ncrystalline quartz; lattice distortion, subsurface damage, and high\nconcentration of elemental impurities near the crystal surface are identified\nas the likely causes. Removal of this compromised surface layer using an\noptimized polishing process is seen to greatly enhance coherence times,\nenabling $\\mu$HBARs with Q-factors of > 240 million at 12 GHz frequencies,\ncorresponding to > 6 ms phonon coherence times and record-level f-Q products.\nComplementary phonon linewidth and time-domain ringdown measurements, performed\nusing a new Brillouin-based pump-probe spectroscopy technique, reveal\nnegligible dephasing within these oscillators. Building on these results, we\nidentify a path to > 100 ms coherence times as the basis for high-frequency\nquantum memories. These findings clearly demonstrate that, with enhanced\ncontrol over surfaces, dissipation and noise can be significantly reduced in a\nwide range of quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-10T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.07538v1","title":"A 950 MHz SIMT Soft Processor","summary":"Although modern FPGAs have a performance potential of a 1 GHz clock frequency\n- with both clock networks and embedded blocks such as memories and DSP Blocks\ncapable of these clock rates - user implementations approaching this speed are\nrarely realized in practice. This is especially true of complex designs such as\nsoft processors.\n  In this work we implement a soft GPGPU which exceeds 950 MHz in an Altera\nAgilex-7 FPGA. The architecture is a 32-bit fixed point Single Instruction,\nMultiple Thread (SIMT) design, with parameterized thread and register spaces.\nUp to 4096 threads and 64K registers can be specified by the user. In one\nexample, a processor with 16K registers and a 16KB shared memory required\napproximately 7K ALMs, 99 M20K memories, and 32 DSP Blocks.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.07540v1","title":"PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and\n  Merkle Proofs","summary":"We present a design called \\emph{Proof of Gradient Optimization} (PoGO) for\nblockchain consensus, where miners produce verifiable evidence of training\nlarge-scale machine-learning models. Building on previous work, we incorporate\n\\emph{quantized gradients} (4-bit precision) to reduce storage and computation\nrequirements, while still preserving the ability of verifiers to check that\nreal progress has been made on lowering the model's loss. Additionally, we\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\nand to enable random leaf checks with minimal on-chain data. We illustrate\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\nto smaller but high-performance models (e.g., \\emph{Gemma~3} with 27B\nparameters). We provide an empirical cost analysis showing that verification is\nsignificantly cheaper than training, thanks in part to quantization and\nsampling. We also discuss the necessity of longer block times (potentially\nhours) when incorporating meaningful training steps, the trade-offs when using\nspecialized GPU hardware, and how binary diffs may incrementally optimize\nupdates. Finally, we note that fine-tuning can be handled in a similar manner,\nmerely changing the dataset and the manner of sampling but preserving the\noverall verification flow. Our protocol allows verifiers to issue either\n\\emph{positive} or \\emph{negative} attestations; these are aggregated at\nfinalization to either confirm the update or slash the miner.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T08:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07541v1","title":"On the initial ideal of a generic artinian Gorenstein algebra","summary":"In this note we show that the initial ideal of the annihilator ideal of a\ngeneric form is generated by the largest possible monomials in each degree. We\nalso show that the initial ideal with respect to the degree reverse\nlexicographical ordering of the annihilator ideal of the complete symmetric\nform has this property, by determining a minimal Gr\\\"obner basis of it.\nMoreover, we determine the total Betti numbers for a class of strongly stable\nmonomial ideals and show that these numbers agree with those for the degree\nreverse lexicographical initial ideals of the ideal generated by a sufficiently\nlarge number of generic forms, and of the annihilator ideal of a generic form.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.07551v1","title":"Topology optimization of decoupling feeding networks for antenna arrays","summary":"Near-field and radiation coupling between nearby radiating elements is\nunavoidable, and it is considered a limiting factor for applications in\nwireless communications and active sensing. This article proposes a\ndensity-based topology optimization approach to design decoupling networks for\nsuch systems. The decoupling networks are designed based on a multi-objective\noptimization problem with the radiating elements replaced by their time-domain\nimpulse response for efficient computations and to enable the solution of the\ndesign problem using gradient-based optimization methods. We use the\nadjoint-field method to compute the gradients of the optimization objectives.\nAdditionally, nonlinear filters are applied during the optimization procedure\nto impose minimum-size control on the optimized designs. We demonstrate the\nconcept by designing the decoupling network for a two-element planar antenna\narray; the antenna is designed in a separate optimization problem. The\noptimized decoupling networks provide a signal path that destructively\ninterferes with the coupling between the radiating elements while preserving\ntheir individual matching to the feeding ports. Compact decoupling networks\ncapable of suppressing the mutual coupling by more than 10 dB between two\nclosely separated planar antennas operating around 2.45 GHz are presented and\nvalidated experimentally.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:27:04Z"}
{"aid":"http://arxiv.org/abs/2504.07552v1","title":"Uniqueness of supercritical Gaussian multiplicative chaos","summary":"We show that, for general convolution approximations to a large class of\nlog-correlated Gaussian fields, the properly normalised supercritical Gaussian\nmultiplicative chaos measures converge stably to a nontrivial limit. This limit\ndepends on the choice of regularisation only through a multiplicative constant\nand can be characterised as an integrated atomic measure with a random\nintensity expressed in terms of the critical Gaussian multiplicative chaos.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-10T08:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.07570v1","title":"Exploring Human-Like Thinking in Search Simulations with Large Language\n  Models","summary":"Simulating user search behavior is a critical task in information retrieval,\nwhich can be employed for user behavior modeling, data augmentation, and system\nevaluation. Recent advancements in large language models (LLMs) have opened up\nnew possibilities for generating human-like actions including querying,\nbrowsing, and clicking. In this work, we explore the integration of human-like\nthinking into search simulations by leveraging LLMs to simulate users' hidden\ncognitive processes. Specifically, given a search task and context, we prompt\nLLMs to first think like a human before executing the corresponding action. As\nexisting search datasets do not include users' thought processes, we conducted\na user study to collect a new dataset enriched with users' explicit thinking.\nWe investigate the impact of incorporating such human-like thinking on\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\nemulate both human thinking and actions. Our experiments span two dimensions in\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\ndemonstrate the feasibility and potential of incorporating human-like thinking\nin user simulations, though performance improvements on some metrics remain\nmodest. We believe this exploration provides new avenues and inspirations for\nadvancing user behavior modeling in search simulations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07575v1","title":"Explicit Uncertainty Modeling for Video Watch Time Prediction","summary":"In video recommendation, a critical component that determines the system's\nrecommendation accuracy is the watch-time prediction module, since how long a\nuser watches a video directly reflects personalized preferences. One of the key\nchallenges of this problem is the user's stochastic watch-time behavior. To\nimprove the prediction accuracy for such an uncertain behavior, existing\napproaches show that one can either reduce the noise through duration bias\nmodeling or formulate a distribution modeling task to capture the uncertainty.\nHowever, the uncontrolled uncertainty is not always equally distributed across\nusers and videos, inducing a balancing paradox between the model accuracy and\nthe ability to capture out-of-distribution samples. In practice, we find that\nthe uncertainty of the watch-time prediction model also provides key\ninformation about user behavior, which, in turn, could benefit the prediction\ntask itself. Following this notion, we derive an explicit uncertainty modeling\nstrategy for the prediction model and propose an adversarial optimization\nframework that can better exploit the user watch-time behavior. This framework\nhas been deployed online on an industrial video sharing platform that serves\nhundreds of millions of daily active users, which obtains a significant\nincrease in users' video watch time by 0.31% through the online A/B test.\nFurthermore, extended offline experiments on two public datasets verify the\neffectiveness of the proposed framework across various watch-time prediction\nbackbones.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.07579v1","title":"Controlling Complex Systems","summary":"This chapter provides a comprehensive overview of controlling collective\nbehavior in complex systems comprising large ensembles of interacting dynamical\nagents. Building upon traditional control theory's foundation in individual\nsystems, we introduce tools designed to address the unique challenges of\ncoordinating networks that exhibit emergent phenomena, including consensus,\nsynchronization, and pattern formation. We analyze how local agent interactions\ngenerate macroscopic behaviors and investigate the fundamental role of network\ntopology in determining system dynamics. Inspired by natural systems, we\nemphasize control strategies that achieve global coordination through localized\ninterventions while considering practical implementation challenges. The\nchapter concludes by presenting novel frameworks for managing very large agent\nensembles and leveraging interacting networks for control purposes.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-10T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.07587v1","title":"Renormalization group-like flows in randomly connected tensor networks","summary":"Randomly connected tensor networks (RCTN) are the dynamical systems defined\nby summing over all the possible networks of tensors. Because of the absence of\nfixed lattice structure, RCTN is not expected to have renormalization\nprocedures. In this paper, however, we consider RCTN with a real tensor, and it\nis proven that a Hamiltonian vector flow of a tensor model in the canonical\nformalism with a positive cosmological constant has the properties which a\nrenormalization group (RG) flow of RCTN would have: The flow has fixed points\non phase transition surfaces; every flow line is asymptotically terminated by\nfixed points at both ends, where an upstream fixed point has higher criticality\nthan a downstream one; the flow goes along phase transition surfaces; there\nexists a function which monotonically decreases along the flow, analogously to\nthe $a$- and $c$-functions of RG. A complete classification of fixed points is\ngiven. Although there are no cyclic flows in the strict sense, these exist, if\ninfinitesimal jumps are allowed near fixed points.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T09:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.07588v1","title":"Jordan Decomposition for WBV-functions in Ordered Normed Spaces","summary":"In this paper, we define two relations one by orthogonality in vector\nlattices named as strong relation and the other by bounded linear functionals\nin normed spaces named as weak relation. It turns out that strong relation is\nan equivalence relation. We study some of the characterizations of these\nrelations. Given a non-zero element in a normed space, we construct an\nextensible cone which makes that normed space, an ordered normed space. This\nextensible cone induces the weak relation in the normed space. Later, we prove\na Jordan Decomposition Theorem in a normed space by the weak relation induced\nby the extensible cone.","main_category":"math.FA","categories":"math.FA","published":"2025-04-10T09:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.07607v1","title":"Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization\n  with Linear Inequality Constraints","summary":"We propose smoothed primal-dual algorithms for solving stochastic and smooth\nnonconvex optimization problems with linear inequality constraints. Our\nalgorithms are single-loop and only require a single stochastic gradient based\non one sample at each iteration. A distinguishing feature of our algorithm is\nthat it is based on an inexact gradient descent framework for the Moreau\nenvelope, where the gradient of the Moreau envelope is estimated using one step\nof a stochastic primal-dual augmented Lagrangian method. To handle inequality\nconstraints and stochasticity, we combine the recently established global error\nbounds in constrained optimization with a Moreau envelope-based analysis of\nstochastic proximal algorithms. For obtaining $\\varepsilon$-stationary points,\nwe establish the optimal $O(\\varepsilon^{-4})$ sample complexity guarantee for\nour algorithms and provide extensions to stochastic linear constraints. We also\nshow how to improve this complexity to $O(\\varepsilon^{-3})$ by using variance\nreduction and the expected smoothness assumption. Unlike existing methods, the\niterations of our algorithms are free of subproblems, large batch sizes or\nincreasing penalty parameters and use dual variable updates to ensure\nfeasibility.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-10T09:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07618v1","title":"CTSR: Cartesian tensor-based sparse regression for data-driven discovery\n  of high-dimensional invariant governing equations","summary":"Accurate and concise governing equations are crucial for understanding system\ndynamics. Recently, data-driven methods such as sparse regression have been\nemployed to automatically uncover governing equations from data, representing a\nsignificant shift from traditional first-principles modeling. However, most\nexisting methods focus on scalar equations, limiting their applicability to\nsimple, low-dimensional scenarios, and failing to ensure rotation and\nreflection invariance without incurring significant computational cost or\nrequiring additional prior knowledge. This paper proposes a Cartesian\ntensor-based sparse regression (CTSR) technique to accurately and efficiently\nuncover complex, high-dimensional governing equations while ensuring\ninvariance. Evaluations on two two-dimensional (2D) and two three-dimensional\n(3D) test cases demonstrate that the proposed method achieves superior accuracy\nand efficiency compared to the conventional technique.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:06:29Z"}
{"aid":"http://arxiv.org/abs/2504.07632v1","title":"A Stochastic Ekman-Stokes Model for Coupled Ocean-Atmosphere-Wave\n  Dynamics","summary":"Accurate representation of atmosphere-ocean boundary layers, including the\ninterplay of turbulence, surface waves, and air-sea fluxes, remains a challenge\nin geophysical fluid dynamics, particularly for climate simulations. This study\nintroduces a stochastic coupled Ekman-Stokes model (SCESM) developed within the\nphysically consistent Location Uncertainty framework, explicitly incorporating\nrandom turbulent fluctuations and surface wave effects. The SCESM integrates\nestablished parameterizations for air-sea fluxes, turbulent viscosity, and\nStokes drift, and its performance is rigorously assessed through ensemble\nsimulations against LOTUS observational data. A performance ranking analysis\nquantifies the impact of different model components, highlighting the critical\nrole of explicit uncertainty representation in both oceanic and atmospheric\ndynamics for accurately capturing system variability. Wave-induced mixing terms\nimprove model performance, while wave-dependent surface roughness enhances\nair-sea fluxes but reduces the relative influence of wave-driven mixing. This\nfully coupled stochastic framework provides a foundation for advancing boundary\nlayer parameterizations in large-scale climate models.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T10:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.07634v1","title":"Agent That Debugs: Dynamic State-Guided Vulnerability Repair","summary":"In recent years, more vulnerabilities have been discovered every day, while\nmanual vulnerability repair requires specialized knowledge and is\ntime-consuming. As a result, many detected or even published vulnerabilities\nremain unpatched, thereby increasing the exposure of software systems to\nattacks. Recent advancements in agents based on Large Language Models have\ndemonstrated their increasing capabilities in code understanding and\ngeneration, which can be promising to achieve automated vulnerability repair.\nHowever, the effectiveness of agents based on static information retrieval is\nstill not sufficient for patch generation. To address the challenge, we propose\na program repair agent called VulDebugger that fully utilizes both static and\ndynamic context, and it debugs programs in a manner akin to humans. The agent\ninspects the actual state of the program via the debugger and infers expected\nstates via constraints that need to be satisfied. By continuously comparing the\nactual state with the expected state, it deeply understands the root causes of\nthe vulnerabilities and ultimately accomplishes repairs. We experimentally\nevaluated VulDebugger on 50 real-life projects. With 60.00% successfully fixed,\nVulDebugger significantly outperforms state-of-the-art approaches for\nvulnerability repair.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.07639v1","title":"IntÃ©grale orbitale pondÃ©rÃ©e via l'induite de Lusztig-Spaltenstein\n  gÃ©nÃ©ralisÃ©e","summary":"In this article, we present two novel approaches to constructing weighted\norbital integrals of an inner form of a general linear group. Our method\nutilizes generalized Lustig-Spaltenstein induction. Furthermore, we will prove\nthat a weighted orbital integral on the Lie algebra constitutes a tempered\ndistribution. We also demonstrate that our new definitions and Arthur's\noriginal definition are consistent.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T10:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.07643v1","title":"CollEX -- A Multimodal Agentic RAG System Enabling Interactive\n  Exploration of Scientific Collections","summary":"In this paper, we introduce CollEx, an innovative multimodal agentic\nRetrieval-Augmented Generation (RAG) system designed to enhance interactive\nexploration of extensive scientific collections. Given the overwhelming volume\nand inherent complexity of scientific collections, conventional search systems\noften lack necessary intuitiveness and interactivity, presenting substantial\nbarriers for learners, educators, and researchers. CollEx addresses these\nlimitations by employing state-of-the-art Large Vision-Language Models (LVLMs)\nas multimodal agents accessible through an intuitive chat interface. By\nabstracting complex interactions via specialized agents equipped with advanced\ntools, CollEx facilitates curiosity-driven exploration, significantly\nsimplifying access to diverse scientific collections and records therein. Our\nsystem integrates textual and visual modalities, supporting educational\nscenarios that are helpful for teachers, pupils, students, and researchers by\nfostering independent exploration as well as scientific excitement and\ncuriosity. Furthermore, CollEx serves the research community by discovering\ninterdisciplinary connections and complementing visual data. We illustrate the\neffectiveness of our system through a proof-of-concept application containing\nover 64,000 unique records across 32 collections from a local scientific\ncollection from a public university.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.CV","published":"2025-04-10T10:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07653v1","title":"Optimum design of permeable diffractive lenses based on photon sieves","summary":"Photon sieves are permeable diffractive optical elements generated by open\napertures on a substrate. These elements are well suited for the monitoring of\nrunning fluids. Our analysis considers the fabrication constrains of the photon\nsieve and translate them into values of the optical parameters of the element.\nWhen used as focusing elements, or diffractive lenses, the spatial distribution\nof apertures can be designed to maximize the intensity at the focal plane and\nthe permeability of the device. This is done by defining a weighted merit\nfunction. The computation time of this merit function is key when applying\ndifferent strategies for the design, which often require a very large number of\ncalculations of this merit function. Then, besides using a reliable propagation\nmethod, we have included an analytic solution applicable for circular\napertures. Also, a geometrical merit function is proposed to simplify and\nreduce the computation even more. The methods proposed in this contribution are\ncompared in terms of the focused irradiance and permeability parameters,\nallowing an educated choice adapted to the given case or application. In this\ncontribution we analyze several methods to generate photon sieves in an optimum\nmanner. The resulted spatial distributions resemble the classical Fresnel zone\narrangement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.07664v1","title":"Data Requirement Goal Modeling for Machine Learning Systems","summary":"Machine Learning (ML) has been integrated into various software and systems.\nTwo main components are essential for training an ML model: the training data\nand the ML algorithm. Given the critical role of data in ML system development,\nit has become increasingly important to assess the quality of data attributes\nand ensure that the data meets specific requirements before its utilization.\nThis work proposes an approach to guide non-experts in identifying data\nrequirements for ML systems using goal modeling. In this approach, we first\ndevelop the Data Requirement Goal Model (DRGM) by surveying the white\nliterature to identify and categorize the issues and challenges faced by data\nscientists and requirement engineers working on ML-related projects. An initial\nDRGM was built to accommodate common tasks that would generalize across\nprojects. Then, based on insights from both white and gray literature, a\ncustomization mechanism is built to help adjust the tasks, KPIs, and goals'\nimportance of different elements within the DRGM. The generated model can aid\nits users in evaluating different datasets using GRL evaluation strategies. We\nthen validate the approach through two illustrative examples based on\nreal-world projects. The results from the illustrative examples demonstrate\nthat the data requirements identified by the proposed approach align with the\nrequirements of real-world projects, demonstrating the practicality and\neffectiveness of the proposed framework. The proposed dataset selection\ncustomization mechanism and the proposed DRGM are helpful in guiding\nnon-experts in identifying the data requirements for machine learning systems\ntailored to a specific ML problem. This approach also aids in evaluating\ndifferent dataset alternatives to choose the optimum dataset for the problem.\nFor future work, we recommend implementing tool support to generate the DRGM\nbased on a chatbot interface.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-10T11:30:25Z"}
{"aid":"http://arxiv.org/abs/2504.07665v1","title":"Chirality-induced selectivity of angular momentum by orbital Edelstein\n  effect in carbon nanotubes","summary":"Carbon nanotubes (CNTs) are promising materials exhibiting exceptional\nstrength, electrical conductivity, and thermal properties, making them\npromising for various technologies. Besides achiral configurations with a\nzigzag or armchair edge, there exist chiral CNTs with a broken inversion\nsymmetry. Here, we demonstrate that chiral CNTs exhibit chirality-induced\norbital selectivity (CIOS), which is caused by the orbital Edelstein effect and\ncould be detected as chirality-induced spin selectivity (CISS). We find that\nthe orbital Edelstein susceptibility is an odd function of the chirality angle\nof the nanotube and is proportional to its radius. For metallic CNTs close to\nthe Fermi level, the orbital Edelstein susceptibility increases quadratically\nwith energy. This makes the CISS and CIOS of metallic chiral nanotubes\nconveniently tunable by doping or applying a gate voltage, which allows for the\ngeneration of spin- and orbital-polarized currents. The possibility of\ngenerating large torques makes chiral CNTs interesting candidates for\ntechnological applications in spin-orbitronics and quantum computing.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-10T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.07666v1","title":"On a fuzzy Landau Equation: Part I. A variational approach","summary":"This article is the first in a series of works on the fuzzy Landau equation,\nwhere particles interact through delocalised Coulomb collisions. Here, we\nestablish a variational characterisation that recasts the fuzzy Landau equation\nwithin the framework of GENERIC systems (General Equations for Non-Equilibrium\nReversible-Irreversible Coupling).","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T11:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.07693v1","title":"Molecular nature of hidden-charm pentaquark states $P_{c\\bar{c}s}$ with\n  strangeness $S=-1$","summary":"We investigate the hidden-charm pentaquark states with strangeness $S=-1$\n($P_{c\\bar{c}s}$) within an off-shell coupled-channel approach based on\neffective Lagrangians that respect heavy-quark spin symmetry, SU(3) flavor\nsymmetry, and hidden local symmetry. All relevant meson-baryon two-body\nchannels composed of low-lying anti-charmed mesons and singly-charmed baryons\nwith $S=-1$, as well as the $J/\\psi \\Lambda$ channel, are included. We find a\ntotal of eleven negative-parity states and three positive-parity states. AMong\nthe negative-parity states, the $P_{c\\bar{c}s}(4338)$ and $P_{c\\bar{c}s}(4459)$\ncan be naturally interpreted as $\\bar{D} \\Xi_c$ and $\\bar{D}^* \\Xi_c$ molecular\nstates, respectively. We identify a second state, $P_{c\\bar{c}s}(4472)$,\nlocated close to the $P_{c\\bar{c}s}(4459)$ but with different spin and width,\nwhich may correspond to the structure observed by the Belle Collaboration. Both\nstates are generated from the $\\bar{D}^* \\Xi_c$ channel and can be interpreted\nas spin partners. Their properties are consistent with recent experimental\nobservations, providing strong support for the molecular interpretation of the\n$P_{c\\bar{c}s}$ states. We also observe a two-pole structure near the\n$\\bar{D}_s^* \\Lambda_c$ and $\\bar{D}^* \\Xi_c'$ channel depending on\nspin-parity.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-10T12:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.07710v1","title":"Constraining off-shell Higgs boson production and the Higgs boson total\n  width using $WW\\to \\ellÎ½\\ellÎ½$ final states with the ATLAS detector","summary":"A measurement of off-shell Higgs boson production is performed in the $H^{*}\n\\rightarrow WW$ channel. The measurement uses a proton-proton collision dataset\nwith an integrated luminosity of 140 fb$^{-1}$ collected at a centre-of-mass\nenergy of 13 TeV by the ATLAS detector at the Large Hadron Collider. Final\nstates in which both $W$ bosons decay leptonically are targeted, and events are\ncategorised based on the flavour of the final-state leptons, the jet\nmultiplicity, and the output of neural network-based classifiers. The data are\nfound to be compatible with the Standard Model expectation. An observed\n(expected) upper limit at 95% confidence level is set on the rate of off-shell\nHiggs boson production at a value of 3.4 (4.4) times the Standard Model\nprediction. These results are combined with the results from the measurement of\non-shell Higgs boson production with the same final states to obtain an\nobserved (expected) upper limit at 95% confidence level on the Higgs boson\ntotal width of 13.1 (17.3) MeV.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T13:01:31Z"}
{"aid":"http://arxiv.org/abs/2504.07711v1","title":"Merging Embedded Topics with Optimal Transport for Online Topic Modeling\n  on Data Streams","summary":"Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T13:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.07717v1","title":"PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented\n  Generation in Large Language Models via Bilevel Optimization","summary":"Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-10T13:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07718v1","title":"Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval","summary":"Fine-grained text-to-image retrieval aims to retrieve a fine-grained target\nimage with a given text query. Existing methods typically assume that each\ntraining image is accurately depicted by its textual descriptions. However,\ntextual descriptions can be ambiguous and fail to depict discriminative visual\ndetails in images, leading to inaccurate representation learning. To alleviate\nthe effects of text ambiguity, we propose a Multi-Modal Reference learning\nframework to learn robust representations. We first propose a multi-modal\nreference construction module to aggregate all visual and textual details of\nthe same object into a comprehensive multi-modal reference. The multi-modal\nreference hence facilitates the subsequent representation learning and\nretrieval similarity computation. Specifically, a reference-guided\nrepresentation learning module is proposed to use multi-modal references to\nlearn more accurate visual and textual representations. Additionally, we\nintroduce a reference-based refinement method that employs the object\nreferences to compute a reference-based similarity that refines the initial\nretrieval results. Extensive experiments are conducted on five fine-grained\ntext-to-image retrieval datasets for different text-to-image retrieval tasks.\nThe proposed method has achieved superior performance over state-of-the-art\nmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,\nour method achieves the Rank1 accuracy of 56.2\\%, surpassing the recent CFine\nby 5.6\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.07728v1","title":"The Scaling Behaviors in Achieving High Reliability via\n  Chance-Constrained Optimization","summary":"We study the problem of resource provisioning under stringent reliability or\nservice level requirements, which arise in applications such as power\ndistribution, emergency response, cloud server provisioning, and regulatory\nrisk management. With chance-constrained optimization serving as a natural\nstarting point for modeling this class of problems, our primary contribution is\nto characterize how the optimal costs and decisions scale for a generic joint\nchance-constrained model as the target probability of satisfying the\nservice/reliability constraints approaches its maximal level. Beyond providing\ninsights into the behavior of optimal solutions, our scaling framework has\nthree key algorithmic implications. First, in distributionally robust\noptimization (DRO) modeling of chance constraints, we show that widely used\napproaches based on KL-divergences, Wasserstein distances, and moments heavily\ndistort the scaling properties of optimal decisions, leading to exponentially\nhigher costs. In contrast, incorporating marginal distributions or using\nappropriately chosen f-divergence balls preserves the correct scaling, ensuring\ndecisions remain conservative by at most a constant or logarithmic factor.\nSecond, we leverage the scaling framework to quantify the conservativeness of\ncommon inner approximations and propose a simple line search to refine their\nsolutions, yielding near-optimal decisions. Finally, given N data samples, we\ndemonstrate how the scaling framework enables the estimation of approximately\nPareto-optimal decisions with constraint violation probabilities significantly\nsmaller than the Omega(1/N)-barrier that arises in the absence of parametric\nassumptions","main_category":"math.OC","categories":"math.OC,math.PR,q-fin.RM","published":"2025-04-10T13:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.07768v1","title":"Weighted special cycles on Rapoport--Zink spaces with almost self-dual\n  level","summary":"We introduce a ``vector valued'' version of special cycles on GSpin\nRapoport--Zink spaces with almost self-dual level in the context of the Kudla\nprogram, with certain linear invariance and local modularity features. They are\nlocal analogs of special cycles on GSpin Shimura varieties with almost\nself-dual parahoric level (e.g. Siegel threefolds with paramodular level). We\nestablish local arithmetic Siegel--Weil formulas relating arithmetic\nintersection numbers of these special cycles and derivatives of certain local\nWhittaker functions in any dimension. The proof is based on a reduction formula\nfor cyclic quadratic lattices.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.07784v1","title":"The row left rank of quaternion unit gain graphs in terms of pendant\n  vertices","summary":"Let $\\widetilde{G}=(G,U(\\mathbb{Q}),\\varphi)$ be a quaternion unit gain graph\n(or $U(\\mathbb{Q})$-gain graph), where $G$ is the underlying graph of\n$\\widetilde{G}$, $U(\\mathbb{Q})=\\{q\\in \\mathbb{Q}: |q|=1\\}$ and\n$\\varphi:\\overrightarrow{E}\\rightarrow U(\\mathbb{Q})$ is the gain function such\nthat $\\varphi(e_{ij})=\\varphi(e_{ji})^{-1}=\\overline{\\varphi(e_{ji})}$ for any\nadjacent vertices $v_{i}$ and $v_{j}$. Let $A(\\widetilde{G})$ be the adjacency\nmatrix of $\\widetilde{G}$ and let $r(\\widetilde{G})$ be the row left rank of\n$\\widetilde{G}$. In this paper, we prove some lower bounds on the row left rank\nof $U(\\mathbb{Q})$-gain graphs in terms of pendant vertices. All corresponding\nextremal graphs are characterized.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07803v1","title":"A System for Comprehensive Assessment of RAG Frameworks","summary":"Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-10T14:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.07816v1","title":"The effect of background matter on the spin oscillations of neutrinos\n  scattered by the supermassive black hole","summary":"We study spin oscillations of neutrinos in relativistic moving matter inside\nan accretion disk. These neutrinos are gravitationally scattered off a spinning\nKerr black hole surrounded by a thick accretion disk. The disk can co-rotate\nand counter-rotate with respect to BH spin. We perform numerical simulations of\nthe propagation of a large number of incoming test neutrinos. We briefly\ndiscuss our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-10T14:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.07819v1","title":"Testing Leptogenesis from Observable Gravitational Waves","summary":"Leptogenesis provides an elegant mechanism to explain the observed baryon\nasymmetry of the Universe (BAU), yet its experimental verification remains\nchallenging due to requirements of either extremely heavy right-handed\nneutrinos or precisely fine-tuned mass splittings. We adapt a solution by\nintroducing an extra scalar field that significantly enhances $CP$ asymmetry\nthrough loop-level contributions. This scalar extension not only facilitates\nsuccessful leptogenesis but also enables a strong first-order electroweak phase\ntransition, generating potentially observable gravitational waves (GWs). We\ndemonstrate a strong correlation between the generated BAU and the GW signal\nstrength, establishing a unique way to test the leptogenesis. We show that when\nthe model achieves a successful BAU, the resulting GW signal from EWPT can have\nsignal-to-noise ratio of $\\mathcal{O}(10^3)$ and $\\mathcal{O}(10^6)$ at the\nupcoming LISA and DECIGO experiments, respectively. This work presents a\nconcrete connection between successful leptogenesis and detectable GWs,\noffering a promising method for experimental testing of the leptogenesis\nmechanism through future GW observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07847v1","title":"An update-resilient Kalman filtering approach","summary":"We propose a new robust filtering paradigm considering the situation in which\nmodel uncertainty, described through an ambiguity set, is present only in the\nobservations. We derive the corresponding robust estimator, referred to as\nupdate-resilient Kalman filter, which appears to be novel compared to existing\nminimax game-based filtering approaches. Moreover, we characterize the\ncorresponding least favorable state space model and analyze the filter\nstability. Finally, some numerical examples show the effectiveness of the\nproposed estimator.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07879v1","title":"Towards Sustainable Creativity Support: An Exploratory Study on Prompt\n  Based Image Generation","summary":"Creativity is a valuable human skill that has long been augmented through\nboth analog and digital tools. Recent progress in generative AI, such as image\ngeneration, provides a disruptive technological solution to supporting human\ncreativity further and helping humans generate solutions faster. While AI image\ngenerators can help to rapidly visualize ideas based on user prompts, the use\nof such AI systems has also been critiqued due to their considerable energy\nusage. In this paper, we report on a user study (N = 24) to understand whether\nenergy consumption can be reduced without impeding on the tool's perceived\ncreativity support. Our results highlight that, for example, a main effect of\n(image generation) condition on energy consumption, and index of creativity\nsupport per prompt but not per task, which seem mainly attributed to image\nquantity per prompt. We provide details of our analysis on the relation between\nenergy usage, creativity support, and prompting behavior, including attitudes\ntowards designing with AI and its environmental impact.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-10T15:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.07887v1","title":"Benchmarking Adversarial Robustness to Bias Elicitation in Large\n  Language Models: Scalable Automated Assessment with LLM-as-a-Judge","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T16:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07902v1","title":"Biased domain walls: faster annihilation, weaker gravitational waves","summary":"We study the evolution of domain wall networks and their phenomenological\nimplications in a model of a real scalar $\\chi$, where a $Z_2$-symmetry is\nslightly broken by a potential bias $V_{bias}$. It is demonstrated that the\nlatter triggers domain wall annihilation considerably earlier than previously\nthought. Namely, we observe that the scaling relation $t_{ann} \\propto\n1/V^{2/3}_{bias}$ for the annihilation time $t_{ann}$ fits to the simulation\ndata better than a commonly assumed $t_{ann} \\propto 1/V_{bias}$. As a result,\nthe energy density of gravitational waves produced by the network of biased\ndomain walls, for a given tiny $V_{bias}$, is suppressed compared to naive\nexpectations. The spectral shape of gravitational waves is similar to that\nresulting from unbiased domain walls, but with more power in the\nclose-to-maximum ultraviolet part. In the far ultraviolet region, the spectrum\nof gravitational waves becomes nearly flat; such a plateau has been recognized\nearlier in the case of unbiased walls. In our investigation we mainly focus on\nthe symmetry breaking potential $V_{breaking} \\propto \\chi^3$, and argue that\nno significant modifications of the domain walls evolution take place if one\nincludes higher powers of $\\chi$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,hep-th","published":"2025-04-10T16:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.07920v1","title":"Directed Temporal Tree Realization for Periodic Public Transport: Easy\n  and Hard Cases","summary":"We study the complexity of the directed periodic temporal graph realization\nproblem. This work is motivated by the design of periodic schedules in public\ntransport with constraints on the quality of service. Namely, we require that\nthe fastest path between (important) pairs of vertices is upper bounded by a\nspecified maximum duration, encoded in an upper distance matrix $D$. While\nprevious work has considered the undirected version of the problem, the\napplication in public transport schedule design requires the flexibility to\nassign different departure times to the two directions of an edge. A problem\ninstance can only be feasible if all values of the distance matrix are at least\nshortest path distances. However, the task of realizing exact fastest path\ndistances in a periodic temporal graph is often too restrictive. Therefore, we\nintroduce a minimum slack parameter $k$ that describes a lower bound on the\nmaximum allowed waiting time on each path. We concentrate on tree topologies\nand provide a full characterization of the complexity landscape with respect to\nthe period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp\nthreshold between NP-complete cases and cases which are always realizable. We\nalso provide hardness results for the special case of period $\\Delta = 2$ for\ngeneral directed and undirected graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM","published":"2025-04-10T17:36:23Z"}
{"aid":"http://arxiv.org/abs/2504.07921v1","title":"Note on the identification of total effect in Cluster-DAGs with cycles","summary":"In this note, we discuss the identifiability of a total effect in\ncluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming\nthe associated underlying DAG to be acyclic). This is presented into two key\nresults: first, restricting the cluster-DAG to clusters containing at most four\nnodes; second, adapting the notion of d-separation. We provide a graphical\ncriterion to address the identifiability problem.","main_category":"math.ST","categories":"math.ST,cs.AI,stat.TH","published":"2025-04-10T17:39:43Z"}
{"aid":"http://arxiv.org/abs/2504.07923v1","title":"Trading Graph Neural Network","summary":"This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)\nthat can structurally estimate the impact of asset features, dealer features\nand relationship features on asset prices in trading networks. It combines the\nstrength of the traditional simulated method of moments (SMM) and recent\nmachine learning techniques -- Graph Neural Network (GNN). It outperforms\nexisting reduced-form methods with network centrality measures in prediction\naccuracy. The method can be used on networks with any structure, allowing for\nheterogeneity among both traders and assets.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.LG,econ.GN,q-fin.EC,q-fin.PR","published":"2025-04-10T17:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07936v1","title":"We Are All Creators: Generative AI, Collective Knowledge, and the Path\n  Towards Human-AI Synergy","summary":"Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T17:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.07953v1","title":"Free monad sequences and extension operations","summary":"In the first part of this article, we give an analysis of the free monad\nsequence in non-cocomplete categories, with the needed colimits explicitly\nparametrized. This enables us to state a more finely grained functoriality\nprinciple for free monad and monoid sequences.\n  In the second part, we deal with the problem of functorially extending via\npullback squares a category of maps along the category of coalgebras of an\nalgebraic weak factorization system. This generalizes the classical problem of\nextending a class of maps along the left class of a weak factorization system\nin the sense of pullback squares where the vertical maps are in the chosen\nclass and the bottom map is in the left class. Such situations arise in the\ncontext of model structures where one might wish to extend fibrations along\ntrivial cofibrations. We derive suitable conditions for the algebraic analogue\nof weak saturation of the extension problem, using the results of the first\npart to reduce the technical burden.","main_category":"math.CT","categories":"math.CT","published":"2025-04-10T17:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.09880v1","title":"The Universal Gap-to-Critical Temperature Ratio in Superconductors: a\n  Statistical Mechanical Perspective","summary":"We propose a statistical mechanical framework to unify the observed\nrelationship between the superconducting energy gap $\\Delta$, the pseudogap\n$\\Delta^\\ast$, and the critical temperature $T_\\mathrm{c}$. In this model,\nfermions couple as a composite boson and condense to occupy a single bound\nstate as the temperature drops. We derive a concise formula for $T_\\mathrm{c}$\nin terms of $\\Delta$ and $\\Delta^\\ast$, namely: $$\\frac{\\Delta}{k_\\mathrm{B}\nT_\\mathrm{c}} = 1.4+4\\log(\\Delta^\\ast/\\Delta).$$ This expression reproduces the\nstandard BCS gap-to-$T_\\mathrm{c}$ ratio in the absence of a pseudogap, while\nnaturally explaining its enhancement in unconventional superconductors. The\nmodel is supported by comparisons with experimental data from several cuprates\nand iron-based superconductors, which highlight its generality. This\nformulation also offers a theoretical explanation for the observed persistence\nof the pseudogap phase into the overdoped regime.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-14T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.09885v1","title":"Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated\n  Piano Hand Motion Synthesis","summary":"Automating the synthesis of coordinated bimanual piano performances poses\nsignificant challenges, particularly in capturing the intricate choreography\nbetween the hands while preserving their distinct kinematic signatures. In this\npaper, we propose a dual-stream neural framework designed to generate\nsynchronized hand gestures for piano playing from audio input, addressing the\ncritical challenge of modeling both hand independence and coordination. Our\nframework introduces two key innovations: (i) a decoupled diffusion-based\ngeneration framework that independently models each hand's motion via\ndual-noise initialization, sampling distinct latent noise for each while\nleveraging a shared positional condition, and (ii) a Hand-Coordinated\nAsymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise\nto highlight asymmetric hand-specific features, while adaptively enhancing\ninter-hand coordination during denoising. The system operates hierarchically:\nit first predicts 3D hand positions from audio features and then generates\njoint angles through position-aware diffusion models, where parallel denoising\nstreams interact via HCAA. Comprehensive evaluations demonstrate that our\nframework outperforms existing state-of-the-art methods across multiple\nmetrics.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-14T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.09890v1","title":"Probing the Quantum Capacitance of Rydberg Transitions of Surface\n  Electrons on Liquid Helium via Microwave Frequency Modulation","summary":"We present a method for probing the quantum capacitance associated with the\nRydberg transition of surface electrons on liquid helium using RF\nreflectometry. Excitation to Rydberg states induces a redistribution of image\ncharges on capacitively coupled electrodes, giving rise to a quantum\ncapacitance. By applying frequency-modulated resonant microwaves to drive the\nRydberg transition, we systematically measured a capacitance sensitivity of\n0.38~aF/$\\sqrt{\\mathrm{Hz}}$. This level of sensitivity is sufficient to\nresolve the Rydberg transition of a single electron, providing a scalable\npathway toward the implementation of qubit readout schemes based on surface\nelectrons on helium.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-14T05:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.09899v1","title":"Digital Staining with Knowledge Distillation: A Unified Framework for\n  Unpaired and Paired-But-Misaligned Data","summary":"Staining is essential in cell imaging and medical diagnostics but poses\nsignificant challenges, including high cost, time consumption, labor intensity,\nand irreversible tissue alterations. Recent advances in deep learning have\nenabled digital staining through supervised model training. However, collecting\nlarge-scale, perfectly aligned pairs of stained and unstained images remains\ndifficult. In this work, we propose a novel unsupervised deep learning\nframework for digital cell staining that reduces the need for extensive paired\ndata using knowledge distillation. We explore two training schemes: (1)\nunpaired and (2) paired-but-misaligned settings. For the unpaired case, we\nintroduce a two-stage pipeline, comprising light enhancement followed by\ncolorization, as a teacher model. Subsequently, we obtain a student staining\ngenerator through knowledge distillation with hybrid non-reference losses. To\nleverage the pixel-wise information between adjacent sections, we further\nextend to the paired-but-misaligned setting, adding the Learning to Align\nmodule to utilize pixel-level information. Experiment results on our dataset\ndemonstrate that our proposed unsupervised deep staining method can generate\nstained images with more accurate positions and shapes of the cell targets in\nboth settings. Compared with competing methods, our method achieves improved\nresults both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied\nour digital staining method to the White Blood Cell (WBC) dataset,\ninvestigating its potential for medical applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T05:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.09914v1","title":"Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated\n  Knowledge","summary":"Memes have become a dominant form of communication in social media in recent\nyears. Memes are typically humorous and harmless, however there are also memes\nthat promote hate speech, being in this way harmful to individuals and groups\nbased on their identity. Therefore, detecting hateful content in memes has\nemerged as a task of critical importance. The need for understanding the\ncomplex interactions of images and their embedded text renders the hateful meme\ndetection a challenging multimodal task. In this paper we propose to address\nthe aforementioned task leveraging knowledge encoded in powerful Large\nMultimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold\nmanner. First, by extracting knowledge oriented to the hateful meme detection\ntask in order to build strong meme representations. Specifically, generic\nsemantic descriptions and emotions that the images along with their embedded\ntexts elicit are extracted, which are then used to train a simple\nclassification head for hateful meme detection. Second, by developing a novel\nhard mining approach introducing directly LMM-encoded knowledge to the training\nprocess, providing further improvements. We perform extensive experiments on\ntwo datasets that validate the effectiveness of the proposed method, achieving\nstate-of-the-art performance. Our code and trained models are publicly\navailable at: https://github.com/IDT-ITI/LMM-CLIP-meme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.09926v1","title":"Quotients of Poisson boundaries, entropy, and spectral gap","summary":"Poisson boundary is a measurable $\\Gamma$-space canonically associated with a\ngroup $\\Gamma$ and a probability measure $\\mu$ on it. The collection of all\nmeasurable $\\Gamma$-equivariant quotients, known as $\\mu$-boundaries, of the\nPoisson boundary forms a partially ordered set, equipped with a strictly\nmonotonic non-negative function, known as Furstenberg or differential entropy.\n  In this paper we demonstrate the richness and the complexity of this lattice\nof quotients for the case of free groups and surface groups and rather general\nmeasures. In particular, we show that there are continuum many unrelated\n$\\mu$-boundaries at each, sufficiently low, entropy level, and there are\ncontinuum many distinct order-theoretic cubes of $\\mu$-boundaries.\n  These $\\mu$-boundaries are constructed from dense linear representations\n$\\rho:\\Gamma\\to G$ to semi-simple Lie groups, like $\\PSL_2(\\bbC)^d$ with\nabsolutely continuous stationary measures on $\\hat\\bbC^d$.","main_category":"math.GR","categories":"math.GR,math.DS","published":"2025-04-14T06:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.09928v1","title":"On the difference of the two initial logarithmic coefficients for\n  Bazilevic class of univalent functions","summary":"In this paper we give sharp bounds of the difference of the moduli of the\nsecond and the first logarithmic coefficient for Bazilevi\\v{c} class of\nunivalent functions.","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T06:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.09934v1","title":"Tight Semidefinite Relaxations for Verifying Robustness of Neural\n  Networks","summary":"For verifying the safety of neural networks (NNs), Fazlyab et al. (2019)\nintroduced a semidefinite programming (SDP) approach called DeepSDP. This\nformulation can be viewed as the dual of the SDP relaxation for a problem\nformulated as a quadratically constrained quadratic program (QCQP). While SDP\nrelaxations of QCQPs generally provide approximate solutions with some gaps,\nthis work focuses on tight SDP relaxations that provide exact solutions to the\nQCQP for single-layer NNs. Specifically, we analyze tightness conditions in\nthree cases: (i) NNs with a single neuron, (ii) single-layer NNs with an\nellipsoidal input set, and (iii) single-layer NNs with a rectangular input set.\nFor NNs with a single neuron, we propose a condition that ensures the SDP\nadmits a rank-1 solution to DeepSDP by transforming the QCQP into an equivalent\ntwo-stage problem leads to a solution collinear with a predetermined vector.\nFor single-layer NNs with an ellipsoidal input set, the collinearity of\nsolutions is proved via the Karush-Kuhn-Tucker condition in the two-stage\nproblem. In case of single-layer NNs with a rectangular input set, we\ndemonstrate that the tightness of DeepSDP can be reduced to the single-neuron\nNNs, case (i), if the weight matrix is a diagonal matrix.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T06:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.09945v1","title":"Topological $Ï€/2$ modes in photonic waveguide arrays","summary":"Periodic driving is a powerful tool to generate exotic topological phases\nwithout static counterparts, such as the anomalous chiral edge modes from bulk\nbands with zero Chern number and topological $\\pi$ modes exhibiting\nperiod-doubled dynamics. Recently, a new class of Floquet topological mode,\nnamely the $\\pi/2$ mode, which carries four-period periodicity and has\npotential applications in quantum computing, was proposed based on a\nsquare-root method and realized in an acoustic system. Here we propose a\nlaser-written waveguide array lattice to realize topological $\\pi/2$ modes in\nphotonics. Our photonic model simulates a square-root periodically driven\nSu-Schrieffer-Heeger model and has a rich phase diagram allowing for the\nco-existence of conventional zero, $\\pi$ modes, and the new $\\pi/2$ modes.\nThrough numerical simulations of the wave equation, we uncover the unique\nfour-period evolution feature of the $\\pi/2$ modes. Our model, which only\ncontains four waveguides per unit cell and two driving steps, is easy to\nimplement with current fabrication techniques and may find applications in\nquantum optics.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-14T07:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.09980v1","title":"Turn-taking annotation for quantitative and qualitative analyses of\n  conversation","summary":"This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.","main_category":"cs.CL","categories":"cs.CL,cs.DB,cs.HC,eess.AS","published":"2025-04-14T08:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.09989v1","title":"FTHP-MPI: Towards Providing Replication-based Fault Tolerance in a\n  Fault-Intolerant Native MPI Library","summary":"Faults in high-performance systems are expected to be very large in the\ncurrent exascale computing era. To compensate for a higher failure rate, the\nstandard checkpoint/restart technique would need to create checkpoints at a\nmuch higher frequency resulting in an excessive amount of overhead which would\nnot be sustainable for many scientific applications. To improve application\nefficiency in such high failure environments, the mechanism of replication of\nMPI processes was proposed. Replication allows for fast recovery from failures\nby simply dropping the failed processes and using their replicas to continue\nthe regular operation of the application.\n  In this paper, we have implemented FTHP-MPI (Fault Tolerance and High\nPerformance MPI), a novel fault-tolerant MPI library that augments\ncheckpoint/restart with replication to provide resilience from failures. The\nnovelty of our work is that it is designed to provide fault tolerance in a\nnative MPI library that does not provide support for fault tolerance. This lets\napplication developers achieve fault tolerance at high failure rates while also\nusing efficient communication protocols in the native MPI libraries that are\ngenerally fine-tuned for specific HPC platforms. We have also implemented\nefficient parallel communication techniques that involve replicas. Our\nframework deals with the unique challenges of integrating support for\ncheckpointing and partial replication.\n  We conducted experiments emulating the failure rates of exascale computing\nsystems with three applications, HPCG, PIC and CloverLeaf. We show that for\nlarge scale systems where the failure intervals are expected to be within a\nhour, our replication-based library provides higher efficiency and performance\nthan checkpointing-based approaches. We show that under failure-free\nconditions, the additional overheads due to replication are negligible in our\nlibrary.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.09997v1","title":"GenTe: Generative Real-world Terrains for General Legged Robot\n  Locomotion Control","summary":"Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.10005v1","title":"Session-based Recommender Systems: User Interest as a Stochastic Process\n  in the Latent Space","summary":"This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-14T09:08:40Z"}
{"aid":"http://arxiv.org/abs/2504.10026v1","title":"An efffcient numerical scheme for two-dimensional nonlinear time\n  fractional SchrÃ¶dinger equation","summary":"In this paper, a linearized fully discrete scheme is proposed to solve the\ntwo-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly\nsingular solutions, which is constructed by using L1 scheme for Caputo\nfractional derivative, backward formula for the approximation of nonlinear term\nand five-point difference scheme in space. We rigorously prove the\nunconditional stability and pointwise-in-time convergence of the fully discrete\nscheme, which does not require any restriction on the grid ratio. Numerical\nresults are presented to verify the accuracy of the theoretical analysis.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T09:30:49Z"}
{"aid":"http://arxiv.org/abs/2504.10034v1","title":"Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for\n  Cognitive Radio Networks","summary":"Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T09:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10036v1","title":"DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics\n  through Extract-Reason-Verify","summary":"Large Language Models (LLMs) are transforming data analytics, but their\nwidespread adoption is hindered by two critical limitations: they are not\nexplainable (opaque reasoning processes) and not verifiable (prone to\nhallucinations and unchecked errors). While retrieval-augmented generation\n(RAG) improves accuracy by grounding LLMs in external data, it fails to address\nthe core challenges of trustworthy analytics - especially when processing\nnoisy, inconsistent, or multi-modal data (for example, text, tables, images).\nWe propose DataMosaic, a framework designed to make LLM-powered analytics both\nexplainable and verifiable. By dynamically extracting task-specific structures\n(for example, tables, graphs, trees) from raw data, DataMosaic provides\ntransparent, step-by-step reasoning traces and enables validation of\nintermediate results. Built on a multi-agent framework, DataMosaic orchestrates\nself-adaptive agents that align with downstream task requirements, enhancing\nconsistency, completeness, and privacy. Through this approach, DataMosaic not\nonly tackles the limitations of current LLM-powered analytics systems but also\nlays the groundwork for a new paradigm of grounded, accurate, and explainable\nmulti-modal data analytics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T09:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.10037v1","title":"A census of galactic spider binary millisecond pulsars with the\n  NanÃ§ay Radio Telescope","summary":"Spider pulsars are systems in which a millisecond pulsar (MSP) tightly orbits\n(Pb $\\lesssim$ 1 day) a low mass (mc $\\lesssim$ 0.5 M$_\\odot$) semi-degenerate\nstar. Spider often display eclipses around superior conjunction. This eclipse\nphenomenon is currently poorly understood. We analyzed eclipses via pulsar\ntiming. The eclipses were fit with a phenomenological model which gives a\nmeasurement of the duration and asymmetry of the eclipses. These parameters\nwere then compared to other eclipse and system measurements to discuss the\npotential link between the presence of eclipses and orbital inclination,\neclipsing systems being known to have higher mass functions than non-eclipsing\nones. We present here a comprehensive review of the NRT NUPPI backend spider\npulsars dataset. We also present the first review and systematic analysis of a\nlarge sample of eclipsers, monitored with the NRT over several years. The\nphenomenological fit allowed us to compare the eclipsers with each other, which\nled to the categorization of eclipsers depending on the shape of their\neclipses. We present the polarimetric properties of the 19 spiders in the\nsample alongside their profiles, which were previously unpublished in some\ncases. For the eclipsing systems, we found evidence for a positive correlation\nbetween eclipse duration and mass function, as expected if more eclipsing\nmaterial crosses the line-of-sight in higher inclination systems. For the\nentire sample, we found marginal evidence for increasing pulse profile width\nwith decreasing mass function. We finally conducted a comprehensive literature\nreview of the published inclination measurements for the pulsars in the sample\nand compared the inclinations to eclipse parameters. Nevertheless, the small\nnumber of available orbital inclination constraints, contradicting each other\nin some cases, hinders such searches for correlations","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T09:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.10062v1","title":"Computing the unitary best approximant to the exponential function","summary":"Unitary best approximation to the exponential function on an interval on the\nimaginary axis has been introduced recently. In the present work two algorithms\nare considered to compute this best approximant: an algorithm based on rational\ninterpolation in successively corrected interpolation nodes and the AAA-Lawson\nmethod. Moreover, a posteriori bounds are introduced to evaluate the quality of\na computed approximant and to show convergence to the unitary best approximant\nin practice. Two a priori estimates -- one based on experimental data, and one\nbased on an asymptotic error estimate -- are introduced to determine the\nunderlying frequency for which the unitary best approximant achieves a given\naccuracy. Performance of algorithms and estimates is verified by numerical\nexperiments. In particular, the interpolation-based algorithm converges to the\nunitary best approximant within a small number of iterations in practice.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.10072v1","title":"Comparison of an OGS/Polystyrene scintillator (BSO-406) with pure OGS\n  (BSO-100), EJ-276, EJ-309, and M600 scintillators","summary":"In this paper, we present an investigation into the scintillation properties\nand pulse shape discrimination (PSD) performance of the new BSO-406, which is a\nblend of 40% organic glass scintillator and 60% polystyrene. We tested a\ncylindrical sample with dimensions of 2x2 inches. The study includes\nmeasurements of neutron-gamma discrimination capability, emission spectra,\nphotoelectron yield, and the analysis of light pulse shapes originating from\nevents related to gamma-rays and fast neutrons. The results were compared to\ndata previously recorded using a pure Organic Glass Scintillator (BSO-100), an\nEJ-309 liquid scintillator, and EJ-276 and M600 polyurethane-based plastic\nscintillators.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-14T10:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.10080v1","title":"Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image\n  Dynamics Correction","summary":"In this paper, we explore how conventional image enhancement can improve\nmodel robustness in medical image analysis. By applying commonly used\nnormalization methods to images from various vendors and studying their\ninfluence on model generalization in transfer learning, we show that the\nnonlinear characteristics of domain-specific image dynamics cannot be addressed\nby simple linear transforms. To tackle this issue, we reformulate the image\nharmonization task as an exposure correction problem and propose a method\ntermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposure\nmismatch. GDCE performs enhancement via a pre-defined polynomial function and\nis trained with the help of a ``domain discriminator'', aiming to improve model\ntransparency in downstream tasks compared to existing black-box methods.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T10:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.10081v1","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning\n  Capability","summary":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-14T10:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.10082v1","title":"Leveraging Metaphors in a VR Serious Game for Computational Thinking","summary":"This paper presents Cooking Code, a VR-based serious game designed to\nintroduce programming concepts to students (ages 12-16) through an immersive,\nscenario-driven experience. Set in a futuristic world where humans and machines\ncoexist, players take on the role of a fast-food chef who must assemble food\norders based on pseudocode instructions. By interpreting and executing these\ninstructions correctly, players develop problem-solving skills, computational\nthinking, and a foundational understanding of programming logic. The game\nleverages the kitchen metaphor to teach computational thinking, using\naffordances for an immersive VR experience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T10:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.10084v1","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based\n  Person Retrieval","summary":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.10085v1","title":"Giant and anisotropic magnetostriction in $Î²$-O$_{2}$ at 110 T","summary":"Magnetostriction is a crystal's deformation under magnetic fields, usually in\nthe range of $10^{-6}$ - $10^{-3}$, where the lattice change occurs with the\nchange of spin and orbital state through spin-lattice couplings. In strong\nmagnetic fields beyond 100 T, the significant Zeeman energy competes with the\nlattice interactions, where one can expect considerable magnetostriction.\nHowever, directly observing magnetostriction above 100 T is challenging,\nbecause generating magnetic fields beyond 100 T accompanies the destruction of\nthe coil with a single-shot $\\mu$-second pulse. Here, we observed the giant and\nanisotropic magnetostriction of $\\sim$1 % at 110 T in the spin-controlled\ncrystal of $\\beta$-O$_{2}$, by combining the single-shot diffraction of x-ray\nfree-electron laser (XFEL) and the state-of-the-art portable 100 T generator.\nThe magnetostriction of $\\sim$1 % is the largest class as a deformation of the\nunit cell. It is a response of the soft lattice of $\\beta$-O$_{2}$ originating,\nnot only in the competing van der Waals force and exchange interaction, but\nalso the soft state of spin and lattice frustrated on the triangular network.\nMeanwhile, the anisotropy originates from the strong two-dimensionality of the\nspin system. Giant magnetostriction in crystals should become more ubiquitous\nand diverse beyond 100 T, where our XFEL experiment above 100 T opens a novel\npathway for their exploration, providing fundamental insights into the roles of\nspin in stabilizing crystal structures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-14T10:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.10091v1","title":"Wasserstein convergence rates for stochastic particle approximation of\n  Boltzmann models","summary":"We establish quantitative convergence rates for stochastic particle\napproximation based on Nanbu-type Monte Carlo schemes applied to a broad class\nof collisional kinetic models. Using coupling techniques and stability\nestimates in the Wasserstein-1 (Kantorovich-Rubinstein) metric, we derive sharp\nerror bounds that reflect the nonlinear interaction structure of the models.\nOur framework includes classical Nanbu Monte Carlo method and more recent\ndevelopments as Time Relaxed Monte Carlo methods. The results bridge the gap\nbetween probabilistic particle approximations and deterministic numerical error\nanalysis, and provide a unified perspective for the convergence theory of Monte\nCarlo methods for Boltzmann-type equations. As a by-product, we also obtain\nexistence and uniqueness of solutions to a large class of Boltzmann-type\nequations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:55:04Z"}
{"aid":"http://arxiv.org/abs/2504.10097v1","title":"STaRFormer: Semi-Supervised Task-Informed Representation Learning via\n  Dynamic Attention-Based Regional Masking for Sequential Data","summary":"Accurate predictions using sequential spatiotemporal data are crucial for\nvarious applications. Utilizing real-world data, we aim to learn the intent of\na smart device user within confined areas of a vehicle's surroundings. However,\nin real-world scenarios, environmental factors and sensor limitations result in\nnon-stationary and irregularly sampled data, posing significant challenges. To\naddress these issues, we developed a Transformer-based approach, STaRFormer,\nwhich serves as a universal framework for sequential modeling. STaRFormer\nemploys a novel, dynamic attention-based regional masking scheme combined with\nsemi-supervised contrastive learning to enhance task-specific latent\nrepresentations. Comprehensive experiments on 15 datasets varying in types\n(including non-stationary and irregularly sampled), domains, sequence lengths,\ntraining samples, and applications, demonstrate the efficacy and practicality\nof STaRFormer. We achieve notable improvements over state-of-the-art\napproaches. Code and data will be made available.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T11:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.10107v1","title":"Enhancing LLM-based Recommendation through Semantic-Aligned\n  Collaborative Knowledge","summary":"Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.10123v1","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera\n  and LiDAR Data","summary":"Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.10152v1","title":"Neo balcobalancing numbers","summary":"In this work, we defined neo balcobalancing numbers, neo Lucas-balcobalancing\nnumbers, neo balcobalancers and neo Lucas-balcobalancers and derived the\ngeneral terms of these numbers in terms of balancing numbers. Conversely we\ndeduced the general terms of balancing, cobalancing, Lucas-balancing and\nLucas-cobalancing numbers in terms of these numbers. We also deduced some\nrelations on Binet formulas, recurrence relations, relationship with Pell,\nPell-Lucas, triangular, square triangular numbers, Pythagorean triples and\nCassini identities. We also formulate the sum of first $n$-terms of these\nnumbers and obtained some formulas for the sums of Pell, Pell-Lucas, balancing\nand Lucas-cobalancing numbers in terms of these numbers.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T12:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.10163v1","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating\n  Scapulohumeral Rhythm for Frozen Shoulder","summary":"This paper presents a novel rehabilitation robot designed to address the\nchallenges of passive range of motion (PROM) exercises for frozen shoulder\npatients by integrating advanced scapulohumeral rhythm stabilization. Frozen\nshoulder is characterized by limited glenohumeral motion and disrupted\nscapulohumeral rhythm, with therapist-assisted interventions being highly\neffective for restoring normal shoulder function. While existing robotic\nsolutions replicate natural shoulder biomechanics, they lack the ability to\nstabilize compensatory movements, such as shoulder shrugging, which are\ncritical for effective rehabilitation. Our proposed device features a 6 degrees\nof freedom (DoF) mechanism, including 5 DoF for shoulder motion and an\ninnovative 1 DoF Joint press for scapular stabilization. The robot employs a\npersonalized two-phase operation: recording normal shoulder movement patterns\nfrom the unaffected side and applying them to guide the affected side.\nExperimental results demonstrated the robot's ability to replicate recorded\nmotion patterns with high precision, with root mean square error (RMSE) values\nconsistently below 1 degree. In simulated frozen shoulder conditions, the robot\neffectively suppressed scapular elevation, delaying the onset of compensatory\nmovements and guiding the affected shoulder to move more closely in alignment\nwith normal shoulder motion, particularly during arm elevation movements such\nas abduction and flexion. These findings confirm the robot's potential as a\nrehabilitation tool capable of automating PROM exercises while correcting\ncompensatory movements. The system provides a foundation for advanced,\npersonalized rehabilitation for patients with frozen shoulders.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T12:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.10173v1","title":"Photosensitive materials for neutron optics","summary":"Photosensitive materials with ever-improving properties are of great\nimportance for optical and photonics applications. Additionally, they are\nextremely useful for designing components for neutron optical devices. We\nprovide an overview on materials that have been tested and successfully used to\ncontrol beams of cold and very cold neutrons based on diffractive elements.\nArtificial gratings are generated and optimized for the specific application in\nmind. We discuss the needs of the neutron optics community and highlight the\nprogress obtained during the last decade. Materials that have been employed so\nfar along with their properties are summarized, outlining the most promising\ncandidates for the construction of an interferometer for very cold neutrons.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T12:25:41Z"}
{"aid":"http://arxiv.org/abs/2504.10187v1","title":"Deep Reasoning Translation via Reinforcement Learning","summary":"Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.10196v1","title":"On compact embeddings in $\\mathbf{L^p}$ and fractional spaces","summary":"Let $X,Y$ be Hilbert spaces and $\\mathcal{A}\\colon X\\to X'$ a continuous and\nsymmetric elliptic operator. We suppose that $X$ is dense in $Y$ and that the\nembedding $X\\subset Y$ is compact. In this paper we show some consequences of\nthis setting on the study of the fractional operator attached to $\\mathcal{A}$\nin the extension setting $\\mathbb{R}^N\\times (0, \\infty)$. Being more specific,\nwe will give some examples where the embedding $H(\\mathbb{R}^{N+1}_+)\\subset\nL^2(\\mathbb{R}^N)$ is compact, with the space $H(\\mathbb{R}^{N+1}_+)$ depending\non the operator $\\mathcal{A}$.","main_category":"math.FA","categories":"math.FA,math.AP","published":"2025-04-14T13:02:48Z"}
{"aid":"http://arxiv.org/abs/2504.10201v1","title":"VibrantLeaves: A principled parametric image generator for training deep\n  restoration models","summary":"Even though Deep Neural Networks are extremely powerful for image restoration\ntasks, they have several limitations. They are poorly understood and suffer\nfrom strong biases inherited from the training sets. One way to address these\nshortcomings is to have a better control over the training sets, in particular\nby using synthetic sets. In this paper, we propose a synthetic image generator\nrelying on a few simple principles. In particular, we focus on geometric\nmodeling, textures, and a simple modeling of image acquisition. These\nproperties, integrated in a classical Dead Leaves model, enable the creation of\nefficient training sets. Standard image denoising and super-resolution networks\ncan be trained on such datasets, reaching performance almost on par with\ntraining on natural image datasets. As a first step towards explainability, we\nprovide a careful analysis of the considered principles, identifying which\nimage properties are necessary to obtain good performances. Besides, such\ntraining also yields better robustness to various geometric and radiometric\nperturbations of the test sets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T13:09:49Z"}
{"aid":"http://arxiv.org/abs/2504.10210v1","title":"Can Competition Enhance the Proficiency of Agents Powered by Large\n  Language Models in the Realm of News-driven Time Series Forecasting?","summary":"Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T13:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10214v1","title":"Balancing Stability and Plasticity in Pretrained Detector: A Dual-Path\n  Framework for Incremental Object Detection","summary":"The balance between stability and plasticity remains a fundamental challenge\nin pretrained model-based incremental object detection (PTMIOD). While existing\nPTMIOD methods demonstrate strong performance on in-domain tasks aligned with\npretraining data, their plasticity to cross-domain scenarios remains\nunderexplored. Through systematic component-wise analysis of pretrained\ndetectors, we reveal a fundamental discrepancy: the localization modules\ndemonstrate inherent cross-domain stability-preserving precise bounding box\nestimation across distribution shifts-while the classification components\nrequire enhanced plasticity to mitigate discriminability degradation in\ncross-domain scenarios. Motivated by these findings, we propose a dual-path\nframework built upon pretrained DETR-based detectors which decouples\nlocalization stability and classification plasticity: the localization path\nmaintains stability to preserve pretrained localization knowledge, while the\nclassification path facilitates plasticity via parameter-efficient fine-tuning\nand resists forgetting with pseudo-feature replay. Extensive evaluations on\nboth in-domain (MS COCO and PASCAL VOC) and cross-domain (TT100K) benchmarks\nshow state-of-the-art performance, demonstrating our method's ability to\neffectively balance stability and plasticity in PTMIOD, achieving robust\ncross-domain adaptation and strong retention of anti-forgetting capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T13:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10226v1","title":"Geodesic interpretation of the global quasi-geostrophic equations","summary":"We give an interpretation of the global shallow water quasi-geostrophic\nequations on the sphere $\\Sph^2$ as a geodesic equation on the central\nextension of the quantomorphism group on $\\Sph^3$. The study includes deriving\nthe model as a geodesic equation for a weak Riemannian metric, demonstrating\nsmooth dependence on the initial data, and establishing global-in-time\nexistence and uniqueness of solutions. We also prove that the Lamb parameter in\nthe model has a stabilizing effect on the dynamics: if it is large enough, the\nsectional curvature along the trade-wind current is positive, implying\nconjugate points.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T13:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.10227v1","title":"Probing then Editing Response Personality of Large Language Models","summary":"Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that exhibit consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nencoding personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly encode personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:46:35Z"}
{"aid":"http://arxiv.org/abs/2504.10231v1","title":"A Model Zoo of Vision Transformers","summary":"The availability of large, structured populations of neural networks - called\n'model zoos' - has led to the development of a multitude of downstream tasks\nranging from model analysis, to representation learning on model weights or\ngenerative modeling of neural network parameters. However, existing model zoos\nare limited in size and architecture and neglect the transformer, which is\namong the currently most successful neural network architectures. We address\nthis gap by introducing the first model zoo of vision transformers (ViT). To\nbetter represent recent training approaches, we develop a new blueprint for\nmodel zoo generation that encompasses both pre-training and fine-tuning steps,\nand publish 250 unique models. They are carefully generated with a large span\nof generating factors, and their diversity is validated using a thorough choice\nof weight-space and behavioral metrics. To further motivate the utility of our\nproposed dataset, we suggest multiple possible applications grounded in both\nextensive exploratory experiments and a number of examples from the existing\nliterature. By extending previous lines of similar work, our model zoo allows\nresearchers to push their model population-based methods from the small model\nregime to state-of-the-art architectures. We make our model zoo available at\ngithub.com/ModelZoos/ViTModelZoo.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.10244v1","title":"Towards contrast- and pathology-agnostic clinical fetal brain MRI\n  segmentation using SynthSeg","summary":"Magnetic resonance imaging (MRI) has played a crucial role in fetal\nneurodevelopmental research. Structural annotations of MR images are an\nimportant step for quantitative analysis of the developing human brain, with\nDeep learning providing an automated alternative for this otherwise tedious\nmanual process. However, segmentation performances of Convolutional Neural\nNetworks often suffer from domain shift, where the network fails when applied\nto subjects that deviate from the distribution with which it is trained on. In\nthis work, we aim to train networks capable of automatically segmenting fetal\nbrain MRIs with a wide range of domain shifts pertaining to differences in\nsubject physiology and acquisition environments, in particular shape-based\ndifferences commonly observed in pathological cases. We introduce a novel\ndata-driven train-time sampling strategy that seeks to fully exploit the\ndiversity of a given training dataset to enhance the domain generalizability of\nthe trained networks. We adapted our sampler, together with other existing data\naugmentation techniques, to the SynthSeg framework, a generator that utilizes\ndomain randomization to generate diverse training data, and ran thorough\nexperimentations and ablation studies on a wide range of training/testing data\nto test the validity of the approaches. Our networks achieved notable\nimprovements in the segmentation quality on testing subjects with intense\nanatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease\nin performance in cases with fewer abnormalities. Our work also lays the\nfoundation for future works on creating and adapting data-driven sampling\nstrategies for other training pipelines.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-14T14:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.10245v1","title":"A short proof for the acyclicity of oriented exchange graphs of cluster\n  algebras","summary":"The statement in the title was proved in \\cite{Cao23} by introducing dominant\nsets of seeds, which are analogs of torsion classes in representation theory.\nIn this note, we observe a short proof by the existence of consistent cluster\nscattering diagrams.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-14T14:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.10249v1","title":"Struggle First, Prompt Later: How Task Complexity Shapes Learning with\n  GenAI-Assisted Pretesting","summary":"This study examines the role of AI-assisted pretesting in enhancing learning\noutcomes, particularly when integrated with generative AI tools like ChatGPT.\nPretesting, a learning strategy in which students attempt to answer questions\nor solve problems before receiving instruction, has been shown to improve\nretention by activating prior knowledge. The adaptability and interactivity of\nAI-assisted pretesting introduce new opportunities for optimizing learning in\ndigital environments. Across three experimental studies, we explored how\npretesting strategies, task characteristics, and student motivation influence\nlearning. Findings suggest that AI-assisted pretesting enhances learning\noutcomes, particularly for tasks requiring higher-order thinking. While\nadaptive AI-driven pretesting increased engagement, its benefits were most\npronounced in complex, exploratory tasks rather than straightforward\ncomputational problems. These results highlight the importance of aligning\npretesting strategies with task demands, demonstrating that AI can optimize\nlearning when applied to tasks requiring deeper cognitive engagement. This\nresearch provides insights into how AI-assisted pretesting can be effectively\nintegrated with generative AI tools to enhance both cognitive and motivational\noutcomes in learning environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.10258v1","title":"XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a\n  Novel Benchmark","summary":"Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-14T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10281v1","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent\n  Characterization of 2D Materials","summary":"Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cs.AI,cs.CV,cs.LG","published":"2025-04-14T14:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10291v1","title":"Towards a Flat Space Carrollian Hologram from AdS$_4$/CFT$_3$","summary":"Finding a concrete example holography in four dimensional asymptotically flat\nspace is an important open problem. A natural strategy is to take the flat\nspace limit of the celebrated AdS$_4$/CFT$_3$ correspondence, which relates\nM-theory in AdS$_4 \\times$S$^7$ to a certain superconformal Chern-Simons-matter\ntheory known as the ABJM theory. In this limit, the boundary of AdS$_4$ becomes\nnull infinity and the ABJM theory should exhibit an emergent superconformal\nCarrollian symmetry. We investigate this possiblity by matching the Carrollian\nlimit of ABJM correlators with four-dimensional supergravity amplitudes that\narise from taking the flat space limit of AdS$_4 \\times$S$^7$ and reducing\nalong the S$^7$. We also present a general analysis of three-dimensional\nsuperconformal Carrollian symmetry.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T15:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10297v1","title":"Bumblebee cosmology: The FLRW solution and the CMB temperature\n  anisotropy","summary":"We put into test the idea of replacing dark energy by a vector field against\nthe cosmic microwave background (CMB) observation using the simplest\nvector-tensor theory, where a massive vector field couples to the Ricci scalar\nand the Ricci tensor quadratically. First, a remarkable\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) metric solution that is\ncompletely independent of the matter-energy compositions of the universe is\nfound. Second, based on the FLRW solution as well as the perturbation\nequations, a numerical code calculating the CMB temperature power spectrum is\nbuilt. We find that though the FLRW solution can mimic the evolution of the\nuniverse in the standard $\\Lambda$CDM model, the calculated CMB temperature\npower spectrum shows unavoidable discrepancies from the CMB power spectrum\nmeasurements.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-14T15:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.10311v1","title":"Performance of a Brownian information engine through potential\n  profiling: Optimum output requisites, Heating-to-Refrigeration transition and\n  their Re-entrance","summary":"Brownian Information engine (BIE) harnesses the energy from a fluctuating\nenvironment by utilizing the associated information change in the presence of a\nsingle heat bath. The engine operates in a space-dependent confining potential\nand requires an appropriate feedback control mechanism. In general, the\nfeedback controller has three different steps: measurement, feedback, and\nrelaxation. The feedback step is related to a sudden change in the potential\nenergy that is essential for a nonzero work output. BIE utilises the amount of\ninformation (surprise) acquired during the measurement step for the energy\noutput. However, due to the relaxation process, a certain amount of acquired\ninformation is lost or becomes unavailable. So, controlling information loss\nduring relaxation is crucial for the overall efficiency of the engine. The net\n(available) information, therefore, can be monitored by tuning the feedback\ncontroller and the shape of the confining potential. In this paper, we explore\nthe effect of the shape modulation of the confining potential, which may have\nmultiple stable valleys and unstable hills, on the net available information\nand, hence, the performance of a BIE that operates under an asymmetric feedback\nprotocol. We examine the optimal performance requirements of the BIE and the\namount of maximum work output under different potential profiling. For\nmonostable trapping, a concave shape in confining potential results in a higher\nwork output than a convex one. We also find that hills and valleys in the\nconfining potential may lead to multiple good operating conditions. An\nappropriate shape modulation can create a heater-refrigerator transition and\ntheir reentrance due to non-trivial changes in information loss during the\nrelaxation process.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10328v1","title":"Continuous fields of interval algebras","summary":"This paper investigates and classifies a specific class of one-parameter\ncontinuous fields of C*-algebras, which can be seen as generalized AI-algebras.\nBuilding on the classification of *-homomorphisms between interval algebras by\nthe Cuntz semigroup, along with a selection theorem and a gluing procedure, we\nemploy a 'local-to-global' strategy to achieve our classification result.","main_category":"math.OA","categories":"math.OA","published":"2025-04-14T15:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.10329v1","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","summary":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been\nextensively utilized for preference alignment of text-to-image models. Existing\nmethods face certain limitations in terms of both data and algorithm. For\ntraining data, most approaches rely on manual annotated preference data, either\nby directly fine-tuning the generators or by training reward models to provide\ntraining signals. However, the high annotation cost makes them difficult to\nscale up, the reward model consumes extra computation and cannot guarantee\naccuracy. From an algorithmic perspective, most methods neglect the value of\ntext and only take the image feedback as a comparative signal, which is\ninefficient and sparse. To alleviate these drawbacks, we propose the\nInstructEngine framework. Regarding annotation cost, we first construct a\ntaxonomy for text-to-image generation, then develop an automated data\nconstruction pipeline based on it. Leveraging advanced large multimodal models\nand human-defined rules, we generate 25K text-image preference pairs. Finally,\nwe introduce cross-validation alignment method, which refines data efficiency\nby organizing semantically analogous samples into mutually comparable pairs.\nEvaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and\nSDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art\nbaselines, with ablation study confirming the benefits of InstructEngine's all\ncomponents. A win rate of over 50% in human reviews also proves that\nInstructEngine better aligns with human preferences.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.10334v1","title":"Flying Hand: End-Effector-Centric Framework for Versatile Aerial\n  Manipulation Teleoperation and Policy Learning","summary":"Aerial manipulation has recently attracted increasing interest from both\nindustry and academia. Previous approaches have demonstrated success in various\nspecific tasks. However, their hardware design and control frameworks are often\ntightly coupled with task specifications, limiting the development of\ncross-task and cross-platform algorithms. Inspired by the success of robot\nlearning in tabletop manipulation, we propose a unified aerial manipulation\nframework with an end-effector-centric interface that decouples high-level\nplatform-agnostic decision-making from task-agnostic low-level control. Our\nframework consists of a fully-actuated hexarotor with a 4-DoF robotic arm, an\nend-effector-centric whole-body model predictive controller, and a high-level\npolicy. The high-precision end-effector controller enables efficient and\nintuitive aerial teleoperation for versatile tasks and facilitates the\ndevelopment of imitation learning policies. Real-world experiments show that\nthe proposed framework significantly improves end-effector tracking accuracy,\nand can handle multiple aerial teleoperation and imitation learning tasks,\nincluding writing, peg-in-hole, pick and place, changing light bulbs, etc. We\nbelieve the proposed framework provides one way to standardize and unify aerial\nmanipulation into the general manipulation community and to advance the field.\nProject website: https://lecar-lab.github.io/flying_hand/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:41:14Z"}
{"aid":"http://arxiv.org/abs/2504.10335v1","title":"MorphTok: Morphologically Grounded Tokenization for Indian Languages","summary":"Tokenization is a crucial step in NLP, especially with the rise of large\nlanguage models (LLMs), impacting downstream performance, computational cost,\nand efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE)\nalgorithm for subword tokenization that greedily merges frequent character\nbigrams. This often leads to segmentation that does not align with\nlinguistically meaningful units. To address this, we propose morphology-aware\nsegmentation as a pre-tokenization step prior to applying BPE. To facilitate\nmorphology-aware segmentation, we create a novel dataset for Hindi and Marathi,\nincorporating sandhi splitting to enhance the subword tokenization. Experiments\non downstream tasks show that morphologically grounded tokenization improves\nperformance for machine translation and language modeling. Additionally, to\nhandle the ambiguity in the Unicode characters for diacritics, particularly\ndependent vowels in syllable-based writing systems, we introduce Constrained\nBPE (CBPE), an extension to the traditional BPE algorithm that incorporates\nscript-specific constraints. Specifically, CBPE handles dependent vowels. Our\nresults show that CBPE achieves a 1.68\\% reduction in fertility scores while\nmaintaining comparable or improved downstream performance in machine\ntranslation, offering a computationally efficient alternative to standard BPE.\nMoreover, to evaluate segmentation across different tokenization algorithms, we\nintroduce a new human evaluation metric, \\textit{EvalTok}, enabling more\nhuman-grounded assessment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T15:44:45Z"}
{"aid":"http://arxiv.org/abs/2504.10346v1","title":"On Differential-Algebraic Equations with Bounded Spectrum in Banach\n  Spaces","summary":"The Weierstra{\\ss} form for regular DAEs in finite dimensions decouples a\nlinear DAE into an ODE and the nilpotent part of the underlying pencil. Here,\nwe provide necessary and sufficient conditions for the possibility of such a\ndecomposition in the case of DAEs in Banach spaces. Moreover, we consider the\nlarger class of linear operator pencils with bounded spectra and show that the\nassociated homogeneous DAE can be reduced to an ODE and a seemingly simple DAE\nof the form $\\frac d{dt}Tx = x$ with a quasi-nilpotent operator $T$. As\nexamples show, there are cases with only the trivial solution and others with\nnon-trivial solutions. We characterize the existence of $L^\\infty$-solutions on\nthe half-axis, $L^2$-solutions on compact time intervals, and analytic\nsolutions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T15:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.10379v1","title":"Minimal surfaces in strongly correlated random environments","summary":"A minimal surface in a random environment (MSRE) is a $d$-dimensional surface\nin $(d+n)$-dimensional space which minimizes the sum of its elastic energy and\nits environment potential energy, subject to prescribed boundary values. Apart\nfrom their intrinsic interest, such surfaces are further motivated by\nconnections with disordered spin systems and first-passage percolation models.\nIn this work, we consider the case of strongly correlated environments,\nrealized by the model of harmonic MSRE in a fractional Brownian environment of\nHurst parameter $H\\in(0,1)$. This includes the case of Brownian environment\n($H=1/2$ and $n=1$), which is commonly used to approximate the domain walls of\nthe $(d+1)$-dimensional random-field Ising model.\n  We prove that surfaces of dimension $d\\in\\{1,2,3\\}$ delocalize with power-law\nfluctuations, and determine their precise transversal and minimal energy\nfluctuation exponents, as well as the stretched exponential exponents governing\nthe tail decay of their distributions. These exponents are found to be the same\nin all codimensions $n$, depending only on $d$ and $H$. The transversal and\nminimal energy fluctuation exponents are specified by two scaling relations.\n  We further show that surfaces of dimension $d=4$ delocalize with\nsub-power-law fluctuations, with their height and minimal energy fluctuations\ntied by a scaling relation. Lastly, we prove that surfaces of dimensions $d\\ge\n5$ localize.\n  These results put several predictions from the physics literature on\nmathematically rigorous ground.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-14T16:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.10380v1","title":"Lorentzian Gromov-Hausdorff convergence and pre-compactness","summary":"To goal of the paper is to introduce a convergence \\`a la Gromov-Hausdorff\nfor Lorentzian spaces, building on $\\epsilon$-nets consisting of causal\ndiamonds and relying only on the time separation function. This yields a\ngeometric notion of convergence, which can be applied to synthetic Lorentzian\nspaces (Lorentzian pre-length spaces) or smooth spacetimes. Among the main\nresults, we prove a Lorentzian counterpart of the celebrated Gromov's\npre-compactness theorem for metric spaces, where controlled covers by balls are\nreplaced by controlled covers by diamonds. This yields a geometric\npre-compactness result for classes of globally hyperbolic spacetimes,\nsatisfying a uniform doubling property on Cauchy hypersurfaces and a suitable\ncontrol on the causality. The final part of the paper establishes several\napplications: we show that Chru\\'sciel-Grant approximations are an instance of\nthe Lorentzian Gromov-Hausdorff convergence here introduced, we prove that\ntimelike sectional curvature bounds are stable under such a convergence, we\nintroduce timelike blow-up tangents and discuss connections with the main\nconjecture of causal set theory.","main_category":"math.DG","categories":"math.DG,gr-qc,math-ph,math.MG,math.MP","published":"2025-04-14T16:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.10382v1","title":"Why Cold BGK Modes Are So Cool: Dispersion Relations from\n  Orbit-Constrained Distribution Functions","summary":"We derive analytic dispersion relations for cold, orbitally constrained\nsystems governed by the Vlasov equation. For magnetized plasmas, we obtain the\nfirst explicit relation for two-dimensional anisotropic BGK modes with finite\nmagnetic field, showing that only a finite number of angular modes can become\nunstable and identifying a magnetic-field threshold for stabilization. In the\ngravitational case, we establish a bound on the growth rate of core\nperturbations, set by the potential's curvature. These results clarify how\norbital constraints shape the spectrum and growth of kinetic instabilities in\ncold, collisionless media.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.GA","published":"2025-04-14T16:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.10385v1","title":"Normalized solutions for SchrÃ¶dinger-Bopp-Podolsky systems in bounded\n  domains","summary":"We consider an elliptic system of Schr\\\"odinger-Bopp-Podolsky type in a\nbounded and smooth domain of R3 with a non constant coupling factor. This kind\nof system has been introduced in the mathematical literature in [14] and in the\nlast years many contributions appeared. In particular here we present the\nresults in [2] and [34] which show existence of solutions by means of the\nLjusternik-Schnirelmann theory under different boundary conditions on the\nelectrostatic potential.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:31Z"}
{"aid":"http://arxiv.org/abs/2504.10392v1","title":"Spin-Orbital Intertwined Topological Superconductivity in a Class of\n  Correlated Noncentrosymmetric Materials","summary":"In this study, we propose an alternative route to achieving topological\nsuperconductivity (TSC). Our approach applies to a new class of correlated\nnoncentrosymmetric materials that host two spin-split Fermi surfaces with\nidentical spin textures due to a spin-orbital intertwined effect. Incorporating\nmulti-orbital repulsive Hubbard interactions, we calculate the superconducting\npairings of a minimal two-orbital effective model within a\nspin-fluctuation-mediated superconductivity framework. We find that, depending\non the effective Rashba spin-orbit coupling (RSOC) strength and filling level,\nthe Hubbard interaction can drive the leading pairing symmetry into the\n$A_1(S_{\\pm})$, $B_1$, $B_2$ or $B_2(d_{\\pm})$ irreducible representations\n(IRs) of the $C_{4v}$ point group. Notably, the $A_1(S_{\\pm})$ pairing gives\nrise to a fully gapped TSC characterized by a $Z_2$ invariant, while the\n$B_2(d_{\\pm})$ pairing results in a nodal TSC. Our analysis reveals that the\nfully gapped TSC is predominated by spin-singlet regardless of the presence of\nthe spin-triplet components. This distinguishes our model from\nnoncentrosymmetric materials with conventional Rashba-split band structures,\nwhere TSC typically emerges near the van Hove singularity and is primarily\ndriven by $p$-wave or $f$-wave spin-triplet pairing. These features enhances\nits experimental accessibility, and we discuss potential experimental systems\nfor its realization.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-14T16:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.10405v1","title":"Performance of Large Language Models in Supporting Medical Diagnosis and\n  Treatment","summary":"The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-14T16:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.10406v1","title":"A discrete model for surface configuration spaces","summary":"One of the primary methods of studying the topology of configurations of\npoints in a graph and configurations of disks in a planar region has been to\nexamine discrete combinatorial models arising from the underlying spaces.\nDespite the success of these models in the graph and disk settings, they have\nnot been constructed for the vast majority of surface configuration spaces. In\nthis paper, we construct such a model for the ordered configuration space of\n$m$ points in an oriented surface $\\Sigma$. More specifically, we prove that if\nwe give $\\Sigma$ a certain cube complex structure $K$, then the ordered\nconfiguration space of $m$ points in $\\Sigma$ is homotopy equivalent to a\nsubcomplex of $K^{m}$","main_category":"math.AT","categories":"math.AT,math.CO,math.GT","published":"2025-04-14T16:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10408v1","title":"Software package for simulations using the coarse-grained CALVADOS model","summary":"We present the CALVADOS package for performing simulations of biomolecules\nusing OpenMM and the coarse-grained CALVADOS model. The package makes it easy\nto run simulations using the family of CALVADOS models of biomolecules\nincluding disordered proteins, multi-domain proteins, proteins in crowded\nenvironments, and disordered RNA. We briefly describe the CALVADOS force fields\nand how they were parametrised. We then discuss the design paradigms and\narchitecture of the CALVADOS package, and give examples of how to use it for\nrunning and analysing simulations. The simulation package is freely available\nunder a GNU GPL license; therefore, it can easily be extended and we provide\nsome examples of how this might be done.","main_category":"q-bio.BM","categories":"q-bio.BM","published":"2025-04-14T16:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.10409v1","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for\n  Efficient Online Class-Incremental Learning","summary":"Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.10412v1","title":"AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance\n  Software Maintainability","summary":"This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SE","published":"2025-04-14T16:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.10413v1","title":"On perimeter minimizing sets in manifolds with quadratic volume growth","summary":"This paper studies whether the presence of a perimeter minimizing set in a\nRiemannian manifold $(M,g)$ forces an isometric splitting. We show that this is\nthe case when $M$ has non-negative sectional curvature and quadratic volume\ngrowth at infinity. Moreover, we obtain that the boundary of the perimeter\nminimizing set is identified with a slice in the product structure of $M$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T16:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10447v1","title":"Quantum geometry from the Moyal product: quantum kinetic equation and\n  non-linear response","summary":"We systematically derive the dissipationless quantum kinetic equation for a\nmulti-band free fermionic system with U(1) symmetry. Using the Moyal product\nformalism, we fully band-diagonalize the dynamics. Expanding to the second\norder in gradients, which is beyond the semiclassical limit, we give a complete\nanalysis of the band-resolved thermodynamics and transport properties,\nespecially those arising from the quantum geometric tensor. We apply our\nframework to a Bloch band theory under electric fields near equilibrium and\nfind the linear and nonlinear transport coefficients. We also obtain the\ndynamical density-density response functions in the metallic case, including\nquantum metric corrections. Our results and approach can be applied very\ngenerally to multi-band problems even in situations with spatially varying\nHamiltonians and distributions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-14T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.10450v1","title":"AC Current-Driven Magnetization Switching and Nonlinear Hall\n  Rectification in a Magnetic Topological Insulator","summary":"Spin-orbit torque arising from the spin-orbit-coupled surface states of\ntopological insulators enables current-induced control of magnetization with\nhigh efficiency. Here, alternating-current (AC) driven magnetization reversal\nis demonstrated in a semi-magnetic topological insulator\n(Cr,Bi,Sb)2Te3/(Bi,Sb)2Te3, facilitated by a low threshold current density of\n1.5x10^9 A/m^2. Time-domain Hall voltage measurements using an oscilloscope\nreveal a strongly nonlinear and nonreciprocal Hall response during the\nmagnetization reversal process. Fourier analysis of the time-varying Hall\nvoltage identifies higher-harmonic signals and a rectified direct-current (DC)\ncomponent, highlighting the complex interplay among the applied current,\nexternal magnetic field, and magnetization dynamics. Furthermore, a hysteretic\nbehavior in the current-voltage characteristics gives rise to frequency mixing\nunder dual-frequency excitation. This effect, distinct from conventional\npolynomial-based nonlinearities, allows for selective extraction of specific\nfrequency components. The results demonstrate that AC excitation can not only\nswitch magnetization efficiently but also induce tunable nonlinear responses,\noffering a new pathway for multifunctional spintronic devices with potential\napplications in energy-efficient memory, signal processing, and frequency\nconversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T17:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.10455v1","title":"The stellar decomposition of Gaussian quantum states","summary":"We introduce the stellar decomposition, a novel method for characterizing\nnon-Gaussian states produced by photon-counting measurements on Gaussian\nstates. Given an (m+n)-mode Gaussian state G, we express it as an (m+n)-mode\n\"Gaussian core state\" G_core followed by a fixed m-mode Gaussian transformation\nT that only acts on the first m modes. The defining property of the Gaussian\ncore state G_core is that measuring the last n of its modes in the\nphoton-number basis leaves the first m modes on a finite Fock support, i.e. a\ncore state. Since T is measurement-independent and G_core has an exact and\nfinite Fock representation, this decomposition exactly describes all\nnon-Gaussian states obtainable by projecting n modes of G onto the Fock basis.\nFor pure states we prove that a physical pair (G_core, T) always exists with\nG_core pure and T unitary. For mixed states, we establish necessary and\nsufficient conditions for (G_core, T) to be a Gaussian mixed state and a\nGaussian channel. Finally, we develop a semidefinite program to extract the\n\"largest\" possible Gaussian channel when these conditions fail. The stellar\ndecomposition leads to practical bounds on achievable state quality in photonic\ncircuits and for GKP state generation in particular. Our results are based on a\nnew characterization of Gaussian completely positive maps in the Bargmann\npicture, which may be of independent interest. As a result, this work provides\nnovel tools for improved simulations of quantum optical systems, and for\nunderstanding the generation of non-Gaussian resource states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.10456v1","title":"Privacy-Preserving Distributed Link Predictions Among Peers in Online\n  Classrooms Using Federated Learning","summary":"Social interactions among classroom peers, represented as social learning\nnetworks (SLNs), play a crucial role in enhancing learning outcomes. While SLN\nanalysis has recently garnered attention, most existing approaches rely on\ncentralized training, where data is aggregated and processed on a local/cloud\nserver with direct access to raw data. However, in real-world educational\nsettings, such direct access across multiple classrooms is often restricted due\nto privacy concerns. Furthermore, training models on isolated classroom data\nprevents the identification of common interaction patterns that exist across\nmultiple classrooms, thereby limiting model performance. To address these\nchallenges, we propose one of the first frameworks that integrates Federated\nLearning (FL), a distributed and collaborative machine learning (ML) paradigm,\nwith SLNs derived from students' interactions in multiple classrooms' online\nforums to predict future link formations (i.e., interactions) among students.\nBy leveraging FL, our approach enables collaborative model training across\nmultiple classrooms while preserving data privacy, as it eliminates the need\nfor raw data centralization. Recognizing that each classroom may exhibit unique\nstudent interaction dynamics, we further employ model personalization\ntechniques to adapt the FL model to individual classroom characteristics. Our\nresults demonstrate the effectiveness of our approach in capturing both shared\nand classroom-specific representations of student interactions in SLNs.\nAdditionally, we utilize explainable AI (XAI) techniques to interpret model\npredictions, identifying key factors that influence link formation across\ndifferent classrooms. These insights unveil the drivers of social learning\ninteractions within a privacy-preserving, collaborative, and distributed ML\nframework -- an aspect that has not been explored before.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T17:43:11Z"}
{"aid":"http://arxiv.org/abs/2504.10460v1","title":"Target Pebbling in Trees","summary":"Graph pebbling is a game played on graphs with pebbles on their vertices. A\npebbling move removes two pebbles from one vertex and places one pebble on an\nadjacent vertex. A configuration $C$ is a supply of pebbles at various vertices\nof a graph $G$, and a distribution $D$ is a demand of pebbles at various\nvertices of $G$. The $D$-pebbling number, $\\pi(G, D)$, of a graph $G$ is\ndefined to be the minimum number $m$ such that every configuration of $m$\npebbles can satisfy the demand $D$ via pebbling moves. The special case in\nwhich $t$ pebbles are demanded on vertex $v$ is denoted $D=v^t$, and the\n$t$-fold pebbling number, $\\pi_{t}(G)$, equals $\\max_{v\\in G}\\pi(G,v^t)$. It\nwas conjectured by Alc\\'on, Gutierrez, and Hurlbert that the pebbling numbers\nof chordal graphs forbidding the pyramid graph can be calculated in polynomial\ntime. Trees, of course, are the most prominent of such graphs. In 1989, Chung\ndetermined $\\pi_t(T)$ for all trees $T$. In this paper, we provide a\npolynomial-time algorithm to compute the pebbling numbers $\\pi(T,D)$ for all\ndistributions $D$ on any tree $T$, and characterize maximum-size configurations\nthat do not satisfy $D$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T17:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.10475v1","title":"Probing the Sivers Asymmetry with Transverse Energy-Energy Correlators\n  in the Small-$x$ Regime","summary":"We investigate transverse energy-energy correlators (TEECs) for both\npolarized and unpolarized targets in the small-$x$ regime at the Electron-Ion\nCollider (EIC). Focusing on the approximately back-to-back electroproduction of\na hadron-electron pair, we apply transverse-momentum-dependent (TMD)\nfactorization formulas that incorporate TMD evolution for both event-shape\nobservables and expand them in terms of the small-$x$ dipole amplitude. This\nallows us to write the TEEC off the transversely polarized proton in terms of a\nC-odd interaction, corresponding to an odderon exchange. Due to the\ncharge-conjugation-odd nature of the small-$x$ quark Sivers function, we\nrestrict the sum over final hadronic states to positively and negatively\ncharged hadrons separately. We present numerical predictions for the TEEC\nSivers asymmetry at the EIC and find the magnitude of the asymmetry to be on\nthe $0.1 \\%$ level. This channel offers a promising avenue for benchmarking the\nstill largely unconstrained odderon amplitude.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-14T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.10476v1","title":"Donor-Acceptor Pairs near Silicon Carbide surfaces","summary":"Donor-acceptor pairs (DAPs) in wide-bandgap semiconductors are promising\nplatforms for the realization of quantum technologies, due to their optically\ncontrollable, long-range dipolar interactions. Specifically, Al-N DAPs in bulk\nsilicon carbide (SiC) have been predicted to enable coherent coupling over\ndistances exceeding 10 nm. However, their practical implementations require an\nunderstanding of the properties of these pairs near surfaces and interfaces.\nHere, using first principles calculations we investigate how the presence of\nsurfaces influence the stability and optical properties of Al-N DAPs in SiC,\nand we show that they retain favorable optical properties comparable to their\nbulk counterparts, despite a slight increase in electron-phonon coupling.\nFurthermore, we introduce the concept of surface-defect pairs (SDPs), where an\nelectron-hole pair is generated between a near-surface defect and an occupied\nsurface state located in the bandgap of the material. We show that\nvanadium-based SDPs near OH-terminated 4H-SiC surfaces exhibit dipoles\nnaturally aligned perpendicular to the surface, greatly enhancing dipole-dipole\ncoupling between SDPs. Our results also reveal significant\npolarization-dependent modulation in the stimulated emission and\nphotoionization cross sections of V-based SDPs, which are tunable by two orders\nof magnitude via the polarization angle of the incident laser light. The\nnear-surface defects investigated here provide novel possibilities for the\ndevelopment of hybrid quantum-classical interfaces, as they can be used to\nmediate information transfer between quantum nodes and integrated photonic\ncircuits.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,quant-ph","published":"2025-04-14T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.10828v1","title":"Following Is All You Need: Robot Crowd Navigation Using People As\n  Planners","summary":"Navigating in crowded environments requires the robot to be equipped with\nhigh-level reasoning and planning techniques. Existing works focus on\ndeveloping complex and heavyweight planners while ignoring the role of human\nintelligence. Since humans are highly capable agents who are also widely\navailable in a crowd navigation setting, we propose an alternative scheme where\nthe robot utilises people as planners to benefit from their effective planning\ndecisions and social behaviours. Through a set of rule-based evaluations, we\nidentify suitable human leaders who exhibit the potential to guide the robot\ntowards its goal. Using a simple base planner, the robot follows the selected\nleader through shorthorizon subgoals that are designed to be straightforward to\nachieve. We demonstrate through both simulated and real-world experiments that\nour novel framework generates safe and efficient robot plans compared to\nexisting planners, even without predictive or data-driven modules. Our method\nalso brings human-like robot behaviours without explicitly defining traffic\nrules and social norms. Code will be available at\nhttps://github.com/centiLinda/PeopleAsPlanner.git.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.10833v1","title":"Towards Spatially-Aware and Optimally Faithful Concept-Based\n  Explanations","summary":"Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-15T03:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.10844v1","title":"Nonlinear Diffusion Equations on Graphs: Global Well-Posedness, Blow-Up\n  Analysis and Applications","summary":"For a nonlinear diffusion equation on graphs whose nonlinearity violates the\nLipschitz condition, we prove short-time solution existence and characterize\nglobal well-posedness by establishing sufficient criteria for blow-up phenomena\nand quantifying blow-up rates. These theoretical results are then applied to\nmodel complex dynamical networks, with supporting numerical experiments. This\nwork mainly makes two contributions: (i) generalization of existing results for\ndiffusion equations on graphs to cases with nontrivial potentials, producing\nricher analytical results; (ii) a new PDE approach to model complex dynamical\nnetworks, with preliminary numerical experiments confirming its validity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T04:06:12Z"}
{"aid":"http://arxiv.org/abs/2504.10849v1","title":"Real-Time Word-Level Temporal Segmentation in Streaming Speech\n  Recognition","summary":"Rich-text captions are essential to help communication for Deaf and\nhard-of-hearing (DHH) people, second-language learners, and those with autism\nspectrum disorder (ASD). They also preserve nuances when converting speech to\ntext, enhancing the realism of presentation scripts and conversation or speech\nlogs. However, current real-time captioning systems lack the capability to\nalter text attributes (ex. capitalization, sizes, and fonts) at the word level,\nhindering the accurate conveyance of speaker intent that is expressed in the\ntones or intonations of the speech. For example, ''YOU should do this'' tends\nto be considered as indicating ''You'' as the focus of the sentence, whereas\n''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a\nsolution that changes the text decorations at the word level in real time. As a\nprototype, we developed an application that adjusts word size based on the\nloudness of each spoken word. Feedback from users implies that this system\nhelped to convey the speaker's intent, offering a more engaging and accessible\ncaptioning experience.","main_category":"cs.HC","categories":"cs.HC,cs.MM,cs.SD,eess.AS","published":"2025-04-15T04:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.10853v1","title":"PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via\n  Semantic-aware Pivotal Tuning","summary":"Watermarking for diffusion images has drawn considerable attention due to the\nwidespread use of text-to-image diffusion models and the increasing need for\ntheir copyright protection. Recently, advanced watermarking techniques, such as\nTree Ring, integrate watermarks by embedding traceable patterns (e.g., Rings)\ninto the latent distribution during the diffusion process. Such methods disrupt\nthe original semantics of the generated images due to the inevitable\ndistribution shift caused by the watermarks, thereby limiting their\npracticality, particularly in digital art creation. In this work, we present\nSemantic-aware Pivotal Tuning Watermarks (PT-Mark), a novel invisible\nwatermarking method that preserves both the semantics of diffusion images and\nthe traceability of the watermark. PT-Mark preserves the original semantics of\nthe watermarked image by gradually aligning the generation trajectory with the\noriginal (pivotal) trajectory while maintaining the traceable watermarks during\nwhole diffusion denoising process. To achieve this, we first compute the\nsalient regions of the watermark at each diffusion denoising step as a spatial\nprior to identify areas that can be aligned without disrupting the watermark\npattern. Guided by the region, we then introduce an additional pivotal tuning\nbranch that optimizes the text embedding to align the semantics while\npreserving the watermarks. Extensive evaluations demonstrate that PT-Mark can\npreserve the original semantics of the diffusion images while integrating\nrobust watermarks. It achieves a 10% improvement in the performance of semantic\npreservation (i.e., SSIM, PSNR, and LPIPS) compared to state-of-the-art\nwatermarking methods, while also showing comparable robustness against\nreal-world perturbations and four times greater efficiency.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T04:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.10856v1","title":"On five-dimensional curvature squared supergravity and holography","summary":"In this work, we report the recent progress in obtaining new\ncurvature-squared invariants in 5D, N=1 gauged minimal supergravity. We exhibit\nthe structure of various composite multiplets that are pivotal in the\nconstruction. We also present the form of the gauged Riemann-squared and\nGauss-Bonnet superinvariants in a dilaton-Weyl multiplet. As a first\napplication of the new curvature squared invariants, we compute their\ncorrections to holographic central charges and the Euclidean action of\nsupersymmetric charged rotating black holes, exhibiting exact matching between\nthe gravity and CFT results.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T04:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.10857v1","title":"ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping","summary":"Robotic grasping is a cornerstone capability of embodied systems. Many\nmethods directly output grasps from partial information without modeling the\ngeometry of the scene, leading to suboptimal motion and even collisions. To\naddress these issues, we introduce ZeroGrasp, a novel framework that\nsimultaneously performs 3D reconstruction and grasp pose prediction in near\nreal-time. A key insight of our method is that occlusion reasoning and modeling\nthe spatial relationships between objects is beneficial for both accurate\nreconstruction and grasping. We couple our method with a novel large-scale\nsynthetic dataset, which comprises 1M photo-realistic images, high-resolution\n3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K\nobjects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the\nGraspNet-1B benchmark as well as through real-world robot experiments.\nZeroGrasp achieves state-of-the-art performance and generalizes to novel\nreal-world objects by leveraging synthetic data.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T04:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.10888v1","title":"CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal\n  Visible-Infrared Detectors","summary":"Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.10890v1","title":"Gravitational Entropy of Hayward Black Hole","summary":"We analyze the gravitational entropy defined by the Weyl curvature for the\nHayward black hole, which is one of the regular black holes without singularity\nin the event horizon. Using the definition by the ratio of the Weyl curvature\nscalar and the Kretschmann scalar as the entropy measure, we evaluate the\ngravitational entropy on the outer and inner horizons. We derive an expression\nfor the curvature tensor of the Hayward black hole that is as independent as\npossible of the parameter added to the black hole and give an equation for the\nentropy measure explicitly independent of that parameter. The gravitational\nentropy density used in previous studies presents questions from the standpoint\nof mathematical rigor while we discuss possible improvements in its definition.\nWe compare the results for the Hayward black hole with the analysis for the\nReisner-Nordst\\\"{o}m black hole and discuss the effect of singularity\nresolution on gravitational entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T05:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.10893v1","title":"ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search","summary":"Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T06:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.10907v1","title":"Evidence for GeV Gamma-Ray Emission from Intense GRB 240529A During the\n  Afterglow's Shallow Decay Phase","summary":"X-ray light curves of gamma-ray burst (GRB) afterglows exhibit various\nfeatures, with the shallow decay phase being particularly puzzling. While some\nstudies report absence of the X-ray shallow decay for hyper-energetic GRBs,\nrecently discovered GRB 240529A shows a clear shallow decay phase with an\nisotropic gamma-ray energy of \\SI{2.2e54}{erg}, making it a highly unusual case\ncompared to typical GRBs. In order to investigate the physical mechanism of the\nshallow decay, we perform the \\textit{Fermi}-LAT analysis of GRB 240529A along\nwith \\textit{Swift}-XRT analysis. We find no jet break feature in the X-ray\nlight curve and then give the lower bound of the collimation-corrected jet\nenergy of $>10^{52}$~erg, which is close to the maximum rotational energy of a\nmagnetar. Our LAT data analysis reveals evidence of GeV emission with a\nstatistical significance of $4.5\\sigma$ during the shallow decay phase, which\ncan be interpreted as the first case for hyper-energetic GRBs with a typical\nshallow decay phase. The GeV to keV flux ratio is calculated to be $4.2\\pm2.3$.\nTogether with X-ray spectral index, this indicates an inverse Compton origin of\nthe GeV emission. Multiwavelength modeling based on time-dependent simulations\ntested two promising models, the energy injection and wind models. Both models\ncan explain the X-ray and gamma-ray data, while our modeling demonstrates that\ngamma-ray observations, along with future GeV--TeV observations by CTAO, will\ndistinguish between them.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T06:39:53Z"}
{"aid":"http://arxiv.org/abs/2504.10920v1","title":"Towards Efficient Partially Relevant Video Retrieval with Active Moment\n  Discovering","summary":"Partially relevant video retrieval (PRVR) is a practical yet challenging task\nin text-to-video retrieval, where videos are untrimmed and contain much\nbackground content. The pursuit here is of both effective and efficient\nsolutions to capture the partial correspondence between text queries and\nuntrimmed videos. Existing PRVR methods, which typically focus on modeling\nmulti-scale clip representations, however, suffer from content independence and\ninformation redundancy, impairing retrieval performance. To overcome these\nlimitations, we propose a simple yet effective approach with active moment\ndiscovering (AMDNet). We are committed to discovering video moments that are\nsemantically consistent with their queries. By using learnable span anchors to\ncapture distinct moments and applying masked multi-moment attention to\nemphasize salient moments while suppressing redundant backgrounds, we achieve\nmore compact and informative video representations. To further enhance moment\nmodeling, we introduce a moment diversity loss to encourage different moments\nof distinct regions and a moment relevance loss to promote semantically\nquery-relevant moments, which cooperate with a partially relevant retrieval\nloss for end-to-end optimization. Extensive experiments on two large-scale\nvideo datasets (\\ie, TVR and ActivityNet Captions) demonstrate the superiority\nand efficiency of our AMDNet. In particular, AMDNet is about 15.5 times smaller\n(\\#parameters) while 6.0 points higher (SumR) than the up-to-date method\nGMMFormer on TVR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.10927v1","title":"Translating between NIP integral domains and topological fields","summary":"We prove that definable ring topologies on NIP fields are closely connected\nto NIP integral domains. More precisely, we show that up to elementary\nequivalence, any NIP topological field arises from an NIP integral domain. As\nan application, we prove several results about definable ring topologies on NIP\nfields, including the following. Let $K$ be an NIP field or expansion of a\nfield. Let $\\tau$ be a definable ring topology on $K$. Then $\\tau$ is a field\ntopology, and $\\tau$ is locally bounded. If $K$ has characteristic $p$ or\nfinite dp-rank, then $\\tau$ is \"generalized t-henselian\" in the sense of\nDittman, Walsberg, and Ye, meaning that the implicit function theorem holds for\npolynomials. If $K$ has finite dp-rank, then $\\tau$ must be a topology of\n\"finite breadth\" (a $W_n$-topology). Using these techniques, we give some\nreformulations of the conjecture that NIP local rings are henselian.","main_category":"math.LO","categories":"math.LO","published":"2025-04-15T07:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10958v1","title":"Recognition of Geometrical Shapes by Dictionary Learning","summary":"Dictionary learning is a versatile method to produce an overcomplete set of\nvectors, called atoms, to represent a given input with only a few atoms. In the\nliterature, it has been used primarily for tasks that explore its powerful\nrepresentation capabilities, such as for image reconstruction. In this work, we\npresent a first approach to make dictionary learning work for shape\nrecognition, considering specifically geometrical shapes. As we demonstrate,\nthe choice of the underlying optimization method has a significant impact on\nrecognition quality. Experimental results confirm that dictionary learning may\nbe an interesting method for shape recognition tasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T08:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.10965v1","title":"Investigating the light curve variation of magnetic white dwarfs induced\n  by the axion-photon conversion","summary":"Axion-photon oscillation refers to the process of mutual conversion between\nphotons and axions when they propagate in a magnetic field. This process\ndepends on the strength of the background magnetic field, and magnetic white\ndwarfs provide a natural laboratory for testing this process. In this work, we\nstudy the behavior of axion-photon oscillation near magnetic white dwarfs: as\nthe magnetic white dwarf rotates, its magnetic field structure rotates\naccordingly, causing a periodic change of the magnetic field along the path of\nphotons. These variations affect the axion-photon oscillation process\nexperienced by the photons emitted from the white dwarf, thereby inducing a\nperiodic modulation in the intensity and polarization of the white dwarf's\nthermal emission that we observe. Our study focuses on the impact of axion\neffects on the observed light curve variation and conducts a detailed\ninvestigation through numerical calculations. Using the light curve data of the\nwhite dwarf PG1015+014 obtained from the observations by the Jacobus Kapteyn\nTelescope, which has a photometric precision of $\\sim1\\%$, we derive the\nconstraints on axion parameters. In the axion mass range of\n$\\lesssim10^{-8}\\,{\\rm eV}$, the 95\\% credible interval upper limit of the\naxion-photon coupling $g_{a\\gamma\\gamma}$ is constrained to $<8.1 \\times\n10^{-12} \\mathrm{GeV^{-1}}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE","published":"2025-04-15T08:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.10975v1","title":"Simplicial volume of open books in dimension 4","summary":"In this short note we adapt a proof by Bucher and Neofytidis to prove that\nthe simplicial volume of 4-manifolds admitting an open book decomposition\nvanishes. In particular this shows that Quinns signature invariant, which\ndetects the existence of an open book decomposition in dimensions above 4, is\ninsufficient to characterize open books in dimension 4, even if one allows\narbitrary stabilizations via connected sums.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-15T08:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.10983v1","title":"ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed\n  Protein Language Model Embeddings","summary":"The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.BM","published":"2025-04-15T08:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.10986v1","title":"PraNet-V2: Dual-Supervised Reverse Attention for Medical Image\n  Segmentation","summary":"Accurate medical image segmentation is essential for effective diagnosis and\ntreatment. Previously, PraNet-V1 was proposed to enhance polyp segmentation by\nintroducing a reverse attention (RA) module that utilizes background\ninformation. However, PraNet-V1 struggles with multi-class segmentation tasks.\nTo address this limitation, we propose PraNet-V2, which, compared to PraNet-V1,\neffectively performs a broader range of tasks including multi-class\nsegmentation. At the core of PraNet-V2 is the Dual-Supervised Reverse Attention\n(DSRA) module, which incorporates explicit background supervision, independent\nbackground modeling, and semantically enriched attention fusion. Our PraNet-V2\nframework demonstrates strong performance on four polyp segmentation datasets.\nAdditionally, by integrating DSRA to iteratively enhance foreground\nsegmentation results in three state-of-the-art semantic segmentation models, we\nachieve up to a 1.36% improvement in mean Dice score. Code is available at:\nhttps://github.com/ai4colonoscopy/PraNet-V2/tree/main/binary_seg/jittor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:49:29Z"}
{"aid":"http://arxiv.org/abs/2504.11014v1","title":"GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*","summary":"The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.11027v1","title":"From Heteropolymer Stiffness Distributions to Effective Homopolymers: A\n  Conformational Analysis of Intrinsically Disordered Proteins","summary":"Intrinsically disordered proteins (IDPs) are characterized by a lack of\ndefined secondary and tertiary structures, and are thus well-suited for\ndescriptions within polymer theory. However, the intrinsic heterogeneity of\nproteins, stemming from their diverse amino acid building blocks, introduces\nlocal variations in chain stiffness, which can impact conformational behavior\nat larger scales. To investigate this effect, we developed a heterogeneous\nworm-like chain model in which the local persistence length follows a Gaussian\ndistribution. We demonstrate that these heterogeneous chains can be effectively\nmapped to homogeneous chains with a single effective persistence length. To\nassess whether this mapping can be extended to naturally occurring IDPs, we\nperformed simulations using various coarse-grained IDP models, finding that the\nsimulated IDPs have similar shapes like the corresponding homogeneous and\nheterogeneous worm-like chains. However, the IDPs are systematically larger\nthan ideal worm-like chains, yet slightly more compact when excluded volume\ninteractions are considered. We attribute these differences to intramolecular\ninteractions between non-bonded monomers, which our theoretical models do not\naccount for.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-15T09:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.11038v1","title":"QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models","summary":"In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T10:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.11043v1","title":"Riemannian optimization for model order reduction of linear systems with\n  quadratic outputs","summary":"This paper investigates the optimal $H_2$ model order reduction for linear\nsystems with quadratic outputs. In the framework of Galerkin projection, we\nfirst formulate the optimal $H_2$ MOR as an unconstrained Riemannian\noptimization problem on the Stiefel manifold. The Riemannian gradient of the\nspecific cost function is derived with the aid of Gramians of systems, and the\nDai-Yuan-type Riemannian conjugate gradient method is adopted to generate\nstructure-preserving reduced models. We also consider the optimal $H_2$ MOR\nbased on the product manifold, where some coefficient matrices of reduced\nmodels are determined directly via the iteration of optimization problem,\ninstead of the Galerkin projection method. In addition, we provide a scheme to\ncompute low-rank approximate solutions of Sylvester equations based on the\ntruncated polynomial expansions, which fully exploits the specific structure of\nSylvester equations in the optimization problems, and enables an efficient\nexecution of our approach. Finally, two numerical examples are simulated to\ndemonstrate the efficiency of our methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T10:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.11059v1","title":"Quantifying Group Fairness in Community Detection","summary":"Understanding community structures is crucial for analyzing networks, as\nnodes join communities that collectively shape large-scale networks. In\nreal-world settings, the formation of communities is often impacted by several\nsocial factors, such as ethnicity, gender, wealth, or other attributes. These\nfactors may introduce structural inequalities; for instance, real-world\nnetworks can have a few majority groups and many minority groups. Community\ndetection algorithms, which identify communities based on network topology, may\ngenerate unfair outcomes if they fail to account for existing structural\ninequalities, particularly affecting underrepresented groups. In this work, we\npropose a set of novel group fairness metrics to assess the fairness of\ncommunity detection methods. Additionally, we conduct a comparative evaluation\nof the most common community detection methods, analyzing the trade-off between\nperformance and fairness. Experiments are performed on synthetic networks\ngenerated using LFR, ABCD, and HICH-BA benchmark models, as well as on\nreal-world networks. Our results demonstrate that the fairness-performance\ntrade-off varies widely across methods, with no single class of approaches\nconsistently excelling in both aspects. We observe that Infomap and\nSignificance methods are high-performing and fair with respect to different\ntypes of communities across most networks. The proposed metrics and findings\nprovide valuable insights for designing fair and effective community detection\nalgorithms.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-15T10:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.11071v1","title":"Avoshifts, Unishifts and Nondeterministic Cellular Automata","summary":"In this paper, we study avoshifts and unishifts on $\\mathbb{Z}^d$. Avoshifts\nare subshifts where for each convex set $C$, and each vector $v$ such that $C\n\\cup \\{\\vec v\\}$ is also convex, the set of valid extensions of globally valid\npatterns on $C$ to ones on $C \\cup \\{v\\}$ is determined by a bounded subpattern\nof $C$. Unishifts are the subshifts where for such $C, \\vec v$, every\n$C$-pattern has the same number of $\\vec v$-extensions. Cellwise quasigroup\nshifts (including group shifts) and TEP subshifts are examples of unishifts,\nwhile unishifts and subshifts with topological strong spatial mixing are\nexamples of avoshifts. We prove that every avoshift is the spacetime subshift\nof a nondeterministic cellular automaton on an avoshift of lower dimension up\nto a linear transformation and a convex blocking. From this, we deduce that all\navoshifts contain periodic points, and that unishifts have dense periodic\npoints and admit equal entropy full shift factors.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-15T11:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.11076v1","title":"Using Time Structure to Estimate Causal Effects","summary":"There exist several approaches for estimating causal effects in time series\nwhen latent confounding is present. Many of these approaches rely on additional\nauxiliary observed variables or time series such as instruments, negative\ncontrols or time series that satisfy the front- or backdoor criterion in\ncertain graphs. In this paper, we present a novel approach for estimating\ndirect (and via Wright's path rule total) causal effects in a time series setup\nwhich does not rely on additional auxiliary observed variables or time series.\nThis approach assumes that the underlying time series is a Structural Vector\nAutoregressive (SVAR) process and estimates direct causal effects by solving\ncertain linear equation systems made up of different covariances and model\nparameters. We state sufficient graphical criteria in terms of the so-called\nfull time graph under which these linear equations systems are uniquely\nsolvable and under which their solutions contain the to-be-identified direct\ncausal effects as components. We also state sufficient lag-based criteria under\nwhich the previously mentioned graphical conditions are satisfied and, thus,\nunder which direct causal effects are identifiable. Several numerical\nexperiments underline the correctness and applicability of our results.","main_category":"stat.ME","categories":"stat.ME,cs.LG,G.3","published":"2025-04-15T11:21:37Z"}
{"aid":"http://arxiv.org/abs/2504.11094v1","title":"Evaluation Report on MCP Servers","summary":"With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.","main_category":"cs.IR","categories":"cs.IR,cs.DB","published":"2025-04-15T11:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11134v1","title":"Visual Re-Ranking with Non-Visual Side Information","summary":"The standard approach for visual place recognition is to use global image\ndescriptors to retrieve the most similar database images for a given query\nimage. The results can then be further improved with re-ranking methods that\nre-order the top scoring images. However, existing methods focus on re-ranking\nbased on the same image descriptors that were used for the initial retrieval,\nwhich we argue provides limited additional signal.\n  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),\nwhich is a graph neural network-based re-ranking method that, in addition to\nthe visual descriptors, can leverage other types of available side information.\nThis can for example be other sensor data (such as signal strength of nearby\nWiFi or BlueTooth endpoints) or geometric properties such as camera poses for\ndatabase images. In many applications this information is already present or\ncan be acquired with low effort. Our architecture leverages the concept of\naffinity vectors to allow for a shared encoding of the heterogeneous\nmulti-modal input. Two large-scale datasets, covering both outdoor and indoor\nlocalization scenarios, are utilized for training and evaluation. In\nexperiments we show significant improvement not only on image retrieval\nmetrics, but also for the downstream visual localization task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:37:16Z"}
{"aid":"http://arxiv.org/abs/2504.11142v1","title":"On the dimension of the boundaries of attracting basins of entire maps","summary":"We study the dimension of the boundaries of periodic Fatou components of\ntranscendental entire maps. We prove that if $U$ is an immediate component of\nthe basin of an attracting periodic point $\\zeta$ of period $p\\ge 1$ of a\ntranscendental entire function $f\\colon \\mathbb C \\to \\mathbb C$ from the\nEremenko--Lyubich class $\\mathcal B$, such that $\\text{deg} f^p|_U = \\infty$\nand $\\overline{\\text{Sing}(f^p|_U)}$ is a compact subset of $U$, then the\nhyperbolic (and, consequently, Hausdorff) dimension of the boundary of $U$ is\nlarger than $1$. The same holds if $U$ is an immediate component of the basin\nof a parabolic $p$-periodic point $\\zeta$, under an additional assumption\n$\\zeta \\notin \\overline{\\text{Sing}(f^p)}$. We also show that if $U$ is a\nbounded immediate component of an attracting basin of a transcendental entire\nfunction $f$, then the hyperbolic dimension of the boundary of $U$ is larger\nthan $1$. In particular, this implies that the boundary of a component of an\nattracting basin of a transcendental entire function is never a smooth or\nrectifiable curve.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.11149v1","title":"An Application of Membrane Computing to Humanitarian Relief via\n  Generalized Nash Equilibrium","summary":"Natural and political disasters, including earthquakes, hurricanes, and\ntsunamis, but also migration and refugees crisis, need quick and coordinated\nresponses in order to support vulnerable populations. In such disasters,\nnongovernmental organizations compete with each other for financial donations,\nwhile people who need assistance suffer a lack of coordination, congestion in\nterms of logistics, and duplication of services. From a theoretical point of\nview, this problem can be formalized as a Generalized Nash Equilibrium (GNE)\nproblem. This is a generalization of the Nash equilibrium problem, where the\nagents' strategies are not fixed but depend on the other agents' strategies. In\nthis paper, we show that Membrane Computing can model humanitarian relief as a\nGNE problem. We propose a family of P systems that compute GNE in this context,\nand we illustrate their capabilities with Hurricane Katrina in 2005 as a case\nstudy.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.11164v1","title":"TSAL: Few-shot Text Segmentation Based on Attribute Learning","summary":"Recently supervised learning rapidly develops in scene text segmentation.\nHowever, the lack of high-quality datasets and the high cost of pixel\nannotation greatly limit the development of them. Considering the\nwell-performed few-shot learning methods for downstream tasks, we investigate\nthe application of the few-shot learning method to scene text segmentation. We\npropose TSAL, which leverages CLIP's prior knowledge to learn text attributes\nfor segmentation. To fully utilize the semantic and texture information in the\nimage, a visual-guided branch is proposed to separately extract text and\nbackground features. To reduce data dependency and improve text detection\naccuracy, the adaptive prompt-guided branch employs effective adaptive prompt\ntemplates to capture various text attributes. To enable adaptive prompts\ncapture distinctive text features and complex background distribution, we\npropose Adaptive Feature Alignment module(AFA). By aligning learnable tokens of\ndifferent attributes with visual features and prompt prototypes, AFA enables\nadaptive prompts to capture both general and distinctive attribute information.\nTSAL can capture the unique attributes of text and achieve precise segmentation\nusing only few images. Experiments demonstrate that our method achieves SOTA\nperformance on multiple text segmentation datasets under few-shot settings and\nshow great potential in text-related domains.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.11177v1","title":"Pressure-Tunable Generalized Wigner Crystal and Fractional Chern\n  Insulator in twisted MoTe$_2$","summary":"Due to the forming of low-energy flat bands, the moir\\'e superlattices of the\ntransition metal dichalcogenides are fascinating platforms for studying novel\ncorrelated states when such flat bands are fractionally filled, with the\nCoulomb interaction dominating. Here, we demonstrate that pressure can\nefficiently tune the flatness and quantum geometry of the single-particle bands\nin twisted bilayer MoTe$_2$ ($\\textit{t}$MoTe$_2$). By fractionally filling the\ntopmost valence band, we find that pressure can act as a flexible means to\nmodulate the fractional Chern insulator (FCI) and the generalized Wigner\ncrystal (GWC) and control their many-body topological phase transitions.\nMoreover, our results indicate a remarkable correspondence between the\nsingle-particle band geometry and the formation of FCI and GWC. As the recent\nexperiments report the presence of FCI phases in $\\textit{t}$MoTe$_2$, our\npredictions could be readily implemented experimentally.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T13:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.11190v1","title":"Enhancing multimodal analogical reasoning with Logic Augmented\n  Generation","summary":"Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T13:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.11192v1","title":"Field-effect detected magnetic resonance of NV centers in diamond based\n  on all-carbon Schottky contacts","summary":"The nitrogen vacancy (NV) center is a defect in diamond whose spin state can\nbe read optically by exploiting its photoluminescence or electrically by\nexploiting its charge generation rate under illumination, both of which being\nspin-dependent. The latter method offers numerous opportunities in terms of\nintegration and performance compared to conventional optical reading. Here, we\ninvestigate the physical properties of a graphitic-diamond-graphitic structure\nunder illumination. We show how, for a type IIa diamond material, electron-hole\npairs generated by an ensemble of NV centers lead to a p-type material upon\nillumination, making this all-carbon structure equivalent to two back-to-back\nSchottky diodes. We analyze how the reverse current flowing upon illumination\nchanges as a function of bias voltage and radiofrequency-induced excitation of\nthe NV ensemble spin resonances. Furthermore, we demonstrate how an additional\nfield effect arising from the illumination scheme affects the reverse current,\nresulting in a photoelectrical signal that can exceed the optical signal under\nthe same illumination conditions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.11198v1","title":"Semi-asymptotic bounds for moderate deviations of suprema of Gaussian\n  polynomials","summary":"We use decoupling inequalities for general Gaussian vectors and classical\ntools from Gaussian processes theory to study moderate deviations of suprema of\n  trigonometric and almost periodic\n  Gaussian polynomials.\n  Let \\begin{eqnarray*} X_x(t) &=& \\sum_{k\\le x} a_k \\,\\big( g_k \\cos 2\\pi k\n\\,t+ g'_k\\sin 2\\pi k \\, t\\, \\big), \\quad 0\\le t\\le 1, \\ x>0, \\end{eqnarray*}\nwhere $(g_k)_{k\\ge 1}$, $(g'_k)_{k\\ge 1}$ are two independent sequences of\ni.i.d. $\\mathcal N(0,1)$ distributed random variables, and $(a_k)_{k\\ge 1}$ are\nreal numbers such that $A_x = \\sum_{k\\le x} a_k^2\\uparrow \\infty$ with $x$.\n  Assume for instance that $A(x)\\sim \\log\\log x$, $x\\to \\infty$ and\n$B=\\sum_{k\\ge 1} a_k^4<\\infty$. Let $0<\\eta< 1$. We prove that\n  there exists an absolute constant $C$, such that for all $x$ large enough,\n\\begin{align*}\n  \\P\\Big\\{ \\sup_{0\\le t\\le 1}\n  X_x(t) \\le\\sqrt{2\\eta (\\log\\log x)(\\log \\log\\log x)}\\Big\\}\n  \\ \\le \\ e^{-\\,\\frac{C (\\log\\log x)^{1-\\eta}}{ \\sqrt{8\\eta (B+1)(\\log \\log\\log\nx)}}}.\n  \\end{align*}\n  We also establish an approximation theorem of moderate deviations of almost\nperiodic Gaussian polynomials by Gaussian polynomials with $\\Q$-frequencies,\nand show that the error term has an exponential decay.\n  We finally study for general non-vanishing coefficient sequences, the\nbehavior along lattices of almost periodic Gaussian polynomials with linearly\nindependent frequencies.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T13:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.11204v1","title":"BenchQC -- Scalable and modular benchmarking of industrial quantum\n  computing applications","summary":"We present BenchQC, a research project funded by the state of Bavaria, which\npromotes an application-centric perspective for benchmarking real-world quantum\napplications. Diverse use cases from industry consortium members are the\nstarting point of a benchmarking workflow, that builds on the open-source\nplatform QUARK, encompassing the full quantum software stack from the hardware\nprovider interface to the application layer. By identifying and evaluating key\nmetrics across the entire pipeline, we aim to uncover meaningful trends,\nprovide systematic guidance on quantum utility, and distinguish promising\nresearch directions from less viable approaches. Ultimately, this initiative\ncontributes to the broader effort of establishing reliable benchmarking\nstandards that drive the transition from experimental demonstrations to\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11207v1","title":"On deformations of AdS$_3$ solutions, supersymmetry and $G$-structures","summary":"We construct new families of supersymmetric AdS$_3$ solutions in both massive\nand massless Type IIA supergravity via deformations to known backgrounds\npreserving $\\mathcal{N} = (4,0)$ and $\\mathcal{N} = (6,0)$ supersymmetry. These\ndeformations are performed along internal isometries and lead to backgrounds\nwith fully preserved or reduced supersymmetry. Using the formalism of\n$G$-structures, we systematically characterise the resulting geometries and\ntrack the evolution of their supersymmetric properties under the deformation.\nIn particular, we identify transitions among SU(3), SU(2), and identity\nstructures, and demonstrate the preservation of Killing spinors through\nexplicit spinor bilinear constructions. Additionally, we investigate D-brane\nembeddings in the deformed geometries, uncovering stable and supersymmetric\nconfigurations supported by the new backgrounds. Our results offer new insights\ninto the classification of AdS$_3$ flux vacua and provide a concrete framework\nfor understanding their potential holographic duals.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T14:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.11219v1","title":"$P$-wave single charmed baryons of the $SU(3)$ flavor $\\bf\\bar3_F$","summary":"We study the $P$-wave single charmed baryons of the $SU(3)$ flavor\n$\\bf\\bar3_F$ within the framework of heavy quark effective theory. We\nsystematically calculate their strong and radiative decay properties using the\nlight-cone sum rule method. Besides the $\\Lambda_c(2595)$, $\\Lambda_c(2625)$,\n$\\Xi_c(2790)$, and $\\Xi_c(2815)$, our results suggest the existence of two\nadditional $\\Lambda_c$ baryons and two additional $\\Xi_c$ baryons. Their\nmasses, mass splittings within the same multiplets, and decay properties are\nsummarized in Table V for future experimental searches.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T14:22:57Z"}
{"aid":"http://arxiv.org/abs/2504.11220v1","title":"Test of lepton flavor universality with measurements of $R(D^{+})$ and\n  $R(D^{*+})$ using semileptonic $B$ tagging at the Belle II experiment","summary":"We report measurements of the ratios of branching fractions\n$\\mathcal{R}(D^{(*)+}) = \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\,\\tau^- \\,\n\\overline{\\nu}_\\tau) / \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\, \\ell^- \\,\n\\overline{\\nu}_\\ell)$, where $\\ell$ denotes either an electron or a muon. These\nratios test the universality of the charged-current weak interaction. The\nresults are based on a $365\\, \\mathrm{fb}^{-1}$ data sample collected with the\nBelle II detector at the SuperKEKB $e^+e^-$ collider, which operates at a\ncenter-of-mass energy corresponding to the $\\Upsilon(4S)$ resonance, just above\nthe threshold for $B\\overline{B}{}$ production. Signal candidates are\nreconstructed by selecting events in which the companion $B$ meson from the\n$\\Upsilon(4S) \\to B\\overline{B}{}$ decay is identified in semileptonic modes.\nThe $\\tau$ lepton is reconstructed via its leptonic decays. We obtain\n$\\mathcal{R}(D^+) = 0.418 \\pm 0.074 ~({\\mathrm{stat}}) \\pm 0.051\n~({\\mathrm{syst}})$ and $\\mathcal{R}(D^{*+}) = 0.306 \\pm 0.034\n~({\\mathrm{stat}}) \\pm 0.018 ~({\\mathrm{syst}})$, which are consistent with\nworld average values. Accounting for the correlation between them, these values\ndiffer from the Standard Model expectation by a collective significance of\n$1.7$ standard deviations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T14:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11241v1","title":"Physics-Aware Initialization Refinement in Code-Aided EM for Blind\n  Channel Estimation","summary":"This paper addresses the well-known local maximum problem of the\nexpectation-maximization (EM) algorithm in blind intersymbol interference (ISI)\nchannel estimation. This problem primarily results from phase and shift\nambiguity during initialization, which blind estimation is inherently unable to\ndistinguish. We propose an effective initialization refinement algorithm that\nutilizes the decoder output as a model selection metric, incorporating a\ntechnique to detect phase and shift ambiguity. Our results show that the\nproposed algorithm significantly reduces the number of local maximum cases to\nnearly one-third for a 3-tap ISI channel under highly uncertain initial\nconditions. The improvement becomes more pronounced as initial errors increase\nand the channel memory grows. When used in a turbo equalizer, the proposed\nalgorithm is required only in the first turbo iteration, which limits any\ncomplexity increase with subsequent iterations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.11247v1","title":"Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks","summary":"Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art\nalgorithm for achieving sample-efficient multi-goal reinforcement learning (RL)\nin robotic manipulation tasks with binary rewards. HER facilitates learning\nfrom failed attempts by replaying trajectories with redefined goals. However,\nit relies on a heuristic-based replay method that lacks a principled framework.\nTo address this limitation, we introduce a novel replay strategy,\n\"Next-Future\", which focuses on rewarding single-step transitions. This\napproach significantly enhances sample efficiency and accuracy in learning\nmulti-goal Markov decision processes (MDPs), particularly under stringent\naccuracy requirements -- a critical aspect for performing complex and precise\nrobotic-arm tasks. We demonstrate the efficacy of our method by highlighting\nhow single-step learning enables improved value approximation within the\nmulti-goal RL framework. The performance of the proposed replay strategy is\nevaluated across eight challenging robotic manipulation tasks, using ten random\nseeds for training. Our results indicate substantial improvements in sample\nefficiency for seven out of eight tasks and higher success rates in six tasks.\nFurthermore, real-world experiments validate the practical feasibility of the\nlearned policies, demonstrating the potential of \"Next-Future\" in solving\ncomplex robotic-arm tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-04-15T14:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.11267v1","title":"Optimal control of geometric phase in pairs of interacting atoms\n  traveling along two-dimensional closed paths","summary":"Universal quantum gates whose operation depends on the manipulation of the\ngeometric phase of atomic systems are promising candidates for implementation\nof quantum computing. We propose a scheme inducing a non-trivial\nAharonov-Anandan geometric phase in pairs of atoms interacting via\ndipole-dipole potential. Our protocol relies on mobile optical trap technology\nand consists of steering a single atom along a closed loop. The trajectory of\nthe atom is controlled by a mobile optical trap, and the shape of the path is\ndesigned by applying an optimal control procedure. The geometric phase is\ngenerated as a residual of the two-atom entanglement induced by the\ndipole-dipole interaction. The stability of our scheme in the presence of noise\nor experimental imperfections is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:06:40Z"}
{"aid":"http://arxiv.org/abs/2504.11268v1","title":"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\n  for Dense Multi-Task Learning","summary":"Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.11286v1","title":"Efficient Medical Image Restoration via Reliability Guided Learning in\n  Frequency Domain","summary":"Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11288v1","title":"Large-time asymptotics of periodic two-dimensional Vlasov-Navier-Stokes\n  flows","summary":"We study the large-time behavior of finite-energy weak solutions for the\nVlasov-Navier-Stokes equations in a two-dimensional torus. We focus first on\nthe homogeneous case where the ambient (incompressible and viscous) fluid\ncarrying the particles has a constant density, and then on the variable-density\ncase. In both cases, large-time convergence to a monokinetic final state is\ndemonstrated. For any finite energy initial data, we exhibit an algebraic\nconvergence rate that deteriorates as the initial particle distribution\nincreases. When the initial particle distribution is suitably small, then the\nconvergence rate becomes exponential, a result consistent with the work of\nHan-Kwan et al. [17] dedicated to the homogeneous, three-dimensional case,\nwhere an additional smallness condition on the velocity was required. In the\nnon-homogeneous case, we establish similar stability results, allowing a\npiecewise constant fluid density with jumps.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T15:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11291v1","title":"Policy heterogeneity improves collective olfactory search in 3-D\n  turbulence","summary":"We investigate the role of policy heterogeneity in enhancing the olfactory\nsearch capabilities of cooperative agent swarms operating in complex,\nreal-world turbulent environments. Using odor fields from direct numerical\nsimulations of the Navier-Stokes equations, we demonstrate that heterogeneous\ngroups, with exploratory and exploitative agents, consistently outperform\nhomogeneous swarms where the exploration-exploitation tradeoff is managed at\nthe individual level. Our results reveal that policy diversity enables the\ngroup to reach the odor source more efficiently by mitigating the detrimental\neffects of spatial correlations in the signal. These findings provide new\ninsights into collective search behavior in biological systems and offer\npromising strategies for the design of robust, bioinspired search algorithms in\nengineered systems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,physics.data-an","published":"2025-04-15T15:31:11Z"}
{"aid":"http://arxiv.org/abs/2504.11304v1","title":"Differentially Private Geodesic and Linear Regression","summary":"In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-15T15:45:48Z"}
{"aid":"http://arxiv.org/abs/2504.11336v1","title":"Looking beyond the next token","summary":"The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.11341v1","title":"Evaluating DAO Sustainability and Longevity Through On-Chain Governance\n  Metrics","summary":"Decentralised Autonomous Organisations (DAOs) automate governance and\nresource allocation through smart contracts, aiming to shift decision-making to\ndistributed token holders. However, many DAOs face sustainability challenges\nlinked to limited user participation, concentrated voting power, and technical\ndesign constraints. This paper addresses these issues by identifying research\ngaps in DAO evaluation and introducing a framework of Key Performance\nIndicators (KPIs) that capture governance efficiency, financial robustness,\ndecentralisation, and community engagement. We apply the framework to a\ncustom-built dataset of real-world DAOs constructed from on-chain data and\nanalysed using non-parametric methods. The results reveal recurring governance\npatterns, including low participation rates and high proposer concentration,\nwhich may undermine long-term viability. The proposed KPIs offer a replicable,\ndata-driven method for assessing DAO governance structures and identifying\npotential areas for improvement. These findings support a multidimensional\napproach to evaluating decentralised systems and provide practical tools for\nresearchers and practitioners working to improve the resilience and\neffectiveness of DAO-based governance models.","main_category":"cs.CY","categories":"cs.CY,cs.ET,cs.SI","published":"2025-04-15T16:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.11369v1","title":"OpenTuringBench: An Open-Model-based Benchmark and Framework for\n  Machine-Generated Text Detection and Attribution","summary":"Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC,physics.soc-ph","published":"2025-04-15T16:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.11421v1","title":"HeatSense: Intelligent Thermal Anomaly Detection for Securing\n  NoC-Enabled MPSoCs","summary":"Multi-Processor System-on-Chips (MPSoCs) are highly vulnerable to thermal\nattacks that manipulate dynamic thermal management systems. To counter this, we\npropose an adaptive real-time monitoring mechanism that detects abnormal\nthermal patterns in chip tiles. Our design space exploration helped identify\nkey thermal features for an efficient anomaly detection module to be\nimplemented at routers of network-enabled MPSoCs. To minimize hardware\noverhead, we employ weighted moving average (WMA) calculations and bit-shift\noperations, ensuring a lightweight yet effective implementation. By defining a\nspectrum of abnormal behaviors, our system successfully detects and mitigates\nmalicious temperature fluctuations, reducing severe cases from 3.00{\\deg}C to\n1.9{\\deg}C. The anomaly detection module achieves up to 82% of accuracy in\ndetecting thermal attacks, which is only 10-15% less than top-performing\nmachine learning (ML) models like Random Forest. However, our approach reduces\nhardware usage by up to 75% for logic resources and 100% for specialized\nresources, making it significantly more efficient than ML-based solutions. This\nmethod provides a practical, low-cost solution for resource-constrained\nenvironments, ensuring resilience against thermal attacks while maintaining\nsystem performance.","main_category":"cs.AR","categories":"cs.AR,cs.SY,eess.SY","published":"2025-04-15T17:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.11424v1","title":"MINDS. Anatomy of a water-rich, inclined, brown dwarf disk: lack of\n  abundant hydrocarbons","summary":"2MASS J04381486+2611399 (or J0438) is one of the few young brown dwarfs (BD)\nwith a highly inclined ($i\\!\\sim\\!70^\\circ$) disk. Here we report results from\nJWST-MIRI MRS, HST-ACS and ALMA Band 7 observations. Despite its late spectral\ntype (M7.25), the spectrum of J0438 resembles those of inner disks around\nearlier-type stars (K1-M5, T Tauri stars), with a volatile reservoir lacking\nhydrocarbons (except for acetylene, C$_2$H$_2$) and dominated by water. Other\nidentified species are H$_2$, CO$_2$, HCN, [Ar$^{+}$], and [Ne$^{+}$]. The\ndominance of water over hydrocarbons is driven by multiple factors such as disk\ndynamics, young disk age, low accretion rate and possible inner disk clearing.\nJ0438 appears highly dynamic, showing a seesaw-like variability and extended\nemission in H$_2 \\,\\,\\, S$(1), $S$(3), $S$(5), [Ne$^{+}$] and CO ($J=3-2$).\nInterestingly, the CO emission reaches up to 400 au from the brown dwarf,\nsuggesting ongoing infalling/outflowing activity impacting the disk chemistry.\nThese observations underscore the combined power of JWST, HST and ALMA in\ncharacterizing the chemical diversity and dynamics of brown dwarf disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.SR","published":"2025-04-15T17:37:59Z"}
{"aid":"http://arxiv.org/abs/2504.11439v1","title":"Combined Evidence for the $X_{17}$ Boson After PADME Results on Resonant\n  Production in Positron Annihilation","summary":"The Positron Annihilation into Dark Matter Experiment at the Laboratori\nNazionali di Frascati has reported an excess of $e^+e^-$ final-state events\nfrom positron annihilation on fixed-target atomic electrons. While the global\nsignificance remains at the $1.8\\,\\sigma$ level, the excess is centered around\n$\\sqrt{s} \\sim 17\\,\\text{MeV}$, coinciding with the invariant mass at which\nanomalous $e^+e^-$ pair production has previously been observed in nuclear\ntransitions from excited to ground states in $^8$Be, $^4$He and $^{12}$C,\nthereby strengthening the case for a common underlying origin, possibly\ninvolving a hypothetical new $X_{17}$ boson. We discuss the significance of\nthis independent accelerator-based evidence. Combining it with existing nuclear\nphysics results, we obtain a value for the $X_{17}$ mass of $m_{X_{17}} = 16.88\n\\pm 0.05\\,$ MeV, reducing the uncertainty from nuclear physics determinations\nalone by more than a factor of two.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-15T17:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.11444v1","title":"Fault Tolerant Quantum Simulation via Symplectic Transvections","summary":"Conventional approaches to fault-tolerant quantum computing realize logical\ncircuits gate-by-gate, synthesizing each gate independently on one or more code\nblocks. This incurs excess overhead and doesn't leverage common structures in\nquantum algorithms. In contrast, we propose a framework that enables the\nexecution of entire logical circuit blocks at once, preserving their global\nstructure. This whole-block approach allows for the direct implementation of\nlogical Trotter circuits - of arbitrary rotation angles - on any stabilizer\ncode, providing a powerful new method for fault tolerant Hamiltonian simulation\nwithin a single code block. At the heart of our approach lies a deep structural\ncorrespondence between symplectic transvections and Trotter circuits. This\nconnection enables both logical and physical circuits to share the Trotter\nstructure while preserving stabilizer centralization and circuit symmetry even\nin the presence of non-Clifford rotations. We discuss potential approaches to\nfault tolerance via biased noise and code concatenation. While we illustrate\nthe key principles using a $[[8,3,3]]$ code, our simulations show that the\nframework applies to Hamiltonian simulation on even good quantum LDPC codes.\nThese results open the door to new algorithm-tailored, block-level strategies\nfor fault tolerant circuit design, especially in quantum simulation.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-15T17:56:07Z"}
{"aid":"http://arxiv.org/abs/2504.11753v1","title":"The $L^p$-boundedness of wave operators for 4-th order SchrÃ¶dinger\n  operators on $\\mathbb{R}^2$, I","summary":"We prove that high energy parts of wave operators for fourth order\nSchr\\\"odinger operators $H=\\Delta^2 + V(x)$ in $\\mathbb{R}^2$ are bounded in\n$L^p(\\mathbb{R}^2)$ for $p\\in(1,\\infty)$.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-16T04:10:47Z"}
{"aid":"http://arxiv.org/abs/2504.11754v1","title":"GrabS: Generative Embodied Agent for 3D Object Segmentation without\n  Scene Supervision","summary":"We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.RO","published":"2025-04-16T04:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11758v1","title":"Hardy spaces, Campanato spaces and higher order Riesz transforms\n  associated with Bessel operators","summary":"Let $\\nu = (\\nu_1, \\ldots, \\nu_n) \\in (-1/2, \\infty)^n$, with $n \\ge 1$, and\nlet $\\Delta_\\nu$ be the multivariate Bessel operator defined by\n  \\[\n  \\Delta_{\\nu} = -\\sum_{j=1}^n\\left( \\frac{\\partial^2}{\\partial x_j^2} -\n\\frac{\\nu_j^2 - 1/4}{x_j^2} \\right).\n  \\]\n  In this paper, we develop the theory of Hardy spaces and BMO-type spaces\nassociated with the Bessel operator $\\Delta_\\nu$. We then study the\nhigher-order Riesz transforms associated with $\\Delta_\\nu$. First, we show that\nthese transforms are Calder\\'on-Zygmund operators. We further prove that they\nare bounded on the Hardy spaces and BMO-type spaces associated with\n$\\Delta_\\nu$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-16T04:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.11761v1","title":"Delayed Acceptance Markov Chain Monte Carlo for Robust Bayesian Analysis","summary":"This study introduces a computationally efficient algorithm, delayed\nacceptance Markov chain Monte Carlo (DA-MCMC), designed to improve posterior\nsimulation in quasi-Bayesian inference. Quasi-Bayesian methods, which do not\nrequire fully specifying a probabilistic model, are often computationally\nexpensive owing to the need to evaluate the inverse and determinant of large\ncovariance matrices. DA-MCMC addresses this challenge by employing a two-stage\nprocess: In the first stage, proposals are screened using an approximate\nposterior, whereas a final acceptance or rejection decision is made in the\nsecond stage based on the exact target posterior. This reduces the need for\ncostly matrix computations, thereby improving efficiency without sacrificing\naccuracy. We demonstrate the effectiveness of DA-MCMC through applications to\nboth synthetic and real data. The results demonstrate that, although DA-MCMC\nslightly reduces the effective sample size per iteration compared with the\nstandard MCMC, it achieves substantial improvement in terms of effective sample\nsize per second, approximately doubling the efficiency. This makes DA-MCMC\nparticularly useful for cases where posterior simulation is computationally\nintensive. Thus, the DA-MCMC algorithm offers a significant advancement in\ncomputational efficiency for quasi-Bayesian inference, making it a valuable\ntool for robust Bayesian analysis.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T04:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.11771v1","title":"Design and Continuation of Nonlinear Teardrop Hovering Formation along\n  the Near Rectilinear Halo Orbit","summary":"This short communication is devoted to the design and continuation of a\nteardrop hovering formation along the Near Rectilinear Halo orbit and provides\nfurther insights into future on-orbit services in the cislunar space. First, we\nextend the concept of the teardrop hovering formation to scenarios along the\nNear Rectilinear Halo orbit in the Earth-Moon circular restricted three-body\nproblem. Then, we develop two methods for designing these formations based on\nthe nonlinear model for relative motion. The first method addresses the design\nof the teardrop hovering formations with relatively short revisit distances,\nwhile the second method continues hovering trajectories from short to longer\nrevisit distances. In particular, new continuation method is developed to meet\nthe design requirements of this new scenario. Simulation results verify the\neffectiveness of the proposed methods, and a near-natural teardrop hovering\nformation is achieved by considering the dynamical properties near the NRHO.\nComparisons between design results obtained using linear and nonlinear models\nfurther strengthen the necessity of using the nonlinear model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T05:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.11772v1","title":"Admissible subcategories and metric techniques","summary":"In this work, we provide a way of constructing new semiorthogonal\ndecompositions using metric techniques (\\`a la Neeman). Given a semiorthogonal\ndecomposition on a category with a special kind of metric, which we call a\ncompressible metric, we can construct new semiorthogonal decomposition on a\ncategory constructed from the given one using the aforementioned metric. In the\nalgebro-geometric setting, this gives us a way of producing new semiorthogonal\ndecompositions on various small triangulated categories associated to a scheme,\nif we are given one. In the general setting, the work is related to that of\nSun-Zhang, while its applications to algebraic geometry are related to the work\nof Bondarko and Kuznetsov-Shinder.","main_category":"math.AG","categories":"math.AG,math.CT","published":"2025-04-16T05:24:55Z"}
{"aid":"http://arxiv.org/abs/2504.11786v1","title":"DART: Disease-aware Image-Text Alignment and Self-correcting\n  Re-alignment for Trustworthy Radiology Report Generation","summary":"The automatic generation of radiology reports has emerged as a promising\nsolution to reduce a time-consuming task and accurately capture critical\ndisease-relevant findings in X-ray images. Previous approaches for radiology\nreport generation have shown impressive performance. However, there remains\nsignificant potential to improve accuracy by ensuring that retrieved reports\ncontain disease-relevant findings similar to those in the X-ray images and by\nrefining generated reports. In this study, we propose a Disease-aware\nimage-text Alignment and self-correcting Re-alignment for Trustworthy radiology\nreport generation (DART) framework. In the first stage, we generate initial\nreports based on image-to-text retrieval with disease-matching, embedding both\nimages and texts in a shared embedding space through contrastive learning. This\napproach ensures the retrieval of reports with similar disease-relevant\nfindings that closely align with the input X-ray images. In the second stage,\nwe further enhance the initial reports by introducing a self-correction module\nthat re-aligns them with the X-ray images. Our proposed framework achieves\nstate-of-the-art results on two widely used benchmarks, surpassing previous\napproaches in both report generation and clinical efficacy metrics, thereby\nenhancing the trustworthiness of radiology reports.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:39:08Z"}
{"aid":"http://arxiv.org/abs/2504.11791v1","title":"Progress in ${\\cal CP}$ violating top-Higgs coupling at the LHC with\n  Machine Learning","summary":"A precise measurement of the top-Higgs coupling is essential in particle\nphysics, as it offers a powerful probe of potential new physics beyond the\nStandard Model (BSM), particularly scenarios involving ${\\cal CP}$ violation,\nwhich is a key condition in addressing the problem of baryon asymmetry of the\nuniverse. In this article, we review the recent progress in the studies of the\nthe top-Higgs coupling at the Large Hadron Collider (LHC). We briefly highlight\nthe recent Machine Learning (ML) algorithms being used and their role in\nconstraining the ${\\cal CP}$ phase of the top-Higgs coupling with an emphasis\non the future potential of beyond-the-traditional methods such as transformers\nand heterogeneous graphs in these studies.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T05:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.11795v1","title":"Schemex: Interactive Structural Abstraction from Examples with\n  Contrastive Refinement","summary":"Each type of creative or communicative work is underpinned by an implicit\nstructure. People learn these structures from examples - a process known in\ncognitive science as schema induction. However, inducing schemas is\nchallenging, as structural patterns are often obscured by surface-level\nvariation. We present Schemex, an interactive visual workflow that scaffolds\nschema induction through clustering, abstraction, and contrastive refinement.\nSchemex supports users through visual representations and interactive\nexploration that connect abstract structures to concrete examples, promoting\ntransparency, adaptability, and effective human-AI collaboration. In our user\nstudy, participants reported significantly greater insight and confidence in\nthe schemas developed with Schemex compared to those created using a baseline\nof an AI reasoning model. We conclude by discussing the broader implications of\nstructural abstraction and contrastive refinement across domains.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T06:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.11810v1","title":"Light WIMPs and MeV Gamma-ray Detection with COSI","summary":"Light weakly interacting massive particles (WIMPs), whose masses are in the\nsub-GeV scale, have been attracting more attention due to the negative results\nsearching for traditional WIMPs. The light WIMPs are expected to produce gamma\nrays from annihilation in the MeV energy region. Advancements in technology\nhave opened up possibilities to precisely detect MeV gamma rays, leading to the\nupcoming space-based mission of the Compton Spectrometer and Imager (COSI). We\ncomprehensively and quantitatively study the phenomenology of light WIMPs to\ndetermine if the COSI observations will probe their viable model parameter\nregions. We first construct models to describe light WIMPs based on the\nminimality and renormalizability of quantum field theory. Next, we impose\nvarious constraints on the models obtained from cosmological observations (CMB,\nBBN) and dark matter searches (accelerator, underground, astrophysical\nexperiments, etc.). Finally, we identify viable parameter regions in each model\nand discuss whether or not COSI will be sensitive to the parameter regions. We\nfind that a velocity-dependent annihilation cross-section is predicted in some\nregions, enabling COSI to detect the dark matter signal while avoiding severe\nconstraints from cosmological observations.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE","published":"2025-04-16T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.11818v1","title":"A phase transition in the Susceptible-Infected model on hypernetworks","summary":"We derive the master equations for the Susceptible-Infected (SI) model on\ngeneral hypernetworks with~$N$-body interactions. We solve these equations\nexactly for infinite~$d$-regular hypernetworks, and obtain an explicit solution\nfor the expected infection level as a function of time. The solution shows that\nthe epidemic spreads out to the entire population as~$t \\to \\infty$ if and only\nif the initial infection level exceeds a positive threshold value. This phase\ntransition is a high-order interactions effect, which is absent with pairwise\ninteractions.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-16T07:09:57Z"}
{"aid":"http://arxiv.org/abs/2504.11832v1","title":"Generation of Paths for Motion Planning for a Dubins Vehicle on Sphere","summary":"In this article, the candidate optimal paths for a Dubins vehicle on a sphere\nare analytically derived. In particular, the arc angles for segments in $CGC$,\n$CCC$, $CCCC$, and $CCCCC$ paths, which have previously been shown to be\noptimal depending on the turning radius $r$ of the vehicle by Kumar \\textit{et\nal.}, are analytically derived. The derived expressions are used for the\nimplementation provided in\nhttps://github.com/DeepakPrakashKumar/Motion-planning-on-sphere.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T07:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.11841v1","title":"Permutation dimensions of prime cyclic groups","summary":"Based on recent successes concerning permutation resolutions of\nrepresentations by Balmer and Gallauer we define a new invariant of finite\ngroups: the p-permutation dimension. We compute this invariant for cyclic\ngroups of prime order.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T08:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.11843v1","title":"Scalable Multi-task Edge Sensing via Task-oriented Joint Information\n  Gathering and Broadcast","summary":"The recent advance of edge computing technology enables significant sensing\nperformance improvement of Internet of Things (IoT) networks. In particular, an\nedge server (ES) is responsible for gathering sensing data from distributed\nsensing devices, and immediately executing different sensing tasks to\naccommodate the heterogeneous service demands of mobile users. However, as the\nnumber of users surges and the sensing tasks become increasingly\ncompute-intensive, the huge amount of computation workloads and data\ntransmissions may overwhelm the edge system of limited resources. Accordingly,\nwe propose in this paper a scalable edge sensing framework for multi-task\nexecution, in the sense that the computation workload and communication\noverhead of the ES do not increase with the number of downstream users or\ntasks. By exploiting the task-relevant correlations, the proposed scheme\nimplements a unified encoder at the ES, which produces a common low-dimensional\nmessage from the sensing data and broadcasts it to all users to execute their\nindividual tasks. To achieve high sensing accuracy, we extend the well-known\ninformation bottleneck theory to a multi-task scenario to jointly optimize the\ninformation gathering and broadcast processes. We also develop an efficient\ntwo-step training procedure to optimize the parameters of the neural\nnetwork-based codecs deployed in the edge sensing system. Experiment results\nshow that the proposed scheme significantly outperforms the considered\nrepresentative benchmark methods in multi-task inference accuracy. Besides, the\nproposed scheme is scalable to the network size, which maintains almost\nconstant computation delay with less than 1% degradation of inference\nperformance when the user number increases by four times.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:06:46Z"}
{"aid":"http://arxiv.org/abs/2504.11850v1","title":"ACE: Attentional Concept Erasure in Diffusion Models","summary":"Large text-to-image diffusion models have demonstrated remarkable image\nsynthesis capabilities, but their indiscriminate training on Internet-scale\ndata has led to learned concepts that enable harmful, copyrighted, or otherwise\nundesirable content generation. We address the task of concept erasure in\ndiffusion models, i.e., removing a specified concept from a pre-trained model\nsuch that prompting the concept (or related synonyms) no longer yields its\ndepiction, while preserving the model's ability to generate other content. We\npropose a novel method, Attentional Concept Erasure (ACE), that integrates a\nclosed-form attention manipulation with lightweight fine-tuning. Theoretically,\nwe formulate concept erasure as aligning the model's conditional distribution\non the target concept with a neutral distribution. Our approach identifies and\nnullifies concept-specific latent directions in the cross-attention modules via\na gated low-rank adaptation, followed by adversarially augmented fine-tuning to\nensure thorough erasure of the concept and its synonyms. Empirically, we\ndemonstrate on multiple benchmarks, including object classes, celebrity faces,\nexplicit content, and artistic styles, that ACE achieves state-of-the-art\nconcept removal efficacy and robustness. Compared to prior methods, ACE better\nbalances generality (erasing concept and related terms) and specificity\n(preserving unrelated content), scales to dozens of concepts, and is efficient,\nrequiring only a few seconds of adaptation per concept. We will release our\ncode to facilitate safer deployment of diffusion models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.11876v1","title":"Generic regularity in time for solutions of the Stefan problem in 4+1\n  dimensions","summary":"We show that the free boundary of a solution of the Stefan problem in\n$\\mathbb R^{4+1}$ is a $3$-dimensional manifold of class $C^\\infty$ in $\\mathbb\nR^4$ for almost every time. This is achieved by showing that for all dimensions\n$n$ the singular set $\\Sigma\\subset \\mathbb R^{n+1}$ can be decomposed in two\nparts $\\Sigma=\\Sigma^\\infty\\cup \\Sigma^*$, where $\\Sigma^\\infty$ is covered by\none $(n-1)$-dimensional manifold of class $C^\\infty$ in $\\mathbb R^{n+1}$ and\nits projection onto the time axis has Hausdorff dimension 0, while $\\Sigma^*$\nis parabolically countably $(n-2)$-rectifiable.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T08:58:40Z"}
{"aid":"http://arxiv.org/abs/2504.11881v1","title":"Universal portfolios in continuous time: a model-free approach","summary":"We provide a simple and straightforward approach to a continuous-time version\nof Cover's universal portfolio strategies within the model-free context of\nF\\\"ollmer's pathwise It\\^o calculus. We establish the existence of the\nuniversal portfolio strategy and prove that its portfolio value process is the\naverage of all values of constant rebalanced strategies. This result relies on\na systematic comparison between two alternative descriptions of self-financing\ntrading strategies within pathwise It\\^o calculus. We moreover provide a\ncomparison result for the performance and the realized volatility and variance\nof constant rebalanced portfolio strategies.","main_category":"q-fin.MF","categories":"q-fin.MF,q-fin.PM","published":"2025-04-16T09:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.11892v1","title":"A structure-preserving numerical method for quasi-incompressible\n  Navier-Stokes-Maxwell-Stefan systems","summary":"A conforming finite element scheme with mixed explicit-implicit time\ndiscretization for quasi-incompressible Navier-Stokes-Maxwell-Stefan systems in\na bounded domain with periodic boundary conditions is presented. The system\nconsists of the Navier-Stokes equations, together with a\nquasi-incompressibility constraint, coupled with the cross-diffusion\nMaxwell-Stefan equations. The numerical scheme preserves the partial masses and\nthe quasi-incompressibility constraint and dissipates the discrete energy.\nNumerical experiments in two space dimensions illustrate the convergence of the\nscheme and the structure-preserving properties.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T09:19:39Z"}
{"aid":"http://arxiv.org/abs/2504.11897v1","title":"A LINAC-based, compact x-ray source by inverse Compton scattering","summary":"In this paper we present the first measured x-rays produced with a compact,\ntunable, inverse Compton scattering-based x-ray source. The experimental flux\nwas $1.2 \\cdot 10^3$ photons per shot, which was comparable to simulations.\nAdditionally, the continuous tunability of photon energy and x-ray polarization\ncontrol possible with the source are shown. The measured x-ray pulse length was\nin the picosecond range. By increasing experimental parameters, implementing\nimprovements and further conditioning of the accelerator structure, an expected\nbrilliance of $10^{12}$ photons/(s $\\times$ mrad$^2$ $\\times$ mm${^{2}}$\n$\\times$ 0.1\\% BW) is expected, while maximum photon energies can go to 40 keV.\nSince the complete electron beamline will fit on a single optical table, it is\nsuitable as in-house x-ray source for e.g. research institutes, companies,\nmuseums, and hospitals.","main_category":"physics.acc-ph","categories":"physics.acc-ph,physics.optics","published":"2025-04-16T09:23:50Z"}
{"aid":"http://arxiv.org/abs/2504.11905v1","title":"A Novel Splitter Design for RSMA Networks","summary":"Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T09:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11910v1","title":"The role of wild birds in the global highly pathogenic avian influenza\n  H5 panzootic","summary":"The highly pathogenic avian influenza (HPAI) H5 clade 2.3.4.4b has triggered\nan unprecedented global panzootic. As the frequency and scale of HPAI H5\noutbreaks continue to rise, understanding how wild birds contribute to shape\nthe global virus spread across regions, affecting poultry, domestic and wild\nmammals, is increasingly critical. In this review, we examine ecological and\nevolutionary studies to map the global transmission routes of HPAI H5 viruses,\nidentify key wild bird species involved in viral dissemination, and explore\ninfection patterns, including mortality and survival. We also highlight major\nremaining knowledge gaps that hinder a full understanding of wild birds role in\nviral dynamics, which must be addressed to enhance surveillance strategies and\nrefine risk assessment models aimed at preventing future outbreaks in wildlife,\ndomestic animals and safeguard public health.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-16T09:42:40Z"}
{"aid":"http://arxiv.org/abs/2504.11932v1","title":"Technological Complexity Based on Japanese Patent Data","summary":"As international competition intensifies in technologies, nations need to\nidentify key technologies to foster innovation. However, the identification is\ndifficult because a technology is independent, therefore has complex nature.\nHere, this study aims to assess patent technological fields by applying\nTechnological Complexity Index from a corporate perspective, addressing its\nunderutilization in Japan despite its potential. By utilizing carefully\nprocessed patent data from fiscal years 1981 to 2010, we analyze the bipartite\nnetwork which consists of 1,938 corporations and 35 or 124 technological\nfields. Our findings provide quantitative characteristics of ubiquity and\nsophistication for patent fields, the detailed technological trends that\nreflect the social context, and methodological stability for policymakers and\nresearchers, contributing to targeted innovation strategies in Japan.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-16T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.11935v1","title":"Note on supersymmetric mechanics with spin-orbit interaction","summary":"We propose a simple model of two-dimensional N=2 superconformal mechanics\nwith a spin-orbit interaction term and demonstrate that it inherits the\nGalilean symmetry of the initial free-particle system. We then propose a\nquaternionic counterpart of this system, which describes the four-dimensional\nN=4 superconformal mechanics$D(1,2|\\alpha). The bosonic part of the Hamiltonian\ndescribes a free particle on the cone, while the fermionic part necessarily\nincludes the spin-orbit interaction term.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T10:15:57Z"}
{"aid":"http://arxiv.org/abs/2504.11937v1","title":"Complete Classification of the Symmetry Groups of Monge-AmpÃ¨re\n  Equation and Affine Maximal type Equation","summary":"The affine maximal type hypersurface has been a core topic in Affine\nGeometry. When the hypersurface is presented as a regular graph of a convex\nfunction $u$, the statement that the graph is of affine maximal type is\nequivalent to the statement that $u$ satisfies the fully nonlinear partial\ndifferential equation\n  $$\n  D_{ij}(U^{ij}w)=0, \\ \\ w\\equiv[\\det D^2u]^{-\\theta}, \\ \\ \\theta>0, \\ \\\n\\forall x\\in{\\mathbb{R}}^N\n  $$ of fourth order. This equation can be regarded as a generalization of the\n$N$-dimensional Monge-Amp\\`{e}re equation\n  $$\n  \\det D^2u=1, \\ \\ \\forall x\\in{\\mathbb{R}}^N\n  $$ of second order, since each solution of Monge-Amp\\`{e}re Equation\nsatisfies affine maximal type equation automatically. In this paper, we will\ndetermine the symmetry groups of these two important fully nonlinear equations\nwithout asymptotic growth assumption. Our method develops the Lie's theory to\nfully nonlinear PDEs.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.11941v1","title":"Admissible matchings and the Castelnuovo-Mumford regularity of\n  square-free powers","summary":"Let $I$ be any square-free monomial ideal, and $\\mathcal{H}_I$ denote the\nhypergraph associated with $I$. Refining the concept of $k$-admissible matching\nof a graph defined by Erey and Hibi, we introduce the notion of generalized\n$k$-admissible matching for any hypergraph. Using this, we give a sharp lower\nbound on the (Castelnuovo-Mumford) regularity of $I^{[k]}$, where $I^{[k]}$\ndenotes the $k^{\\text{th}}$ square-free power of $I$. In the special case when\n$I$ is equigenerated in degree $d$, this lower bound can be described using a\ncombinatorial invariant $\\mathrm{aim}(\\mathcal{H}_I,k)$, called the\n$k$-admissible matching number of $\\mathcal{H}_I$. Specifically, we prove that\n$\\mathrm{reg}(I^{[k]})\\ge (d-1)\\mathrm{aim}(\\mathcal{H}_I,k)+k$, whenever\n$I^{[k]}$ is non-zero. Even for the edge ideal $I(G)$ of a graph $G$, it turns\nout that $\\mathrm{aim}(G,k)+k$ is the first general lower bound for the\nregularity of $I(G)^{[k]}$. In fact, when $G$ is a forest, $\\mathrm{aim}(G,k)$\ncoincides with the $k$-admissible matching number introduced by Erey and Hibi.\nNext, we show that if $G$ is a block graph, then $\\mathrm{reg}(I(G)^{[k]})=\n\\mathrm{aim}(G,k)+k$, and this result can be seen as a generalization of the\ncorresponding regularity formula for forests. Additionally, for a\nCohen-Macaulay chordal graph $G$, we prove that $\\mathrm{reg}(I(G)^{[2]})=\n\\mathrm{aim}(G,2)+2$. Finally, we propose a conjecture on the regularity of\nsquare-free powers of edge ideals of chordal graphs.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-16T10:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.11942v1","title":"ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign\n  Language Translation","summary":"Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-16T10:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.11957v1","title":"Unconditional robustness of multipartite entanglement of superposition","summary":"We study the robustness of genuine multipartite entanglement and\ninseparability of multipartite pure states under superposition with product\npure states. We introduce the concept of the maximal and the minimal Schmidt\nranks for multipartite states. From the minimal Schmidt rank of the first order\nwe present criterion of verifying unconditional robustness of genuine\nmultipartite entanglement of multipartite pure states under superposition with\nproduct pure states. By the maximal Schmidt rank of the first order we verify\nthe unconditional robustness of multipartite inseparability under superposition\nwith product pure states. The number of product states superposed to a given\nentangled state which result in a separable state is investigated in detail.\nFurthermore, the minimal Schmidt ranks of the second order are also introduced\nto identify the unconditional robustness of an entangled state for tripartite\ninseparability.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T10:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11968v1","title":"Dynamical reweighting for estimation of fluctuation formulas","summary":"We propose a variance reduction method for calculating transport coefficients\nin molecular dynamics using an importance sampling method via Girsanov's\ntheorem applied to Green--Kubo's formula. We optimize the magnitude of the\nperturbation applied to the reference dynamics by means of a scalar\nparameter~$\\alpha$ and propose an asymptotic analysis to fully characterize the\nlong-time behavior in order to evaluate the possible variance reduction.\nTheoretical results corroborated by numerical results show that this method\nallows for some reduction in variance, although rather modest in most\nsituations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:01:20Z"}
{"aid":"http://arxiv.org/abs/2504.11989v1","title":"Epstein zeta method for many-body lattice sums","summary":"Many-body interactions arise naturally in the perturbative treatment of\nclassical and quantum many-body systems and play a crucial role in the\ndescription of condensed matter systems. In the case of three-body\ninteractions, the Axilrod-Teller-Muto (ATM) potential is highly relevant for\nthe quantitative prediction of material properties. The computation of the\nresulting energies in d-dimensional lattice systems is challenging, as a\nhigh-dimensional lattice sum needs to be evaluated to high precision. This work\nsolves this long-standing issue. We present an efficiently computable\nrepresentation of many-body lattice sums in terms of singular integrals over\nproducts of Epstein zeta functions. For three-body interactions in 3D, this\napproach reduces the runtime for computing the ATM lattice sum from weeks to\nminutes. Our approach further extends to a broad class of n-body lattice sums.\nWe demonstrate that the computational cost of our method only increases\nlinearly with n, evading the exponential increase in complexity of direct\nsummation. The evaluation of 51-body interactions on a two-dimensional lattice,\ncorresponding to a 100-dimensional sum, can be performed within seconds on a\nlaptop. We discuss techniques for computing the arising singular integrals and\ncompare the accuracy of our results against computable benchmarks, achieving\nfull precision for exponents greater than the system dimension. Finally, we\napply our method to study the stability of a three-dimensional lattice system\nwith Lennard-Jones two-body interactions under the inclusion of an ATM\nthree-body term at finite pressure, finding a transition from the\nface-centered-cubic to the body-centered-cubic lattice structure with\nincreasing ATM coupling strength. This work establishes the mathematical\nfoundation for an ongoing investigation into the influence of many-body\ninteractions on the stability of matter.","main_category":"math.NA","categories":"math.NA,cond-mat.mtrl-sci,cond-mat.str-el,cs.NA","published":"2025-04-16T11:30:11Z"}
{"aid":"http://arxiv.org/abs/2504.12004v1","title":"Scaled Block Vecchia Approximation for High-Dimensional Gaussian Process\n  Emulation on GPUs","summary":"Emulating computationally intensive scientific simulations is essential to\nenable uncertainty quantification, optimization, and decision-making at scale.\nGaussian Processes (GPs) offer a flexible and data-efficient foundation for\nstatistical emulation, but their poor scalability limits applicability to large\ndatasets. We introduce the Scaled Block Vecchia (SBV) algorithm for distributed\nGPU-based systems. SBV integrates the Scaled Vecchia approach for anisotropic\ninput scaling with the Block Vecchia (BV) method to reduce computational and\nmemory complexity while leveraging GPU acceleration techniques for efficient\nlinear algebra operations. To the best of our knowledge, this is the first\ndistributed implementation of any Vecchia-based GP variant. Our implementation\nemploys MPI for inter-node parallelism and the MAGMA library for\nGPU-accelerated batched matrix computations. We demonstrate the scalability and\nefficiency of the proposed algorithm through experiments on synthetic and\nreal-world workloads, including a 50M point simulation from a respiratory\ndisease model. SBV achieves near-linear scalability on up to 64 A100 and GH200\nGPUs, handles 320M points, and reduces energy use relative to exact GP solvers,\nestablishing SBV as a scalable and energy-efficient framework for emulating\nlarge-scale scientific models on GPU-based distributed systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-16T11:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12020v1","title":"MixSignGraph: A Sign Sequence is Worth Mixed Graphs of Nodes","summary":"Recent advances in sign language research have benefited from CNN-based\nbackbones, which are primarily transferred from traditional computer vision\ntasks (\\eg object identification, image recognition). However, these CNN-based\nbackbones usually excel at extracting features like contours and texture, but\nmay struggle with capturing sign-related features. In fact, sign language tasks\nrequire focusing on sign-related regions, including the collaboration between\ndifferent regions (\\eg left hand region and right hand region) and the\neffective content in a single region. To capture such region-related features,\nwe introduce MixSignGraph, which represents sign sequences as a group of mixed\ngraphs and designs the following three graph modules for feature extraction,\n\\ie Local Sign Graph (LSG) module, Temporal Sign Graph (TSG) module and\nHierarchical Sign Graph (HSG) module. Specifically, the LSG module learns the\ncorrelation of intra-frame cross-region features within one frame, \\ie focusing\non spatial features. The TSG module tracks the interaction of inter-frame\ncross-region features among adjacent frames, \\ie focusing on temporal features.\nThe HSG module aggregates the same-region features from different-granularity\nfeature maps of a frame, \\ie focusing on hierarchical features. In addition, to\nfurther improve the performance of sign language tasks without gloss\nannotations, we propose a simple yet counter-intuitive Text-driven CTC\nPre-training (TCP) method, which generates pseudo gloss labels from text labels\nfor model pre-training. Extensive experiments conducted on current five public\nsign language datasets demonstrate the superior performance of the proposed\nmodel. Notably, our model surpasses the SOTA models on multiple sign language\ntasks across several datasets, without relying on any additional cues.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:23:30Z"}
{"aid":"http://arxiv.org/abs/2504.12048v1","title":"Modular-Cam: Modular Dynamic Camera-view Video Generation with LLM","summary":"Text-to-Video generation, which utilizes the provided text prompt to generate\nhigh-quality videos, has drawn increasing attention and achieved great success\ndue to the development of diffusion models recently. Existing methods mainly\nrely on a pre-trained text encoder to capture the semantic information and\nperform cross attention with the encoded text prompt to guide the generation of\nvideo. However, when it comes to complex prompts that contain dynamic scenes\nand multiple camera-view transformations, these methods can not decompose the\noverall information into separate scenes, as well as fail to smoothly change\nscenes based on the corresponding camera-views. To solve these problems, we\npropose a novel method, i.e., Modular-Cam. Specifically, to better understand a\ngiven complex prompt, we utilize a large language model to analyze user\ninstructions and decouple them into multiple scenes together with transition\nactions. To generate a video containing dynamic scenes that match the given\ncamera-views, we incorporate the widely-used temporal transformer into the\ndiffusion model to ensure continuity within a single scene and propose\nCamOperator, a modular network based module that well controls the camera\nmovements. Moreover, we propose AdaControlNet, which utilizes ControlNet to\nensure consistency across scenes and adaptively adjusts the color tone of the\ngenerated video. Extensive qualitative and quantitative experiments prove our\nproposed Modular-Cam's strong capability of generating multi-scene videos\ntogether with its ability to achieve fine-grained control of camera movements.\nGenerated results are available at https://modular-cam.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T13:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.12049v1","title":"Impact of spin correlations on resistivity and microwave absorption of\n  Ba(Fe$_{1-x}$Co$_x$)$_2$As$_2$","summary":"The results of studies of BaFe$_2$As$_2$ single crystals doped with cobalt by\nmeans of resistivity and microwave absorption measurement are reported. A\ntheoretical description of the behavior of the microwave absorption amplitude\nis made taking into account the temperature dependence of resistivity, magnetic\nsusceptibility and the lifetime of spin fluctuations. An assumption has been\nmade that the deviation from the linear dependence of resistivity on\ntemperature at $T<100$ K is not related to the electron-electron scattering\nmechanism, but it is due to the appearance of nematic fluctuations. Estimates\nof the rate of scattering by spin fluctuations indicate their nematic nature at\ntemperatures near the structural transition.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.12052v1","title":"Bayesian dynamic borrowing considering semantic similarity between\n  outcomes for disproportionality analysis in FAERS","summary":"We present a Bayesian dynamic borrowing (BDB) approach to enhance the\nquantitative identification of adverse events (AEs) in spontaneous reporting\nsystems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior\nwithin a Bayesian hierarchical model and incorporates semantic similarity\nmeasures (SSMs) to enable weighted information sharing from MedDRA Preferred\nTerms (PTs) that are clinical similar to the target PT. This continuous\nsimilarity-based borrowing addresses limitation of rigid hierarchical grouping\nin current disproportionality analysis (DPA).\n  Using data from the FDA Adverse Event Reporting System (FAERS) between 2015\nand 2019, we evalute this approach - termed IC SSM - against standard\nInformation Component (IC) analysis and IC with borrowing at the MedDRA\nhigh-level group term (HLGT) level. A novel references set (PVLens), derived\nfrom FDA product label updates, enabled prospective evaluation of method\nperformance in identifying AEs prior to official labeling.\n  The IC SSM approach demonstrated improved sensitivity compared to both\ntraditional IC and HLGT-based borrowing, with minor trade-offs in F1 scores and\nYouden's index. IC SSM consistently identified more true positives and detected\nsignals over 5 months sooner than traditional IC. Despite a marginally lower\naggregate Youden's index, IC SSM showed higher performance in the early\npost-marketing period, providing more stable and relevant estimates than\nHLGT-based borrowing and traditional IC.\n  These findings support the use of SSM-informed Bayesian borrowing as a\nscalable and context-aware enhancement to traditional DPA methods. Future\nresearch should validate this approach across other datasets and explore\nadditional similarity metrics and Bayesian inference strategies using\ncase-level data.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T13:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.12064v1","title":"One-stage hollow-core fiber-based compression of Yb:KGW lasers to the\n  single-cycle regime","summary":"The generation of intense, waveform-controlled, single-cycle pulses based on\nYb:KGW amplifiers is central to integrating these lasers with attosecond\nmetrology and spectroscopy. Here, we demonstrate single-stage, multi-octave (~\n2.4 octaves) spectral broadening of Yb:KGW amplified pulses in a\nneon-pressurized hollow-core fiber (HCF) capillary and their compression to the\nsingle-cycle regime (1.1 cycles at 880 nm) using chirped mirrors. Utilizing\nHomochromatic Attosecond Streaking (HAS), we characterize the field waveforms\nof the generated pulses and demonstrate precise control of their\ncarrier-envelope phase. Our results provide a simplified route to single-cycle\npulse generation using Yb:KGW technology, previously possible only with\nTi:Sapphire-based front ends. This work paves the way for advanced applications\nin attosecond science, strong-field physics, and spectroscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.12082v1","title":"Selective Demonstration Retrieval for Improved Implicit Hate Speech\n  Detection","summary":"Hate speech detection is a crucial area of research in natural language\nprocessing, essential for ensuring online community safety. However, detecting\nimplicit hate speech, where harmful intent is conveyed in subtle or indirect\nways, remains a major challenge. Unlike explicit hate speech, implicit\nexpressions often depend on context, cultural subtleties, and hidden biases,\nmaking them more challenging to identify consistently. Additionally, the\ninterpretation of such speech is influenced by external knowledge and\ndemographic biases, resulting in varied detection results across different\nlanguage models. Furthermore, Large Language Models often show heightened\nsensitivity to toxic language and references to vulnerable groups, which can\nlead to misclassifications. This over-sensitivity results in false positives\n(incorrectly identifying harmless statements as hateful) and false negatives\n(failing to detect genuinely harmful content). Addressing these issues requires\nmethods that not only improve detection precision but also reduce model biases\nand enhance robustness. To address these challenges, we propose a novel method,\nwhich utilizes in-context learning without requiring model fine-tuning. By\nadaptively retrieving demonstrations that focus on similar groups or those with\nthe highest similarity scores, our approach enhances contextual comprehension.\nExperimental results show that our method outperforms current state-of-the-art\ntechniques. Implementation details and code are available at TBD.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T13:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.12087v1","title":"Extrae.jl: Julia bindings for the Extrae HPC Profiler","summary":"The Julia programming language has gained acceptance within the\nHigh-Performance Computing (HPC) community due to its ability to tackle\ntwo-language problem: Julia code feels as high-level as Python but allows\ndevelopers to tune it to C-level performance. But to squeeze every drop of\nperformance, Julia needs to integrate with advanced performance analysis tools,\nalso known as profilers. In this work, we present Extrae.jl, a Julia package to\ninterface with the Extrae profiler.","main_category":"cs.DC","categories":"cs.DC,cs.PF","published":"2025-04-16T13:48:37Z"}
{"aid":"http://arxiv.org/abs/2504.12099v1","title":"Logical multi-qubit entanglement with dual-rail superconducting qubits","summary":"Recent advances in quantum error correction (QEC) across hardware platforms\nhave demonstrated operation near and beyond the fault-tolerance threshold, yet\nachieving exponential suppression of logical errors through code scaling\nremains a critical challenge. Erasure qubits, which enable hardware-level\ndetection of dominant error types, offer a promising path toward\nresource-efficient QEC by exploiting error bias. Single erasure qubits with\ndual-rail encoding in superconducting cavities and transmons have demonstrated\nhigh coherence and low single-qubit gate errors with mid-circuit erasure\ndetection, but the generation of multi-qubit entanglement--a fundamental\nrequirement for quantum computation and error correction--has remained an\noutstanding milestone. Here, we demonstrate a superconducting processor\nintegrating four dual-rail erasure qubits that achieves the logical multi-qubit\nentanglement with error-biased protection. Each dual-rail qubit, encoded in\npairs of tunable transmons, preserves millisecond-scale coherence times and\nsingle-qubit gate errors at the level of $10^{-5}$. By engineering tunable\ncouplings between logical qubits, we generate high-fidelity entangled states\nresilient to physical qubit noise, including logical Bell states (98.8%\nfidelity) and a three-logical-qubit Greenberger-Horne-Zeilinger (GHZ) state\n(93.5% fidelity). A universal gate set is realized through a calibrated logical\ncontrolled-NOT (CNOT) gate with 96.2% process fidelity, enabled by\ncoupler-activated $XX$ interactions in the protected logical subspace. This\nwork advances dual-rail architectures beyond single-qubit demonstrations,\nproviding a blueprint for concatenated quantum error correction with erasure\nqubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:02:30Z"}
{"aid":"http://arxiv.org/abs/2504.12114v1","title":"An Extended Generalized Prandtl-Ishlinskii Hysteresis Model for I2RIS\n  Robot","summary":"Retinal surgery requires extreme precision due to constrained anatomical\nspaces in the human retina. To assist surgeons achieve this level of accuracy,\nthe Improved Integrated Robotic Intraocular Snake (I2RIS) with dexterous\ncapability has been developed. However, such flexible tendon-driven robots\noften suffer from hysteresis problems, which significantly challenges precise\ncontrol and positioning. In particular, we observed multi-stage hysteresis\nphenomena in the small-scale I2RIS. In this paper, we propose an Extended\nGeneralized Prandtl-Ishlinskii (EGPI) model to increase the fitting accuracy of\nthe hysteresis. The model incorporates a novel switching mechanism that enables\nit to describe multi-stage hysteresis in the regions of monotonic input.\nExperimental validation on I2RIS data demonstrate that the EGPI model\noutperforms the conventional Generalized Prandtl-Ishlinskii (GPI) model in\nterms of RMSE, NRMSE, and MAE across multiple motor input directions. The EGPI\nmodel in our study highlights the potential in modeling multi-stage hysteresis\nin minimally invasive flexible robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.12116v1","title":"Improvement of the square-root low bounds on the minimum distances of\n  BCH codes and Matrix-product codes","summary":"The task of constructing infinite families of self-dual codes with unbounded\nlengths and minimum distances exhibiting square-root lower bounds is extremely\nchallenging, especially when it comes to cyclic codes. Recently, the first\ninfinite family of Euclidean self-dual binary and nonbinary cyclic codes, whose\nminimum distances have a square-root lower bound and have a lower bound better\nthan square-root lower bounds are constructed in \\cite{Chen23} for the lengths\nof these codes being unbounded. Let $q$ be a power of a prime number and\n$Q=q^2$. In this paper, we first improve the lower bounds on the minimum\ndistances of Euclidean and Hermitian duals of BCH codes with length\n$\\frac{q^m-1}{q^s-1}$ over $\\mathbb{F}_q$ and $\\frac{Q^m-1}{Q-1}$ over\n$\\mathbb{F}_Q$ in \\cite{Fan23,GDL21,Wang24} for the designed distances in some\nranges, respectively, where $\\frac{m}{s}\\geq 3$. Then based on matrix-product\nconstruction and some lower bounds on the minimum distances of BCH codes and\ntheir duals, we obtain several classes of Euclidean and Hermitian self-dual\ncodes, whose minimum distances have square-root lower bounds or a\nsquare-root-like lower bounds. Our lower bounds on the minimum distances of\nEuclidean and Hermitian self-dual cyclic codes improved many results in\n\\cite{Chen23}. In addition, our lower bounds on the minimum distances of the\nduals of BCH codes are almost $q^s-1$ or $q$ times that of the existing lower\nbounds.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T14:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.12118v1","title":"Unraveling the origin of giant exoplanets -- Observational implications\n  of convective mixing","summary":"The connection between the atmospheric composition of giant planets and their\norigin remains elusive. In this study, we explore how convective mixing can\nlink the planetary primordial state to its atmospheric composition. We simulate\nthe long-term evolution of gas giants with masses between 0.3 and 3 Jupiter\nmasses, considering various composition profiles and primordial entropies\n(assuming no entropy-mass dependence). Our results show that when convective\nmixing is considered, the atmospheric metallicity increases with time and that\nthis time evolution encodes information about the planetary primordial\nstructure. Additionally, the degree of compositional mixing affects the\nplanetary radius, altering its evolution in a measurable way. By applying mock\nobservations, we demonstrate that combining radius and atmospheric composition\ncan help to constrain the planetary formation history. Young systems emerge as\nprime targets for such characterization, with lower-mass gas giants\n(approaching Saturn's mass) being particularly susceptible to mixing-induced\nchanges. Our findings highlight convective mixing as a key mechanism for\nprobing the primordial state of giant planets, offering new constraints on\nformation models and demonstrating that the conditions inside giant planets\nshortly after their formation are not necessarily erased over billions of years\nand can leave a lasting imprint on their evolution.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.12127v1","title":"A Strong-Coupling-Limit Study on the Pairing Mechanism in the\n  Pressurized La$_3$Ni$_2$O$_7$","summary":"Recently, the bilayer perovskite nickelate La$_3$Ni$_2$O$_7$ has been\nreported to exhibit high-temperature superconductivity (SC) near $80$K under a\nmoderate pressure of about $14$GPa. To investigate the underlying pairing\nmechanism and symmetry in this complex system, we propose and analyze a mixed\nspin-$1$ and spin-$\\frac{1}{2}$ bilayer $t$-$J$ model in the strong coupling\nregime. This model explicitly incorporates the crucial role of strong Hund's\ncoupling, which favors the formation of local spin-triplet states from the two\nonsite $E_g$ orbital electrons at half-filling. We further investigate the\nmodel using both slave-particle mean-field theory and the density matrix\nrenormalization group method. Our simulation results reveal that the dominate\npairing channel is the interlayer one in the $3d_{x^2-y^2}$ orbital. The Hund's\ncoupling is shown to enhance SC within a reasonable physical range. Moreover,\nelectron doping strengthens SC by increasing carrier density; in contrast, hole\ndoping weakens SC. These findings offer critical insights into the\nunconventional SC of pressurized La$_3$Ni$_2$O$_7$ and underline the important\nrole of orbital-selective behavior and Hund's rule.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-16T14:42:22Z"}
{"aid":"http://arxiv.org/abs/2504.12131v1","title":"Equidistribution of CM points on Shimura Curves and ternary theta series","summary":"We prove an equidistribution statement for the reduction of Galois orbits of\nCM points on the special fiber of a Shimura curve over a totally real field,\nconsidering both the split and the ramified case. The main novelty of the\nramified case consists in the use of the moduli interpretation of the\nCerednik--Drinfeld uniformisation. Our result is achieved by associating to the\nreduction of CM points certain Hilbert modular forms of weight $3/2$ and by\nanalyzing their Fourier coefficients. Moreover, we also deduce the Shimura\ncurves case of the integral version of the Andr\\'e--Oort conjecture.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T14:45:22Z"}
{"aid":"http://arxiv.org/abs/2504.12133v1","title":"Coherent EUV scatterometry of 2D periodic structure profiles with\n  mathematically optimal experimental design","summary":"Extreme ultraviolet (EUV) scatterometry is an increasingly important\nmetrology that can measure critical parameters of periodic nanostructured\nmaterials in a fast, accurate, and repeatable manner and with high sensitivity\nto nanoscale structure and material composition. Because of this, EUV\nscatterometry could support manufacturing of semiconductor devices or polymer\nmetamaterials, addressing the limitations of traditional imaging methods such\nas resolution and field of view, sample damage, throughput, or low sensitivity.\nHere we use EUV scatterometry to measure the profile of an industrially\nrelevant 2D periodic interconnect structure, using $\\lambda = 29$ nm light from\na table-top high harmonic generation source. We show that EUV scatterometry is\nsensitive to out-of-plane features with single-nanometer sensitivity.\nFurthermore, we also apply a methodology based on the Fisher information matrix\nto optimize experimental design parameters, such as incidence angles and\nwavelength, to show how measurement sensitivity can be maximized. This\nmethodology reveals the strong dependence of measurement sensitivity on both\nincidence angle and wavelength $-$ even in a simple two-parameter case. Through\na simultaneous optimization of incidence angles and wavelength, we determine\nthat the most sensitive measurement of the quantities of interest can be made\nat a wavelength of $\\sim$14 nm. In the future, by reducing sample contamination\ndue to sample preparation, deep sub-nanometer sensitivity to axial profiles and\n2D structures will be possible. Our results are an important step in guiding\nEUV scatterometry towards increased accuracy and throughput with a priori\ncomputations and by leveraging new experimental capabilities.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T14:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12134v1","title":"Quantum sensing with arbitrary frequency resolution via correlation\n  measurements","summary":"Achieving high-frequency spectral resolution with quantum sensors, while\ncrucial in fields ranging from physical to biological sciences, is challenging\ndue to their finite coherence time. Here, we introduce a novel protocol that\nachieves this goal by measuring phase correlations of AC magnetic fields using\nensembles of NV centers. Our method extends the sensing dynamic range to\nfrequencies higher than the system's Rabi frequency while achieving arbitrary\nfrequency resolution, limited only by the target field coherence time.\nMoreover, our approach operates more robustly with respect to the magnetic\nfield's amplitude. Thanks to this robustness, our protocol allows the\napplication of more $\\pi$-pulses in pulse sequences such as CPMG, enabling the\ndecoupling of a broader range of frequency noise. The higher harmonics\ngenerated in this process continue to act as a part of the signal, ultimately\nimproving the frequency resolution. This method paves the way for achieving\narbitrary frequency resolution with improved performances, making it highly\nversatile for quantum sensing applications across diverse scientific fields.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph","published":"2025-04-16T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.12138v1","title":"Exactness of cochain complexes via additive functors","summary":"We investigate the relation between the notion of $e$-exactness, recently\nintroduced by Akray and Zebary, and some functors naturally related to it, such\nas the functor $P\\colon\\operatorname{Mod} R\\to\n\\operatorname{Spec}(\\operatorname{Mod} R)$, where\n$\\operatorname{Spec}(\\operatorname{Mod} R)$ denotes the spectral category of\n$\\operatorname{Mod} R$, and the localization functor with respect to the\nsingular torsion theory.","main_category":"math.RA","categories":"math.RA","published":"2025-04-16T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.12145v1","title":"Factorizations of polynomials with integral non-negative coefficients","summary":"We study the structure of the commutative multiplicative monoid $\\mathbb\nN_0[x]^*$ of all the non-zero polynomials in $\\mathbb Z[x]$ with non-negative\ncoefficients. We show that $\\mathbb N_0[x]^*$ is not a half-factorial monoid\nand is not a Krull monoid, but has a structure very similar to that of Krull\nmonoids, replacing valuations into $\\mathbb N_0$ with derivations into $\\mathbb\nN_0$. We study ideals, chain of ideals, prime ideals and prime elements of\n$\\mathbb N_0[x]^*$. Our monoid $\\mathbb N_0[x]^*$ is a submonoid of the\nmultiplicative monoid of the ring $\\mathbb Z[x]$, which is a left module over\nthe Weyl algebra $A_1(\\mathbb Z)$.","main_category":"math.AC","categories":"math.AC","published":"2025-04-16T14:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12175v1","title":"Approximation Bounds for Transformer Networks with Application to\n  Regression","summary":"We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-16T15:25:58Z"}
{"aid":"http://arxiv.org/abs/2504.12183v1","title":"Towards asteroseismology of neutron stars with physics-informed neural\n  networks","summary":"The study of the gravitational wave signatures of neutron star oscillations\nmay provide important information of their interior structure and Equation of\nState (EoS) at high densities. We present a novel technique based on physically\ninformed neural networks (PINNs) to solve the eigenvalue problem associated\nwith normal oscillation modes of neutron stars. The procedure is tested in a\nsimplified scenario, with an analytical solution, that can be used to test the\nperformance and the accuracy of the method. We show that it is possible to get\naccurate results of both the eigenfrequencies and the eigenfunctions with this\nscheme. The flexibility of the method and its capability of adapting to complex\nscenarios may serve in the future as a path to include more physics into these\nsystems.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-16T15:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.12198v1","title":"Diagrammatic Simplification of Linearized Coupled Cluster Theory","summary":"Linearized Coupled Cluster Doubles (LinCCD) often provides near-singular\nenergies in small-gap systems that exhibit static correlation. This has been\nattributed to the lack of quadratic $T_2^2$ terms that typically balance out\nsmall energy denominators in the CCD amplitude equations. Herein, I show that\nexchange contributions to ring and crossed-ring contractions (not small\ndenominators per se) cause the divergent behavior of LinCC(S)D approaches.\nRather than omitting exchange terms, I recommend a regular and size-consistent\nmethod that retains only linear ladder diagrams. As LinCCD and configuration\ninteraction doubles (CID) equations are isomorphic, this also implies that\nsimplification (rather than quadratic extensions) of CID amplitude equations\ncan lead to a size-consistent theory. Linearized ladder CCD (LinLCCD) is robust\nin statically-correlated systems and can be made\n$O(n_{\\text{occ}}^4n_{\\text{vir}}^2)$ with a hole-hole approximation. The\nrelationship between LinLCCD and random-phase approximation sets the stage for\nthe development of next-generation double-hybrid density functionals that can\ndescribe static correlation.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-16T15:48:33Z"}
{"aid":"http://arxiv.org/abs/2504.12211v1","title":"Creating benchmarkable components to measure the quality ofAI-enhanced\n  developer tools","summary":"In the AI community, benchmarks to evaluate model quality are well\nestablished, but an equivalent approach to benchmarking products built upon\ngenerative AI models is still missing. This has had two consequences. First, it\nhas made teams focus on model quality over the developer experience, while\nsuccessful products combine both. Second, product team have struggled to answer\nquestions about their products in relation to their competitors.\n  In this case study, we share: (1) our process to create robust,\nenterprise-grade and modular components to support the benchmarking of the\ndeveloper experience (DX) dimensions of our team's AI for code offerings, and\n(2) the components we have created to do so, including demographics and\nattitudes towards AI surveys, a benchmarkable task, and task and feature\nsurveys. By doing so, we hope to lower the barrier to the DX benchmarking of\ngenAI-enhanced code products.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-16T15:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12233v1","title":"Hardness of observing strong-to-weak symmetry breaking","summary":"Spontaneous symmetry breaking (SSB) is the cornerstone of our understanding\nof quantum phases of matter. Recent works have generalized this concept to the\ndomain of mixed states in open quantum systems, where symmetries can be\nrealized in two distinct ways dubbed strong and weak. Novel intrinsically mixed\nphases of quantum matter can then be defined by the spontaneous breaking of\nstrong symmetry down to weak symmetry. However, proposed order parameters for\nstrong-to-weak SSB (based on mixed-state fidelities or purities) seem to\nrequire exponentially many copies of the state, raising the question: is it\npossible to efficiently detect strong-to-weak SSB in general? Here we answer\nthis question negatively in the paradigmatic cases of $Z_2$ and $U(1)$\nsymmetries. We construct ensembles of pseudorandom mixed states that do not\nbreak the strong symmetry, yet are computationally indistinguishable from\nstates that do. This rules out the existence of efficient state-agnostic\nprotocols to detect strong-to-weak SSB.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-16T16:31:27Z"}
{"aid":"http://arxiv.org/abs/2504.12236v1","title":"Towards Human-Centered Early Prediction Models for Academic Performance\n  in Real-World Contexts","summary":"Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered considerations, limiting trust among students and reducing their\nusefulness for educators and institutional decision-makers. Second, most models\nrequire at least a month of data before making reliable predictions, delaying\nopportunities for early intervention. Third, current models primarily rely on\nsporadically collected, classroom-derived data, missing broader behavioral\npatterns that could provide more continuous and actionable insights. To address\nthese gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to\nclassify students as low or high academic performers. We evaluate them based on\nexplainability, fairness, and generalizability to assess their alignment with\nkey social values. Using behavioral and self-reported data collected within the\nfirst week of two Spring terms, we demonstrate that these models can identify\nat-risk students as early as week one. However, trade-offs across\nhuman-centered considerations highlight the complexity of designing predictive\nmodels that effectively support multi-stakeholder decision-making and\nintervention strategies. We discuss these trade-offs and their implications for\ndifferent stakeholders, outlining how predictive models can be integrated into\nstudent support systems. Finally, we examine broader socio-technical challenges\nin deploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T16:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.12241v1","title":"The Late-time Afterglow of GW170817 and Implications for Jet Dynamics","summary":"GW170817 is the first binary neutron star merger detected with gravitational\nand electromagnetic waves, and its afterglow is still detectable 7 years\npost-merger. Some previous studies of the X-ray afterglow have claimed the\nonset of a new afterglow component or raised concerns about the data processing\ntechniques. Motivated thus, we present here a reanalysis of X-ray afterglow\ndata for GW170817 and find potential sources of discrepancies between the data\nreduction techniques employed by various research groups. We also analyze the\nupdated panchromatic afterglow data to find that there is no significant\nevidence for any new afterglow component (e.g. due to the ejecta that gave rise\nto the kilonova) and that the jet must be still in a mildly relativistic phase.\nThe decline in the afterglow light curve is significantly shallower compared to\nthat expected from the standard synchrotron afterglow jet models with sideways\nspreading, indicating either an additional energy injection at late times or\nthe velocity dependence on the microphysics parameters. In this context, we\ndiscuss the implications of the late time afterglow data on jet dynamics.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.12250v1","title":"AnomalyGen: An Automated Semantic Log Sequence Generation Framework with\n  LLM for Anomaly Detection","summary":"The scarcity of high-quality public log datasets has become a critical\nbottleneck in advancing log-based anomaly detection techniques. Current\ndatasets exhibit three fundamental limitations: (1) incomplete event coverage,\n(2) artificial patterns introduced by static analysis-based generation\nframeworks, and (3) insufficient semantic awareness. To address these\nchallenges, we present AnomalyGen, the first automated log synthesis framework\nspecifically designed for anomaly detection. Our framework introduces a novel\nfour-phase architecture that integrates enhanced program analysis with\nChain-of-Thought reasoning (CoT reasoning), enabling iterative log generation\nand anomaly annotation without requiring physical system execution. Evaluations\non Hadoop and HDFS distributed systems demonstrate that AnomalyGen achieves\nsubstantially broader log event coverage (38-95 times improvement over existing\ndatasets) while producing more operationally realistic log sequences compared\nto static analysis-based approaches. When augmenting benchmark datasets with\nsynthesized logs, we observe maximum F1-score improvements of 3.7% (average\n1.8% improvement across three state-of-the-art anomaly detection models). This\nwork not only establishes a high-quality benchmarking resource for automated\nlog analysis but also pioneers a new paradigm for applying large language\nmodels (LLMs) in software engineering workflows.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.12253v1","title":"Stability conditions on K3 surfaces via mass of spherical objects","summary":"We prove that a stability condition on a K3 surface is determined by the\nmasses of spherical objects up to a natural $\\mathbb{C}$-action. This is\nmotivated by the result of Huybrechts and the recent proposal of\nBapat-Deopurkar-Licata on the construction of a compactification of a stability\nmanifold. We also construct lax stability conditions in the sense of\nBroomhead-Pauksztello-Ploog-Woolf associated to spherical bundles.","main_category":"math.AG","categories":"math.AG,math.GT","published":"2025-04-16T17:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.12255v1","title":"Human Aligned Compression for Robust Models","summary":"Adversarial attacks on image models threaten system robustness by introducing\nimperceptible perturbations that cause incorrect predictions. We investigate\nhuman-aligned learned lossy compression as a defense mechanism, comparing two\nlearned models (HiFiC and ELIC) against traditional JPEG across various quality\nlevels. Our experiments on ImageNet subsets demonstrate that learned\ncompression methods outperform JPEG, particularly for Vision Transformer\narchitectures, by preserving semantically meaningful content while removing\nadversarial noise. Even in white-box settings where attackers can access the\ndefense, these methods maintain substantial effectiveness. We also show that\nsequential compression--applying rounds of\ncompression/decompression--significantly enhances defense efficacy while\nmaintaining classification performance. Our findings reveal that human-aligned\ncompression provides an effective, computationally efficient defense that\nprotects the image features most relevant to human and machine understanding.\nIt offers a practical approach to improving model robustness against\nadversarial threats.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T17:05:58Z"}
{"aid":"http://arxiv.org/abs/2504.12262v1","title":"SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via\n  Scalable Conditioned Neural Fields","summary":"Spatiotemporal learning is challenging due to the intricate interplay between\nspatial and temporal dependencies, the high dimensionality of the data, and\nscalability constraints. These challenges are further amplified in scientific\ndomains, where data is often irregularly distributed (e.g., missing values from\nsensor failures) and high-volume (e.g., high-fidelity simulations), posing\nadditional computational and modeling difficulties. In this paper, we present\nSCENT, a novel framework for scalable and continuity-informed spatiotemporal\nrepresentation learning. SCENT unifies interpolation, reconstruction, and\nforecasting within a single architecture. Built on a transformer-based\nencoder-processor-decoder backbone, SCENT introduces learnable queries to\nenhance generalization and a query-wise cross-attention mechanism to\neffectively capture multi-scale dependencies. To ensure scalability in both\ndata size and model complexity, we incorporate a sparse attention mechanism,\nenabling flexible output representations and efficient evaluation at arbitrary\nresolutions. We validate SCENT through extensive simulations and real-world\nexperiments, demonstrating state-of-the-art performance across multiple\nchallenging tasks while achieving superior scalability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T17:17:31Z"}
{"aid":"http://arxiv.org/abs/2504.12274v1","title":"Kernels for Storage Capacity and Dual Index Coding","summary":"The storage capacity of a graph measures the maximum amount of information\nthat can be stored across its vertices, such that the information at any vertex\ncan be recovered from the information stored at its neighborhood. The study of\nthis graph quantity is motivated by applications in distributed storage and by\nits intimate relations to the index coding problem from the area of network\ninformation theory. In the latter, one wishes to minimize the amount of\ninformation that has to be transmitted to a collection of receivers, in a way\nthat enables each of them to discover its required data using some prior side\ninformation.\n  In this paper, we initiate the study of the Storage Capacity and Index Coding\nproblems from the perspective of parameterized complexity. We prove that the\nStorage Capacity problem parameterized by the solution size admits a\nkernelization algorithm producing kernels of linear size. We also provide such\na result for the Index Coding problem, in the linear and non-linear settings,\nwhere it is parameterized by the dual value of the solution, i.e., the length\nof the transmission that can be saved using the side information. A key\ningredient in the proofs is the crown decomposition technique due to Chor,\nFellows, and Juedes (WG 2003, WG 2004). As an application, we significantly\nextend an algorithmic result of Dau, Skachek, and Chee (IEEE Trans. Inform.\nTheory, 2014).","main_category":"cs.DS","categories":"cs.DS,cs.IT,math.IT","published":"2025-04-16T17:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.12276v1","title":"The Tenth NTIRE 2025 Image Denoising Challenge Report","summary":"This paper presents an overview of the NTIRE 2025 Image Denoising Challenge\n({\\sigma} = 50), highlighting the proposed methodologies and corresponding\nresults. The primary objective is to develop a network architecture capable of\nachieving high-quality denoising performance, quantitatively evaluated using\nPSNR, without constraints on computational complexity or model size. The task\nassumes independent additive white Gaussian noise (AWGN) with a fixed noise\nlevel of 50. A total of 290 participants registered for the challenge, with 20\nteams successfully submitting valid results, providing insights into the\ncurrent state-of-the-art in image denoising.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.12279v1","title":"Dysarthria Normalization via Local Lie Group Transformations for Robust\n  ASR","summary":"We present a geometry-driven method for normalizing dysarthric speech using\nlocal Lie group transformations of spectrograms. Time, frequency, and amplitude\ndistortions are modeled as smooth, invertible deformations, parameterized by\nscalar fields and applied via exponential maps. A neural network is trained to\ninfer these fields from synthetic distortions of typical speech-without using\nany pathological data. At test time, the model applies an approximate inverse\nto real dysarthric inputs. Despite zero-shot generalization, we observe\nsubstantial ASR gains, including up to 16 percentage points WER reduction on\nchallenging TORGO samples, with no degradation on clean speech. This work\nintroduces a principled, interpretable approach for robust speech recognition\nunder motor speech disorders","main_category":"cs.SD","categories":"cs.SD,cs.CL,cs.LG,eess.AS","published":"2025-04-16T17:41:19Z"}
{"aid":"http://arxiv.org/abs/2504.12291v1","title":"Liouvillean Spectral Transition in Noisy Quantum Many-Body Scars","summary":"Understanding the behavior of quantum many-body systems under decoherence is\nessential for developing robust quantum technologies. Here, we examine the fate\nof weak ergodicity breaking in systems hosting quantum many-body scars when\nsubject to local pure dephasing -- an experimentally relevant form of\nenvironmental noise. Focusing on a large class of models with an approximate\nsu(2)-structured scar subspace, we show that scarred eigenmodes of the\nLiouvillean exhibit a transition reminiscent of spontaneous\n$\\mathbb{PT}$-symmetry breaking as the dephasing strength increases. Unlike\npreviously studied non-Hermitian mechanisms, this transition arises from a\ndistinct quantum jump effect. Remarkably, in platforms such as the XY spin\nladder and PXP model of Rydberg atom arrays, the critical dephasing rate shows\nonly weak dependence on system size, revealing an unexpected robustness of\nscarred dynamics in noisy quantum simulators.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-16T17:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.12297v1","title":"Optimal flock formation induced by agent heterogeneity","summary":"The study of flocking in biological systems has identified conditions for\nself-organized collective behavior, inspiring the development of decentralized\nstrategies to coordinate the dynamics of swarms of drones and other autonomous\nvehicles. Previous research has focused primarily on the role of the\ntime-varying interaction network among agents while assuming that the agents\nthemselves are identical or nearly identical. Here, we depart from this\nconventional assumption to investigate how inter-individual differences between\nagents affect the stability and convergence in flocking dynamics. We show that\nflocks of agents with optimally assigned heterogeneous parameters significantly\noutperform their homogeneous counterparts, achieving 20-40% faster convergence\nto desired formations across various control tasks. These tasks include target\ntracking, flock formation, and obstacle maneuvering. In systems with\ncommunication delays, heterogeneity can enable convergence even when flocking\nis unstable for identical agents. Our results challenge existing paradigms in\nmulti-agent control and establish system disorder as an adaptive, distributed\nmechanism to promote collective behavior in flocking dynamics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cs.SY,eess.SY,math.DS,math.OC,nlin.AO","published":"2025-04-16T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.12626v1","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video\n  Generation","summary":"We present a neural network structure, FramePack, to train next-frame (or\nnext-frame-section) prediction models for video generation. The FramePack\ncompresses input frames to make the transformer context length a fixed number\nregardless of the video length. As a result, we are able to process a large\nnumber of frames using video diffusion with computation bottleneck similar to\nimage diffusion. This also makes the training video batch sizes significantly\nhigher (batch sizes become comparable to image diffusion training). We also\npropose an anti-drifting sampling method that generates frames in inverted\ntemporal order with early-established endpoints to avoid exposure bias (error\naccumulation over iterations). Finally, we show that existing video diffusion\nmodels can be finetuned with FramePack, and their visual quality may be\nimproved because the next-frame prediction supports more balanced diffusion\nschedulers with less extreme flow shift timesteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T04:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.12654v1","title":"The Paradox of Professional Input: How Expert Collaboration with AI\n  Systems Shapes Their Future Value","summary":"This perspective paper examines a fundamental paradox in the relationship\nbetween professional expertise and artificial intelligence: as domain experts\nincreasingly collaborate with AI systems by externalizing their implicit\nknowledge, they potentially accelerate the automation of their own expertise.\nThrough analysis of multiple professional contexts, we identify emerging\npatterns in human-AI collaboration and propose frameworks for professionals to\nnavigate this evolving landscape. Drawing on research in knowledge management,\nexpertise studies, human-computer interaction, and labor economics, we develop\na nuanced understanding of how professional value may be preserved and\ntransformed in an era of increasingly capable AI systems. Our analysis suggests\nthat while the externalization of tacit knowledge presents certain risks to\ntraditional professional roles, it also creates opportunities for the evolution\nof expertise and the emergence of new forms of professional value. We conclude\nwith implications for professional education, organizational design, and policy\ndevelopment that can help ensure the codification of expert knowledge enhances\nrather than diminishes the value of human expertise.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-17T05:32:21Z"}
{"aid":"http://arxiv.org/abs/2504.12662v1","title":"Flat Circular Velocities on a megaparsec scale from the $Î›$CDM\n  model","summary":"A recent study using weak gravitational lensing reveals that there are some\nisolated galaxies having almost flat rotation curves at very large distance\nfrom the galactic centres. According to the authors of the study this provides\na strong challenge the standard cold dark matter model, since the dark haloes\nare too small to explain their observations, especially for small stellar\nmasses. In this article, we show that improving their model, the virial radius\nis larger than their estimates. The NFW rotational curve, and especially the\npseudo Isothermal one, are in agreement with their flat rotational curves,\nespecially for the larger baryonic mass bins used by the authors.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T05:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.12672v1","title":"Post-processing improves accuracy of Artificial Intelligence weather\n  forecasts","summary":"Artificial Intelligence (AI) weather models are now reaching\noperational-grade performance for some variables, but like traditional\nNumerical Weather Prediction (NWP) models, they exhibit systematic biases and\nreliability issues. We test the application of the Bureau of Meteorology's\nexisting statistical post-processing system, IMPROVER, to ECMWF's deterministic\nArtificial Intelligence Forecasting System (AIFS), and compare results against\npost-processed outputs from the ECMWF HRES and ENS models. Without any\nmodification to configuration or processing workflows, post-processing yields\ncomparable accuracy improvements for AIFS as for traditional NWP forecasts, in\nboth expected value and probabilistic outputs. We show that blending AIFS with\nNWP models improves overall forecast skill, even when AIFS alone is not the\nmost accurate component. These findings show that statistical post-processing\nmethods developed for NWP are directly applicable to AI models, enabling\nnational meteorological centres to incorporate AI forecasts into existing\nworkflows in a low-risk, incremental fashion.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.AI,cs.LG","published":"2025-04-17T06:05:10Z"}
{"aid":"http://arxiv.org/abs/2504.12684v1","title":"SOPHY: Generating Simulation-Ready Objects with Physical Materials","summary":"We present SOPHY, a generative model for 3D physics-aware shape synthesis.\nUnlike existing 3D generative models that focus solely on static geometry or 4D\nmodels that produce physics-agnostic animations, our approach jointly\nsynthesizes shape, texture, and material properties related to physics-grounded\ndynamics, making the generated objects ready for simulations and interactive,\ndynamic environments. To train our model, we introduce a dataset of 3D objects\nannotated with detailed physical material attributes, along with an annotation\npipeline for efficient material annotation. Our method enables applications\nsuch as text-driven generation of interactive, physics-aware 3D objects and\nsingle-image reconstruction of physically plausible shapes. Furthermore, our\nexperiments demonstrate that jointly modeling shape and material properties\nenhances the realism and fidelity of generated shapes, improving performance on\ngenerative geometry evaluation metrics.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T06:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12697v1","title":"The Theory Of Auxiliary Weierstrassian Zeta Functions And Zeta\n  Differences","summary":"In this paper, we expand the theory of Weierstrassian elliptic functions by\nintroducing auxiliary zeta functions $\\zeta_\\lambda$, zeta differences of first\nkind $\\Delta_\\lambda$ and second kind $\\Delta_{\\lambda,\\mu}$ where\n$\\lambda,\\mu=1,2,3$. Fundamental and novel results pertaining to these\nfunctions are proven. Furthermore, results already existing in the literature\nare translated in terms of auxiliary zeta functions. Their relationship to\nJacobian elliptic functions and Jacobian functions are given.","main_category":"math.CV","categories":"math.CV,math.NT","published":"2025-04-17T06:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12705v1","title":"7-Methylquinolinium Iodobismuthate Memristor: Exploring Plasticity and\n  Memristive Properties for Digit Classification in Physical Reservoir\n  Computing","summary":"This study investigates 7-methylquinolinium halobismuthates (I, Br, and Cl)\nin two aspects: (1) their structural and semiconducting properties influenced\nby anionic composition, and (2) their memristive and plasticity characteristics\nfor neuromorphic and reservoir computing applications. Structural changes\ninduced by halides form low-dimensional halobismuthate fragments, confirmed by\ncrystallographic analysis. Optical band gaps were studied using diffuse\nreflectance spectroscopy, aligning with density functional theory results. Due\nto solubility limitations, only bismuth iodide complexes were explored in\nelectronic devices. Current-voltage scans showed pinched hysteresis loops,\ncharacteristic of memristors. Conductivity versus temperature study indicates\ncombined ionic and electronic contributions to conductivity of the devices.\nGiven that a memristor can function as a single synapse without the need for\nprogramming, aligning with the requirements of neuromorphic computing, the\nstudy investigated long-term depression, potentiation, and spike-time-dependent\nplasticity. As the potentiation-depression plots showed non-linearity with\nfading memory, these materials can be a good candidate for application in\nphysical reservoir computing. To further assess this material, an electronic\ndevice with sixteen gold electrodes was applied, featuring one input and 15\noutput electrodes deposited on silicon substrate and covered with a layer of\nstudied compound. Basic test to assess the complexity and non-linearity of the\ndevices were conducted through a series of benchmark tasks, including waveform\ngeneration, NARMA-2, memory capacity assessment, and noise study under both DC\nand AC current. The ability of device in MNIST digit classification with 82.26%\naccuracy and voice classification for digit 2 for six different people with 82\n% accuracy has been demonstrated.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-17T07:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.12709v1","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\n  Autonomous Driving","summary":"The significant achievements of pre-trained models leveraging large volumes\nof data in the field of NLP and 2D vision inspire us to explore the potential\nof extensive data pre-training for 3D perception in autonomous driving. Toward\nthis goal, this paper proposes to utilize massive unlabeled data from\nheterogeneous datasets to pre-train 3D perception models. We introduce a\nself-supervised pre-training framework that learns effective 3D representations\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\nadaptation strategy to reduce dataset bias. The approach significantly improves\nmodel performance on downstream tasks such as 3D object detection, BEV\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\nperformance increase as the training data volume scales up, demonstrating the\npotential of continually benefit 3D perception models for autonomous driving.\nWe will release the source code to inspire further investigations in the\ncommunity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T07:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.12734v1","title":"Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning\n  Across Diverse Structured Knowledge","summary":"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language\nquestions (NLQs) by using structured sources such as tables, databases, and\nknowledge graphs in a unified way. Existing USKR methods either rely on\nemploying task-specific strategies or custom-defined representations, which\nstruggle to leverage the knowledge transfer between different SKR tasks or\nalign with the prior of LLMs, thereby limiting their performance. This paper\nproposes a novel USKR framework named \\textsc{Pandora}, which takes advantage\nof \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge\nrepresentation for alignment with LLM pre-training. It employs an LLM to\ngenerate textual reasoning steps and executable Python code for each question.\nDemonstrations are drawn from a memory of training examples that cover various\nSKR tasks, facilitating knowledge transfer. Extensive experiments on four\nbenchmarks involving three SKR tasks demonstrate that \\textsc{Pandora}\noutperforms existing unified frameworks and competes effectively with\ntask-specific methods.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.12742v1","title":"Decentralized Nonconvex Composite Federated Learning with Gradient\n  Tracking and Momentum","summary":"Decentralized Federated Learning (DFL) eliminates the reliance on the\nserver-client architecture inherent in traditional federated learning,\nattracting significant research interest in recent years. Simultaneously, the\nobjective functions in machine learning tasks are often nonconvex and\nfrequently incorporate additional, potentially nonsmooth regularization terms\nto satisfy practical requirements, thereby forming nonconvex composite\noptimization problems. Employing DFL methods to solve such general optimization\nproblems leads to the formulation of Decentralized Nonconvex Composite\nFederated Learning (DNCFL), a topic that remains largely underexplored. In this\npaper, we propose a novel DNCFL algorithm, termed \\bf{DEPOSITUM}. Built upon\nproximal stochastic gradient tracking, DEPOSITUM mitigates the impact of data\nheterogeneity by enabling clients to approximate the global gradient. The\nintroduction of momentums in the proximal gradient descent step, replacing\ntracking variables, reduces the variance introduced by stochastic gradients.\nAdditionally, DEPOSITUM supports local updates of client variables,\nsignificantly reducing communication costs. Theoretical analysis demonstrates\nthat DEPOSITUM achieves an expected $\\epsilon$-stationary point with an\niteration complexity of $\\mathcal{O}(1/\\epsilon^2)$. The proximal gradient,\nconsensus errors, and gradient estimation errors decrease at a sublinear rate\nof $\\mathcal{O}(1/T)$. With appropriate parameter selection, the algorithm\nachieves network-independent linear speedup without requiring mega-batch\nsampling. Finally, we apply DEPOSITUM to the training of neural networks on\nreal-world datasets, systematically examining the influence of various\nhyperparameters on its performance. Comparisons with other federated composite\noptimization algorithms validate the effectiveness of the proposed method.","main_category":"cs.LG","categories":"cs.LG,cs.DC,math.OC","published":"2025-04-17T08:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.12752v1","title":"Model calculations of the strains associated with surface acoustic waves","summary":"Magnon-phonon coupling has garnered increasing interest in condensed matter\nphysics due to its fertile physics and potential applications in devices with\nnovel functionalities. Surface acoustic waves (SAWs) are commonly employed as a\nsource of coherent acoustic phonons. The strain associated with SAWs couples to\nmagnetization of magnetic materials via magnetoelastic coupling and/or\nspin-rotation coupling. A typical SAW device is formed on a piezoelectric\nsubstrate with anisotropic crystal structure. Since the form of strain depends\non the material parameters and structure of the SAW device, it is of vital\nimportance to understand its character. In this paper, we present a\ncomprehensive methodology to numerically calculate the SAW velocity, SAW\nexcitation efficiency, lattice displacement and all strain components\nassociated with SAW. LiNbO$_3$ is used as a prototypical material system. All\nquantities depend on the SAW propagation direction with respect to the\ncrystalline axis and on the electrical boundary conditions. In contrast to\nnon-piezoelectric isotropic media, we find that all shear strain components can\nbe induced in LiNbO$_3$, with their amplitude and relative phase (with respect\nto the longitudinal strain) dependent on the propagation direction and the\nboundary conditions at the LiNbO$_3$ surface. These results offer a robust\nfoundation for analyzing strain-driven magnon-phonon coupling mechanisms and\ncontribute to designing strain-engineered functional magnonic and phononic\ndevices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T08:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.12768v1","title":"Self-consistent random phase approximation and optimized hybrid\n  functionals for solids","summary":"The random phase approximation (RPA) and the $GW$ approximation share the\nsame total energy functional but RPA is defined on a restricted domain of\nGreen's functions determined by a local Kohn-Sham (KS) potential. In this work,\nwe perform self-consistent RPA calculations by optimizing the local KS\npotential through the optimized effective potential equation. We study a number\nof solids (C, Si, BN, LiF, MgO, TiO$_2$), and find in all cases a lowering of\nthe total energy with respect to non-self-consistent RPA. We then propose a\nvariational approach to optimize PBE0-type hybrid functionals based on the\nminimization of the RPA total energy with respect to the fraction of exact\nexchange used to generate the input KS orbitals. We show that this scheme leads\nto hybrid functionals with a KS band structure in close agreement with RPA, and\nwith lattice constants of similar accuracy as within RPA. Finally, we evaluate\n$G_0W_0$ gaps using RPA and hybrid KS potentials as starting points. Special\nattention is given to TiO$_2$, which exhibits a strong starting-point\ndependence.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T09:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.12769v1","title":"On Error Classification from Physiological Signals within Airborne\n  Environment","summary":"Human error remains a critical concern in aviation safety, contributing to\n70-80% of accidents despite technological advancements. While physiological\nmeasures show promise for error detection in laboratory settings, their\neffectiveness in dynamic flight environments remains underexplored. Through\nlive flight trials with nine commercial pilots, we investigated whether\nestablished error-detection approaches maintain accuracy during actual flight\noperations. Participants completed standardized multi-tasking scenarios across\nconditions ranging from laboratory settings to straight-and-level flight and 2G\nmanoeuvres while we collected synchronized physiological data. Our findings\ndemonstrate that EEG-based classification maintains high accuracy (87.83%)\nduring complex flight manoeuvres, comparable to laboratory performance\n(89.23%). Eye-tracking showed moderate performance (82.50\\%), while ECG\nperformed near chance level (51.50%). Classification accuracy remained stable\nacross flight conditions, with minimal degradation during 2G manoeuvres. These\nresults provide the first evidence that physiological error detection can\ntranslate effectively to operational aviation environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.12778v1","title":"Towards Lossless Token Pruning in Late-Interaction Retrieval Models","summary":"Late interaction neural IR models like ColBERT offer a competitive\neffectiveness-efficiency trade-off across many benchmarks. However, they\nrequire a huge memory space to store the contextual representation for all the\ndocument tokens. Some works have proposed using either heuristics or\nstatistical-based techniques to prune tokens from each document. This however\ndoesn't guarantee that the removed tokens have no impact on the retrieval\nscore. Our work uses a principled approach to define how to prune tokens\nwithout impacting the score between a document and a query. We introduce three\nregularization losses, that induce a solution with high pruning ratios, as well\nas two pruning strategies. We study them experimentally (in and out-domain),\nshowing that we can preserve ColBERT's performance while using only 30\\% of the\ntokens.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T09:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.12779v1","title":"Crossover in Electronic Specific Heat near Narrow-Sense Type-III Dirac\n  Cones","summary":"Two-dimensional massless Dirac fermions exhibit Dirac cones, which are\nclassified into three types: type-I, type-II, and type-III. In both type-I and\ntype-II cones, the energy dispersion is linear in all momentum directions.\nType-I cones are characterized by a non-overtilted structure, where the Dirac\npoint serves as a local minimum (maximum) for the upper (lower) band. In\ncontrast, type-II cones exhibit overtilted dispersions, leading to the\ncoexistence of electron and hole pockets. At the critical tilt, the linear\nenergy dispersion vanishes in one momentum direction, corresponding to a\ntype-III Dirac cone. We further define a special case, termed the\n\"narrow-sense\" type-III cone, where not only the linear term but also quadratic\nand higher-order terms vanish, resulting in a completely flat dispersion along\none direction. In this work, we numerically investigate the temperature ($T$)\n-dependence of the electronic specific heat ($C$), as the Dirac cone is\ncontinuously tilted from type-I to narrow-sense type-III. A model with\nparticle-hole symmetry is employed to ensure that the chemical potential\n($\\mu$) remains temperature independent. Our results reveal a notable crossover\nin $C$ near narrow-sense type-III, where $C$ changes from $C \\propto T^{2}$\nbelow the crossover temperature ($T_{\\rm co}$) to $C \\propto T^{\\frac{1}{2}}$\nabove $T_{\\rm co}$. This crossover is attributed to the energy-dependent\nstructure of the density of states. The present findings suggest a feasible\napproach for experimentally probing the degree of Dirac cone tilting near the\nnarrow-sense type-III limit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-17T09:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.12789v1","title":"Enumeration of cube-free groups and counting certain types of split\n  extensions","summary":"A group is said to be cube-free if its order is not divisible by the cube of\nany prime. Let $f_{cf,sol}(n)$ denote the isomorphism classes of solvable\ncube-free groups of order $n$. We find asymptotic bounds for $f_{cf,sol}(n)$ in\nthis paper. Let $p$ be a prime and let $q = p^k$ for some positive integer $k$.\nWe also give a formula for the number of conjugacy classes of the subgroups\nthat are maximal amongst non-abelian solvable cube-free $p'$-subgroups of ${\\rm\nGL}(2,q)$. Further, we find the exact number of split extensions of $P$ by $Q$\nup to isomorphism of a given order where $P \\in \\{{\\mathbb Z}_p \\times {\\mathbb\nZ}_p, {\\mathbb Z}_{p^{\\alpha}}\\}$, $p$ is a prime, $\\alpha$ is a positive\ninteger and $Q$ is a cube-free abelian group of odd order such that $p \\nmid\n|Q|$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.12795v1","title":"EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand\n  Multi-Source Remote Sensing Imagery","summary":"Recent advances in the visual-language area have developed natural\nmulti-modal large language models (MLLMs) for spatial reasoning through visual\nprompting. However, due to remote sensing (RS) imagery containing abundant\ngeospatial information that differs from natural images, it is challenging to\neffectively adapt natural spatial models to the RS domain. Moreover, current RS\nMLLMs are limited in overly narrow interpretation levels and interaction\nmanner, hindering their applicability in real-world scenarios. To address those\nchallenges, a spatial MLLM named EarthGPT-X is proposed, enabling a\ncomprehensive understanding of multi-source RS imagery, such as optical,\nsynthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and\nzoom-out insight, and possesses flexible multi-grained interactive abilities.\nMoreover, EarthGPT-X unifies two types of critical spatial tasks (i.e.,\nreferring and grounding) into a visual prompting framework. To achieve these\nversatile capabilities, several key strategies are developed. The first is the\nmulti-modal content integration method, which enhances the interplay between\nimages, visual prompts, and text instructions. Subsequently, a cross-domain\none-stage fusion training strategy is proposed, utilizing the large language\nmodel (LLM) as a unified interface for multi-source multi-task learning.\nFurthermore, by incorporating a pixel perception module, the referring and\ngrounding tasks are seamlessly unified within a single framework. In addition,\nthe experiments conducted demonstrate the superiority of the proposed\nEarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal\ninteraction, revealing significant advancements of MLLM in the RS field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T09:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.12796v1","title":"A Survey on Cross-Modal Interaction Between Music and Multimodal Data","summary":"Multimodal learning has driven innovation across various industries,\nparticularly in the field of music. By enabling more intuitive interaction\nexperiences and enhancing immersion, it not only lowers the entry barriers to\nthe music but also increases its overall appeal. This survey aims to provide a\ncomprehensive review of multimodal tasks related to music, outlining how music\ncontributes to multimodal learning and offering insights for researchers\nseeking to expand the boundaries of computational music. Unlike text and\nimages, which are often semantically or visually intuitive, music primarily\ninteracts with humans through auditory perception, making its data\nrepresentation inherently less intuitive. Therefore, this paper first\nintroduces the representations of music and provides an overview of music\ndatasets. Subsequently, we categorize cross-modal interactions between music\nand multimodal data into three types: music-driven cross-modal interactions,\nmusic-oriented cross-modal interactions, and bidirectional music cross-modal\ninteractions. For each category, we systematically trace the development of\nrelevant sub-tasks, analyze existing limitations, and discuss emerging trends.\nFurthermore, we provide a comprehensive summary of datasets and evaluation\nmetrics used in multimodal tasks related to music, offering benchmark\nreferences for future research. Finally, we discuss the current challenges in\ncross-modal interactions involving music and propose potential directions for\nfuture research.","main_category":"cs.MM","categories":"cs.MM,cs.SD,eess.AS","published":"2025-04-17T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.12831v1","title":"Long-wavelength optical lattices from optical beatnotes: theory and\n  applications","summary":"We present a theoretical analysis of Beat-Note Superlattices (BNSLs), a\nrecently demonstrated technique for generating periodic trapping potentials for\nultracold atomic clouds, with arbitrarily large lattice spacings while\nmaintaining interferometric stability. By combining two optical lattices with\nslightly different wavelengths, a beatnote intensity pattern is formed,\ngenerating, for low depths, an effective lattice potential with a periodicity\nequal to the wavelength associated to the difference between the wavevectors of\nthe two lattices. We study the range of lattice depths and wavelengths under\nwhich this approximation is valid and investigate its robustness against\nperturbations. We present a few examples where the use of BNSLs could offer\nsignificant advantages in comparison to well established techniques for the\nmanipulation of ultracold atomic gases. Our results highlight the potential of\nBNSLs for quantum simulation, atom interferometry, and other applications in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-17T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.12844v1","title":"High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion","summary":"Generative Adversarial Network (GAN) inversion have demonstrated excellent\nperformance in image inpainting that aims to restore lost or damaged image\ntexture using its unmasked content. Previous GAN inversion-based methods\nusually utilize well-trained GAN models as effective priors to generate the\nrealistic regions for missing holes. Despite excellence, they ignore a hard\nconstraint that the unmasked regions in the input and the output should be the\nsame, resulting in a gap between GAN inversion and image inpainting and thus\ndegrading the performance. Besides, existing GAN inversion approaches often\nconsider a single modality of the input image, neglecting other auxiliary cues\nin images for improvements. Addressing these problems, we propose a novel GAN\ninversion approach, dubbed MMInvertFill, for image inpainting. MMInvertFill\ncontains primarily a multimodal guided encoder with a pre-modulation and a GAN\ngenerator with F&W+ latent space. Specifically, the multimodal encoder aims to\nenhance the multi-scale structures with additional semantic segmentation edge\ntexture modalities through a gated mask-aware attention module. Afterwards, a\npre-modulation is presented to encode these structures into style vectors. To\nmitigate issues of conspicuous color discrepancy and semantic inconsistency, we\nintroduce the F&W+ latent space to bridge the gap between GAN inversion and\nimage inpainting. Furthermore, in order to reconstruct faithful and\nphotorealistic images, we devise a simple yet effective Soft-update Mean Latent\nmodule to capture more diversified in-domain patterns for generating\nhigh-fidelity textures for massive corruptions. In our extensive experiments on\nsix challenging datasets, we show that our MMInvertFill qualitatively and\nquantitatively outperforms other state-of-the-arts and it supports the\ncompletion of out-of-domain images effectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.12853v1","title":"A scaling relation of vortex-induced rectification effects in a\n  superconducting thin-film heterostructure","summary":"Supercurrent rectification, nonreciprocal response of superconducting\nproperties sensitive to the polarity of bias and magnetic field, has attracted\ngrowing interest as an ideal diode. While the superconducting rectification\neffect is a consequence of the asymmetric vortex pinning, the mechanisms to\ndevelop its asymmetric potentials have been a subject of ongoing debate, mainly\nfocusing on microscopic breaking of spatial inversion symmetry and macroscopic\nimbalance of the sample structure. Here, we report on comparative study of the\nsuperconducting diode effect and nonreciprocal resistance in a superconducting\nFe(Se,Te)/FeTe heterostructure. In normal state, we observe finite\nnonreciprocal resistance as a hallmark of the spin-orbit interaction with\nstructural inversion asymmetry. In the superconducting state, we find that the\nstrongly enhanced nonreciprocal coefficient in transition regime is directly\ncoupled to the superconducting diode efficiency through a universal scaling\nlaw, indicating the role of spin-momentum-locked state on the asymmetric\npinning potential. Our findings, providing a unified picture of the\nsuperconducting rectification, pave the way for functionalizing superconducting\ndiode devices.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-17T11:20:04Z"}
{"aid":"http://arxiv.org/abs/2504.12856v1","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","summary":"Large pretrained vision foundation models have shown significant potential in\nvarious vision tasks. However, for industrial anomaly detection, the scarcity\nof real defect samples poses a critical challenge in leveraging these models.\nWhile 2D anomaly generation has significantly advanced with established\ngenerative models, the adoption of 3D sensors in industrial manufacturing has\nmade leveraging 3D data for surface quality inspection an emerging trend. In\ncontrast to 2D techniques, 3D anomaly generation remains largely unexplored,\nlimiting the potential of 3D data in industrial quality inspection. To address\nthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,\nbased on Perlin noise and surface parameterization. Our method generates\nrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,\nsampling multi-scale noise values from a Perlin noise field, and perturbing the\npoint cloud along its normal direction. Through comprehensive visualization\nexperiments, we demonstrate how key parameters - including noise scale,\nperturbation strength, and octaves, provide fine-grained control over the\ngenerated anomalies, enabling the creation of diverse defect patterns from\npronounced deformations to subtle surface variations. Additionally, our\ncross-category experiments show that the method produces consistent yet\ngeometrically plausible anomalies across different object types, adapting to\ntheir specific surface characteristics. We also provide a comprehensive\ncodebase and visualization toolkit to facilitate future research.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO,I.5.4","published":"2025-04-17T11:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12860v1","title":"When do Random Forests work?","summary":"We study the effectiveness of randomizing split-directions in random forests.\nPrior literature has shown that, on the one hand, randomization can reduce\nvariance through decorrelation, and, on the other hand, randomization\nregularizes and works in low signal-to-noise ratio (SNR) environments. First,\nwe bring together and revisit decorrelation and regularization by presenting a\nsystematic analysis of out-of-sample mean-squared error (MSE) for different SNR\nscenarios based on commonly-used data-generating processes. We find that\nvariance reduction tends to increase with the SNR and forests outperform\nbagging when the SNR is low because, in low SNR cases, variance dominates bias\nfor both methods. Second, we show that the effectiveness of randomization is a\nquestion that goes beyond the SNR. We present a simulation study with fixed and\nmoderate SNR, in which we examine the effectiveness of randomization for other\ndata characteristics. In particular, we find that (i) randomization can\nincrease bias in the presence of fat tails in the distribution of covariates;\n(ii) in the presence of irrelevant covariates randomization is ineffective\nbecause bias dominates variance; and (iii) when covariates are mutually\ncorrelated randomization tends to be effective because variance dominates bias.\nBeyond randomization, we find that, for both bagging and random forests, bias\ncan be significantly reduced in the presence of correlated covariates. This\nlast finding goes beyond the prevailing view that averaging mostly works by\nvariance reduction. Given that in practice covariates are often correlated, our\nfindings on correlated covariates could open the way for a better understanding\nof why random forests work well in many applications.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T11:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.12868v1","title":"Computer-Aided Design of Personalized Occlusal Positioning Splints Using\n  Multimodal 3D Data","summary":"Contemporary digital technology has a pivotal role in the design of\ncustomized medical appliances, including occlusal splints used in the treatment\nof stomatognathic system dysfunctions. We present an approach to computer-aided\ndesign and precision assessment of positioning occlusal splints, bridging\nclinical concepts with current digital dental practice. In our model, a 3D\nsplint is generated based on a transformation matrix that represents the\ntherapeutic change in mandibular position, defined by a specialist using a\nvirtual patient model reconstructed from intraoral scans, CBCT, 3D facial scans\nand plaster model digitisation. The paper introduces a novel method for\ngenerating splints that accurately reproduce occlusal conditions in the\ntherapeutic position, including a mechanism for resolving surface conflicts\nthrough virtual embossing. We demonstrate how transformation matrices can be\nacquired through clinical tools and intraoral devices, and evaluate the\naccuracy of the designed and printed splints using profile and surface\ndeviation analysis. The proposed method enables reproducible, patient-specific\nsplint fabrication and opens new possibilities in diagnostics, multimodal image\nregistration and quantification of occlusal discrepancies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.12869v1","title":"SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation\n  Framework for Visible and Thermal Image Registration","summary":"Multispectral imaging plays a critical role in a range of intelligent\ntransportation applications, including advanced driver assistance systems\n(ADAS), traffic monitoring, and night vision. However, accurate visible and\nthermal (RGB-T) image registration poses a significant challenge due to the\nconsiderable modality differences. In this paper, we present a novel joint\nSelf-Correlation and Cross-Correspondence Estimation Framework (SC3EF),\nleveraging both local representative features and global contextual cues to\neffectively generate RGB-T correspondences. For this purpose, we design a\nconvolution-transformer-based pipeline to extract local representative features\nand encode global correlations of intra-modality for inter-modality\ncorrespondence estimation between unaligned visible and thermal images. After\nmerging the local and global correspondence estimation results, we further\nemploy a hierarchical optical flow estimation decoder to progressively refine\nthe estimated dense correspondence maps. Extensive experiments demonstrate the\neffectiveness of our proposed method, outperforming the current\nstate-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore,\nit also shows competitive generalization capabilities across challenging\nscenarios, including large parallax, severe occlusions, adverse weather, and\nother cross-modal datasets (e.g., RGB-N and RGB-D).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:54:12Z"}
{"aid":"http://arxiv.org/abs/2504.12874v1","title":"Homomorphisms with semilocal endomorphism rings between modules","summary":"We study the category $\\operatorname{Morph}(\\operatorname{Mod} R)$ whose\nobjects are all morphisms between two right $R$-modules. The behavior of\nobjects of $\\operatorname{Morph}(\\operatorname{Mod} R)$ whose endomorphism ring\nin $\\operatorname{Morph}(\\operatorname{Mod} R)$ is semilocal is very similar to\nthe behavior of modules with a semilocal endomorphism ring. For instance,\ndirect-sum decompositions of a direct sum $\\oplus_{i=1}^nM_i$, that is,\nblock-diagonal decompositions, where each object $M_i$ of\n$\\operatorname{Morph}(\\operatorname{Mod} R)$ denotes a morphism\n$\\mu_{M_i}\\colon M_{0,i}\\to M_{1,i}$ and where all the modules $M_{j,i}$ have a\nlocal endomorphism ring $\\operatorname{End}(M_{j,i})$, depend on two\ninvariants. This behavior is very similar to that of direct-sum decompositions\nof serial modules of finite Goldie dimension, which also depend on two\ninvariants (monogeny class and epigeny class). When all the modules $M_{j,i}$\nare uniserial modules, the direct-sum decompositions (block-diagonal\ndecompositions) of a direct-sum $\\oplus_{i=1}^nM_i$ depend on four invariants.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T12:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.12878v1","title":"Frustrated kagome-lattice bilayer quantum Heisenberg antiferromagnet","summary":"We consider the $S=1/2$ antiferromagnetic Heisenberg model on a frustrated\nkagome-lattice bilayer with strong nearest-neighbor interlayer coupling and\nexamine its low-temperature magnetothermodynamics using a mapping onto a rhombi\ngas on the kagome lattice. Besides, we use finite-size numerics to illustrate\nthe validity of the classical lattice-gas description. Among our findings there\nare i) the absence of an order-disorder phase transition and ii) the\nsensitivity of the specific heat at low temperatures to the shape of the system\njust below the saturation magnetic field even in the thermodynamic limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-17T12:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.12911v1","title":"Benchmarking Multi-National Value Alignment for Large Language Models","summary":"Do Large Language Models (LLMs) hold positions that conflict with your\ncountry's values? Occasionally they do! However, existing works primarily focus\non ethical reviews, failing to capture the diversity of national values, which\nencompass broader policy, legal, and moral considerations. Furthermore, current\nbenchmarks that rely on spectrum tests using manually designed questionnaires\nare not easily scalable.\n  To address these limitations, we introduce NaVAB, a comprehensive benchmark\nto evaluate the alignment of LLMs with the values of five major nations: China,\nthe United States, the United Kingdom, France, and Germany. NaVAB implements a\nnational value extraction pipeline to efficiently construct value assessment\ndatasets. Specifically, we propose a modeling procedure with instruction\ntagging to process raw data sources, a screening process to filter\nvalue-related topics and a generation process with a Conflict Reduction\nmechanism to filter non-conflicting values.We conduct extensive experiments on\nvarious LLMs across countries, and the results provide insights into assisting\nin the identification of misaligned scenarios. Moreover, we demonstrate that\nNaVAB can be combined with alignment techniques to effectively reduce value\nconcerns by aligning LLMs' values with the target country.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T13:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.12920v1","title":"CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective\n  Embedding-Based Retrieval","summary":"Multi-objective embedding-based retrieval (EBR) has become increasingly\ncritical due to the growing complexity of user behaviors and commercial\nobjectives. While traditional approaches often suffer from data sparsity and\nlimited information sharing between objectives, recent methods utilizing a\nshared network alongside dedicated sub-networks for each objective partially\naddress these limitations. However, such methods significantly increase the\nmodel parameters, leading to an increased retrieval latency and a limited\nability to model causal relationships between objectives. To address these\nchallenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel\nmethod that enhances both retrieval efficiency and serving performance for\nmulti-objective EBR. The CSMF framework selectively masks model parameters to\nfree up independent learning space for each objective, leveraging the cascading\nrelationships between objectives during the sequential fine-tuning. Without\nincreasing network parameters or online retrieval overhead, CSMF computes a\nlinearly weighted fusion score for multiple objective probabilities while\nsupporting flexible adjustment of each objective's weight across various\nrecommendation scenarios. Experimental results on real-world datasets\ndemonstrate the superior performance of CSMF, and online experiments validate\nits significant practical value.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-17T13:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.12949v1","title":"RL-PINNs: Reinforcement Learning-Driven Adaptive Sampling for Efficient\n  Training of PINNs","summary":"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs). However, their performance\nheavily relies on the strategy used to select training points. Conventional\nadaptive sampling methods, such as residual-based refinement, often require\nmulti-round sampling and repeated retraining of PINNs, leading to computational\ninefficiency due to redundant points and costly gradient\ncomputations-particularly in high-dimensional or high-order derivative\nscenarios. To address these limitations, we propose RL-PINNs, a reinforcement\nlearning(RL)-driven adaptive sampling framework that enables efficient training\nwith only a single round of sampling. Our approach formulates adaptive sampling\nas a Markov decision process, where an RL agent dynamically selects optimal\ntraining points by maximizing a long-term utility metric. Critically, we\nreplace gradient-dependent residual metrics with a computationally efficient\nfunction variation as the reward signal, eliminating the overhead of derivative\ncalculations. Furthermore, we employ a delayed reward mechanism to prioritize\nlong-term training stability over short-term gains. Extensive experiments\nacross diverse PDE benchmarks, including low-regular, nonlinear,\nhigh-dimensional, and high-order problems, demonstrate that RL-PINNs\nsignificantly outperforms existing residual-driven adaptive methods in\naccuracy. Notably, RL-PINNs achieve this with negligible sampling overhead,\nmaking them scalable to high-dimensional and high-order problems.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-17T13:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12956v1","title":"Optic Fingerprint(OFP): Enhancing Security in Li-Fi Networks","summary":"We present a hardware-integrated security framework for LiFi networks through\ndevice fingerprint extraction within the IEEE 802.15.7 protocol. Our Optic\nFingerprint (OFP) model utilizes inherent LED nonlinearities to generate\namplitude-based feature vectors in time and frequency domains, specifically\ndesigned for optical wireless systems. Experimental results with 39 commercial\nLEDs demonstrate 90.36% classification accuracy across SNR 10-30 dB while\nmaintaining standard compliance, offering a practical physical-layer\nauthentication solution for visible light communication.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.12981v1","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model\n  in Magnetic Particle Imaging","summary":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of\nreal-time, high-sensitivity mapping of superparamagnetic iron oxide\nnanoparticles. Model-based image reconstruction provides an alternative to\nconventional methods that rely on a measured system matrix, eliminating the\nneed for laborious calibration measurements. Nevertheless, model-based\napproaches must account for the complexities of the imaging chain to maintain\nhigh image quality. A recently proposed direct reconstruction method leverages\nweighted Chebyshev polynomials in the frequency domain, removing the need for a\nsimulated system matrix. However, the underlying model neglects key physical\neffects, such as nanoparticle anisotropy, leading to distortions in\nreconstructed images. To mitigate these artifacts, an adapted direct Chebyshev\nreconstruction (DCR) method incorporates a spatially variant deconvolution\nstep, significantly improving reconstruction accuracy at the cost of increased\ncomputational demands. In this work, we evaluate the adapted DCR on six\nexperimental phantoms, demonstrating enhanced reconstruction quality in real\nmeasurements and achieving image fidelity comparable to or exceeding that of\nsimulated system matrix reconstruction. Furthermore, we introduce an efficient\napproximation for the spatially variable deconvolution, reducing both runtime\nand memory consumption while maintaining accuracy. This method achieves\ncomputational complexity of O(N log N ), making it particularly beneficial for\nhigh-resolution and three-dimensional imaging. Our results highlight the\npotential of the adapted DCR approach for improving model-based MPI\nreconstruction in practical applications.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,eess.IV,math.NA","published":"2025-04-17T14:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.12988v1","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to a Set\n  of Experts","summary":"Learning-to-Defer (L2D) enables decision-making systems to improve\nreliability by selectively deferring uncertain predictions to more competent\nagents. However, most existing approaches focus exclusively on single-agent\ndeferral, which is often inadequate in high-stakes scenarios that require\ncollective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of\nthe classical two-stage L2D framework that allocates each query to the $k$ most\nconfident agents instead of a single one. To further enhance flexibility and\ncost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive\nextension that learns the optimal number of agents to consult for each query,\nbased on input complexity, agent competency distributions, and consultation\ncosts. For both settings, we derive a novel surrogate loss and prove that it is\nBayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring\nconvergence to the Bayes-optimal allocation. Notably, we show that the\nwell-established model cascades paradigm arises as a restricted instance of our\nTop-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse\nbenchmarks demonstrate the effectiveness of our framework on both\nclassification and regression tasks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-17T14:50:40Z"}
{"aid":"http://arxiv.org/abs/2504.12989v1","title":"Query Complexity of Classical and Quantum Channel Discrimination","summary":"Quantum channel discrimination has been studied from an information-theoretic\nperspective, wherein one is interested in the optimal decay rate of error\nprobabilities as a function of the number of unknown channel accesses. In this\npaper, we study the query complexity of quantum channel discrimination, wherein\nthe goal is to determine the minimum number of channel uses needed to reach a\ndesired error probability. To this end, we show that the query complexity of\nbinary channel discrimination depends logarithmically on the inverse error\nprobability and inversely on the negative logarithm of the (geometric and\nHolevo) channel fidelity. As a special case of these findings, we precisely\ncharacterize the query complexity of discriminating between two classical\nchannels. We also provide lower and upper bounds on the query complexity of\nbinary asymmetric channel discrimination and multiple quantum channel\ndiscrimination. For the former, the query complexity depends on the geometric\nR\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends\non the negative logarithm of (geometric and Uhlmann) channel fidelity. For\nmultiple channel discrimination, the upper bound scales as the logarithm of the\nnumber of channels.","main_category":"quant-ph","categories":"quant-ph,cs.IT,cs.LG,math.IT,math.ST,stat.TH","published":"2025-04-17T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.12993v1","title":"New Frontiers in Muon-Spin Spectroscopy Using Si-Pixel Detectors","summary":"The study of novel quantum materials relies on muon-spin rotation,\nrelaxation, or resonance (\\mSR) measurements. Yet, a fundamental limitation\npersists: many of these materials can only be synthesized in extremely small\nquantities, often at sub-millimeter scales. While \\mSR ~offers unique insights\ninto electronic and magnetic properties, existing spectrometers lack a\nsub-millimeter spatial resolution and the possibility of triggerless pump-probe\ndata acquisition, which would enable more advanced measurements. The General\nPurpose Surface-muon instrument (GPS) at the Paul Scherrer Institute (PSI) is\ncurrently limited to a muon stopping rate of \\SI{40}{\\kilo\\hertz} to\n\\SI{120}{\\kilo\\hertz}, a constraint that will become more pressing with the\nupcoming High-Intensity Muon Beam (HIMB) project. To overcome these challenges,\nwe demonstrate the feasibility of employing ultra-thin monolithic Si-pixel\ndetectors to reconstruct the stopping position of muons within the sample,\nthereby significantly enhancing the capability of measuring at higher muon\nrate. Additionally, we explore the first steps toward a triggerless pump-probe\n\\mSR ~measurement scheme. Unlike conventional pump-probe techniques that\nrequire external triggers, a triggerless readout system can continuously\nintegrate stimuli pulses into the data stream, allowing real-time tracking of\nultra-fast dynamics in quantum materials. This approach will enable the study\nof transient states, spin dynamics, and quantum coherence under external\nstimuli.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T15:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.12996v1","title":"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained\n  Unlearning for Large Language Models via Knowledge Isolation","summary":"Large language models (LLMs) frequently memorize sensitive information during\ntraining, posing risks when deploying publicly accessible models. Current\nmachine unlearning methods struggle to selectively remove specific data\nassociations without degrading overall model capabilities. This paper presents\nour solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a\ntwo-stage methodology that combines causal mediation analysis with\nlayer-specific optimization. Through systematic causal tracing experiments on\nOLMo architectures (1B and 7B parameters), we identify the critical role of the\nfirst few transformer layers (layers 0-5) in storing subject-attribute\nassociations within MLP modules. Building on this insight, we develop a\nconstrained optimization approach that freezes upper layers while applying a\nnovel joint loss function to lower layers-simultaneously maximizing forget set\nloss via output token cross-entropy penalties and minimizing retain set\ndeviation through adaptive regularization. Our method achieves 2nd place in the\n1B model track, demonstrating strong task performance while maintaining 88% of\nbaseline MMLU accuracy. These results establish causal-informed layer\noptimization as a promising paradigm for efficient, precise unlearning in LLMs,\noffering a significant step forward in addressing data privacy concerns in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T15:05:40Z"}
{"aid":"http://arxiv.org/abs/2504.13011v1","title":"Two-loop Feynman integrals for leading colour $t\\bar{t}W$ production at\n  hadron colliders","summary":"We compute a complete set of the two-loop Feynman integrals that are required\nfor the next-to-next-to-leading order QCD corrections to on-shell top-pair\nproduction in association with a $W$ boson at hadron colliders in the leading\ncolour approximation. These Feynman integrals also contribute to Higgs or\n$Z$-boson production in association with a top pair. We employ the method of\ndifferential equations (DEs), facilitated by the use of finite field methods to\nhandle the algebraic complexity stemming from the seven-scale kinematics. The\npresence of the top quark in the virtual propagators, in addition to the mass\nof the external $W$ boson, gives rise to nested square roots and three elliptic\ncurves. We obtain DEs that depend at most quadratically on the dimensional\nregulator $\\epsilon$ for sectors where these analytic structures appear, and\nare $\\epsilon$-factorised otherwise. We express the DEs in terms of a minimal\nset of differential one-forms, separating the logarithmic ones. We solve the\nDEs numerically in the physical kinematic region, with the method of\ngeneralised power series expansions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T15:17:35Z"}
{"aid":"http://arxiv.org/abs/2504.13026v1","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for\n  Remote Sensing Image Super-Resolution","summary":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution\n(HR) remote sensing images from low-resolution inputs to support fine-grained\nground object interpretation. Existing methods face three key challenges: (1)\nDifficulty in extracting multi-scale features from spatially heterogeneous RS\nscenes, (2) Limited prior information causing semantic inconsistency in\nreconstructions, and (3) Trade-off imbalance between geometric accuracy and\nvisual quality. To address these issues, we propose the Texture Transfer\nResidual Denoising Dual Diffusion Model (TTRD3) with three innovations: First,\na Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous\nconvolutional kernels for multi-scale feature extraction. Second, a Sparse\nTexture Transfer Guidance (STTG) module that transfers HR texture priors from\nreference images of similar scenes. Third, a Residual Denoising Dual Diffusion\nModel (RDDM) framework combining residual diffusion for deterministic\nreconstruction and noise diffusion for diverse generation. Experiments on\nmulti-source RS datasets demonstrate TTRD3's superiority over state-of-the-art\nmethods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared\nto best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.13028v1","title":"Profinite Iterated Monodromy Groups of Unicritical Polynomials","summary":"Let $f(x) = ax^d + b \\in K[x]$ be a unicritical polynomial with degree $d\n\\geq 2$ which is coprime to $\\mathrm{char} K$. We provide an explicit\npresentation for the profinite iterated monodromy group of $f$, analyze the\nstructure of this group, and use this analysis to determine the constant field\nextension in $K(f^{-\\infty}(t))/K(t)$.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-17T15:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.13066v1","title":"Some spherical function values for two-row tableaux and Young subgroups\n  with three factors","summary":"A Young subgroup of the symmetric group $\\mathcal{S}_{N}$ with three factors,\nis realized as the stabilizer $G_{n}$ of a monomial $x^{\\lambda}$ (\n$=x_{1}^{\\lambda_{1}}x_{2}^{\\lambda_{2}}\\cdots x_{N}^{\\lambda_{N}}$) with\n$\\lambda=\\left( d_{1}^{n_{1}},d_{2}^{n_{2}},d_{3}^{n_{3}}\\right) $ (meaning\n$d_{j}$ is repeated $n_{j}$ times, $1\\leq j\\leq3$), thus is isomorphic to the\ndirect product $\\mathcal{S}_{n_{1}}\\times\\mathcal{S}_{n_{2}}\\times\n\\mathcal{S}_{n_{3}}$. The orbit of $x^{\\lambda}$ under the action of\n$\\mathcal{S}_{N}$ (by permutation of coordinates) spans a module $V_{\\lambda}%\n$, the representation induced from the identity representation of $G_{n}$. The\nspace $V_{\\lambda}$ decomposes into a direct sum of irreducible $\\mathcal{S}%\n_{N}$-modules. The spherical function is defined for each of these, it is the\ncharacter of the module averaged over the group $G_{n}$. This paper concerns\nthe value of certain spherical functions evaluated at a cycle which has no more\nthan one entry in each of the three intervals $I_{j}=\\left\\{\ni:\\lambda_{i}=d_{j}\\right\\} ,1\\leq j\\leq3$. These values appear in the study of\neigenvalues of the Heckman-Polychronakos operators in the paper by V. Gorin and\nthe author (arXiv:2412:01938v1). The present paper determines the spherical\nfunction values for $\\mathcal{S}_{N}$-modules $V$ of two-row tableau type,\ncorresponding to Young tableaux of shape $\\left[ N-k,k\\right] $. The method is\nbased on analyzing the effect of a cycle on $G_{n}$-invariant elements of $V$.\nThese are constructed in terms of Hahn polynomials in two variables.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-17T16:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.13068v1","title":"Accuracy is Not Agreement: Expert-Aligned Evaluation of Crash Narrative\n  Classification Models","summary":"This study explores the relationship between deep learning (DL) model\naccuracy and expert agreement in the classification of crash narratives. We\nevaluate five DL models -- including BERT variants, the Universal Sentence\nEncoder (USE), and a zero-shot classifier -- against expert-labeled data and\nnarrative text. The analysis is further extended to four large language models\n(LLMs): GPT-4, LLaMA 3, Qwen, and Claude. Our results reveal a counterintuitive\ntrend: models with higher technical accuracy often exhibit lower agreement with\ndomain experts, whereas LLMs demonstrate greater expert alignment despite\nrelatively lower accuracy scores. To quantify and interpret model-expert\nagreement, we employ Cohen's Kappa, Principal Component Analysis (PCA), and\nSHAP-based explainability techniques. Findings indicate that expert-aligned\nmodels tend to rely more on contextual and temporal language cues, rather than\nlocation-specific keywords. These results underscore that accuracy alone is\ninsufficient for evaluating models in safety-critical NLP applications. We\nadvocate for incorporating expert agreement as a complementary metric in model\nevaluation frameworks and highlight the promise of LLMs as interpretable,\nscalable tools for crash analysis pipelines.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.13078v1","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\n  Try-Off","summary":"Computer vision is transforming fashion through Virtual Try-On (VTON) and\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\ngarment using a target photo and a standardized garment image, while a more\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\nof another person wearing the garment. VTOFF, on the other hand, extracts\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\na diffusion-based VTOFF model. Built on a latent diffusion framework with\nSigLIP image conditioning, it effectively captures garment properties like\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T16:45:18Z"}
{"aid":"http://arxiv.org/abs/2504.13101v1","title":"An Empirically Grounded Identifiability Theory Will Accelerate\n  Self-Supervised Learning Research","summary":"Self-Supervised Learning (SSL) powers many current AI systems. As research\ninterest and investment grow, the SSL design space continues to expand. The\nPlatonic view of SSL, following the Platonic Representation Hypothesis (PRH),\nsuggests that despite different methods and engineering approaches, all\nrepresentations converge to the same Platonic ideal. However, this phenomenon\nlacks precise theoretical explanation. By synthesizing evidence from\nIdentifiability Theory (IT), we show that the PRH can emerge in SSL. However,\ncurrent IT cannot explain SSL's empirical success. To bridge the gap between\ntheory and practice, we propose expanding IT into what we term Singular\nIdentifiability Theory (SITh), a broader theoretical framework encompassing the\nentire SSL pipeline. SITh would allow deeper insights into the implicit data\nassumptions in SSL and advance the field towards learning more interpretable\nand generalizable representations. We highlight three critical directions for\nfuture research: 1) training dynamics and convergence properties of SSL; 2) the\nimpact of finite samples, batch size, and data diversity; and 3) the role of\ninductive biases in architecture, augmentations, initialization schemes, and\noptimizers.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-17T17:10:33Z"}
{"aid":"http://arxiv.org/abs/2504.13108v1","title":"Global patterns in signed permutations","summary":"Global permutation patterns have recently been shown to characterize\nimportant properties of a Coxeter group. Here we study global patterns in the\ncontext of signed permutations, with both characterizing and enumerative\nresults. Surprisingly, many properties of signed permutations may be\ncharacterized by avoidance of the same set of patterns as the corresponding\nproperties in the symmetric group. We also extend previous enumerative work of\nEgge, and our work has connections to the Garfinkle--Barbasch--Vogan\ncorrespondence, the Erd\\H{o}s--Szekeres theorem, and well-known integer\nsequences.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T17:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.13119v1","title":"Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM\n  Integration","summary":"Most adaptive AR storytelling systems define environmental semantics using\nsimple object labels and spatial coordinates, limiting narratives to rigid,\npre-defined logic. This oversimplification overlooks the contextual\nsignificance of object relationships-for example, a wedding ring on a\nnightstand might suggest marital conflict, yet is treated as just \"two objects\"\nin space. To address this, we explored integrating Vision Language Models\n(VLMs) into AR pipelines. However, several challenges emerged: First, stories\ngenerated with simple prompt guidance lacked narrative depth and spatial usage.\nSecond, spatial semantics were underutilized, failing to support meaningful\nstorytelling. Third, pre-generated scripts struggled to align with AR\nFoundation's object naming and coordinate systems. We propose a scene-driven AR\nstorytelling framework that reimagines environments as active narrative agents,\nbuilt on three innovations: 1. State-aware object semantics: We decompose\nobject meaning into physical, functional, and metaphorical layers, allowing\nVLMs to distinguish subtle narrative cues between similar objects. 2.\nStructured narrative interface: A bidirectional JSON layer maps VLM-generated\nmetaphors to AR anchors, maintaining spatial and semantic coherence. 3. STAM\nevaluation framework: A three-part experimental design evaluates narrative\nquality, highlighting both strengths and limitations of VLM-AR integration. Our\nfindings show that the system can generate stories from the environment itself,\nnot just place them on top of it. In user studies, 70% of participants reported\nseeing real-world objects differently when narratives were grounded in\nenvironmental symbolism. By merging VLMs' generative creativity with AR's\nspatial precision, this framework introduces a novel object-driven storytelling\nparadigm, transforming passive spaces into active narrative landscapes.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T17:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.13130v1","title":"General Analytic Solutions for Circumplanetary Disks during the Late\n  Stages of Giant Planet Formation","summary":"Forming giant planets are accompanied by circumplanetary disks, as indicated\nby considerations of angular momentum conservation, observations of candidate\nprotoplanets, and the satellite systems of planets in our Solar System. This\npaper derives surface density distributions for circumplanetary disks during\nthe final stage of evolution when most of the mass is accreted. This approach\ngeneralizes previous treatments to include the angular momentum bias for the\ninfalling material, more accurate solutions for the incoming trajectories,\ncorrections to the outer boundary condition of the circumplanetary disk, and\nthe adjustment of newly added material as it becomes incorporated into the\nKeplerian flow of the pre-existing disk. These generalizations lead to smaller\ncentrifugal radii, higher column density for the surrounding envelopes, and\nhigher disk accretion efficiency. In addition, we explore the consequences of\ndifferent angular distributions for the incoming material at the outer\nboundary, with the concentration of the incoming flow varying from polar to\nisotropic to equatorial. These geometric variations modestly affect the disk\nsurface density, but also lead to substantial modification to the location in\nthe disk where the mass accretion rate changes sign. This paper finds analytic\nsolutions for the orbits, source functions, surface density distributions, and\nthe corresponding disk temperature profiles over the expanded parameter space\noutlined above.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.13136v1","title":"Freezing of the renormalized one-loop primordial scalar power spectrum","summary":"By consistently using the effective field theory of inflationary fluctuations\nin the decoupling limit, we explicitly prove that the renormalized one-loop\npower spectrum of the primordial curvature perturbation freezes exactly on\nscales larger than its sound horizon.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-17T17:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.13138v1","title":"Extending the Mott-Gurney law to one-dimensional nonplanar diodes using\n  point transformations","summary":"Recent studies have applied variational calculus, conformal mapping, and\npoint transformations to generalize the one-dimensional (1D) space-charge\nlimited current density (SCLCD) and electron emission mechanisms to nonplanar\ngeometries; however, these assessments have focused on extending the\nChild-Langmuir law (CLL) for SCLCD in vacuum. Since the charge in the diode is\nindependent of coordinate system (i.e., covariant), we apply bijective point\ntransformations to extend the Mott-Gurney law (MGL) for the SCLCD in a\ncollisional or semiconductor gap to nonplanar 1D geometries. This yields a\nmodified MGL that replaces the Cartesian gap distance with a canonical gap\ndistance that may be written generally in terms of geometric scale factors that\nare known for multiple geometries. We tabulate results for common geometries.\nSuch an approach may be applied to any current density, including\nnon-space-charge limited gaps and SCLCD that may fall between the CLL and MGL.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.plasm-ph","published":"2025-04-17T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.13141v1","title":"Complexity at Scale: A Quantitative Analysis of an Alibaba Microservice\n  Deployment","summary":"Microservice architectures are increasingly prevalent in organisations\nproviding online applications. Recent studies have begun to explore the\ncharacteristics of real-world large-scale microservice deployments; however,\ntheir operational complexities, and the degree to which this complexities are\nconsistent across different deployments, remains under-explored. In this paper,\nwe analyse a microservice dataset released by Alibaba along three dimensions of\ncomplexity: scale, heterogeneity, and dynamicity. We find that large-scale\ndeployments can consist of tens of thousands of microservices, that support an\neven broader array of front-end functionality. Moreover, our analysis shows\nwide-spread long-tailed distributions of characteristics between microservices,\nsuch as share of workload and dependencies, highlighting inequality across the\ndeployment. This diversity is also reflected in call graphs, where we find that\nwhilst front-end services produce dominant call graphs, rarer non-dominant call\ngraphs are prevalent and could involve dissimilar microservice calls. We also\nfind that runtime dependencies between microservices deviate from the static\nview of system dependencies, and that the deployment undergoes daily changes to\nmicroservices. We discuss the implications of our findings for state-of-the-art\nresearch in microservice management and research testbed realism, and compare\nour results to previous descriptions of large-scale microservice deployments to\nbegin to build an understanding of their commonalities.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-17T17:50:44Z"}
{"aid":"http://arxiv.org/abs/2504.13143v1","title":"$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for\n  Complexity-Controllable Image Editing Benchmark","summary":"We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to\nsystematically evaluate instruction-based image editing models across\ninstructions of varying complexity. To develop this benchmark, we harness\nGPT-4o to automatically collect a diverse set of editing instructions at scale.\nOur approach follows a well-structured ``Chain-of-Edit'' pipeline: we first\ngenerate individual atomic editing tasks independently and then integrate them\nto form cohesive, complex instructions. Additionally, we introduce a suite of\nmetrics to assess various aspects of editing performance, along with a\nVLM-based auto-evaluation pipeline that supports large-scale assessments. Our\nbenchmark yields several notable insights: 1) Open-source models significantly\nunderperform relative to proprietary, closed-source models, with the\nperformance gap widening as instruction complexity increases; 2) Increased\ninstructional complexity primarily impairs the models' ability to retain key\nelements from the input images and to preserve the overall aesthetic quality;\n3) Decomposing a complex instruction into a sequence of atomic steps, executed\nin a step-by-step manner, substantially degrades performance across multiple\nmetrics; 4) A straightforward Best-of-N selection strategy improves results for\nboth direct editing and the step-by-step sequential approach; and 5) We observe\na ``curse of synthetic data'': when synthetic data is involved in model\ntraining, the edited images from such models tend to appear increasingly\nsynthetic as the complexity of the editing instructions rises -- a phenomenon\nthat intriguingly also manifests in the latest GPT-4o outputs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13157v1","title":"AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis","summary":"We explore the task of geometric reconstruction of images captured from a\nmixture of ground and aerial views. Current state-of-the-art learning-based\napproaches fail to handle the extreme viewpoint variation between aerial-ground\nimage pairs. Our hypothesis is that the lack of high-quality, co-registered\naerial-ground datasets for training is a key reason for this failure. Such data\nis difficult to assemble precisely because it is difficult to reconstruct in a\nscalable way. To overcome this challenge, we propose a scalable framework\ncombining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google\nEarth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The\npseudo-synthetic data simulates a wide range of aerial viewpoints, while the\nreal, crowd-sourced images help improve visual fidelity for ground-level images\nwhere mesh-based renderings lack sufficient detail, effectively bridging the\ndomain gap between real images and pseudo-synthetic renderings. Using this\nhybrid dataset, we fine-tune several state-of-the-art algorithms and achieve\nsignificant improvements on real-world, zero-shot aerial-ground tasks. For\nexample, we observe that baseline DUSt3R localizes fewer than 5% of\naerial-ground pairs within 5 degrees of camera rotation error, while\nfine-tuning with our data raises accuracy to nearly 56%, addressing a major\nfailure point in handling large viewpoint changes. Beyond camera estimation and\nscene reconstruction, our dataset also improves performance on downstream tasks\nlike novel-view synthesis in challenging aerial-ground scenarios, demonstrating\nthe practical value of our approach in real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:05Z"}
