{"aid":"http://arxiv.org/abs/2503.21664v1","title":"Functions of bounded variation and Lipschitz algebras in metric measure\n  spaces","summary":"Given a unital algebra $\\mathscr A$ of locally Lipschitz functions defined\nover a metric measure space $({\\mathrm X},{\\mathsf d},\\mathfrak m)$, we study\ntwo associated notions of function of bounded variation and their relations:\nthe space ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$, obtained by\napproximating in energy with elements of $\\mathscr A$, and the space ${\\mathrm\nBV}_{\\mathrm W}({\\mathrm X};\\mathscr A)$, defined through an\nintegration-by-parts formula that involves derivations acting in duality with\n$\\mathscr A$. Our main result provides a sufficient condition on the algebra\n$\\mathscr A$ under which ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$\ncoincides with the standard metric BV space ${\\mathrm BV}_{\\mathrm H}({\\mathrm\nX})$, which corresponds to taking as $\\mathscr A$ the collection of all locally\nLipschitz functions. Our result applies to several cases of interest, for\nexample to Euclidean spaces and Riemannian manifolds equipped with the algebra\nof smooth functions, or to Banach and Wasserstein spaces equipped with the\nalgebra of cylinder functions. Analogous results for metric Sobolev spaces\n${\\mathrm H}^{1,p}$ of exponent $p\\in(1,\\infty)$ were previously obtained by\nseveral different authors.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-03-27T16:32:47Z"}
{"aid":"http://arxiv.org/abs/2503.21686v1","title":"Molecular Quantum Transformer","summary":"The Transformer model, renowned for its powerful attention mechanism, has\nachieved state-of-the-art performance in various artificial intelligence tasks\nbut faces challenges such as high computational cost and memory usage.\nResearchers are exploring quantum computing to enhance the Transformer's\ndesign, though it still shows limited success with classical data. With a\ngrowing focus on leveraging quantum machine learning for quantum data,\nparticularly in quantum chemistry, we propose the Molecular Quantum Transformer\n(MQT) for modeling interactions in molecular quantum systems. By utilizing\nquantum circuits to implement the attention mechanism on the molecular\nconfigurations, MQT can efficiently calculate ground-state energies for all\nconfigurations. Numerical demonstrations show that in calculating ground-state\nenergies for H_2, LiH, BeH_2, and H_4, MQT outperforms the classical\nTransformer, highlighting the promise of quantum effects in Transformer\nstructures. Furthermore, its pretraining capability on diverse molecular data\nfacilitates the efficient learning of new molecules, extending its\napplicability to complex molecular systems with minimal additional effort. Our\nmethod offers an alternative to existing quantum algorithms for estimating\nground-state energies, opening new avenues in quantum chemistry and materials\nscience.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-03-27T16:54:15Z"}
{"aid":"http://arxiv.org/abs/2503.21731v1","title":"Cylindrical Algebraic Decomposition in \\textit{Macaulay2}","summary":"\\texttt{CylindricalAlgebraicDecomposition.m2} is the first implementation of\nCylindrical Algebraic Decomposition (CAD) in \\textit{Macaulay2}. CAD decomposes\nspace into `cells' where input polynomials are sign-invariant. This package\ncomputes an Open CAD (full-dimensional cells only) for sets of real polynomials\nwith rational coefficients, enabling users to solve existential problems\ninvolving strict inequalities. With the construction of a full CAD (cells of\nall dimensions), this tool could be extended to solve any real quantifier\nelimination problem. The current implementation employs the Lazard projection\nand introduces a new heuristic for choosing the variable ordering.","main_category":"cs.SC","categories":"cs.SC,math.AG","published":"2025-03-27T17:46:24Z"}
{"aid":"http://arxiv.org/abs/2503.21761v1","title":"Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single\n  Video","summary":"This paper presents a unified approach to understanding dynamic scenes from\ncasual videos. Large pretrained vision foundation models, such as\nvision-language, video depth prediction, motion tracking, and segmentation\nmodels, offer promising capabilities. However, training a single model for\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\nmulti-stage optimization framework that harnesses multiple pretrained models to\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\npose estimation, and dense 3D motion tracking. Our results show\nstate-of-the-art performance in dynamic 4D modeling with superior visual\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\neffectiveness of repurposing visual foundation models for 4D understanding.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:32Z"}
{"aid":"http://arxiv.org/abs/2503.23713v1","title":"GNN-Based Candidate Node Predictor for Influence Maximization in\n  Temporal Graphs","summary":"In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-03-31T04:28:37Z"}
{"aid":"http://arxiv.org/abs/2503.23768v1","title":"Texture or Semantics? Vision-Language Models Get Lost in Font\n  Recognition","summary":"Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic\ncapabilities, achieving impressive performance in various tasks such as image\nrecognition and object localization. However, their effectiveness in\nfine-grained tasks remains an open question. In everyday scenarios, individuals\nencountering design materials, such as magazines, typography tutorials,\nresearch papers, or branding content, may wish to identify aesthetically\npleasing fonts used in the text. Given their multimodal capabilities and free\naccessibility, many VLMs are often considered potential tools for font\nrecognition. This raises a fundamental question: Do VLMs truly possess the\ncapability to recognize fonts? To investigate this, we introduce the Font\nRecognition Benchmark (FRB), a compact and well-structured dataset comprising\n15 commonly used fonts. FRB includes two versions: (i) an easy version, where\n10 sentences are rendered in different fonts, and (ii) a hard version, where\neach text sample consists of the names of the 15 fonts themselves, introducing\na stroop effect that challenges model perception. Through extensive evaluation\nof various VLMs on font recognition tasks, we arrive at the following key\nfindings: (i) Current VLMs exhibit limited font recognition capabilities, with\nmany state-of-the-art models failing to achieve satisfactory performance. (ii)\nFew-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits\nin improving font recognition accuracy across different VLMs. (iii) Attention\nanalysis sheds light on the inherent limitations of VLMs in capturing semantic\nfeatures.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-03-31T06:33:21Z"}
{"aid":"http://arxiv.org/abs/2503.23771v1","title":"XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large\n  Ultra-High-Resolution Remote Sensing Imagery?","summary":"The astonishing breakthrough of multimodal large language models (MLLMs) has\nnecessitated new benchmarks to quantitatively assess their capabilities, reveal\ntheir limitations, and indicate future research directions. However, this is\nchallenging in the context of remote sensing (RS), since the imagery features\nultra-high resolution that incorporates extremely complex semantic\nrelationships. Existing benchmarks usually adopt notably smaller image sizes\nthan real-world RS scenarios, suffer from limited annotation quality, and\nconsider insufficient dimensions of evaluation. To address these issues, we\npresent XLRS-Bench: a comprehensive benchmark for evaluating the perception and\nreasoning capabilities of MLLMs in ultra-high-resolution RS scenarios.\nXLRS-Bench boasts the largest average image size (8500$\\times$8500) observed\nthus far, with all evaluation samples meticulously annotated manually, assisted\nby a novel semi-automatic captioner on ultra-high-resolution RS images. On top\nof the XLRS-Bench, 16 sub-tasks are defined to evaluate MLLMs' 10 kinds of\nperceptual capabilities and 6 kinds of reasoning capabilities, with a primary\nemphasis on advanced cognitive processes that facilitate real-world\ndecision-making and the capture of spatiotemporal changes. The results of both\ngeneral and RS-focused MLLMs on XLRS-Bench indicate that further efforts are\nneeded for real-world RS applications. We have open-sourced XLRS-Bench to\nsupport further research in developing more powerful MLLMs for remote sensing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:41:18Z"}
{"aid":"http://arxiv.org/abs/2503.23773v1","title":"Seasonal bias-correction of daily precipitation over France using a\n  stitch model designed for robust extremes representation","summary":"Highly resoluted and accurate daily precipitation data are required for\nimpact models to perform adequately and to correctly measure high-risk events'\nimpact. In order to produce such data, bias-correction is often needed. Most of\nthose statistical methods correct the probability distributions of daily\nprecipitation by modeling them using either empirical or parametric\ndistributions. A recent semi-parametric model based on a penalized Berk-Jones\n(BJ) statistical test which allows for an automatic and personalized splicing\nof parametric and nonparametric has been developed. This method, called\nStitch-BJ model, was found to be able to model daily precipitation correctly\nand showed interesting potential in a bias-correction setting. In the present\nstudy, we will consolidate these results by taking into account the seasonal\nproperties of daily precipitation in an out-of-sample context, and by\nconsidering dry days probabilities in our methodology. We evaluate the\nperformance of the Stitch-BJ method in this seasonal bias-correction setting\nagainst more classical models such as the Gamma, Exponentiated Weibull (ExpW),\nExtended Generalized Pareto (EGP) or empirical distributions. The Stitch-BJ\ndistribution was able to consistently perform as well or better than all the\nother models over the validation set, including the empirical distribution,\nwhich is often used due to its robustness.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2503.23832v1","title":"An extrapolated and provably convergent algorithm for nonlinear matrix\n  decomposition with the ReLU function","summary":"Nonlinear matrix decomposition (NMD) with the ReLU function, denoted\nReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ and\na factorization rank $r$, identify a rank-$r$ matrix $\\Theta$ such that\n$X\\approx \\max(0,\\Theta)$. This decomposition finds application in data\ncompression, matrix completion with entries missing not at random, and manifold\nlearning. The standard ReLU-NMD model minimizes the least squares error, that\nis, $\\|X - \\max(0,\\Theta)\\|_F^2$. The corresponding optimization problem is\nnondifferentiable and highly nonconvex. This motivated Saul to propose an\nalternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introduced\nand satisfies $\\max(0,Z)=X$ while minimizing $\\|Z - \\Theta\\|_F^2$ (``A\nnonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\nMath. Data Sci., 2022). Our first contribution is to show that the two\nformulations may yield different low-rank solutions $\\Theta$; in particular, we\nshow that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning that\nthere are instances in which the infimum of Latent-ReLU-NMD is not attained\nwhile that of ReLU-NMD is. We also consider another alternative model, called\n3B-ReLU-NMD, which parameterizes $\\Theta=WH$, where $W$ has $r$ columns and $H$\nhas $r$ rows, allowing one to get rid of the rank constraint in\nLatent-ReLU-NMD. Our second contribution is to prove the convergence of a block\ncoordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Our\nthird contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD,\nwhich we prove is also convergent under mild assumptions. We illustrate the\nsignificant acceleration effect of eBCD-NMD compared to BCD-NMD, and also show\nthat eBCD-NMD performs well against the state of the art on synthetic and\nreal-world data sets.","main_category":"cs.LG","categories":"cs.LG,eess.IV,math.OC,stat.ML","published":"2025-03-31T08:27:41Z"}
{"aid":"http://arxiv.org/abs/2503.23856v1","title":"Explodability criteria for the neutrino-driven supernova mechanism","summary":"Massive stars undergoing iron core collapse at the end of their evolution\nterminate their lives either in successful or failed supernovae (SNe). The\nphysics of core collapse supernovae (CCSNe) is complex, and their understanding\nrequires computationally expensive simulations. The sampling of large, densely\nsampled parameter spaces of SN progenitors, as is needed e.g. for population\nsynthesis studies, is thus not feasible. To remedy this situation, we present\ncriteria that allow us to predict the final fates of stars by evaluating\nmultiple explodability proxies derived from the stellar structure at the onset\nof core collapse. These are formulated based on the outcomes of a semi-analytic\nsupernova model, evaluated over a set of ~3,900 heterogeneous stellar\nprogenitors (single stars, binary-stripped and accretor stars). Over these, the\nexplodabiliy criteria achieve an accuracy of >99% agreement with the\nsemi-analytic model. The criteria are tested on 29 state-of-the-art 3D CCSN\nsimulation outcomes from two different groups. Furthermore, we find that all\nexplodability proxies needed for our pre-SN criteria have two distinct peaks\nand intervening valleys as a function of the carbon-oxygen (CO) core mass\n$M_\\mathrm{CO}$, which coincide with failed and successful SNe, respectively.\nThe CO core masses of explodability peaks shift systematically with\nmetallicity, $Z$, and with the timing of hydrogen-rich envelope removal in\nbinary-stripped stars. With these, we identify critical values in\n$M_\\mathrm{CO}$ that define windows over which black holes form by direct\ncollapse. The outcome is a CCSN recipe based on $M_\\mathrm{CO}$ and $Z$,\napplicable for rapid binary population synthesis and other studies. Our\nexplodability formalism is consistent with SN observations that constrain the\nprogenitor $M_\\mathrm{CO}$ and partially addresses the missing red supergiant\nproblem by direct black hole formation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T09:04:10Z"}
{"aid":"http://arxiv.org/abs/2503.23868v1","title":"Modelling Gaia photometry signals of dark halos","summary":"We use the framework of microlensing to show that observations of binary\nsystems, such as those made by {\\it Gaia}, combined with follow-up weak lensing\nmeasurements, can provide a means to probe halos of exotic matter, possibly\nclumped around compact objects such as black holes. This could potentially\ncover a broad range of physical scenarios - from dark matter mini-halos to\nblack holes with bosonic configurations around them, known as hair. Assuming\nthat light can freely propagate through the halo of the exotic matter, the\ncompanion star will produce characteristic, sizable lensing signatures due to\nthe deviation from a central gravitational potential. The signature of the\nmultiple images, the magnification and the light-curve could be the smoking gun\nof such structures. We discuss how the precise observations of the {\\it Gaia}\nsurvey offer an opportunity to search for new, yet undiscovered fundamental\nfields interacting gravitationally with baryons.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-03-31T09:17:48Z"}
{"aid":"http://arxiv.org/abs/2503.23892v1","title":"Surveying Uncertainty Representation: A Unified Model for Cyber-Physical\n  Systems","summary":"Cyber-Physical Systems (CPS) operate in dynamic environments, leading to\ndifferent types of uncertainty. This work provides a comprehensive review of\nuncertainty representations and categorizes them based on the dimensions used\nto represent uncertainty. Through this categorization, key gaps and limitations\nin existing approaches are identified. To address these issues, a Conceptual\nModel of Uncertainty Representations in CPS is introduced, integrating and\nextending existing models. Its applicability is demonstrated through examples\nfrom the automotive domain, showing its effectiveness in capturing and\nstructuring uncertainty in real-world scenarios.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:42:51Z"}
{"aid":"http://arxiv.org/abs/2503.23907v1","title":"HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human\n  Image Aesthetic Assessment","summary":"Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:58:11Z"}
{"aid":"http://arxiv.org/abs/2503.23913v1","title":"Entropy-Based Adaptive Weighting for Self-Training","summary":"The mathematical problem-solving capabilities of large language models have\nbecome a focal point of research, with growing interests in leveraging\nself-generated reasoning paths as a promising way to refine and enhance these\nmodels. These paths capture step-by-step logical processes while requiring only\nthe correct answer for supervision. The self-training method has been shown to\nbe effective in reasoning tasks while eliminating the need for external models\nand manual annotations. However, optimizing the use of self-generated data for\nmodel training remains an open challenge. In this work, we propose\nEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive\nweighting strategy designed to prioritize uncertain data during self-training.\nSpecifically, EAST employs a mapping function with a tunable parameter that\ncontrols the sharpness of the weighting, assigning higher weights to data where\nthe model exhibits greater uncertainty. This approach guides the model to focus\non more informative and challenging examples, thereby enhancing its reasoning\nability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical\nresults show that, while the vanilla method yields virtually no improvement\n(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,\nEAST attains a further 1-2% performance boost compared to the vanilla method.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T10:04:35Z"}
{"aid":"http://arxiv.org/abs/2503.23926v1","title":"Reliable Traffic Monitoring Using Low-Cost Doppler Radar Units","summary":"Road traffic monitoring typically involves the counting and recording of\nvehicles on public roads over extended periods. The data gathered from such\nmonitoring provides useful information to municipal authorities in urban areas.\nThis paper presents a low-cost, widely deployable sensing subsystem based on\nContinuous Wave Doppler radar. The proposed system can perform vehicle\ndetection and speed estimation with a total cost of less than 100 USD. The\nsensing system (including the hardware subsystem and the algorithms) is\ndesigned to be placed on the side of the road, allowing for easy deployment and\nserviceability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T10:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.23927v1","title":"Detecting Localized Density Anomalies in Multivariate Data via Coin-Flip\n  Statistics","summary":"Detecting localized density differences in multivariate data is a crucial\ntask in computational science. Such anomalies can indicate a critical system\nfailure, lead to a groundbreaking scientific discovery, or reveal unexpected\nchanges in data distribution. We introduce EagleEye, an anomaly detection\nmethod to compare two multivariate datasets with the aim of identifying local\ndensity anomalies, namely over- or under-densities affecting only localised\nregions of the feature space. Anomalies are detected by modelling, for each\npoint, the ordered sequence of its neighbours' membership label as a\ncoin-flipping process and monitoring deviations from the expected behaviour of\nsuch process. A unique advantage of our method is its ability to provide an\naccurate, entirely unsupervised estimate of the local signal purity. We\ndemonstrate its effectiveness through experiments on both synthetic and\nreal-world datasets. In synthetic data, EagleEye accurately detects anomalies\nin multiple dimensions even when they affect a tiny fraction of the data. When\napplied to a challenging resonant anomaly detection benchmark task in simulated\nLarge Hadron Collider data, EagleEye successfully identifies particle decay\nevents present in just 0.3% of the dataset. In global temperature data,\nEagleEye uncovers previously unidentified, geographically localised changes in\ntemperature fields that occurred in the most recent years. Thanks to its key\nadvantages of conceptual simplicity, computational efficiency, trivial\nparallelisation, and scalability, EagleEye is widely applicable across many\nfields.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T10:20:04Z"}
{"aid":"http://arxiv.org/abs/2503.23941v1","title":"Choco-Q: Commute Hamiltonian-based QAOA for Constrained Binary\n  Optimization","summary":"Constrained binary optimization aims to find an optimal assignment to\nminimize or maximize the objective meanwhile satisfying the constraints, which\nis a representative NP problem in various domains, including transportation,\nscheduling, and economy. Quantum approximate optimization algorithms (QAOA)\nprovide a promising methodology for solving this problem by exploiting the\nparallelism of quantum entanglement. However, existing QAOA approaches based on\npenalty-term or Hamiltonian simulation fail to thoroughly encode the\nconstraints, leading to extremely low success rate and long searching latency.\n  This paper proposes Choco-Q, a formal and universal framework for constrained\nbinary optimization problems, which comprehensively covers all constraints and\nexhibits high deployability for current quantum devices. The main innovation of\nChoco-Q is to embed the commute Hamiltonian as the driver Hamiltonian,\nresulting in a much more general encoding formulation that can deal with\narbitrary linear constraints. Leveraging the arithmetic features of commute\nHamiltonian, we propose three optimization techniques to squeeze the overall\ncircuit complexity, including Hamiltonian serialization, equivalent\ndecomposition, and variable elimination. The serialization mechanism transforms\nthe original Hamiltonian into smaller ones. Our decomposition methods only take\nlinear time complexity, achieving end-to-end acceleration. Experiments\ndemonstrate that Choco-Q shows more than 235$\\times$ algorithmic improvement in\nsuccessfully finding the optimal solution, and achieves 4.69$\\times$ end-to-end\nacceleration, compared to prior QAOA designs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:47:20Z"}
{"aid":"http://arxiv.org/abs/2503.23970v1","title":"A predator-prey model with Allee effect for a type of predator","summary":"This paper investigates the dynamical behaviors of a Holling type I\nLeslie-Gower predator-prey model where the predator exhibits an Allee effect\nand is subjected to constant harvesting. The model demonstrates three types of\nequilibrium points under different parameter conditions, which could be either\nstable or unstable nodes (foci), saddle nodes, weak centers, or cusps. The\nsystem exhibits a saddle-node bifurcation near the saddle-node point and a Hopf\nbifurcation near the weak center. By calculating the first Lyapunov\ncoefficient, the conditions for the occurrence of both supercritical and\nsubcritical Hopf bifurcations are derived. Finally, it is proven that when the\npredator growth rate and the prey capture coefficient vary within a specific\nsmall neighborhood, the system undergoes a codimension-2 Bogdanov-Takens\nbifurcation near the cusp point.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T11:34:48Z"}
{"aid":"http://arxiv.org/abs/2503.23987v1","title":"Revisiting cyclic elements in growth spaces","summary":"We revisit the problem of characterizing cyclic elements for the shift\noperator in a broad class of radial growth spaces of holomorphic functions on\nthe unit disk, focusing on functions of finite Nevanlinna characteristic. We\nprovide results in the range of Dini regular weights, and in the regime of\nlogarithmic integral divergence. Our proofs are largely constructive, enabling\nus to simplify and extend a classical result by Korenblum and Roberts, and a\nrecent Theorem due to El-Fallah, Kellay, and Seip.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-03-31T11:56:27Z"}
{"aid":"http://arxiv.org/abs/2503.24017v1","title":"Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings\n  for Robust Image Classification","summary":"Crossmodal knowledge distillation (KD) aims to enhance a unimodal student\nusing a multimodal teacher model. In particular, when the teacher's modalities\ninclude the student's, additional complementary information can be exploited to\nimprove knowledge transfer. In supervised image classification, image datasets\ntypically include class labels that represent high-level concepts, suggesting a\nnatural avenue to incorporate textual cues for crossmodal KD. However, these\nlabels rarely capture the deeper semantic structures in real-world visuals and\ncan lead to label leakage if used directly as inputs, ultimately limiting KD\nperformance. To address these issues, we propose a multi-teacher crossmodal KD\nframework that integrates CLIP image embeddings with learnable WordNet-relaxed\ntext embeddings under a hierarchical loss. By avoiding direct use of exact\nclass names and instead using semantically richer WordNet expansions, we\nmitigate label leakage and introduce more diverse textual cues. Experiments\nshow that this strategy significantly boosts student performance, whereas noisy\nor overly precise text embeddings hinder distillation efficiency.\nInterpretability analyses confirm that WordNet-relaxed prompts encourage\nheavier reliance on visual features over textual shortcuts, while still\neffectively incorporating the newly introduced textual cues. Our method\nachieves state-of-the-art or second-best results on six public datasets,\ndemonstrating its effectiveness in advancing crossmodal KD.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T12:41:26Z"}
{"aid":"http://arxiv.org/abs/2503.24022v1","title":"Wasserstein KL-divergence for Gaussian distributions","summary":"We introduce a new version of the KL-divergence for Gaussian distributions\nwhich is based on Wasserstein geometry and referred to as WKL-divergence. We\nshow that this version is consistent with the geometry of the sample space\n${\\Bbb R}^n$. In particular, we can evaluate the WKL-divergence of the Dirac\nmeasures concentrated in two points which turns out to be proportional to the\nsquared distance between these points.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-03-31T12:49:01Z"}
{"aid":"http://arxiv.org/abs/2503.24024v1","title":"Degrees in the $β$- and $β'$-Delaunay graphs","summary":"We investigate the typical cells $\\widehat{Z}$ and $\\widehat{Z}^\\prime$ of\n$\\beta$- and $\\beta'$-Voronoi tessellations in $\\mathbb{R}^d$, establishing a\nComplementary Theorem which entails: 1) a gamma distribution of the\n$\\Phi$-content (a suitable homogeneous functional) of the typical cell with\n$n$-facets; 2) the independence of this $\\Phi$-content with the shape of the\ncell; 3) a practical integral representation of the distribution of\n$Z^{(\\prime)}$. We exploit the latter to derive bounds on the distribution of\nthe facet numbers. Using duality, we get bounds on the typical degree\ndistributions of $\\beta$- and $\\beta'$-Delaunay triangulations. For\n$\\beta'$-Delaunay, the resulting exponential lower bound seems to be the first\nof its kind for random spatial graphs arising as the skeletons of random\ntessellations. For $\\beta$-Delaunay, matching super-exponential bounds allow us\nto show concentration of the maximal degree in a growing window to only a\nfinite number of deterministic values (in particular, only two values for\n$d=2$).","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T12:50:40Z"}
{"aid":"http://arxiv.org/abs/2503.24030v1","title":"Jacquetium, a new, naturally-occurring chemical element","summary":"I report the discovery of jacquetium ($_0$Jq), the first naturally occurring\nelement found since more than 80 years.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.EP","published":"2025-03-31T12:57:10Z"}
{"aid":"http://arxiv.org/abs/2503.24040v1","title":"Adventures in FRET and Specification","summary":"This paper gives an overview of previous work in which the authors used\nNASA's Formal Requirement Elicitation Tool (FRET) to formalise requirements. We\ndiscuss four case studies where we used FRET to capture the system's\nrequirements. These formalised requirements subsequently guided the case study\nspecifications in a combination of formal paradigms. For each case study we\nsummarise insights gained during this process, exploring the expressiveness and\nthe potential interoperability of these approaches. Our experience confirms\nFRET's suitability as a framework for the elicitation and understanding of\nrequirements and for providing traceability from requirements to specification.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:03:34Z"}
{"aid":"http://arxiv.org/abs/2503.24053v1","title":"ReaLM: Reliable and Efficient Large Language Model Inference with\n  Statistical Algorithm-Based Fault Tolerance","summary":"The demand for efficient large language model (LLM) inference has propelled\nthe development of dedicated accelerators. As accelerators are vulnerable to\nhardware faults due to aging, variation, etc, existing accelerator designs\noften reserve a large voltage margin or leverage algorithm-based fault\ntolerance (ABFT) techniques to ensure LLM inference correctness. However,\nprevious methods often overlook the inherent fault tolerance of LLMs, leading\nto high computation and energy overhead. To enable reliable yet efficient LLM\ninference, in this paper, we propose a novel algorithm/circuit co-design\nframework, dubbed ReaLM. For the first time, we systematically characterize the\nfault tolerance of LLMs by performing a large-scale error injection study of\nrepresentative LLMs and natural language understanding tasks. Then, we propose\na statistical ABFT algorithm that fully leverages the error robustness to\nminimize error recovery as much as possible. We also customize the error\ndetection circuits to enable a low-cost online collection of error statistics.\nExtensive experiments show that with only 1.42% circuit area and 1.79% power\noverhead, our ReaLM can reduce perplexity degradation from 18.54 to 0.29.\nCompared to existing methods, ReaLM consistently reduces recovery costs across\ndifferent operating voltages and improves energy efficiency by up to 35.83%\nwithout compromising LLM performance. Our error injection code is available at\nhttps://github.com/2000012835xt/ReaLM-DAC.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T13:15:03Z"}
{"aid":"http://arxiv.org/abs/2503.24059v1","title":"Robust Magnetic Polaron Percolation in the Antiferromagnetic CMR System\n  EuCd$_2$P$_2$","summary":"Antiferromagnetic EuCd$_2$P$_2$ has attracted considerable attention due to\nits unconventional (magneto)transport properties. At a temperature $T_{\\rm\npeak}$ significantly above the magnetic ordering temperature $T_\\textrm{N} =\n11\\,$K a large peak in resistivity is observed which gets strongly suppressed\nin magnetic field, resulting in a colossal magnetoresistance (CMR), for which\nmagnetic fluctuations and the formation of ferromagnetic clusters have been\nproposed as underlying mechanisms. Employing a selection of sensitive probes\nincluding fluctuation spectroscopy and third-harmonic resistance, Hall effect,\nAC susceptibility and $\\mu$SR measurements, allows for a direct comparison of\nelectronic and magnetic properties on multiple time scales. We find compelling\nevidence for the formation and percolation of magnetic polarons, which explains\nthe CMR of the system. Large peaks in the weakly-nonlinear transport and the\nresistance noise power spectral density at zero magnetic field signify an\ninhomogeneous, percolating electronic system below $T^\\ast \\approx\n2\\,T_\\textrm{N}$ with a percolation threshold at $T_{\\rm peak}$. In magnetic\nfields, the onset of large negative MR in the paramagnetic regime occurs at a\nuniversal critical magnetization similar to ferromagnetic CMR materials. The\nsize of the magnetic polarons at the percolation threshold is estimated to\n$\\sim 1 - 2\\,$nm. The mechanism of magntic cluster formation and percolation in\nEuCd$_2$P$_2$ appears to be rather robust despite large variations in carrier\nconcentration and likely is relevant for other Eu-based antiferromagnetic CMR\nsystems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:21:07Z"}
{"aid":"http://arxiv.org/abs/2503.24067v1","title":"TransMamba: Flexibly Switching between Transformer and Mamba","summary":"Transformers are the cornerstone of modern large language models, but their\nquadratic computational complexity limits efficiency in long-sequence\nprocessing. Recent advancements in Mamba, a state space model (SSM) with linear\ncomplexity, offer promising efficiency gains but suffer from unstable\ncontextual learning and multitask generalization. This paper proposes\nTransMamba, a novel framework that unifies Transformer and Mamba through shared\nparameter matrices (e.g., QKV and CBx), and thus could dynamically switch\nbetween attention and SSM mechanisms at different token lengths and layers. We\ndesign the Memory converter to bridge Transformer and Mamba by converting\nattention outputs into SSM-compatible states, ensuring seamless information\nflow at TransPoints where the transformation happens. The TransPoint scheduling\nis also thoroughly explored for further improvements. We conducted extensive\nexperiments demonstrating that TransMamba achieves superior training efficiency\nand performance compared to baselines, and validated the deeper consistency\nbetween Transformer and Mamba paradigms, offering a scalable solution for\nnext-generation sequence modeling.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2503.24082v1","title":"NUMEXO2: a versatile digitizer for nuclear physics","summary":"NUMEXO2 is a 16 channels 14bit/200MHz digitizer and processing board\ninitially developed for gamma-ray spectroscopy (for EXOGAM: EXOtic nuclei GAMma\nray). Numexo2 has been gradually extended and improved as a general purpose\ndigitizer to fulfill various needs in nuclear physics detection at GANIL. This\nwas possible thanks to reprogrammable components like FPGAs and the\noptimization of different algorithms. The originality of this work compared to\nsimilar systems is that all numerical operations follow the digital data flow\nfrom ADCs, without any storage step of samples. Some details are given on\ndigital processing of the signals, delivered by a large variety of detectors:\nHPGe, silicon strip detector, ionisation chamber, liquid and plastic\nscintillators read-out with photomultipliers, Multi Wire Proportional Counter\nand drift chamber.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-03-31T13:35:46Z"}
{"aid":"http://arxiv.org/abs/2503.24084v1","title":"Environmental effects in stellar mass gravitational wave sources I:\n  Expected fraction of signals with significant dephasing in the dynamical and\n  AGN channels","summary":"We present the first overview of the expected quantity of signals which will\nshowcase significant gravitational wave phase shifts caused by astrophysical\nenvironments, considering the upcoming A+ and A\\# LIGO/Virgo/KAGRA, Cosmic\nExplorer and Einstein Telescope detectors. We construct and analyse two general\nfamilies of dephasing prescriptions with extensions to eccentric sources, as\nwell as collect five specific prescriptions for the fundamental smoking gun\nphysical mechanisms at play in the dynamical and AGN formation channel for\nstellar mass binary black holes: Roemer delays, tidal forces and hydrodynamical\ninteractions. We compute the expected fraction of signals containing\nastrophysical dephasing, as a function of environmental properties and based on\nobserved distributions of binary parameters. We find that next generation\ndetectors can expect to find environmental effects in hundreds of detected\nsignals.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.GA,gr-qc","published":"2025-03-31T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2503.24100v1","title":"Fuzzing-based Mutation Testing of C/C++ CPS","summary":"Mutation testing can help minimize the delivery of faulty software.\nTherefore, it is a recommended practice for developing embedded software in\nsafety-critical cyber-physical systems (CPS). However, state-of-the-art\nmutation testing techniques for C and C++ software, which are common languages\nfor CPS, depend on symbolic execution. Unfortunately, symbolic execution's\nlimitations hinder its applicability (e.g., systems with black-box components).\n  We propose relying on fuzz testing, which has demonstrated its effectiveness\nfor C and C++ software. Fuzz testing tools automatically create test inputs\nthat explore program branches in various ways, exercising statements in\ndifferent program states, and thus enabling the detection of mutants, which is\nour objective.\n  We empirically evaluated our approach using software components from\noperational satellite systems. Our assessment shows that our approach can\ndetect between 40% and 90% of the mutants not detected by developers' test\nsuites. Further, we empirically determined that the best results are obtained\nby integrating the Clang compiler, a memory address sanitizer, and relying on\nlaf-intel instrumentation to collect coverage and guide fuzzing. Our approach\ndetects a significantly higher percentage of live mutants compared to symbolic\nexecution, with an increase of up to 50 percentage points; further, we observed\nthat although the combination of fuzzing and symbolic execution leads to\nadditional mutants being killed, the benefits are minimal (a gain of less than\none percentage point).","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:55:27Z"}
{"aid":"http://arxiv.org/abs/2503.24105v1","title":"Data-Driven Distributed Output Synchronization of Heterogeneous\n  Discrete-Time Multi-Agent Systems","summary":"In this paper, we assume that an autonomous exosystem generates a reference\noutput, and we consider the problem of designing a distributed data-driven\ncontrol law for a family of discrete-time heterogeneous LTI agents, connected\nthrough a directed graph, in order to synchronize the agents' outputs to the\nreference one. The agents of the network are split into two categories:\nleaders, with direct access to the exosystem output, and followers, that only\nreceive information from their neighbors. All agents aim to achieve output\nsynchronization by means of a state feedback that makes use of their own states\nas well as of an estimate of the exogenous system state, provided by an\ninternal state observer. Such observer has a different structure for leaders\nand followers. Necessary and sufficient conditions for the existence of a\nsolution are first derived in the model-based set-up and then in a data-driven\ncontext. An example illustrates both the implementation procedure and the\nperformance of the proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2503.24106v1","title":"Computing and software for LHCb Upgrade II","summary":"A second major upgrade of the LHCb experiment is necessary to allow full\nexploitation of the High Luminosity LHC for flavour physics. The new experiment\nwill operate in Run 5 of the LHC at a luminosity up to $1.5\\times\n10^{34}cm^{-2}s^{-1}$. The experiment will therefore experience extremely high\nparticle fluences and data rates, posing a high challenge not only for the\ndetector but also for the software and computing resources needed to readout,\nreconstruct, select and analyse the data. This document presents these\nchallenges and the ongoing and future R&D programme necessary to address them.\nThis programme will benefit not only the LHCb Upgrade II experiment, but the\nwhole particle physics community as similar challenges will be faced by the\nnext generation of experiments.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-03-31T13:57:27Z"}
{"aid":"http://arxiv.org/abs/2503.24128v1","title":"Perfect circle-valued Morse functions on hyperbolic 6-manifolds","summary":"We build the first example of a hyperbolic 6-manifold that admits a perfect\ncircle-valued Morse function, which can be considered as the analogue of a\nfibration over the circle for manifolds with non-vanishing Euler\ncharacteristic. As a consequence, we obtain a new example of a subgroup of a\nhyperbolic group which is of type $\\mathcal{F}_2$ but not $\\mathcal{F}_3$.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-03-31T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2503.24130v1","title":"Graph Neural Network-Based Predictive Modeling for Robotic Plaster\n  Printing","summary":"This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.","main_category":"cs.CE","categories":"cs.CE,cs.AI,cs.LG,cs.RO","published":"2025-03-31T14:15:00Z"}
{"aid":"http://arxiv.org/abs/2503.24161v1","title":"Hypergenerated Carnot groups","summary":"In this paper we provide an algebraic characterization of those stratified\ngroups in which boundaries with locally constant normal are locally flat. We\nshow that these groups, which we call hypergenerated, are exactly the\nstratified groups where embeddings of non-characteristic hypersurfaces are\nlocally bi-Lipschitz. Finally, we extend these results to submanifolds of\narbitrary codimension.","main_category":"math.MG","categories":"math.MG,math.DG,math.GR","published":"2025-03-31T14:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.24165v1","title":"Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer\n  Using Multimodal Machine Learning","summary":"Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T14:47:02Z"}
{"aid":"http://arxiv.org/abs/2503.24183v1","title":"Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees\n  via Constrained Mean-Field Reinforcement Learning","summary":"The rapid expansion of ride-sourcing services such as Uber, Lyft, and Didi\nChuxing has fundamentally reshaped urban transportation by offering flexible,\non-demand mobility via mobile applications. Despite their convenience, these\nplatforms confront significant operational challenges, particularly vehicle\nrebalancing - the strategic repositioning of thousands of vehicles to address\nspatiotemporal mismatches in supply and demand. Inadequate rebalancing results\nin prolonged rider waiting times, inefficient vehicle utilization, and\ninequitable distribution of services, leading to disparities in driver\navailability and income.\n  To tackle these complexities, we introduce scalable continuous-state\nmean-field control (MFC) and reinforcement learning (MFRL) models that\nexplicitly represent each vehicle's precise location and employ continuous\nrepositioning actions guided by the distribution of other vehicles. To ensure\nequitable service distribution, an accessibility constraint is integrated\nwithin our optimal control formulation, balancing operational efficiency with\nequitable access to the service across geographic regions. Our approach\nacknowledges realistic conditions, including inherent stochasticity in\ntransitions, the simultaneous occurrence of vehicle-rider matching, vehicles'\nrebalancing and cruising, and variability in rider behaviors. Crucially, we\nrelax the traditional mean-field assumption of equal supply-demand volume,\nbetter reflecting practical scenarios. Extensive empirical evaluation using\nreal-world data-driven simulation of Shenzhen demonstrates the real-time\nefficiency and robustness of our approach at the scale of tens of thousands of\nvehicles.\n  The code is available at\nhttps://github.com/mjusup1501/mf-vehicle-rebalancing.","main_category":"cs.LG","categories":"cs.LG,cs.MA","published":"2025-03-31T15:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.24199v1","title":"Agent-Based Simulations of Online Political Discussions: A Case Study on\n  Elections in Germany","summary":"User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-03-31T15:17:04Z"}
{"aid":"http://arxiv.org/abs/2503.24228v1","title":"PAARS: Persona Aligned Agentic Retail Shoppers","summary":"In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.MA","published":"2025-03-31T15:41:51Z"}
{"aid":"http://arxiv.org/abs/2503.24240v1","title":"Analysis of the French system imbalance paving the way for a novel\n  operating reserve sizing approach","summary":"This paper examines the relationship between system imbalance and several\nexplanatory variables within the French electricity system. The factors\nconsidered include lagged imbalance values, observations of renewable energy\nsources (RES) generation and consumption, and forecasts for RES generation and\nconsumption. The study analyzes the distribution of system imbalance in\nrelation to these variables. Additionally, an HGBR machine-learning model is\nemployed to assess the predictability of imbalances and the explanatory power\nof the input variables studied.\n  The results indicate no clear correlation between RES generation or\nconsumption and the observed imbalances. However, it is possible to predict the\nimbalance adequately using forecasts available a few hours before real-time,\nalong with the lagged values of the imbalance. Predicting the imbalance a day\nin advance proves to be complex with the variables examined; however, the\nextreme quantiles of the imbalance used for reserve sizing and contracting can\nbe predicted with sufficient accuracy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T15:53:47Z"}
{"aid":"http://arxiv.org/abs/2503.24285v1","title":"Advanced Quantum Annealing Approach to Vehicle Routing Problems with\n  Time Windows","summary":"In this paper, we explore the potential for quantum annealing to solve\nrealistic routing problems. We focus on two NP-Hard problems, including the\nTraveling Salesman Problem with Time Windows and the Capacitated Vehicle\nRouting Problem with Time Windows. We utilize D-Wave's Quantum Annealer and\nConstrained Quadratic Model (CQM) solver within a hybrid framework to solve\nthese problems. We demonstrate that while the CQM solver effectively minimizes\nroute costs, it struggles to maintain time window feasibility as the problem\nsize increases. To address this limitation, we implement a heuristic method\nthat fixes infeasible solutions through a series of swapping operations.\nTesting on benchmark instances shows our method achieves promising results with\nan average optimality gap of 3.86%.","main_category":"cs.ET","categories":"cs.ET,quant-ph","published":"2025-03-31T16:32:40Z"}
{"aid":"http://arxiv.org/abs/2503.24300v1","title":"Solving the Best Subset Selection Problem via Suboptimal Algorithms","summary":"Best subset selection in linear regression is well known to be nonconvex and\ncomputationally challenging to solve, as the number of possible subsets grows\nrapidly with increasing dimensionality of the problem. As a result, finding the\nglobal optimal solution via an exact optimization method for a problem with\ndimensions of 1000s may take an impractical amount of CPU time. This suggests\nthe importance of finding suboptimal procedures that can provide good\napproximate solutions using much less computational effort than exact methods.\nIn this work, we introduce a new procedure and compare it with other popular\nsuboptimal algorithms to solve the best subset selection problem. Extensive\ncomputational experiments using synthetic and real data have been performed.\nThe results provide insights into the performance of these methods in different\ndata settings. The new procedure is observed to be a competitive suboptimal\nalgorithm for solving the best subset selection problem for high-dimensional\ndata.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-03-31T16:43:33Z"}
{"aid":"http://arxiv.org/abs/2503.24313v1","title":"1-Tb/s/λ Transmission over Record 10714-km AR-HCF","summary":"We present the first single-channel 1.001-Tb/s DP-36QAM-PCS recirculating\ntransmission over 73 loops of 146.77-km ultra-low-loss & low-IMI DNANF-5 fiber,\nachieving a record transmission distance of 10,714.28 km.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-03-31T17:01:01Z"}
{"aid":"http://arxiv.org/abs/2503.24349v1","title":"Faster Releases, Fewer Risks: A Study on Maven Artifact Vulnerabilities\n  and Lifecycle Management","summary":"In modern software ecosystems, dependency management plays a critical role in\nensuring secure and maintainable applications. However, understanding the\nrelationship between release practices and their impact on vulnerabilities and\nupdate cycles remains a challenge. In this study, we analyze the release\nhistories of 10,000 Maven artifacts, covering over 203,000 releases and 1.7\nmillion dependencies. We evaluate how release speed affects software security\nand lifecycle. Our results show an inverse relationship between release speed\nand dependency outdatedness. Artifacts with more frequent releases maintain\nsignificantly shorter outdated times. We also find that faster release cycles\nare linked to fewer CVEs in dependency chains, indicating a strong negative\ncorrelation. These findings emphasize the importance of accelerated release\nstrategies in reducing security risks and ensuring timely updates. Our research\nprovides valuable insights for software developers, maintainers, and ecosystem\nmanagers.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T17:32:45Z"}
{"aid":"http://arxiv.org/abs/2503.24366v1","title":"StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian\n  Splatting","summary":"3D Gaussian splatting (3DGS) is a popular radiance field method, with many\napplication-specific extensions. Most variants rely on the same core algorithm:\ndepth-sorting of Gaussian splats then rasterizing in primitive order. This\nensures correct alpha compositing, but can cause rendering artifacts due to\nbuilt-in approximations. Moreover, for a fixed representation, sorted rendering\noffers little control over render cost and visual fidelity. For example, and\ncounter-intuitively, rendering a lower-resolution image is not necessarily\nfaster. In this work, we address the above limitations by combining 3D Gaussian\nsplatting with stochastic rasterization. Concretely, we leverage an unbiased\nMonte Carlo estimator of the volume rendering equation. This removes the need\nfor sorting, and allows for accurate 3D blending of overlapping Gaussians. The\nnumber of Monte Carlo samples further imbues 3DGS with a way to trade off\ncomputation time and quality. We implement our method using OpenGL shaders,\nenabling efficient rendering on modern GPU hardware. At a reasonable visual\nquality, our method renders more than four times faster than sorted\nrasterization.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-03-31T17:46:18Z"}
{"aid":"http://arxiv.org/abs/2503.24375v1","title":"Transverse orbital angular momentum: setting the record straight","summary":"The nature of the transverse orbital angular momentum (tOAM) associated with\nspatiotemporal optical vortex (STOV) pulses has been the subject of recent\ndebate. We demonstrate that the approaches to tOAM presented in several recent\npapers are incorrect and lead to unphysical results, including erroneous claims\nof zero total tOAM. We emphasize the importance of calculating the OAM of any\nextended physical object at a common instant of time, and reemphasize the\nspecial status of the centre of energy as a reference point for all OAM\ncalculations. The theory presented in [Phys. Rev. Lett. 127, 193901 (2021)] is\nthe only correct classical field-based framework that both agrees with\nexperiments and provides a self consistent understanding of transverse OAM in\nspatiotemporal light fields.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2503.24384v1","title":"High Energy Emission from the Intrabinary Shocks in Redback Pulsars","summary":"The intrabinary shocks (IBS) of spider pulsars emit non-thermal synchrotron\nX-rays from accelerated electrons and positrons in the shocked pulsar wind,\nlikely energized by magnetic reconnection. In redback spider pulsars, the IBS\ntypically wraps around the sub-stellar companion, leading to a near-normal IBS\nshock with relatively bright X-ray emission. The characteristic energies of\nradiating particles and the magnetic fields in the IBS suggest spectral\nfeatures in the hard X-ray band. Here we perform joint soft-hard X-ray analyses\nof three redback pulsars, J1723-2837, J2215+5135, and J2339-0533, including new\nJ2215 NuSTAR data. We identify a significant cooling break in J1723-2837 and a\nmarginal break in J2215+5135, while placing constraints on the break energy in\nJ2339-0533. Interpreting these as synchrotron cooling features allows us to\nestimate the IBS magnetic field $B_{\\rm IBS} \\sim 40-100$ G and place lower\nbounds on the maximum radiating electron energy. Our results constrain the\nmagnetization of the pulsar wind as well as pair-production in millisecond\npulsar magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.plasm-ph","published":"2025-03-31T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.24389v1","title":"SU-YOLO: Spiking Neural Network for Efficient Underwater Object\n  Detection","summary":"Underwater object detection is critical for oceanic research and industrial\nsafety inspections. However, the complex optical environment and the limited\nresources of underwater equipment pose significant challenges to achieving high\naccuracy and low power consumption. To address these issues, we propose Spiking\nUnderwater YOLO (SU-YOLO), a Spiking Neural Network (SNN) model. Leveraging the\nlightweight and energy-efficient properties of SNNs, SU-YOLO incorporates a\nnovel spike-based underwater image denoising method based solely on integer\naddition, which enhances the quality of feature maps with minimal computational\noverhead. In addition, we introduce Separated Batch Normalization (SeBN), a\ntechnique that normalizes feature maps independently across multiple time steps\nand is optimized for integration with residual structures to capture the\ntemporal dynamics of SNNs more effectively. The redesigned spiking residual\nblocks integrate the Cross Stage Partial Network (CSPNet) with the YOLO\narchitecture to mitigate spike degradation and enhance the model's feature\nextraction capabilities. Experimental results on URPC2019 underwater dataset\ndemonstrate that SU-YOLO achieves mAP of 78.8% with 6.97M parameters and an\nenergy consumption of 2.98 mJ, surpassing mainstream SNN models in both\ndetection accuracy and computational efficiency. These results underscore the\npotential of SNNs for engineering applications. The code is available in\nhttps://github.com/lwxfight/snn-underwater.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-03-31T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.01329v1","title":"Flexible and Explainable Graph Analysis for EEG-based Alzheimer's\n  Disease Classification","summary":"Alzheimer's Disease is a progressive neurological disorder that is one of the\nmost common forms of dementia. It leads to a decline in memory, reasoning\nability, and behavior, especially in older people. The cause of Alzheimer's\nDisease is still under exploration and there is no all-inclusive theory that\ncan explain the pathologies in each individual patient. Nevertheless, early\nintervention has been found to be effective in managing symptoms and slowing\ndown the disease's progression. Recent research has utilized\nelectroencephalography (EEG) data to identify biomarkers that distinguish\nAlzheimer's Disease patients from healthy individuals. Prior studies have used\nvarious machine learning methods, including deep learning and graph neural\nnetworks, to examine electroencephalography-based signals for identifying\nAlzheimer's Disease patients. In our research, we proposed a Flexible and\nExplainable Gated Graph Convolutional Network (GGCN) with Multi-Objective\nTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a\nflexible solution that efficiently identifies the optimal number of GGCN blocks\nto achieve the optimized precision, specificity, and recall outcomes, as well\nas the optimized area under the Receiver Operating Characteristic (AUC). Our\nfindings demonstrated a high efficacy with an over 0.9 Receiver Operating\nCharacteristic score, alongside precision, specificity, and recall scores in\ndistinguishing health control with Alzheimer's Disease patients in Moderate to\nSevere Dementia using the power spectrum density (PSD) of\nelectroencephalography signals across various frequency bands. Moreover, our\nresearch enhanced the interpretability of the embedded adjacency matrices,\nrevealing connectivity differences in frontal and parietal brain regions\nbetween Alzheimer's patients and healthy individuals.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T03:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.01333v1","title":"Reconfigurable Codebook-Based Beamforming for RDARS-Aided mmWave MU-MIMO\n  Systems","summary":"Reconfigurable distributed antenna and reflecting surface (RDARS) is a new\narchitecture for the sixth-generation (6G) millimeter wave (mmWave)\ncommunications. In RDARS-aided mmWave systems, the active and passive\nbeamforming design and working mode configuration for reconfigurable elements\nare crucial for system performance. In this paper, we aim to maximize the\nweighted sum rate (WSR) in the RDARS-aided mmWave system. To take advantage of\nRDARS, we first design a reconfigurable codebook (RCB) in which the number and\ndimension of the codeword can be flexibly adjusted. Then, a low overhead beam\ntraining scheme based on hierarchical search is proposed. Accordingly, the\nactive and passive beamforming for data transmission is designed to achieve the\nmaximum WSR for both space-division multiple access (SDMA) and time-division\nmultiple access (TDMA) schemes. For the TDMA scheme, the optimal number of\nRDARS transmit elements and the allocated power budget for WSR maximization are\nderived in closed form. Besides, the superiority of the RDARS is verified and\nthe conditions under which RDARS outperforms RIS and DAS are given. For the\nSDMA scheme, we characterize the relationship between the number of RDARS\nconnected elements and the user distribution, followed by the derivation of the\noptimal placement positions of the RDARS transmit elements. High-quality\nbeamforming design solutions are derived to minimize the inter-user\ninterference (IUI) at the base station and RDARS side respectively, which\nnearly leads to the maximal WSR. Finally, simulation results confirm our\ntheoretical findings and the superiority of the proposed schemes.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T03:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.01342v1","title":"Foundations and Evaluations in NLP","summary":"This memoir explores two fundamental aspects of Natural Language Processing\n(NLP): the creation of linguistic resources and the evaluation of NLP system\nperformance. Over the past decade, my work has focused on developing a\nmorpheme-based annotation scheme for the Korean language that captures\nlinguistic properties from morphology to semantics. This approach has achieved\nstate-of-the-art results in various NLP tasks, including part-of-speech\ntagging, dependency parsing, and named entity recognition. Additionally, this\nwork provides a comprehensive analysis of segmentation granularity and its\ncritical impact on NLP system performance. In parallel with linguistic resource\ndevelopment, I have proposed a novel evaluation framework, the jp-algorithm,\nwhich introduces an alignment-based method to address challenges in\npreprocessing tasks like tokenization and sentence boundary detection (SBD).\nTraditional evaluation methods assume identical tokenization and sentence\nlengths between gold standards and system outputs, limiting their applicability\nto real-world data. The jp-algorithm overcomes these limitations, enabling\nrobust end-to-end evaluations across a variety of NLP tasks. It enhances\naccuracy and flexibility by incorporating linear-time alignment while\npreserving the complexity of traditional evaluation metrics. This memoir\nprovides key insights into the processing of morphologically rich languages,\nsuch as Korean, while offering a generalizable framework for evaluating diverse\nend-to-end NLP systems. My contributions lay the foundation for future\ndevelopments, with broader implications for multilingual resource development\nand system evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:14:03Z"}
{"aid":"http://arxiv.org/abs/2504.01348v1","title":"Prompt-Guided Attention Head Selection for Focus-Oriented Image\n  Retrieval","summary":"The goal of this paper is to enhance pretrained Vision Transformer (ViT)\nmodels for focus-oriented image retrieval with visual prompting. In real-world\nimage retrieval scenarios, both query and database images often exhibit\ncomplexity, with multiple objects and intricate backgrounds. Users often want\nto retrieve images with specific object, which we define as the Focus-Oriented\nImage Retrieval (FOIR) task. While a standard image encoder can be employed to\nextract image features for similarity matching, it may not perform optimally in\nthe multi-object-based FOIR task. This is because each image is represented by\na single global feature vector. To overcome this, a prompt-based image\nretrieval solution is required. We propose an approach called Prompt-guided\nattention Head Selection (PHS) to leverage the head-wise potential of the\nmulti-head attention mechanism in ViT in a promptable manner. PHS selects\nspecific attention heads by matching their attention maps with user's visual\nprompts, such as a point, box, or segmentation. This empowers the model to\nfocus on specific object of interest while preserving the surrounding visual\ncontext. Notably, PHS does not necessitate model re-training and avoids any\nimage alteration. Experimental results show that PHS substantially improves\nperformance on multiple datasets, offering a practical and training-free\nsolution to enhance model performance in the FOIR task.","main_category":"cs.CV","categories":"cs.CV,cs.IR","published":"2025-04-02T04:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.01364v1","title":"Maximizing the number of stars in graphs with forbidden properties","summary":"Erd\\H{o}s proved an upper bound on the number of edges in an $n$-vertex\nnon-Hamiltonian graph with given minimum degree and showed sharpness via two\nmembers of a particular graph family. F\\\"{u}redi, Kostochka and Luo showed that\nthese two graphs play the same role when ``number of edges'' is replaced by\n``number of t-stars,'' and that two members of a more general graph family\nmaximize the number of edges among non-$k$-edge-Hamiltonian graphs. In this\npaper we generalize their former result from Hamiltonicity to related\nproperties (traceability, Hamiltonian-connectedness, $k$-edge Hamiltonicity,\n$k$-Hamiltonicity) and their latter result from edges to $t$-stars. We identify\na family of extremal graphs for each property that is forbidden. This problem\nwithout the minimum degree condition was also open; here we conjecture a\ncomplete description of the extremal family for each property, and prove the\ncharacterization in some cases. Finally, using a different family of extremal\ngraphs, we find the maximum number of $t$-stars in non-$k$-connected graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T05:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.01371v1","title":"A simple schematic model for a cross section deficit in\n  $^{12}$C+$^{12}$C fusion reactions","summary":"A cross section deficit phenomenon has been observed in $^{12}$C+$^{12}$C\nfusion reactions at astrophysical energies, at which fusion cross sections are\nsuppressed in the off-resonance regions as compared to fusion cross sections\nfor the $^{12}$C+$^{13}$C system. I here construct a simple schematic model\nwhich simulates this phenomenon. The model consists of a random matrix\nHamiltonian based on the Gaussian Orthogonal Ensemble (GOE), which is coupled\nto an entrance channel Hamiltonian in the discrete basis representation. I show\nthat the transmission coefficients are almost unity when both the level density\nand the decay widths of the GOE configurations are large, realizing the strong\nabsorption regime. On the other hand, when these parameters are small, the\ntransmission coefficients are significantly structured as a function of energy.\nIn that situation, the transmission coefficients at resonance energies reach\nunity in this model, that is consistent with the experimental finding of the\ncross section deficit.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-02T05:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.01385v1","title":"Dynamics of ring solitons in an expanding cloud of a Bose-Einstein\n  condensate","summary":"In this paper, we derive equations for the dynamics of ring dark solitons in\nan expanding cloud of a two-dimensional Bose-Einstein condensate. Assuming that\nthe soliton's width is much smaller than its radius, we obtain the Hamilton\nequations for its evolution. Then they are transformed into the Newton\nequation, which is more convenient for applications. The general theory is\nillustrated by the solution of the Newton equation for the case of the axially\nsymmetric condensate cloud, which expands after switching off a harmonic trap.\nThe validity of our approximate analytical approach is confirmed by comparison\nwith the results of numerical simulations of the Gross-Pitaevskii equation.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-02T05:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.01400v1","title":"ToolACE-R: Tool Learning with Adaptive Self-Refinement","summary":"Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-02T06:38:56Z"}
{"aid":"http://arxiv.org/abs/2504.01402v1","title":"A Survey on Physics-based Differentiable Rendering","summary":"Physics-based differentiable rendering has emerged as a powerful technique in\ncomputer graphics and vision, with a broad range of applications in solving\ninverse rendering tasks. At its core, differentiable rendering enables the\ncomputation of gradients with respect to scene parameters, allowing\noptimization-based approaches to solve various problems. Over the past few\nyears, significant advancements have been made in both the underlying theory\nand the practical implementations of differentiable rendering algorithms. In\nthis report, we provide a comprehensive overview of the current state of the\nart in physics-based differentiable rendering, focusing on recent advances in\ngeneral differentiable rendering theory, Monte Carlo sampling strategy, and\ncomputational efficiency.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-02T06:39:50Z"}
{"aid":"http://arxiv.org/abs/2504.01417v1","title":"Hook fusion procedure for direct product of symmetric groups","summary":"In this work, we derive a new expression for the diagonal matrix elements of\nirreducible representations of the direct product group $S_r\\times S_s$ using\nGrime's hook fusion procedure for symmetric groups, which simplifies the fusion\nprocedure by reducing the number of auxiliary parameters needed. By extending\nthis approach to the product group setting, we provide a method for\nconstructing a complete set of orthogonal primitive idempotents.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T07:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.01423v1","title":"Dynamic Incentive Strategies for Smart EV Charging Stations: An\n  LLM-Driven User Digital Twin Approach","summary":"This paper presents an enhanced electric vehicle demand response system based\non large language models, aimed at optimizing the application of\nvehicle-to-grid technology. By leveraging an large language models-driven\nmulti-agent framework to construct user digital twins integrated with\nmultidimensional user profile features, it enables deep simulation and precise\nprediction of users' charging and discharging decision-making patterns.\nAdditionally, a data- and knowledge-driven dynamic incentive mechanism is\nproposed, combining a distributed optimization model under network constraints\nto optimize the grid-user interaction while ensuring both economic viability\nand security. Simulation results demonstrate that the approach significantly\nimproves load peak-valley regulation and charging/discharging strategies.\nExperimental validation highlights the system's substantial advantages in load\nbalancing, user satisfaction and grid stability, providing decision-makers with\na scalable V2G management tool that promotes the sustainable, synergistic\ndevelopment of vehicle-grid integration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T07:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.01434v1","title":"Contribution of ALEGRO to the Update of the European Strategy on\n  Particle Physics","summary":"Advanced and novel accelerators (ANAs), driven a by laser pulse or a\nrelativistic particle bunch, have made remarkable progress over the last\ndecades. They accelerated electrons by 10GeV in 30cm (laser driven) and by\n42GeV in 85cm (particle bunch driven). Rapid progress continues with lasers,\nplasma sources, computational methods, and more. In this document we highlight\nthe main contributions made by the various major collaborations, facilities,\nand experiments that develop ANAs for applications to particle and high-energy\nphysics. These include: ALiVE, ANL-AWA, AWAKE, BNL-ATF, CEPC Injector,\nDESY-KALDERA, ELI ERIC, EuPRAXIA, HALHF, LBNL-BELLA, LBNL-kBELLA, LCvison,\nPETRA IV Injector, 10TeV Collider design, SLAC-FACET II, as well as the\ndevelopment of structures, lasers and plasma sources, and sustainability, and\ndemonstrate the intense activities in the field. ANAs can have, and already\nhave, applications to particle and high-energy physics as subsystems, the\nso-called intermediate applications: injectors, lower energy experiments, beam\ndump experiments, test beds for detectors, etc. Additionally, an ANA could be\nan upgrade for any Higgs factory based on a linear accelerator, as proposed in\nthe LCvison project. ANAs have advantages over other concepts for reaching\nmulti-TeV energies: lower geographical and environmental footprints, higher\nluminosity to power ratio, and are thus more sustainable than other\naccelerators. However, ANAs must still meet a number of challenges before they\ncan produce bunches with parameters and the luminosity required for a linear\ncollider at the energy frontier. It is therefore extremely important to\nstrongly support vigorous R&D of ANAs, because they are, at this time, the most\nsustainable acceleration scheme to reach very high energies with a linear\naccelerator.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-02T07:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.01460v1","title":"K2: On Optimizing Distributed Transactions in a Multi-region Data Store\n  with TrueTime Clocks (Extended Version)","summary":"TrueTime clocks (TTCs) that offer accurate and reliable time within limited\nuncertainty bounds have been increasingly implemented in many clouds.\nMulti-region data stores that seek decentralized synchronization for high\nperformance represent an ideal application of TTC. However, the co-designs\nbetween the two were often undervalued or failed to realize their full\npotential.\n  This paper proposes K2, a multi-region data store that intensely explores the\nopportunity of using TTC for distributed transactions. Compared to its pioneer,\nGoogle Spanner, K2 augments TTC's semantics in three core design pillars.\nFirst, K2 carries a new timestamp-generating scheme that is capable of\nproviding a small time uncertainty bound at scale. Second, K2 revitalizes\nexisting multi-version timestamp-ordered concurrency control to realize\nmulti-version properties for read-write transactions. Third, K2 introduces a\nnew TTC-based visibility control protocol that provides efficient reads at\nreplicas. Our evaluation shows that, K2 achieves an order of magnitude higher\ntransaction throughput relative to other practical geo-distributed transaction\nprotocols while ensuring a lower visibility delay at asynchronous replicas.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.01501v1","title":"Vertex-Based Localization of Erdős-Gallai Theorems for Paths and\n  Cycles","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-02T08:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.01513v1","title":"Laser Annealing of Transparent ZnO Thin Films: A Route to Improve\n  Electrical Conductivity and Oxygen Sensing Capabilities","summary":"The chemical deposition of high-performance Zinc Oxide (ZnO) thin films is\nchallenging, thus significant efforts have been devoted during the past decades\nto develop cost-effective, scalable fabrication methods in gas phase. This work\ndemonstrates how ultra-short-pulse Laser Beam Scanning (LBS) can be used to\nmodulate electrical conductivity in ZnO thin films deposited on soda-lime glass\nby Spatial Atomic Layer Deposition (SALD), a high-throughput, low-temperature\ndeposition technique suitable for large-area applications. By systematically\noptimizing laser parameters, including pulse energy and hatching distance,\nsignificant improvements in the electrical performance of 90 nm-thick ZnO films\nwere achieved. The optimization of the laser annealing parameters, 0.21\nuJ/pulse energy and a 1 micron hatching distance, yielded ZnO films with an\nelectrical resistivity of (9 +- 2) 10-2 Ohm cm, 3 orders of magnitude lower\nthan as deposited films. This result suggests that laser\npost-deposition-processing can play an important role in tailoring the\nproperties of ZnO thin films. Excessive laser intensity can compromise\nstructural integrity of the films, however, degrading their electrical\ntransport properties. Notably, the electrical resistance of laser-annealed ZnO\nfilms exhibited high sensitivity to oxygen concentration in the surrounding\natmosphere, suggesting exciting prospects for application in devices based on\ntransparent oxygen sensors. This study thus positions ultra-short pulsed laser\nannealing as a versatile post-deposition method for fine-tuning the properties\nof ZnO thin films, enabling their use in advanced optoelectronic and\ngas-sensing technologies, particularly on temperature-sensitive substrates.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T09:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01515v1","title":"Training-free Dense-Aligned Diffusion Guidance for Modular Conditional\n  Image Synthesis","summary":"Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T09:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.01523v1","title":"Adapting Knowledge Prompt Tuning for Enhanced Automated Program Repair","summary":"Automated Program Repair (APR) aims to enhance software reliability by\nautomatically generating bug-fixing patches. Recent work has improved the\nstate-of-the-art of APR by fine-tuning pre-trained large language models\n(LLMs), such as CodeT5, for APR. However, the effectiveness of fine-tuning\nbecomes weakened in data scarcity scenarios, and data scarcity can be a common\nissue in practice, limiting fine-tuning performance. To alleviate this\nlimitation, this paper adapts prompt tuning for enhanced APR and conducts a\ncomprehensive study to evaluate its effectiveness in data scarcity scenarios,\nusing three LLMs of different sizes and six diverse datasets across four\nprogramming languages. Prompt tuning rewrites the input to a model by adding\nextra prompt tokens and tunes both the model and the prompts on a small\ndataset. These tokens provide task-specific knowledge that can improve the\nmodel for APR, which is especially critical in data scarcity scenarios.\nMoreover, domain knowledge has proven crucial in many code intelligence tasks,\nbut existing studies fail to leverage domain knowledge during the prompt tuning\nfor APR. To close this gap, we introduce knowledge prompt tuning, an approach\nthat adapts prompt tuning with six distinct types of code- or bug-related\ndomain knowledge for APR. Our work, to the best of our knowledge, is the first\nto adapt and evaluate prompt tuning and the effectiveness of code- or\nbug-related domain knowledge for APR, particularly under data scarcity\nsettings. Our evaluation results demonstrate that prompt tuning with knowledge\ngenerally outperforms fine-tuning under various experimental settings,\nachieving an average improvement of 87.33% over fine-tuning in data scarcity\nscenarios.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.01533v1","title":"LightDefense: A Lightweight Uncertainty-Driven Defense against\n  Jailbreaks via Shifted Token Distribution","summary":"Large Language Models (LLMs) face threats from jailbreak prompts. Existing\nmethods for defending against jailbreak attacks are primarily based on\nauxiliary models. These strategies, however, often require extensive data\ncollection or training. We propose LightDefense, a lightweight defense\nmechanism targeted at white-box models, which utilizes a safety-oriented\ndirection to adjust the probabilities of tokens in the vocabulary, making\nsafety disclaimers appear among the top tokens after sorting tokens by\nprobability in descending order. We further innovatively leverage LLM's\nuncertainty about prompts to measure their harmfulness and adaptively adjust\ndefense strength, effectively balancing safety and helpfulness. The\neffectiveness of LightDefense in defending against 5 attack methods across 2\ntarget LLMs, without compromising helpfulness to benign user queries,\nhighlights its potential as a novel and lightweight defense mechanism,\nenhancing security of LLMs.","main_category":"cs.CR","categories":"cs.CR,cs.CY","published":"2025-04-02T09:21:26Z"}
{"aid":"http://arxiv.org/abs/2504.01550v1","title":"Representation Bending for Large Language Model Safety","summary":"Large Language Models (LLMs) have emerged as powerful tools, but their\ninherent safety risks - ranging from harmful content generation to broader\nsocietal harms - pose significant challenges. These risks can be amplified by\nthe recent adversarial attacks, fine-tuning vulnerabilities, and the increasing\ndeployment of LLMs in high-stakes environments. Existing safety-enhancing\ntechniques, such as fine-tuning with human feedback or adversarial training,\nare still vulnerable as they address specific threats and often fail to\ngeneralize across unseen attacks, or require manual system-level defenses. This\npaper introduces RepBend, a novel approach that fundamentally disrupts the\nrepresentations underlying harmful behaviors in LLMs, offering a scalable\nsolution to enhance (potentially inherent) safety. RepBend brings the idea of\nactivation steering - simple vector arithmetic for steering model's behavior\nduring inference - to loss-based fine-tuning. Through extensive evaluation,\nRepBend achieves state-of-the-art performance, outperforming prior methods such\nas Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success\nrates across diverse jailbreak benchmarks, all with negligible reduction in\nmodel usability and general capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CR","published":"2025-04-02T09:47:01Z"}
{"aid":"http://arxiv.org/abs/2504.01565v1","title":"Learning and criticality in a self-organizing model of connectome growth","summary":"The exploration of brain networks has reached an important milestone as\nrelatively large and reliable information has been gathered for connectomes of\ndifferent species. Analyses of connectome data sets reveal that the structural\nlength and the distributions of in- and out-node strengths follow heavy-tailed\nlognormal statistics, while the functional network properties exhibit powerlaw\ntails, suggesting that the brain operates close to a critical point where\ncomputational capabilities and sensitivity to stimulus is optimal. Because\nthese universal network features emerge from bottom-up (self-)organization, one\ncan pose the question of whether they can be modeled via a common framework,\nparticularly through the lens of criticality of statistical physical systems.\nHere, we simultaneously reproduce the powerlaw statistics of connectome edge\nweights and the lognormal distributions of node strengths from an\navalanche-type model with learning that operates on baseline networks that\nmimic the neuronal circuitry. We observe that the avalanches created by a\nsandpile-like model on simulated neurons connected by a hierarchical modular\nnetwork (HMN) produce robust powerlaw avalanche size distributions with\ncritical exponents of 3/2 characteristic of neuronal systems. Introducing\nHebbian learning, wherein neurons that `fire together, wire together,' recovers\nthe powerlaw distribution of edge weights and the lognormal distributions of\nnode degrees, comparable to those obtained from connectome data. Our results\nstrengthen the notion of a critical brain, one whose local interactions drive\nconnectivity and learning without a need for external intervention and precise\ntuning.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-02T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.01576v1","title":"Strong Nonlinear Flexoelectricity in Bulk Ferroelectrics","summary":"Flexoelectricity induced by strain gradient in dielectrics is highly\ndesirable for electromechanical actuating and sensing systems. It is broadly\nadopted that flexoelectric polarization responds linearly to strain gradient\nwithout considering nonlinearity. Consequently, the implication of nonlinear\nflexoelectricity in electromechanical systems remains unclear. Herein, we\nestablish a nonlinear constitutive model for flexoelectricity and thereby\npropose a strategy for quantitatively measuring its nonlinearity through the\nhigh-order harmonic generations. A strong nonlinear flexoelectricity in bulk\nferroelectrics is revealed and its coefficient is determined, as evidenced by\ntheir nonlinear dependence of harmonics on strain gradient. On this basis, we\nillustrate the nonlinear flexoelectricity manifests a functionality to\ntransduce mixed mechanical excitations into coherent electrical signals\nfeaturing difference- and sum-frequencies, thereby offering utilization in\nsignal processing for frequency conversion. These findings emphasize the\nsignificance of nonlinear flexoelectricity in ferroelectrics and open up new\nopportunities for designing electromechanical transducer based on nonlinear\nflexoelectricity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.01579v1","title":"Conditions for Unitarity in Timeless Quantum Theory","summary":"Quantum timeless approaches solve the problem of time by recovering the usual\nunitary evolution of quantum theory relative to a clock in a stationary quantum\nUniverse. For some Hamiltonians of the Universe, such as those including an\ninteraction term with the clock, the dynamics is substantially altered and can\nbe non-unitary. This work derives necessary and sufficient conditions for the\nrelative dynamics to be unitary and finds the general form of the unitary\nevolution operator. A physical interpretation of these conditions is given in\nterms of the clock's rate. Unitary dynamics is associated with rates that are\nconstant in time and independent of the clock's internal structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.01582v1","title":"MERE: Hardware-Software Co-Design for Masking Cache Miss Latency in\n  Embedded Processors","summary":"Runahead execution is a technique to mask memory latency caused by irregular\nmemory accesses. By pre-executing the application code during occurrences of\nlong-latency operations and prefetching anticipated cache-missed data into the\ncache hierarchy, runahead effectively masks memory latency for subsequent cache\nmisses and achieves high prefetching accuracy; however, this technique has been\nlimited to superscalar out-of-order and superscalar in-order cores. For\nimplementation in scalar in-order cores, the challenges of\narea-/energy-constraint and severe cache contention remain.\n  Here, we build the first full-stack system featuring runahead, MERE, from SoC\nand a dedicated ISA to the OS and programming model. Through this deployment,\nwe show that enabling runahead in scalar in-order cores is possible, with\nminimal area and power overheads, while still achieving high performance. By\nre-constructing the sequential runahead employing a hardware/software co-design\napproach, the system can be implemented on a mature processor and SoC. Building\non this, an adaptive runahead mechanism is proposed to mitigate the severe\ncache contention in scalar in-order cores. Combining this, we provide a\ncomprehensive solution for embedded processors managing irregular workloads.\nOur evaluation demonstrates that the proposed MERE attains 93.5% of a 2-wide\nout-of-order core's performance while constraining area and power overheads\nbelow 5%, with the adaptive runahead mechanism delivering an additional 20.1%\nperformance gain through mitigating the severe cache contention issues.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T10:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.01583v1","title":"LL-Localizer: A Life-Long Localization System based on Dynamic i-Octree","summary":"This paper proposes an incremental voxel-based life-long localization method,\nLL-Localizer, which enables robots to localize robustly and accurately in\nmulti-session mode using prior maps. Meanwhile, considering that it is\ndifficult to be aware of changes in the environment in the prior map and robots\nmay traverse between mapped and unmapped areas during actual operation, we will\nupdate the map when needed according to the established strategies through\nincremental voxel map. Besides, to ensure high performance in real-time and\nfacilitate our map management, we utilize Dynamic i-Octree, an efficient\norganization of 3D points based on Dynamic Octree to load local map and update\nthe map during the robot's operation. The experiments show that our system can\nperform stable and accurate localization comparable to state-of-the-art LIO\nsystems. And even if the environment in the prior map changes or the robots\ntraverse between mapped and unmapped areas, our system can still maintain\nrobust and accurate localization without any distinction. Our demo can be found\non Blibili (https://www.bilibili.com/video/BV1faZHYCEkZ) and youtube\n(https://youtu.be/UWn7RCb9kA8) and the program will be available at\nhttps://github.com/M-Evanovic/LL-Localizer.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T10:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.01600v1","title":"Automatic Estimation of Pedestrian Gait Features using a single camera\n  recording: Algorithm and Statistical Analysis for Gender Difference and\n  Obstacle Interactions","summary":"The pedestrian gait features - body sway frequency, amplitude, stride length,\nand speed, along with pedestrian personal space and directional bias, are\nimportant parameters to be used in different pedestrian dynamics studies. Gait\nfeature measurements are paramount for wide-ranging applications, varying from\nthe medical field to the design of bridges. Personal space and choice of\ndirection (directional bias) play important roles during crowd simulations. In\nthis study, we formulate an automatic algorithm for calculating the gait\nfeatures of a trajectory extracted from video recorded using a single camera\nattached to the roof of a building. Our findings indicate that females have\n28.64% smaller sway amplitudes, 8.68% smaller stride lengths, and 8.14% slower\nspeeds compared to males, with no significant difference in frequency. However,\naccording to further investigation, our study reveals that the body parameters\nare the main variables that dominate gait features rather than gender. We have\nconducted three experiments in which the volunteers are walking towards the\ndestination a) without any obstruction, b) with a stationary non-living\nobstacle present in the middle of the path, and c) with a human being standing\nin the middle of the path. From a comprehensive statistical analysis, key\nobservations include no significant difference in gait features with respect to\ngender, no significant difference in gait features in the absence or presence\nof an obstacle, pedestrians treating stationary human beings and stationary\nobstacles the same given that the gender is same to match the comfort level,\nand a directional bias towards the left direction, likely influenced by\nleft-hand traffic rule in India.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T11:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01612v1","title":"The Mini-SiTian Array: first-two-year operation","summary":"The SiTian project, designed to utilize 60 telescopes distributed across\nmultiple sites in China, is a next-generation time-domain survey initiative. As\na pathfinder for the SiTian project, the Mini-SiTian (MST) has been proposed\nand implemented to test the SiTian's brain and data pipeline, and to evaluate\nthe feasibility of its technology and science cases. Mounted at the Xinglong\nObservatory, the MST project comprises three 30 cm telescopes and has been\noperated since Nov. 2022. Each telescope of the MST possesses a large field of\nview, covering $2.29^{\\circ}$ $\\times$ $1.53^{\\circ}$ FOV, and is equipped with\n$g'$, $r'$ and $i'$ filters, respectively. Acting as the pioneer of the\nforthcoming SiTian project, the MST is dedicated to the discovery of variable\nstars, transients, and outburst events, and has already obtained some\ninteresting scientific results. In this paper, we will summarize the\nfirst-two-year operation of the MST project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:07Z"}
{"aid":"http://arxiv.org/abs/2504.01676v1","title":"Satellite Edge Artificial Intelligence with Large Models: Architectures\n  and Technologies","summary":"Driven by the growing demand for intelligent remote sensing applications,\nlarge artificial intelligence (AI) models pre-trained on large-scale unlabeled\ndatasets and fine-tuned for downstream tasks have significantly improved\nlearning performance for various downstream tasks due to their generalization\ncapabilities. However, many specific downstream tasks, such as extreme weather\nnowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield\nsurveillance, require real-time data processing. Traditional methods via\ntransferring raw data to ground stations for processing often cause significant\nissues in terms of latency and trustworthiness. To address these challenges,\nsatellite edge AI provides a paradigm shift from ground-based to on-board data\nprocessing by leveraging the integrated communication-and-computation\ncapabilities in space computing power networks (Space-CPN), thereby enhancing\nthe timeliness, effectiveness, and trustworthiness for remote sensing\ndownstream tasks. Moreover, satellite edge large AI model (LAM) involves both\nthe training (i.e., fine-tuning) and inference phases, where a key challenge\nlies in developing computation task decomposition principles to support\nscalable LAM deployment in resource-constrained space networks with\ntime-varying topologies. In this article, we first propose a satellite\nfederated fine-tuning architecture to split and deploy the modules of LAM over\nspace and ground networks for efficient LAM fine-tuning. We then introduce a\nmicroservice-empowered satellite edge LAM inference architecture that\nvirtualizes LAM components into lightweight microservices tailored for\nmulti-task multimodal inference. Finally, we discuss the future directions for\nenhancing the efficiency and scalability of satellite edge LAM, including\ntask-oriented communication, brain-inspired computing, and satellite edge AI\nnetwork optimization.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI,eess.SP","published":"2025-04-02T12:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.01680v1","title":"Arbitrary gauge quantisation of light-matter theories with\n  time-dependent constraints","summary":"We provide a general framework for the quantisation of light-matter theories\nwith time-dependent holonomic constraints. Unless time dependence is present\nfrom the outset at the Lagrangian level, different gauges generally produce\nnon-equivalent canonical theories. The irrotational gauge is defined as that\nwhich also yields a correct theory when time dependence is introduced at the\nHamiltonian level. We unify examples of such gauges found in existing\nliterature. In particular, we show that for describing time-dependent\nlight-matter interactions the Coulomb gauge is not generally irrotational, so\nit does not enjoy any special status, contradicting the conclusions in Phys.\nRev. A 107, 013722 (2023) and Phys. Rev. Research 3, 023079 (2021), while\nreaffirming the prior treatment and conclusions reported in Phys. Rev. Research\n3, 013116 (2021).","main_category":"quant-ph","categories":"quant-ph,cond-mat.supr-con,hep-th,physics.atom-ph,physics.optics","published":"2025-04-02T12:27:00Z"}
{"aid":"http://arxiv.org/abs/2504.01692v1","title":"Segmentation variability and radiomics stability for predicting\n  Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging","summary":"Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-04-02T12:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01707v1","title":"InfiniteICL: Breaking the Limit of Context Window Size via Long\n  Short-term Memory Transformation","summary":"In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T13:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.01730v1","title":"AI-Driven Framework for Multi-Service Multi-Modal Devices in NextG ORAN\n  Systems","summary":"In this paper, an artificial intelligence (AI)-driven efficient RAN\nmanagement framework is proposed. This framework introduces the concept of a\nintroducing the multi-service-modal UE (MSMU) system, which allows a single UE\nto handle both eMBB and uRLLC services. The proposed framework integrates\ntraffic demand prediction, route optimization, RAN slicing, service\nidentification, and radio resource management under uncertainty. The challenge\nof dynamic environments in such a system is addressed by decomposing the\noptimization problem into long-term (L-SP) and short-term (S-SP) subproblems.\nUsing a long short-term memory (LSTM) model, the proposed approach allows the\nprediction of eMBB and uRLLC traffic demands and optimal routes for RAN slicing\nin the L-SP. For the S-SP, another LSTM model is employed to handle real-time\nservice type identification and resource management based on long-term\npredictions. To support continuous adaptation, continual learning is\nincorporated into the S-SP framework, allowing the model to learn new service\ntypes while retaining prior knowledge. Experimental results show that the\nproposed framework efficiently manages dual-mode UEs, achieving low mean square\nerror for traffic demand (0.003), resource block prediction (0.003), and power\nprediction (0.002), with 99\\% accuracy in service type and route selection and\nover 95\\% average accuracy for continual service adaptation across seven tasks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T13:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.01732v1","title":"FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D\n  Scene Reconstruction and Benchmarking","summary":"The development of large-scale 3D scene reconstruction and novel view\nsynthesis methods mostly rely on datasets comprising perspective images with\nnarrow fields of view (FoV). While effective for small-scale scenes, these\ndatasets require large image sets and extensive structure-from-motion (SfM)\nprocessing, limiting scalability. To address this, we introduce a fisheye image\ndataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye\nlenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoor\nscenes. Each scene has sparse SfM point clouds and precise LIDAR-derived dense\npoint clouds that can be used as geometric ground-truth, enabling robust\nbenchmarking under challenging conditions such as occlusions and reflections.\nWhile the baseline experiments focus on vanilla Gaussian Splatting and NeRF\nbased Nerfacto methods, the dataset supports diverse approaches for scene\nreconstruction, novel view synthesis, and image-based rendering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.01736v1","title":"Design and Experimental Validation of an Urban Microclimate Tool\n  Integrating Indoor-Outdoor Detailed Longwave Radiative Fluxes at District\n  Scale","summary":"Numerical simulation is a powerful tool for assessing the causes of an Urban\nHeat Island (UHI) effect or quantifying the impact of mitigation solutions on\noutdoor and indoor thermal comfort. For that purpose, several models have been\ndeveloped at the district scale. At this scale, the outside surface energy\nbudget is detailed, however building models are very simplified and considered\nas a boundary condition of the district scale model. This shortcoming inhibits\nthe opportunity to investigate the effect of urban microclimate on the inside\nbuilding conditions. The aim of this work is to improve the representation of\nthe physical phenomena involved in the building models of a district model. For\nthat purpose, the model integrates inside and outside fully detailed long-wave\nradiative flux. The numerical model is based on finite differences to solve\nconduction through all the surfaces and the radiosity method to solve long-wave\nradiative heat fluxes inside and outside. Calculated temperatures and heat\nfluxes are evaluated with respect to \\textit{in situ} measurements from an\nexperimental demonstrator over 14 sensors and a 24-day period. Results are also\ncompared to state-of-the-art models simulation tool show improvement of the\nRMSE of $0.9 \\ \\mathsf{^{\\,\\circ}C}$ to $2.1 \\ \\mathsf{^{\\,\\circ}C}$ on the\nsurface temperature modeled.","main_category":"cs.CE","categories":"cs.CE,I.6","published":"2025-04-02T13:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.01800v1","title":"Motility and rotation of multi-timescale microswimmers in linear\n  background flows","summary":"Microswimming cells and robots exhibit diverse behaviours due to both their\nswimming and their environment. One of the core environmental features\nimpacting inertialess swimming is background flows. While the influence of\nselect flows, particularly shear flows, have been extensively investigated,\nthese are special cases. Here, we examine inertialess swimmers in more general\nflows, specifically general linear planar flows that may also possess rapid\noscillations. Relatively weak symmetry constraints are imposed on the swimmer\nto ensure planarity and to reduce complexity. A further constraint reflecting\ncommon observation is imposed, namely that the swimmer is inefficient, which we\nsuitably define. This introduces two separate timescales: a fast timescale\nassociated with swimmer actuation, and a second timescale associated with net\nswimmer movement, with inefficiency dictating that this latter timescale is\nmuch slower, allowing for a multiple timescale simplification of the governing\nequations. With the exception of mathematically precise edge cases, we find\nthat the behaviour of the swimmer is dictated by two parameter groupings, both\nof which measure balances between the angular velocity and rate of strain of\nthe background flow. While the measures of flow angular velocity and strain\nrates that primarily govern the rotational dynamics are modulated by swimmer\nproperties, the primary features of the translational motion are determined\nsolely by a ratio of flow angular velocity to strain rate. Hence, a simple\nclassification of the swimmer dynamics emerges. For example, this illustrates\nthe limited extent to which, and how, microswimmers may control their\norientations and trajectories in flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T15:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.01825v1","title":"How the microphysical properties of external photoevaporation influence\n  the global evolution of protoplanetary discs","summary":"External photoevaporation is one of the dominant mechanisms for mass loss\nfrom protoplanetary discs. However this mass loss is theoretically expected to\ndepend upon the microphysical properties of protoplanetary discs, which are\ncurrently poorly constrained in observations. In this work we explore the\nimpact of microphysics on the bulk evolution of discs. The polycyclic aromatic\nhydrocarbon (PAH) abundance, and the extent to which grain growth has occurred\nin the disc have profound effects on the strength of mass loss rates due to\nexternal photoevaporation, which in turn can have a significant impact on the\ndisc evolution, impacting disc radii and accretion rates over time. The\nstrongest sensitivity is to whether grain growth has occurred in the disc,\nwhich reduces the amount of dust entrained in the wind to shield the disc, thus\nincreasing the rate at which gas is lost. Additionally, larger PAH abundances\nresult in stronger heating and higher mass loss rates, but to a lesser extent\nthan grain growth. We find that plausible variations in the PAH abundance and\ndisc dust evolution can leave observable differences in disc populations. This\nwork highlights the importance of obtaining observational constraints of the\nmicrophysical properties of protoplanetary discs. Future observations from JWST\nshould soon be able to provide these constraints.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T15:30:58Z"}
{"aid":"http://arxiv.org/abs/2504.01835v1","title":"Autonomous optical navigation for DESTINY+: Enhancing misalignment\n  robustness in flyby observations with a rotating telescope","summary":"DESTINY+ is an upcoming JAXA Epsilon medium-class mission to flyby multiple\nasteroids including Phaethon. As an asteroid flyby observation instrument, a\ntelescope mechanically capable of single-axis rotation, named TCAP, is mounted\non the spacecraft to track and observe the target asteroids during flyby. As in\npast flyby missions utilizing rotating telescopes, TCAP is also used as a\nnavigation camera for autonomous optical navigation during the closest-approach\nphase. To mitigate the degradation of the navigation accuracy, past missions\nperformed calibration of the navigation camera's alignment before starting\noptical navigation. However, such calibration requires significant operational\ntime to complete and imposes constraints on the operation sequence. From the\nabove background, the DESTINY+ team has studied the possibility of reducing\noperational costs by allowing TCAP alignment errors to remain. This paper\ndescribes an autonomous optical navigation algorithm robust to the misalignment\nof rotating telescopes, proposed in this context. In the proposed method, the\nmisalignment of the telescope is estimated simultaneously with the spacecraft's\norbit relative to the flyby target. To deal with the nonlinearity between the\nmisalignment and the observation value, the proposed method utilizes the\nunscented Kalman filter, instead of the extended Kalman filter widely used in\npast studies. The proposed method was evaluated with numerical simulations on a\nPC and with hardware-in-the-loop simulation, taking the Phaethon flyby in the\nDESTINY+ mission as an example. The validation results suggest that the\nproposed method can mitigate the misalignment-induced degradation of the\noptical navigation accuracy with reasonable computational costs suited for\nonboard computers.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.LG","published":"2025-04-02T15:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.01844v1","title":"BOGausS: Better Optimized Gaussian Splatting","summary":"3D Gaussian Splatting (3DGS) proposes an efficient solution for novel view\nsynthesis. Its framework provides fast and high-fidelity rendering. Although\nless complex than other solutions such as Neural Radiance Fields (NeRF), there\nare still some challenges building smaller models without sacrificing quality.\nIn this study, we perform a careful analysis of 3DGS training process and\npropose a new optimization methodology. Our Better Optimized Gaussian Splatting\n(BOGausS) solution is able to generate models up to ten times lighter than the\noriginal 3DGS with no quality degradation, thus significantly boosting the\nperformance of Gaussian Splatting compared to the state of the art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:49:23Z"}
{"aid":"http://arxiv.org/abs/2504.01851v1","title":"Virtual Target Trajectory Prediction for Stochastic Targets","summary":"Trajectory prediction of other vehicles is crucial for autonomous vehicles,\nwith applications from missile guidance to UAV collision avoidance. Typically,\ntarget trajectories are assumed deterministic, but real-world aerial vehicles\nexhibit stochastic behavior, such as evasive maneuvers or gliders circling in\nthermals. This paper uses Conditional Normalizing Flows, an unsupervised\nMachine Learning technique, to learn and predict the stochastic behavior of\ntargets of guided missiles using trajectory data. The trained model predicts\nthe distribution of future target positions based on initial conditions and\nparameters of the dynamics. Samples from this distribution are clustered using\na time series k-means algorithm to generate representative trajectories, termed\nvirtual targets. The method is fast and target-agnostic, requiring only\ntraining data in the form of target trajectories. Thus, it serves as a drop-in\nreplacement for deterministic trajectory predictions in guidance laws and path\nplanning. Simulated scenarios demonstrate the approach's effectiveness for\naerial vehicles with random maneuvers, bridging the gap between deterministic\npredictions and stochastic reality, advancing guidance and control algorithms\nfor autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T16:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.01879v1","title":"TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving\n  Semi-structured Tables","summary":"Humans continuously make new discoveries, and understanding temporal sequence\nof events leading to these breakthroughs is essential for advancing science and\nsociety. This ability to reason over time allows us to identify future steps\nand understand the effects of financial and political decisions on our lives.\nHowever, large language models (LLMs) are typically trained on static datasets,\nlimiting their ability to perform effective temporal reasoning. To assess the\ntemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES\ndataset, which comprises 3,971 questions derived from over 14,000 tables,\nspanning 1,238 entities across multiple time periods. We introduce a\ntemplate-based question-generation pipeline that harnesses LLMs to refine both\ntemplates and questions. Additionally, we establish baseline results using\nstate-of-the-art LLMs to create a benchmark. We also introduce novel modeling\nstrategies centered around task decomposition, enhancing LLM performance.","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.IR","published":"2025-04-02T16:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.01885v1","title":"Observing Spatial Charge and Spin Correlations in a Strongly-Interacting\n  Fermi Gas","summary":"Two-dimensional correlated fermions constitute a cornerstone of quantum\nmatter, covering a broad fundamental and technological scope, and have\nattracted increasing interest with the emergence of modern materials such as\nhigh-$T_{\\rm c}$ superconductors, graphene, topological insulators, and Moir\\'e\nstructures. Atom-based quantum simulators provide a new pathway to understand\nthe microscopic mechanisms occurring at the heart of such systems. In this\nwork, we explore two-dimensional attractive Fermi gases at the microscopic\nlevel by probing spatial charge and spin correlations in situ. Using\natom-resolved continuum quantum gas microscopy, we directly observe fermion\npairing and study the evolution of two- and three-point correlation functions\nas inter-spin attraction is increased. The precision of our measurement allows\nus to reveal a marked dip in the pair correlation function, fundamentally\nforbidden by the mean-field result based on Bardeen-Cooper-Schrieffer (BCS)\ntheory but whose existence we confirm in exact auxiliary-field quantum Monte\nCarlo calculations. We demonstrate that the BCS prediction is critically\ndeficient not only in the superfluid crossover regime but also deep in the\nweakly attractive side. Guided by our measurements, we find a remarkable\nrelation between two- and three-point correlations that establishes the\ndominant role of pair-correlations. Finally, leveraging local single-pair\nlosses, we independently characterize the short-range behavior of pair\ncorrelations, via the measurement of Tan's Contact, and find excellent\nagreement with numerical predictions. Our measurements provide an unprecedented\nmicroscopic view into two-dimensional Fermi gases and constitute a paradigm\nshift for future studies of strongly-correlated fermionic matter in the\ncontinuum.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-02T16:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.01886v1","title":"GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical\n  Reasoning","summary":"Recent advances in general medical AI have made significant strides, but\nexisting models often lack the reasoning capabilities needed for complex\nmedical decision-making. This paper presents GMAI-VL-R1, a multimodal medical\nreasoning model enhanced by reinforcement learning (RL) to improve its\nreasoning abilities. Through iterative training, GMAI-VL-R1 optimizes\ndecision-making, significantly boosting diagnostic accuracy and clinical\nsupport. We also develop a reasoning data synthesis method, generating\nstep-by-step reasoning data via rejection sampling, which further enhances the\nmodel's generalization. Experimental results show that after RL training,\nGMAI-VL-R1 excels in tasks such as medical image diagnosis and visual question\nanswering. While the model demonstrates basic memorization with supervised\nfine-tuning, RL is crucial for true generalization. Our work establishes new\nevaluation benchmarks and paves the way for future advancements in medical\nreasoning models. Code, data, and model will be released at\n\\href{https://github.com/uni-medical/GMAI-VL-R1}{this link}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T16:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.01892v1","title":"Synchro-curvature description of γ-ray light curves and spectra\n  of pulsars: concurrent fitting","summary":"We present a concurrent fitting of spectra and light curves of the whole\npopulation of detected gamma-ray pulsars. Using a synchro-curvature model we\ncompare our theoretical output with the observational data published in the\nThird Fermi Pulsar Catalog, which has significantly increased the number of\nknown gamma-ray pulsars. Our model properly fits all the spectra and reproduces\nwell a considerable fraction of light curves. Light curve fitting is carried\nout with two different techniques, whose strong points and caveats are\ndiscussed. We use a weighted reduced \\{chi}^2 of light curves in time domain,\nand the Euclidean distance of the Fourier transform of the light curves, i.e.\ntransforming the light curves to the frequency domain. The performance of both\nmethods is found to be qualitatively similar, but individual best-fit solutions\nmay differ. We also show that, in our model based on few effective parameters,\nthe light curve fitting is basically insensitive to the timing and spectral\nparameters of the pulsar. Finally, we look for correlations between model and\nphysical parameters, and recover trends found in previous studies but without\nany significant correlation involving geometrical parameters.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-02T16:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.01893v1","title":"A minimal Pati-Salam theory: from cosmic defects to gravitational waves\n  and colliders","summary":"We discuss a minimal renormalizable Pati-Salam theory based on the\n$SU(4)_{\\rm C}\\,\\times\\,SU(2)_{\\rm L}\\,\\times\\,SU(2)_{\\rm R}$ gauge group, with\nunification scale Higgs multiplets taken as $SU(2)_{\\rm L}$ and $SU(2)_{\\rm R}$\ndoublets, which lead to neutrino Dirac picture. Although a number of scalar\nparticles could be light, even lying at the LHC energies, the unification scale\nis hopelessly out of reach in any foreseeable future. Moreover, phase\ntransition in the early Universe leads to the production of magnetic monopoles\nand domain walls, both incompatible with the standard cosmological model. A\nsmall explicit breaking of the discrete left-right symmetry allows the domain\nwalls to decay, and in the process possibly sweep away the monopoles,\nanalogously to the previously discussed case of $SU(5)$ grand unified theory.\nThis leaves an important imprint of gravitational waves, within the reach of\nnext generation searches, correlated with monopole detection and new light\nparticles at collider energies. The theory has a dark matter candidate in the\nform of an inert scalar doublet, with a mass below TeV, which can further\ntrigger electroweak baryogenesis.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,hep-ex","published":"2025-04-02T16:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.01923v1","title":"Sliding Dynamics of Skyrmion Molecular Crystals","summary":"Using both atomistic and particle-based simulations, we investigate the\ncurrent-driven dynamics of skyrmions on two-dimensional periodic substrates\nwhen there are multiple skyrmions per substrate minimum. At zero drive, the\nsystem forms pinned skyrmion molecular crystal states consisting of dimers,\ntrimers, or dimer-trimer mixtures that have both positional and orientational\norder. On a square substrate lattice, the motion above depinning occurs via a\nrunning soliton that travels completely transverse to the applied current. This\nmotion is generated by a torque from the Magnus force, which rotates the\n$n$-mer states perpendicular to the applied current. At higher drives, the flow\nbecomes disordered while the Hall angle diminishes and gradually approaches the\nintrinsic value. In some cases, we also find directional locking where the Hall\nangle becomes locked to certain symmetry directions of the substrate over a\nrange of currents. The transitions into and out of directionally locked states\nare accompanied by negative differential mobility in which the net velocity\ndecreases as the drive increases. On a triangular substrate, we find no\ntransverse mobility effects, but still observe directionally locked motion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T17:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.01925v1","title":"Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution\n  Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time","summary":"Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T17:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.01944v1","title":"Graphon games and an idealized limit of large network games","summary":"Graphon games are a class of games with a continuum of agents, introduced to\napproximate the strategic interactions in large network games. The first result\nof this study is an equilibrium existence theorem in graphon games, under the\nsame conditions as those in network games. We prove the existence of an\nequilibrium in a graphon game with an infinite-dimensional strategy space,\nunder the continuity and quasi-concavity of the utility functions. The second\nresult characterizes Nash equilibria in graphon games as the limit points of\nasymptotic Nash equilibria in large network games. If a sequence of large\nnetwork games converges to a graphon game, any convergent sequence of\nasymptotic Nash equilibria in these large network games also converges to a\nNash equilibrium of the graphon game. In addition, for any graphon game and its\nequilibrium, there exists a sequence of large network games that converges to\nthe graphon game and has asymptotic Nash equilibria converging to the\nequilibrium. These results suggest that the concept of a graphon game is an\nidealized limit of large network games as the number of players tends to\ninfinity.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.01952v1","title":"Image Difference Grounding with Natural Language","summary":"Visual grounding (VG) typically focuses on locating regions of interest\nwithin an image using natural language, and most existing VG methods are\nlimited to single-image interpretations. This limits their applicability in\nreal-world scenarios like automatic surveillance, where detecting subtle but\nmeaningful visual differences across multiple images is crucial. Besides,\nprevious work on image difference understanding (IDU) has either focused on\ndetecting all change regions without cross-modal text guidance, or on providing\ncoarse-grained descriptions of differences. Therefore, to push towards\nfiner-grained vision-language perception, we propose Image Difference Grounding\n(IDG), a task designed to precisely localize visual differences based on user\ninstructions. We introduce DiffGround, a large-scale and high-quality dataset\nfor IDG, containing image pairs with diverse visual variations along with\ninstructions querying fine-grained differences. Besides, we present a baseline\nmodel for IDG, DiffTracker, which effectively integrates feature differential\nenhancement and common suppression to precisely locate differences. Experiments\non the DiffGround dataset highlight the importance of our IDG dataset in\nenabling finer-grained IDU. To foster future research, both DiffGround data and\nDiffTracker model will be publicly released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.01954v1","title":"Towards Unified Referring Expression Segmentation Across Omni-Level\n  Visual Target Granularities","summary":"Referring expression segmentation (RES) aims at segmenting the entities'\nmasks that match the descriptive language expression. While traditional RES\nmethods primarily address object-level grounding, real-world scenarios demand a\nmore versatile framework that can handle multiple levels of target granularity,\nsuch as multi-object, single object or part-level references. This introduces\ngreat challenges due to the diverse and nuanced ways users describe targets.\nHowever, existing datasets and models mainly focus on designing grounding\nspecialists for object-level target localization, lacking the necessary data\nresources and unified frameworks for the more practical multi-grained RES. In\nthis paper, we take a step further towards visual granularity unified RES task.\nTo overcome the limitation of data scarcity, we introduce a new\nmulti-granularity referring expression segmentation (MRES) task, alongside the\nRefCOCOm benchmark, which includes part-level annotations for advancing\nfiner-grained visual understanding. In addition, we create MRES-32M, the\nlargest visual grounding dataset, comprising over 32.2M masks and captions\nacross 1M images, specifically designed for part-level vision-language\ngrounding. To tackle the challenges of multi-granularity RES, we propose\nUniRES++, a unified multimodal large language model that integrates\nobject-level and part-level RES tasks. UniRES++ incorporates targeted designs\nfor fine-grained visual feature exploration. With the joint model architecture\nand parameters, UniRES++ achieves state-of-the-art performance across multiple\nbenchmarks, including RefCOCOm for MRES, gRefCOCO for generalized RES, and\nRefCOCO, RefCOCO+, RefCOCOg for classic RES. To foster future research into\nmulti-grained visual grounding, our RefCOCOm benchmark, MRES-32M dataset and\nmodel UniRES++ will be publicly available at\nhttps://github.com/Rubics-Xuan/MRES.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:05Z"}
{"aid":"http://arxiv.org/abs/2504.02249v1","title":"Stock Price Prediction Using Triple Barrier Labeling and Raw OHLCV Data:\n  Evidence from Korean Markets","summary":"This paper demonstrates that deep learning models trained on raw OHLCV\n(open-high-low-close-volume) data can achieve comparable performance to\ntraditional machine learning models using technical indicators for stock price\nprediction in Korean markets. While previous studies have emphasized the\nimportance of technical indicators and feature engineering, we show that a\nsimple LSTM network trained on raw OHLCV data alone can match the performance\nof sophisticated ML models that incorporate technical indicators. Using a\ndataset of Korean stocks from 2006 to 2024, we optimize the triple barrier\nlabeling parameters to achieve balanced label proportions with a 29-day window\nand 9\\% barriers. Our experiments reveal that LSTM networks achieve similar\nperformance to traditional machine learning models like XGBoost, despite using\nonly raw OHLCV data without any technical indicators. Furthermore, we identify\nthat the optimal window size varies with model hidden size, with a\nconfiguration of window size 100 and hidden size 8 yielding the best\nperformance. Additionally, our results confirm that using full OHLCV data\nprovides better predictive accuracy compared to using only close price or close\nprice with volume. These findings challenge conventional approaches to feature\nengineering in financial forecasting and suggest that simpler approaches\nfocusing on raw data and appropriate model selection may be more effective than\ncomplex feature engineering strategies.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T03:30:50Z"}
{"aid":"http://arxiv.org/abs/2504.02276v1","title":"Distortion from spheres into Euclidean space","summary":"Any function from a round $n$-dimensional sphere of radius $r$ into\n$n$-dimensional Euclidean space must distort the metric additively by at least\n$\\frac{2\\pi r}{2 + \\sqrt{3-2/n}}$. This is proved using a fixed-point theorem\nof Granas that generalizes the classical theorem of Borsuk--Ulam to set-valued\nfunctions.","main_category":"math.MG","categories":"math.MG,math.GN","published":"2025-04-03T04:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.02284v1","title":"Non-perturbative heavy quark diffusion coefficients in a weakly\n  magnetized thermal QCD medium","summary":"In this work, the perturbative and non-perturbative contributions to the\nheavy quark (HQ) momentum ($\\kappa$) as well as spatial ($D_s$) diffusion\ncoefficients are computed in a weak background magnetic field. The formalism\nadopted here involves calculation of the in-medium potential of the HQ in a\nweak magnetic field, which then serves as a proxy for the resummed gluon\npropagator in the calculation of HQ self-energy ($\\Sigma$). The self-energy\ndetermines the scattering rate of HQs with light thermal partons, which is\nsubsequently used to evaluate $\\kappa$ and $D_s$. It is observed that\nnon-perturbative effects play a dominant role at low temperature. The spatial\ndiffusion coefficient $2\\pi T D_s$, exhibits good agreement with recent LQCD\nresults. These findings can be applied to calculate the heavy quark directed\nflow at RHIC and LHC energies. An extension of this formalism to the case of\nfinite HQ momentum has also been attempted.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T05:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.02306v1","title":"Lepton emission rates of 43-64V isotopes under stellar conditions","summary":"In astrophysical conditions prevalent during the late times of stellar\nevolution, lepton ($e^-$ and $e^+$) emission processes compete with the\ncorresponding lepton capture processes. Prior to the collapse, lepton emissions\nsignificantly affect the cooling of the core and reduce its entropy. Therefore,\nthe lepton emission rates for Fe-group nuclei serve as an important input for\ncore-collapse simulations of high-mass stars.\n  From earlier simulation studies, isotopes of vanadium (V) have great\nastrophysical significance in regard to their weak-decay rates, which\nsubstantially affect $Y_e$ (fraction of lepton to baryon number) during the\nfinal developmental stages of massive stars. The current study involves the\ncomputation of the weak lepton emission (LE) rates for V isotopes by employing\nthe improved deformed proton-neutron Quasi-particle Random Phase Approximation\n(pn-QRPA) model. The mass numbers of the selected isotopes range from 43 to 64.\nThe LE rates on these isotopes have been estimated for a broad spectrum of\ndensity and temperature under astrophysical conditions. The ranges considered\nfor density and temperature are $10^1$ to $10^{11}$ (g/cm$^3$) and $10^7$ to $3\n\\times 10^{11}$ (K), respectively.\n  The lepton emission rates from the present study were also compared to the\nrates previously estimated by using the independent-particle model (IPM) and\nlarge-scale shell model (LSSM). IPM rates are generally bigger than QRPA rates,\nwhile LSSM rates overall show a good comparison with the reported rates.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.02316v1","title":"ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D\n  Generation","summary":"Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.02318v1","title":"X-Capture: An Open-Source Portable Device for Multi-Sensory Learning","summary":"Understanding objects through multiple sensory modalities is fundamental to\nhuman perception, enabling cross-sensory integration and richer comprehension.\nFor AI and robotic systems to replicate this ability, access to diverse,\nhigh-quality multi-sensory data is critical. Existing datasets are often\nlimited by their focus on controlled environments, simulated objects, or\nrestricted modality pairings. We introduce X-Capture, an open-source, portable,\nand cost-effective device for real-world multi-sensory data collection, capable\nof capturing correlated RGBD images, tactile readings, and impact audio. With a\nbuild cost under $1,000, X-Capture democratizes the creation of multi-sensory\ndatasets, requiring only consumer-grade tools for assembly. Using X-Capture, we\ncurate a sample dataset of 3,000 total points on 500 everyday objects from\ndiverse, real-world environments, offering both richness and variety. Our\nexperiments demonstrate the value of both the quantity and the sensory breadth\nof our data for both pretraining and fine-tuning multi-modal representations\nfor object-centric tasks such as cross-sensory retrieval and reconstruction.\nX-Capture lays the groundwork for advancing human-like sensory representations\nin AI, emphasizing scalability, accessibility, and real-world applicability.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T06:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.02327v1","title":"LearNAT: Learning NL2SQL with AST-guided Task Decomposition for Large\n  Language Models","summary":"Natural Language to SQL (NL2SQL) has emerged as a critical task for enabling\nseamless interaction with databases. Recent advancements in Large Language\nModels (LLMs) have demonstrated remarkable performance in this domain. However,\nexisting NL2SQL methods predominantly rely on closed-source LLMs leveraging\nprompt engineering, while open-source models typically require fine-tuning to\nacquire domain-specific knowledge. Despite these efforts, open-source LLMs\nstruggle with complex NL2SQL tasks due to the indirect expression of user query\nobjectives and the semantic gap between user queries and database schemas.\nInspired by the application of reinforcement learning in mathematical\nproblem-solving to encourage step-by-step reasoning in LLMs, we propose LearNAT\n(Learning NL2SQL with AST-guided Task Decomposition), a novel framework that\nimproves the performance of open-source LLMs on complex NL2SQL tasks through\ntask decomposition and reinforcement learning. LearNAT introduces three key\ncomponents: (1) a Decomposition Synthesis Procedure that leverages Abstract\nSyntax Trees (ASTs) to guide efficient search and pruning strategies for task\ndecomposition, (2) Margin-aware Reinforcement Learning, which employs\nfine-grained step-level optimization via DPO with AST margins, and (3) Adaptive\nDemonstration Reasoning, a mechanism for dynamically selecting relevant\nexamples to enhance decomposition capabilities. Extensive experiments on two\nbenchmark datasets, Spider and BIRD, demonstrate that LearNAT enables a\n7B-parameter open-source LLM to achieve performance comparable to GPT-4, while\noffering improved efficiency and accessibility.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:59:44Z"}
{"aid":"http://arxiv.org/abs/2504.02336v1","title":"Spectral asymmetry via pseudodifferential projections: the massless\n  Dirac operator","summary":"A new approach to the study of spectral asymmetry for systems of partial\ndifferential equations (PDEs) on closed manifolds was proposed in a recent\nseries of papers by the first author and collaborator. They showed that\ninformation on spectral asymmetry can be encoded within and recovered from a\nnegative order pseudodifferential operator -- the asymmetry operator --\nconstructed from appropriately defined pseudodifferential (spectral)\nprojections. In this manuscript we apply these techniques to the study of the\nmassless Dirac operator; in particular, we compute the principal symbol of the\nasymmetry operator, accounting for the underlying gauge invariance.","main_category":"math-ph","categories":"math-ph,math.AP,math.DG,math.MP,math.SP","published":"2025-04-03T07:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02351v1","title":"Agglomerating Large Vision Encoders via Distillation for VFSS\n  Segmentation","summary":"The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T07:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.02352v1","title":"Liquid Neural Networks: Next-Generation AI for Telecom from First\n  Principles","summary":"Artificial intelligence (AI) has emerged as a transformative technology with\nimmense potential to reshape the next-generation of wireless networks. By\nleveraging advanced algorithms and machine learning techniques, AI offers\nunprecedented capabilities in optimizing network performance, enhancing data\nprocessing efficiency, and enabling smarter decision-making processes. However,\nexisting AI solutions face significant challenges in terms of robustness and\ninterpretability. Specifically, current AI models exhibit substantial\nperformance degradation in dynamic environments with varying data\ndistributions, and the black-box nature of these algorithms raises concerns\nregarding safety, transparency, and fairness. This presents a major challenge\nin integrating AI into practical communication systems. Recently, a novel type\nof neural network, known as the liquid neural networks (LNNs), has been\ndesigned from first principles to address these issues. In this paper, we\nexplore the potential of LNNs in telecommunications. First, we illustrate the\nmechanisms of LNNs and highlight their unique advantages over traditional\nnetworks. Then we unveil the opportunities that LNNs bring to future wireless\nnetworks. Furthermore, we discuss the challenges and design directions for the\nimplementation of LNNs. Finally, we summarize the performance of LNNs in two\ncase studies.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-03T07:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.02354v1","title":"Improving turbulence control through explainable deep learning","summary":"Turbulent-flow control aims to develop strategies that effectively manipulate\nfluid systems, such as the reduction of drag in transportation and enhancing\nenergy efficiency, both critical steps towards reducing global CO$_2$\nemissions. Deep reinforcement learning (DRL) offers novel tools to discover\nflow-control strategies, which we combine with our knowledge of the physics of\nturbulence. We integrate explainable deep learning (XDL) to objectively\nidentify the coherent structures containing the most informative regions in the\nflow, with a DRL model trained to reduce them. The trained model targets the\nmost relevant regions in the flow to sustain turbulence and produces a drag\nreduction which is higher than that of a model specifically trained to reduce\nthe drag, while using only half its power consumption. Moreover, the XDL model\nresults in a better drag reduction than other models focusing on specific\nclassically identified coherent structures. This demonstrates that combining\nDRL with XDL can produce causal control strategies that precisely target the\nmost influential features of turbulence. By directly addressing the core\nmechanisms that sustain turbulence, our approach offers a powerful pathway\ntowards its efficient control, which is a long-standing challenge in physics\nwith profound implications for energy systems, climate modeling and\naerodynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T07:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.02362v1","title":"Brightness Perceiving for Recursive Low-Light Image Enhancement","summary":"Due to the wide dynamic range in real low-light scenes, there will be large\ndifferences in the degree of contrast degradation and detail blurring of\ncaptured images, making it difficult for existing end-to-end methods to enhance\nlow-light images to normal exposure. To address the above issue, we decompose\nlow-light image enhancement into a recursive enhancement task and propose a\nbrightness-perceiving-based recursive enhancement framework for high dynamic\nrange low-light image enhancement. Specifically, our recursive enhancement\nframework consists of two parallel sub-networks: Adaptive Contrast and Texture\nenhancement network (ACT-Net) and Brightness Perception network (BP-Net). The\nACT-Net is proposed to adaptively enhance image contrast and details under the\nguidance of the brightness adjustment branch and gradient adjustment branch,\nwhich are proposed to perceive the degradation degree of contrast and details\nin low-light images. To adaptively enhance images captured under different\nbrightness levels, BP-Net is proposed to control the recursive enhancement\ntimes of ACT-Net by exploring the image brightness distribution properties.\nFinally, in order to coordinate ACT-Net and BP-Net, we design a novel\nunsupervised training strategy to facilitate the training procedure. To further\nvalidate the effectiveness of the proposed method, we construct a new dataset\nwith a broader brightness distribution by mixing three low-light datasets.\nCompared with eleven existing representative methods, the proposed method\nachieves new SOTA performance on six reference and no reference metrics.\nSpecifically, the proposed method improves the PSNR by 0.9 dB compared to the\nexisting SOTA method.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T07:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.02388v1","title":"Steiner Traveling Salesman Problem with Quantum Annealing","summary":"The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.","main_category":"quant-ph","categories":"quant-ph,cs.AI,cs.ET","published":"2025-04-03T08:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.02396v1","title":"High-Resolution Observations of a Small-Scale Cancellation Nanoflare:\n  Supporting Evidence for the Cancellation Nanoflare Model","summary":"An analytical cancellation nanoflare model has recently been established to\nshow the fundamental role that ubiquitous small-scale cancellation nanoflares\nplay in solar atmospheric heating. Although this model is well-supported by\nsimulations, observational evidence is needed to deepen our understanding of\ncancellation nanoflares. We present observations of a small-scale cancellation\nnanoflare event, analyzing its magnetic topology evolution, triggers, and\nphysical parameters. Using coordinated observations from Solar Dynamics\nObservatory and Goode Solar Telescope, we identify a photospheric flow-driven\ncancellation event with a flux cancellation rate of ~10^{15} Mx/s and a heating\nrate of 8.7 x 10^6 erg cm^{-2} s^{-1}. The event shows the characteristic\ntransition from $\\pi$-shaped to X-shaped magnetic configuration before forming\na two arcsecs current sheet, closely matching model predictions. This event\nprovides critical observational support for the cancellation nanoflare model\nand its role in solar atmospheric heating.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-03T08:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.02401v1","title":"Comparing the Sun to Sun-like stars. On the importance of addressing\n  faculae/spot domination","summary":"Whether the Sun is an ordinary G-type star is still an open scientific\nquestion. Stellar surveys by Kepler and TESS, however, revealed that Sun-like\nstars tend to show much stronger flare activity than the Sun. This study aims\nto reassess observed flare and spot activity of Sun-like Kepler stars by\nfine-tuning the criteria for a more robust definition of Sun-like conditions\nand better comparability between the current Sun and Sun-like stars. We update\none of the recent stellar Sun-like star samples by applying new empirical\nstellar relations between the starspot size and the effective stellar\ntemperature to derive more reliable starspot group sizes. From the 265\nsolar-type stars, we could select 48 stars supporting the Kepler 30-minute\ncadence light curves. These were analyzed by implementing the gradient of the\npower spectra method to distinguish between spot- and faculae-dominated stars.\nWe employed the $\\alpha$-factor to quantify the area ratio of bright and dark\nfeatures on the stellar surface. We were able to group the 48 stars as being\nspot- or faculae-dominated, revealing a preferential distribution of the Kepler\nSun-like stars towards the spot-dominated (44 stars) and transitional (four\nstars) regimes. As the current Sun is faculae-dominated, only the transitional\nstars were utilized for further evaluation. Additionally, accounting for\ncomparability in stellar mass, radius, and rotation period, we show that only\none of the utilized 265 Sun-like stars in the Kepler sample (i.e., KIC\n11599385) allows for direct comparison to the current Sun. We further show that\nthe single flare observed on KIC 11599385 falls right within the flare energy\nrange estimated for the AD774/775 event observed in the cosmogenic radionuclide\narchives of $^{10}$Be, $^{14}$C, and $^{36}$Cl.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T08:51:00Z"}
{"aid":"http://arxiv.org/abs/2504.02410v1","title":"Limits of group algebras for growing symmetric groups and wreath\n  products","summary":"Let $S(\\infty)$ denote the infinite symmetric group formed by the finitary\npermutations of the set of natural numbers; this is a countable group. We\nintroduce its virtual group algebra, a completion of the conventional group\nalgebra $\\mathbb C[S(\\infty)]$. The virtual group algebra is obtained by taking\nlarge-$n$ limits of the finite-dimensional group algebras $\\mathbb C[S(n)]$ in\nthe so-called tame representations of $S(\\infty)$. We establish a connection\nwith the centralizer construction of Molev-Olshanski [J. Algebra, 237 (2001),\n302-341; arXiv:math/0002165] and Drinfeld-Lusztig degenerate affine Hecke\nalgebras. This makes it possible to describe the structure of the virtual group\nalgebra. Then we extend the results to wreath products $G\\wr S(\\infty)$ with\narbitrary finite groups $G$.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-03T09:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.02426v1","title":"Narrative Studio: Visual narrative exploration using LLMs and Monte\n  Carlo Tree Search","summary":"Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T09:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.02430v1","title":"How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired\n  by Aristotle's Posterior Analytics","summary":"Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.","main_category":"cs.AI","categories":"cs.AI,cs.LO,I.2.4","published":"2025-04-03T09:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.02456v1","title":"The Amenability Framework: Rethinking Causal Ordering Without Estimating\n  Causal Effects","summary":"Who should we prioritize for intervention when we cannot estimate\nintervention effects? In many applied domains (e.g., advertising, customer\nretention, and behavioral nudging) prioritization is guided by predictive\nmodels that estimate outcome probabilities rather than causal effects. This\npaper investigates when these predictions (scores) can effectively rank\nindividuals by their intervention effects, particularly when direct effect\nestimation is infeasible or unreliable. We propose a conceptual framework based\non amenability: an individual's latent proclivity to be influenced by an\nintervention. We then formalize conditions under which predictive scores serve\nas effective proxies for amenability. These conditions justify using non-causal\nscores for intervention prioritization, even when the scores do not directly\nestimate effects. We further show that, under plausible assumptions, predictive\nmodels can outperform causal effect estimators in ranking individuals by\nintervention effects. Empirical evidence from an advertising context supports\nour theoretical findings, demonstrating that predictive modeling can offer a\nmore robust approach to targeting than effect estimation. Our framework\nsuggests a shift in focus, from estimating effects to inferring who is\namenable, as a practical and theoretically grounded strategy for prioritizing\ninterventions in resource-constrained environments.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-03T10:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.02471v1","title":"Semantic segmentation of forest stands using deep learning","summary":"Forest stands are the fundamental units in forest management inventories,\nsilviculture, and financial analysis within operational forestry. Over the past\ntwo decades, a common method for mapping stand borders has involved delineation\nthrough manual interpretation of stereographic aerial images. This is a\ntime-consuming and subjective process, limiting operational efficiency and\nintroducing inconsistencies. Substantial effort has been devoted to automating\nthe process, using various algorithms together with aerial images and canopy\nheight models constructed from airborne laser scanning (ALS) data, but manual\ninterpretation remains the preferred method. Deep learning (DL) methods have\ndemonstrated great potential in computer vision, yet their application to\nforest stand delineation remains unexplored in published research. This study\npresents a novel approach, framing stand delineation as a multiclass\nsegmentation problem and applying a U-Net based DL framework. The model was\ntrained and evaluated using multispectral images, ALS data, and an existing\nstand map created by an expert interpreter. Performance was assessed on\nindependent data using overall accuracy, a standard metric for classification\ntasks that measures the proportions of correctly classified pixels. The model\nachieved an overall accuracy of 0.73. These results demonstrate strong\npotential for DL in automated stand delineation. However, a few key challenges\nwere noted, especially for complex forest environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.02482v1","title":"Berry-Esseen bound for the Moment Estimation of the fractional\n  Ornstein-Uhlenbeck model under fixed step size discrete observations","summary":"Let the Ornstein-Uhlenbeck process $\\{X_t,\\,t\\geq 0\\}$ driven by a fractional\nBrownian motion $B^H$ described by $d X_t=-\\theta X_t dt+ d B_t^H,\\, X_0=0$\nwith known parameter $H\\in (0,\\frac34)$ be observed at discrete time instants\n$t_k=kh, k=1,2,\\dots, n $. If $\\theta>0$ and if the step size $h>0$ is\narbitrarily fixed, we derive Berry-Ess\\'{e}en bound for the ergodic type\nestimator (or say the moment estimator) $\\hat{\\theta}_n$, i.e., the Kolmogorov\ndistance between the distribution of $\\sqrt{n}(\\hat{\\theta}_n-\\theta)$ and its\nlimit distribution is bounded by a constant $C_{\\theta, H,h}$ times\n$n^{-\\frac12}$ and $ n^{4H-3}$ when $H\\in (0,\\,\\frac58]$ and $H\\in\n(\\frac58,\\,\\frac34)$, respectively. This result greatly improve the previous\nresult in literature where $h$ is forced to go zero. Moreover, we extend the\nBerry-Esseen bound to the Ornstein-Uhlenbeck model driven by a lot of Gaussian\nnoises such as the sub-bifractional Brownian motion and others. A few ideas of\nthe present paper come from Haress and Hu (2021), Sottinen and Viitasaari\n(2018), and Chen and Zhou (2021).","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.02495v1","title":"Inference-Time Scaling for Generalist Reward Modeling","summary":"Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T11:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.02499v1","title":"The Gradient of Mean Molecular Weight Across the Radius Valley","summary":"Photo-evaporation shapes the observed radii of small exoplanets and\nconstrains the underlying distributions of atmospheric and core masses.\nHowever, the diversity of atmospheric chemistries corresponding to these\ndistributions remains unelucidated. We develop a first-principles\ncarbon-hydrogen-oxygen-sulfur-silicon (CHOSSi) outgassing model that accounts\nfor non-ideal gas behavior (via fugacities) at high pressures, as well as the\ntendency for water and hydrogen to dissolve in melt (via solubility laws). We\nuse data-driven radius valley constraints to establish the relationship between\nthe atmospheric surface pressures and melt temperatures of sub-Neptunes.\nSub-Neptunes with less massive rocky cores retain less of their primordial\nhydrogen envelopes, which leads to less heat retention and diminished melt\ntemperatures at the surfaces of these cores. Lower melt temperatures lead\nthermodynamically to the dominance of carbon-, oxygen-, sulfur- and\nsilicon-bearing molecules over molecular hydrogen, which naturally produce a\ndiversity of mean molecular weights. Our geochemical outgassing calculations\nrobustly predict a gradient of mean molecular weight across the radius valley,\nwhere the strength of this gradient is primarily driven by the oxygen fugacity\nof the molten cores and not by the carbon enrichment (or \"metallicity\") of the\natmosphere. Smaller sub-Neptunes are predicted to have less hydrogen-dominated\natmospheres. The precise relationship between the observed and outgassed\nchemistries requires an understanding of how convection near the core interacts\nwith large-scale atmospheric circulation (driven by stellar heating) near the\nphotosphere, as well as the influence of photochemistry.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph,physics.geo-ph","published":"2025-04-03T11:22:08Z"}
{"aid":"http://arxiv.org/abs/2504.02525v1","title":"Detection of cosmological dipoles aligned with transverse peculiar\n  velocities","summary":"We present the first observations of a novel dipole signature imprinted on\nthe CMB by transverse velocities. Cosmological peculiar velocities point\ntowards gravitational wells and away from potential hills, reflecting a\nlarge-scale dipole in the gravitational potential, coherent over hundreds of\nMpc. We predict large-scale dipoles in all fields correlated with the\npotential, observable via effects of gravitational lensing and the integrated\nSachs-Wolfe (ISW). The ISW dipole is distinct from the small-scale moving lens\neffect, which has a dipole of the opposite sign. We provide a unified framework\nfor analysing these dipoles, and make the first detections in galaxy density,\nCMB lensing convergence and the ISW effect. We show that the observed signals\nare consistent with LCDM predictions, and set limits on modified gravity. The\nCMB dipole signal is independent of galaxy bias, and orthogonal to the monopole\ncorrelation function, so this new observable provides additional cosmological\ninformation (abridged).","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-03T12:29:36Z"}
{"aid":"http://arxiv.org/abs/2504.02528v1","title":"RAFFLE: Active learning accelerated interface structure prediction","summary":"Interfaces between materials play a crucial role in the performance of most\ndevices. However, predicting the structure of a material interface is\ncomputationally demanding due to the vast configuration space, which requires\nevaluating an unfeasibly large number of highly complex structures. We\nintroduce RAFFLE, a software package designed to efficiently explore low-energy\ninterface configurations between any two crystals. RAFFLE leverages physical\ninsights and genetic algorithms to intelligently sample the configuration\nspace, using dynamically evolving 2-, 3-, and 4-body distribution functions as\ngeneralised structural descriptors. These descriptors are iteratively updated\nthrough active learning, which inform atom placement strategies. RAFFLE's\neffectiveness is demonstrated across a diverse set of systems, including bulk\nmaterials, intercalation structures, and interfaces. When tested on bulk\naluminium and MoS$_2$, it successfully identifies known ground-state and\nhigh-pressure phases. Applied to intercalation systems, it predicts stable\nintercalant phases. For Si|Ge interfaces, RAFFLE identifies intermixing as a\nstrain compensation mechanism, generating reconstructions that are more stable\nthan abrupt interfaces. By accelerating interface structure prediction, RAFFLE\noffers a powerful tool for materials discovery, enabling efficient exploration\nof complex configuration spaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn","published":"2025-04-03T12:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.02529v1","title":"Probabilistic Simulation of Aircraft Descent via a Hybrid Physics-Data\n  Approach","summary":"This paper presents a method for generating probabilistic descent\ntrajectories in simulations of real-world airspace. A dataset of 116,066\ntrajectories harvested from Mode S radar returns in UK airspace was used to\ntrain and test the model. Thirteen aircraft types with varying performance\ncharacteristics were investigated. It was found that the error in the mean\nprediction of time to reach the bottom of descent for the proposed method was\nless than that of the the Base of Aircraft Data (BADA) model by a factor of 10.\nFurthermore, the method was capable of generating a range of trajectories that\nwere similar to the held out test dataset when analysed in distribution. The\nproposed method is hybrid, with aircraft drag and calibrated airspeed functions\ngenerated probabilistically to parameterise the BADA equations, ensuring the\nphysical plausibility of generated trajectories.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T12:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.02543v1","title":"Probabilistic Pontryagin's Maximum Principle for Continuous-Time\n  Model-Based Reinforcement Learning","summary":"Without exact knowledge of the true system dynamics, optimal control of\nnon-linear continuous-time systems requires careful treatment of epistemic\nuncertainty. In this work, we propose a probabilistic extension to Pontryagin's\nmaximum principle by minimizing the mean Hamiltonian with respect to epistemic\nuncertainty. We show minimization of the mean Hamiltonian is a necessary\noptimality condition when optimizing the mean cost, and propose a multiple\nshooting numerical method scalable to large-scale probabilistic dynamical\nmodels, including ensemble neural ordinary differential equations. Comparisons\nagainst state-of-the-art methods in online and offline model-based\nreinforcement learning tasks show that our probabilistic Hamiltonian\nformulation leads to reduced trial costs in offline settings and achieves\ncompetitive performance in online scenarios. By bridging optimal control and\nreinforcement learning, our approach offers a principled and practical\nframework for controlling uncertain systems with learned dynamics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T12:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.02549v1","title":"Emergent version of Drinfeld's associator equations","summary":"The works of Alekseev and Torossian [AT] and Alekseev, Enriquez, and\nTorossian [AET] show that any solution of Drinfeld's associator equations gives\nrise to a solution of the Kashiwara-Vergne equations in an explicit way. We\nintroduce a weak version of Drinfeld's associator equations that we call the\nemergent version of the original equations. It is shown that solutions to the\nresulting linearized emergent Drinfeld's equations still lead to solutions to\nthe linearized Kashiwara-Vergne equations.\n  The emergent Drinfeld equations arise within a natural topological context of\nemergent braids, which we discuss. Our results are adjacent to the results of\nBar-Natan, Dancso, Hogan, Liu and Scherich [BDHLS] on the relationship between\nemergent tangles and the Goldman-Turaev Lie bialgebra. We hope that in time our\nresults will play a role in relating several bodies of work, on Drinfeld\nassociators, Kashiwara-Vergne equations, and on expansions for classical\ntangles, for w-tangles, and for the Goldman-Turaev Lie bialgebra.","main_category":"math.GT","categories":"math.GT,math.QA","published":"2025-04-03T13:02:04Z"}
{"aid":"http://arxiv.org/abs/2504.02561v1","title":"Digital Twins for Internet of Battlespace Things (IoBT) Coalitions","summary":"This paper presents a new framework for integrating Digital Twins (DTs)\nwithin Internet of battlespace Things (IoBT) coalitions. We introduce a novel\nthree-tier architecture that enables efficient coordination and management of\nDT models across coalition partners while addressing key challenges in\ninteroperability, security, and resource allocation. The architecture comprises\nspecialized controllers at each tier: Digital Twin Coalition Partner (DTCP)\ncontrollers managing individual coalition partners' DT resources, a central\nDigital Twin Coalition(DTC) controller orchestrating cross-partner\ncoordination, and Digital Twin Coalition Mission (DTCP) controllers handling\nmission-specific DT interactions. We propose a hybrid approach for DT model\nplacement across edge devices, tactical nodes, and cloud infrastructure,\noptimizing performance while maintaining security and accessibility. The\narchitecture leverages software-defined networking principles for dynamic\nresource allocation and slice management, enabling efficient sharing of\ncomputational and network resources between DT operations and primary IoBT\nfunctions. Our proposed framework aims to provide a robust foundation for\ndeploying and managing Digital Twins in coalition warfare, enhancing\nsituational awareness, decision-making capabilities, and operational\neffectiveness while ensuring secure and interoperable operations across diverse\ncoalition partners.","main_category":"cs.NI","categories":"cs.NI,cs.SY,eess.SY","published":"2025-04-03T13:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.02588v1","title":"Topological signatures of collective dynamics and turbulent-like energy\n  cascades in active granular matter","summary":"Active matter refers to a broad class of non-equilibrium systems where energy\nis continuously injected at the level of individual ``particles.\" These systems\nexhibit emergent collective behaviors that have no direct thermal-equilibrium\ncounterpart. Their scale ranges from micrometer-sized swarms of bacteria to\nmeter-scale human crowds. In recent years, the role of topology and\nself-propelled topological defects in active systems has garnered significant\nattention, particularly in polar and nematic active matter. Building on these\nideas, we investigate emergent collective dynamics in apolar active granular\nfluids. Using granular vibrators as a model experimental system of apolar\nactive Brownian particles in a dry environment, we uncover a distinctive\nthree-stage time evolution arising from the intricate interplay between\nactivity and inelastic interactions. By analyzing the statistics, spatial\ncorrelations, and dynamics of vortex-like topological defects in the\ndisplacement vector field, we demonstrate their ability to describe and predict\nthis intrinsic collective motion. Furthermore, we show that topological defects\nplay a crucial role in the development of a turbulent-like inverse energy\ncascade, where kinetic energy transfers across different length scales over\ntime. As the system evolves, the power scaling of the energy transfer increases\nwith the duration of observation. Our findings demonstrate how topological\nconcepts can be applied to predict macroscopic collective phenomena in apolar\nactive matter. This establishes a direct link between microscopic topological\ndynamics and large-scale behaviors in active granular fluids.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T13:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.02604v1","title":"LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech\n  Recognition in Tunisian Arabic Dialect","summary":"Developing Automatic Speech Recognition (ASR) systems for Tunisian Arabic\nDialect is challenging due to the dialect's linguistic complexity and the\nscarcity of annotated speech datasets. To address these challenges, we propose\nthe LinTO audio and textual datasets -- comprehensive resources that capture\nphonological and lexical features of Tunisian Arabic Dialect. These datasets\ninclude a variety of texts from numerous sources and real-world audio samples\nfeaturing diverse speakers and code-switching between Tunisian Arabic Dialect\nand English or French. By providing high-quality audio paired with precise\ntranscriptions, the LinTO audio and textual datasets aim to provide qualitative\nmaterial to build and benchmark ASR systems for the Tunisian Arabic Dialect.\n  Keywords -- Tunisian Arabic Dialect, Speech-to-Text, Low-Resource Languages,\nAudio Data Augmentation","main_category":"cs.CL","categories":"cs.CL,cs.SD,eess.AS","published":"2025-04-03T14:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.02623v1","title":"Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents\n  through Related and Dynamic Missions","summary":"Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T14:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.02636v1","title":"A Framework for Developing University Policies on Generative AI\n  Governance: A Cross-national Comparative Study","summary":"As generative artificial intelligence (GAI) becomes more integrated into\nhigher education and research, universities adopt varied approaches to GAI\npolicy development. To explore these variations, this study conducts a\ncomparative analysis of leading universities in the United States, Japan, and\nChina, examining their institution-wide policies on GAI application and\ngovernance. Based on these findings, the study proposes a University Policy\nDevelopment Framework for GAI (UPDF-GAI) to provide both theoretical insights\nand practical guidance for universities in developing and refining their GAI\npolicies. A qualitative content analysis of 124 policy documents from 110\nuniversities was conducted, employing thematic coding to synthesize 20 key\nthemes and 9 sub-themes. These themes and sub-themes formed the basis for\ndeveloping the framework. The analysis reveals varying priorities and focus of\nGAI policy of universities in different countries. U.S. universities emphasize\nfaculty autonomy, practical application, and policy adaptability, shaped by\ncutting-edge research and peer collaboration. Japanese universities take a\ngovernment-regulated approach, prioritizing ethics and risk management, but\nprovide limited support for AI implementation and flexibility. Chinese\nuniversities follow a centralized, government-led model, focusing on technology\napplication over early policy development, while actively exploring GAI\nintegration in education and research. The UPDF-GAI framework offers a\nsystematic, adaptable framework for assessing and optimizing GAI policies\nacross different educational contexts. By identifying key policy\ncharacteristics, enhancing policy effectiveness, and balancing technology,\nethics, and education, enabling universities to develop sustainable,\ncontextually relevant policies that strengthen their digital competitiveness\nand institutional readiness for AI-driven education.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-03T14:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.02645v1","title":"Black Holes, Moduli Stabilisation and the Swampland","summary":"In theories with moduli, extremal black holes behave such that for generic\ninitial conditions, the distance traveled by the scalars from infinity to the\nhorizon can grow with the size of the black hole. This, in turn, implies that\nlarger black holes can probe more of the UV ingredients of the theory, in\ncontrast with (naive) EFT expectations. We relate this discrepancy to the lack\nof cosmological moduli stabilisation. Indeed, for would-be scale-separated\nstring vacua with parametrically heavy stabilised scalars -- dubbed\n\\emph{rigid} compactifications -- one recovers the EFT intuition where only\nsmall black holes probe the UV. We make this explicit in a toy model and then\nturn to top-down models and construct near-horizon solutions in IIA\nscale-separated compactifications with stabilised moduli. In these top-down\nmodels we still observe large field variations for large black holes which can\nbe traced back to the absence of parametrically heavy moduli. We are led to\nspeculate that needing UV physics to allow for non-local effects near the\nhorizon of large black holes is at odds with having a rigid compactification,\nhinting to the possibility that such compactifications are in the Swampland.","main_category":"hep-th","categories":"hep-th","published":"2025-04-03T14:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.02647v1","title":"Adaptive Frequency Enhancement Network for Remote Sensing Image Semantic\n  Segmentation","summary":"Semantic segmentation of high-resolution remote sensing images plays a\ncrucial role in land-use monitoring and urban planning. Recent remarkable\nprogress in deep learning-based methods makes it possible to generate\nsatisfactory segmentation results. However, existing methods still face\nchallenges in adapting network parameters to various land cover distributions\nand enhancing the interaction between spatial and frequency domain features. To\naddress these challenges, we propose the Adaptive Frequency Enhancement Network\n(AFENet), which integrates two key components: the Adaptive Frequency and\nSpatial feature Interaction Module (AFSIM) and the Selective feature Fusion\nModule (SFM). AFSIM dynamically separates and modulates high- and low-frequency\nfeatures according to the content of the input image. It adaptively generates\ntwo masks to separate high- and low-frequency components, therefore providing\noptimal details and contextual supplementary information for ground object\nfeature representation. SFM selectively fuses global context and local detailed\nfeatures to enhance the network's representation capability. Hence, the\ninteractions between frequency and spatial features are further enhanced.\nExtensive experiments on three publicly available datasets demonstrate that the\nproposed AFENet outperforms state-of-the-art methods. In addition, we also\nvalidate the effectiveness of AFSIM and SFM in managing diverse land cover\ntypes and complex scenarios. Our codes are available at\nhttps://github.com/oucailab/AFENet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.02664v1","title":"How humans evaluate AI systems for person detection in automatic train\n  operation: Not all misses are alike","summary":"If artificial intelligence (AI) is to be applied in safety-critical domains,\nits performance needs to be evaluated reliably. The present study aimed to\nunderstand how humans evaluate AI systems for person detection in automatic\ntrain operation. In three experiments, participants saw image sequences of\npeople moving in the vicinity of railway tracks. A simulated AI had highlighted\nall detected people, sometimes correctly and sometimes not. Participants had to\nprovide a numerical rating of the AI's performance and then verbally explain\ntheir rating. The experiments varied several factors that might influence human\nratings: the types and plausibility of AI mistakes, the number of affected\nimages, the number of people present in an image, the position of people\nrelevant to the tracks, and the methods used to elicit human evaluations. While\nall these factors influenced human ratings, some effects were unexpected or\ndeviated from normative standards. For instance, the factor with the strongest\nimpact was people's position relative to the tracks, although participants had\nexplicitly been instructed that the AI could not process such information.\nTaken together, the results suggest that humans may sometimes evaluate more\nthan the AI's performance on the assigned task. Such mismatches between AI\ncapabilities and human expectations should be taken into consideration when\nconducting safety audits of AI systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.02666v1","title":"BECAME: BayEsian Continual Learning with Adaptive Model MErging","summary":"Continual Learning (CL) strives to learn incrementally across tasks while\nmitigating catastrophic forgetting. A key challenge in CL is balancing\nstability (retaining prior knowledge) and plasticity (learning new tasks).\nWhile representative gradient projection methods ensure stability, they often\nlimit plasticity. Model merging techniques offer promising solutions, but prior\nmethods typically rely on empirical assumptions and carefully selected\nhyperparameters. In this paper, we explore the potential of model merging to\nenhance the stability-plasticity trade-off, providing theoretical insights that\nunderscore its benefits. Specifically, we reformulate the merging mechanism\nusing Bayesian continual learning principles and derive a closed-form solution\nfor the optimal merging coefficient that adapts to the diverse characteristics\nof tasks. To validate our approach, we introduce a two-stage framework named\nBECAME, which synergizes the expertise of gradient projection and adaptive\nmerging. Extensive experiments show that our approach outperforms\nstate-of-the-art CL methods and existing merging strategies.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T15:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.02674v1","title":"Limitations of Religious Data and the Importance of the Target Domain:\n  Towards Machine Translation for Guinea-Bissau Creole","summary":"We introduce a new dataset for machine translation of Guinea-Bissau Creole\n(Kiriol), comprising around 40 thousand parallel sentences to English and\nPortuguese. This dataset is made up of predominantly religious data (from the\nBible and texts from the Jehovah's Witnesses), but also a small amount of\ngeneral domain data (from a dictionary). This mirrors the typical resource\navailability of many low resource languages. We train a number of\ntransformer-based models to investigate how to improve domain transfer from\nreligious data to a more general domain. We find that adding even 300 sentences\nfrom the target domain when training substantially improves the translation\nperformance, highlighting the importance and need for data collection for\nlow-resource languages, even on a small-scale. We additionally find that\nPortuguese-to-Kiriol translation models perform better on average than other\nsource and target language pairs, and investigate how this relates to the\nmorphological complexity of the languages involved and the degree of lexical\noverlap between creoles and lexifiers. Overall, we hope our work will stimulate\nresearch into Kiriol and into how machine translation might better support\ncreole languages in general.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.02708v1","title":"The Hidden Space of Safety: Understanding Preference-Tuned LLMs in\n  Multilingual context","summary":"Alignment tuning has enabled large language models to excel in reasoning,\ninstruction-following, and minimizing harmful generations. However, despite\ntheir widespread deployment, these models exhibit a monolingual bias, raising\nconcerns about the effectiveness of alignment across languages. Current\nalignment methods predominantly focus on English, leaving it unclear how\nalignment mechanism generalize to multilingual settings. To address this, we\nconduct a systematic analysis of distributional shifts in the embedding space\nof LLMs before and after alignment, uncovering its impact on model behavior\nacross diverse languages. We leverage the alignment-induced separation in\nsafety space as a quantitative tool to measure how alignment enforces safety\nconstraints. Our study evaluates seven LLMs using balanced toxicity datasets\nand parallel text-detoxification benchmarks, revealing substantial disparities\nin the latent representation space between high-resource and low-resource\nlanguages. These findings underscore the need for language-specific fine-tuning\nto ensure fair, reliable and robust multilingual alignment. Our insights\nprovide a foundation for developing truly safe multilingual LLMs, emphasizing\nthe urgency of addressing alignment gaps in underrepresented languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.02733v1","title":"Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study","summary":"Large Language Models (LLMs) are highly vulnerable to input perturbations, as\neven a small prompt change may result in a substantially different output.\nExisting methods to enhance LLM robustness are primarily focused on perturbed\ndata samples, whereas improving resiliency to perturbations of task-level\ninstructions has remained relatively underexplored. In this work, we focus on\ncharacter- and word-level edits of task-specific instructions, which\nsubstantially degrade downstream performance. We experiment with a variety of\ntechniques to enhance the robustness of LLMs, including self-denoising and\nrepresentation alignment, testing different models (Llama 3 and Flan-T5),\ndatasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and\nrole-oriented). We find that, on average, self-denoising -- whether performed\nby a frozen LLM or a fine-tuned model -- achieves substantially higher\nperformance gains than alternative strategies, including more complex baselines\nsuch as ensembling and supervised methods.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:56Z"}
{"aid":"http://arxiv.org/abs/2504.02742v1","title":"Quantum synchronization blockade induced by nonreciprocal coupling","summary":"Recently, the synchronization of coupled quantum oscillators has attracted a\ngreat deal of interest. Synchronization requires driven constituents, and in\nsuch systems, the coupling can be designed to be nonreciprocal.\nNonreciprocally-coupled oscillators exhibit a rich variety of behavior\nincluding active traveling-wave type states. In this work, we study the\ninterplay of three competing synchronization mechanisms in a setup of two\nnonreciprocally-coupled quantum van der Pol oscillators. One of the oscillators\nis driven externally which induces phase locking. A dissipative interaction\nleads to anti-phase locking, whereas a coherent interaction nurtures bistable\nphase locking and active states. We approximate the phase diagram of the\nquantum case by evaluating the synchronization measure of a perturbation\nexpansion of the steady state. Furthermore, we study the phase diagrams of two\nand three oscillators in the mean-field limit and find highly nontrivial active\nstates.","main_category":"quant-ph","categories":"quant-ph,nlin.PS","published":"2025-04-03T16:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.02749v1","title":"Bacon-Shor Board Games","summary":"We identify a period-4 measurement schedule for the checks of the Bacon-Shor\ncode that fully covers spacetime with constant-weight detectors, and is\nnumerically observed to provide the code with a threshold. Unlike previous\napproaches, our method does not rely on code concatenation and instead arises\nas the solution to a coloring game on a square grid. Under a uniform\ncircuit-level noise model, we observe a threshold of approximately $0.3\\%$ when\ndecoding with minimum weight perfect matching, and we conjecture that this\ncould be improved using a more tailored decoder.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-03T16:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.02756v1","title":"Stability of acoustic streaming jets","summary":"We study the stability of a steady Eckart streaming jet that is acoustically\nforced at one end of a closed cylindrical cavity and impinges the wall at the\nother end, where a recirculation forms. This configuration generically\nrepresents industrial processes where acoustic forcing offers a contactless\nmeans of stirring or controlling confined flows. Successfully doing so,\nhowever, requires sufficient insight into the topology of the acoustically\nforced flow. This raises the question of whether the base acoustic streaming\njet is stable and, when not, of which alternative states emerge. Using Linear\nStability Analysis (LSA) and three-dimensional nonlinear simulations, we\nidentify the instability mechanisms and determine the nature of the\nbifurcations that ensue. We show that the ratio $C_R$ between the cavity and\nthe maximum beam radii determines the dominant unstable mode. For $4 \\leq C_R\n\\leq 6$, a non-oscillatory perturbation rooted in the jet impingement triggers\na supercritical bifurcation. For $C_R = 3$, the flow destabilises through a\nsubcritical non-oscillatory bifurcation. Further reducing $C_R$ increases the\nshear within the flow, and gradually relocates the instability in the shear\nlayer between impingement-induced vortices: for $C_R = 2$, an unstable\ntravelling wave grows out of a subcritical bifurcation, which becomes\nsupercritical for $C_R=1$. For each geometry, the nonlinear 3D simulations\nvalidate the LSA, identify the saturated nonlinear state and its stability.\nThis study offers fundamental insight into the stability of acoustically-driven\nflows in general, but also opens possible pathways to either induce turbulence\nacoustically, or to avoid it in realistic configurations.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T16:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.02782v1","title":"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image\n  Generation","summary":"The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:23:16Z"}
{"aid":"http://arxiv.org/abs/2504.04723v1","title":"Quantum Incompatibility in Parallel vs Antiparallel Spins","summary":"We investigate the joint measurability of incompatible quantum observables on\nensembles of parallel and antiparallel spin pairs. In parallel configuration,\ntwo systems are identically prepared, whereas in antiparallel configuration\neach system is paired with its spin-flipped counterpart. We demonstrate that\nthe antiparallel configuration enables exact simultaneous prediction of three\nmutually orthogonal spin components -- an advantage unattainable in the\nparallel case. As we show, this enhanced measurement compatibility in\nantiparallel configuration is better explained within the framework of\ngeneralized probabilistic theories, which allow a broader class of composite\nstructures while preserving quantum descriptions at the subsystem level.\nFurthermore, this approach extends the study of measurement incompatibility to\nmore general configurations beyond just the parallel and antiparallel cases,\nproviding deeper insights into the boundary between physical and unphysical\nquantum state evolutions. To this end, we discuss how the enhanced measurement\ncompatibility in antiparallel configuration can be observed on a finite\nensemble of qubit states, paving the way for an experimental demonstration of\nthis advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T04:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04731v1","title":"A High-Performance Curve25519 and Curve448 Unified Elliptic Curve\n  Cryptography Accelerator","summary":"In modern critical infrastructure such as power grids, it is crucial to\nensure security of data communications between network-connected devices while\nfollowing strict latency criteria. This necessitates the use of cryptographic\nhardware accelerators. We propose a high-performance unified elliptic curve\ncryptography accelerator supporting NIST standard Montgomery curves Curve25519\nand Curve448 at 128-bit and 224-bit security levels respectively. Our\naccelerator implements extensive parallel processing of Karatsuba-style\nlarge-integer multiplications, restructures arithmetic operations in the\nMontgomery Ladder and exploits special mathematical properties of the\nunderlying pseudo-Mersenne and Solinas prime fields for optimized performance.\nOur design ensures efficient resource sharing across both curve computations\nand also incorporates several standard side-channel countermeasures. Our ASIC\nimplementation achieves record performance and energy of 10.38 $\\mu$s / 54.01\n$\\mu$s and 0.72 $\\mu$J / 3.73 $\\mu$J respectively for Curve25519 / Curve448,\nwhich is significantly better than state-of-the-art.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T05:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.04753v1","title":"CADCrafter: Generating Computer-Aided Design Models from Unconstrained\n  Images","summary":"Creating CAD digital twins from the physical world is crucial for\nmanufacturing, design, and simulation. However, current methods typically rely\non costly 3D scanning with labor-intensive post-processing. To provide a\nuser-friendly design process, we explore the problem of reverse engineering\nfrom unconstrained real-world CAD images that can be easily captured by users\nof all experiences. However, the scarcity of real-world CAD data poses\nchallenges in directly training such models. To tackle these challenges, we\npropose CADCrafter, an image-to-parametric CAD model generation framework that\ntrains solely on synthetic textureless CAD data while testing on real-world\nimages. To bridge the significant representation disparity between images and\nparametric CAD models, we introduce a geometry encoder to accurately capture\ndiverse geometric features. Moreover, the texture-invariant properties of the\ngeometric features can also facilitate the generalization to real-world\nscenarios. Since compiling CAD parameter sequences into explicit CAD models is\na non-differentiable process, the network training inherently lacks explicit\ngeometric supervision. To impose geometric validity constraints, we employ\ndirect preference optimization (DPO) to fine-tune our model with the automatic\ncode checker feedback on CAD sequence quality. Furthermore, we collected a\nreal-world dataset, comprised of multi-view images and corresponding CAD\ncommand sequence pairs, to evaluate our method. Experimental results\ndemonstrate that our approach can robustly handle real unconstrained CAD\nimages, and even generalize to unseen general objects.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T06:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.04755v1","title":"Effects of Surface Corrugation on Gas-Surface Scattering and Macroscopic\n  Flows","summary":"Gas-surface scattering exhibits a transition from thermal to structure\nscattering regime as incident energy increases, characterized by changes in\nangular and energy distributions. Capturing scattering behavior across\ndifferent regimes is essential for modeling momentum and energy exchange at the\ngas-surface interface. This study presents a corrugated Cercignani-Lampis-Lord\n(CLL) model to account for surface corrugation in scattering. It extends the\nwashboard-CLL hybrid approach by incorporating tangential momentum\naccommodation in local collisions. The model is validated against molecular\nbeam scattering experiments, focusing on its ability to reproduce the variation\nin scattering behavior with increasing incident energy. Compared to the\nconventional CLL model, the proposed model qualitatively improves the\nrepresentation of key features across the scattering regimes. In particular, it\ncaptures broader angular distributions and increasing reflected energy with\nreflected angle at higher incident energy. It is further applied to Direct\nSimulation Monte-Carlo (DSMC) analysis of rarefied flows over a cylinder and\nwithin an intake to examine the influence of surface corrugation on macroscopic\nflow behavior. The results show that surface corrugation has limited impact on\ntotal drag, while decreasing pressure drag and increasing friction drag. In the\nintake, enhanced tangential accommodation reduces capture efficiency and\nincreases compression ratio. These findings highlight the importance of\nincorporating surface corrugation in rarefied flow simulations under VLEO\nconditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T06:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.04762v1","title":"Extension of Yager's negation of probability distribution based on\n  uncertainty measures","summary":"Existing research on negations primarily focuses on entropy and extropy.\nRecently, new functions such as varentropy and varextropy have been developed,\nwhich can be considered as\n  extensions of entropy and extropy. However, the impact of negation on these\nextended measures, particularly varentropy and varextropy, has not been\nextensively explored. To address\n  this gap, this paper investigates the effect of negation on Shannon entropy,\nvarentropy, and varextropy. We explore how the negation of a probability\ndistribution influences these\n  measures, showing that the negated distribution consistently leads to higher\nvalues of Shannon entropy, varentropy, and varextropy compared to the original\ndistribution.\n  Additionally, we prove that the negation of a probability distribution\nmaximizes these measures during the process. The paper provides theoretical\nproofs and a detailed analysis of\n  the behaviour of these measures, contributing to a better understanding of\nthe interplay between probability distributions, negation, and\ninformation-theoretic quantities.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T06:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.04775v1","title":"Low-Count X-ray Polarimetry using the Bayesian Approach Reveals Fast\n  Polarization Angle Variations","summary":"X-ray polarimetry of accreting compact object has revealed fast time\nvariations in the polarization angle (PA), suggesting that the geometry and/or\noptical depth of the corona is changing rapidly. This prompts investigations\ninto how fast such variability can be. Conventionally, the data are often\nbinned to examine the time variability such that the measurement in each bin is\nabove the minimum detectable polarization (MDP). Here we demonstrate that this\nis unnecessary, and even below the MDP, one can infer the posterior\ndistribution of PA reliably using the Bayesian approach and still be able to\nplace useful constraints on the physics in many cases. With this approach, we\ndiscovered that the PA variation in one of the Imaging X-ray Polarimetry\nExplorer (IXPE) observations of GX 13+1 is not following a linear rotation mode\nas suggested previously. Instead, the PA swings between two discrete angles,\nsuggesting that there are two emitting components, e.g., the boundary layer and\nthe spreading layer, competing with each other. Also in one of the observations\nof GX 13+1 and Sco X-1, the PA is found to vary in correlation with the source\ncount rate, indicating that the mass accretion rate is shaping the corona\nproperties. Also, during the IXPE observation of Sco X-1, the PA in highest\nflux level seems to deviate from the averaged value and appear to be consistent\nwith previous measurement results with PolarLight and OSO-8.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T07:09:08Z"}
{"aid":"http://arxiv.org/abs/2504.04780v1","title":"Bottom-Up Scattering Information Perception Network for SAR target\n  recognition","summary":"Deep learning methods based synthetic aperture radar (SAR) image target\nrecognition tasks have been widely studied currently. The existing deep methods\nare insufficient to perceive and mine the scattering information of SAR images,\nresulting in performance bottlenecks and poor robustness of the algorithms. To\nthis end, this paper proposes a novel bottom-up scattering information\nperception network for more interpretable target recognition by constructing\nthe proprietary interpretation network for SAR images. Firstly, the localized\nscattering perceptron is proposed to replace the backbone feature extractor\nbased on CNN networks to deeply mine the underlying scattering information of\nthe target. Then, an unsupervised scattering part feature extraction model is\nproposed to robustly characterize the target scattering part information and\nprovide fine-grained target representation. Finally, by aggregating the\nknowledge of target parts to form the complete target description, the\ninterpretability and discriminative ability of the model is improved. We\nperform experiments on the FAST-Vehicle dataset and the SAR-ACD dataset to\nvalidate the performance of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:15:08Z"}
{"aid":"http://arxiv.org/abs/2504.04792v1","title":"Uniqueness and Longtime Behavior of the Completely Positively Correlated\n  Symbiotic Branching Model","summary":"The symbiotic branching model in $\\mathbb{R}$ describes the behavior of two\nbranching populations migrating in space $\\mathbb{R}$ in terms of a\ncorresponding system of stochastic partial differential equations. The system\nis parametrized with a correlation parameter $\\rho$, which takes values in\n$[-1,1]$ and governs the correlation between the branching mechanisms of the\ntwo populations. While existence and uniqueness for this system were\nestablished for $\\rho \\in [-1,1)$, weak uniqueness for the completely\npositively correlated case of $\\rho = 1$ has been an open problem. In this\npaper, we resolve this problem, establishing weak uniqueness for the\ncorresponding system of stochastic partial differential equations. The proof\nuses a new duality between the symbiotic branching model and the well-known\nparabolic Anderson model. Furthermore, we use this duality to investigate the\nlong-term behavior of the completely positively correlated symbiotic branching\nmodel. We show that, under suitable initial conditions, after a long time, one\nof the populations dies out. We treat the case of integrable initial conditions\nand the case of bounded non-integrable initial conditions with well-defined\nmean.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.04803v1","title":"Out of Sight, Still at Risk: The Lifecycle of Transitive Vulnerabilities\n  in Maven","summary":"The modern software development landscape heavily relies on transitive\ndependencies. They enable seamless integration of third-party libraries.\nHowever, they also introduce security challenges. Transitive vulnerabilities\nthat arise from indirect dependencies expose projects to risks associated with\nCommon Vulnerabilities and Exposures (CVEs). It happens even when direct\ndependencies remain secure. This paper examines the lifecycle of transitive\nvulnerabilities in the Maven ecosystem. We employ survival analysis to measure\nthe time projects remain exposed after a CVE is introduced. Using a large\ndataset of Maven projects, we identify factors that influence the resolution of\nthese vulnerabilities. Our findings offer practical advice on improving\ndependency management.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-07T07:54:15Z"}
{"aid":"http://arxiv.org/abs/2504.04807v1","title":"Fast gates for bit-flip protected superconducting qubits","summary":"Superconducting qubits offer an unprecedentedly high degree of flexibility in\nterms of circuit encoding and parameter choices. However, in designing the\nqubit parameters one typically faces the conflicting goals of long coherence\ntimes and simple control capabilities. Both are determined by the wavefunction\noverlap of the qubit basis states and the corresponding matrix elements. Here,\nwe address this problem by introducing a qubit architecture with real-time\ntunable bit-flip protection. In the first, the `heavy' regime, the energy\nrelaxation time can be on the order of hours for fluxons located in two\nnear-degenerate ground states, as recently demonstrated in Ref. [Hassani et\nal., Nat.~Commun.~14 (2023)]. The second, `light' regime, on the other hand\nfacilitates high-fidelity control on nanosecond timescales without the need for\nmicrowave signals. We propose two different tuning mechanisms of the qubit\npotential and show that base-band flux-pulses of around 10 ns are sufficient to\nrealize a universal set of high-fidelity single- and two-qubit gates. We expect\nthat the concept of real-time wavefunction control can also be applied to other\nhardware-protected qubit designs.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-07T08:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.04814v1","title":"Explainability of AI Uncertainty: Application to Multiple Sclerosis\n  Lesion Segmentation on MRI","summary":"Trustworthy artificial intelligence (AI) is essential in healthcare,\nparticularly for high-stakes tasks like medical image segmentation. Explainable\nAI and uncertainty quantification significantly enhance AI reliability by\naddressing key attributes such as robustness, usability, and explainability.\nDespite extensive technical advances in uncertainty quantification for medical\nimaging, understanding the clinical informativeness and interpretability of\nuncertainty remains limited. This study introduces a novel framework to explain\nthe potential sources of predictive uncertainty, specifically in cortical\nlesion segmentation in multiple sclerosis using deep ensembles. The proposed\nanalysis shifts the focus from the uncertainty-error relationship towards\nrelevant medical and engineering factors. Our findings reveal that\ninstance-wise uncertainty is strongly related to lesion size, shape, and\ncortical involvement. Expert rater feedback confirms that similar factors\nimpede annotator confidence. Evaluations conducted on two datasets (206\npatients, almost 2000 lesions) under both in-domain and distribution-shift\nconditions highlight the utility of the framework in different scenarios.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-07T08:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.04824v1","title":"Optimal regularity for degenerate parabolic equations on a flat boundary","summary":"We establish the optimal regularity of viscosity solutions to\n  \\begin{equation*}\n  u_t - x_n^\\gamma \\Delta u = f,\n  \\end{equation*} which arises in the regularity theory for the porous medium\nequation. Specifically, we prove that under the zero Dirichlet boundary\ncondition on $\\{x_n=0\\}$, the optimal regularity of $u$ up to the flat boundary\n$\\{x_n=0\\}$ is $C^{1,1-\\gamma}$. Moreover, for the homogeneous equations, we\nestablish that the optimal regularity of $u$ is $C^{2,1-\\gamma}$ in the spatial\nvariables, and that $x_n^{-\\gamma}u$ is smooth in the variables $x'$ and $t$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T08:25:02Z"}
{"aid":"http://arxiv.org/abs/2504.04833v1","title":"Explanation-Driven Interventions for Artificial Intelligence Model\n  Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology","summary":"The integration of Artificial Intelligence (AI) in modern society is heavily\nshifting the way that individuals carry out their tasks and activities.\nEmploying AI-based systems raises challenges that designers and developers must\naddress to ensure that humans remain in control of the interaction process,\nparticularly in high-risk domains. This article presents a novel End-User\nDevelopment (EUD) approach for black-box AI models through a redesigned user\ninterface in the Rhino-Cyt platform, a medical AI-based decision-support system\nfor medical professionals (more precisely, rhinocytologists) to carry out cell\nclassification. The proposed interface empowers users to intervene in AI\ndecision-making process by editing explanations and reconfiguring the model,\ninfluencing its future predictions. This work contributes to Human-Centered AI\n(HCAI) and EUD by discussing how explanation-driven interventions allow a blend\nof explainability, user intervention, and model reconfiguration, fostering a\nsymbiosis between humans and user-tailored AI systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-07T08:44:48Z"}
{"aid":"http://arxiv.org/abs/2504.04872v1","title":"Simulating Persuasive Dialogues on Meat Reduction with Generative Agents","summary":"Meat reduction benefits human and planetary health, but social norms keep\nmeat central in shared meals. To date, the development of communication\nstrategies that promote meat reduction while minimizing social costs has\nrequired the costly involvement of human participants at each stage of the\nprocess. We present work in progress on simulating multi-round dialogues on\nmeat reduction between Generative Agents based on large language models (LLMs).\nWe measure our main outcome using established psychological questionnaires\nbased on the Theory of Planned Behavior and additionally investigate Social\nCosts. We find evidence that our preliminary simulations produce outcomes that\nare (i) consistent with theoretical expectations; and (ii) valid when compared\nto data from previous studies with human participants. Generative agent-based\nmodels are a promising tool for identifying novel communication strategies on\nmeat reduction-tailored to highly specific participant groups-to then be tested\nin subsequent studies with human participants.","main_category":"cs.CY","categories":"cs.CY,cs.HC,cs.MA","published":"2025-04-07T09:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.04875v1","title":"Note on some Gromoll filtration groups and fundamental groups of\n  $\\mathrm{Diff}_{\\partial}(D^n)$","summary":"In this note, we will compute some Gromoll filtration groups\n$\\Gamma^{n+1}_{i+1}$ for certain $i$ when $8\\leq n \\leq 17$ and $n=4k+2\\geq\n18$. We will also use these results to obtain some information of\n$\\pi_1\\mathrm{Diff}_{\\partial} (D^n)$ when $6\\leq n \\leq 15$ and $\\pi_2\n\\mathrm{Diff}_{\\partial} (D^{4k+3})$ when $4k+3\\geq 15$.","main_category":"math.AT","categories":"math.AT,math.GT","published":"2025-04-07T09:31:20Z"}
{"aid":"http://arxiv.org/abs/2504.04879v1","title":"Mixed memories in Hopfield networks","summary":"We consider the class of Hopfield models of associative memory with\nactivation function $F$ and state space $\\{-1,1\\}^N$, where each vertex of the\ncube describes a configuration of $N$ binary neurons. $M$ randomly chosen\nconfigurations, called patterns, are stored using an energy function designed\nto make them local minima. If they are, which is known to depend on how $M$\nscales with $N$, then they can be retrieved using a dynamics that decreases the\nenergy. However, storing the patterns in the energy function also creates\nunintended local minima, and thus false memories. Although this has been known\nsince the earliest work on the subject, it has only been supported by numerical\nsimulations and non-rigorous calculations, except in elementary cases.\n  Our results are twofold. For a generic function $F$, we explicitly construct\na set of configurations, called mixed memories, whose properties are intended\nto characterise the local minima of the energy function. For three prominent\nmodels, namely the classical, the dense and the modern Hopfield models,\nobtained for quadratic, polynomial and exponential functions $F$ respectively,\nwe give conditions on the growth rate of $M$ which guarantee that, as $N$\ndiverges, mixed memories are fixed points of the retrieval dynamics and thus\nexact minima of the energy. We conjecture that in this regime, all local minima\nare mixed memories.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.04887v1","title":"A mechanism for growth of topological entropy and global changes of the\n  shape of chaotic attractors","summary":"The theoretical and numerical understanding of the key concept of topological\nentropy is an important problem in dynamical systems. Most studies have been\ncarried out on maps (discrete-time systems). We analyse a scenario of global\nchanges of the structure of an attractor in continuous-time systems leading to\nan unbounded growth of the topological entropy of the underlying dynamical\nsystem. As an example, we consider the classical Roessler system. We show that\nfor an explicit range of parameters a chaotic attractor exists. We also prove\nthe existence of a sequence of bifurcations leading to the growth of the\ntopological entropy. The proofs are computer-aided.","main_category":"math.DS","categories":"math.DS,cs.NA,math.NA,nlin.CD","published":"2025-04-07T09:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.04929v1","title":"The Linearized Vlasov-Maxwell System as a Hamiltonian System","summary":"We present a Hamiltonian formulation for the linearized Vlasov-Maxwell system\nwith a Maxwellian background distribution function. We discuss the geometric\nproperties of the model at the continuous level, and how to discretize the\nmodel in the GEMPIC framework [1]. This method allows us to keep the structure\nof the system at the semi-discrete level. To integrate the model in time, we\nemploy a Poisson splitting and discuss how to integrate each subsystem\nseparately. We test the model against the full Vlasov-Maxwell model with a\ncontrol variate method for noise reduction; the two chosen test-cases are the\nweak Landau damping and the Bernstein waves. Both test-cases exhibit the same\nphysical properties for short simulations but our model enjoys better long-time\nstability and energy conservation due to its geometric construction. The model\nis implemented in the open-source Python library STRUPHY [2, 3].","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T11:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.04946v1","title":"Scalable chip-based 3D ion traps","summary":"Ion traps are used for a wide range of applications from metrology to quantum\nsimulations and quantum information processing. Microfabricated chip-based 3D\nion traps are scalable to store many ions for the realization of a large number\nof qubits, provide deep trapping potentials compared to surface traps, and very\ngood shielding from external electric fields. In this work, we give an overview\nof our recent developments on chip-based 3D ion traps. Different types of chip\nmaterials, the integration of electronic filter components on-chip and compact\nelectrical connections in vacuum are discussed. Further, based on finite\nelement method (FEM) simulations, we discuss how integrating micro-optics in 3D\nion traps is possible without disturbing the trapped ions.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-07T11:33:37Z"}
{"aid":"http://arxiv.org/abs/2504.04988v1","title":"RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with\n  a Multi-Modal Dataset and Retrieval-Augmented Generation Model","summary":"Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T12:13:43Z"}
{"aid":"http://arxiv.org/abs/2504.05055v1","title":"Detecting relevant dependencies under measurement error with\n  applications to the analysis of planetary system evolution","summary":"Exoplanets play an important role in understanding the mechanics of planetary\nsystem formation and orbital evolution. In this context the correlations of\ndifferent parameters of the planets and their host star are useful guides in\nthe search for explanatory mechanisms. Based on a reanalysis of the data set\nfrom \\cite{figueria14} we study the as of now still poorly understood\ncorrelation between planetary surface gravity and stellar activity of Hot\nJupiters. Unfortunately, data collection often suffers from measurement errors\ndue to complicated and indirect measurement setups, rendering standard\ninference techniques unreliable.\n  We present new methods to estimate and test for correlations in a\ndeconvolution framework and thereby improve the state of the art analysis of\nthe data in two directions. First, we are now able to account for additive\nmeasurement errors which facilitates reliable inference. Second we test for\nrelevant changes, i.e. we are testing for correlations exceeding a certain\nthreshold $\\Delta$. This reflects the fact that small nonzero correlations are\nto be expected for real life data almost always and that standard statistical\ntests will therefore always reject the null of no correlation given sufficient\ndata. Our theory focuses on quantities that can be estimated by U-Statistics\nwhich contain a variety of correlation measures. We propose a bootstrap test\nand establish its theoretical validity. As a by product we also obtain\nconfidence intervals. Applying our methods to the Hot Jupiter data set from\n\\cite{figueria14}, we observe that taking into account the measurement errors\nyields smaller point estimates and the null of no relevant correlation is\nrejected only for very small $\\Delta$. This demonstrates the importance of\nconsidering the impact of measurement errors to avoid misleading conclusions\nfrom the resulting statistical analysis.","main_category":"stat.ME","categories":"stat.ME,astro-ph.EP,astro-ph.IM,math.ST,stat.TH","published":"2025-04-07T13:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.05069v1","title":"Weak thermal fluctuations impede steering of chiral magnetic nanobots","summary":"Rotating magnetic field is an efficient method of actuation of synthetic\ncolloids in liquids. In this Letter we theoretically study the effect of the\nthermal noise on torque-driven steering of magnetic nanohelices. Using a\ncombination of numerical and analytical methods, we demonstrate that\nsurprisingly a weak thermal noise can substantially disrupt the orientation and\nrotation of the nanohelix, severely impeding its propulsion. The results of\nLangevin simulations are in excellent agreement with the numerical solution of\nthe Fokker-Planck equation and the analytical effective field approximation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.05092v1","title":"Distortions in Periodicity Analysis of Blazars: The Impact of Flares","summary":"Blazars, a unique class of active galactic nuclei, exhibit highly variable\nemission across the electromagnetic spectrum. This variability frequently\nmanifests as intense flaring events, sparking an ongoing debate in recent\nliterature about whether these flares exhibit periodic behavior in certain\nsources. However, many blazars also show clear signs of stochastic,\nuncorrelated flares that do not follow a regular pattern. This paper explores\nhow the presence of one such of these stochastic flares can distort an\nintrinsically periodic pattern of emission in blazars. Our results demonstrate\nthat, depending on the specific circumstances, the deviations in significance\nand periods can exceed 100\\%. Sometimes, these deviations can be so severe that\nthey eliminate any evidence of a periodic pattern. These findings highlight the\ndramatic impact that flares can have on periodicity searches. To confront this\nchallenge, we propose an innovative approach, the Singular Spectrum Analysis\nmethod, which appears more robust against the effects of flares. As an\nalternative solution, we also propose the sigma clipping technique to mitigate\nthe impact of flares. This framework offers a valuable foundation for analyzing\nperiodicity in similar astrophysical sources that are also subject to\nstochastic flaring events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T14:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05095v1","title":"Dust Growth in ALMA Rings: II. Dusty Rossby Wave Instability","summary":"Annular substructures serve as ideal venues for planetesimal formation. In\nthis series, we investigate the linear stage of dust growth within rings. The\nfirst paper examines the global streaming instability, while this study focuses\non the dusty Rossby wave instability (DRWI). We perform a linear analysis of\nthe two-fluid equations on a background pressure bump, representing annular\nsubstructures. The spectral code \\textsc{Dedalus} is used to solve the linear\neigenvalue problem. We identify two distinct DRWI modes: Type I, which\noriginates from dust-modified gas RWI, and Type II, which results from dust-gas\ncoupling. These modes never coexist for a given azimuthal wavenumber $\\ky$, but\ntransition between each other as $\\ky$ varies. Type I modes are driven by the\nadvection of background vorticity, whereas Type II modes involve two primary\nwaves: Rossby waves, driven by advection, and thin waves, driven by dust-gas\ndrag. Finally, we assess the relevance of DRWI in ALMA rings using DSHARP\nsources. Our findings suggest that Type I modes could explain the absence of\nazimuthal asymmetries in many ALMA disks, whereas Type II modes are entirely\nabsent in all eight observed rings, implying that unresolved narrow rings or\nalternative mechanisms may play a role in dust growth within annular\nsubstructures.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-07T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.05101v1","title":"Safe and Efficient Coexistence of Autonomous Vehicles with Human-Driven\n  Traffic at Signalized Intersections","summary":"The proliferation of connected and automated vehicles (CAVs) has positioned\nmixed traffic environments, which encompass both CAVs and human driven vehicles\n(HDVs), as critical components of emerging mobility systems. Signalized\nintersections are paramount for optimizing transportation efficiency and\nenhancing energy economy, as they inherently induce stop and go traffic\ndynamics. In this paper, we present an integrated framework that concurrently\noptimizes signal timing and CAV trajectories at signalized intersections, with\nthe dual objectives of maximizing traffic throughput and minimizing energy\nconsumption for CAVs. We first formulate an optimal control strategy for CAVs\nthat prioritizes trajectory planning to circumvent state constraints, while\nincorporating the impact of signal timing and HDV behavior. Furthermore, we\nintroduce a traffic signal control methodology that dynamically adjusts signal\nphases based on vehicular density per lane, while mitigating disruption for\nCAVs scheduled to traverse the intersection. Acknowledging the system's\ninherent dynamism, we also explore event triggered replanning mechanisms that\nenable CAVs to iteratively refine their planned trajectories in response to the\nemergence of more efficient routing options. The efficacy of our proposed\nframework is evaluated through comprehensive simulations in MATLAB.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T14:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.05115v1","title":"Inertia-induced scaling and criticality in martensites","summary":"Martensites subjected to quasistatic deformation are known to exhibit power\nlaw distributed acoustic emission in a broad range of scales. However, the\norigin of the observed scaling behavior and the mechanism of self organization\ntowards criticality remains obscure. Here we argue that the power law structure\nof the fluctuations spectrum can be interpreted as an effect of inertia. The\ngeneral insight is that inertial dynamics can become a crucial player when the\nunderlying mechanical system is only marginally stable. We first illustrate the\npossibility of inertia-induced criticality using an elementary example of mass\npoints connected by bi-stable springs. We then explore the effects of inertia\nin the fully realistic two and three dimensional continuum models of specific\nelastic phase transitions in crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-07T14:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.05129v1","title":"Superconductivity, Anomalous Hall Effect, and Stripe Order in\n  Rhombohedral Hexalayer Graphene","summary":"We report the discovery of a unique superconducting phase in rhombohedral\nhexalayer graphene characterized by its simultaneous emergence with both the\nanomalous Hall effect and stripe charge order. The onset of stripe charge order\nis revealed through angle-resolved transport measurements, which show thermally\nactivated insulating behavior along one axis and highly conductive transport\nalong the orthogonal direction. Superconductivity develops exclusively along\nthe high-conductivity axis, giving rise to a one-dimensional-like\nsuperconducting channel. This superconducting state exhibits first-order\ntransitions under an out-of-plane magnetic field, consistent with a chiral\norder parameter that breaks time-reversal symmetry. Most remarkably, thermally\ndriven superconducting transitions display pronounced hysteresis-an uncommon\nphenomenon that reflects the complex interplay among stripe formation, broken\ntime-reversal symmetry, and superconductivity. Together, these results uncover\na previously unidentified quantum phase: a chiral superconductor embedded\nwithin an anomalous Hall crystal.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-07T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.05150v1","title":"A Reinforcement Learning Method for Environments with Stochastic\n  Variables: Post-Decision Proximal Policy Optimization with Dual Critic\n  Networks","summary":"This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T14:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05154v1","title":"CARE: Aligning Language Models for Regional Cultural Awareness","summary":"Existing language models (LMs) often exhibit a Western-centric bias and\nstruggle to represent diverse cultural knowledge. Previous attempts to address\nthis rely on synthetic data and express cultural knowledge only in English. In\nthis work, we study whether a small amount of human-written, multilingual\ncultural preference data can improve LMs across various model families and\nsizes. We first introduce CARE, a multilingual resource of 24.1k responses with\nhuman preferences on 2,580 questions about Chinese and Arab cultures, all\ncarefully annotated by native speakers and offering more balanced coverage.\nUsing CARE, we demonstrate that cultural alignment improves existing LMs beyond\ngeneric resources without compromising general capabilities. Moreover, we\nevaluate the cultural awareness of LMs, native speakers, and retrieved web\ncontent when queried in different languages. Our experiment reveals regional\ndisparities among LMs, which may also be reflected in the documentation gap:\nnative speakers often take everyday cultural commonsense and social norms for\ngranted, while non-natives are more likely to actively seek out and document\nthem. CARE is publicly available at https://github.com/Guochry/CARE (we plan to\nadd Japanese data in the near future).","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05166v1","title":"Effective spin model with anisotropic exchange interactions for the\n  spin-orbit coupled Hubbard model at half-filling","summary":"Spin-orbit coupling (SOC) in noncentrosymmetric materials is the source of\nincommensurate magnetic structures. In semiconductors, it drives the Rashba\nspin splitting and spin momentum locking, while in magnetic insulators based on\ntransition metals, it induces anisotropic spin exchange interactions, like\nDzyaloshinskii-Moriya (DM) interaction which drive chiral magnetism and\nskyrmion formation. Here, we establish a direct connection between SOC and spin\nexchange interactions by deriving an effective spin model from the SOC Hubbard\nmodel at half-filling. Using a strong-coupling expansion up to fourth order, we\nidentify Heisenberg, Ising-like, and ring exchange interactions, as well as a\nvariety of four-body terms for realistic Hubbard parameters. These parameters\nconstrain the relative strengths of spin interactions, providing a natural\ninterpolation between metallic and insulating phases that host complex magnetic\ntextures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-07T15:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.05191v1","title":"Distributed Quantum Advantage in Locally Checkable Labeling Problems","summary":"In this paper, we present the first known example of a locally checkable\nlabeling problem (LCL) that admits asymptotic distributed quantum advantage in\nthe LOCAL model of distributed computing: our problem can be solved in $O(\\log\nn)$ communication rounds in the quantum-LOCAL model, but it requires\n$\\Omega(\\log n \\cdot \\log^{0.99} \\log n)$ communication rounds in the classical\nrandomized-LOCAL model. We also show that distributed quantum advantage cannot\nbe arbitrarily large: if an LCL problem can be solved in $T(n)$ rounds in the\nquantum-LOCAL model, it can also be solved in $\\tilde O(\\sqrt{n T(n)})$ rounds\nin the classical randomized-LOCAL model. In particular, a problem that is\nstrictly global classically is also almost-global in quantum-LOCAL. Our second\nresult also holds for $T(n)$-dependent probability distributions. As a\ncorollary, if there exists a finitely dependent distribution over valid\nlabelings of some LCL problem $\\Pi$, then the same problem $\\Pi$ can also be\nsolved in $\\tilde O(\\sqrt{n})$ rounds in the classical randomized-LOCAL and\ndeterministic-LOCAL models. That is, finitely dependent distributions cannot\nexist for global LCL problems.","main_category":"cs.DC","categories":"cs.DC,cs.CC,quant-ph","published":"2025-04-07T15:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.05197v1","title":"P2Mark: Plug-and-play Parameter-intrinsic Watermarking for Neural Speech\n  Generation","summary":"Recently, a large number of advanced neural speech generation methods have\nemerged in the open-source community. Although this has facilitated the\napplication and development of technology, it has also increased the difficulty\nof preventing the abuse of generated speech and protecting copyrights. Audio\nwatermarking technology is an effective method for proactively protecting\ngenerated speech, but when the source codes and model weights of the neural\nspeech generation methods are open-sourced, audio watermarks based on previous\nwatermarking methods can be easily removed or manipulated. This paper proposes\na Plug-and-play Parameter-intrinsic WaterMarking (P2Mark) method for neural\nspeech generation system protection. The main advantage of P2Mark is that the\nwatermark information is flexibly integrated into the neural speech generation\nmodel in the form of parameters by training a watermark adapter rather than\ninjecting the watermark into the model in the form of features. After the\nwatermark adapter with the watermark embedding is merged with the pre-trained\ngeneration model, the watermark information cannot be easily removed or\nmanipulated. Therefore, P2Mark will be a reliable choice for proactively\ntracing and protecting the copyrights of neural speech generation models in\nopen-source white-box scenarios. We validated P2Mark on two main types of\ndecoders in neural speech generation: vocoder and codec. Experimental results\nshow that P2Mark achieves performance comparable to state-of-the-art audio\nwatermarking methods that cannot be used for open-source white-box protection\nscenarios in terms of watermark extraction accuracy, watermark\nimperceptibility, and robustness.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-07T15:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.05208v1","title":"On the cyclic behavior of singular inner functions in Besov and sequence\n  spaces","summary":"We show the existence of singular inner functions that are cyclic in some\nBesov-type spaces of analytic functions over the unit disc. Our sufficient\ncondition is stated only in terms of the modulus of smoothness of the\nunderlying measure. Such singular inner functions are cyclic also in the space\n$\\ell^p_A$ of holomorphic functions with coefficients in $\\ell^p$. This can\nonly happen for measures that place no mass on any Beurling-Carleson set.","main_category":"math.CV","categories":"math.CV,math.FA","published":"2025-04-07T15:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.05238v1","title":"Federated Learning for Medical Image Classification: A Comprehensive\n  Benchmark","summary":"The federated learning paradigm is wellsuited for the field of medical image\nanalysis, as it can effectively cope with machine learning on isolated\nmulticenter data while protecting the privacy of participating parties.\nHowever, current research on optimization algorithms in federated learning\noften focuses on limited datasets and scenarios, primarily centered around\nnatural images, with insufficient comparative experiments in medical contexts.\nIn this work, we conduct a comprehensive evaluation of several state-of-the-art\nfederated learning algorithms in the context of medical imaging. We conduct a\nfair comparison of classification models trained using various federated\nlearning algorithms across multiple medical imaging datasets. Additionally, we\nevaluate system performance metrics, such as communication cost and\ncomputational efficiency, while considering different federated learning\narchitectures. Our findings show that medical imaging datasets pose substantial\nchallenges for current federated learning optimization algorithms. No single\nalgorithm consistently delivers optimal performance across all medical\nfederated learning scenarios, and many optimization algorithms may underperform\nwhen applied to these datasets. Our experiments provide a benchmark and\nguidance for future research and application of federated learning in medical\nimaging contexts. Furthermore, we propose an efficient and robust method that\ncombines generative techniques using denoising diffusion probabilistic models\nwith label smoothing to augment datasets, widely enhancing the performance of\nfederated learning on classification tasks across various medical imaging\ndatasets. Our code will be released on GitHub, offering a reliable and\ncomprehensive benchmark for future federated learning studies in medical\nimaging.","main_category":"cs.CV","categories":"cs.CV,cs.DC","published":"2025-04-07T16:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.05242v1","title":"Spectral correlations of dynamical Resonance Fluorescence","summary":"Frequency-filtered photon correlations have been proven to be extremely\nuseful in grasping how the detection process alters photon statistics.\nHarnessing the spectral correlations also permits refinement of the emission\nand unraveling of previously hidden strong correlations in a plethora of\nquantum-optical systems under continuous-wave excitation. In this work, we\ninvestigate such correlations for time-dependent excitation and develop a\nmethodology to compute efficiently time-integrated correlations, which are at\nthe heart of the photon-counting theory, and subsequently apply it to analyze\nthe photon emission of pulsed systems. By combining this formalism with the\nsensor method -- which facilitates frequency-resolved correlations -- we\ndemonstrate how spectral filtering enhances single-photon purity and suppresses\nmulti-photon noise in time-bin-encoded quantum states. Specifically, filtering\nthe central spectral peak of a dynamically driven two-level system boosts\ntemporal coherence and improves the fidelity of time-bin entanglement\npreparation, even under conditions favoring multi-photon emission. These\nresults establish spectral filtering as a critical tool for tailoring photon\nstatistics in pulsed quantum light sources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T16:27:13Z"}
{"aid":"http://arxiv.org/abs/2504.05244v1","title":"Behind the Spotlight: A systematic assessment of outshining using NIRCam\n  medium-bands in the JADES Origins Field","summary":"The spatial resolution and sensitivity of JWST's NIRCam instrument has\nrevolutionised our ability to probe the internal structure of early galaxies.\nBy leveraging deep medium-band imaging in the Jades Origins Field, we assemble\ncomprehensive spectral energy distributions (SEDs) using 19 photometric bands\nfor over 200 high-redshift galaxies ($z \\geq 4.5$). We present an analysis of\nthis sample with particular emphasis on investigating the \"outshining\"\nphenomenon, which can bias the inferred stellar populations by masking the\npresence of evolved stellar populations ($\\geq$ 100 Myr) with the light of\nbright, young O and B-type stars. We address this problem by performing\nspatially-resolved SED-fitting of both binned and full pixel-by-pixel\nphotometry, which we compare to the traditional integrated approach. We find\nevidence for systematic underestimation of stellar mass in low-mass galaxies\n($\\leq 10^9 \\rm M_\\odot$) with bursty star formation, which can exceed a factor\nof 10 in individual cases, but on average is typically a factor of 1.25-2.5,\ndepending on the binning methodology and SFH model used. The observed mass\noffset correlates with burstiness (SFR$_{10 \\ \\rm Myr}$/SFR$_{100 \\ \\rm Myr}$)\nand sSFR, such that galaxies with recently rising SFHs have larger mass\noffsets. The integrated SFH models which produce the most consistent stellar\nmasses are the double power-law and non-parametric `continuity' models,\nalthough no integrated model fully reproduces all resolved SFHs. We apply an\noutshining correction factor to the Stellar Mass Function at $z=7$, finding\nlittle impact within the uncertainties. We conclude that outshining can be\nimportant in individual low-mass galaxies, but the overall impact is limited\nand should be considered alongside other systematic SED fitting effects.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T16:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.05263v1","title":"An X-ray and Optical Study of the Dwarf Nova Candidate OGLE-BLG-DN-0064","summary":"The source OGLE-BLG-DN-0064 (hereafter OGLE64) was classified as a potential\ndwarf nova based on its regular outburst activity revealed by the OGLE optical\nsurvey. In this paper, we investigate the X-ray and optical emissions from the\nsource OGLE64 based on archival Chandra and Swift X-ray data and our optical\nobservations with the 6-m BTA telescope at the Special Astrophysical\nObservatory of the Russian Academy of Sciences. OGLE64 shows an X-ray\nluminosity $ L_X \\approx 1.6 \\times 10^{32} \\, \\text{erg s}^{-1} $ and a high\nX-ray-to-optical flux ratio $ F_X / F_{\\text{opt}} \\approx 1.5$, typical for\naccreting white dwarfs. The X-ray spectrum of OGLE64 is better fitted by the\nmodels of a power law with a photon index $\\Gamma \\approx 1.9$ and an optically\nthin plasma with a temperature $ kT \\approx 6.4 \\, \\text{keV} $. The optical\nspectrum shows hydrogen and neutral helium emission lines, in some of which a\ndouble-peaked structure is observed. An analysis of the outburst activity of\nOGLE64, based on data from the OGLE, ZTF, ATLAS, and ASAS-SN optical surveys,\nhas revealed superoutbursts with a characteristic supercycle $ P_{\\text{super}}\n\\approx 400 \\, \\text{days} $. We found no significant variability in either the\nX-ray or optical light curves of OGLE64 that could be associated with the\nchange in the visibility conditions for the emitting regions at different\norbital phases. Our estimates of the orbital period of the system by indirect\nmethods show that the period probably lies in the range $ P_{\\text{orb}} \\sim\n1.5 - 3.5 \\, \\text{h} $. The properties of the X-ray and optical emissions from\nOGLE64 lead us to conclude that the system is an SU UMa-type dwarf nova.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.05264v1","title":"Existence and characterizations of hyper-dual group inverse","summary":"Motivated by the recent work of Xiao and Zhong [AIMS Math. 9 (2024),\n35125--35150: MR4840882], we propose a generalized inverse for a hyper-dual\nmatrix called hyper-dual group generalized inverse (HDGGI). Under certain\nnecessary and sufficient conditions, we establish the existence of the HDGGI of\na hyper-dual matrix. We then show that the HDGGI is unique (whenever exists).\nThe HDGGI is then used to solve a linear hyper-dual system. We also exploit\nsome sufficient conditions under which the reverse and forward-order laws for a\nparticular form of the HDGGI and HDMPGI hold. We also discuss the least-squares\nproperties of hyper-dual group inverse. Using the definition of dual matrix of\norder $n$, we finally establish necessary and sufficient condition for the\nexistence of the group inverse of a dual matrix of order $n$.","main_category":"math.RA","categories":"math.RA,math.AC,math.FA","published":"2025-04-07T16:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.05299v1","title":"SmolVLM: Redefining small and efficient multimodal models","summary":"Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-07T17:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.05300v1","title":"Dimension-Free Convergence of Diffusion Models for Approximate Gaussian\n  Mixtures","summary":"Diffusion models are distinguished by their exceptional generative\nperformance, particularly in producing high-quality samples through iterative\ndenoising. While current theory suggests that the number of denoising steps\nrequired for accurate sample generation should scale linearly with data\ndimension, this does not reflect the practical efficiency of widely used\nalgorithms like Denoising Diffusion Probabilistic Models (DDPMs). This paper\ninvestigates the effectiveness of diffusion models in sampling from complex\nhigh-dimensional distributions that can be well-approximated by Gaussian\nMixture Models (GMMs). For these distributions, our main result shows that DDPM\ntakes at most $\\widetilde{O}(1/\\varepsilon)$ iterations to attain an\n$\\varepsilon$-accurate distribution in total variation (TV) distance,\nindependent of both the ambient dimension $d$ and the number of components $K$,\nup to logarithmic factors. Furthermore, this result remains robust to score\nestimation errors. These findings highlight the remarkable effectiveness of\ndiffusion models in high-dimensional settings given the universal approximation\ncapability of GMMs, and provide theoretical insights into their practical\nsuccess.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,math.ST,stat.ML,stat.TH","published":"2025-04-07T17:59:07Z"}
{"aid":"http://arxiv.org/abs/2504.05629v1","title":"PTRL: Prior Transfer Deep Reinforcement Learning for Legged Robots\n  Locomotion","summary":"In the field of legged robot motion control, reinforcement learning (RL)\nholds great promise but faces two major challenges: high computational cost for\ntraining individual robots and poor generalization of trained models. To\naddress these problems, this paper proposes a novel framework called Prior\nTransfer Reinforcement Learning (PTRL), which improves both training efficiency\nand model transferability across different robots. Drawing inspiration from\nmodel transfer techniques in deep learning, PTRL introduces a fine-tuning\nmechanism that selectively freezes layers of the policy network during\ntransfer, making it the first to apply such a method in RL. The framework\nconsists of three stages: pre-training on a source robot using the Proximal\nPolicy Optimization (PPO) algorithm, transferring the learned policy to a\ntarget robot, and fine-tuning with partial network freezing. Extensive\nexperiments on various robot platforms confirm that this approach significantly\nreduces training time while maintaining or even improving performance.\nMoreover, the study quantitatively analyzes how the ratio of frozen layers\naffects transfer results, providing valuable insights into optimizing the\nprocess. The experimental outcomes show that PTRL achieves better walking\ncontrol performance and demonstrates strong generalization and adaptability,\noffering a promising solution for efficient and scalable RL-based control of\nlegged robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05638v1","title":"TAGC: Optimizing Gradient Communication in Distributed Transformer\n  Training","summary":"The increasing complexity of large language models (LLMs) necessitates\nefficient training strategies to mitigate the high computational costs\nassociated with distributed training. A significant bottleneck in this process\nis gradient synchronization across multiple GPUs, particularly in the\nzero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware\nGradient Compression (TAGC), an optimized gradient compression algorithm\ndesigned specifically for transformer-based models. TAGC extends the lossless\nhomomorphic compression method by adapting it for sharded models and\nincorporating transformer-specific optimizations, such as layer-selective\ncompression and dynamic sparsification. Our experimental results demonstrate\nthat TAGC accelerates training by up to 15% compared to the standard Fully\nSharded Data Parallel (FSDP) approach, with minimal impact on model quality. We\nintegrate TAGC into the PyTorch FSDP framework, the implementation is publicly\navailable at https://github.com/ipolyakov/TAGC.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T03:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.05657v1","title":"Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven\n  Speech Anti-spoofing","summary":"Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.SD","published":"2025-04-08T04:11:28Z"}
{"aid":"http://arxiv.org/abs/2504.05707v1","title":"Hamilton-Jacobi-Bellman equation and Viscosity solutions for an optimal\n  control problem for stochastic convective Brinkman-Forchheimer equations","summary":"In this work, we consider the following two- and three-dimensional stochastic\nconvective Brinkman-Forchheimer (SCBF) equations in torus $\\mathbb{T}^d,\\\nd\\in\\{2,3\\}$:\n  \\begin{align*}\n  \\mathrm{d}\\boldsymbol{u}+\\left[-\\mu\n\\Delta\\boldsymbol{u}+(\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}+\\alpha\\boldsymbol{u}+\\beta|\\boldsymbol{u}|^{r-1}\\boldsymbol{u}+\\nabla\np\\right]\\mathrm{d}t=\\mathrm{d}\\mathrm{W}, \\ \\nabla\\cdot\\boldsymbol{u}=0,\n  \\end{align*}\n  where $\\mu,\\alpha,\\beta>0$, $r\\in[1,\\infty)$ and $\\mathrm{W}$ is a Hilbert\nspace valued $\\mathrm{Q}-$Wiener process. The above system can be considered as\ndamped stochastic Navier-Stokes equations. Using the dynamic programming\napproach, we study the infinite-dimensional second-order Hamilton-Jacobi\nequation associated with an optimal control problem for SCBF equations. For the\nsupercritical case, that is, $r\\in(3,\\infty)$ for $d=2$ and $r\\in(3,5)$ for\n$d=3$ ($2\\beta\\mu\\geq 1$ for $r=3$ in $d\\in\\{2,3\\}$), we first prove the\nexistence of a viscosity solution for the infinite-dimensional HJB equation,\nwhich we identify with the value function of the associated control problem. By\nestablishing a comparison principle for $r\\in(3,\\infty)$ and $r=3$ with\n$2\\beta\\mu\\geq1$ in $d\\in\\{2,3\\}$, we prove that the value function is the\nunique viscosity solution and hence we resolve the global unique solvability of\nthe HJB equation in both two and three dimensions.","main_category":"math.OC","categories":"math.OC,math.AP","published":"2025-04-08T06:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.05727v1","title":"SAP-CoPE: Social-Aware Planning using Cooperative Pose Estimation with\n  Infrastructure Sensor Nodes","summary":"Autonomous driving systems must operate safely in human-populated indoor\nenvironments, where challenges such as limited perception and occlusion\nsensitivity arise when relying solely on onboard sensors. These factors\ngenerate difficulties in the accurate recognition of human intentions and the\ngeneration of comfortable, socially aware trajectories. To address these\nissues, we propose SAP-CoPE, a social-aware planning framework that integrates\ncooperative infrastructure with a novel 3D human pose estimation method and a\nmodel predictive control-based controller. This real-time framework formulates\nan optimization problem that accounts for uncertainty propagation in the camera\nprojection matrix while ensuring human joint coherence. The proposed method is\nadaptable to single- or multi-camera configurations and can incorporate sparse\nLiDAR point-cloud data. To enhance safety and comfort in human environments, we\nintegrate a human personal space field based on human pose into a model\npredictive controller, enabling the system to navigate while avoiding\ndiscomfort zones. Extensive evaluations in both simulated and real-world\nsettings demonstrate the effectiveness of our approach in generating socially\naware trajectories for autonomous systems.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T06:55:39Z"}
{"aid":"http://arxiv.org/abs/2504.05746v1","title":"Exploiting Temporal Audio-Visual Correlation Embedding for Audio-Driven\n  One-Shot Talking Head Animation","summary":"The paramount challenge in audio-driven One-shot Talking Head Animation\n(ADOS-THA) lies in capturing subtle imperceptible changes between adjacent\nvideo frames. Inherently, the temporal relationship of adjacent audio clips is\nhighly correlated with that of the corresponding adjacent video frames,\noffering supplementary information that can be pivotal for guiding and\nsupervising talking head animations. In this work, we propose to learn\naudio-visual correlations and integrate the correlations to help enhance\nfeature representation and regularize final generation by a novel Temporal\nAudio-Visual Correlation Embedding (TAVCE) framework. Specifically, it first\nlearns an audio-visual temporal correlation metric, ensuring the temporal audio\nrelationships of adjacent clips are aligned with the temporal visual\nrelationships of corresponding adjacent video frames. Since the temporal audio\nrelationship contains aligned information about the visual frame, we first\nintegrate it to guide learning more representative features via a simple yet\neffective channel attention mechanism. During training, we also use the\nalignment correlations as an additional objective to supervise generating\nvisual frames. We conduct extensive experiments on several publicly available\nbenchmarks (i.e., HDTF, LRW, VoxCeleb1, and VoxCeleb2) to demonstrate its\nsuperiority over existing leading algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T07:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.05757v1","title":"A Douglas-Rachford Splitting Method for Solving Monotone Variational\n  Inequalities in Linear-quadratic Dynamic Games","summary":"This paper considers constrained linear dynamic games with quadratic\nobjective functions, which can be cast as affine variational inequalities. By\nleveraging the problem structure, we apply the Douglas-Rachford splitting,\nwhich generates a solution algorithm with linear convergence rate. The fast\nconvergence of the method enables receding-horizon control architectures.\nFurthermore, we demonstrate that the associated VI admits a closed-form\nsolution within a neighborhood of the attractor, thus allowing for a further\nreduction in computation time. Finally, we benchmark the proposed method via\nnumerical experiments in an automated driving application.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-08T07:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.05767v1","title":"Cross-Document Contextual Coreference Resolution in Knowledge Graphs","summary":"Coreference resolution across multiple documents poses a significant\nchallenge in natural language processing, particularly within the domain of\nknowledge graphs. This study introduces an innovative method aimed at\nidentifying and resolving references to the same entities that appear across\ndiffering texts, thus enhancing the coherence and collaboration of information.\nOur method employs a dynamic linking mechanism that associates entities in the\nknowledge graph with their corresponding textual mentions. By utilizing\ncontextual embeddings along with graph-based inference strategies, we\neffectively capture the relationships and interactions among entities, thereby\nimproving the accuracy of coreference resolution. Rigorous evaluations on\nvarious benchmark datasets highlight notable advancements in our approach over\ntraditional methodologies. The results showcase how the contextual information\nderived from knowledge graphs enhances the understanding of complex\nrelationships across documents, leading to better entity linking and\ninformation extraction capabilities in applications driven by knowledge. Our\ntechnique demonstrates substantial improvements in both precision and recall,\nunderscoring its effectiveness in the area of cross-document coreference\nresolution.","main_category":"cs.CL","categories":"cs.CL,cs.MA","published":"2025-04-08T07:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.05773v1","title":"Simultaneous Multiphoton-Multiatom Processes in Atomic Gases under Laser\n  Fields","summary":"We investigate simultaneous multiphoton-multiatom processes in atomic gases\nexposed to laser fields under specific frequency conditions, where multiple\natoms are simultaneously excited through the absorption of one laser photon\neach. These processes represent natural high-order quantum electrodynamics\n(QED) effects that occur independently of inter-atomic interactions. A\ncharacteristic length scale emerges, governing the physical range over which\nthese phenomena manifest. We propose experiments to demonstrate the fundamental\naspects of these collective QED processes.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas","published":"2025-04-08T07:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.05793v1","title":"Negotiating Strict Latency Limits for Dynamic Real-Time Services in\n  Vehicular Time-Sensitive Networks","summary":"Future vehicles are expected to dynamically deploy in-vehicle applications\nwithin a Service-Oriented Architecture (SOA). Critical services operate under\nhard real-time constraints, which Time-Sensitive Networking (TSN) complements\non the in-vehicle Ethernet layer. TSN ensures deterministic communication\nbetween critical services and its Credit-Based Shaper (CBS) supports dynamic\nresource reservations. However, the dynamic nature of service deployment\nchallenges network resource configuration, since any new reservation may change\nthe latency of already validated flows. In addition, standard methods of\nworst-case latency analysis for CBS have been found incorrect, and current TSN\nstream reservation procedures lack mechanisms to signal application layer\nQuality-of-Service (QoS) requirements or verify deadlines. In this paper, we\npropose a QoS negotiation scheme within the automotive SOA that interacts with\nthe TSN network controller to reserve resources while ensuring latency bounds.\nWe comparatively evaluate reservation schemes using worst-case analysis and\nsimulations of a realistic In-Vehicle Network (IVN) for demonstrating their\nimpact on QoS guarantees, resource utilization, and setup times. We find that\nonly a reservation scheme utilizing per-queue delay budgets and network\ncalculus provides valid configurations and guarantees acceptable latency bounds\nthroughout the IVN. The proposed service negotiation mechanism efficiently\nestablishes 450 vehicular network reservations in just 11ms.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-08T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.05815v1","title":"Parasite: A Steganography-based Backdoor Attack Framework for Diffusion\n  Models","summary":"Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:53:47Z"}
{"aid":"http://arxiv.org/abs/2504.05817v1","title":"Combinatorial Ricci flows on infinite disk triangulations","summary":"In this paper, we introduce combinatorial Ricci flows (CRFs in short) in\nEuclidean and hyperbolic background geometries on infinite triangulations of\nthe open disk, which are discrete analogs of Ricci flows on simply connected\nopen surfaces. We establish well-posedness results, the existence and the\nuniqueness, of CRFs in both Euclidean and hyperbolic background geometries.\nMoreover, we prove convergence results of CRFs, which indicate a uniformization\ntheorem for CRFs on infinite disk triangulations. As an application, we prove\nan existence result of circle-packing metrics with infinite prescribed cone\nangles in hyperbolic background geometry. To our knowledge, these are the first\nresults of CRFs on infinite triangulations.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-08T08:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.05821v1","title":"On the Hopf envelope of finite-dimensional bialgebras","summary":"The Hopf envelope of a bialgebra is the free Hopf algebra generated by the\ngiven bialgebra. Its existence, as well as that of the cofree Hopf algebra, is\na well-known fact in Hopf algebra theory, but their construction is not\nparticularly handy or friendly. In this note, we offer a novel realisation of\nthe Hopf envelope and of the cofree Hopf algebra of a finite-dimensional\nbialgebra as a particular quotient and sub-bialgebra, respectively, of the\nbialgebra itself. Our construction can also be extended to the\ninfinite-dimensional case, provided that the bialgebra satisfies additional\nconditions, such as being left Artinian as an algebra or admitting a\n$n$-antipode, the latter being a notion hereby introduced.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA,math.RT","published":"2025-04-08T09:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05832v1","title":"Channel State Information Analysis for Jamming Attack Detection in\n  Static and Dynamic UAV Networks -- An Experimental Study","summary":"Networks built on the IEEE 802.11 standard have experienced rapid growth in\nthe last decade. Their field of application is vast, including smart home\napplications, Internet of Things (IoT), and short-range high throughput static\nand dynamic inter-vehicular communication networks. Within such networks,\nChannel State Information (CSI) provides a detailed view of the state of the\ncommunication channel and represents the combined effects of multipath\npropagation, scattering, phase shift, fading, and power decay. In this work, we\ninvestigate the problem of jamming attack detection in static and dynamic\nvehicular networks. We utilize ESP32-S3 modules to set up a communication\nnetwork between an Unmanned Aerial Vehicle (UAV) and a Ground Control Station\n(GCS), to experimentally test the combined effects of a constant jammer on\nrecorded CSI parameters, and the feasibility of jamming detection through CSI\nanalysis in static and dynamic communication scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.RO","published":"2025-04-08T09:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05848v1","title":"Relativistic limits on the discretization and temporal resolution of a\n  quantum clock","summary":"We provide a brief discussion regarding relativistic limits on the\ndiscretization and temporal resolution of time values in a quantum clock. Our\nclock is characterized by a time observable chosen to be the complement of a\nbounded and discrete Hamiltonian which can have an equally-spaced or a generic\nspectrum. In the first case the time observable can be described by an\nHermitian operator and we find a limit in the discretization for the time\neigenvalues. Nevertheless, in both cases, the time observable can be described\nby a POVM and, by increasing the number of time states, we can arbitrarily\nreduce the bound on the minimum time quantum, demonstrating that we can safely\ntake the time values as continuous when the number of time states tends to\ninfinity. Finally, we find a limit for temporal resolution of our time\nobservable when the clock is used (together with light signals) in a\nrelativistic framework for measuring spacetime distances.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:27:41Z"}
{"aid":"http://arxiv.org/abs/2504.05873v1","title":"Leptophilic ALPs in Laboratory Experiments","summary":"We study the collider phenomenology of leptophilic axion-like particles\n(ALPs), i.e. pseudoscalar particles that couple only to charged leptons. Loops\nof charged leptons induce effective interactions of the ALPs with photons,\nwhich depend on the momenta of the interacting particles and differ between\npseudoscalar and derivative lepton couplings. We systematically discuss the\nform of the interaction with photons for general external momenta and identify\nthe regimes when it can be safely approximated by an effective coupling\nconstant. We use these results to derive novel constraints from LEP and\ncalculate state-of-the-art limits from E137 and NA64 for four different\nscenarios, in which the ALPs couple either to a single lepton generation or\nuniversally to all, for both pseudoscalar and derivative lepton couplings. We\ncollect complementary bounds from astrophysics, flavour, and other laboratory\nexperiments to chart the allowed parameter space of leptophilic ALPs in the\nMeV-GeV mass range.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T09:58:09Z"}
{"aid":"http://arxiv.org/abs/2504.05911v1","title":"A note on the stability of self-similar blow-up solutions for\n  superconformal semilinear wave equations","summary":"In this note, we investigate the stability of self-similar blow-up solutions\nfor superconformal semilinear wave equations in all dimensions. A central\naspect of our analysis is the spectral equivalence of the linearized operators\nunder Lorentz transformations in self-similar variables. This observation\nserves as a useful tool in proving mode stability and provides insights that\nmay aid the study of self-similar solutions in related problems. As a direct\nconsequence, we establish the asymptotic stability of the ODE blow-up family,\nextending the classical results of Merle and Zaag [Merle-Zaag, 2007, 2016] to\nthe superconformal case and generalizing the recent findings of Ostermann\n[Ostermann, 2024] to include the entire ODE blow-up family.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T11:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.05938v1","title":"Umbral oscillations in the photosphere. A comprehensive statistical\n  study","summary":"It is well-known that the global acoustic oscillations of the Sun's\natmosphere can excite resonance modes within large-scale magnetic\nconcentrations. These structures are conduits of energy between the different\nlayers of the solar atmosphere, and understanding their dynamics can explain\nthe processes behind coronal heating and solar wind acceleration. In this work,\nwe studied the Doppler velocity spectrum of more than a thousand large-scale\nmagnetic structures (i.e., sunspots) in the solar photosphere that crossed near\nthe disk centre of the Sun. We exploited the excellent stability and\nseeing-free conditions of the Helioseismic and Magnetic Imager (HMI) instrument\nonboard the Solar Dynamics Observatory (SDO) to cover nearly seven years of\nobservations, providing the most comprehensive statistical analysis of its\nkind. Here, we show that the power spectra of the umbra of sunspots in the\nphotosphere is remarkably different from the one of quiet-Sun regions, with\nboth exhibiting a primary peak at 3.3 mHz, but the sunspot umbrae also\ndisplaying a closely packed series of secondary peaks in the $4-6$~mHz band.\nUnderstanding the origin of such peaks is a challenging task. Here, we explore\nseveral possible explanations for the observed oscillations, all pointing\ntoward a potential resonant interaction within these structures and an unknown\ndriver. Our observational result provides further insight into the magnetic\nconnectivity between the different layers of the dynamic atmosphere of the Sun.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.05940v1","title":"A Lorentz Covariant Matrix Model for Bosonic M2-Branes: Nambu Brackets\n  and Restricted Volume-Preserving Deformations","summary":"We propose a Lorentz covariant matrix model as a nonperturbative formulation\nof the bosonic M2-brane in M-theory. Unlike previous approaches relying on the\nlight-cone gauge or symmetry-based constructions, our model retains full\n11-dimensional Lorentz invariance by introducing a novel gauge-fixing condition\nthat restricts the symmetry of volume-preserving deformations (VPD) to a\nsubclass, which we call restricted VPD (RVPD). This restriction enables a\nconsistent matrix regularization of the Nambu bracket, bypassing the\nlong-standing obstructions related to the Leibniz rule and the Fundamental\nIdentity. The resulting model exhibits RVPD symmetry, admits particle-like and\nnoncommutative membrane solutions, and lays the foundation for a\nLorentz-invariant, nonperturbative matrix description of M2-branes. Our work\noffers a new paradigm for constructing Lorentz-invariant matrix models of\nmembranes, revisiting the algebraic structure underlying M-theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-08T11:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.05942v1","title":"Higher-order meshless schemes for hyperbolic equations","summary":"We discuss the order, efficiency, stability and positivity of several\nmeshless schemes for linear scalar hyperbolic equations. Meshless schemes are\nGeneralised Finite Difference Methods (GFDMs) for arbitrary irregular grids in\nwhich there is no connectivity between the grid points. We propose a new\nMUSCL-like meshless scheme that uses a central stencil, with which we can\nachieve arbitrarily high orders, and compare it to existing meshless upwind\nschemes and meshless WENO schemes. The stability of the newly proposed scheme\nis guaranteed by an upwind reconstruction to the midpoints of the stencil. The\nnew meshless MUSCL scheme is also efficient due to the reuse of the GFDM\nsolution in the reconstruction. We combine the new MUSCL scheme with a\nMulti-dimensional Optimal Order Detection (MOOD) procedure to avoid spurious\noscillations at discontinuities. In one spatial dimension, our fourth order\nMUSCL scheme outperforms existing WENO and upwind schemes in terms of stability\nand accuracy. In two spatial dimensions, our MUSCL scheme achieves similar\naccuracy to an existing WENO scheme but is significantly more stable.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T11:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.05957v1","title":"Drought forecasting using a hybrid neural architecture for integrating\n  time series and static data","summary":"Reliable forecasting is critical for early warning systems and adaptive\ndrought management. Most previous deep learning approaches focus solely on\nhomogeneous regions and rely on single-structured data. This paper presents a\nhybrid neural architecture that integrates time series and static data,\nachieving state-of-the-art performance on the DroughtED dataset. Our results\nillustrate the potential of designing neural models for the treatment of\nheterogeneous data in climate related tasks and present reliable prediction of\nUSDM categories, an expert-informed drought metric. Furthermore, this work\nvalidates the potential of DroughtED for enabling location-agnostic training of\ndeep learning models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T12:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.05965v1","title":"Generalized Parameter Lifting: Finer Abstractions for Parametric Markov\n  Chains","summary":"Parametric Markov chains (pMCs) are Markov chains (MCs) with symbolic\nprobabilities. A pMC encodes a family of MCs, where each member is obtained by\nreplacing parameters with constants. The parameters allow encoding dependencies\nbetween transitions, which sets pMCs apart from interval MCs. The verification\nproblem for pMCs asks whether each MC in the corresponding family satisfies a\ngiven temporal specification. The state-of-the-art approach for this problem is\nparameter lifting (PL) -- an abstraction-refinement loop that abstracts the pMC\nto a non-parametric model analyzed with standard probabilistic model checking\ntechniques. This paper presents two key improvements to tackle the main\nlimitations of PL. First, we introduce generalized parameter lifting (GPL) to\nlift various restrictive assumptions made by PL. Second, we present a big-step\ntransformation algorithm that reduces parameter dependencies in pMCs and,\ntherefore, results in tighter approximations. Experiments show that GPL is\nwidely applicable and that the big-step transformation accelerates pMC\nverification by up to orders of magnitude.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-08T12:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.06024v1","title":"AriaQuanta: A Quantum Software for Quantum Computing","summary":"We introduce AriaQuanta, a powerful and flexible tool for designing,\nsimulating, and implementing quantum circuits. This open-source software is\ndesigned to make it easy for users of all experience levels to learn and use\nquantum computing. The first version includes a compiler for implementing\nvarious quantum circuits and algorithms. Additionally, parametric circuits\nallow for the implementation of variational quantum algorithms, and various\nnoise models are available for simulating noisy circuits. We performed numerous\nnumerical simulations on AriaQuanta in various applications, including quantum\nalgorithms and noisy circuits. The results, compared with popular counterparts,\ndemonstrate the high performance of AriaQuanta.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:27:58Z"}
{"aid":"http://arxiv.org/abs/2504.06036v1","title":"Multi-Sense Embeddings for Language Models and Knowledge Distillation","summary":"Transformer-based large language models (LLMs) rely on contextual embeddings\nwhich generate different (continuous) representations for the same token\ndepending on its surrounding context. Nonetheless, words and tokens typically\nhave a limited number of senses (or meanings). We propose multi-sense\nembeddings as a drop-in replacement for each token in order to capture the\nrange of their uses in a language. To construct a sense embedding dictionary,\nwe apply a clustering algorithm to embeddings generated by an LLM and consider\nthe cluster centers as representative sense embeddings. In addition, we propose\na novel knowledge distillation method that leverages the sense dictionary to\nlearn a smaller student model that mimics the senses from the much larger base\nLLM model, offering significant space and inference time savings, while\nmaintaining competitive performance. Via thorough experiments on various\nbenchmarks, we showcase the effectiveness of our sense embeddings and knowledge\ndistillation approach. We share our code at\nhttps://github.com/Qitong-Wang/SenseDict","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T13:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06052v1","title":"Categorical matrix factorizations and monomorphism categories","summary":"This article generalizes the correspondence between matrix factorizations and\nmaximal Cohen-Macaulay modules over hypersurface rings due to Eisenbud and\nYoshino. We consider factorizations with several factors in a purely\ncategorical context, extending results of Sun and Zhang for Gorenstein\nprojective module factorizations. Our formulation relies on a notion of\nhypersurface category and replaces Gorenstein projectives by objects of general\nFrobenius exact subcategories. We show that factorizations over such categories\nform again a Frobenius category. Our main result is then a triangle equivalence\nbetween the stable category of factorizations and that of chains of\nmonomorphisms.","main_category":"math.CT","categories":"math.CT,math.AC","published":"2025-04-08T13:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.06056v1","title":"$L_\\textrm{dT}$: An ionospheric activity index based on distributions in\n  GNSS-derived TEC rates of change","summary":"Many aspects of our societies now depend upon satellite telecommunications,\nsuch as those requiring Global Navigation Satellite Systems (GNSS). GNSS is\nbased on radio waves that propagate through the ionosphere and experience\ncomplicated propagation effects caused by inhomogeneities in its electron\ndensity. The Earth's ionosphere forms part of the solar-terrestrial\nenvironment, and its state is determined by the spatial distribution and\ntemporal evolution of its electron density. It varies in response to the \"space\nweather\" combination of solar activity and geomagnetic conditions. Notably, the\nradio waves used in satellite telecommunications suffer due to the dispersive\nnature of the ionospheric plasma.\n  Scales and indices that summarise the state of the solar-terrestrial\nenvironment due to solar activity and geomagnetic conditions already exist.\nHowever, the response of the ionosphere to active geomagnetic conditions, its\ngeoeffectiveness, and its likely impact on systems and services are not\nencapsulated by these. This is due to the ionosphere's intrinsic day-to-day\nvariability, persistent seasonal patterns, and because radio wave measurements\nof the ionosphere depend upon many factors.\n  Here we develop a novel index that describes the state of the ionosphere\nduring specific space weather conditions. It is based on propagation\ndisturbances in GNSS signals, and is able to characterise the spatio-temporal\nevolution of ionospheric disturbances in near real time. This new scale\nencapsulates day-to-day variability, seasonal patterns, and the geo-effective\nresponse of the ionosphere to disturbed space weather conditions; and can be\napplied to data from any GNSS network. It is intended that this new scale will\nbe utilised by agencies providing space weather services, as well as by service\noperators to appreciate the current conditions in the ionosphere, thus\ninforming their operations.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-08T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.06078v1","title":"Carbon, Cost and Capacity: Multi-objective Charging of Electric Buses","summary":"The public transport sector is in the process of decarbonizing by\nelectrifying its bus fleets. This results in challenges if the high electricity\ndemand resulting from battery charging demand is confronted with limited grid\ncapacity and high synchronicity at bus charging sites. In this paper, we\nexplore multi-objective scheduling for bus charging sites to minimize the\nemissions associated with charging processes and to aid the operation of the\nelectricity grid by mitigating peak consumption. In particular, we discuss and\nvalidate optimization approaches for those objectives, as well as their\nweighted combination, based on data from a real-life bus charging site in the\nNetherlands. The simulation results show that compared to uncontrolled\ncharging, power peaks can be reduced by up to 57%, while time-of-use emissions\nassociated with the charging of electric buses are also reduced significantly.\nFurthermore, by using a synthetic baseload, we illustrate the flexibility\npotential offered by bus charging sites, and advocate that such sites should\nshare a grid connection with other high-load assets.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T14:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.06085v1","title":"Contact embeddings of 3-dimensional contact groups","summary":"A 3-dimensional contact group is a 3-dimensional Lie group endowed with a\nleft-invariant contact structure. Making use of techniques from Riemannian\ngeometry, we prove that any simply connected 3-dimensional contact group not\nisomorphic to SU(2) satisfies a unique factorization property. As an\napplication, we develop a method to construct embeddings of 3-dimensional\nsimply connected contact groups into one among two model tight contact\nmanifolds.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-08T14:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.06088v1","title":"MCAT: Visual Query-Based Localization of Standard Anatomical Clips in\n  Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer","summary":"Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:29:15Z"}
{"aid":"http://arxiv.org/abs/2504.06092v1","title":"Greedy Emulators for Nuclear Two-Body Scattering","summary":"Applications of reduced basis method emulators are increasing in low-energy\nnuclear physics because they enable fast and accurate sampling of high-fidelity\ncalculations, enabling robust uncertainty quantification. In this paper, we\ndevelop, implement, and test two model-driven emulators based on\n(Petrov-)Galerkin projection using the prototypical test case of two-body\nscattering with the Minnesota potential and a more realistic local chiral\npotential. The high-fidelity scattering equations are solved with the matrix\nNumerov method, a reformulation of the popular Numerov recurrence relation for\nsolving special second-order differential equations as a linear system of\ncoupled equations. A novel error estimator based on reduced-space residuals is\napplied to an active learning approach (a greedy algorithm) to choosing\ntraining samples (\"snapshots\") for the emulator and contrasted with a proper\northogonal decomposition (POD) approach. Both approaches allow for\ncomputationally efficient offline-online decompositions, but the greedy\napproach requires much fewer snapshot calculations. These developments set the\ngroundwork for emulating scattering observables based on chiral nucleon-nucleon\nand three-nucleon interactions and optical models, where computational\nspeed-ups are necessary for Bayesian uncertainty quantification. Our emulators\nand error estimators are widely applicable to linear systems.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex,physics.data-an","published":"2025-04-08T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06098v1","title":"Extremely asymmetric bipolar magnetic field of the Bp star HD 57372","summary":"Fossil magnetic fields of early-type stars are typically characterised by\nsymmetric or slightly distorted oblique dipolar surface geometries. Contrary to\nthis trend, the late-B magnetic chemically peculiar star HD 57372 exhibits an\nunusually large rotational variation of its mean magnetic field modulus,\nsuggesting a highly atypical field configuration. In this study, we present a\nZeeman Doppler imaging analysis of HD 57372, revealing an exceptionally\nasymmetric bipolar magnetic topology, rarely observed in early-type stars.\nAccording to our magnetic field maps, reconstructed from the intensity and\ncircular polarisation profiles of Fe, Cr, and Ti lines, approximately 66 per\ncent of the stellar surface is covered by a diffuse outward-directed radial\nfield, with local field strengths reaching 11.6 kG, while the remaining 34 per\ncent hosts a highly concentrated inward-directed field with a strong horizontal\ncomponent and a peak strength of 17.8 kG. These unusual surface magnetic field\ncharacteristics make HD 57372 a notable object for testing fossil-field\ntheories and interpreting phase-resolved spectropolarimetric observations of\nearly-type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T14:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.06099v1","title":"Towards Varroa destructor mite detection using a narrow spectra\n  illumination","summary":"This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T14:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.06116v1","title":"To Match or Not to Match: Revisiting Image Matching for Reliable Visual\n  Place Recognition","summary":"Visual Place Recognition (VPR) is a critical task in computer vision,\ntraditionally enhanced by re-ranking retrieval results with image matching.\nHowever, recent advancements in VPR methods have significantly improved\nperformance, challenging the necessity of re-ranking. In this work, we show\nthat modern retrieval systems often reach a point where re-ranking can degrade\nresults, as current VPR datasets are largely saturated. We propose using image\nmatching as a verification step to assess retrieval confidence, demonstrating\nthat inlier counts can reliably predict when re-ranking is beneficial. Our\nfindings shift the paradigm of retrieval pipelines, offering insights for more\nrobust and adaptive VPR systems.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.06131v1","title":"FaceCloak: Learning to Protect Face Templates","summary":"Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face raising security\nand privacy concerns. We present FaceCloak, a neural network framework that\nprotects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperforms leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. FaceCloak-based matching is\nextremely fast (inference time cost=0.28ms) and light-weight (0.57MB).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06136v1","title":"QGen Studio: An Adaptive Question-Answer Generation, Training and\n  Evaluation Platform","summary":"We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T15:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.06137v1","title":"Coexistence of magnetic and dielectric glassy states in alternating\n  kagome and triangular lattice LuBaCo$_4$O$_7$ cobaltite","summary":"To date, the alternating kagome and triangular lattice cobaltites,\nRBaCo$_4$O$_7$ (R = Ca, Y, and rare earth elements), have been well studied for\ntheir large structural distortions, anisotropic exchange interactions, chiral\nspin liquid states, and giant multiferroic properties. Here, we report the\nco-existence of magnetic and dielectric glassy states in LuBaCo$_4$O$_7$ below\n50 K. AC magnetization studies show an absence of conventional spin-freezing\nbehavior. The cooling and heating in unequal fields (CHUF), thermal cycling,\nand time-dependent magnetization measurements at low temperature ($T$) show the\npresence of magnetic glassy state. The $T$-dependent dielectric constant\n$\\epsilon'$ measurements exhibit a strong frequency-independent response at the\nfirst-order structural phase transition $T = 160$ K (trigonal $P31c$ to\nmonoclinic $Cc$) and also significant features at the $T = 110$ K (monoclinic\n$Cc$ to orthorhombic $Pbn2_1$) phase transition. Further, $\\epsilon'$ shows a\nfrequency-independent peak at 43 K ($Pbn2_1$) and also dipolar glassy features\nbelow 20 K ($Cc$). The non-equilibrium magnetic glassy dynamics and dipolar\nglassy state at low-$T$ arises from the kinetic arrest of $Cc$ and $Pbn2_1$\nphases. From the dielectric probe, we are able to clearly distinguish the\nkinetically arrested phases at low-$T$ , whereas the bulk magnetization studies\nare unable to do so as the arrested phases have low magnetic moments.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T15:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.06184v1","title":"The two-loop Higgs impact factor","summary":"In the HEFT, we consider the Regge limit of the two-loop amplitudes for Higgs\nboson production in association with a jet, expanded to NNLL accuracy. We\ndiscuss the issue of the Regge cuts versus poles in this context, and determine\nfor the first time the Higgs impact factor at two-loop accuracy.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T16:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.06235v1","title":"Decentralized Federated Domain Generalization with Style Sharing: A\n  Formal Modeling and Convergence Analysis","summary":"Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06238v1","title":"Infinite Boundary Friction Limit for Weak Solutions of the Stochastic\n  Navier-Stokes Equations","summary":"We address convergence of the unique weak solutions of the 2D stochastic\nNavier-Stokes equations with Navier boundary conditions, as the boundary\nfriction is taken uniformly to infinity, to the unique weak solution under the\nno-slip condition. Our result is that for initial velocity in $L^2_x$, the\nconvergence holds in probability in $C_tW^{-\\varepsilon,2}_x \\cap L^2_tL^2_x$\nfor any $0 < \\varepsilon$. The noise is of transport-stretching type, although\nthe theorem holds with other transport, multiplicative and additive noise\nstructures. This seems to be the first work concerning the large boundary\nfriction limit with noise, and convergence for weak solutions, due to only\n$L^2_{x}$ initial data, appears new even deterministically.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T17:34:29Z"}
{"aid":"http://arxiv.org/abs/2504.06266v1","title":"Constraining the [CII] luminosity function from the power spectrum of\n  line intensity maps at redshift 3.6","summary":"Forthcoming measurements of the line-intensity-mapping power spectrum (PS)\nare expected to set precious constraints on several quantities of astrophysical\nand cosmological interest. Our study targets the [CII] luminosity function (LF)\nat high redshift, which is still highly uncertain, in particular at the faint\nend. As an example of future opportunities, we present forecasts for the Deep\nSpectroscopic Survey (DSS) that will be conducted with the Fred Young\nSubmillimeter Telescope at $z \\simeq 3.6$ and also make predictions for\neventual $10\\times$ wider and/or $\\sqrt{10}\\times$ more sensitive surveys. The\nhalo-occupation properties of [CII] emitters in the MARIGOLD simulations\nprovide us with the motivation to abundance match two versions of the ALPINE LF\nagainst the halo mass function. We employ the resulting luminosity-mass\nrelation within the halo model to predict the expected PS signal and its\nuncertainty. Finally, we use Bayesian inference to analyse mock PS data and\nforecast what constraints could be achieved on the first two moments of the LF\nand on Schechter fits. Depending on the actual LF, the DSS will measure the\nclustering and shot-noise amplitudes of the PS with a signal-to-noise ratio of\n$\\sim 3$ or higher. However, degeneracies with the bias parameter and\nredshift-space distortions make it unfeasible to extract the first moment of\nthe LF. Even the widest and most sensitive survey we consider can only\nconstrain it with a $50\\%$ uncertainty. By jointly fitting the PS and the LF,\nwe directly constrain Schechter-function parameters. We find that the\nnormalisation and the cutoff luminosity are precisely and accurately measured\nwhile the faint-end slope remains highly uncertain (unless the true value\napproaches $-2$). Overall, increasing the survey sensitivity at fixed sky\ncoverage yields greater improvements than covering a larger area at fixed\nsensitivity.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06562v1","title":"FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion","summary":"Heterogeneous model fusion enhances the performance of LLMs by integrating\nthe knowledge and capabilities of multiple structurally diverse models.\nHowever, existing approaches often rely solely on selecting the best output for\neach prompt from source models, which underutilizes their full potential due to\nlimited source knowledge and results in sparse optimization signals. To address\nthis limitation, we propose FuseRL, a novel two-stage framework comprising\nFuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT\nestablishes a robust initialization by integrating the strengths of\nheterogeneous source models through weighted supervised fine-tuning (SFT) on\ndiverse outputs for each prompt. FusePO optimizes weighted preferences based on\nthe outputs of multiple source models to enable superior alignment performance.\nExtensive experiments demonstrate the effectiveness of our framework across\nvarious preference alignment methods, including RLOO, DPO, and SimPO. Using\nLlama-3.1-8B-Instruct as the target model, our approach achieves\nstate-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard\nbenchmarks. Further analysis suggests that FuseSFT regularizes the training\nprocess to reduce overfitting, while FusePO introduces dense and diverse\nsignals for preference optimization.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.06580v1","title":"Exploring Ordinal Bias in Action Recognition for Instructional Videos","summary":"Action recognition models have achieved promising results in understanding\ninstructional videos. However, they often rely on dominant, dataset-specific\naction sequences rather than true video comprehension, a problem that we define\nas ordinal bias. To address this issue, we propose two effective video\nmanipulation methods: Action Masking, which masks frames of frequently\nco-occurring actions, and Sequence Shuffling, which randomizes the order of\naction segments. Through comprehensive experiments, we demonstrate that current\nmodels exhibit significant performance drops when confronted with nonstandard\naction sequences, underscoring their vulnerability to ordinal bias. Our\nfindings emphasize the importance of rethinking evaluation strategies and\ndeveloping models capable of generalizing beyond fixed action patterns in\ndiverse instructional videos.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T05:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.06606v1","title":"Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program","summary":"Recent advancements in reward signal usage for Large Language Models (LLMs)\nare remarkable. However, significant challenges exist when transitioning reward\nsignal to the multimodal domain, including labor-intensive annotations,\nover-reliance on one-step rewards, and inadequate evaluation. To address these\nissues, we propose SVIP, a novel approach to train a step-level\nmulti-dimensional Chain-of-Thought~(CoT) reward model automatically. It\ngenerates code for solving visual tasks and transforms the analysis of code\nblocks into the evaluation of CoT step as training samples. Then, we train\nSVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The\nadvantages of SVIP-Reward are evident throughout the entire process of MLLM. We\nalso introduce a benchmark for CoT reward model training and testing.\nExperimental results demonstrate that SVIP-Reward improves MLLM performance\nacross training and inference-time scaling, yielding better results on\nbenchmarks while reducing hallucinations and enhancing reasoning ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.06620v1","title":"InstantSticker: Realistic Decal Blending via Disentangled Object\n  Reconstruction","summary":"We present InstantSticker, a disentangled reconstruction pipeline based on\nImage-Based Lighting (IBL), which focuses on highly realistic decal blending,\nsimulates stickers attached to the reconstructed surface, and allows for\ninstant editing and real-time rendering. To achieve stereoscopic impression of\nthe decal, we introduce shadow factor into IBL, which can be adaptively\noptimized during training. This allows the shadow brightness of surfaces to be\naccurately decomposed rather than baked into the diffuse color, ensuring that\nthe edited texture exhibits authentic shading. To address the issues of warping\nand blurriness in previous methods, we apply As-Rigid-As-Possible (ARAP)\nparameterization to pre-unfold a specified area of the mesh and use the local\nUV mapping combined with a neural texture map to enhance the ability to express\nhigh-frequency details in that area. For instant editing, we utilize the Disney\nBRDF model, explicitly defining material colors with 3-channel diffuse albedo.\nThis enables instant replacement of albedo RGB values during the editing\nprocess, avoiding the prolonged optimization required in previous approaches.\nIn our experiment, we introduce the Ratio Variance Warping (RVW) metric to\nevaluate the local geometric warping of the decal area. Extensive experimental\nresults demonstrate that our method surpasses previous decal blending methods\nin terms of editing quality, editing speed and rendering speed, achieving the\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06622v1","title":"Quantum neural networks facilitating quantum state classification","summary":"The classification of quantum states into distinct classes poses a\nsignificant challenge. In this study, we address this problem using quantum\nneural networks in combination with a problem-inspired circuit and customised\nas well as predefined ans\\\"{a}tz. To facilitate the resource-efficient quantum\nstate classification, we construct the dataset of quantum states using the\nproposed problem-inspired circuit. The problem-inspired circuit incorporates\ntwo-qubit parameterised unitary gates of varying entangling power, which is\nfurther integrated with the ans\\\"{a}tz, developing an entire quantum neural\nnetwork. To demonstrate the capability of the selected ans\\\"{a}tz, we visualise\nthe mitigated barren plateaus. The designed quantum neural network demonstrates\nthe efficiency in binary and multi-class classification tasks. This work\nestablishes a foundation for the classification of multi-qubit quantum states\nand offers the potential for generalisation to multi-qubit pure quantum states.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-09T06:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.06639v1","title":"Dielectronic recombination studies of ions relevant to kilonovae and\n  non-LTE plasma","summary":"This study presents calculations of rate coefficients, resonance strengths,\nand cross sections for the dielectronic recombination (DR) of Y^+, Sr^+, Te^2+,\nand Ce^2+--low-charge ions relevant to kilonovae and non-local thermodynamic\nequilibrium (non-LTE) plasmas. Using relativistic atomic structure methods, we\ncomputed DR rate coefficients under conditions typical of these environments.\nOur results highlight the critical role of low-lying DR resonances in shaping\nrate coefficients at kilonova temperatures (~ 10^4 K) and regulating\ncharge-state distributions. Pronounced near-threshold DR resonances\nsignificantly influence the evolving ionization states and opacity of neutron\nstar merger ejecta. Comparisons with previous studies emphasize the necessity\nof including high-n Rydberg states for accurate DR rate coefficients,\nespecially for complex heavy ions with dense energy levels. Discrepancies with\nexisting datasets underscore the need for refined computational techniques to\nminimize uncertainties. These results provide essential input for interpreting\nspectroscopic observations of neutron star mergers, including James Webb Space\nTelescope data. We also put forward suitable candidates for experimental\nstudies, recognizing the challenges involved in such measurements. The data\npresented here have potential to refine models of heavy-element\nnucleosynthesis, enhance plasma simulation accuracy, and improve non-LTE plasma\nmodeling in astrophysical and laboratory settings.","main_category":"astro-ph.HE","categories":"astro-ph.HE,physics.atom-ph","published":"2025-04-09T07:30:19Z"}
{"aid":"http://arxiv.org/abs/2504.06652v1","title":"The Shortest Temporal Exploration Problem","summary":"A temporal graph is a graph for which the edge set can change from one time\nstep to the next. This paper considers undirected temporal graphs defined over\nL time steps and connected at each time step. We study the Shortest Temporal\nExploration Problem (STEXP) that, given all the evolution of the graph, asks\nfor a temporal walk that starts at a given vertex, moves over at most one edge\nat each time step, visits all the vertices, takes at most L time steps and\ntraverses the smallest number of edges. . We prove that every constantly\nconnected temporal graph with n vertices can be explored with O(n 1.5 ) edges\ntraversed within O(n 3.5 ) time steps. This result improves the upper bound of\nO(n 2 ) edges for an exploration provided by the upper bound of time steps for\nan exploration which is also O(n 2 ). Morever, we study the case where the\ngraph has a diameter bounded by a parameter k at each time step and we prove\nthat there exists an exploration which takes O(kn 2 ) time steps and traverses\nO(kn) edges. Finally, the case where the underlying graph is a cycle is studied\nand tight bounds are provided on the number of edges traversed in the\nworst-case if L $\\ge$ 2n -3.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T07:42:25Z"}
{"aid":"http://arxiv.org/abs/2504.06675v1","title":"Probability Density Geodesics in Image Diffusion Latent Space","summary":"Diffusion models indirectly estimate the probability density over a data\nspace, which can be used to study its structure. In this work, we show that\ngeodesics can be computed in diffusion latent space, where the norm induced by\nthe spatially-varying inner product is inversely proportional to the\nprobability density. In this formulation, a path that traverses a high density\n(that is, probable) region of image latent space is shorter than the equivalent\npath through a low density region. We present algorithms for solving the\nassociated initial and boundary value problems and show how to compute the\nprobability density along the path and the geodesic distance between two\npoints. Using these techniques, we analyze how closely video clips approximate\ngeodesics in a pre-trained image diffusion space. Finally, we demonstrate how\nthese techniques can be applied to training-free image sequence interpolation\nand extrapolation, given a pre-trained image diffusion model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:28:53Z"}
{"aid":"http://arxiv.org/abs/2504.06683v1","title":"Hyperparameter Optimisation with Practical Interpretability and\n  Explanation Methods in Probabilistic Curriculum Learning","summary":"Hyperparameter optimisation (HPO) is crucial for achieving strong performance\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\ncurriculum learning strategy designed to improve RL performance by structuring\nthe agent's learning process, yet effective hyperparameter tuning remains\nchallenging and computationally demanding. In this paper, we provide an\nempirical analysis of hyperparameter interactions and their effects on the\nperformance of a PCL algorithm within standard RL tasks, including point-maze\nnavigation and DC motor control. Using the AlgOS framework integrated with\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\nAdditionally, we introduce a novel SHAP-based interpretability approach\ntailored specifically for analysing hyperparameter impacts, offering clear\ninsights into how individual hyperparameters and their interactions influence\nRL performance. Our work contributes practical guidelines and interpretability\ntools that significantly improve the effectiveness and computational\nfeasibility of hyperparameter optimisation in reinforcement learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T08:41:27Z"}
{"aid":"http://arxiv.org/abs/2504.06685v1","title":"Testing Multivariate Conditional Independence Using Exchangeable\n  Sampling and Sufficient Statistics","summary":"We consider testing multivariate conditional independence between a response\nY and a covariate vector X given additional variables Z. We introduce the\nMultivariate Sufficient Statistic Conditional Randomization Test (MS-CRT),\nwhich generates exchangeable copies of X by conditioning on sufficient\nstatistics of P(X|Z). MS-CRT requires no modelling assumption on Y and\naccommodates any test statistics, including those derived from complex\npredictive models. It relaxes the assumptions of standard conditional\nrandomization tests by allowing more unknown parameters in P(X|Z) than the\nsample size. MS-CRT avoids multiplicity corrections and effectively detects\njoint signals, even when individual components of X have only weak effects on Y\n. Our method extends to group selection with false discovery rate control. We\ndevelop efficient implementations for two important cases where P(X,Z) is\neither multivariate normal or belongs to a graphical model. For normal models,\nwe establish the minimax rate optimality. For graphical models, we demonstrate\nthe superior performance of our method compared to existing methods through\ncomprehensive simulations and real-data examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T08:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06731v1","title":"FJ-MM: The Friedkin-Johnsen Opinion Dynamics Model with Memory and\n  Higher-Order Neighbors","summary":"The Friedkin-Johnsen (FJ) model has been extensively explored and validated,\nspanning applications in social science, systems and control, game theory, and\nalgorithmic research. In this paper, we introduce an advanced generalization of\nthe FJ model, termed FJ-MM which incorporates both memory effects and multi-hop\n(higher-order neighbor) influence. This formulation allows agents to naturally\nincorporate both current and previous opinions at each iteration stage. Our\nnumerical results demonstrate that incorporating memory and multi-hop influence\nsignificantly reshapes the opinion landscape; for example, the final opinion\nprofile can exhibit reduced polarization. We analyze the stability and\nequilibrium properties of the FJ-MM model, showing that these properties can be\nreduced to those of a comparison model--namely, the standard FJ model with a\nmodified influence matrix. This reduction enables us to leverage established\nstability results from FJ dynamics. Additionally, we examine the convergence\nrate of the FJ-MM model and demonstrate that, as can be expected, the time lags\nintroduced by memory and higher-order neighbor influences result in slower\nconvergence.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC,physics.soc-ph","published":"2025-04-09T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.06750v1","title":"Robust Capacity Expansion Modelling for Renewable Energy Systems under\n  Weather and Demand Uncertainty","summary":"Future greenhouse gas neutral energy systems will be dominated by variable\nrenewable energy technologies. However, renewable electricity generation from\nwind and solar technologies, as well as electricity demand, varies with the\nweather. This work addresses the problem of determining optimal capacities for\nrenewable technologies in energy systems that ensure sufficient electricity\nsupply when dealing with multi-year time-series data. An iterative algorithm is\nproposed that starts by optimising an arbitrary starting time-series, followed\nby adding additional constraints and reoptimising the modified optimisation\nproblem until sufficient energy supply is provided for all time--series, i.e.\nthe solution is robust to weather and demand variations. This is evaluated in a\ncomputational study on a German energy system model.The results show that the\niterative algorithm finds robust solutions for an increase of 2-2.5% in total\nannual cost for a simplified model in gurobipy and 2.9% for a model built in\nthe model framework ETHOS.FINE. Testing the feasibility for non robust\nsolutions showed that supply gaps occurred in at least some of the remaining\nyears. Based on the results of this work, ensuring feasibility within an energy\nsystem model for multiple time-series boils down to two factors: ensuring\nsufficient back-up capacity to overcome periods of high demand combined with\nlow electricity generation from wind and photovoltaic, and enforcing sufficient\ntotal annual electricity generation. Our proposed open source iterative\nalgorithm is able to ensure this. For general modelling, it is recommended to\ncheck for systematic effects of different years' time--series on energy system\nmodels especially for wind, but also for photovoltaics, include dark lull and\ncold period effects on generation and demand in time--series, and assess the\nfeasibility of energy system models using different time-series.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,I.6","published":"2025-04-09T10:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.06778v1","title":"Controllable Automatic Foley Artist","summary":"Foley is a key element in video production, refers to the process of adding\nan audio signal to a silent video while ensuring semantic and temporal\nalignment. In recent years, the rise of personalized content creation and\nadvancements in automatic video-to-audio models have increased the demand for\ngreater user control in the process. One possible approach is to incorporate\ntext to guide audio generation. While supported by existing methods, challenges\nremain in ensuring compatibility between modalities, particularly when the text\nintroduces additional information or contradicts the sounds naturally inferred\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\nArtist) a video-and-text-to-audio model that generates semantically and\ntemporally aligned audio for a given video, guided by text input. CAFA is built\nupon a text-to-audio model and integrates video information through a modality\nadapter mechanism. By incorporating text, users can refine semantic details and\nintroduce creative variations, guiding the audio synthesis beyond the expected\nvideo contextual cues. Experiments show that besides its superior quality in\nterms of semantic alignment and audio-visual synchronization the proposed\nmethod enable high textual controllability as demonstrated in subjective and\nobjective evaluations.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-09T10:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.06802v1","title":"The ALMA-ATOMS survey: A sample of weak hot core candidates identified\n  through line stacking","summary":"Hot cores represent critical astrophysical environments for high-mass star\nformation, distinguished by their rich spectra of organic molecular emission\nlines. We aim to utilize high-angular resolution molecular line data from ALMA\nto identify hot cores, with a particular focus on weak-emission candidates, and\nto provide one of the largest samples of hot core candidates. We propose to use\nspectral stacking and imaging techniques of complex organic molecules (COMs) in\nthe ALMA-ATOMS survey, including line identification & weights, segmentation of\nline datacubes, resampling, stacking and normalization, moment 0 maps, and data\nanalysis, to search for hot core candidates. We classify cores with dense\nemission of CH3OH and at least one molecule from the other six molecules as hot\ncore candidates. In addition to the existing sample of 60 strong hot cores from\nthe ALMA-ATOMS survey, we have detected 40 new weak candidates through\nstacking. All hot core candidates display compact emission from at least one of\nthe other six COM species. For the strong sample, the stacking method provides\nmolecular column density estimates that are consistent with previous fitting\nresults. For the newly identified weak candidates, all species except CH3CHO\nshow compact emission in the stacked image, which cannot be fully resolved\nspatially. These weak candidates exhibit column densities of COMs that are\napproximately one order of magnitude lower than those of the strong sample. The\nentire hot core sample, including the weak candidates, reveals tight\ncorrelations between the compact emission of CH3OH and other COM species,\nsuggesting they may share a similar chemical environment for COMs, with CH3OH\npotentially acting as a precursor for other COMs. The molecular line stacking\ntechnique is used to identify hot core candidates in this work, leading to the\nidentification of 40 new hot core candidates.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T11:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.06834v1","title":"Green building blocks reveal the complex anatomy of climate change\n  mitigation technologies","summary":"Climate-change mitigating innovation is considered essential for the world's\ntransition toward a sustainable global economy. To guide this transition,\nintegrated assessment models map sectoral emissions reduction targets into\nlong-term trajectories towards carbon neutrality at the macro-level, while\ndetailed engineering studies at the micro-level develop concrete\ncarbon-mitigation technologies tailored to individual industries. However, we\nlack a meso-level understanding of how solutions connect across technological\ndomains. Building on the notion that innovating often entails combining\nexisting technologies in new ways, we identify Green Building Blocks (GBBs):\nmodules of technologies that can be added to nongreen technologies to mitigate\ntheir climate-change impact. Using natural language processing and\ndimensionality reduction techniques, we show how GBBs can be extracted from\nlarge-scale patent data. Next, we describe the anatomy of the green transition\nas a network that connects nongreen technologies to GBBs. This network has a\nnontrivial structure: whereas some nongreen technologies can connect to various\nGBBs, opening up a variety of ways to mitigate their impact on the global\nclimate, other nongreen technologies only connect to a single GBB. Similarly,\nsome GBBs are general purpose technologies that can reduce green house gases in\na vast range of applications, whereas others are tailored to specific use\ncases. Furthermore, GBBs prove predictive of the green technologies that firms\ndevelop, allowing us to map the green capabilities of firms not in terms of the\nspecific green technological solutions they invent, but in terms of their\ncapacity to develop broader classes of solutions with the GBBs they possess.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SI","published":"2025-04-09T12:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.06845v1","title":"Probability density function for dispersion measure of fast radio burst\n  from extragalactic medium","summary":"Fast Radio Bursts (FRBs) have emerged as powerful probes in cosmology. An\noptimized method for extracting the cosmic baryon density from localized FRBs,\nbased on maximizing the joint likelihood function of the extragalactic\ndispersion measure ($\\mathrm{DM}_{\\mathrm{ext}}$), was proposed by Macquart et\nal. [Nature 581, 391 (2020)]. In this Letter, we identify a crucial term that\nwas omitted in their derivation of the probability density function (PDF) for\n$\\mathrm{DM}_{\\mathrm{ext}}$. Using simulated FRB data, we demonstrate that\nneglecting this term leads to a systematic bias in the inferred cosmic baryon\ndensity, with deviations exceeding the $1\\sigma$ confidence level. This\nhighlights the importance of the missing term for the reliable cosmological\napplication of FRBs. Furthermore, employing a sample of 88 real localized FRBs,\nwe find that the baryon density derived using the original PDF by Macquart et\nal. is inconsistent with the Planck 2018 CMB data, while our corrected PDF\nyields a result in excellent agreement. We conclude that the omitted term is\nessential and must be included in order to obtain accurate cosmological\nconstraints from FRB observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T13:02:33Z"}
{"aid":"http://arxiv.org/abs/2504.06872v1","title":"More connection, less community: network formation and local public\n  goods provision","summary":"This paper presents a model of network formation and public goods provision\nin local communities. Here, networks can sustain public good provision by\nspreading information about people's behaviour. I find a critical threshold in\nnetwork connectedness at which public good provision drops sharply, even though\nagents are highly heterogeneous. Technology change can tear a community's\nsocial fabric by pushing high-skilled workers to withdraw from their local\ncommunity. This can help explain rising resentment toward perceived ``elites''\n-- their withdrawal actively harms those left behind. Moreover, well-meaning\npolicies that upskill workers can make them worse off by reducing network\nconnectedness.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T13:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.06890v1","title":"Combining high-contrast imaging with high-resolution spectroscopy:\n  Actual on-sky MIRI/MRS results compared to expectations","summary":"CONTEXT: Combining high-contrast imaging with high-resolution spectroscopy\noffers a powerful way to detect and characterize exoplanets around nearby\nstars, despite challenges linked to their faintness. Instruments like\nVLT/SPHERE are state of the art in high-contrast imaging, but their spectral\nresolution (R=50) limits them to basic characterization of close companions.\nThese systems can detect planets down to 5-10 Mjup at 10 AU from their stars.\nDetection limits are mainly constrained by speckle noise, which dominates over\nphoton and detector noise at short separations, even with advanced differential\nimaging. Space-based high-contrast imaging is also limited by image stability.\nSpeckle noise can, however, be mitigated through molecular mapping, a technique\nthat leverages high-resolution spectroscopic data.\n  AIMS: We aim to predict detection limits in spectro-imaging after molecular\nmapping, analyzing how photon and detector noise propagate and comparing\npredictions with real data to assess performance losses from instrumental\neffects. We also propose mitigation strategies and validate our model using\nobservations.\n  METHODS: We analyzed JWST/MIRI/MRS data with FastCurves, an numerical tool,\nand compared results to outputs from the MIRI simulator. We also applied\nprincipal component analysis (PCA) to identify and isolate systematic effects,\nwith and without molecular mapping.\n  RESULTS: We studied various systematic effects and their impacts on signal\nand noise. PCA helped highlight and reduce straylight, fringes, and aliasing.\nWe further compared observed and modeled companion spectra.\n  CONCLUSIONS: FastCurves was improved to account for systematics and validated\nwith real data. In high-flux regimes, systematics impose contrast limits even\nwith molecular mapping. Our approach could benefit other instruments and inform\nthe planning of future facilities like ELT/ANDES and ELT/PCS.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-04-09T13:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.06910v1","title":"Identifying Aspects in Peer Reviews","summary":"Peer review is central to academic publishing, but the growing volume of\nsubmissions is straining the process. This motivates the development of\ncomputational approaches to support peer review. While each review is tailored\nto a specific paper, reviewers often make assessments according to certain\naspects such as Novelty, which reflect the values of the research community.\nThis alignment creates opportunities for standardizing the reviewing process,\nimproving quality control, and enabling computational support. While prior work\nhas demonstrated the potential of aspect analysis for peer review assistance,\nthe notion of aspect remains poorly formalized. Existing approaches often\nderive aspect sets from review forms and guidelines of major NLP venues, yet\ndata-driven methods for aspect identification are largely underexplored. To\naddress this gap, our work takes a bottom-up approach: we propose an\noperational definition of aspect and develop a data-driven schema for deriving\nfine-grained aspects from a corpus of peer reviews. We introduce a dataset of\npeer reviews augmented with aspects and show how it can be used for\ncommunity-level review analysis. We further show how the choice of aspects can\nimpact downstream applications, such as LLM-generated review detection. Our\nresults lay a foundation for a principled and data-driven investigation of\nreview aspects, and pave the path for new applications of NLP to support peer\nreview.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T14:14:42Z"}
{"aid":"http://arxiv.org/abs/2504.06921v1","title":"Leveraging Anatomical Priors for Automated Pancreas Segmentation on\n  Abdominal CT","summary":"An accurate segmentation of the pancreas on CT is crucial to identify\npancreatic pathologies and extract imaging-based biomarkers. However, prior\nresearch on pancreas segmentation has primarily focused on modifying the\nsegmentation model architecture or utilizing pre- and post-processing\ntechniques. In this article, we investigate the utility of anatomical priors to\nenhance the segmentation performance of the pancreas. Two 3D full-resolution\nnnU-Net models were trained, one with 8 refined labels from the public PANORAMA\ndataset, and another that combined them with labels derived from the public\nTotalSegmentator (TS) tool. The addition of anatomical priors resulted in a 6\\%\nincrease in Dice score ($p < .001$) and a 36.5 mm decrease in Hausdorff\ndistance for pancreas segmentation ($p < .001$). Moreover, the pancreas was\nalways detected when anatomy priors were used, whereas there were 8 instances\nof failed detections without their use. The use of anatomy priors shows promise\nfor pancreas segmentation and subsequent derivation of imaging biomarkers.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.06947v1","title":"RuOpinionNE-2024: Extraction of Opinion Tuples from Russian News Texts","summary":"In this paper, we introduce the Dialogue Evaluation shared task on extraction\nof structured opinions from Russian news texts. The task of the contest is to\nextract opinion tuples for a given sentence; the tuples are composed of a\nsentiment holder, its target, an expression and sentiment from the holder to\nthe target. In total, the task received more than 100 submissions. The\nparticipants experimented mainly with large language models in zero-shot,\nfew-shot and fine-tuning formats. The best result on the test set was obtained\nwith fine-tuning of a large language model. We also compared 30 prompts and 11\nopen source language models with 3-32 billion parameters in the 1-shot and\n10-shot settings and found the best models and prompts.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-09T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.06955v1","title":"Parametric Reachable Sets Via Controlled Dynamical Embeddings","summary":"In this work, we propose a new framework for reachable set computation\nthrough continuous evolution of a set of parameters and offsets which define a\nparametope, through the intersection of constraints. This results in a\ndynamical approach towards nonlinear reachability analysis: a single trajectory\nof an embedding system provides a parametope reachable set for the original\nsystem, and uncertainties are accounted for through continuous parameter\nevolution. This is dual to most existing computational strategies, which define\nsets through some combination of generator vectors, and usually discretize the\nsystem dynamics. We show how, under some regularity assumptions of the dynamics\nand the set considered, any desired parameter evolution can be accommodated as\nlong as the offset dynamics are set accordingly, providing a virtual \"control\ninput\" for reachable set computation. In a special case of the theory, we\ndemonstrate how closing the loop for the parameter dynamics using the adjoint\nof the linearization results in a desirable first-order cancellation of the\noriginal system dynamics. Using interval arithmetic in JAX, we demonstrate the\nefficiency and utility of reachable parametope computation through two\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-09T15:02:46Z"}
{"aid":"http://arxiv.org/abs/2504.06971v1","title":"Extinction rates for nonradial solutions to the Stefan problem","summary":"We consider the one-phase Stefan problem describing the evolution of melting\nice. On the one hand, we focus on understanding the evolution of the free\nboundary near isolated singular points, and we establish for the first time\nupper and (more surprisingly) lower estimates for its evolution. In 2D, these\nbounds almost match the best known ones for radial solutions, but hold for all\nsolutions to the Stefan problem, with no extra assumption on the initial or\nboundary data. On the other hand, as a consequence of our results, we also\ncharacterize the global regularity of the free boundary, as follows: it can be\nwritten as a graph $t = \\Gamma(x)$, where $\\Gamma$ is $C^1$ (and not $C^2$)\nnear any singular points in the lower strata $\\Sigma_m$, $m \\leq n - 2$.\nMoreover, $\\Gamma$ is not $C^1$ at singular points in $\\Sigma_{n-1}$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T15:26:54Z"}
{"aid":"http://arxiv.org/abs/2504.06982v1","title":"SIGMAN:Scaling 3D Human Gaussian Generation with Millions of Assets","summary":"3D human digitization has long been a highly pursued yet challenging task.\nExisting methods aim to generate high-quality 3D digital humans from single or\nmultiple views, but remain primarily constrained by current paradigms and the\nscarcity of 3D human assets. Specifically, recent approaches fall into several\nparadigms: optimization-based and feed-forward (both single-view regression and\nmulti-view generation with reconstruction). However, they are limited by slow\nspeed, low quality, cascade reasoning, and ambiguity in mapping low-dimensional\nplanes to high-dimensional space due to occlusion and invisibility,\nrespectively. Furthermore, existing 3D human assets remain small-scale,\ninsufficient for large-scale training. To address these challenges, we propose\na latent space generation paradigm for 3D human digitization, which involves\ncompressing multi-view images into Gaussians via a UV-structured VAE, along\nwith DiT-based conditional generation, we transform the ill-posed\nlow-to-high-dimensional mapping problem into a learnable distribution shift,\nwhich also supports end-to-end inference. In addition, we employ the multi-view\noptimization approach combined with synthetic data to construct the HGS-1M\ndataset, which contains $1$ million 3D Gaussian assets to support the\nlarge-scale training. Experimental results demonstrate that our paradigm,\npowered by large-scale training, produces high-quality 3D human Gaussians with\nintricate textures, facial details, and loose clothing deformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.06998v1","title":"A Krylov projection algorithm for large symmetric matrices with dense\n  spectra","summary":"We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d.\n$A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times\np}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output\n(MIMO) transfer functions for large-scale discretizations of problems with\ncontinuous spectral measures, such as linear time-invariant (LTI) PDEs on\nunbounded domains. Traditional Krylov methods, such as the Lanczos or CG\nalgorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with\nreal positive $s$, resulting in an adaptation to the distinctively discrete and\nnonuniform spectra. However, the adaptation is damped for matrices with dense\nspectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of\nScientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss\n-Radau quadratures computed using the block-Lanczos method significantly\nreduces approximation errors for such problems. Here, we introduce an adaptive\nKre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing\nfurther acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau\nquadrature, a low-rank modification is applied to the (block) Lanczos matrix.\nHowever, unlike the Gau\\ss -Radau quadrature, this modification depends on\n$\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e\napproximants, which are known to be efficient for problems with branch-cuts,\nthat can be good approximations to dense spectral intervals. Numerical results\nfor large-scale discretizations of heat-diffusion and quasi-magnetostatic\nMaxwell's operators in unbounded domains confirm the efficiency of the proposed\napproach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07000v1","title":"Deviation Estimates for Extremal Relay Random Geometric Graphs","summary":"In this paper, we consider a deterministic graph~\\(\\Gamma\\) drawn on the unit\nsquare with straight line segments as edges and connect vertices of~\\(\\Gamma\\)\nusing edges of a random geometric graph (RGG)~\\(G\\) with adjacency\ndistance~\\(r_n\\) as relays. We call the resulting graph as a \\emph{relay} RGG\nand determine sufficient conditions under such relay RGGs exist and are also\nnear optimal, in terms of the graph parameters of~\\(\\Gamma.\\) We then equip\nedges of~\\(G\\) with independent, exponentially distributed weights and obtain\nbounds for the maximum possible weight~\\(W_n\\) of a relay RGG with a given\nlength~\\(L_n.\\)","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.07009v1","title":"Efficient Light Generation in Ultraviolet-A Band on Chip","summary":"Lithium niobate nano photonics provides highly efficient nonlinear optics\nprocesses covering a broad spectrum from ultraviolet to mid-infrared, yet\nstudies thus far have concentrated in the near-infrared regime. Here we\ndemonstrate light generation in the Ultraviolet-A band in a periodic poled\nwaveguide via second harmonic generation. The internal efficiency reaches 1797\n$\\% W^{-1}/cm^{-2}$, marking a 9.1-times improvement over the state of art,\nthanks to better mode overlap and poling. Our technique can find applications\nin atomic clocks, frequency comb generation, sensing, and visible entanglement\ngeneration.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-09T16:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07040v1","title":"Bounds on the number of squares in recurrence sequences: arbitrary $b$,\n  III","summary":"We generalise our earlier work on the number of squares in binary recurrence\nsequences, $\\left\\{ y_{k} \\right\\}_{k \\geq -\\infty}$. In the notation of our\nprevious papers, here we consider the case when $N_{\\alpha}$ is any negative\ninteger and $y_{0}=b^{2}$ for any positive integer, $b$. We show that there are\nat most $4$ distinct squares with $y_{k}$ sufficiently large. This allows us to\nalso show that there are at most $9$ distinct squares in such sequences when\n$b=1,2$ or $3$, or once $d$ is sufficiently large.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T16:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.07070v1","title":"A Survey on Personalized and Pluralistic Preference Alignment in Large\n  Language Models","summary":"Personalized preference alignment for large language models (LLMs), the\nprocess of tailoring LLMs to individual users' preferences, is an emerging\nresearch direction spanning the area of NLP and personalization. In this\nsurvey, we present an analysis of works on personalized alignment and modeling\nfor LLMs. We introduce a taxonomy of preference alignment techniques, including\ntraining time, inference time, and additionally, user-modeling based methods.\nWe provide analysis and discussion on the strengths and limitations of each\ngroup of techniques and then cover evaluation, benchmarks, as well as open\nproblems in the field.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:39:58Z"}
{"aid":"http://arxiv.org/abs/2504.07079v1","title":"SkillWeaver: Web Agents can Self-Improve by Discovering and Honing\n  Skills","summary":"To survive and thrive in complex environments, humans have evolved\nsophisticated self-improvement mechanisms through environment exploration,\nhierarchical abstraction of experiences into reuseable skills, and\ncollaborative construction of an ever-growing skill repertoire. Despite recent\nadvancements, autonomous web agents still lack crucial self-improvement\ncapabilities, struggling with procedural knowledge abstraction, refining\nskills, and skill composition. In this work, we introduce SkillWeaver, a\nskill-centric framework enabling agents to self-improve by autonomously\nsynthesizing reusable skills as APIs. Given a new website, the agent\nautonomously discovers skills, executes them for practice, and distills\npractice experiences into robust APIs. Iterative exploration continually\nexpands a library of lightweight, plug-and-play APIs, significantly enhancing\nthe agent's capabilities. Experiments on WebArena and real-world websites\ndemonstrate the efficacy of SkillWeaver, achieving relative success rate\nimprovements of 31.8% and 39.8%, respectively. Additionally, APIs synthesized\nby strong agents substantially enhance weaker agents through transferable\nskills, yielding improvements of up to 54.3% on WebArena. These results\ndemonstrate the effectiveness of honing diverse website interactions into APIs,\nwhich can be seamlessly shared among various web agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-09T17:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.07442v1","title":"RIS-Aided Integrated Sensing and Communication Waveform Design With\n  Tunable PAPR","summary":"Low peak-to-average power ratio (PAPR) transmission is an important and\nfavorable requirement prevalent in radar and communication systems, especially\nin transmission links integrated with high power amplifiers. Meanwhile,\nmotivated by the advantages of reconfigurable intelligent surface (RIS) in\nmitigating multi-user interference (MUI) to enhance the communication rate,\nthis paper investigates the design problem of joint waveform and passive\nbeamforming with PAPR constraint for integrated sensing and communication\n(ISAC) systems, where RIS is deployed for downlink communication. We first\nconstruct a trade-off optimization problem for the MUI and beampattern\nsimilarity under PAPR constraint. Then, in order to solve this multivariate\nproblem, an iterative optimization algorithm based on alternating direction\nmethod of multipliers (ADMM) and manifold optimization is proposed. Finally,\nthe simulation results show that the designed waveforms can well satisfy the\nPAPR requirement of the ISAC systems and achieve a trade-off between radar and\ncommunication performance. Under high signal-to-noise ratio (SNR) conditions,\ncompared to systems without RIS, RIS-aided ISAC systems have a performance\nimprovement of about 50\\% in communication rate and at least 1 dB in\nbeampatterning error.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T04:18:23Z"}
{"aid":"http://arxiv.org/abs/2504.07453v1","title":"Probability Estimation and Scheduling Optimization for Battery Swap\n  Stations via LRU-Enhanced Genetic Algorithm and Dual-Factor Decision System","summary":"To address the challenges of limited Battery Swap Stations datasets, high\noperational costs, and fluctuating user charging demand, this research proposes\na probability estimation model based on charging pile data and constructs nine\nscenario-specific battery swap demand datasets. In addition, this study\ncombines Least Recently Used strategy with Genetic Algorithm and incorporates a\nguided search mechanism, which effectively enhances the global optimization\ncapability. Thus, a dual-factor decision-making based charging schedule\noptimization system is constructed. Experimental results show that the\nconstructed datasets exhibit stable trend characteristics, adhering to 24-hour\nand 168-hour periodicity patterns, with outlier ratios consistently below\n3.26%, confirming data validity. Compared to baseline, the improved algorithm\nachieves better fitness individuals in 80% of test regions under the same\niterations. When benchmarked against immediate swap-and-charge strategy, our\nalgorithm achieves a peak cost reduction of 13.96%. Moreover, peak user\nsatisfaction reaches 98.57%, while the average iteration time remains below 0.6\nseconds, demonstrating good computational efficiency. The complete datasets and\noptimization algorithm are open-sourced at\nhttps://github.com/qingshufan/GA-EVLRU.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T04:58:24Z"}
{"aid":"http://arxiv.org/abs/2504.07469v1","title":"Vortex droplets and lattice patterns in two-dimensional traps: A\n  photonic spin-orbit-coupling perspective","summary":"In the context of the mean-field exciton-polariton (EP) theory with balanced\nloss and pump, we investigate the formation of lattice structures built of\nindividual vortex-antivortex (VAV) bound states under the action of the\ntwo-dimensional harmonic-oscillator (HO) potential trap and effective\nspin-orbit coupling (SOC), produced by the TE-TM splitting in the polariton\nsystem. The number of VAV elements (pixels) building the structures grow with\nthe increase of self- and cross-interaction coefficients. Depending upon their\nvalues and the trapping frequency, stable ring-shaped, circular, square-shaped,\nrectangular, pentagonal, hexagonal, and triangular patterns are produced, with\nthe central site left vacant or occupied in the lattice patterns of different\ntypes. The results suggest the experimental creation of the new patterns and\ntheir possible use for the design of integrated circuits in EP setups,\ncontrolled by the strengths of the TE-TM splitting, nonlinearity, and HO trap.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T05:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.07487v1","title":"Microscopic model for yields and total kinetic energy in nuclear fission","summary":"An extension of time-dependent density functional theory (TDDFT), the\ngeneralized time-dependent generator coordinate method (TDGCM), is applied to a\nstudy of induced nuclear fission dynamics. In the generalized TDGCM, the\ncorrelated nuclear wave function is represented as a coherent superposition of\ntime-dependent DFT trajectories. In the first realistic application, a large\nbasis of 25 TDDFT trajectories is employed to calculate the charge yields and\ntotal kinetic energy distribution for the fission of $^{240}$Pu. The results\nare compared with available data, and with those obtained using a standard\nTDDFT, that does not consider quantum fluctuations, and the adiabatic TDGCM+GOA\n(Gaussian overlap approximation). It is shown that fragment yields and kinetic\nenergies can simultaneously be described in a consistent microscopic framework\nthat includes fluctuations in the collective degrees of freedom and the\none-body dissipation mechanism.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-10T06:42:56Z"}
{"aid":"http://arxiv.org/abs/2504.07536v1","title":"Criteria for finite injective dimension of modules over a local ring","summary":"Let $R$ be a commutative Noetherian local ring. We prove that the finiteness\nof the injective dimension of a finitely generated $R$-module $C$ is determined\nby the existence of a Cohen--Macaulay module $M$ that satisfies an inequality\nconcerning multiplicity and type, together with the vanishing of finitely many\nExt modules. As applications, we recover a result of Rahmani and Taherizadeh\nand provide sufficient conditions for a finitely generated $R$-module to have\nfinite injective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.07544v1","title":"SeparationPINN: Physics-Informed Neural Networks for Seismic P- and\n  S-Wave Mode Separation","summary":"Accurate separation of P- and S-waves is essential for multi-component\nseismic data processing, as it helps eliminate interference between wave modes\nduring imaging or inversion, which leads to high-accuracy results. Traditional\nmethods for separating P- and S-waves rely on the Christoffel equation to\ncompute the polarization direction of the waves in the wavenumber domain, which\nis computationally expensive. Although machine learning has been employed to\nimprove the computational efficiency of the separation process, most methods\nstill require supervised learning with labeled data, which is often unavailable\nfor field data. To address this limitation, we propose a wavefield separation\ntechnique based on the physics-informed neural network (PINN). This\nunsupervised machine learning approach is applicable to unlabeled data.\nFurthermore, the trained PINN model provides a mesh-free numerical solution\nthat effectively captures wavefield features at multiple scales. Numerical\ntests demonstrate that the proposed PINN-based separation method can accurately\nseparate P- and S-waves in both homogeneous and heterogeneous media.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.07563v1","title":"Post-Newtonian dynamics of compact binaries with mass transfer","summary":"Taking into account the mass transfer effect, we derive the equations of\nmotion of a compact binary system at the second-half post-Newtonian order.\nApplying such equations of motion to quasi-circular orbits, we obtain the time\nderivative of the orbital frequency, which is consistent with the angular\nmomentum balance equation. Numerical estimates of the phase of gravitational\nwaves are provided for typical mass transfer rates. Our result can be used to\nimprove the waveforms of gravitational waves emitted by compact binaries with\nmass transfer.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:49:57Z"}
{"aid":"http://arxiv.org/abs/2504.07567v1","title":"Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf\n  Foundation Models, Fine-Tuning Strategies and Practical Trade-offs","summary":"We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CE,cs.IR,cs.LG","published":"2025-04-10T08:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.07569v1","title":"Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple\n  modelling","summary":"We provide an updated test for modifications of gravity from a sample of\nwide-binary stars from GAIA DR3, and their sky-projected relative velocities.\nHere we extend on our earlier 2023 study, using several updated selection cuts\naimed at reducing contamination from triple systems with an undetected third\nstar. We also use improved mass estimates from FLAMES, and we add refinements\nto previous modelling of the triple and other populations and the\nmodel-fitting. We fit histograms of observed vs Newtonian velocity differences\nto a flexible mixture of binary + triple populations with realistic\neccentricity distributions, plus unbound flyby and random-chance populations.\nWe find as before that Newtonian models provide a significantly better fit than\nMOND, though improved understanding of the triple population is necessary to\nmake this fully decisive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-10T09:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.07585v1","title":"High-Level Synthesis of Digital Circuits from Template Haskell and\n  SDF-AP","summary":"Functional languages as input specifications for High-Level Synthesis (HLS)\ntools allow to specify data dependencies but do not contain a notion of time\nnor execution order. In this paper, we propose a method to add this notion to\nthe functional description using the dataflow model SDF-AP. SDF-AP consists of\npatterns that express consumption and production that we can use to enforce\nresource usage. We created an HLS-tool that can synthesize parallel hardware,\nboth data and control path, based on the repetition, expressed in Higher-Order\nFunctions, combined with specified SDF-AP patterns.\n  Our HLS-tool, based on Template Haskell, generates an Abstract Syntax Tree\nbased on the given patterns and the functional description uses the\nClash-compiler to generate VHDL/Verilog.\n  Case studies show consistent resource consumption and temporal behavior for\nour HLS. A comparison with a commercially available HLS-tool shows that our HLS\ntool outperforms in terms of latency and sometimes in resource consumption.\n  The method and tool presented in this paper offer more transparency to the\ndeveloper and allow to specify more accurately the synthesized hardware\ncompared to what is possible with pragmas of the Vitis HLS-tool.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:25:47Z"}
{"aid":"http://arxiv.org/abs/2504.07601v1","title":"Restricted Poisson algebras in characteristic 2","summary":"In this paper, we introduce restricted Poisson algebras in characteristic 2\nand their relationship with restricted Lie-Rinehart algebras, for which we\ndevelop a cohomology theory and investigate abelian extensions. We also\nconstruct a full cohomology complex for restricted Poisson algebras in\ncharacteristic 2 that captures formal deformations and prove that it is\nisomorphic to the cohomology complex of a suitable restricted Lie-Rinehart\nalgebra, under certain assumptions. A number of examples are provided in order\nto illustrate our constructions.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T09:54:29Z"}
{"aid":"http://arxiv.org/abs/2504.07615v1","title":"VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model","summary":"Recently DeepSeek R1 has shown that reinforcement learning (RL) can\nsubstantially improve the reasoning capabilities of Large Language Models\n(LLMs) through a simple yet effective design. The core of R1 lies in its\nrule-based reward formulation, which leverages tasks with deterministic\nground-truth answers to enable precise and stable reward computation. In the\nvisual domain, we similarly observe that a wide range of visual understanding\ntasks are inherently equipped with well-defined ground-truth annotations. This\nproperty makes them naturally compatible with rule-based reward mechanisms.\nMotivated by this observation, we investigate the extension of R1-style\nreinforcement learning to Vision-Language Models (VLMs), aiming to enhance\ntheir visual reasoning capabilities. To this end, we develop VLM-R1, a\ndedicated framework designed to harness RL for improving VLMs' performance on\ngeneral vision-language tasks. Using this framework, we further explore the\nfeasibility of applying RL to visual domain. Experimental results indicate that\nthe RL-based model not only delivers competitive performance on visual\nunderstanding tasks but also surpasses Supervised Fine-Tuning (SFT) in\ngeneralization ability. Furthermore, we conduct comprehensive ablation studies\nthat uncover a series of noteworthy insights, including the presence of reward\nhacking in object detection, the emergence of the \"OD aha moment\", the impact\nof training data quality, and the scaling behavior of RL across different model\nsizes. Through these analyses, we aim to deepen the understanding of how\nreinforcement learning enhances the capabilities of vision-language models, and\nwe hope our findings and open-source contributions will support continued\nprogress in the vision-language RL community. Our code and model are available\nat https://github.com/om-ai-lab/VLM-R1","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T10:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.07622v1","title":"A new quasar strongly-lensed candidate by the galaxy cluster WHJ0400-27\n  with a $18''$ image-separation","summary":"Time-delay cosmography (TDC) using multiply-lensed quasars (QSOs) by galaxies\nhas recently emerged as an independent and competitive tool to measure the\nvalue of the Hubble constant. Lens galaxy clusters hosting multiply-imaged\nQSOs, when coupled with an accurate and precise knowledge of their total mass\ndistribution, are equally powerful cosmological probes. However, less than ten\nsuch systems have been identified to date. Our study aims to expand the limited\nsample of cluster-lensed QSO systems by identifying new candidates within rich\ngalaxy clusters. Starting from a sample of ~$10^5$ galaxy cluster candidates\n(Wen & Han, 2022), built from Dark Energy Survey and Wide-field Infrared Survey\nExplorer imaging data, and a highly-pure catalogue of over one million QSOs,\nbased on Gaia DR3 data, we cross-correlate them to identify candidate lensed\nQSOs near the core of massive galaxy clusters. Our search yielded 3 lensed\ndouble candidates over an area of ~$5000$ sq. degree. In this work, we focus on\nthe best candidate consisting of a double QSO with Gaia-based redshift of 1.35,\nprojected behind a moderately rich cluster (WHJ0400-27) at $z_{phot}=0.65$.\nBased on a first spectroscopic follow-up study, we confirm the two QSOs at\n$z=1.345$, with indistinguishable spectra, and a brightest cluster galaxy at\n$z=0.626$. These observations seem to support the strong lensing nature of this\nsystem, although some tension emerges when the cluster mass from a preliminary\nlens model is compared with that from other mass proxies. We also discuss the\npossibility that such system is a rare physical association of two distinct\nQSOs with a projected physical distance of ~$150$ kpc. If further spectroscopic\nobservations confirm its lensing nature, such a rare lens system would exhibit\none of the largest image separations observed to date\n($\\Delta\\vartheta=17.8''$), opening interesting TDC applications.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-10T10:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.07623v1","title":"Joint Travel Route Optimization Framework for Platooning","summary":"Platooning represents an advanced driving technology designed to assist\ndrivers in traffic convoys of varying lengths, enhancing road safety, reducing\ndriver fatigue, and improving fuel efficiency. Sophisticated automated driving\nassistance systems have facilitated this innovation. Recent advancements in\nplatooning emphasize cooperative mechanisms within both centralized and\ndecentralized architectures enabled by vehicular communication technologies.\nThis study introduces a cooperative route planning optimization framework aimed\nat promoting the adoption of platooning through a centralized platoon formation\nstrategy at the system level. This approach is envisioned as a transitional\nphase from individual (ego) driving to fully collaborative driving.\nAdditionally, this research formulates and incorporates travel cost metrics\nrelated to fuel consumption, driver fatigue, and travel time, considering\nregulatory constraints on consecutive driving durations. The performance of\nthese cost metrics has been evaluated using Dijkstra's and A* shortest path\nalgorithms within a network graph framework. The results indicate that the\nproposed architecture achieves an average cost improvement of 14 % compared to\nindividual route planning for long road trips.","main_category":"cs.ET","categories":"cs.ET,cs.RO,cs.SY,eess.SY","published":"2025-04-10T10:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.07627v1","title":"Robustness of Online Identification-based Policy Iteration to Noisy Data","summary":"This article investigates the core mechanisms of indirect data-driven control\nfor unknown systems, focusing on the application of policy iteration (PI)\nwithin the context of the linear quadratic regulator (LQR) optimal control\nproblem. Specifically, we consider a setting where data is collected\nsequentially from a linear system subject to exogenous process noise, and is\nthen used to refine estimates of the optimal control policy. We integrate\nrecursive least squares (RLS) for online model estimation within a\ncertainty-equivalent framework, and employ PI to iteratively update the control\npolicy. In this work, we investigate first the convergence behavior of RLS\nunder two different models of adversarial noise, namely point-wise and energy\nbounded noise, and then we provide a closed-loop analysis of the combined model\nidentification and control design process. This iterative scheme is formulated\nas an algorithmic dynamical system consisting of the feedback interconnection\nbetween two algorithms expressed as discrete-time systems. This system\ntheoretic viewpoint on indirect data-driven control allows us to establish\nconvergence guarantees to the optimal controller in the face of uncertainty\ncaused by noisy data. Simulations illustrate the theoretical results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T10:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.07669v1","title":"Languages of Boundedly-Ambiguous Vector Addition Systems with States","summary":"The aim of this paper is to deliver broad understanding of a class of\nlanguages of boundedly-ambiguous VASS, that is k-ambiguous VASS for some\nnatural k. These are languages of Vector Addition Systems with States with the\nacceptance condition defined by the set of accepting states such that each\naccepted word has at most k accepting runs. We develop tools for proving that a\ngiven language is not accepted by any k-ambiguous VASS. Using them we show a\nfew negative results: lack of some closure properties of languages of\nk-ambiguous VASS and undecidability of the k-ambiguity problem, namely the\nquestion whether a given VASS language is a language of some k-ambiguous VASS.\nFinally, we show that the regularity problem is decidable for k-ambiguous VASS.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-10T11:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.07674v1","title":"Is the atmospheric river operating at a self-organized criticality\n  state?","summary":"Atmospheric rivers (ARs) are essential components of the global hydrological\ncycle, with profound implications for water resources, extreme weather events,\nand climate dynamics. Yet, the statistical organization and underlying physical\nmechanisms of AR intensity and evolution remain poorly understood. Here we\napply methods from statistical physics to analyze the full life cycle of ARs\nand identify universal signatures of self-organized criticality (SOC). We\ndemonstrate that AR morphology exhibits nontrivial fractal geometry, while AR\nevent sizes, quantified via integrated water vapor transport, follow robust\npower-law distributions, displaying finite-size scaling. These scaling\nbehaviors persist under warming scenarios, suggesting that ARs operate near a\ncritical state as emergent, self-regulating systems. Concurrently, we observe a\nsystematic poleward migration and intensification of ARs, linked to\nthermodynamic amplification and dynamical reorganization. Our findings\nestablish a statistical physics framework for ARs, linking critical phenomena\nto the spatiotemporal structure of extreme events in a warming climate.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T11:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.07685v1","title":"Context-Aware Monolingual Human Evaluation of Machine Translation","summary":"This paper explores the potential of context-aware monolingual human\nevaluation for assessing machine translation (MT) when no source is given for\nreference. To this end, we compare monolingual with bilingual evaluations (with\nsource text), under two scenarios: the evaluation of a single MT system, and\nthe comparative evaluation of pairwise MT systems. Four professional\ntranslators performed both monolingual and bilingual evaluations by assigning\nratings and annotating errors, and providing feedback on their experience. Our\nfindings suggest that context-aware monolingual human evaluation achieves\ncomparable outcomes to human bilingual evaluations, and suggest the feasibility\nand potential of monolingual evaluation as an efficient approach to assessing\nMT.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-10T12:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.07686v1","title":"Measurements of Higgs boson production via gluon-gluon fusion and\n  vector-boson fusion using $H\\rightarrow WW^\\ast \\rightarrow \\ellν\\ellν$\n  decays in $pp$ collisions with the ATLAS detector and their effective field\n  theory interpretations","summary":"Higgs boson production cross-sections via gluon-gluon fusion and vector-boson\nfusion in proton-proton collisions are measured in the $H\\rightarrow WW^\\ast\n\\rightarrow \\ell\\nu\\ell\\nu$ decay channel. The Large Hadron Collider delivered\nproton-proton collisions at a centre-of-mass energy of $13\\,\\textrm{TeV}$\nbetween 2015 and 2018, which were recorded by the ATLAS detector, corresponding\nto an integrated luminosity of $140\\,\\textrm{fb}^{-1}$. The total\ncross-sections for Higgs boson production by gluon-gluon fusion and\nvector-boson fusion times the $H\\rightarrow WW^\\ast$ branching ratio are\nmeasured to be $12.4^{+1.3}_{-1.2}\\,\\textrm{pb}$ and\n$0.79^{+0.18}_{-0.16}\\,\\textrm{pb}$, respectively, in agreement with the\nStandard Model predictions. Higgs boson production is further characterised\nthrough measurements of Simplified Template Cross-Sections in a total of\nfifteen kinematic fiducial regions. A new scheme of kinematic fiducial regions\nhas been introduced to enhance the sensitivity to CP-violating effects in Higgs\nboson interactions. Both schemes are used to constrain CP-even and CP-odd\ndimension-six operators in the Standard Model effective field theory.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T12:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.07731v1","title":"Adaptive Robust Unscented Kalman Filter for Dynamic State Estimation of\n  Power System","summary":"Non-Gaussian noise and the uncertainty of noise distribution are the common\nfactors that reduce accuracy in dynamic state estimation of power systems (PS).\nIn addition, the optimal value of the free coefficients in the unscented Kalman\nfilter (UKF) based on information theoretic criteria is also an urgent problem.\nIn this paper, a robust adaptive UKF (AUKF) under generalized minimum mixture\nerror entropy with fiducial points (GMMEEF) over improve Snow Geese algorithm\n(ISGA) (ISGA-GMMEEF-AUKF) is proposed to overcome the above difficulties. The\nestimation process of the proposed algorithm is based on several key steps\nincluding augmented regression error model (AREM) construction, adaptive state\nestimation, and free coefficients optimization. Specifically, an AREM\nconsisting of state prediction and measurement errors is established at the\nfirst step. Then, GMMEEF-AUKF is developed by solving the optimization problem\nbased on GMMEEF, which uses a generalized Gaussian kernel combined with mixture\ncorrentropy to enhance the flexibility further and resolve the data problem\nwith complex attributes and update the noise covariance matrix according to the\nAREM framework. Finally, the ISGA is designed to automatically calculate the\noptimal value of coefficients such as the shape coefficients of the kernel in\nthe GMMEEF criterion, the coefficients selection sigma points in unscented\ntransform, and the update coefficient of the noise covariance matrices fit with\nthe PS model. Simulation results on the IEEE 14, 30, and 57-bus test systems in\ncomplex scenarios have confirmed that the proposed algorithm outperforms the\nMEEF-UKF and UKF by an average efficiency of 26% and 65%, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T13:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.07735v1","title":"$q$-Differential Operators for $q$-Spinor Variables","summary":"In this paper we introduce the $q$-differential operator for $q$-spinor\nvariables. We establish the $q$-spinor chain rule , the new $q$-differential\noperator, the $q$-Dirac differential operators and the $q$-complex spinor\nintegrals. We also define the $q$-spinor differential equation. The suggestions\nfor further work at the end of the paper.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-10T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.07740v1","title":"Zero-Shot Cross-Domain Code Search without Fine-Tuning","summary":"Code search aims to retrieve semantically relevant code snippets for natural\nlanguage queries. While pre-trained language models (PLMs) have shown\nremarkable performance in this task, they struggle in cross-domain scenarios,\noften requiring costly fine-tuning or facing performance drops in zero-shot\nsettings. RAPID, which generates synthetic data for model fine-tuning, is\ncurrently the only effective method for zero-shot cross-domain code search.\nDespite its effectiveness, RAPID demands substantial computational resources\nfor fine-tuning and needs to maintain specialized models for each domain,\nunderscoring the need for a zero-shot, fine-tuning-free approach for\ncross-domain code search.\n  The key to tackling zero-shot cross-domain code search lies in bridging the\ngaps among domains. In this work, we propose to break the query-code matching\nprocess of code search into two simpler tasks: query-comment matching and\ncode-code matching. Our empirical study reveals the strong complementarity\namong the three matching schemas in zero-shot cross-domain settings, i.e.,\nquery-code, query-comment, and code-code matching. Based on the findings, we\npropose CodeBridge, a zero-shot, fine-tuning-free approach for cross-domain\ncode search. Specifically, CodeBridge uses Large Language Models (LLMs) to\ngenerate comments and pseudo-code, then combines query-code, query-comment, and\ncode-code matching via PLM-based similarity scoring and sampling-based fusion.\nExperimental results show that our approach outperforms the state-of-the-art\nPLM-based code search approaches, i.e., CoCoSoDa and UniXcoder, by an average\nof 21.4% and 24.9% in MRR, respectively, across three datasets. Our approach\nalso yields results that are better than or comparable to those of the\nzero-shot cross-domain code search approach RAPID, which requires costly\nfine-tuning.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-10T13:36:37Z"}
{"aid":"http://arxiv.org/abs/2504.07766v1","title":"Realigning Incentives to Build Better Software: a Holistic Approach to\n  Vendor Accountability","summary":"In this paper, we ask the question of why the quality of commercial software,\nin terms of security and safety, does not measure up to that of other (durable)\nconsumer goods we have come to expect. We examine this question through the\nlens of incentives. We argue that the challenge around better quality software\nis due in no small part to a sequence of misaligned incentives, the most\ncritical of which being that the harm caused by software problems is by and\nlarge shouldered by consumers, not developers. This lack of liability means\nsoftware vendors have every incentive to rush low-quality software onto the\nmarket and no incentive to enhance quality control. Within this context, this\npaper outlines a holistic technical and policy framework we believe is needed\nto incentivize better and more secure software development. At the heart of the\nincentive realignment is the concept of software liability. This framework\ntouches on various components, including legal, technical, and financial, that\nare needed for software liability to work in practice; some currently exist,\nsome will need to be re-imagined or established. This is primarily a\nmarket-driven approach that emphasizes voluntary participation but highlights\nthe role appropriate regulation can play. We connect and contrast this with the\nEU legal environment and discuss what this framework means for open-source\nsoftware (OSS) development and emerging AI risks. Moreover, we present a\nCrowdStrike case study complete with a what-if analysis had our proposed\nframework been in effect. Our intention is very much to stimulate a robust\nconversation among both researchers and practitioners.","main_category":"cs.CR","categories":"cs.CR,cs.SE,econ.TH","published":"2025-04-10T14:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.07772v1","title":"Extremum Seeking Boundary Control for Euler-Bernoulli Beam PDEs","summary":"This paper presents the design and analysis of an extremum seeking (ES)\ncontroller for scalar static maps in the context of infinite-dimensional\ndynamics governed by the 1D Euler-Bernoulli (EB) beam Partial Differential\nEquation (PDE). The beam is actuated at one end (using position and moment\nactuators). The map's input is the displacement at the beam's uncontrolled end,\nwhich is subject to a sliding boundary condition. Notably, ES for this class of\nPDEs remains unexplored in the existing literature. To compensate for PDE\nactuation dynamics, we employ a boundary control law via a backstepping\ntransformation and averaging-based estimates for the gradient and Hessian of\nthe static map to be optimized. This compensation controller leverages a\nSchr\\\"odinger equation representation of the EB beam and adapts existing\nbackstepping designs to stabilize the beam. Using the semigroup and averaging\ntheory in infinite dimensions, we prove local exponential convergence to a\nsmall neighborhood of the unknown optimal point. Finally, simulations\nillustrate the effectiveness of the design in optimizing the unknown static\nmap.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T14:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07795v1","title":"Measurement of coincident photon-initiated processes in ultra-peripheral\n  Pb+Pb collisions with the ATLAS detector","summary":"The Lorentz-contracted electromagnetic fields of the ions in\nultra-relativistic heavy-ion collisions generate intense quasi-real photon\nfluxes. These lead to photon-induced interactions that are observed in\nultra-peripheral collisions (UPCs), such as vector meson and lepton-pair\nproduction. The high photon flux also enables the occurrence of multiple\nphoton-induced processes in a single collision. Presented is the first\nmeasurement of the coincident production of $\\gamma\\gamma \\rightarrow\n\\mu^{+}\\mu^{-}$ and $\\gamma+A\\rightarrow\\rho^{0}+A$ in UPC Pb+Pb collisions at\ncentre-of-mass energies of 5.02 TeV and 5.36 TeV with the ATLAS detector at the\nLarge Hadron Collider. The rate of the coincident process relative to the\nexclusive $\\gamma\\gamma \\rightarrow \\mu^{+}\\mu^{-}$ process is measured\ndifferentially in intervals of forward event activity, quantified by the Zero\nDegree Calorimeters. The relative rate, summed over forward event activity, for\nthe coincident $\\rho^{0}$ production is measured to be\n$(9.3\\,\\pm0.4\\,\\mathrm{(stat.)}\\,\\pm0.2\\,\\mathrm{(syst.)})\\times10^{-3}$.\nCorrelations between the dimuon kinematic properties, such as its mass, and the\ncoincident $\\rho^{0}$ meson production rate, are also presented. These\nmeasurements confirm the presence of multi photon-induced processes in UPC\ncollisions, and can provide new insight into the impact parameter dependence of\nphoton-induced vector meson production.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-10T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.07811v1","title":"The ISC Creator: Human-Centered Design of Learning Analytics Interactive\n  Indicator Specification Cards","summary":"Emerging research on human-centered learning analytics (HCLA) has\ndemonstrated the importance of involving diverse stakeholders in co-designing\nlearning analytics (LA) systems. However, there is still a demand for effective\nand efficient methods to co-design LA dashboards and indicators. Indicator\nSpecification Cards (ISCs) have been introduced recently to facilitate the\nsystematic co-design of indicators by different LA stakeholders. In this paper,\nwe strive to enhance the user experience and usefulness of the ISC-based\nindicator design process. Towards this end, we present the systematic design,\nimplementation, and evaluation details of the ISC Creator, an interactive LA\ntool that allows low-cost and flexible design of LA indicators. Our findings\ndemonstrate the importance of carefully considered interactivity and\nrecommendations for orienting and supporting non-expert LA stakeholders to\ndesign custom LA indicators.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-10T14:49:47Z"}
{"aid":"http://arxiv.org/abs/2504.07824v1","title":"Go Figure: Transparency in neuroscience images preserves context and\n  clarifies interpretation","summary":"Visualizations are vital for communicating scientific results. Historically,\nneuroimaging figures have only depicted regions that surpass a given\nstatistical threshold. This practice substantially biases interpretation of the\nresults and subsequent meta-analyses, particularly towards non-reproducibility.\nHere we advocate for a \"transparent thresholding\" approach that not only\nhighlights statistically significant regions but also includes subthreshold\nlocations, which provide key experimental context. This balances the dual needs\nof distilling modeling results and enabling informed interpretations for modern\nneuroimaging. We present four examples that demonstrate the many benefits of\ntransparent thresholding, including: removing ambiguity, decreasing\nhypersensitivity to non-physiological features, catching potential artifacts,\nimproving cross-study comparisons, reducing non-reproducibility biases, and\nclarifying interpretations. We also demonstrate the many software packages that\nimplement transparent thresholding, several of which were added or streamlined\nrecently as part of this work. A point-counterpoint discussion addresses issues\nwith thresholding raised in real conversations with researchers in the field.\nWe hope that by showing how transparent thresholding can drastically improve\nthe interpretation (and reproducibility) of neuroimaging findings, more\nresearchers will adopt this method.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-10T15:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.07826v1","title":"MuSaRoNews: A Multidomain, Multimodal Satire Dataset from Romanian News\n  Articles","summary":"Satire and fake news can both contribute to the spread of false information,\neven though both have different purposes (one if for amusement, the other is to\nmisinform). However, it is not enough to rely purely on text to detect the\nincongruity between the surface meaning and the actual meaning of the news\narticles, and, often, other sources of information (e.g., visual) provide an\nimportant clue for satire detection. This work introduces a multimodal corpus\nfor satire detection in Romanian news articles named MuSaRoNews. Specifically,\nwe gathered 117,834 public news articles from real and satirical news sources,\ncomposing the first multimodal corpus for satire detection in the Romanian\nlanguage. We conducted experiments and showed that the use of both modalities\nimproves performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T15:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.07830v1","title":"MOSAIC: Modeling Social AI for Content Dissemination and Regulation in\n  Multi-Agent Simulations","summary":"We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SI","published":"2025-04-10T15:06:54Z"}
{"aid":"http://arxiv.org/abs/2504.07834v1","title":"Inverse Design of Block Polymer Materials with Desired Nanoscale\n  Structure and Macroscale Properties","summary":"The rational design of novel polymers with tailored material properties has\nbeen a long-standing challenge in the field due to the large number of possible\npolymer design variables. To accelerate this design process, there is a\ncritical need to develop novel tools to aid in the inverse design process and\nefficiently explore the high-dimensional polymer design space. Optimizing\nmacroscale material properties for polymeric systems is difficult as properties\nare dictated by features on a multitude of length scales, ranging from the\nchosen monomer chemistries to the chain level design to larger-scale domain\nstructures. In this work, we present an efficient high-throughput in-silico\nbased framework to effectively design high-performance polymers with desired\nmulti-scale nanostructure and macroscale properties, which we call RAPSIDY 2.0\n- Rapid Analysis of Polymer Structure and Inverse Design strategY 2.0. This new\nversion of RAPSIDY builds upon our previous work, RAPSIDY 1.0, which focused\npurely on identifying polymer designs that stabilized a desired nanoscale\nmorphology. In RAPSIDY 2.0 we use a combination of molecular dynamics\nsimulations and Bayesian optimization driven active learning to optimally query\nhigh-dimensional polymer design spaces and propose promising design candidates\nthat simultaneously stabilize a selected nanoscale morphology and exhibit\ndesired macroscale material properties. We utilize MD simulations with polymer\nchains preplaced into selected nanoscale morphologies and perform virtual\nexperiments to determine the stability of the chosen polymer design within the\ntarget morphology and calculate the desired macroscale material properties\n(e.g., thermal conductivity). Our methodology directly addresses the unique\nchallenge associated with copolymers, whose macroscale properties are a\nfunction of both their chain design and mesoscale morphology, which are\ncoupled.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.07836v1","title":"AerialVG: A Challenging Benchmark for Aerial Visual Grounding by\n  Exploring Positional Relations","summary":"Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T15:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.07840v1","title":"Understanding Learner-LLM Chatbot Interactions and the Impact of\n  Prompting Guidelines","summary":"Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CL","published":"2025-04-10T15:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.07860v1","title":"Conformally weighted Einstein manifolds: the uniqueness problem","summary":"We discuss smooth metric measure spaces admitting two weighted Einstein\nrepresentatives of the same weighted conformal class. First, we describe the\nlocal geometries of such manifolds in terms of certain Einstein and\nquasi-Einstein warped products. Secondly, a global classification result is\nobtained when one of the underlying metrics is complete, showing that either it\nis a weighted space form, a special Einstein warped product, or a specific\nfamily of quasi-Einstein warped products. As a consequence, it must be a\nweighted sphere in the compact case.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.07862v1","title":"Resummation of Universal Tails in Gravitational Waveforms","summary":"We present a formula for the universal anomalous scaling of the multipole\nmoments of a generic gravitating source in classical general relativity. We\nderive this formula in two independent ways using effective field theory\nmethods. First, we use the absorption of low frequency gravitational waves by a\nblack hole to identify the total multipole scaling dimension as the\nrenormalized angular momentum of black hole perturbation theory. More\ngenerally, we show that the anomalous dimension is determined by phase shifts\nof gravitational waves elastically scattering off generic source multipole\nmoments, which reproduces the renormalized angular momentum in the particular\ncase of black holes. The effective field theory approach thus clarifies the\nrole of the renormalized angular momentum in the multipole expansion. The\nuniversality of the point-particle effective description of compact gravitating\nsystems further allows us to extract the universal part of the anomalous\ndimension, which is the same for any object, including black holes, neutron\nstars, and binary systems. As an application, we propose a novel resummation of\nthe universal short-distance logarithms (``tails'') in the gravitational\nwaveform of binary systems, which may improve the modeling of signals from\ncurrent and future gravitational wave experiments.","main_category":"hep-th","categories":"hep-th,astro-ph.HE,gr-qc,hep-ph","published":"2025-04-10T15:39:05Z"}
{"aid":"http://arxiv.org/abs/2504.07877v1","title":"Gauge and parametrization dependence of Quantum Einstein Gravity within\n  the Proper Time flow","summary":"Proper time functional flow equations have garnered significant attention in\nrecent years, as they are particularly suitable in analyzing non-perturbative\ncontexts. By resorting to this flow, we investigate the regulator and gauge\ndependence in quantum Einstein gravity within the asymptotic safety framework,\nconsidering various regularization schemes. Our findings indicate that some\ndetails of the regulator have minor influence on the critical properties of the\ntheory. In contrast, the selection between linear and exponential\nparametrizations appears to have a more substantial impact on the scaling\nbehavior of the renormalized flow near the non-Gaussian fixed point.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T15:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.07885v1","title":"Self-Evaluated Expertise in experimental physics: a measure of students'\n  physics self-recognition","summary":"We introduce and theoretically justify a new measure of the self-recognition\ncomponent of student physics identity called Self-Evaluated Expertise (SEE).\nThis measure is constructed such that it can be extracted from existing\nresponses to the E-CLASS. In this work, we compare scores from SEE with the\ntraditional measure calculated from the E-CLASS, which probes student views\nabout experimental physics, to show that the SEE score is a quantitatively\ndifferent measure. Consequently, we show that student self-recognition\ndecreases from pre-instruction administration of the E-CLASS to the\npost-instruction administration when averaged across data from 494 courses\nhaving taken place between 2016--2019.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-10T15:59:27Z"}
{"aid":"http://arxiv.org/abs/2504.07908v1","title":"Majorization for probability distributions, column stochastic matrices\n  and their linear preservers","summary":"In this paper we investigate majorization for probability distributions and\ncolumn stochastic matrices. We show that majorizations in general can be\nreduced to these sets. We characterize linear operators that preserve\nmajorization for probability distributions, and show their equivalence to\noperators preserving vector majorization. Our main result provides a complete\ncharacterization of linear preservers of strong majorization for column\nstochastic matrices, revealing a richer structure of preservers, than in the\nstandard setting. As a prerequisite to this characterization, we solve the\nproblem of characterizing linear preservers of majorization for zero-sum\nvectors, which yields a new structural insight into the classical results of\nAndo and of Li and Poon.","main_category":"math.RA","categories":"math.RA","published":"2025-04-10T16:29:54Z"}
{"aid":"http://arxiv.org/abs/2504.07914v1","title":"Scaling and Predictability in Surface Quasi-Geostrophic Turbulence","summary":"Turbulent flows are strongly chaotic and unpredictable, with a Lyapunov\nexponent that increases with the Reynolds number. Here, we study the chaoticity\nof the Surface Quasi-geostrophic system, a two-dimensional model for\ngeophysical flows that displays a direct cascade similar to that of\nthree-dimensional turbulence. Using high-resolution direct numerical\nsimulations, we investigate the dependence of the Lyapunov exponent on the\nReynolds number and find an anomalous scaling exponent larger than the one\npredicted by dimensional arguments. We also study the finite-time fluctuation\nof the Lyapunov exponent by computing the Cram\\'er function associated with its\nprobability distribution. We find that the Cram\\'er function attains a\nself-similar form at large Re.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-10T17:23:13Z"}
{"aid":"http://arxiv.org/abs/2504.07922v1","title":"Exploring Structure Constants in Planar $\\mathcal{N} = 4$ SYM: From\n  Small Spin to Strong Coupling","summary":"We study the structure constants of two conformal primary operators and one\nspinning operator in planar $\\mathcal{N} = 4$ Super-Yang-Mills theory using the\nhexagon formalism. By analytically continuing in the spin, we derive a formula\nfor computing these structure constants at any coupling in the small-spin\nlimit, up to a normalization factor. This formula allows us to explore their\nanalytical properties at strong coupling. In this regime, using classical\nstring calculations and a suitable ansatz, we extend our analysis to\nfinite-spin operators, verifying recent two-loop results for structure\nconstants in string theory and generalizing them to operators with arbitrary\nR-charges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.07941v1","title":"Quantum error correction via multi-particle discrete-time quantum walk","summary":"We propose a scheme of quantum error correction that employs a multi-particle\nquantum walk defined on nested squares, each hosting a single particle. In this\nmodel, each particle moves within its own distinct square through iterations of\nthree discrete-time steps. First, a particle updates its two-level internal\n{\\it coin} state. Next, it either moves to an adjacent vertex or stays put,\ndepending on the outcome. Finally, it interacts with another particle if these\nparticles arrive at the nearest-neighbor vertices of the two adjacent squares,\nacquiring a phase factor of $-1$. Because a single particle represents a\nthree-qubit state through its position and coin state, Shor's nine-qubit code\nis implemented using only three particles, with two additional particles for\nsyndrome measurement. Furthermore, by exploiting gauge symmetry, our scheme\nachieves redundant encoding, error correction, and arbitrary operations on the\nencoded information using only nearest-neighbor interactions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T17:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.07942v1","title":"MARS: a Multimodal Alignment and Ranking System for Few-Shot\n  Segmentation","summary":"Current Few Shot Segmentation literature lacks a mask selection method that\ngoes beyond visual similarity between the query and example images, leading to\nsuboptimal predictions. We present MARS, a plug-and-play ranking system that\nleverages multimodal cues to filter and merge mask proposals robustly. Starting\nfrom a set of mask predictions for a single query image, we score, filter, and\nmerge them to improve results. Proposals are evaluated using multimodal scores\ncomputed at local and global levels. Extensive experiments on COCO-20i,\nPascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring\ncomponents is crucial for robust ranking, validating our contribution. As MARS\ncan be effortlessly integrated with various mask proposal systems, we deploy it\nacross a wide range of top-performer methods and achieve new state-of-the-art\nresults on multiple existing benchmarks. Code will be available upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:53:23Z"}
{"aid":"http://arxiv.org/abs/2504.07949v1","title":"InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars\n  with Deformable Gaussians","summary":"With the rising interest from the community in digital avatars coupled with\nthe importance of expressions and gestures in communication, modeling natural\navatar behavior remains an important challenge across many industries such as\nteleconferencing, gaming, and AR/VR. Human hands are the primary tool for\ninteracting with the environment and essential for realistic human behavior\nmodeling, yet existing 3D hand and head avatar models often overlook the\ncrucial aspect of hand-body interactions, such as between hand and face. We\npresent InteracttAvatar, the first model to faithfully capture the\nphotorealistic appearance of dynamic hand and non-rigid hand-face interactions.\nOur novel Dynamic Gaussian Hand model, combining template model and 3D Gaussian\nSplatting as well as a dynamic refinement module, captures pose-dependent\nchange, e.g. the fine wrinkles and complex shadows that occur during\narticulation. Importantly, our hand-face interaction module models the subtle\ngeometry and appearance dynamics that underlie common gestures. Through\nexperiments of novel view synthesis, self reenactment and cross-identity\nreenactment, we demonstrate that InteracttAvatar can reconstruct hand and\nhand-face interactions from monocular or multiview videos with high-fidelity\ndetails and be animated with novel poses.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.09892v1","title":"Vermilion: A Traffic-Aware Reconfigurable Optical Interconnect with\n  Formal Throughput Guarantees","summary":"The increasing gap between datacenter traffic volume and the capacity of\nelectrical switches has driven the development of reconfigurable network\ndesigns utilizing optical circuit switching. Recent advancements, particularly\nthose featuring periodic fixed-duration reconfigurations, have achieved\npractical end-to-end delays of just a few microseconds. However, current\ndesigns rely on multi-hop routing to enhance utilization, which can lead to a\nsignificant reduction in worst-case throughput and added overhead from\ncongestion control and routing complexity. These factors pose significant\noperational challenges for the large-scale deployment of these technologies.\n  We present Vermilion, a reconfigurable optical interconnect that breaks the\nthroughput barrier of existing periodic reconfigurable networks, without the\nneed for multi-hop routing -- thus eliminating congestion control and\nsimplifying routing to direct communication. Vermilion adopts a traffic-aware\napproach while retaining the simplicity of periodic fixed-duration\nreconfigurations, similar to RotorNet. We formally establish throughput bounds\nfor Vermilion, demonstrating that it achieves at least $33\\%$ more throughput\nin the worst-case compared to existing designs. The key innovation of Vermilion\nis its short traffic-aware periodic schedule, derived using a matrix rounding\ntechnique. This schedule is then combined with a traffic-oblivious periodic\nschedule to efficiently manage any residual traffic. Our evaluation results\nsupport our theoretical findings, revealing significant performance gains for\ndatacenter workloads.","main_category":"cs.NI","categories":"cs.NI,cs.DS","published":"2025-04-14T05:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.09893v1","title":"LangPert: Detecting and Handling Task-level Perturbations for Robust\n  Object Rearrangement","summary":"Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T05:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.09936v1","title":"KeepKV: Eliminating Output Perturbation in KV Cache Compression for\n  Efficient LLMs Inference","summary":"Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-14T06:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.09942v1","title":"Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting\n  Loewner-State Model for EM Simulation of Multiport Systems","summary":"This paper employs a fully adaptive and semi-adaptive frequency sweep\nalgorithm using the Loewner matrix-based state model for the electromagnetic\nsimulation. The proposed algorithms use two Loewner matrix models with\ndifferent or the same orders with small frequency perturbation for adaptive\nfrequency selection. The error between the two models is calculated in each\niteration, and the next frequency points are selected to minimize maximum\nerror. With the help of memory, the algorithm terminates when the error between\nthe model and the simulation result is reached within the specified error\ntolerance. In the fully adaptive frequency sweep algorithm, the method starts\nwith the minimum and maximum frequency of simulation. In the semi-adaptive\nalgorithm, a novel approach has been proposed to determine the initial number\nof frequency points necessary for system interpolation based on the electrical\nsize of the structure. The proposed algorithms have been compared with the\nStoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for\nelectromagnetic simulation. Four examples are presented using MATLAB R2024b.\nThe results show that the proposed methods offer better performance in terms of\nspeed, accuracy and the requirement of the minimum number of frequency samples.\nThe proposed method shows remarkable consistency with full-wave simulation\ndata, and the algorithm can be effectively applicable to electromagnetic\nsimulations.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,G.1.1","published":"2025-04-14T07:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.09957v1","title":"Programmable time-frequency mode encoded quantum state generator for\n  silicon-on-insulator platform","summary":"We propose a method for the programmable generation of time-frequency mode\n(TFM) encoded quantum states of light on the silicon-on-insulator (SOI)\nplatform. The state generator consists of an N-tap finite impulse response\nfilter and a Mach-Zehnder interferometer (MZI)-based coupled-ring resonator.\nThrough numerical simulations, its capability of producing TFM-encoded\nmaximally entangled states in two, three, and four dimensions is theoretically\ndemonstrated, with fidelities of 0.950, 0.954, and 0.971, respectively.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T07:54:17Z"}
{"aid":"http://arxiv.org/abs/2504.09968v1","title":"Some memos on Stable Symplectic Structured Space","summary":"In these memos, we define a pregeometry $\\mathcal{T}_{\\mathbb{S}} ^{alg}$ and\na geometry $\\mathcal{G}_{\\mathbb{S}} ^{alg}$ which integrate symplectic\nmanifolds with $E_{\\infty}$-ring sheaves, enabling the construction of\n$\\mathcal{G}_{\\mathbb{S}} ^{alg}$-schemes as structured $\\infty$-topoi. Our\nframework and results establish a profound connection between algebraic\ninvariants and homological properties, opening new pathways for exploring\nsymplectic phenomena through the lens of higher category theory and derived\ngeometry.","main_category":"math.AG","categories":"math.AG,math.SG","published":"2025-04-14T08:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.09982v1","title":"The gravitational index of a small black ring","summary":"Certain supersymmetric elementary string states with angular momentum can be\nviewed as small black rings in a five-dimensional string theory. These black\nrings have zero area event horizon. The 4D-5D connection relates these small\nrings to small black holes without angular momentum in one less dimension.\nRecent works have proposed saddle solutions that compute the supersymmetric\nindex for small black holes using gravitational path integral. In this paper,\nwe propose an analogous saddle solution for a five-dimensional small black\nring. The dominant contribution comes from a black ring saddle that rotates in\nboth independent planes in five dimensions and has a finite area event horizon.\nWe also write the saddle solution as a three-center Bena-Warner solution.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T08:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.10008v1","title":"Time for Timed Monitorability","summary":"Monitoring is an important part of the verification toolbox, in particular in\nsituations where exhaustive verification using, e.g., model-checking, is\ninfeasible. The goal of online monitoring is to determine the satisfaction or\nviolation of a specification during runtime, i.e., based on finite execution\nprefixes. However, not every specification is amenable to monitoring, e.g.,\nproperties for which no finite execution can witness satisfaction or violation.\nMonitorability is the question whether a given specification is amenable to\nmonitoring, and has been extensively studied in discrete time.\n  Here, we study, for the first time, the monitorability problem for real-time\nspecifications. For specifications given by deterministic Timed Muller\nAutomata, we prove decidability while we show that the problem is undecidable\nfor specifications given by nondeterministic Timed B\\\"uchi automata.\nFurthermore, we refine monitorability to also determine bounds on the number of\nevents as well as the time that must pass before monitoring the property may\nyield an informative verdict. We prove that for deterministic Timed Muller\nautomata, such bounds can be effectively computed. In contrast we show that for\nnondeterministic Timed B\\\"uchi automata such bounds are not computable.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-14T09:12:58Z"}
{"aid":"http://arxiv.org/abs/2504.10013v1","title":"Training LLMs on HPC Systems: Best Practices from the OpenGPT-X Project","summary":"The training of large language models (LLMs) requires substantial\ncomputational resources, complex software stacks, and carefully designed\nworkflows to achieve scalability and efficiency. This report presents best\npractices and insights gained from the OpenGPT-X project, a German initiative\nfocused on developing open, multilingual LLMs optimized for European languages.\nWe detail the use of high-performance computing (HPC) systems, primarily JUWELS\nBooster at JSC, for training Teuken-7B, a 7-billion-parameter transformer\nmodel. The report covers system architecture, training infrastructure, software\nchoices, profiling and benchmarking tools, as well as engineering and\noperational challenges.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T09:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.10022v1","title":"Parameters estimation of a Threshold Chan-Karolyi-Longstaff-Sanders\n  process from continuous and discrete observations","summary":"We consider a continuous time process that is self-exciting and ergodic,\ncalled threshold Chan-Karolyi-Longstaff-Sanders (CKLS) process. This process is\na generalization of various models in econometrics, such as Vasicek model,\nCox-Ingersoll-Ross, and Black-Scholes, allowing for the presence of several\nthresholds which determine changes in the dynamics. We study the asymptotic\nbehavior of maximum-likelihood and quasi-maximum-likelihood estimators of the\ndrift parameters in the case of continuous time and discrete time observations.\nWe show that for high frequency observations and infinite horizon the\nestimators satisfy the same asymptotic normality property as in the case of\ncontinuous time observations. We also discuss diffusion coefficient estimation.\nFinally, we apply our estimators to simulated and real data to motivate\nconsidering (multiple) thresholds.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-14T09:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.10025v1","title":"Progressive Transfer Learning for Multi-Pass Fundus Image Restoration","summary":"Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-14T09:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.10077v1","title":"Towards Quantifying Commonsense Reasoning with Mechanistic Insights","summary":"Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T10:21:59Z"}
{"aid":"http://arxiv.org/abs/2504.10134v1","title":"Let's Talk About It: Making Scientific Computational Reproducibility\n  Easy","summary":"Computational reproducibility of scientific results, that is, the execution\nof a computational experiment (e.g., a script) using its original settings\n(data, code, etc.), should always be possible. However, reproducibility has\nbecome a significant challenge, as researchers often face difficulties in\naccurately replicating experiments due to inconsistencies in documentation,\nsetup configurations, and missing data. This lack of reproducibility may\nundermine the credibility of scientific results.\n  To address this issue, we propose a conversational, text-based tool that\nallows researchers to easily reproduce computational experiments (theirs or\nfrom others) and package them in a single file that can be re-executed with\njust a double click on any computer, requiring the installation of a single\nwidely-used software. Researchers interact with the platform in natural\nlanguage, which our tool processes to automatically create a computational\nenvironment able to execute the provided experiment/code.\n  We conducted two studies to evaluate our proposal. In the first study, we\ngathered qualitative data by executing 18 experiments from the literature.\nAlthough in some cases it was not possible to execute the experiment, in most\ninstances, it was necessary to have little or even no interaction for the tool\nto reproduce the results.\n  We also conducted a user study comparing our tool with an enterprise-level\none. During this study, we measured the usability of both tools using the\nSystem Usability Scale (SUS) and participants' workload using the NASA Task\nLoad Index (TLX). The results show a statistically significant difference\nbetween both tools in favor of our proposal, demonstrating that the usability\nand workload of our tool are superior to the current state of the art.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.10167v1","title":"C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination\n  Evaluation","summary":"Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.10180v1","title":"ChartOptimiser: Task-driven Optimisation of Chart Designs","summary":"Effective chart design is essential for satisfying viewers' information\nneeds, such as retrieving values from a chart or comparing two values. However,\ncreating effective charts is challenging and time-consuming due to the large\ndesign space and the inter-dependencies between individual design parameters.\nTo address this challenge, we propose ChartOptimiser -- a Bayesian approach for\ntask-driven optimisation of charts, such as bar charts. At the core of\nChartOptimiser is a novel objective function to automatically optimise an\neight-dimensional design space combining four perceptual metrics: visual\nsaliency, text legibility, colour preference, and white space ratio. Through\nempirical evaluation on 12 bar charts and four common analytical tasks --\nfinding the extreme value, retrieving a value, comparing two values, and\ncomputing a derived value -- we show that ChartOptimiser outperforms existing\ndesign baselines concerning task-solving ease, visual aesthetics, and chart\nclarity. We also discuss two practical applications of ChartOptimiser:\ngenerating charts for accessibility and content localisation. Taken together,\nChartOptimiser opens up an exciting new research direction in automated chart\ndesign where charts are optimised for users' information needs, preferences,\nand contexts.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.10181v1","title":"A New Paradigm in IBR Modeling for Power Flow and Short Circuit Analysis","summary":"The fault characteristics of inverter-based resources (IBRs) are different\nfrom conventional synchronous generators. The fault response of IBRs is\nnon-linear due to saturation states and mainly determined by fault ride through\n(FRT) strategies of the associated voltage source converter (VSC). This results\nin prohibitively large solution times for power flows considering these short\ncircuit characteristics, especially when the power system states change fast\ndue to uncertainty in IBR generations. To overcome this, a phasor-domain steady\nstate (SS) short circuit (SC) solver for IBR dominated power systems is\nproposed in this paper, and subsequently the developed IBR models are\nincorporated with a novel Jacobian-based Power Flow (PF) solver. In this\nmultiphase PF solver, any power system components can be modeled by considering\ntheir original non-linear or linear mathematical representations. Moreover, two\nnovel FRT strategies are proposed to fully utilize the converter capacity and\nto comply with IEEE-2800 2022 std and German grid code. The results are\ncompared with the Electromagnetic Transient (EMT) simulation on the IEEE 34\ntest network and the 120 kV EPRI benchmark system. The developed IBR sequence\ndomain PF model demonstrates more accurate behavior compared to the classical\nIBR generator model. The error in calculating the short circuit current with\nthe proposed SC solver is less than 3%, while achieving significant speed\nimprovements of three order of magnitudes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T12:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.10194v1","title":"Black Hole Singularities from Holographic Complexity","summary":"Using a second law of complexity, we prove a black hole singularity theorem.\nBy introducing the notion of trapped extremal surfaces, we show that their\nexistence implies null geodesic incompleteness inside globally hyperbolic black\nholes. We also demonstrate that the vanishing of the growth rate of the volume\nof extremal surfaces provides a sharp diagnostic of the black hole singularity.\nIn static, uncharged, spherically symmetric spacetimes, this corresponds to the\ngrowth rate of spacelike extremal surfaces going to zero at the singularity. In\ncharged or rotating spacetimes, such as the Reissner-Nordstr\\\"om and Kerr black\nholes, we identify novel timelike extremal surfaces that exhibit the same\nbehavior at the timelike singularity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T12:56:04Z"}
{"aid":"http://arxiv.org/abs/2504.10208v1","title":"From Prompting to Alignment: A Generative Framework for Query\n  Recommendation","summary":"In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-14T13:21:29Z"}
{"aid":"http://arxiv.org/abs/2504.10215v1","title":"Public Health Insurance of Children and Maternal Labor Market Outcomes","summary":"This paper exploits variation resulting from a series of federal and state\nMedicaid expansions between 1977 and 2017 to estimate the effects of children's\nincreased access to public health insurance on the labor market outcomes of\ntheir mothers. The results imply that the extended Medicaid eligibility of\nchildren leads to positive labor supply responses at the extensive and\nintensive margins of single mothers and to negative labor supply responses at\nthe extensive margin of married mothers. The analysis of mechanisms suggests\nthat extended children's Medicaid eligibility positively affects take-up of\nMedicaid and health of children.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T13:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.10219v1","title":"Inverse design of multiresonance filters via quasi-normal mode theory","summary":"We present a practical methodology for inverse design of compact\nhigh-order/multiresonance filters in linear passive 2-port wave-scattering\nsystems, targeting any desired transmission spectrum (such as standard\npass/stop-band filters). Our formulation allows for both large-scale topology\noptimization and few-variable parametrized-geometry optimization. It is an\nextension of a quasi-normal mode theory and analytical filter-design criteria\n(on the system resonances and background response) derived in our previous\nwork. Our new optimization-oriented formulation relies solely on a scattering\nsolver and imposes these design criteria as equality constraints with easily\ncalculated (via the adjoint method) derivatives, so that our algorithm is\nnumerically tractable, robust, and well-suited for large-scale inverse design.\nWe demonstrate its effectiveness by designing 3rd- and 4th-order elliptic and\nChebyshev filters for photonic metasurfaces, multilayer films, and electrical\nLC-ladder circuits.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.optics","published":"2025-04-14T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.10269v1","title":"Multiple solutions to asymptotically linear problems driven by\n  superposition operators","summary":"In this paper, we investigate the existence and multiplicity of weak\nsolutions to problems involving a superposition operator of the type\n$$\\int_{[0, 1]}(- \\Delta)^s u d \\mu(s),$$ for a signed measure $\\mu$ on the\ninterval of fractional exponents $[0,1]$, when the nonlinearity is subcritical\nand asymptotically linear at infinity; thus, we deal with a perturbation of the\neigenvalue problem for the superposition operator. We use variational tools,\nextending to this setting well-known results for the classical and the\nfractional Laplace operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.10299v1","title":"IRR-Based AS Type of Relationship Inference","summary":"The Internet comprises tens of thousands of autonomous systems (ASes) whose\ncommercial relationships are not publicly announced. The classification of the\nType of Relationship (ToR) between ASes has been extensively studied over the\npast two decades due to its relevance in network routing management and\nsecurity.\n  This paper presents a new approach to ToR classification, leveraging publicly\navailable BGP data from the Internet Routing Registry (IRR). We show how the\nIRR can be mined and the results refined to achieve a large and accurate ToR\ndatabase. Using a ground truth database with hundreds of entries we show that\nwe indeed manage to obtain high accuracy. About two-thirds of our ToRs are new,\nnamely, they were not obtained by previous works, which means that we enrich\nour ToR knowledge with links that are otherwise missed.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T15:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.10345v1","title":"AraOS: Analyzing the Impact of Virtual Memory Management on Vector Unit\n  Performance","summary":"Vector processor architectures offer an efficient solution for accelerating\ndata-parallel workloads (e.g., ML, AI), reducing instruction count, and\nenhancing processing efficiency. This is evidenced by the increasing adoption\nof vector ISAs, such as Arm's SVE/SVE2 and RISC-V's RVV, not only in\nhigh-performance computers but also in embedded systems. The open-source nature\nof RVV has particularly encouraged the development of numerous vector processor\ndesigns across industry and academia. However, despite the growing number of\nopen-source RVV processors, there is a lack of published data on their\nperformance in a complex application environment hosted by a full-fledged\noperating system (Linux). In this work, we add OS support to the open-source\nbare-metal Ara2 vector processor (AraOS) by sharing the MMU of CVA6, the scalar\ncore used for instruction dispatch to Ara2, and integrate AraOS into the\nopen-source Cheshire SoC platform. We evaluate the performance overhead of\nvirtual-to-physical address translation by benchmarking matrix multiplication\nkernels across several problem sizes and translation lookaside buffer (TLB)\nconfigurations in CVA6's shared MMU, providing insights into vector performance\nin a full-system environment with virtual memory. With at least 16 TLB entries,\nthe virtual memory overhead remains below 3.5%. Finally, we benchmark a 2-lane\nAraOS instance with the open-source RiVEC benchmark suite for RVV\narchitectures, with peak average speedups of 3.2x against scalar-only\nexecution.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T15:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.10384v1","title":"A 10.8mW Mixed-Signal Simulated Bifurcation Ising Solver using SRAM\n  Compute-In-Memory with 0.6us Time-to-Solution","summary":"Combinatorial optimization problems are funda- mental for various fields\nranging from finance to wireless net- works. This work presents a simulated\nbifurcation (SB) Ising solver in CMOS for NP-hard optimization problems. Analog\ndomain computing led to a superior implementation of this algorithm as inherent\nand injected noise is required in SB Ising solvers. The architecture novelties\ninclude the use of SRAM compute-in-memory (CIM) to accelerate bifurcation as\nwell as the generation and injection of optimal decaying noise in the analog\ndomain. We propose a novel 10-T SRAM cell capable of performing ternary\nmultiplication. When measured with 60- node, 50% density, random, binary MAXCUT\ngraphs, this all- to-all connected Ising solver reliably achieves above 93% of\nthe ground state solution in 0.6us with 10.8mW average power in TSMC 180nm\nCMOS. Our chip achieves an order of magnitude improvement in time-to-solution\nand power compared to previously proposed Ising solvers in CMOS and other\nplatforms.","main_category":"eess.SY","categories":"eess.SY,cs.CL,cs.SY","published":"2025-04-14T16:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.10434v1","title":"Anchor Token Matching: Implicit Structure Locking for Training-free AR\n  Image Editing","summary":"Text-to-image generation has seen groundbreaking advancements with diffusion\nmodels, enabling high-fidelity synthesis and precise image editing through\ncross-attention manipulation. Recently, autoregressive (AR) models have\nre-emerged as powerful alternatives, leveraging next-token generation to match\ndiffusion models. However, existing editing techniques designed for diffusion\nmodels fail to translate directly to AR models due to fundamental differences\nin structural control. Specifically, AR models suffer from spatial poverty of\nattention maps and sequential accumulation of structural errors during image\nediting, which disrupt object layouts and global consistency. In this work, we\nintroduce Implicit Structure Locking (ISLock), the first training-free editing\nstrategy for AR visual models. Rather than relying on explicit attention\nmanipulation or fine-tuning, ISLock preserves structural blueprints by\ndynamically aligning self-attention patterns with reference images through the\nAnchor Token Matching (ATM) protocol. By implicitly enforcing structural\nconsistency in latent space, our method ISLock enables structure-aware editing\nwhile maintaining generative autonomy. Extensive experiments demonstrate that\nISLock achieves high-quality, structure-consistent edits without additional\ntraining and is superior or comparable to conventional editing techniques. Our\nfindings pioneer the way for efficient and flexible AR-based image editing,\nfurther bridging the performance gap between diffusion and autoregressive\ngenerative models. The code will be publicly available at\nhttps://github.com/hutaiHang/ATM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.10440v1","title":"HybridCollab: Unifying In-Person and Remote Collaboration for\n  Cardiovascular Surgical Planning in Mobile Augmented Reality","summary":"Surgical planning for congenital heart disease traditionally relies on\ncollaborative group examinations of a patient's 3D-printed heart model, a\nprocess that lacks flexibility and accessibility. While mobile augmented\nreality (AR) offers a promising alternative with its portability and familiar\ninteraction gestures, existing solutions limit collaboration to users in the\nsame physical space. We developed HybridCollab, the first iOS AR application\nthat introduces a novel paradigm that enables both in-person and remote medical\nteams to interact with a shared AR heart model in a single surgical planning\nsession. For example, a team of two doctors in one hospital room can\ncollaborate in real time with another team in a different hospital.Our approach\nis the first to leverage Apple's GameKit service for surgical planning,\nensuring an identical collaborative experience for all participants, regardless\nof location. Additionally, co-located users can interact with the same anchored\nheart model in their shared physical space. By bridging the gap between remote\nand in-person collaboration across medical teams, HybridCollab has the\npotential for significant real-world impact, streamlining communication and\nenhancing the effectiveness of surgical planning. Watch the demo:\nhttps://youtu.be/hElqJYDuvLM.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T17:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10446v1","title":"Evolution equations on co-evolving graphs: long-time behaviour and the\n  graph continuity equation","summary":"We focus on evolution equations on co-evolving, infinite, graphs and\nestablish a rigorous link with a class of nonlinear continuity equations, whose\nvector fields depend on the graphs considered. More precisely, weak solutions\nof the so-called graph-continuity equation are shown to be the push-forward of\ntheir initial datum through the flow map solving the associated\ncharacteristics' equation, which depends on the co-evolving graph considered.\nThis connection can be used to prove contractions in a suitable distance,\nalthough the flow on the graphs requires a too limiting assumption on the\noverall flux. Therefore, we consider upwinding dynamics on graphs with\npointwise and monotonic velocity and prove long-time convergence of the\nsolutions towards the uniform mass distribution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T17:36:55Z"}
{"aid":"http://arxiv.org/abs/2504.10448v1","title":"A High-Precision, Fast, Robust, and Cost-Effective Muon Detector Concept\n  for the FCC-ee","summary":"We propose a high-precision, fast, robust and cost-effective muon detector\nconcept for an FCC-ee experiment. This design combines precision drift tubes\nwith fast plastic scintillator strips to enable both spatial and timing\nmeasurements. The drift tubes deliver two-dimensional position measurements\nperpendicular to the tubes with a resolution around 100~$\\mu$m. Meanwhile, the\nscintillator strips, read out with the wavelength-shifting fibers and silicon\nphotomultipliers, provide fast timing information with a precision of 200~ps or\nbetter and measure the third coordinate along the tubes with a resolution of\nabout 1~mm.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-14T17:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.10459v1","title":"The Price of Competitive Information Disclosure","summary":"In many decision-making scenarios, individuals strategically choose what\ninformation to disclose to optimize their own outcomes. It is unclear whether\nsuch strategic information disclosure can lead to good societal outcomes. To\naddress this question, we consider a competitive Bayesian persuasion model in\nwhich multiple agents selectively disclose information about their qualities to\na principal, who aims to choose the candidates with the highest qualities.\nUsing the price-of-anarchy framework, we quantify the inefficiency of such\nstrategic disclosure. We show that the price of anarchy is at most a constant\nwhen the agents have independent quality distributions, even if their utility\nfunctions are heterogeneous. This result provides the first theoretical\nguarantee on the limits of inefficiency in Bayesian persuasion with competitive\ninformation disclosure.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-14T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.10464v1","title":"Implications of distance duality violation for the $H_0$ tension and\n  evolving dark energy","summary":"We investigate whether a violation of the distance duality relation (DDR),\n$D_L(z) = (1+z)^2 D_A(z)$, connecting the angular diameter and luminosity\ndistances, can explain the Hubble tension and alter the evidence for dynamical\ndark energy in recent cosmological observations. We constrain five\nphenomenological parameterisations of DDR violation using Baryon Acoustic\nOscillation measurements from the DESI survey calibrated with the sound horizon\nderived from \\textit{Planck} Cosmic Microwave Background data and the Pantheon+\nType Ia supernova (SNIa) catalogue calibrated with the supernova absolute\nmagnitude from S$H_0$ES. We find that two toy models can resolve the tension: a\nconstant offset in the DDR (equivalent to a shift in the calibration of the\nSNIa data), $D_L(z)/D_A(z)\\simeq 0.925(1+z)^2$, which leaves the hint for\nevolving dark energy unaffected; or a change in the power-law\nredshift-dependence of the DDR, restricted to $z\\lesssim 1$,\n$D_L(z)/D_A(z)\\simeq(1+z)^{1.866}$, together with a {\\it constant} phantom dark\nenergy equation of state $w\\sim -1.155$. The Bayesian evidence slightly favours\nthe latter model. Our phenomenological approach motivates the investigation of\nphysical models of DDR violation as a novel way to explain the Hubble tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-14T17:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.10467v1","title":"De-excitation of $K$-shell hollow atoms with $12 \\le Z \\le 20$:\n  transition rates and branching ratios","summary":"Investigating $K$-shell hollow atom spectra enhances our understanding of\nfemtosecond phenomena in atomic physics, chemistry, and biology. Synchrotron\nmeasurements of two-electron one-photon (TEOP) transitions in low-$Z$ atoms\nhave revealed discrepancies between experimental results and theoretical\npredictions of TEOP relative intensities. These discrepancies appear to\noriginate from an incomplete description of an atom's response to the strong\nperturbation caused by $K$-shell double photoionization (DPI). The\nmulticonfiguration Dirac-Hartree-Fock relativistic configuration interaction\nmethod has been applied for studying the TEOP spectra of Mg, Al, Si, S, Ar, and\nCa atoms. The results show that branching ratios can be accurately reproduced\nby accounting for the effects of core and valence electron correlations, as\nwell as the outer-shell ionization and excitation processes following $K$-shell\nDPI.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-14T17:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10470v1","title":"Online Advanced Labs in Physics","summary":"At Arizona State University we have built the first and only fully online\nBachelor of Science degree in Physics, with a complete curriculum, including\nlabs. The upper division Advanced Lab courses present a special challenge for\nonline delivery. We address that using a set of custom-built simulator modules\nthat replicate all the imperfections (noise, background, etc) inherent in\nreal-world data. The set of experiments duplicates those of the in-person\nclasses. In this paper, we present an overview of these labs and discuss the\nadvantages and challenges of delivering them online. We assert that these labs\nprovide a valid and rigorous component for the fully online degree. The entire\nset of labs is available as Open Source Supplemental Materials and is shared\nfor others to use in part or in whole, with suitable attribution.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-14T17:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10483v1","title":"REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion\n  Transformers","summary":"In this paper we tackle a fundamental question: \"Can we train latent\ndiffusion models together with the variational auto-encoder (VAE) tokenizer in\nan end-to-end manner?\" Traditional deep-learning wisdom dictates that\nend-to-end training is often preferable when possible. However, for latent\ndiffusion transformers, it is observed that end-to-end training both VAE and\ndiffusion-model using standard diffusion-loss is ineffective, even causing a\ndegradation in final performance. We show that while diffusion loss is\nineffective, end-to-end training can be unlocked through the\nrepresentation-alignment (REPA) loss -- allowing both VAE and diffusion model\nto be jointly tuned during the training process. Despite its simplicity, the\nproposed training recipe (REPA-E) shows remarkable performance; speeding up\ndiffusion model training by over 17x and 45x over REPA and vanilla training\nrecipes, respectively. Interestingly, we observe that end-to-end tuning with\nREPA-E also improves the VAE itself; leading to improved latent space structure\nand downstream generation performance. In terms of final performance, our\napproach sets a new state-of-the-art; achieving FID of 1.26 and 1.83 with and\nwithout classifier-free guidance on ImageNet 256 x 256. Code is available at\nhttps://end2end-diffusion.github.io.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.10831v1","title":"Hallucination-Aware Generative Pretrained Transformer for Cooperative\n  Aerial Mobility Control","summary":"This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-15T03:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.10832v1","title":"Unlimited Vector Processing for Wireless Baseband Based on RISC-V\n  Extension","summary":"Wireless baseband processing (WBP) serves as an ideal scenario for utilizing\nvector processing, which excels in managing data-parallel operations due to its\nparallel structure. However, conventional vector architectures face certain\nconstraints such as limited vector register sizes, reliance on power-of-two\nvector length multipliers, and vector permutation capabilities tied to specific\narchitectures. To address these challenges, we have introduced an instruction\nset extension (ISE) based on RISC-V known as unlimited vector processing (UVP).\nThis extension enhances both the flexibility and efficiency of vector\ncomputations. UVP employs a novel programming model that supports\nnon-power-of-two register groupings and hardware strip-mining, thus enabling\nsmooth handling of vectors of varying lengths while reducing the software\nstrip-mining burden. Vector instructions are categorized into symmetric and\nasymmetric classes, complemented by specialized load/store strategies to\noptimize execution. Moreover, we present a hardware implementation of UVP\nfeaturing sophisticated hazard detection mechanisms, optimized pipelines for\nsymmetric tasks such as fixed-point multiplication and division, and a robust\npermutation engine for effective asymmetric operations. Comprehensive\nevaluations demonstrate that UVP significantly enhances performance, achieving\nup to 3.0$\\times$ and 2.1$\\times$ speedups in matrix multiplication and fast\nFourier transform (FFT) tasks, respectively, when measured against lane-based\nvector architectures. Our synthesized RTL for a 16-lane configuration using\nSMIC 40nm technology spans 0.94 mm$^2$ and achieves an area efficiency of 21.2\nGOPS/mm$^2$.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-15T03:23:02Z"}
{"aid":"http://arxiv.org/abs/2504.10860v1","title":"Bell-Mermin-Klyshko Inequalities and One-way Information Deficit of\n  Dirac Fields in Noninertial Frames","summary":"We investigate the Bell-Mermin-Klyshko inequalities and the one-way\ninformation deficit of Dirac fields in noninertial frames, where the quantum\ncorrelations are shared between inertial and accelerated observers due to the\nUnruh effect. We derive partial analytical results for specific quantum states\nusing the one-way information deficit. Additionally, we present numerical\nresults for the Bell-Mermin-Klyshko inequalities. The study reveals the\npresence of Bell nonlocality and the significance of the one-way information\ndeficit in relativistic quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T04:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.10864v1","title":"Automata for the commutative closure of regular sets","summary":"Consider $ A^* $, the free monoid generated by the finite alphabet $A$ with\nthe concatenation operation. Two words have the same commutative image when one\nis a permutation of the symbols of the other. The commutative closure of a set\n$ L \\subseteq A^* $ is the set $ {C}(L) \\subseteq A^* $ of words whose\ncommutative image coincides with that of some word in $ L $. We provide an\nalgorithm that, given a regular set $ L $, produces a finite state automaton\nthat accepts the commutative closure $ {C}(L) $, provided that this closure set\nis regular. The problem of deciding whether $ {C}(L) $ is regular was solved by\nGinsburg and Spanier in 1966 using the decidability of Presburger sentences,\nand by Gohon in 1985 via formal power series. The problem of constructing an\nautomaton that accepts $ {C}(L) $ has already been studied in the literature.\nWe give a simpler algorithm using an algebraic approach.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-15T04:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.10882v1","title":"A Quantum Advantage in Localizing Transmission Loss Change in Optical\n  Networks","summary":"The ability to localize transmission loss change to a subset of links in\noptical networks is crucial for maintaining network reliability, performance\nand security. \\emph{Quantum probes}, implemented by sending blocks of $n$\ncoherent-state pulses augmented with continuous-variable (CV) squeezing ($n=1$)\nor weak temporal-mode entanglement ($n>1$) over a lossy channel to a receiver\nwith homodyne detection capabilities, are known to be more sensitive than their\nquasi-classical counterparts in detecting a sudden increase in channel loss.\nThe enhanced sensitivity can be characterized by the increased Kullback-Leibler\n(KL) divergence of the homodyne output, before and after the loss change\noccurs. When combined with the theory of quickest change detection (QCD), the\nincrease in KL divergence translates into a decrease in detection latency.\n  In this work, we first revisit quantum probes over a channel, generalizing\nprevious results on $n=1$ (CV squeezed states) to arbitrary values of $n$.\nAssuming a subset of nodes in an optical network is capable of sending and\nreceiving such probes through intermediate nodes with all-optical switching\ncapabilities, we present a scheme for quickly detecting the links that have\nsuffered a sudden drop in transmissivity. Since quantum probes lose their\nsensitivity with increasing loss in the channel, we first propose a probe\nconstruction algorithm that makes the set of links suffering transmission loss\nchange identifiable, while minimizing the longest distance a probe traverses.\nWe then introduce new cumulative sum (CUSUM) statistics with a stopping rule,\nwhich allows us to run the CUSUM algorithm to quickly localize the lossy links\nusing our constructed probes. Finally, we show that the proposed scheme\nachieves a quantum advantage in decreasing the detection delay.","main_category":"quant-ph","categories":"quant-ph,cs.NI","published":"2025-04-15T05:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.10883v1","title":"Bringing together invertible UNets with invertible attention modules for\n  memory-efficient diffusion models","summary":"Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.10901v1","title":"Design and Verification of a Synchronus First In First Out (FIFO)","summary":"This project focuses on designing and verifying a synchronous FIFO First In\nFirst Out (FIFO) memory, a critical component in digital systems for temporary\ndata storage and seamless data transfer. The FIFO operates under a single clock\ndomain, ensuring synchronized read and write operations, making it suitable for\nsystems requiring high-speed, reliable data buffering. This design includes\nFIFO's key features, such as read and write operations, full and empty flag\ngeneration, and pointer management for memory control. The FIFO was implemented\nusing Verilog to define the Register Transfer Level (RTL) design, ensuring\nfunctionality and timing requirements were met. For verification, three\napproaches were employed: (1) UVM-based Verification: A Universal Verification\nMethodology (UVM) testbench was developed to test the FIFO design rigorously.\nThe testbench includes components like interface, sequence item, driver,\nmonitor, scoreboard, agent, and environment. Directed and random tests were\nperformed to verify corner cases, such as simultaneous reads and writes, full\nand empty conditions, and overflow and underflow scenarios; (2) Traditional\nVerilog Testbench: A standalone Verilog testbench was also used to validate the\nfunctionality of the FIFO through directed test scenarios and waveform\nanalysis; (3) FPGA implementation: Additionally, the design was implemented on\nan FPGA for real-time testing to verify its functionality and timing behavior\nin hardware. FPGA-based verification ensured the design performed as expected\nunder practical conditions. The results confirmed the correct operation of the\nFIFO, including accurate data transfer, flag behavior, and timing\nsynchronization. The project successfully demonstrated the robustness and\nreliability of the synchronous FIFO design, highlighting its importance in\nmodern digital systems for efficient data handling and buffering.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-15T06:23:09Z"}
{"aid":"http://arxiv.org/abs/2504.10906v1","title":"Understanding LLMs' Cross-Lingual Context Retrieval: How Good It Is And\n  Where It Comes From","summary":"The ability of cross-lingual context retrieval is a fundamental aspect of\ncross-lingual alignment of large language models (LLMs), where the model\nextracts context information in one language based on requests in another\nlanguage. Despite its importance in real-life applications, this ability has\nnot been adequately investigated for state-of-the-art models. In this paper, we\nevaluate the cross-lingual context retrieval ability of over 40 LLMs across 12\nlanguages to understand the source of this ability, using cross-lingual machine\nreading comprehension (xMRC) as a representative scenario. Our results show\nthat several small, post-trained open LLMs show strong cross-lingual context\nretrieval ability, comparable to closed-source LLMs such as GPT-4o, and their\nestimated oracle performances greatly improve after post-training. Our\ninterpretability analysis shows that the cross-lingual context retrieval\nprocess can be divided into two main phases: question encoding and answer\nretrieval, which are formed in pre-training and post-training, respectively.\nThe phasing stability correlates with xMRC performance, and the xMRC bottleneck\nlies at the last model layers in the second phase, where the effect of\npost-training can be evidently observed. Our results also indicate that\nlarger-scale pretraining cannot improve the xMRC performance. Instead, larger\nLLMs need further multilingual post-training to fully unlock their\ncross-lingual context retrieval potential. Our code and is available at\nhttps://github.com/NJUNLP/Cross-Lingual-Context-Retrieval","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T06:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.10910v1","title":"Full Cooperation in Repeated Multi-Player Games on Hypergraphs","summary":"Nearly all living systems, especially humans, depend on collective\ncooperation for survival and prosperity. However, the mechanisms driving the\nevolution of cooperative behavior remain poorly understood, particularly in the\ncontext of simultaneous interactions involving multiple individuals, repeated\nencounters, and complex interaction structures. Here, we introduce a novel\nframework for studying repeated multi-player interactions in structured\npopulations -- repeated multi-player games on hypergraphs -- where multiple\nindividuals within each hyperedge engage in a repeated game, and each player\ncan simultaneously participate in many games. We focus on public goods games,\nwhere individuals differ in their initial endowments, their allocation of\nendowments across games, and their productivity, which determines the impact of\ntheir contributions. Through Nash equilibrium analysis, we reveal the intricate\ninterplay between full cooperation (all individuals contribute their entire\nendowments, maximizing collective benefits) and key factors such as initial\nendowments, productivity, contribution strategies, and interaction structure.\nNotably, while equal endowments are most effective in promoting full\ncooperation in homogeneous hypergraphs, they can hinder cooperation in\nheterogeneous hypergraphs, suggesting that equal endowments are not universally\noptimal. To address this, we propose two optimization strategies: one for\npolicymakers to adjust endowment distributions and another for players to\nmodify their contribution strategies. Both approaches successfully promote full\ncooperation across all studied hypergraphs. Our findings provide novel insights\ninto the emergence of full cooperation, offering valuable guidance for both\nplayers and policymakers in fostering collective cooperation.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T06:45:15Z"}
{"aid":"http://arxiv.org/abs/2504.10925v1","title":"Transfer Learning for Temporal Link Prediction","summary":"Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T07:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.10951v1","title":"Convergence rate for a semidiscrete approximation of scalar conservation\n  laws","summary":"We propose a semidiscrete scheme for approximation of entropy solutions of\none-dimensional scalar conservation laws with nonnegative initial data. The\nscheme is based on the concept of particle paths for conservation laws and can\nbe interpreted as a finite-particle discretization. A convergence rate of order\n$1/2$ with respect to initial particle spacing is proved. As a special case,\nthis covers the convergence of the Follow--the--Leader model to the\nLighthill--Whitham--Richards model for traffic flow.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA","published":"2025-04-15T07:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.10966v1","title":"Non-uniqueness of mild solutions for 2d-heat equations with singular\n  initial data","summary":"In a recent article by the authors [15] it was shown that wide classes of\nsemilinear elliptic equations with exponential type nonlinearities admit\nsingular radial solutions $U$ on the punctured disc in $\\mathbb R^2$ which are\nalso distributional solutions on the whole disc. We show here that these\nsolutions, taken as initial data of the associated heat equation, give rise to\nnon-uniqueness of mild solutions: ${u_s}(t,x) \\equiv U(x)$ is a stationary\nsolution, and there exists also a solution ${u_r}(t,x)$ departing from $U$\nwhich is bounded for $t > 0$. While such non-uniqueness results have been known\nin higher dimensions by Ni--Sacks [33], Terraneo [40] and Galaktionov--Vazquez\n[16], only two very specific results have recently been obtained in two\ndimensions by Ioku--Ruf--Terraneo [22] and Ibrahim--Kikuchi--Nakanishi--Wei\n[21].","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T08:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.10972v1","title":"AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained\n  Representation in Radiographic Images","summary":"Current self-supervised methods, such as contrastive learning, predominantly\nfocus on global discrimination, neglecting the critical fine-grained anatomical\ndetails required for accurate radiographic analysis. To address this challenge,\nwe propose an Anatomy-driven self-supervised framework for enhancing\nFine-grained Representation in radiographic image analysis (AFiRe). The core\nidea of AFiRe is to align the anatomical consistency with the unique\ntoken-processing characteristics of Vision Transformer. Specifically, AFiRe\nsynergistically performs two self-supervised schemes: (i) Token-wise\nanatomy-guided contrastive learning, which aligns image tokens based on\nstructural and categorical consistency, thereby enhancing fine-grained\nspatial-anatomical discrimination; (ii) Pixel-level anomaly-removal\nrestoration, which particularly focuses on local anomalies, thereby refining\nthe learned discrimination with detailed geometrical information. Additionally,\nwe propose Synthetic Lesion Mask to enhance anatomical diversity while\npreserving intra-consistency, which is typically corrupted by traditional data\naugmentations, such as Cropping and Affine transformations. Experimental\nresults show that AFiRe: (i) provides robust anatomical discrimination,\nachieving more cohesive feature clusters compared to state-of-the-art\ncontrastive learning methods; (ii) demonstrates superior generalization,\nsurpassing 7 radiography-specific self-supervised methods in multi-label\nclassification tasks with limited labeling; and (iii) integrates fine-grained\ninformation, enabling precise anomaly detection using only image-level\nannotations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:29:54Z"}
{"aid":"http://arxiv.org/abs/2504.11030v1","title":"Sobolev homeomorphisms and composition operators on homogeneous Lie\n  groups","summary":"In this article we study Sobolev homeomorphisms and composition operators on\nhomogeneous Lie groups. We prove, that a measurable homeomorphism $\\varphi:\n\\Omega \\to\\widetilde{\\Omega}$ belongs to the Sobolev space $L^{1}_{q}(\\Omega;\n\\widetilde{\\Omega})$, $1\\leq q < \\infty$, if and only if $\\varphi$ generates a\nbounded composition operator on Sobolev spaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T09:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.11040v1","title":"Infinite topological entropy, positive mean dimension, and factors of\n  subshifts","summary":"We study dynamical systems with the property that all the nontrivial factors\nhave infinite topological entropy (or, positive mean dimension). We establish\nan ``if and only if'' condition for this property among a typical class of\ndynamical systems, the subshifts of block type in the Hilbert cube. This in\nparticular leads to a large class of concrete (and new) examples of dynamical\nsystems having this property.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T10:05:29Z"}
{"aid":"http://arxiv.org/abs/2504.11096v1","title":"A fully variational numerical method for structural topology\n  optimization based on a Cahn-Hilliard model","summary":"We formulate a novel numerical method suitable for the solution of topology\noptimization problems in solid mechanics. The most salient feature of the new\napproach is that the space and time discrete equations of the numerical method\ncan be obtained as the optimality conditions of a single incremental potential.\nThe governing equations define a gradient flow of the mass in the domain that\nmaximizes the stiffness of the proposed solid, while exactly preserving the\nmass of the allocated material. Moreover, we propose a change of variables in\nthe model equations that constrains the value of the density within admissible\nbounds and a continuation strategy that speeds up the evolution of the flow.\nThe proposed strategy results in a robust and efficient topology optimization\nmethod that is exactly mass-preserving, does not employ Lagrange multipliers,\nand is fully variational.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MP","published":"2025-04-15T11:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.11098v1","title":"Electron-transverse acoustic phonon couplings in three-dimensional\n  pentatellurides","summary":"Transverse acoustic (TA) phonon waves are analogous to electromagnetic waves\nand can carry a certain angular momentum. In this paper, we study the\nelectron-TA phonon couplings in three-dimensional pentatellurides and explore\nthe conditions under which the TA phonon condensation is stable. We analyze the\nLindhard response function, phonon softening, mean-field parameters, and\nrenormalized dispersions, on the basis of which the phase diagrams of the\nelectron-phonon couplings in ZrTe$_5$ and HfTe$_5$ are calculated. The phase\ndiagrams show that, if the chemical potential lies near the Weyl nodes, the TA\nphonon condensation will dominate and lead to the shear strain wave phase. We\nfurther reveal that when the wave vector of the particular phonon mode is\nsmaller, the critical coupling strength will be weaker for the phonon\ncondensation, which thus favors the condensation phase.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T11:44:40Z"}
{"aid":"http://arxiv.org/abs/2504.11102v1","title":"Origin of Reactor Antineutrino Anomaly","summary":"The reactor antineutrino anomaly, discovered in 2011, means a noticeable\ndifference between the observed rate of inverse beta decays and the expected\n(theoretical) rate of such processes based on the measurement of the spectra of\nelectrons in beta decay of $^{235}$U, $^{239}$Pu, $^{241}$Pu, and $^{238}$U\nnuclei and their subsequent conversion into right-handed antineutrino spectra.\nThis paper provides a rationale for the fact that both right-handed and\nleft-handed antineutrinos are produced in beta decays of nuclei. But the\nconversion procedure in any case assigns a right-handed antineutrino to each\nelectron, which leads to the superiority of the theoretical rate of inverse\nbeta decays over the experimental one. The right-handed antineutrino is\nproduced in the mode of beta decay of the nucleus due to the standard\nelectroweak interaction. The left-handed antineutrino appears in the mode\ncaused by the existence of a interaction, the carrier of which is a massless\npseudoscalar boson having a Yukawa coupling with the electron neutrino and\nnucleons. The emission of such a boson from a virtual right-handed antineutrino\nconverts it into a free left-handed antineutrino.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-15T11:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.11121v1","title":"$B$ meson decays to vector charmonium(like) states and a $K$ meson: the\n  role of final-state interactions","summary":"A series of vector charmonium(like) states, accompanied by a $K$ meson, have\nbeen observed in the decays of $B$ meson. These processes are color-suppressed\nat the quark level, as inferred from topological diagram analysis. In this\nwork, we calculate the branching fractions of the decays $B \\to \\psi K$, where\n$\\psi$ denotes the charmonium(like) states $\\psi(1S)$, $\\psi(2S)$,\n$\\psi(4040)$, $\\psi(3770)$, and $\\psi(4160)$. Our analysis incorporates both\nshort-distance (naive factorization approach) and long-distance (final-state\ninteractions) contributions. Within reasonable parameters, our results align\nwith experimental data except for the $ \\psi(4160)$, suggesting its possible\nexotic nature. Furthermore, we find that long-distance contributions dominate\nthese decay processes, highlighting the crucial role of final-state\ninteractions in the productions of charmonium(like) states in $B$ decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T12:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.11124v1","title":"A Unified Hardware Accelerator for Fast Fourier Transform and Number\n  Theoretic Transform","summary":"The Number Theoretic Transform (NTT) is an indispensable tool for computing\nefficient polynomial multiplications in post-quantum lattice-based\ncryptography. It has strong resemblance with the Fast Fourier Transform (FFT),\nwhich is the most widely used algorithm in digital signal processing. In this\nwork, we demonstrate a unified hardware accelerator supporting both 512-point\ncomplex FFT as well as 256-point NTT for the recently standardized NIST\npost-quantum key encapsulation and digital signature algorithms ML-KEM and\nML-DSA respectively. Our proposed architecture effectively utilizes the\narithmetic circuitry required for complex FFT, and the only additional circuits\nrequired are for modular reduction along with modifications in the control\nlogic. Our implementation achieves performance comparable to state-of-the-art\nML-KEM / ML-DSA NTT accelerators on FPGA, thus demonstrating how an FFT\naccelerator can be augmented to support NTT and the unified hardware can be\nused for both digital signal processing and post-quantum lattice-based\ncryptography applications.","main_category":"cs.CR","categories":"cs.CR,eess.SP","published":"2025-04-15T12:13:05Z"}
{"aid":"http://arxiv.org/abs/2504.11130v1","title":"Divergence of Empirical Neural Tangent Kernel in Classification Problems","summary":"This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-15T12:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.11152v1","title":"The imprints of QCD cascades in hadron multiplicity distribution","summary":"The relation between parton and hadron multiplicity distributions is\ndiscussed. To obtain parton multiplicity distribution we propose decomposition\nof the multiplicity distributions of final state hadrons. Such procedure offers\nhope for experimental testing of physical probes of quantum complexity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T12:53:12Z"}
{"aid":"http://arxiv.org/abs/2504.11158v1","title":"More fields are different: Stochastic view of multi-field inflationary\n  scenario","summary":"High-energy physics often motivates multi-field inflationary scenarios where\nstochastic effects play a crucial role. Peculiar to multi-field models, the\nnoise-induced centrifugal force results in a longer duration of inflation\ndepending on the number of fields, even when the stochastic noises themselves\nare small. We show that, in such small-noise regimes, the number of fields\ngenerically discriminates whether inflation successfully terminates or lasts\nforever. Our results indicate that inflation with an extremely large number of\nfields may fail to realise our observable Universe.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-15T13:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11159v1","title":"C-SHAP for time series: An approach to high-level temporal explanations","summary":"Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T13:06:32Z"}
{"aid":"http://arxiv.org/abs/2504.11161v1","title":"Refinements of the Blanco-Koldobsky-Turnšek Theorem","summary":"We refine the well-known Blanco-Koldobsky-Turn\\v{s}ek Theorem which states\nthat a norm one linear operator defined on a Banach space is an isometry if and\nonly if it preserves orthogonality at every element of the space. We improve\nthe result for Banach spaces in which the set of all smooth points forms a\ndense $G_{\\delta}$-set by proving that a norm one linear operator that\npreserves orthogonality on a dense subset of the space is an isometry. We\nfurther demonstrate that if such an operator preserves orthogonality on a\nhyperplane not passing through the origin then it is an isometry. In the\ncontext of finite-dimensional Banach spaces, we prove that preserving\northogonality on the set all extreme points of the unit ball forces the\noperator to be an isometry, which substantially refines\nBlanco-Koldobsky-Turn\\v{s}ek theorem. Finally, for finite-dimensional\npolyhedral spaces, we establish the significance of the set of all $k$-smooth\npoints for any possible $k,$ in the study of isometric theory.","main_category":"math.FA","categories":"math.FA","published":"2025-04-15T13:10:43Z"}
{"aid":"http://arxiv.org/abs/2504.11213v1","title":"Characterizing High Schmidt Number Witnesses in Arbitrary Dimensions\n  System","summary":"A profound comprehension of quantum entanglement is crucial for the\nprogression of quantum technologies. The degree of entanglement can be assessed\nby enumerating the entangled degrees of freedom, leading to the determination\nof a parameter known as the Schmidt number. In this paper, we develop an\nefficient analytical tool for characterizing high Schmidt number witnesses for\nbipartite quantum states in arbitrary dimensions. Our methods not only offer\nviable mathematical methods for constructing high-dimensional Schmidt number\nwitnesses in theory but also simplify the quantification of entanglement and\ndimensionality. Most notably, we develop high-dimensional Schmidt number\nwitnesses within arbitrary-dimensional systems, with our Schmidt witness\ncoefficients relying solely on the operator Schmidt coefficient. Subsequently,\nwe demonstrate our theoretical advancements and computational superiority by\nconstructing Schmidt number witnesses in arbitrary dimensional bipartite\nquantum systems with Schmidt numbers four and five.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math-ph,math.MP,math.NA,math.SP","published":"2025-04-15T14:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.11215v1","title":"Observational Study of Recurrent Jets: Evolution of Magnetic Flux,\n  Current, and Helicity","summary":"We observed three recurrent blowout jets in an active regio with Atmospheric\nImaging Assembly (AIA) aboard the Solar Dynamics Observatory (SDO). Using\nHelioseismic Magnetic Imager (HMI) data. We found that the magnetic flux of an\nemerging negative pole increases steadily before declining just as the jets\nerupt. Certain physical quantities, like the total unsigned vertical current,\nalign with the periodicity of the jets. The differential affine velocity of the\nvector magnetograms reveals strong shear around the negative pole. The Doppler\nvelocity map, calculated from the H$\\alpha$ spectra observed by the Chinese\nH$\\alpha$ Solar Explorer (CHASE), shows upflows with large initial velocity\nbefore it can be observed by AIA. The magnetic field derived from the nonlinear\nforce-free field (NLFFF) model suggests a topology akin to fan-spine structure,\nconsistent with AIA images. We calculated the evolution of volumetric helicity\nratio using the NLFFF model and found its phase aligns with the jet flux in AIA\n171 \\AA. These results suggest that recurrent jets may be triggered by the\naccumulation and release of energy and helicity, driven by emergence, shearing\nand cancellation of photospheric magnetic field.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T14:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.11222v1","title":"Fusion research in a Deuterium-Tritium tokamak","summary":"The recent ITER re-baselining calls for new fusion-relevant research best\ncarried out in a DT-capable tokamak device with similar characteristics. The\npresent paper describes key issues that could be addressed in a Suitably\nEnhanced DT-capable Tokamak (SET), with tungsten plasma facing components,\nboronization systems, and 10 MW of ECRH, based on characteristics and\nknowledgebase of JET. We discuss hardware options, and show that\nfusion-relevant operational scenarios could be achieved. Notably, development,\nvalidation and testing of fusion and nuclear diagnostics, to be used in next\ngeneration devices, would require a D-T capable tokamak as described.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,nucl-ex","published":"2025-04-15T14:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.11237v1","title":"Periodic table for highly charged ions","summary":"Mendeleev's periodic table successfully groups atomic elements according to\ntheir chemical and spectroscopic properties. However, it becomes less\nsufficient in describing the electronic properties of highly charged ions\n(HCIs) in which many of the outermost electrons are ionized. In this work, we\nput forward a periodic table particularly suitable for HCIs. It is constructed\npurely based on the successive electron occupation of relativistic orbitals.\nWhile providing a much-simplified description of the level structure of highly\ncharged isoelectronic ions -- essential for laboratory and astrophysical plasma\nspectroscopies, such a periodic table predicts a large family of highly\nforbidden transitions suitable for the development of next-generation optical\natomic clocks. Furthermore, we also identify universal linear $Z$ scaling laws\n($Z$ is the nuclear charge) in the so-called ``Coulomb splittings'' between\nangular momentum multiplets along isoelectronic sequences, complementing the\nphysics of electron-electron interactions in multielectron atomic systems.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.optics,physics.plasm-ph,quant-ph","published":"2025-04-15T14:39:09Z"}
{"aid":"http://arxiv.org/abs/2504.11271v1","title":"Distillation-Supervised Convolutional Low-Rank Adaptation for Efficient\n  Image Super-Resolution","summary":"Convolutional neural networks (CNNs) have been widely used in efficient image\nsuper-resolution. However, for CNN-based methods, performance gains often\nrequire deeper networks and larger feature maps, which increase complexity and\ninference costs. Inspired by LoRA's success in fine-tuning large language\nmodels, we explore its application to lightweight models and propose\nDistillation-Supervised Convolutional Low-Rank Adaptation (DSCLoRA), which\nimproves model performance without increasing architectural complexity or\ninference costs. Specifically, we integrate ConvLoRA into the efficient SR\nnetwork SPAN by replacing the SPAB module with the proposed SConvLB module and\nincorporating ConvLoRA layers into both the pixel shuffle block and its\npreceding convolutional layer. DSCLoRA leverages low-rank decomposition for\nparameter updates and employs a spatial feature affinity-based knowledge\ndistillation strategy to transfer second-order statistical information from\nteacher models (pre-trained SPAN) to student models (ours). This method\npreserves the core knowledge of lightweight models and facilitates optimal\nsolution discovery under certain conditions. Experiments on benchmark datasets\nshow that DSCLoRA improves PSNR and SSIM over SPAN while maintaining its\nefficiency and competitive image quality. Notably, DSCLoRA ranked first in the\nOverall Performance Track of the NTIRE 2025 Efficient Super-Resolution\nChallenge. Our code and models are made publicly available at\nhttps://github.com/Yaozzz666/DSCF-SR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:12:57Z"}
{"aid":"http://arxiv.org/abs/2504.11284v1","title":"Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation","summary":"Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-15T15:25:27Z"}
{"aid":"http://arxiv.org/abs/2504.11300v1","title":"Multi-Orbiter Continuous Lunar Beaming","summary":"In this work, free-space optics-based continuous wireless power transmission\nbetween multiple low lunar orbit satellites and a solar panel on the lunar\nrover located at the lunar south pole are investigated based on the\ntime-varying harvested power and overall system efficiency metrics. The\nperformances are compared between a solar panel with the tracking ability and a\nfixed solar panel that induces \\textit{the cosine effect} due to the\ntime-dependent angle of incidence (AoI). In our work, the Systems Tool Kit\n(STK) high-precision orbit propagator, which calculates the ephemeris data\nprecisely, is utilized. Interestingly, orbiter deployments in constellations\nchange significantly during a Moon revolution; thus, short-duration simulations\ncannot be used straightforwardly. In our work, many satellite configurations\nare assessed to be able to find a Cislunar constellation that establishes a\ncontinuous line-of-sight (LoS) between the solar panel and at least a single\nLLO satellite. It is found that 40-satellite schemes enable the establishment\nof a continuous WPT system model. Besides, a satellite selection method (SSM)\nis introduced so that only the best LoS link among multiple simultaneous links\nfrom multiple satellites will be active for optimum efficiency. Our benchmark\nsystem of a 40-satellite quadruple orbit scheme is compared with 30-satellite\nand a single satellite schemes based on the average harvested powers and\noverall system efficiencies 27.3 days so the trade-off options can be assessed\nfrom the multiple Cislunar models. The outcomes show that the average system\nefficiencies of single, 30-satellite, and 40-satellite schemes are 2.84%,\n32.33%, and 33.29%, respectively, for the tracking panel and 0.97%, 18.33%, and\n20.44%, respectively, for the fixed solar panel case.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T15:43:39Z"}
{"aid":"http://arxiv.org/abs/2504.11325v1","title":"Crystal nucleation and growth in high-entropy alloys revealed by atomic\n  electron tomography","summary":"High-entropy alloys (HEAs) balance mixing entropy and intermetallic phase\nformation enthalpy, creating a vast compositional space for structural and\nfunctional materials (1-6). They exhibit exceptional strength-ductility\ntrade-offs in metallurgy (4-10) and near-continuum adsorbate binding energies\nin catalysis (11-16). A deep understanding of crystal nucleation and growth in\nHEAs is essential for controlling their formation and optimizing their\nstructural and functional properties. However, atomic-scale nucleation in HEAs\nchallenges traditional theories based on one or two principal elements (17-23).\nThe intricate interplay of structural and chemical orders among multiple\nprincipal elements further obscures our understanding of nucleation pathways\n(5,24-27). Due to the lack of direct three-dimensional (3D) atomic-scale\nobservations, previous studies have relied on simulations and indirect\nmeasurements (28-32), leaving HEA nucleation and growth fundamentally elusive.\nHere, we advance atomic electron tomography (33,34) to resolve the 3D atomic\nstructure and chemical composition of 7,662 HEA and 498 medium-entropy alloy\nnuclei at different nucleation stages. We observe local structural order that\ndecreases from core to boundary, correlating with local chemical order. As\nnuclei grow, structural order improves. At later stages, most nuclei coalesce\nwithout misorientation, while some form coherent twin boundaries. To explain\nthese experimental observations, we propose the gradient nucleation pathways\nmodel, in which the nucleation energy barrier progressively increases through\nmultiple evolving intermediate states. We expect these findings to not only\nprovide fundamental insights into crystal nucleation and growth in HEAs, but\nalso offer a general framework for understanding nucleation mechanisms in other\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.soft","published":"2025-04-15T16:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.11340v1","title":"Organisation and dynamics of individual DNA segments in topologically\n  complex genomes","summary":"Capturing the physical organisation and dynamics of genomic regions is one of\nthe major open challenges in biology. The kinetoplast DNA (kDNA) is a\ntopologically complex genome, made by thousands of DNA (mini and maxi) circles\ninterlinked into a two-dimensional Olympic network. The organisation and\ndynamics of these DNA circles are poorly understood. In this paper, we show\nthat dCas9 linked to Quantum Dots can efficiently label different classes of\nDNA minicircles in kDNA. We use this method to study the distribution and\ndynamics of different classes of DNA minicircles within the network. We\ndiscover that maxicircles display a preference to localise at the periphery of\nthe network and that they undergo subdiffusive dynamics. From the latter, we\ncan also quantify the effective network stiffness, confirming previous indirect\nestimations via AFM. Our method could be used more generally, to quantify the\nlocation, dynamics and material properties of genomic regions in other complex\ngenomes, such as that of bacteria, and to study their behaviour in the presence\nof DNA-binding proteins.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-15T16:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.11358v1","title":"DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks","summary":"LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-15T16:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.11385v1","title":"GLL-type Nonmonotone Descent Methods Revisited under\n  Kurdyka-Łojasiewicz Property","summary":"The purpose of this paper is to extend the full convergence results of the\nclassic GLL-type (Grippo-Lampariello-Lucidi) nonmonotone methods to nonconvex\nand nonsmooth optimization. We propose a novel iterative framework for the\nminimization of a proper and lower semicontinuous function $\\Phi$. The\nframework consists of the GLL-type nonmonotone decrease condition for a\nsequence, a relative error condition for its augmented sequence with respect to\na Kurdyka-{\\L}ojasiewicz (KL) function $\\Theta$, and a relative gap condition\nfor the partial maximum objective value sequence. The last condition is shown\nto be a product of the prox-regularity of $\\Phi$ on the set of cluster points,\nand to hold automatically under a mild condition on the objective value\nsequence. We prove that for any sequence and its bounded augmented sequence\ntogether falling within the framework, the sequence itself is convergent.\nFurthermore, when $\\Theta$ is a KL function of exponent $\\theta\\in(0, 1)$, the\nconvergence admits a linear rate if $\\theta\\in(0, 1/2]$ and a sublinear rate if\n$\\theta\\in(1/2, 1)$. As applications, we prove, for the first time, that the\ntwo existing algorithms, namely the nonmonotone proximal gradient (NPG) method\nwith majorization and NPG with extrapolation both enjoy the full convergence of\nthe iterate sequences for nonconvex and nonsmooth KL composite optimization\nproblems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T16:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.11419v1","title":"Embodied World Models Emerge from Navigational Task in Open-Ended\n  Environments","summary":"Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI,cs.NE","published":"2025-04-15T17:35:13Z"}
{"aid":"http://arxiv.org/abs/2504.11436v1","title":"Shifting Work Patterns with Generative AI","summary":"We present evidence on how generative AI changes the work patterns of\nknowledge workers using data from a 6-month-long, cross-industry, randomized\nfield experiment. Half of the 6,000 workers in the study received access to a\ngenerative AI tool integrated into the applications they already used for\nemails, document creation, and meetings. We find that access to the AI tool\nduring the first year of its release primarily impacted behaviors that could be\nchanged independently and not behaviors that required coordination to change:\nworkers who used the tool spent 3 fewer hours, or 25% less time on email each\nweek (intent to treat estimate is 1.4 hours) and seemed to complete documents\nmoderately faster, but did not significantly change time spent in meetings.","main_category":"econ.GN","categories":"econ.GN,cs.LG,q-fin.EC","published":"2025-04-15T17:52:00Z"}
{"aid":"http://arxiv.org/abs/2504.11751v1","title":"Wandering Flows on the Plane","summary":"We study planar flows without non-wandering points and prove several\nproperties of these flows in relation with their prolongational relation. The\nmain results of this article are that a planar (regular) wandering flow has no\ngeneralized recurrence and has only two topological invariants: the space of\nits orbits and its prolongational relation (or, equivalently, its smallest\nstream). As a byproduct, our results show that, even in absence of any type of\nrecurrence, the stream of a flow contains fundamental information on its\nbehavior.","main_category":"math.DS","categories":"math.DS,math.GN","published":"2025-04-16T04:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.11777v1","title":"Bridging the Semantic Gaps: Improving Medical VQA Consistency with\n  LLM-Augmented Question Sets","summary":"Medical Visual Question Answering (MVQA) systems can interpret medical images\nin response to natural language queries. However, linguistic variability in\nquestion phrasing often undermines the consistency of these systems. To address\nthis challenge, we propose a Semantically Equivalent Question Augmentation\n(SEQA) framework, which leverages large language models (LLMs) to generate\ndiverse yet semantically equivalent rephrasings of questions. Specifically,\nthis approach enriches linguistic diversity while preserving semantic meaning.\nWe further introduce an evaluation metric, Total Agreement Rate with\nSemantically Equivalent Input and Correct Answer (TAR-SC), which assesses a\nmodel's capability to generate consistent and correct responses to semantically\nequivalent linguistic variations. In addition, we also propose three other\ndiversity metrics - average number of QA items per image (ANQI), average number\nof questions per image with the same answer (ANQA), and average number of\nopen-ended questions per image with the same semantics (ANQS). Using the SEQA\nframework, we augmented the benchmarked MVQA public datasets of SLAKE, VQA-RAD,\nand PathVQA. As a result, all three datasets achieved significant improvements\nby incorporating more semantically equivalent questions: ANQI increased by an\naverage of 86.1, ANQA by 85.1, and ANQS by 46. Subsequent experiments evaluate\nthree MVQA models (M2I2, MUMC, and BiomedGPT) under both zero-shot and\nfine-tuning settings on the enhanced datasets. Experimental results in MVQA\ndatasets show that fine-tuned models achieve an average accuracy improvement of\n19.35%, while our proposed TAR-SC metric shows an average improvement of 11.\n61%, indicating a substantial enhancement in model consistency.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T05:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.11794v1","title":"Fast Baryonic Field Painting for Sunyaev-Zel'dovich Analyses: Transfer\n  Function vs. Hybrid Effective Field Theory","summary":"We present two approaches for \"painting\" baryonic properties relevant to the\nSunyaev-Zel'dovich (SZ) effect - optical depth and Compton-$y$ - onto\n3-dimensional $N$-body simulations, using the MillenniumTNG suite as a\nbenchmark. The goal of these methods is to produce fast and accurate\nreconstruction methods to aid future analyses of baryonic feedback using the SZ\neffect. The first approach employs a Gaussian Process emulator to model the SZ\nquantities via a transfer function, while the second utilizes Hybrid Effective\nField Theory (HEFT) to reproduce these quantities within the simulation. Our\nanalysis involves comparing both methods to the true MillenniumTNG optical\ndepth and Compton-$y$ fields using several metrics, including the\ncross-correlation coefficient, power spectrum, and power spectrum error.\nAdditionally, we assess how well the reconstructed fields correlate with dark\nmatter haloes across various mass thresholds. The results indicate that the\ntransfer function method yields more accurate reconstructions for fields with\ninitially high correlations ($r \\approx 1$), such as between the optical depth\nand dark matter fields. Conversely, the HEFT-based approach proves more\neffective in enhancing correlations for fields with weaker initial correlations\n($r \\sim 0.5$), such as between the Compton-$y$ and dark matter fields. Lastly,\nwe discuss extensions of our methods to improve the reconstruction performance\nat the field level.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-16T06:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.11804v1","title":"Advanced MST3 Encryption scheme based on generalized Suzuki 2-groups","summary":"This article presents a method for enhancing the encryption algorithm in the\nMST3 cryptosystem for generalized Suzuki 2-groups. The conventional MST\ncryptosystem based on Suzuki groups utilizes logarithmic signatures (LS)\nrestricted to the center of the group, resulting in an expansive array of\nlogarithmic signatures. We propose an encryption scheme based on\nmulti-parameter non-commutative groups, specifically selecting multi-parameter\ngeneralized Suzuki 2-groups as the group construction framework. In our\napproach, the logarithmic signature extends across the entire group, with\ncipher security dependent on the group order. This design enables the\ndevelopment of encryption optimized for implementation efficiency determined by\nlogarithmic signature size while maintaining robust security through\nappropriate key sizes and the finite field of group representation. The primary\ninnovation in our encryption implementation lies in the sequential\nde-encapsulation of keys from ciphertext using logarithmic signatures and\nassociated keys. The security evaluation of the cipher relies on attack\ncomplexity analysis, which is quantified through comprehensive key enumeration\nmethodologies.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-16T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11806v1","title":"Phase Separation in Active Binary Mixtures With Chemical Reaction","summary":"We study motility-induced phase separation~(MIPS) in active AB binary\nmixtures undergoing the chemical reaction $A \\rightleftharpoons B$. Starting\nfrom the evolution equations for the density fields $\\rho_i(\\vec r, t)$\ndescribing MIPS, we phenomenologically incorporate the effects of the reaction\nthrough the reaction rate $\\Gamma$ into the equations. The steady-state domain\nmorphologies depend on $\\Gamma$ and the relative activity of the species,\n$\\Delta$. For a sufficiently large $\\Gamma$ and $\\Delta\\ne 1$, the more active\ncomponent of the mixture forms a droplet morphology. We characterize the\nmorphology of domains by calculating the equal-time correlation function $C(r,\nt)$ and the structure factor $S(k, t)$, exhibiting scaling violation. The\naverage domain size, $L(t)$, follows a diffusive growth as $L(t)\\sim t^{1/3}$\nbefore reaching the steady state domain size, $L_{\\rm ss}$. Additionally,\n$L_{\\rm ss}$ shows the scaling relation $L_{\\rm ss}\\sim\\Gamma^{-1/4}$,\nindependent of $\\Delta$.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-16T06:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.11835v1","title":"Particle Data Cloning for Complex Ordinary Differential Equations","summary":"Ordinary differential equations (ODEs) are fundamental tools for modeling\ncomplex dynamic systems across scientific disciplines. However, parameter\nestimation in ODE models is challenging due to the multimodal nature of the\nlikelihood function, which can lead to local optima and unstable inference. In\nthis paper, we propose particle data cloning (PDC), a novel approach that\nenhances global optimization by leveraging data cloning and annealed sequential\nMonte Carlo (ASMC). PDC mitigates multimodality by refining the likelihood\nthrough data clones and progressively extracting information from the sharpened\nposterior. Compared to standard data cloning, PDC provides more reliable\nfrequentist inference and demonstrates superior global optimization\nperformance. We offer practical guidelines for efficient implementation and\nillustrate the method through simulation studies and an application to a\nprey-predator ODE model. Our implementation is available at\nhttps://github.com/SONDONGHUI/PDC.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T07:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.11842v1","title":"Bloch phonon-polaritons with anomalous dispersion in polaritonic Fourier\n  crystals","summary":"The recently suggested concept of a polaritonic Fourier crystal (PFC) is\nbased on a harmonically-corrugated mirror substrate for a thin pristine\npolaritonic crystal layer. The propagating polaritons in PFC experience a\nharmonic and mode-selective momentum modulation leading to a manifestation of\nBloch modes with practically zero inter-mode scattering. PFC was first\ndemonstrated for the hyperbolic phonon-polaritons in hexagonal boron nitride\n(hBN) within its Type II Reststrahlen band (RB-II) where the in-plane\ncomponents of the dielectric permittivity tensor are isotropic and negative,\nwhile the out-of-plane component is positive. By contrast, a Type I\nReststrahlen band (RB-I) is characterized by negative out-of-plane and positive\nin-plane permittivity components, and consequently, the inversion of field\nsymmetry of phonon-polaritons compared to RB-II. Behavior of such RB-I modes in\na polaritonic crystal is yet to be explored. Here, we employ a biaxial crystal\nalpha-phase molybdenum trioxide ({\\alpha}-MoO3) and near-field imaging to study\npolaritonic Bloch modes in a one-dimensional PFC within the RB-I where the\nmid-infrared phonon-polaritons in {\\alpha}-MoO3 have anomalous dispersion and\nnegative phase velocity. Surprisingly, we observe a manifestation of Bloch\nwaves as a dispersionless near-field pattern across the first Brillouin zone,\nin contrast to RB-II case demonstrated with in-plane isotropic hBN. We\nattribute this difference to the opposite field symmetry of the lowest-order\nphonon-polariton mode in the two RBs, leading to a different momentum\nmodulation regime in the polaritonic Fourier crystal. Our results reveal the\nimportance of mode symmetry for polaritonic crystals in general and for the\nemerging field of Fourier crystals in particular, which promise new ways to\nmanipulate the nanolight.","main_category":"physics.optics","categories":"physics.optics,cond-mat.other,physics.app-ph","published":"2025-04-16T08:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.11844v1","title":"Evaluating the Goal-Directedness of Large Language Models","summary":"To what extent do LLMs use their capabilities towards their given goal? We\ntake this as a measure of their goal-directedness. We evaluate\ngoal-directedness on tasks that require information gathering, cognitive\neffort, and plan execution, where we use subtasks to infer each model's\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\nand Anthropic show that goal-directedness is relatively consistent across\ntasks, differs from task performance, and is only moderately sensitive to\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\nour goal-directedness evaluations will enable better monitoring of LLM\nprogress, and enable more deliberate design choices of agentic properties in\nLLMs.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-16T08:07:08Z"}
{"aid":"http://arxiv.org/abs/2504.11854v1","title":"Less-excludable Mechanism for DAOs in Public Good Auctions","summary":"With the rise of smart contracts, decentralized autonomous organizations\n(DAOs) have emerged in public good auctions, allowing \"small\" bidders to gather\ntogether and enlarge their influence in high-valued auctions. However, models\nand mechanisms in the existing research literature do not guarantee\nnon-excludability, which is a main property of public goods. As such, some\nmembers of the winning DAO may be explicitly prevented from accessing the\npublic good. This side effect leads to regrouping of small bidders within the\nDAO to have a larger say in the final outcome. In particular, we provide a\npolynomial-time algorithm to compute the best regrouping of bidders that\nmaximizes the total bidding power of a DAO. We also prove that such a\nregrouping is less-excludable, better aligning the needs of the entire DAO and\nthe nature of public goods. Next, notice that members of a DAO in public good\nauctions often have a positive externality among themselves. Thus we introduce\na collective factor into the members' utility functions. We further extend the\nmechanism's allocation for each member to allow for partial access to the\npublic good. Under the new model, we propose a mechanism that is incentive\ncompatible in generic games and achieves higher social welfare as well as\nless-excludable allocations.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-16T08:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.11862v1","title":"Twist Grain Boundary phases in proper ferroelectric liquid crystals\n  realm","summary":"The twist-grain-boundary (TGB) phases, characterized by a periodic, helical\narrangement of blocks made of polar smectic phases, SmAF and SmCF, have been\ndiscovered. They have been observed for rod-like molecules with a strong\nlongitudinal dipole moment, featuring an (S)-2-methylbutyl end group having\nonly weak twisting power, and emerge below the antiferroelectric SmAAF phase,\nwhere the lamellar structure is already well established. It is suggested that\nthe structure is governed by electrostatic interactions amplified by weak\nchiral forces, in striking contrast to the mechanism of TGB phase formation\nfound in non-polar materials. The TGB phases exhibit light selective reflection\nin the visible range, while the value of electric polarization confirms an\nalmost perfectly ordered dipole alignment.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-16T08:36:48Z"}
{"aid":"http://arxiv.org/abs/2504.11872v1","title":"A Category-Fragment Segmentation Framework for Pelvic Fracture\n  Segmentation in X-ray Images","summary":"Pelvic fractures, often caused by high-impact trauma, frequently require\nsurgical intervention. Imaging techniques such as CT and 2D X-ray imaging are\nused to transfer the surgical plan to the operating room through image\nregistration, enabling quick intraoperative adjustments. Specifically,\nsegmenting pelvic fractures from 2D X-ray imaging can assist in accurately\npositioning bone fragments and guiding the placement of screws or metal plates.\nIn this study, we propose a novel deep learning-based category and fragment\nsegmentation (CFS) framework for the automatic segmentation of pelvic bone\nfragments in 2D X-ray images. The framework consists of three consecutive\nsteps: category segmentation, fragment segmentation, and post-processing. Our\nbest model achieves an IoU of 0.91 for anatomical structures and 0.78 for\nfracture segmentation. Results demonstrate that the CFS framework is effective\nand accurate.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.11883v1","title":"Quantum Optical Spanner: Twisting Superconductors with Vortex Beam via\n  Higgs Mode","summary":"Light carrying orbital angular momentum (OAM)--known as vortex beams--has\nbroadened the scope of understanding and applications of light's angular\nmomentum. Optical tweezers using OAM, often referred to as optical spanners,\nhave significantly expanded the tunability of optical manipulation. A key\nfrontier now lies in understanding how vortex beams interact with quantum\nstates of matter. In this work, we numerically investigate the dynamics of a\nsuperconductor under vortex beam illumination and demonstrate the transfer of\nangular momentum from light to the superconducting collective mode, resulting\nin mechanical rotation. Our findings open a pathway for optical manipulation in\nthe quantum regime, which we term the quantum optical spanner.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,physics.optics","published":"2025-04-16T09:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.11887v1","title":"Coherent States in Classical Field Theory","summary":"We illustrate the emergence of classical analogue of coherent state and its\ngeneralisation in a purely classical field theoretical setting. Our algebraic\napproach makes use of the Poisson bracket and symmetries of the underlying\nfield theory, in a complete parallel to the quantum construction. The classical\nphase space picture is found to play a key role in this construction.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-16T09:14:20Z"}
{"aid":"http://arxiv.org/abs/2504.11890v1","title":"A Novel Jet Model for the Novikov-Thorne Disk and its Observable Impact","summary":"Recent high-resolution observations have established a strong link between\nblack hole jets and accretion disk structures, particularly in the 3.5 mm\nwavelength band [Nature. 616, 686 (2023)]. In this work, we propose a\n``jet-modified Novikov-Thorne disk model'' that explicitly incorporates jet\nluminosity into the accretion disk radiation framework. By integrating\nsynchrotron radiation from relativistic electrons in the jet, we derive a\nmodified luminosity function that accounts for both the accretion disk and jet\ncontributions. Our analysis demonstrates that the inclusion of jet luminosity\nenhances the total accretion disk luminosity by approximately 33.5\\%, as\nderived from the integration of radiative flux. Furthermore, we compare our\nmodified model with the standard Novikov-Thorne model and find that the jet\ncontribution remains significant across different observational inclinations.\nThese results highlight the necessity of incorporating jet effects when\nestimating the observable flux of black hole accretion systems, which has\ndirect implications for future astronomical observations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T09:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11909v1","title":"Deflection of Light due to Kerr Sen Black Hole in Heterotic String\n  Theory using Material Medium Approach","summary":"The deflection of light in the gravitational field of a massive body can be\nanalyzed through diverse theoretical approaches. The null geodesic approach is\ncommonly employed to calculate light deflection within strong and weak field\nlimits. Alternatively, several studies have explored the gravitational\ndeflection of light using the material medium approach. For a static,\nnon-rotating spherical mass, the deflection in a Schwarzschild field can be\ndetermined by expressing the metric in an isotropic form and evaluating the\nrefractive index to trace the light ray's trajectory. In this study, we extend\nthe above-mentioned approach to the Kerr-Sen black hole spacetime in heterotic\nstring theory, a solution representing a rotating, charged solution in\nheterotic string theory. The frame-dragging effects inherent to the Kerr-Sen\ngeometry are incorporated to compute the velocity of light rays, enabling the\nderivation of the refractive index in this field. Considering the far-field\napproximation, we calculate the deflection of light in the Kerr-Sen spacetime\nand compare our results with those obtained for the Kerr and Schwarzschild\nblack hole solution in GR.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T09:40:01Z"}
{"aid":"http://arxiv.org/abs/2504.11915v1","title":"Starting the study of outer length billiards","summary":"We focus on the outer length billiard dynamics, acting on the exterior of a\nstrictly-convex planar domain. We first show that ellipses are totally\nintegrable. We then provide an explicit representation of first order terms for\nthe formal Taylor expansion of the corresponding Mather's $\\beta$-function.\nFinally, we provide explicit Lazutkin coordinates up to order 4.","main_category":"math.DS","categories":"math.DS","published":"2025-04-16T09:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.11924v1","title":"Topological Analysis of Mixer Activities in the Bitcoin Network","summary":"Cryptocurrency users increasingly rely on obfuscation techniques such as\nmixers, swappers, and decentralised or no-KYC exchanges to protect their\nanonymity. However, at the same time, these services are exploited by criminals\nto conceal and launder illicit funds. Among obfuscation services, mixers remain\none of the most challenging entities to tackle. This is because their owners\nare often unwilling to cooperate with Law Enforcement Agencies, and\ntechnically, they operate as 'black boxes'. To better understand their\nfunctionalities, this paper proposes an approach to analyse the operations of\nmixers by examining their address-transaction graphs and identifying\ntopological similarities to uncover common patterns that can define the mixer's\nmodus operandi. The approach utilises community detection algorithms to extract\ndense topological structures and clustering algorithms to group similar\ncommunities. The analysis is further enriched by incorporating data from\nexternal sources related to known Exchanges, in order to understand their role\nin mixer operations. The approach is applied to dissect the Blender.io mixer\nactivities within the Bitcoin blockchain, revealing: i) consistent structural\npatterns across address-transaction graphs; ii) that Exchanges play a key role,\nfollowing a well-established pattern, which raises several concerns about their\nAML/KYC policies. This paper represents an initial step toward dissecting and\nunderstanding the complex nature of mixer operations in cryptocurrency networks\nand extracting their modus operandi.","main_category":"cs.CR","categories":"cs.CR,cs.CE,cs.SI","published":"2025-04-16T09:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.11980v1","title":"Characterizing physical and logical errors in a transversal CNOT via\n  cycle error reconstruction","summary":"The development of prototype quantum information processors has progressed to\na stage where small instances of logical qubit systems perform better than the\nbest of their physical constituents. Advancing towards fault-tolerant quantum\ncomputing will require an understanding of the underlying error mechanisms in\nlogical primitives as they relate to the performance of quantum error\ncorrection. In this work we demonstrate the novel capability to characterize\nthe physical error properties relevant to fault-tolerant operations via cycle\nerror reconstruction. We illustrate this diagnostic capability for a\ntransversal CNOT, a prototypical component of quantum logical operations, in a\n16-qubit register of a trapped-ion quantum computer. Our error characterization\ntechnique offers three key capabilities: (i) identifying context-dependent\nphysical layer errors, enabling their mitigation; (ii) contextualizing\ncomponent gates in the environment of logical operators, validating the\nperformance differences in terms of characterized component-level physics, and\n(iii) providing a scalable method for predicting quantum error correction\nperformance using pertinent error terms, differentiating correctable versus\nuncorrectable physical layer errors. The methods with which our results are\nobtained have scalable resource requirements that can be extended with moderate\noverhead to capture overall logical performance in increasingly large and\ncomplex systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T11:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.12012v1","title":"Purposefully Induced Psychosis (PIP): Embracing Hallucination as\n  Imagination in Large Language Models","summary":"Hallucinations in Large Language Models (LLMs) are widely regarded as errors\n- outputs that deviate from factual accuracy. However, in creative or\nexploratory contexts, these \"mistakes\" may represent unexpected avenues for\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\nHerman Melville's Moby-Dick, where Pip's \"madness\" reveals profound insight, we\nreframe hallucinations as a source of computational imagination rather than a\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\nsurreal outputs - hallucinations that are useful when factual accuracy is not\nthe chief objective. Inspired by the consensual illusions of theater and stage\nmagic, PIP situates these creative missteps in contexts where users willingly\nsuspend disbelief, thereby transforming \"errors\" into catalysts for new ways of\nthinking. We discuss potential applications, design principles for ensuring\nuser consent, preliminary observations, and implications for broader AI ethics\nand human-AI collaboration.","main_category":"cs.AI","categories":"cs.AI,cs.HC","published":"2025-04-16T12:13:02Z"}
{"aid":"http://arxiv.org/abs/2504.12029v1","title":"Object Placement for Anything","summary":"Object placement aims to determine the appropriate placement (\\emph{e.g.},\nlocation and size) of a foreground object when placing it on the background\nimage. Most previous works are limited by small-scale labeled dataset, which\nhinders the real-world application of object placement. In this work, we devise\na semi-supervised framework which can exploit large-scale unlabeled dataset to\npromote the generalization ability of discriminative object placement models.\nThe discriminative models predict the rationality label for each foreground\nplacement given a foreground-background pair. To better leverage the labeled\ndata, under the semi-supervised framework, we further propose to transfer the\nknowledge of rationality variation, \\emph{i.e.}, whether the change of\nforeground placement would result in the change of rationality label, from\nlabeled data to unlabeled data. Extensive experiments demonstrate that our\nframework can effectively enhance the generalization ability of discriminative\nobject placement models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:39:00Z"}
{"aid":"http://arxiv.org/abs/2504.12030v1","title":"Planetary albedo is limited by the above-cloud atmosphere: Implications\n  for sub-Neptune climate","summary":"Energy limits that delineate the `habitable zone' for exoplanets depend on a\ngiven exoplanet's net planetary albedo (or `Bond albedo'). We here demonstrate\nthat the planetary albedo of an observed exoplanet is limited by the\nabove-cloud atmosphere - the region of the atmosphere that is probed in remote\nobservation. We derive an analytic model to explore how the maximum planetary\nalbedo depends on the above-cloud optical depth and scattering versus absorbing\nproperties, even in the limit of a perfectly reflective grey cloud layer. We\napply this framework to sub-Neptune K2-18b, for which a high planetary albedo\nhas recently been invoked to argue for the possibility of maintaining a liquid\nwater ocean surface, despite K2-18b receiving an energy flux from its host star\nthat places it inside of its estimated `habitable zone' inner edge. We use a\nnumerical multiple-scattering line-by-line radiative transfer model to retrieve\nthe albedo of K2-18b based on the observational constraints from the\nabove-cloud atmosphere. Our results demonstrate that K2-18b's observed\ntransmission spectrum already restricts its possible planetary albedo to values\nbelow the threshold required to be potentially habitable, with the data\nfavouring a median planetary albedo of 0.17-0.18. Our results thus reveal that\ncurrently characteriseable sub-Neptunes are likely to be magma-ocean or\ngas-dwarf worlds. The methods that we present are generally applicable to\nconstrain the planetary albedo of any exoplanet with measurements of its\nobservable atmosphere, enabling the quantification of potential exoplanet\nhabitability with current observational capabilities.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T12:39:54Z"}
{"aid":"http://arxiv.org/abs/2504.12058v1","title":"ProvSQL: A General System for Keeping Track of the Provenance and\n  Probability of Data","summary":"We present the data model, design choices, and performance of ProvSQL, a\ngeneral and easy-to-deploy provenance tracking and probabilistic database\nsystem implemented as a PostgreSQL extension. ProvSQL's data and query models\nclosely reflect that of a large core of SQL, including multiset semantics, the\nfull relational algebra, and terminal aggregation. A key part of its\nimplementation relies on generic provenance circuits stored in memory-mapped\nfiles. We propose benchmarks to measure the overhead of provenance and\nprobabilistic evaluation and demonstrate its scalability and competitiveness\nwith respect to other state-of-the-art systems.","main_category":"cs.DB","categories":"cs.DB,H.2.4","published":"2025-04-16T13:11:07Z"}
{"aid":"http://arxiv.org/abs/2504.12080v1","title":"DC-SAM: In-Context Segment Anything in Images and Videos via Dual\n  Consistency","summary":"Given a single labeled example, in-context segmentation aims to segment\ncorresponding objects. This setting, known as one-shot segmentation in few-shot\nlearning, explores the segmentation model's generalization ability and has been\napplied to various vision tasks, including scene understanding and image/video\nediting. While recent Segment Anything Models have achieved state-of-the-art\nresults in interactive segmentation, these approaches are not directly\napplicable to in-context segmentation. In this work, we propose the Dual\nConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2\nfor in-context segmentation of both images and videos. Our key insights are to\nenhance the features of the SAM's prompt encoder in segmentation by providing\nhigh-quality visual prompts. When generating a mask prior, we fuse the SAM\nfeatures to better align the prompt encoder. Then, we design a cycle-consistent\ncross-attention on fused features and initial visual prompts. Next, a\ndual-branch design is provided by using the discriminative positive and\nnegative prompts in the prompt encoder. Furthermore, we design a simple\nmask-tube training strategy to adopt our proposed dual consistency method into\nthe mask tube. Although the proposed DC-SAM is primarily designed for images,\nit can be seamlessly extended to the video domain with the support of SAM2.\nGiven the absence of in-context segmentation in the video domain, we manually\ncurate and construct the first benchmark from existing video segmentation\ndatasets, named In-Context Video Object Segmentation (IC-VOS), to better assess\nthe in-context capability of the model. Extensive experiments demonstrate that\nour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on\nPASCAL-5i, and a J&F score of 71.52 on the proposed IC-VOS benchmark. Our\nsource code and benchmark are available at https://github.com/zaplm/DC-SAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T13:41:59Z"}
{"aid":"http://arxiv.org/abs/2504.12089v1","title":"Accelerating MCMC with Quantum Walks: Design, Implementation, and\n  Results","summary":"Markov Chain Monte Carlo (MCMC) methods are algorithms for sampling\nprobability distributions, often applied to the Boltzmann distribution in\nphysical and chemical models, such as protein folding and the Ising model.\nThese methods enable the study of such systems by sampling their most probable\nstates. However, sampling multidimensional and multimodal distributions with\nMCMC demands significant computational resources, leading to the development of\ntechniques aimed at improving sampling efficiency. In this context, quantum\ncomputing, with its potential to accelerate classical methods, emerges as a\npromising solution to the sampling problem. In this work, we present the design\nand implementation of a novel MCMC algorithm (QMCMC) based on the Discrete\nQuantum Walk (DQW) algorithm. We test several Gaussian distributions, including\nmixtures and demonstrate that it effectively captures the structure of the\ntarget distribution by leveraging quantum superposition. In addition, we\nintroduce a circuit extension that significantly improves convergence speed,\nwhich in turn enhances the scalability of the algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.12102v1","title":"Successive-Cancellation Flip and Perturbation Decoder of Polar Codes","summary":"In this paper, two decoding algorithms based on Successive Cancellation (SC)\nare proposed to improve the error-correction performance of cyclic redundancy\ncheck (CRC)-aided polar codes while aiming for a low-complexity implementation.\nComparisons with Dynamic SC Flip (DSCF) and SC Perturbation (SCP) are carried\nout since the proposed DSCF and Perturbation (DSCFP) and Perturbed DSCF (PDSCF)\nalgorithms combine both methods. The analysis includes comparisons with several\ncode lengths $N$ and various number of decoding attempts $T_{max}$. For\n$N=1024$ and the coding rate $R=\\frac{1}{2}$, the DSCFP and the SCP algorithms\nwith $T_{max}=17$ are bested by approximately $0.1$\\,dB at block error rate\n(BLER) of $0.001$. At $\\text{BLER}=10^{-6}$ and for $T_{max}=64$, the gain is\nof $0.375$ dB and $>0.5$ dB with respect to DSCF and SCP, respectively. At high\nsignal-to-noise ratio, the average computational complexity of the proposed\nalgorithms is virtually equivalent to that of SC.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T14:08:25Z"}
{"aid":"http://arxiv.org/abs/2504.12112v1","title":"A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image\n  Reconstruction","summary":"Remote sensing imagery is essential for environmental monitoring,\nagricultural management, and disaster response. However, data loss due to cloud\ncover, sensor failures, or incomplete acquisition-especially in high-resolution\nand high-frequency tasks-severely limits satellite imagery's effectiveness.\nTraditional interpolation methods struggle with large missing areas and complex\nstructures. Remote sensing imagery consists of multiple bands, each with\ndistinct meanings, and ensuring consistency across bands is critical to avoid\nanomalies in the combined images. This paper proposes SatelliteMaker, a\ndiffusion-based method that reconstructs missing data across varying levels of\ndata loss while maintaining spatial, spectral, and temporal consistency. We\nalso propose Digital Elevation Model (DEM) as a conditioning input and use\ntailored prompts to generate realistic images, making diffusion models\napplicable to quantitative remote sensing tasks. Additionally, we propose a\nVGG-Adapter module based on Distribution Loss, which reduces distribution\ndiscrepancy and ensures style consistency. Extensive experiments show that\nSatelliteMaker achieves state-of-the-art performance across multiple tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.12125v1","title":"EmoACT: a Framework to Embed Emotions into Artificial Agents Based on\n  Affect Control Theory","summary":"As robots and artificial agents become increasingly integrated into daily\nlife, enhancing their ability to interact with humans is essential. Emotions,\nwhich play a crucial role in human interactions, can improve the naturalness\nand transparency of human-robot interactions (HRI) when embodied in artificial\nagents. This study aims to employ Affect Control Theory (ACT), a psychological\nmodel of emotions deeply rooted in interaction, for the generation of synthetic\nemotions. A platform-agnostic framework inspired by ACT was developed and\nimplemented in a humanoid robot to assess its impact on human perception.\nResults show that the frequency of emotional displays impacts how users\nperceive the robot. Moreover, appropriate emotional expressions seem to enhance\nthe robot's perceived emotional and cognitive agency. The findings suggest that\nACT can be successfully employed to embed synthetic emotions into robots,\nresulting in effective human-robot interactions, where the robot is perceived\nmore as a social agent than merely a machine.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.12160v1","title":"On the counting function of cubic function fields","summary":"We study the counting function for cubic function fields, extending results\nof Zhao, who proved the existence of a secondary term in this counting\nfunction. Specifically, we improve the error term in the estimate for this\ncounting function to $\\mathcal{O}\\big(X^{2/3+\\epsilon}\\big)$, which matches the\nbest-known result, due to Bhargava, Taniguchi and Thorne, over $\\mathbb{Q}$.\nFurthermore, we obtain estimates for the refined counting function, where one\nspecifies the splitting behaviour of finitely many primes. Also in this case,\nour error term matches what is known for number fields. However, in the\nfunction field setting, the secondary term becomes more difficult to write down\nexplicitly.\n  Our proof uses geometry of numbers methods, which are especially effective\nfor function fields. In particular, we obtain an exact formula for the number\nof orbits of cubic forms with fixed absolute discriminant. Moreover, by\nstudying the one-level density of a family of Artin $L$-functions associated to\nthese cubic fields, we prove an unconditional lower bound on the error term in\nthe estimate for the refined counting function. This generalises a conditional\nresult over $\\mathbb{Q}$, due to Cho, Fiorilli, Lee and S\\\"odergren.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T15:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.12178v1","title":"Search for additional scalar bosons within the Inert Doublet Model in a\n  final state with two leptons at the FCC-ee","summary":"In this work, we investigate the discovery reach of a new physics model, the\nInert Doublet Model, at an $e^+e^-$ machine with centre-of-mass energies\n$\\sqrt{s}$ of 240 and 365 GeV. Within this model, four additional scalar bosons\n($H$, $A$, $H^+$ and $H^-$) are predicted. Due to an additional symmetry, the\nlightest new scalar, here chosen to be $H$, is stable and provides an adequate\ndark matter candidate. The search for pair production of the new scalars is\ninvestigated in final states with two electrons or two muons, in the context of\nthe future circular collider proposal, FCC-ee. Building on previous studies in\nthe context of the CLIC proposal, this analysis extends the search to\ndetector-level objects, using a parametric neural network to enhance the signal\ncontributions over the Standard Model backgrounds, and sets limits in the\n$m_A-m_H$ vs $m_H$ plane. With a total integrated luminosity of 10.8 (2.7)\nab$^{-1}$ for $\\sqrt{s}=240$ (365) GeV, almost the entire phase-space available\nin the $m_A-m_H$ vs $m_H$ plane is expected to be excluded at 95% CL, reaching\nup to $m_H=110$ (165) GeV. The discovery reach is also explored, reaching $m_H=\n108$ (157) GeV for $m_A-m_H=15$ GeV at $\\sqrt{s}=240$ (365) GeV.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-16T15:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.12180v1","title":"Trusting CHATGPT: how minor tweaks in the prompts lead to major\n  differences in sentiment classification","summary":"One fundamental question for the social sciences today is: how much can we\ntrust highly complex predictive models like ChatGPT? This study tests the\nhypothesis that subtle changes in the structure of prompts do not produce\nsignificant variations in the classification results of sentiment polarity\nanalysis generated by the Large Language Model GPT-4o mini. Using a dataset of\n100.000 comments in Spanish on four Latin American presidents, the model\nclassified the comments as positive, negative, or neutral on 10 occasions,\nvarying the prompts slightly each time. The experimental methodology included\nexploratory and confirmatory analyses to identify significant discrepancies\namong classifications.\n  The results reveal that even minor modifications to prompts such as lexical,\nsyntactic, or modal changes, or even their lack of structure impact the\nclassifications. In certain cases, the model produced inconsistent responses,\nsuch as mixing categories, providing unsolicited explanations, or using\nlanguages other than Spanish. Statistical analysis using Chi-square tests\nconfirmed significant differences in most comparisons between prompts, except\nin one case where linguistic structures were highly similar.\n  These findings challenge the robustness and trust of Large Language Models\nfor classification tasks, highlighting their vulnerability to variations in\ninstructions. Moreover, it was evident that the lack of structured grammar in\nprompts increases the frequency of hallucinations. The discussion underscores\nthat trust in Large Language Models is based not only on technical performance\nbut also on the social and institutional relationships underpinning their use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.12228v1","title":"Data Assimilation for Robust UQ Within Agent-Based Simulation on HPC\n  Systems","summary":"Agent-based simulation provides a powerful tool for in silico system\nmodeling. However, these simulations do not provide built-in methods for\nuncertainty quantification (UQ). Within these types of models a typical\napproach to UQ is to run multiple realizations of the model then compute\naggregate statistics. This approach is limited due to the compute time required\nfor a solution. When faced with an emerging biothreat, public health decisions\nneed to be made quickly and solutions for integrating near real-time data with\nanalytic tools are needed.\n  We propose an integrated Bayesian UQ framework for agent-based models based\non sequential Monte Carlo sampling. Given streaming or static data about the\nevolution of an emerging pathogen, this Bayesian framework provides a\ndistribution over the parameters governing the spread of a disease through a\npopulation. These estimates of the spread of a disease may be provided to\npublic health agencies seeking to abate the spread.\n  By coupling agent-based simulations with Bayesian modeling in a data\nassimilation, our proposed framework provides a powerful tool for modeling\ndynamical systems in silico. We propose a method which reduces model error and\nprovides a range of realistic possible outcomes. Moreover, our method addresses\ntwo primary limitations of ABMs: the lack of UQ and an inability to assimilate\ndata. Our proposed framework combines the flexibility of an agent-based model\nwith UQ provided by the Bayesian paradigm in a workflow which scales well to\nHPC systems. We provide algorithmic details and results on a simulated outbreak\nwith both static and streaming data.","main_category":"stat.AP","categories":"stat.AP,stat.CO","published":"2025-04-16T16:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.12252v1","title":"Electric field tunable spin-orbit gap in a bilayer graphene/WSe$_{2}$\n  quantum dot","summary":"We report on the investigation of proximity-induced spin-orbit coupling (SOC)\nin a heterostructure of bilayer graphene (BLG) and tungsten diselenide\n(WSe$_2$). A BLG quantum dot (QD) in the few-particle regime acts as a\nsensitive probe for induced SOC. Finite bias and magnetotransport spectroscopy\nmeasurements reveal a significantly enhanced SOC that decreases with the\napplied displacement field, distinguishing it from pristine BLG. We attribute\nthis tunability to an increased layer localization of the QD states on the BLG\nlayer distant to the WSe$_2$. Furthermore, our measurements demonstrate a\nreduced valley $g$-factor at larger displacement fields, consistent with a\nweaker lateral confinement of the QD. Our findings show evidence of the\ninfluence of WSe$_2$ across BLG layers, driven by reduced real-space\nconfinement and increased layer localization at higher displacement fields.\nThis study demonstrates the electrostatic tunability of spin-orbit gap in\nBLG/WSe$_2$ heterostructures, which is especially relevant for the field of\nspintronics and future spin qubit control in BLG QDs.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-16T16:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.12288v1","title":"The underlap coefficient as a measure of a biomarker's discriminatory\n  ability","summary":"The first step in evaluating a potential diagnostic biomarker is to examine\nthe variation in its values across different disease groups. In a three-class\ndisease setting, the volume under the receiver operating characteristic surface\nand the three-class Youden index are commonly used summary measures of a\nbiomarker's discriminatory ability. However, these measures rely on a\nstochastic ordering assumption for the distributions of biomarker outcomes\nacross the three groups. This assumption can be restrictive, particularly when\ncovariates are involved, and its violation may lead to incorrect conclusions\nabout a biomarker's ability to distinguish between the three disease classes.\nEven when a stochastic ordering exists, the order may vary across different\nbiomarkers in discovery studies involving dozens or even thousands of candidate\nbiomarkers, complicating automated ranking. To address these challenges and\ncomplement existing measures, we propose the underlap coefficient, a novel\nsummary index of a biomarker's ability to distinguish between three (or more)\ndisease groups, and study its properties. Additionally, we introduce Bayesian\nnonparametric estimators for both the unconditional underlap coefficient and\nits covariate-specific counterpart. These estimators are broadly applicable to\na wide range of biomarkers and populations. A simulation study reveals a good\nperformance of the proposed estimators across a range of conceivable scenarios.\nWe illustrate the proposed approach through an application to an Alzheimer's\ndisease (AD) dataset aimed to assess how four potential AD biomarkers\ndistinguish between individuals with normal cognition, mild impairment, and\ndementia, and how and if age and gender impact this discriminatory ability.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T17:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.12299v1","title":"Adapting a World Model for Trajectory Following in a 3D Game","summary":"Imitation learning is a powerful tool for training agents by leveraging\nexpert knowledge, and being able to replicate a given trajectory is an integral\npart of it. In complex environments, like modern 3D video games, distribution\nshift and stochasticity necessitate robust approaches beyond simple action\nreplay. In this study, we apply Inverse Dynamics Models (IDM) with different\nencoders and policy heads to trajectory following in a modern 3D video game --\nBleeding Edge. Additionally, we investigate several future alignment strategies\nthat address the distribution shift caused by the aleatoric uncertainty and\nimperfections of the agent. We measure both the trajectory deviation distance\nand the first significant deviation point between the reference and the agent's\ntrajectory and show that the optimal configuration depends on the chosen\nsetting. Our results show that in a diverse data setting, a GPT-style policy\nhead with an encoder trained from scratch performs the best, DINOv2 encoder\nwith the GPT-style policy head gives the best results in the low data regime,\nand both GPT-style and MLP-style policy heads had comparable results when\npre-trained on a diverse setting and fine-tuned for a specific behaviour\nsetting.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-16T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.12614v1","title":"From Regulation to Support: Centering Humans in Technology-Mediated\n  Emotion Intervention in Care Contexts","summary":"Enhancing emotional well-being has become a significant focus in HCI and\nCSCW, with technologies increasingly designed to track, visualize, and manage\nemotions. However, these approaches have faced criticism for potentially\nsuppressing certain emotional experiences. Through a scoping review of 53\nempirical studies from ACM proceedings implementing Technology-Mediated Emotion\nIntervention (TMEI), we critically examine current practices through lenses\ndrawn from HCI critical theories. Our analysis reveals emotion intervention\nmechanisms that extend beyond traditional emotion regulation paradigms,\nidentifying care-centered goals that prioritize non-judgmental emotional\nsupport and preserve users' identities. The findings demonstrate how\nresearchers design technologies for generating artificial care, intervening in\npower dynamics, and nudging behavioral changes. We contribute the concept of\n\"emotion support\" as an alternative approach to \"emotion regulation,\"\nemphasizing human-centered approaches to emotional well-being. This work\nadvances the understanding of diverse human emotional needs beyond individual\nand cognitive perspectives, offering design implications that critically\nreimagine how technologies can honor emotional complexity, preserve human\nagency, and transform power dynamics in care contexts.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T03:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.12623v1","title":"Privacy-Preserving CNN Training with Transfer Learning: Two Hidden\n  Layers","summary":"In this paper, we present the demonstration of training a four-layer neural\nnetwork entirely using fully homomorphic encryption (FHE), supporting both\nsingle-output and multi-output classification tasks in a non-interactive\nsetting. A key contribution of our work is identifying that replacing\n\\textit{Softmax} with \\textit{Sigmoid}, in conjunction with the Binary\nCross-Entropy (BCE) loss function, provides an effective and scalable solution\nfor homomorphic classification. Moreover, we show that the BCE loss function,\noriginally designed for multi-output tasks, naturally extends to the\nmulti-class setting, thereby enabling broader applicability. We also highlight\nthe limitations of prior loss functions such as the SLE loss and the one\nproposed in the 2019 CVPR Workshop, both of which suffer from vanishing\ngradients as network depth increases. To address the challenges posed by\nlarge-scale encrypted data, we further introduce an improved version of the\npreviously proposed data encoding scheme, \\textit{Double Volley Revolver},\nwhich achieves a better trade-off between computational and memory efficiency,\nmaking FHE-based neural network training more practical. The complete, runnable\nC++ code to implement our work can be found at:\n\\href{https://github.com/petitioner/ML.NNtraining}{$\\texttt{https://github.com/petitioner/ML.NNtraining}$}.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T03:58:23Z"}
{"aid":"http://arxiv.org/abs/2504.12634v1","title":"Toponium: Implementation of a toponium model in FeynRules","summary":"Toponium -- a bound state of the top-antitop pair ($t\\bar{t}$) -- emerges as\nthe smallest and simplest hadronic system in QCD, with an ultrashort lifetime\n($\\tau_t \\sim 2.5\\times 10^{-25}$~s) and a femtometer-scale Bohr radius\n($r_{\\text{Bohr}} \\sim 7\\times 10^{-18}$~m). We present a computational\nframework extending the Standard Model (SM) with two S-wave toponium states: a\nspin-singlet $\\eta_t$ ($J^{PC}=0^{-+}$) and a spin-triplet $J_t$\n($J^{PC}=1^{--}$). Using nonrelativistic QCD (NRQCD) and a Coulomb potential,\nwe derived couplings to SM particles (gluons, electroweak bosons, Higgs boson,\nand fermion pairs) and implemented the Lagrangian in FeynRules, generating\nFeynArts, MadGraph, and WHIZARD models for collider simulations. Key results\ninclude dominant decay channels ($\\eta_t \\to gg/ZH$, $J_t \\to W^+W^-/b\\bar{b}$)\nand leading order (LO) cross sections for $pp \\to \\eta_t(nS) \\to {\\rm\nnon-}t\\bar{t}$ ({66 fb} at 13 TeV). The model avoids double-counting artifacts\nby excluding direct $t\\bar{t}$ couplings, thereby ensuring consistency with\nperturbative QCD. This work establishes a complete pipeline for precision\ntoponium studies, bridging NRQCD, collider phenomenology, and tests of SM\nvalidity at future lepton colliders (e.g., CEPC, FCC-ee, muon colliders) and\nthe LHC. This provides the first publicly available UFO model for toponium,\nenabling direct integration with MadGraph and WHIZARD for simulations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T04:31:54Z"}
{"aid":"http://arxiv.org/abs/2504.12671v1","title":"Generalized Legendrian racks: Classification, tensors, and knot coloring\n  invariants","summary":"Generalized Legendrian racks are nonassociative algebraic structures based on\nthe Legendrian Reidemeister moves. We study algebraic aspects of GL-racks and\ncoloring invariants of Legendrian links.\n  We answer an open question characterizing the group of GL-structures on a\ngiven rack. As applications, we classify several infinite families of GL-racks.\nWe also compute automorphism groups of dihedral GL-quandles and the categorical\ncenter of GL-racks.\n  Then we construct an equivalence of categories between racks and GL-quandles.\n  We also study tensor products of racks and GL-racks coming from universal\nalgebra. Surprisingly, the categories of racks and GL-racks have tensor units.\nThe induced symmetric monoidal structure on medial racks is closed, and\nsimilarly for medial GL-racks.\n  Answering another open question, we use GL-racks to distinguish Legendrian\nknots whose classical invariants are identical. In particular, we complete the\nclassification of Legendrian $8_{13}$ knots.\n  Finally, we use exhaustive search algorithms to classify GL-racks up to order\n8.","main_category":"math.GT","categories":"math.GT,math.GR,math.QA","published":"2025-04-17T06:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.12685v1","title":"High Breakdown Electric Field (> 5 MV/cm) in UWBG AlGaN Transistors","summary":"We report on the design and demonstration of ultra-wide bandgap (UWBG)\nAlGaN-channel metal-insulator heterostructure field effect transistors (HEFTs)\nfor high-power, high-frequency applications. We find that the integration of\ngate dielectrics and field plates greatly improves the breakdown field in these\ndevices, with state-of-art average breakdown field of 5.3 MV/cm (breakdown\nvoltage > 260 V) with an associated maximum current density of 342 mA/mm, and\ncut-off frequency of 9.1 GHz. Furthermore, low trap-related impact was observed\nfrom minimal gate and drain lag estimated from pulsed I-V characteristics. The\nreported results provide the potential of UWBG AlGaN HEFTs for the next\ngeneration high-power radio frequency applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-17T06:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.12708v1","title":"Ultrafast dynamics of vibronically dressed core-excitons in graphite: a\n  femtosecond RIXS perspective","summary":"This study demonstrates one of the first implementations of time-resolved\nresonant inelastic X-ray scattering (tr-RIXS), marking a seminal extension of\nRIXS spectroscopy into the ultrafast time domain. By investigating the\nultrafast dynamics of vibronically dressed core excitons in graphite using\nfemtosecond X-ray pulses from a Free Electron Laser, we reveal previously\ninaccessible insights into the transient coupling between core excitons and\nspecific optical phonon modes. Our approach establishes tr-RIXS as a powerful,\ntransformative tool capable of elucidating the intricate interplay between\nelectronic and lattice dynamics, opening new avenues in ultrafast materials\nresearch.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T07:25:38Z"}
{"aid":"http://arxiv.org/abs/2504.12723v1","title":"KODIS: A Multicultural Dispute Resolution Dialogue Corpus","summary":"We present KODIS, a dyadic dispute resolution corpus containing thousands of\ndialogues from over 75 countries. Motivated by a theoretical model of culture\nand conflict, participants engage in a typical customer service dispute\ndesigned by experts to evoke strong emotions and conflict. The corpus contains\na rich set of dispositional, process, and outcome measures. The initial\nanalysis supports theories of how anger expressions lead to escalatory spirals\nand highlights cultural differences in emotional expression. We make this\ncorpus and data collection framework available to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T07:57:31Z"}
{"aid":"http://arxiv.org/abs/2504.12744v1","title":"Biasing the Driving Style of an Artificial Race Driver for Online\n  Time-Optimal Maneuver Planning","summary":"In this work, we present a novel approach to bias the driving style of an\nartificial race driver (ARD) for online time-optimal trajectory planning. Our\nmethod leverages a nonlinear model predictive control (MPC) framework that\ncombines time minimization with exit speed maximization at the end of the\nplanning horizon. We introduce a new MPC terminal cost formulation based on the\ntrajectory planned in the previous MPC step, enabling ARD to adapt its driving\nstyle from early to late apex maneuvers in real-time. Our approach is\ncomputationally efficient, allowing for low replan times and long planning\nhorizons. We validate our method through simulations, comparing the results\nagainst offline minimum-lap-time (MLT) optimal control and online minimum-time\nMPC solutions. The results demonstrate that our new terminal cost enables ARD\nto bias its driving style, and achieve online lap times close to the MLT\nsolution and faster than the minimum-time MPC solution. Our approach paves the\nway for a better understanding of the reasons behind human drivers' choice of\nearly or late apex maneuvers.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T08:35:28Z"}
{"aid":"http://arxiv.org/abs/2504.12801v1","title":"Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch","summary":"The performance gap between training sparse neural networks from scratch\n(PaI) and dense-to-sparse training presents a major roadblock for efficient\ndeep learning. According to the Lottery Ticket Hypothesis, PaI hinges on\nfinding a problem specific parameter initialization. As we show, to this end,\ndetermining correct parameter signs is sufficient. Yet, they remain elusive to\nPaI. To address this issue, we propose Sign-In, which employs a dynamic\nreparameterization that provably induces sign flips. Such sign flips are\ncomplementary to the ones that dense-to-sparse training can accomplish,\nrendering Sign-In as an orthogonal method. While our experiments and theory\nsuggest performance improvements of PaI, they also carve out the main open\nchallenge to close the gap between PaI and dense-to-sparse training.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-17T10:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.12826v1","title":"UncAD: Towards Safe End-to-end Autonomous Driving via Online Map\n  Uncertainty","summary":"End-to-end autonomous driving aims to produce planning trajectories from raw\nsensors directly. Currently, most approaches integrate perception, prediction,\nand planning modules into a fully differentiable network, promising great\nscalability. However, these methods typically rely on deterministic modeling of\nonline maps in the perception module for guiding or constraining vehicle\nplanning, which may incorporate erroneous perception information and further\ncompromise planning safety. To address this issue, we delve into the importance\nof online map uncertainty for enhancing autonomous driving safety and propose a\nnovel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty\nof the online map in the perception module. It then leverages the uncertainty\nto guide motion prediction and planning modules to produce multi-modal\ntrajectories. Finally, to achieve safer autonomous driving, UncAD proposes an\nuncertainty-collision-aware planning selection strategy according to the online\nmap uncertainty to evaluate and select the best trajectory. In this study, we\nincorporate UncAD into various state-of-the-art (SOTA) end-to-end methods.\nExperiments on the nuScenes dataset show that integrating UncAD, with only a\n1.9% increase in parameters, can reduce collision rates by up to 26% and\ndrivable area conflict rate by up to 42%. Codes, pre-trained models, and demo\nvideos can be accessed at https://github.com/pengxuanyang/UncAD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-17T10:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.12839v1","title":"Whitney Approximation: domains and bounds","summary":"We investigate properties of holomorphic extensions in the one-variable case\nof Whitney's Approximation Theorem on intervals. Improving a result of\nGauthier-Kienzle, we construct tangentially approximating functions which\nextend holomorphically to domains of optimal size. For approximands on\nunbounded closed intervals, we also bound the growth of holomorphic extensions,\nin the spirit of Arakelyan, Bernstein, Keldych, and Kober.","main_category":"math.CV","categories":"math.CV,math.CA","published":"2025-04-17T10:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.12882v1","title":"ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection\n  in Videos","summary":"The growing influence of video content as a medium for communication and\nmisinformation underscores the urgent need for effective tools to analyze\nclaims in multilingual and multi-topic settings. Existing efforts in\nmisinformation detection largely focus on written text, leaving a significant\ngap in addressing the complexity of spoken text in video transcripts. We\nintroduce ViClaim, a dataset of 1,798 annotated video transcripts across three\nlanguages (English, German, Spanish) and six topics. Each sentence in the\ntranscripts is labeled with three claim-related categories: fact-check-worthy,\nfact-non-check-worthy, or opinion. We developed a custom annotation tool to\nfacilitate the highly complex annotation process. Experiments with\nstate-of-the-art multilingual language models demonstrate strong performance in\ncross-validation (macro F1 up to 0.896) but reveal challenges in generalization\nto unseen topics, particularly for distinct domains. Our findings highlight the\ncomplexity of claim detection in video transcripts. ViClaim offers a robust\nfoundation for advancing misinformation detection in video-based communication,\naddressing a critical gap in multimodal analysis.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T12:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.12883v1","title":"Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?","summary":"Implicit bias plays an important role in explaining how overparameterized\nmodels generalize well. Explicit regularization like weight decay is often\nemployed in addition to prevent overfitting. While both concepts have been\nstudied separately, in practice, they often act in tandem. Understanding their\ninterplay is key to controlling the shape and strength of implicit bias, as it\ncan be modified by explicit regularization. To this end, we incorporate\nexplicit regularization into the mirror flow framework and analyze its lasting\neffects on the geometry of the training dynamics, covering three distinct\neffects: positional bias, type of bias, and range shrinking. Our analytical\napproach encompasses a broad class of problems, including sparse coding, matrix\nsensing, single-layer attention, and LoRA, for which we demonstrate the utility\nof our insights. To exploit the lasting effect of regularization and highlight\nthe potential benefit of dynamic weight decay schedules, we propose to switch\noff weight decay during training, which can improve generalization, as we\ndemonstrate in experiments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T12:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.12890v1","title":"Euclidean Thermodynamics and Lyapunov Exponents of\n  Einstein-Power-Yang-Mills AdS Black Holes","summary":"We study the thermodynamics of Einstein-Power-Yang-Mills AdS black holes via\nthe Euclidean path integral method, incorporating appropriate boundary and\ncounterterms. By analyzing unstable timelike and null circular geodesics, we\ndemonstrate that their Lyapunov exponents reflect the thermodynamic phase\nstructure obtained from the Euclidean action. Specifically, the small-large\nblack hole phase transition, analogous to a van der Waals fluid, is signaled by\na discontinuity in the Lyapunov exponent. Treating this discontinuity as an\norder parameter, we observe a universal critical exponent of $1/2$, consistent\nwith mean-field theory. These results extend previous insights from black hole\nspacetimes with Abelian charges to scenarios involving nonlinear, non-Abelian\ngauge fields, highlighting the interplay between black hole thermodynamics and\nchaotic dynamics.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T12:31:32Z"}
{"aid":"http://arxiv.org/abs/2504.12894v1","title":"Homeomorphism type of the non-negative part of a complete toric variety","summary":"In this note we show that the nonnegative part of a proper complex toric\nvariety has the homeomorphism type of a sphere, and consequently that the\nnonnegative part has a natural structure of a cell complex. This extends\nprevious results of Ehlers and Jurkiewicz. The proof also provides a simplicial\ndecomposition of the nonnegative part, and a parameterization of each maximal\nsimplex.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12909v1","title":"Real-time High-fidelity Gaussian Human Avatars with Position-based\n  Interpolation of Spatially Distributed MLPs","summary":"Many works have succeeded in reconstructing Gaussian human avatars from\nmulti-view videos. However, they either struggle to capture pose-dependent\nappearance details with a single MLP, or rely on a computationally intensive\nneural network to reconstruct high-fidelity appearance but with rendering\nperformance degraded to non-real-time. We propose a novel Gaussian human avatar\nrepresentation that can reconstruct high-fidelity pose-dependence appearance\nwith details and meanwhile can be rendered in real time. Our Gaussian avatar is\nempowered by spatially distributed MLPs which are explicitly located on\ndifferent positions on human body. The parameters stored in each Gaussian are\nobtained by interpolating from the outputs of its nearby MLPs based on their\ndistances. To avoid undesired smooth Gaussian property changing during\ninterpolation, for each Gaussian we define a set of Gaussian offset basis, and\na linear combination of basis represents the Gaussian property offsets relative\nto the neutral properties. Then we propose to let the MLPs output a set of\ncoefficients corresponding to the basis. In this way, although Gaussian\ncoefficients are derived from interpolation and change smoothly, the Gaussian\noffset basis is learned freely without constraints. The smoothly varying\ncoefficients combined with freely learned basis can still produce distinctly\ndifferent Gaussian property offsets, allowing the ability to learn\nhigh-frequency spatial signals. We further use control points to constrain the\nGaussians distributed on a surface layer rather than allowing them to be\nirregularly distributed inside the body, to help the human avatar generalize\nbetter when animated under novel poses. Compared to the state-of-the-art\nmethod, our method achieves better appearance quality with finer details while\nthe rendering speed is significantly faster under novel views and novel poses.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T12:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12927v1","title":"Dynamics of Geometric Invariants in the Asymptotically Hyperboloidal\n  Setting: Energy and Linear Momentum","summary":"We investigate the evolution of geometric invariants, as defined by Michel\n\\cite{Michel}, in the context of asymptotically hyperboloidal initial data\nsets. Our focus lies on the charges of energy and linear momentum, and we study\ntheir behavior under the Einstein evolution equations. We construct foliations\ndescribing the evolution of asymptotically hyperboloidal initial data sets\nusing hyperboloidal time function. We define E-P chargeability as a property of\nthe initial data set, and we show that it is preserved under the evolution for\nour choice of time function. This ensures that the charges are well-defined\nalong the evolution, which is crucial for our approach. Along such foliations,\nwe recover the same energy-loss and linear momentum-loss formulae as those\nderived by Bondi, Sachs, and Metzner \\cite{Bondi-vanderBurg-Metzner} while\noperating under weaker asymptotic assumptions. Our approach is distinct from\nprevious work as we do not utilize conformal compactifications and work\ndirectly at the level of the initial data set.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T13:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.12947v1","title":"Unraveling the thermodynamics and mechanism behind the lowering of\n  reduction temperatures in oxide mixtures","summary":"Hydrogen-based direct reduction offers a sustainable pathway to decarbonize\nthe metal production industry. However, stable metal oxides, like Cr$_2$O$_3$,\nare notoriously difficult to reduce, requiring extremely high temperatures\n(above 1300 $^\\circ$C). Herein, we show how reducing mixed oxides can be\nleveraged to lower hydrogen-based reduction temperatures of stable oxides and\nproduce alloys in a single process. Using a newly developed thermodynamic\nframework, we predict the precise conditions (oxygen partial pressure,\ntemperature, and oxide composition) needed for co-reduction. We showcase this\napproach by reducing Cr$_2$O$_3$ mixed with Fe$_2$O$_3$ at 1100 $^\\circ$C,\nsignificantly lowering reduction temperatures (by $\\geq$200 $^\\circ$C). Our\nmodel and post-reduction atom probe tomography analysis elucidate that the\ntemperature-lowering effect is driven by the lower chemical activity of Cr in\nthe metallic phase. This strategy achieves low-temperature co-reduction of\nmixed oxides, dramatically reducing energy consumption and CO$_2$ emissions,\nwhile unlocking transformative pathways toward sustainable alloy design.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T13:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.13002v1","title":"The Role of Empathy in Software Engineering -- A Socio-Technical\n  Grounded Theory","summary":"Empathy, defined as the ability to understand and share others' perspectives\nand emotions, is essential in software engineering (SE), where developers often\ncollaborate with diverse stakeholders. It is also considered as a vital\ncompetency in many professional fields such as medicine, healthcare, nursing,\nanimal science, education, marketing, and project management. Despite its\nimportance, empathy remains under-researched in SE. To further explore this, we\nconducted a socio-technical grounded theory (STGT) study through in-depth\nsemi-structured interviews with 22 software developers and stakeholders. Our\nstudy explored the role of empathy in SE and how SE activities and processes\ncan be improved by considering empathy. Through applying the systematic steps\nof STGT data analysis and theory development, we developed a theory that\nexplains the role of empathy in SE. Our theory details the contexts in which\nempathy arises, the conditions that shape it, the causes and consequences of\nits presence and absence. We also identified contingencies for enhancing\nempathy or overcoming barriers to its expression. Our findings provide\npractical implications for SE practitioners and researchers, offering a deeper\nunderstanding of how to effectively integrate empathy into SE processes.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.13008v1","title":"Reconstruction and Performance Evaluation of FASER's Emulsion Detector\n  at the LHC","summary":"This paper presents the reconstruction and performance evaluation of the\nFASER$\\nu$ emulsion detector, which aims to measure interactions from neutrinos\nproduced in the forward direction of proton-proton collisions at the CERN Large\nHadron Collider. The detector, composed of tungsten plates interleaved with\nemulsion films, records charged particles with sub-micron precision. A key\nchallenge arises from the extremely high track density environment, reaching\n$\\mathcal{O}(10^5)$ tracks per cm$^2$. To address this, dedicated alignment\ntechniques and track reconstruction algorithms have been developed, building on\ntechniques from previous experiments and introducing further optimizations. The\nperformance of the detector is studied by evaluating the single-film\nefficiency, position and angular resolution, and the impact parameter\ndistribution of reconstructed vertices. The results demonstrate that an\nalignment precision of 0.3 micrometers and robust track and vertex\nreconstruction are achieved, enabling accurate neutrino measurements in the TeV\nenergy range.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T15:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.13014v1","title":"Extended scalar sectors from all angles (in 15 minutes)","summary":"In this proceedings contribution, I briefly summarize various aspects that\nare important in the discussions of new physics searches with novel scalar\nstates, at current and future colliders. In particular, I give a brief glance\non the status of two Higgs doublet models, and discuss multi-scalar production\nas well as interference effects in Di-Higgs searches. I also mention searches\nof new scalar final states at possible Higgs factories.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T15:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.13040v1","title":"Quantum-gas microscopy of the Bose-glass phase","summary":"Disordered potentials fundamentally alter the transport properties and\ncoherence of quantum systems. They give rise to phenomena such as Anderson\nlocalization in non-interacting systems, inhibiting transport. When\ninteractions are introduced, the interplay with disorder becomes significantly\nmore complex, and the conditions under which localization can be observed\nremain an open question. In interacting bosonic systems, a Bose glass is\nexpected to emerge at low energies as an insulating yet compressible state\nwithout long-range phase coherence. While originally predicted to occur as a\nground-state phase, more recent studies indicate that it exists at finite\ntemperature. A key open challenge has been the direct observation of reduced\nphase coherence in the Bose-glass regime. In this study, we utilize ultracold\nbosonic atoms in a quantum-gas microscope to probe the emergence of the\nBose-glass phase in a two-dimensional square lattice with a site-resolved,\nreproducible disordered potential. We identify the phase through in-situ\ndistribution and particle fluctuations, via a local measurement of the\nEdwards-Anderson parameter. To measure the short-range phase coherence in the\nBose glass, we employ Talbot interferometry in combination with\nsingle-atom-resolved detection. Finally, by driving the system in and out of\nthe Bose-glass phase, we observe signatures for non-ergodic behavior.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.dis-nn,physics.atom-ph,quant-ph","published":"2025-04-17T15:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.13048v1","title":"Design Topological Materials by Reinforcement Fine-Tuned Generative\n  Model","summary":"Topological insulators (TIs) and topological crystalline insulators (TCIs)\nare materials with unconventional electronic properties, making their discovery\nhighly valuable for practical applications. However, such materials,\nparticularly those with a full band gap, remain scarce. Given the limitations\nof traditional approaches that scan known materials for candidates, we focus on\nthe generation of new topological materials through a generative model.\nSpecifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained\ngenerative model, thereby aligning the model's objectives with our material\ndesign goals. We demonstrate that ReFT is effective in enhancing the model's\nability to generate TIs and TCIs, with minimal compromise on the stability of\nthe generated materials. Using the fine-tuned model, we successfully identify a\nlarge number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a\nrepresentative example--a TI with a full band gap of 0.26 eV, ranking among the\nlargest known in this category.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.AI","published":"2025-04-17T16:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.13052v1","title":"GraphAttack: Exploiting Representational Blindspots in LLM Safety\n  Mechanisms","summary":"Large Language Models (LLMs) have been equipped with safety mechanisms to\nprevent harmful outputs, but these guardrails can often be bypassed through\n\"jailbreak\" prompts. This paper introduces a novel graph-based approach to\nsystematically generate jailbreak prompts through semantic transformations. We\nrepresent malicious prompts as nodes in a graph structure with edges denoting\ndifferent transformations, leveraging Abstract Meaning Representation (AMR) and\nResource Description Framework (RDF) to parse user goals into semantic\ncomponents that can be manipulated to evade safety filters. We demonstrate a\nparticularly effective exploitation vector by instructing LLMs to generate code\nthat realizes the intent described in these semantic graphs, achieving success\nrates of up to 87% against leading commercial LLMs. Our analysis reveals that\ncontextual framing and abstraction are particularly effective at circumventing\nsafety measures, highlighting critical gaps in current safety alignment\ntechniques that focus primarily on surface-level patterns. These findings\nprovide insights for developing more robust safeguards against structured\nsemantic attacks. Our research contributes both a theoretical framework and\npractical methodology for systematically stress-testing LLM safety mechanisms.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T16:09:12Z"}
{"aid":"http://arxiv.org/abs/2504.13074v1","title":"SkyReels-V2: Infinite-length Film Generative Model","summary":"Recent advances in video generation have been driven by diffusion models and\nautoregressive frameworks, yet critical challenges persist in harmonizing\nprompt adherence, visual quality, motion dynamics, and duration: compromises in\nmotion dynamics to enhance temporal visual quality, constrained video duration\n(5-10 seconds) to prioritize resolution, and inadequate shot-aware generation\nstemming from general-purpose MLLMs' inability to interpret cinematic grammar,\nsuch as shot composition, actor expressions, and camera motions. These\nintertwined limitations hinder realistic long-form synthesis and professional\nfilm-style generation. To address these limitations, we propose SkyReels-V2, an\nInfinite-length Film Generative Model, that synergizes Multi-modal Large\nLanguage Model (MLLM), Multi-stage Pretraining, Reinforcement Learning, and\nDiffusion Forcing Framework. Firstly, we design a comprehensive structural\nrepresentation of video that combines the general descriptions by the\nMulti-modal LLM and the detailed shot language by sub-expert models. Aided with\nhuman annotation, we then train a unified Video Captioner, named\nSkyCaptioner-V1, to efficiently label the video data. Secondly, we establish\nprogressive-resolution pretraining for the fundamental video generation,\nfollowed by a four-stage post-training enhancement: Initial concept-balanced\nSupervised Fine-Tuning (SFT) improves baseline quality; Motion-specific\nReinforcement Learning (RL) training with human-annotated and synthetic\ndistortion data addresses dynamic artifacts; Our diffusion forcing framework\nwith non-decreasing noise schedules enables long-video synthesis in an\nefficient search space; Final high-quality SFT refines visual fidelity. All the\ncode and models are available at https://github.com/SkyworkAI/SkyReels-V2.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.13090v1","title":"Quadratic gravity with propagating torsion and asymptotic freedom","summary":"We consider a class of metric-affine gravitational theories with action\nquadratic in curvature and torsion tensors. Using the heat kernel technique, we\ncompute the torsion contributions to the one-loop counterterms in the\nultraviolet limit. It is found that vectorial and axial components of torsion\npreserve the qualitative picture of the renormalization group flow of the\nmetric sector. However, there exists a specific nonminimal kinetic term for the\npure tensorial (hook-antisymmetric traceless) component of torsion that renders\nthe gravitational couplings asymptotically free in the absence of tachyons.","main_category":"hep-th","categories":"hep-th","published":"2025-04-17T16:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.13116v1","title":"Predicting BVD Re-emergence in Irish Cattle From Highly Imbalanced\n  Herd-Level Data Using Machine Learning Algorithms","summary":"Bovine Viral Diarrhoea (BVD) has been the focus of a successful eradication\nprogramme in Ireland, with the herd-level prevalence declining from 11.3% in\n2013 to just 0.2% in 2023. As the country moves toward BVD freedom, the\ndevelopment of predictive models for targeted surveillance becomes increasingly\nimportant to mitigate the risk of disease re-emergence. In this study, we\nevaluate the performance of a range of machine learning algorithms, including\nbinary classification and anomaly detection techniques, for predicting\nBVD-positive herds using highly imbalanced herd-level data. We conduct an\nextensive simulation study to assess model performance across varying sample\nsizes and class imbalance ratios, incorporating resampling, class weighting,\nand appropriate evaluation metrics (sensitivity, positive predictive value,\nF1-score and AUC values). Random forests and XGBoost models consistently\noutperformed other methods, with the random forest model achieving the highest\nsensitivity and AUC across scenarios, including real-world prediction of 2023\nherd status, correctly identifying 219 of 250 positive herds while halving the\nnumber of herds that require compared to a blanket-testing strategy.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-17T17:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.13117v1","title":"Tunable Entangling and Steering of Ferrimagnetic Magnons via an\n  OptoMagnoMechanical Ring","summary":"Recently, magnomechanical systems have emerged as promising platforms for\nquantum technologies, exploiting magnon-photon-phonon interactions to store\nhigh-fidelity quantum information. In this paper, we propose a scheme to\nentangle two spatially separated ferrimagnetic YIG crystals by injecting a\nmicrowave field into an optomagnonic ring cavity. The proposed\noptomagnomechanical configuration utilizes the coupling between\nmagnetostriction-induced mechanical displacements and the optical cavity via\nradiation pressure. Magnons - collective spin excitations in macroscopic\nferromagnets - are directly driven by an electromagnetic field. We demonstrate\nthe generation of macroscopic magnon entanglement by exciting the optical\ncavity with a red detuned microwave field and the YIG crystals with a blue\ndetuned field. Our analysis reveals that magnon entanglement vanishes for\nidentical magnomechanical couplings but remains robust against thermal\nfluctuations. The magnon modes entangled in two ferrimagnetic crystals\nrepresent genuine macroscopic quantum states with potential applications in the\nstudy of macroscopic quantum mechanics and quantum information processing based\non magnonics. The configuration is based on experimentally accessible\nparameters, providing a feasible route of quantum technologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:36:37Z"}
{"aid":"http://arxiv.org/abs/2504.13126v1","title":"A hybrid U-Net and Fourier neural operator framework for the large-eddy\n  simulation of turbulent flows over periodic hills","summary":"Accurate and efficient predictions of three-dimensional (3D) turbulent flows\nare of significant importance in the fields of science and engineering. In the\ncurrent work, we propose a hybrid U-Net and Fourier neural operator (HUFNO)\nmethod, tailored for mixed periodic and non-periodic boundary conditions which\nare often encountered in complex turbulence problems. The HUFNO model is tested\nin the large-eddy simulation (LES) of 3D periodic hill turbulence featuring\nstrong flow separations. Compared to the original Fourier neural operator (FNO)\nand the convolutional neural network (CNN)-based U-Net framework, the HUFNO\nmodel has a higher accuracy in the predictions of the velocity field and\nReynolds stresses. Further numerical experiments in the LES show that the HUFNO\nframework outperforms the traditional Smagorinsky (SMAG) model and the\nwall-adapted local eddy-viscosity (WALE) model in the predictions of the\nturbulence statistics, the energy spectrum, the wall stresses and the flow\nseparation structures, with much lower computational cost. Importantly, the\naccuracy and efficiency are transferable to unseen initial conditions and hill\nshapes, underscoring its great potentials for the fast prediction of strongly\nseparated turbulent flows over curved boundaries.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-17T17:43:23Z"}
{"aid":"http://arxiv.org/abs/2504.13146v1","title":"Antidistillation Sampling","summary":"Frontier models that generate extended reasoning traces inadvertently produce\nrich token sequences that can facilitate model distillation. Recognizing this\nvulnerability, model owners may seek sampling strategies that limit the\neffectiveness of distillation without compromising model performance.\n\\emph{Antidistillation sampling} provides exactly this capability. By\nstrategically modifying a model's next-token probability distribution,\nantidistillation sampling poisons reasoning traces, rendering them\nsignificantly less effective for distillation while preserving the model's\npractical utility. For further details, see https://antidistillation.com.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-17T17:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.13159v1","title":"Digital Twin Generation from Visual Data: A Survey","summary":"This survey explores recent developments in generating digital twins from\nvideos. Such digital twins can be used for robotics application, media content\ncreation, or design and construction works. We analyze various approaches,\nincluding 3D Gaussian Splatting, generative in-painting, semantic segmentation,\nand foundation models highlighting their advantages and limitations.\nAdditionally, we discuss challenges such as occlusions, lighting variations,\nand scalability, as well as potential future research directions. This survey\naims to provide a comprehensive overview of state-of-the-art methodologies and\ntheir implications for real-world applications. Awesome list:\nhttps://github.com/ndrwmlnk/awesome-digital-twins","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.13170v1","title":"A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal\n  Control with Time Scaling","summary":"We introduce a semidefinite relaxation for optimal control of linear systems\nwith time scaling. These problems are inherently nonconvex, since the system\ndynamics involves bilinear products between the discretization time step and\nthe system state and controls. The proposed relaxation is closely related to\nthe standard second-order semidefinite relaxation for quadratic constraints,\nbut we carefully select a subset of the possible bilinear terms and apply a\nchange of variables to achieve empirically tight relaxations while keeping the\ncomputational load light. We further extend our method to handle\npiecewise-affine (PWA) systems by formulating the PWA optimal-control problem\nas a shortest-path problem in a graph of convex sets (GCS). In this GCS,\ndifferent paths represent different mode sequences for the PWA system, and the\nconvex sets model the relaxed dynamics within each mode. By combining a tight\nconvex relaxation of the GCS problem with our semidefinite relaxation with time\nscaling, we can solve PWA optimal-control problems through a single\nsemidefinite program.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY,math.OC","published":"2025-04-17T17:59:23Z"}
{"aid":"http://arxiv.org/abs/2504.13174v1","title":"Quantum algorithm for solving nonlinear differential equations based on\n  physics-informed effective Hamiltonians","summary":"We propose a distinct approach to solving linear and nonlinear differential\nequations (DEs) on quantum computers by encoding the problem into ground states\nof effective Hamiltonian operators. Our algorithm relies on constructing such\noperators in the Chebyshev space, where an effective Hamiltonian is a sum of\nglobal differential and data constraints. Once the effective Hamiltonian is\nformed, solutions of differential equations can be obtained using the ground\nstate preparation techniques (e.g. imaginary-time evolution and quantum\nsingular value transformation), bypassing variational search. Unlike approaches\nbased on discrete grids, the algorithm enables evaluation of solutions beyond\nfixed grid points and implements constraints in the physics-informed way. Our\nproposal inherits the best traits from quantum machine learning-based DE\nsolving (compact basis representation, automatic differentiation, nonlinearity)\nand quantum linear algebra-based approaches (fine-grid encoding, provable\nspeed-up for state preparation), offering a robust strategy for quantum\nscientific computing in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.14824v1","title":"An Enhanced Dual-Currency VCG Auction Mechanism for Resource Allocation\n  in IoV: A Value of Information Perspective","summary":"The Internet of Vehicles (IoV) is undergoing a transformative evolution,\nenabled by advancements in future 6G network technologies, to support\nintelligent, highly reliable, and low-latency vehicular services. However, the\nenhanced capabilities of loV have heightened the demands for efficient network\nresource allocation while simultaneously giving rise to diverse vehicular\nservice requirements. For network service providers (NSPs), meeting the\ncustomized resource-slicing requirements of vehicle service providers (VSPs)\nwhile maximizing social welfare has become a significant challenge. This paper\nproposes an innovative solution by integrating a mean-field multi-agent\nreinforcement learning (MFMARL) framework with an enhanced\nVickrey-Clarke-Groves (VCG) auction mechanism to address the problem of social\nwelfare maximization under the condition of unknown VSP utility functions. The\ncore of this solution is introducing the ``value of information\" as a novel\nmonetary metric to estimate the expected benefits of VSPs, thereby ensuring the\neffective execution of the VCG auction mechanism. MFMARL is employed to\noptimize resource allocation for social welfare maximization while adapting to\nthe intelligent and dynamic requirements of IoV. The proposed enhanced VCG\nauction mechanism not only protects the privacy of VSPs but also reduces the\nlikelihood of collusion among VSPs, and it is theoretically proven to be\ndominant-strategy incentive compatible (DSIC). The simulation results\ndemonstrate that, compared to the VCG mechanism implemented using quantization\nmethods, the proposed mechanism exhibits significant advantages in convergence\nspeed, social welfare maximization, and resistance to collusion, providing new\ninsights into resource allocation in intelligent 6G networks.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-21T03:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.14826v1","title":"Distribution-aware Dataset Distillation for Efficient Image Restoration","summary":"With the exponential increase in image data, training an image restoration\nmodel is laborious. Dataset distillation is a potential solution to this\nproblem, yet current distillation techniques are a blank canvas in the field of\nimage restoration. To fill this gap, we propose the Distribution-aware Dataset\nDistillation method (TripleD), a new framework that extends the principles of\ndataset distillation to image restoration. Specifically, TripleD uses a\npre-trained vision Transformer to extract features from images for complexity\nevaluation, and the subset (the number of samples is much smaller than the\noriginal training set) is selected based on complexity. The selected subset is\nthen fed through a lightweight CNN that fine-tunes the image distribution to\nalign with the distribution of the original dataset at the feature level. To\nefficiently condense knowledge, the training is divided into two stages. Early\nstages focus on simpler, low-complexity samples to build foundational\nknowledge, while later stages select more complex and uncertain samples as the\nmodel matures. Our method achieves promising performance on multiple image\nrestoration tasks, including multi-task image restoration, all-in-one image\nrestoration, and ultra-high-definition image restoration tasks. Note that we\ncan train a state-of-the-art image restoration model on an\nultra-high-definition (4K resolution) dataset using only one consumer-grade GPU\nin less than 8 hours (500 savings in computing resources and immeasurable\ntraining time).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T03:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.14834v1","title":"Output regulation for a reaction-diffusion system with input delay and\n  unknown frequency","summary":"This study solves the output regulation problem for a reaction-diffusion\nsystem confronting concurrent input delay and fully unidentified disturbances\n(encompassing both unknown frequencies and amplitudes) across all channels. The\nprincipal innovation emerges from a novel adaptive control architecture that\nsynergizes the modal decomposition technique with a dual-observer mechanism,\nenabling real-time concurrent estimation of unmeasurable system states and\ndisturbances through a state observer and an adaptive disturbance estimator.\nUnlike existing approaches limited to either delay compensation or partial\ndisturbance rejection, our methodology overcomes the technical barrier of\ncoordinating these two requirements through a rigorously constructed\ntracking-error-based controller, achieving exponential convergence of system\noutput to reference signals. Numerical simulations are presented to validate\nthe effectiveness of the proposed output feedback control strategy.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T03:29:09Z"}
{"aid":"http://arxiv.org/abs/2504.14842v1","title":"A Short Proof of Coding Theorems for Reed-Muller Codes","summary":"In this paper, we present a short proof that ReedMuller (RM) codes are\nentropy-achieving as source coding for Bernoulli sources and capacity-achieving\nas channel coding for binary memoryless symmetric (BMS) channels, also known as\nmemoryless binary-input output-symmetric (BIOS) channels, in terms of bit error\nrate (BER) under maximum-likelihood (ML) decoding.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T03:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.14846v1","title":"Converting $PT$-Symmetric Topological Classes by Floquet Engineering","summary":"Going beyond the conventional classification rule of Altland-Zirnbauer\nsymmetry classes, $PT$ symmetric topological phases are classified by\n$(PT)^2=1$ or $-1$. The interconversion between the two $PT$-symmetric\ntopological classes is generally difficult due to the constraint of $(PT)^2$.\nHere, we propose a scheme to control and interconvert the $PT$-symmetric\ntopological classes by Floquet engineering. We find that it is the breakdown of\nthe $\\mathbb{Z}_2$ gauge, induced by the $\\pi$ phase difference between\ndifferent hopping rates, by the periodic driving that leads to such an\ninterconversion. Relaxing the system from the constraint of $(PT)^2$, rich\nexotic topological phases, e.g., the coexisting $PT$-symmetric first-order real\nChern insulator and second-order topological insulators not only in different\nquasienergy gaps, but also in one single gap, are generated. In contrast to\nconventional Floquet topological phases, our result provides a way to realize\nexotic topological phases without changing symmetries. It enriches the family\nof topological phases and gives an insightful guidance for the development of\nmultifunctional quantum devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-21T03:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.14856v1","title":"Transparentize the Internal and External Knowledge Utilization in LLMs\n  with Trustworthy Citation","summary":"While hallucinations of large language models could been alleviated through\nretrieval-augmented generation and citation generation, how the model utilizes\ninternal knowledge is still opaque, and the trustworthiness of its generated\nanswers remains questionable. In this work, we introduce Context-Prior\nAugmented Citation Generation task, requiring models to generate citations\nconsidering both external and internal knowledge while providing trustworthy\nreferences, with 5 evaluation metrics focusing on 3 aspects: answer\nhelpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the\nparadigm for our task, and also design INTRALIGN, an integrated method\ncontaining customary data generation and an alignment algorithm. Our\nexperimental results show that our method achieves a better cross-scenario\nperformance with regard to other baselines. Our extended experiments further\nreveal that retrieval quality, question types, and model knowledge have\nconsiderable influence on the trustworthiness in citation generation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T04:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.14869v1","title":"X-ray Polarization of the BL Lac Type Blazar H 1426+428","summary":"We report the X-ray polarization properties of the high-synchrotron-peaked BL\nLac H 1426+428, based on two-epoch observational data from the Imaging X-ray\nPolarimetry Explorer (IXPE). For the first observation, only an upper limit of\npolarization degree ($\\Pi_{\\rm X}$), $\\Pi_{\\rm X}<19.5\\%$, at the 99\\%\nconfidence level (C.L.) is determined. In contrast, for the second observation,\nwe derive $\\Pi_{\\rm X}=20.6\\%\\pm2.9\\%$ with a polarization angle ($\\psi_{\\rm\nX}$) of $\\psi_{\\rm X}=116.1^{\\circ}\\pm4.1^{\\circ}$ at a C.L. of 7.1 $\\sigma$.\nThe time-resolved and energy-resolved polarization analysis reveals no\nsignificant variation in $\\psi_{\\rm X}$ and no detectable polarization within\nnarrower energy bins for the first observation, while the polarization during\nthe second observation is predominantly dominated by low-energy photons.\nFurthermore, the X-rays during the second observation are found to be in a\nhigher flux state with a harder spectrum compared to that observed during the\nfirst observation, consistent with a {\\it harder-when-brighter} behavior. We\npropose that the plasma responsible for the X-ray emission during the first\nobservation propagates downstream and encounters a shock, leading to electron\nacceleration and more ordered of the magnetic fields. The enhanced X-ray\nemission observed during the second observation is produced by\nshock-accelerated electrons within an ordered magnetic field region via\nsynchrotron radiation. No significant detection of polarization during the\nfirst IXPE observation may be due to the limited number of detected photons.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-21T05:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.14897v1","title":"Physics-Aware Compression of Plasma Distribution Functions with\n  GPU-Accelerated Gaussian Mixture Models","summary":"Data compression is a critical technology for large-scale plasma simulations.\nStoring complete particle information requires Terabyte-scale data storage, and\nanalysis requires ad-hoc scalable post-processing tools. We propose a\nphysics-aware in-situ compression method using Gaussian Mixture Models (GMMs)\nto approximate electron and ion velocity distribution functions with a number\nof Gaussian components. This GMM-based method allows us to capture plasma\nfeatures such as mean velocity and temperature, and it enables us to identify\nheating processes and generate beams. We first construct a histogram to reduce\ncomputational overhead and apply GPU-accelerated, in-situ GMM fitting within\n\\texttt{iPIC3D}, a large-scale implicit Particle-in-Cell simulator, ensuring\nreal-time compression. The compressed representation is stored using the\n\\texttt{ADIOS 2} library, thus optimizing the I/O process. The GPU and\nhistogramming implementation provides a significant speed-up with respect to\nGMM on particles (both in time and required memory at run-time), enabling\nreal-time compression. Compared to algorithms like SZ, MGARD, and BLOSC2, our\nGMM-based method has a physics-based approach, retaining the physical\ninterpretation of plasma phenomena such as beam formation, acceleration, and\nheating mechanisms. Our GMM algorithm achieves a compression ratio of up to\n$10^4$, requiring a processing time comparable to, or even lower than, standard\ncompression engines.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-21T07:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.14923v1","title":"Maximum Entropy Production Principle of Thermodynamics for the Birth and\n  Evolution of Life","summary":"Research on the birth and evolution of life are reviewed with reference to\nthe maximum entropy production principle (MEPP). It has been shown that this\nprinciple is essential for consistent understanding of the birth and evolution\nof life. First, a recent work for the birth of a self-replicative system as\npre-RNA life is reviewed in relation to the MEPP. A critical condition of\npolymer concentration in a local system is reported by a dynamical system\napproach, above which, an exponential increase of entropy production is\nguaranteed. Secondly, research works of early stage of evolutions are reviewed;\nexperimental research for the numbers of cells necessary for forming a\nmulti-cellular organization, and numerical research of differentiation of a\nmodel system and its relation with MEPP. It is suggested by this review article\nthat the late stage of evolution is characterized by formation of society and\nexternal entropy production. A hypothesis on the general route of evolution is\ndiscussed from the birth to the present life which follows the MEPP. Some\nexamples of life which happened to face poor thermodynamic condition are\npresented with thermodynamic discussion. It is observed through this review\nthat MEPP is consistently useful for thermodynamic understanding of birth and\nevolution of life, subject to a thermodynamic condition far from equilibrium.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.stat-mech,nlin.AO,physics.chem-ph","published":"2025-04-21T07:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.14975v1","title":"Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency\n  Regularization","summary":"Despite the remarkable progress of 3D generation, achieving controllability,\ni.e., ensuring consistency between generated 3D content and input conditions\nlike edge and depth, remains a significant challenge. Existing methods often\nstruggle to maintain accurate alignment, leading to noticeable discrepancies.\nTo address this issue, we propose \\name{}, a new framework that enhances\ncontrollable 3D generation by explicitly encouraging cyclic consistency between\nthe second-order 3D content, generated based on extracted signals from the\nfirst-order generation, and its original input controls. Specifically, we\nemploy an efficient feed-forward backbone that can generate a 3D object from an\ninput condition and a text prompt. Given an initial viewpoint and a control\nsignal, a novel view is rendered from the generated 3D content, from which the\nextracted condition is used to regenerate the 3D content. This re-generated\noutput is then rendered back to the initial viewpoint, followed by another\nround of control signal extraction, forming a cyclic process with two\nconsistency constraints. \\emph{View consistency} ensures coherence between the\ntwo generated 3D objects, measured by semantic similarity to accommodate\ngenerative diversity. \\emph{Condition consistency} aligns the final extracted\nsignal with the original input control, preserving structural or geometric\ndetails throughout the process. Extensive experiments on popular benchmarks\ndemonstrate that \\name{} significantly improves controllability, especially for\nfine-grained details, outperforming existing methods across various conditions\n(e.g., +14.17\\% PSNR for edge, +6.26\\% PSNR for sketch).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:05:52Z"}
{"aid":"http://arxiv.org/abs/2504.14983v1","title":"The Effect of Hydration and Dynamics on the Mass Density of Single\n  Proteins","summary":"The density of a protein molecule is a key property within a variety of\nexperimental techniques. We present a computational method for determining\nprotein mass density that explicitly incorporates hydration effects. Our\napproach uses molecular dynamics simulations to quantify the volume of solvent\nexcluded by a protein. Applied to a dataset of 260 soluble proteins, this\nyields an average density of 1.296 g cm-3, notably lower than the widely cited\nvalue of 1.35 g cm-3. Contrary to previous suggestions, we find no correlation\nbetween protein density and molecular weight. We instead find correlations with\nresidue composition, particularly with hydrophobic amino acid content. Using\nthese correlations, we train a regressor capable of accurately predicting\nprotein density from sequence-derived features alone. Examining the effect of\nincorporating water molecules on the measured density, we find that water\nmolecules buried in internal cavities have a negligible effect, whereas those\nat the surface have a profound impact. Furthermore, by calculating the density\nof a titin domain and of the Bovine Pancreatic Trypsin over molecular dynamics\ntrajectories, we show that individual proteins can occupy states with close but\ndistinguishable densities. Finally, we analyse the density of water in the\nvicinity of proteins, showing that the first two hydration shells exhibit\nhigher density than bulk water. When included in cumulative density\ncalculations, these hydration layers contribute to a net increase in local\nsolvent density. Overall, we find that proteins are less dense than previously\nreported, which is offset by their ability to induce a higher density of water\nin their vicinity.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-21T09:23:05Z"}
{"aid":"http://arxiv.org/abs/2504.14990v1","title":"Normalization of Quaternionic Polynomials in Coordinate-Free\n  Quaternionic Variables in Conjugate-Alternating Order","summary":"Quaternionic polynomials occur naturally in applications of quaternions in\nscience and engineering, and normalization of quaternionic polynomials is a\nbasic manipulation. Once a Groebner basis is certified for the defining ideal I\nof the quaternionic polynomial algebra, the normal form of a quaternionic\npolynomial can be computed by routine top reduction with respect to the\nGroebner basis. In the literature, a Groebner basis under the\nconjugate-alternating order of quaternionic variables was conjectured for I in\n2013, but no readable and convincing proof was found.\n  In this paper, we present the first readable certification of the conjectured\nGroebner basis. The certification is based on several novel techniques for\nreduction in free associative algebras, which enables to not only make\nreduction to S-polynomials more efficiently, but also reduce the number of\nS-polynomials needed for the certification.","main_category":"cs.SC","categories":"cs.SC","published":"2025-04-21T09:41:01Z"}
{"aid":"http://arxiv.org/abs/2504.15017v1","title":"Identity Dilemma in Immigrant Consumers: a discourse analysis of\n  diaspora marketing","summary":"Purpose - Diasporas of a country of origin are groups interested in\ncountry-of-origin scattered in host countries and familiar with markets of host\ncountries. This paper aims to discourse analysis of diaspora marketing\nresearches. Methodology - In judgmental sampling using selected keywords 24\nresearches in two eras before and after 2010 are selected for discourse\nanalysis. Faircloughs critical discourse analysis model is used to analyze\nresearch data. Findings- Two different discourses can be distinguished in\ndiaspora marketing researches. The diaspora niche marketing discourse is\nfocused on penetrating into diaspora niche market. The diaspora marketing\nstrategy discourse is focused on developing into international market using\ndiaspora leverage. Research limitations and implications - Judgmental sampling\nand lived experience of researchers in a developing country which is usually\nconsidered as a diasporas country of origin rather than a diasporas host\ncountry limit the generalizability of research results. Practical implications\n- Understanding the extensions of diaspora marketing concept and diaspora\nmarketing discourses is helpful for designing appropriate strategies for\nentering and developing in the international market. Originality - this paper\ninvestigates extensions of diaspora concept in previous research identifies\ndiaspora marketing discourses and compares dominant diaspora marketing\ndiscourse with global marketing discourse.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-21T10:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.15048v1","title":"Neumann Data and Second Variation Formula of Renormalized Area for\n  Conformally Compact Static Spaces","summary":"In this paper, we derive the first and second variation formulas for the\nrenormalized area for static Einstein spaces along a specific direction,\ndemonstrating that the negativity of the Neumann data implies instability.\nConsequently, we obtain a rigidity result for the case when the conformal\nboundary is a warped product torus, which strengthens the result presented in\n\\cite{GSW}.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.15064v1","title":"Matrix Representations of Derivations for Low-Dimensional Mock-Lie\n  Algebras","summary":"In this work, we study the matrix representation of derivations for Mock-Lie\nalgebras with dimensions up to four. Using matrix methods, we examine their\nstructure and properties, showing how these derivations help us better\nunderstand the algebraic nature of Mock-Lie algebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-21T12:49:13Z"}
{"aid":"http://arxiv.org/abs/2504.15067v1","title":"Ordering and association of patchy particles in narrow channels","summary":"We show that the formalism of Wertheim's first order thermodynamic\nperturbation theory can be generalised for the fluid of anisotropic sticky\nparticles confined to a quasi-one-dimensional channel. Using the transfer\nmatrix method, we prove that the theory is exact if the hard body interaction\nis additive, only the first neighbors interact and the particles can stick\ntogether only along the channel. We show that the most convenient treatment of\nassociation in narrow channels is to work in NPT ensemble, where all structural\nand thermodynamic quantities can be expressed as a function of pressure and\nfraction of sites unbonded.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-21T12:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.15073v1","title":"Hermitian Quaternion Toeplitz Matrices by Quaternion-valued Generating\n  Functions","summary":"In this paper, we study Hermitian quaternion Toeplitz matrices generated by\nquaternion-valued functions. We show that such generating function must be the\nsum of a real-valued function and an odd function with imaginary component.\nThis setting is different from the case of Hermitian complex Toeplitz matrices\ngenerated by real-valued functions only. By using of 2-by-2 block complex\nrepresentation of quaternion matrices, we give a quaternion version of\nGrenander-Szeg\\\"{o} theorem stating the distribution of eigenvalues of\nHermitian quaternion Toeplitz matrices in terms of its generating function. As\nan application, we investigate Strang's circulant preconditioners for Hermitian\nquaternion Toeplitz linear systems arising from quaternion signal processing.\nWe show that Strang's circulant preconditioners can be diagionalized by\ndiscrete quaternion Fourier transform matrices whereas general quaternion\ncirculant matrices cannot be diagonalized by them. Also we verify the\ntheoretical and numerical convergence results of Strang's circulant\npreconditioned conjugate gradient method for solving Hermitian quaternion\nToeplitz systems.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T13:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.15079v1","title":"Generative Artificial Intelligence for Beamforming in Low-Altitude\n  Economy","summary":"The growth of low-altitude economy (LAE) has driven a rising demand for\nefficient and secure communication. However, conventional beamforming\noptimization techniques struggle in the complex LAE environments. In this\ncontext, generative artificial intelligence (GenAI) methods provide a promising\nsolution. In this article, we first introduce the core concepts of LAE and the\nroles of beamforming in advanced communication technologies for LAE. We then\nexamine their interrelation, followed by an analysis of the limitations of\nconventional beamforming methods. Next, we provide an overview of how GenAI\nmethods enhance the process of beamforming, with a focus on its applications in\nLAE. Furthermore, we present a case study using a generative diffusion model\n(GDM)-based algorithm to enhance the performance of aerial collaborative\nbeamforming-enabled remote secure communications in LAE and simulation results\nverified the effectiveness of the proposed algorithms. Finally, promising\nresearch opportunities are identified.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T13:09:15Z"}
{"aid":"http://arxiv.org/abs/2504.15099v1","title":"Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training\n  of GAN","summary":"Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T13:41:09Z"}
{"aid":"http://arxiv.org/abs/2504.15122v1","title":"MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry\n  Monocular Video","summary":"We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS)\nframework capable of reconstructing sharp and high-quality novel\nspatio-temporal views from blurry monocular videos in an end-to-end manner.\nExisting dynamic novel view synthesis (NVS) methods are highly sensitive to\nmotion blur in casually captured videos, resulting in significant degradation\nof rendering quality. While recent approaches address motion-blurred inputs for\nNVS, they primarily focus on static scene reconstruction and lack dedicated\nmotion modeling for dynamic objects. To overcome these limitations, our MoBGS\nintroduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for\neffective latent camera trajectory estimation, improving global camera motion\ndeblurring. In addition, we propose a physically-inspired Latent Camera-induced\nExposure Estimation (LCEE) method to ensure consistent deblurring of both\nglobal camera and local object motion. Our MoBGS framework ensures the temporal\nconsistency of unseen latent timestamps and robust motion decomposition of\nstatic and dynamic regions. Extensive experiments on the Stereo Blur dataset\nand real-world blurry videos show that our MoBGS significantly outperforms the\nvery recent advanced methods (DyBluRF and Deblur4DGS), achieving\nstate-of-the-art performance for dynamic NVS under motion blur.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.15127v1","title":"Reconstructing the redshift evolution of Type Ia supernovae absolute\n  magnitude","summary":"This work investigates a potential time dependence of the absolute magnitude\nof Type Ia Supernovae (SN Ia). Employing the Gaussian Process approach, we\nobtain the SN Ia absolute magnitude and its derivative as a function of\nredshift. The data set considered in the analysis comprises measurements of\napparent magnitude from SN Ia, Hubble rate from cosmic chronometers, and the\nratio between angular and radial distances from Large-Scale Structure data (BAO\nand voids). Our findings reveal good compatibility between the reconstructed SN\nIa absolute magnitudes and a constant value. However, the mean value obtained\nfrom the Gaussian Process reconstruction is $M=-19.456\\pm 0.059$, which is\n$3.2\\sigma$ apart from local measurements by Pantheon+SH0ES. This\nincompatibility may be directly associated to the $\\Lambda$CDM model and local\ndata, as it does not appear in either model-dependent or model-independent\nestimates of the absolute magnitude based on early universe data. Furthermore,\nwe assess the implications of a variable $M$ within the context of modified\ngravity theories. Considering the local estimate of the absolute magnitude, we\nfind $\\sim3\\sigma$ tension supporting departures from General Relativity in\nanalyzing scenarios involving modified gravity theories with variations in\nPlanck mass through Newton's constant.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:22:41Z"}
{"aid":"http://arxiv.org/abs/2504.15130v1","title":"Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning","summary":"Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-21T14:25:32Z"}
{"aid":"http://arxiv.org/abs/2504.15133v1","title":"EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language\n  Models","summary":"In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CV,cs.HC,cs.LG","published":"2025-04-21T14:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.15141v1","title":"Breaking Down Quantum Compilation: Profiling and Identifying Costly\n  Passes","summary":"With the increasing capabilities of quantum systems, the efficient, practical\nexecution of quantum programs is becoming more critical. Each execution\nincludes compilation time, which accounts for substantial overhead of the\noverall program runtime. To address this challenge, proposals that leverage\nprecompilation techniques have emerged, whereby entire circuits or select\ncomponents are precompiled to mitigate the compilation time spent during\nexecution. Considering the impact of compilation time on quantum program\nexecution, identifying the contribution of each individual compilation task to\nthe execution time is necessary in directing the community's research efforts\ntowards the development of an efficient compilation and execution pipeline. In\nthis work, we perform a preliminary analysis of the quantum circuit compilation\nprocess in Qiskit, examining the cumulative runtime of each individual\ncompilation task and identifying the tasks that most strongly impact the\noverall compilation time. Our results indicate that, as the desired level of\noptimization increases, circuit optimization and gate synthesis passes become\nthe dominant tasks in compiling a Quantum Fourier Transform, with individual\npasses consuming up to 87% of the total compilation time. Mapping passes\nrequire the most compilation time for a GHZ state preparation circuit,\naccounting for over 99% of total compilation time.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-21T14:45:01Z"}
{"aid":"http://arxiv.org/abs/2504.15153v1","title":"Distribution Testing Meets Sum Estimation","summary":"We study the problem of estimating the sum of $n$ elements, each with weight\n$w(i)$, in a structured universe. Our goal is to estimate $W = \\sum_{i=1}^n\nw(i)$ within a $(1 \\pm \\epsilon)$ factor using a sublinear number of samples,\nassuming weights are non-increasing, i.e., $w(1) \\geq w(2) \\geq \\dots \\geq\nw(n)$. The sum estimation problem is well-studied under different access models\nto the universe $U$. However, to the best of our knowledge, nothing is known\nabout the sum estimation problem using non-adaptive conditional sampling. In\nthis work, we explore the sum estimation problem using non-adaptive conditional\nweighted and non-adaptive conditional uniform samples, assuming that the\nunderlying distribution ($D(i)=w(i)/W$) is monotone. We also extend our\napproach to to the case where the underlying distribution of $U$ is unimodal.\nAdditionally, we consider support size estimation when $w(i) = 0$ or $w(i) \\geq\nW/n$, using hybrid sampling (both weighted and uniform) to access $U$. We\npropose an algorithm to estimate $W$ under the non-increasing weight\nassumption, using $O(\\frac{1}{\\epsilon^3} \\log{n} + \\frac{1}{\\epsilon^6})$\nnon-adaptive weighted conditional samples and $O(\\frac{1}{\\epsilon^3} \\log{n})$\nuniform conditional samples. Our algorithm matches the $\\Omega(\\log{n})$ lower\nbound by \\cite{ACK15}. For unimodal distributions, the sample complexity\nremains similar, with an additional $O(\\log{n})$ evaluation queries to locate\nthe minimum weighted point in the domain. For estimating the support size $k$\nof $U$, where weights are either $0$ or at least $W/n$, our algorithm uses\n$O\\big( \\frac{\\log^3(n/\\epsilon)}{\\epsilon^8} \\cdot \\log^4\n\\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ uniform samples and $O\\big(\n\\frac{\\log(n/\\epsilon)}{\\epsilon^2} \\cdot \\log\n\\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ weighted samples to output $\\hat{k}$\nsatisfying $k - 2\\epsilon n \\leq \\hat{k} \\leq k + \\epsilon n$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-21T14:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.15160v1","title":"The Synthetic Imputation Approach: Generating Optimal Synthetic Texts\n  For Underrepresented Categories In Supervised Classification Tasks","summary":"Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa,\nrequire that all categories in an annotation task be sufficiently represented\nin the training data for optimal performance. However, it is often difficult to\nfind sufficient examples for all categories in a task when building a\nhigh-quality training set. In this article, I describe this problem and propose\na solution, the synthetic imputation approach. Leveraging a generative LLM\n(GPT-4o), this approach generates synthetic texts based on careful prompting\nand five original examples drawn randomly with replacement from the sample.\nThis approach ensures that new synthetic texts are sufficiently different from\nthe original texts to reduce overfitting, but retain the underlying substantive\nmeaning of the examples to maximize out-of-sample performance. With 75 original\nexamples or more, synthetic imputation's performance is on par with a full\nsample of original texts, and overfitting remains low, predictable and\ncorrectable with 50 original samples. The synthetic imputation approach\nprovides a novel role for generative LLMs in research and allows applied\nresearchers to balance their datasets for best performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.15187v1","title":"Method for simulating open-system dynamics using mid-circuit\n  measurements on a quantum computer","summary":"We present a method for simulating the dynamics of an open electronic system\non a quantum computer. This approach entails mid-circuit measurements and\nresets to simulate the addition or removal of fermions from the system and\nprovides a way to apply non-reversible operations to a quantum computer. Using\nthis method, we simulate the dynamics of an open electronic system consisting\nof a fermionic chain positioned between two conductive leads on the\n$ibm\\_torino$ quantum computer.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T15:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15192v1","title":"Breast density in MRI: an AI-based quantification and relationship to\n  assessment in mammography","summary":"Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T16:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.15221v1","title":"On Walker and para-Hermite Einstein spaces","summary":"A special class of (complex) para-Hermite Einstein spaces is analyzed. For\nthis class of spaces the self-dual Weyl tensor is type-[D] in the\nPetrov-Penrose classification. The anti-self-dual Weyl tensor is algebraically\ndegenerate, equivalently, there exists an anti-self-dual congruence of null\nstrings. It is assumed that this congruence is parallely propagated. Thus, the\nspaces are not only para-Hermite but also Walker. A classification of the\nspaces according to three criteria is given. Finally, explicit metrics of all\nadmitted Petrov-Penrose types are found.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-21T16:47:54Z"}
{"aid":"http://arxiv.org/abs/2504.15256v1","title":"Impulsive pattern recognition of a myoelectric hand via Dynamic Time\n  Warping","summary":"Although myoelectric prosthetic hands provide amputees with intuitive\ncontrol, their reliance on many EMG sensors limits accessibility and makes them\ncomplex and expensive. To address this problem, this work presents a different\nperspective that makes use of a single EMG sensor and brief impulse signals in\nconjunction with Dynamic Time Warping (DTW) for accurate pattern detection.\nConventional techniques rely on real-time data from multiple sensors, which can\nbe costly and bulky. The method presents high accuracy while lowering hardware\ncomplexity and expense. A DTW-based system that reliably identifies muscle\nactivation patterns from short EMG signals was created and tested. Results show\nthat this single-sensor approach obtained an accuracy rate of 92%, which is\nsimilar to that of conventional multi-sensor systems. This research provides a\nmore straightforward and economical approach that can be used to obtain\nenhanced myoelectric control. These findings provide a different perspective on\nmore easily accessible and user-friendly prosthetic devices, which will be\nespecially helpful in disaster-affected areas where quick deployment is\nessential. Future improvements would investigate this system's dependability\nover time and wider implementations in real situations, to take prosthetic\ntechnology one step further.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-21T17:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.15279v1","title":"VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal\n  Large Language Models","summary":"Visual reasoning is a core component of human intelligence and a critical\ncapability for advanced multimodal models. Yet current reasoning evaluations of\nmultimodal large language models (MLLMs) often rely on text descriptions and\nallow language-based reasoning shortcuts, failing to measure genuine\nvision-centric reasoning. To address this, we introduce VisuLogic: a benchmark\nof 1,000 human-verified problems across six categories (e.g., quantitative\nshifts, spatial relations, attribute comparisons). These various types of\nquestions can be evaluated to assess the visual reasoning capabilities of MLLMs\nfrom multiple perspectives. We evaluate leading MLLMs on this benchmark and\nanalyze their results to identify common failure modes. Most models score below\n30% accuracy-only slightly above the 25% random baseline and far below the\n51.4% achieved by humans-revealing significant gaps in visual reasoning.\nFurthermore, we provide a supplementary training dataset and a\nreinforcement-learning baseline to support further progress.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.15552v1","title":"A Multi-Agent Framework for Automated Qinqiang Opera Script Generation\n  Using Large Language Models","summary":"This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T03:14:29Z"}
{"aid":"http://arxiv.org/abs/2504.15557v1","title":"Asymptotics of higher-order conditional tail moments for\n  convolution-equivalently distributed losses","summary":"This paper investigates the asymptotic behavior of higher-order conditional\ntail moments, which quantify the contribution of individual losses in the event\nof systemic collapse. The study is conducted within a framework comprising two\ninvestment portfolios experiencing dependent losses that follow\nconvolution-equivalent distributions. The main results are encapsulated in two\ntheorems: one addressing light-tailed losses with convolution-equivalent\ndistributions and the other focusing on heavy-tailed losses with regularly\nvarying distributions. Both results reveal that the asymptotic behavior remains\nrobust regardless of the strength of dependence. Additionally, numerical\nsimulations are performed under specific scenarios to validate the theoretical\nresults.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T03:24:07Z"}
{"aid":"http://arxiv.org/abs/2504.15575v1","title":"Exploring the User Experience of AI-Assisted Sound Searching Systems for\n  Creative Workflows","summary":"Locating the right sound effect efficiently is an important yet challenging\ntopic for audio production. Most current sound-searching systems rely on\npre-annotated audio labels created by humans, which can be time-consuming to\nproduce and prone to inaccuracies, limiting the efficiency of audio production.\nFollowing the recent advancement of contrastive language-audio pre-training\n(CLAP) models, we explore an alternative CLAP-based sound-searching system\n(CLAP-UI) that does not rely on human annotations. To evaluate the\neffectiveness of CLAP-UI, we conducted comparative experiments with a widely\nused sound effect searching platform, the BBC Sound Effect Library. Our study\nevaluates user performance, cognitive load, and satisfaction through\necologically valid tasks based on professional sound-searching workflows. Our\nresult shows that CLAP-UI demonstrated significantly enhanced productivity and\nreduced frustration while maintaining comparable cognitive demands. We also\nqualitatively analyzed the participants' feedback, which offered valuable\nperspectives on the design of future AI-assisted sound search systems.","main_category":"eess.AS","categories":"eess.AS,cs.SD","published":"2025-04-22T04:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.15576v1","title":"Reply to Comment on 'Product states and Schmidt rank of mutually\n  unbiased bases in dimension six'","summary":"Daniel McNulty $et.al$ \\cite{commentMUB} voiced suspicions to the Lemma 11(v)\nPart 6 in \\cite{Chen2017Product} and three theorems derived in later\npublications \\cite{Liang2019,lma2020,xyc}. For these suspicions, we reprove\nthat any $6\\times 6$ complex Hadamard matrix whose number of real elements more\nthan 22 does not belong to a set of four mutually unbiased bases. We show that\nthe number of $2\\times 2$ complex Hadamard submatrices of any $H_2$-reducible\nmatrix is not $10,...,16,18$. We also put forward some possible directions for\nfurther development.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T04:20:58Z"}
{"aid":"http://arxiv.org/abs/2504.15582v1","title":"Smooth Calibration and Decision Making","summary":"Calibration requires predictor outputs to be consistent with their Bayesian\nposteriors. For machine learning predictors that do not distinguish between\nsmall perturbations, calibration errors are continuous in predictions, e.g.,\nsmooth calibration error (Foster and Hart, 2018), Distance to Calibration\n(Blasiok et al., 2023a). On the contrary, decision-makers who use predictions\nmake optimal decisions discontinuously in probabilistic space, experiencing\nloss from miscalibration discontinuously. Calibration errors for\ndecision-making are thus discontinuous, e.g., Expected Calibration Error\n(Foster and Vohra, 1997), and Calibration Decision Loss (Hu and Wu, 2024).\nThus, predictors with a low calibration error for machine learning may suffer a\nhigh calibration error for decision-making, i.e., they may not be trustworthy\nfor decision-makers optimizing assuming their predictions are correct. It is\nnatural to ask if post-processing a predictor with a low calibration error for\nmachine learning is without loss to achieve a low calibration error for\ndecision-making. In our paper, we show that post-processing an online predictor\nwith $\\epsilon$ distance to calibration achieves $O(\\sqrt{\\epsilon})$ ECE and\nCDL, which is asymptotically optimal. The post-processing algorithm adds noise\nto make predictions differentially private. The optimal bound from low distance\nto calibration predictors from post-processing is non-optimal compared with\nexisting online calibration algorithms that directly optimize for ECE and CDL.","main_category":"cs.LG","categories":"cs.LG,cs.DS,stat.ML","published":"2025-04-22T04:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.15591v1","title":"Reconciling the Waiting Time Peaks Variations of Repeating FRBs with an\n  Eccentric Neutron Star--White Dwarf Binary","summary":"Fast radio bursts (FRBs) are luminous radio transients with millisecond\nduration. For some active repeaters, such as FRBs 20121102A and 20201124A, more\nthan a thousand bursts have been detected by the Five-hundred-meter Aperture\nSpherical radio Telescope (FAST). The waiting time (WT) distributions of both\nrepeaters, defined as the time intervals between adjacent (detected) bursts,\nexhibit a bimodal structure well-fitted by two log-normal functions. Notably,\nthe time scales of the long-duration WT peaks for both repeaters show a\ndecreasing trend over time. These similar burst features suggest that there may\nbe a common physical mechanism for FRBs~20121102A and 20201124A. In this paper,\nwe {revisit} the neutron star (NS)--white dwarf (WD) binary model with an\neccentric orbit to account for the observed changes in the long-duration WT\npeaks. According to our model, the shortening of the WT peaks corresponds to\nthe orbital period decay of the NS-WD binary. We consider two mass transfer\nmodes, namely, stable and unstable mass transfer, to examine how the orbital\nperiod evolves. Our findings reveal distinct evolutionary pathways for the two\nrepeaters: for FRB~20121102A, the NS-WD binary likely undergoes a combination\nof common envelope (CE) ejection and Roche lobe overflow, whereas for\nFRB~20201124A the system may experience multiple CE ejections. These findings\nwarrant further validation through follow-up observations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-22T05:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.15607v1","title":"Coupled Instantons In A Four-Well Potential With Application To The\n  Tunneling Of A Composite Particle","summary":"Coupled instantons are introduced by generalizing the double well potential\nto multiple mutually coupled wells. Physically this corresponds to the\nsimultaneous tunneling of multiple degrees of freedom. A system with four equal\nminima is examined in detail. It has three instanton types or flavors with\ndistinct actions. For weak coupling and subject to there being a single large\n(or small) parameter, the interactive system can be handled perturbatively. The\nzero mode problem arising from time translation symmetry is handled via the\nFadeev-Popov procedure. A diagrammatic procedure allows corrections to the\nfluctuation determinant to be calculated systematically. Independent instanton\ncontributions are summed over by extending the dilute gas approximation to\nthree flavors and energy splittings of the lowest four states is calculated.\nAll tunneling amplitudes are concisely expressed in terms of elementary\nfunctions. While the model is possibly useful for a variety of physical\nsystems, an application is made here to the tunneling of a composite particle\nin one dimension.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP,nucl-th","published":"2025-04-22T05:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.15628v1","title":"Joint Security-Latency Design for Short Packet-Based Low-Altitude\n  Communications","summary":"In this article, a joint security and latency analysis of short packet-based\nlow-altitude communications when the eavesdropper is close to the receiver is\naddressed. To reveal the impacts of the signal-to-noise ratio (SNR) and\nblock-length on latency in communications, we propose a new metric named secure\nlatency (SL) and derive the expressions for the effective secure probability\n(ESP) and the average SL. To minimize the average SL, different transmission\ndesigns are analyzed, in which the optimal solutions of SNR and block-length\nare provided. Numerical results validate our analysis and reveal the trade-off\nbetween reliability and security and the impacts of the block-length, SNR, and\npacket-generating rate on average SL, of which SNR and the block-length account\nfor main factors. In addition, we find that the performance of SL can be\nenhanced by allocating less SNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-22T06:40:28Z"}
{"aid":"http://arxiv.org/abs/2504.15636v1","title":"Contracting elements and conjugacy growth in Coxeter groups, graph\n  products, and further groups","summary":"In this article we construct contracting elements in the standard Cayley\ngraphs of the so-called periagroups, a family of groups introduced by the\nsecond-named author which include Coxeter groups, graph products, and Dyer\ngroups. As a consequence, we deduce that, unless they virtually split as direct\nproducts, periagroups are acylindrically hyperbolic and their conjugacy growth\nseries, with respect to standard generating sets, are transcendental.","main_category":"math.GR","categories":"math.GR,math.CO,math.MG","published":"2025-04-22T06:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.15672v1","title":"Comparative Analysis of Evolutionary Algorithms for Energy-Aware\n  Production Scheduling","summary":"The energy transition is driving rapid growth in renewable energy generation,\ncreating the need to balance energy supply and demand with energy price\nawareness. One such approach for manufacturers to balance their energy demand\nwith available energy is energyaware production planning. Through energy-aware\nproduction planning, manufacturers can align their energy demand with dynamic\ngrid conditions, supporting renewable energy integration while benefiting from\nlower prices and reduced emissions. Energy-aware production planning can be\nmodeled as a multi-criteria scheduling problem, where the objectives extend\nbeyond traditional metrics like makespan or required workers to also include\nminimizing energy costs and emissions. Due to market dynamics and the NP-hard\nmulti-objective nature of the problem, evolutionary algorithms are widely used\nfor energy-aware scheduling. However, existing research focuses on the design\nand analysis of single algorithms, with limited comparisons between different\napproaches. In this study, we adapt NSGA-III, HypE, and $\\theta$-DEA as memetic\nmetaheuristics for energy-aware scheduling to minimize makespan, energy costs,\nemissions, and the number of workers, within a real-time energy market context.\nThese adapted metaheuristics present different approaches for environmental\nselection. In a comparative analysis, we explore differences in solution\nefficiency and quality across various scenarios which are based on benchmark\ninstances from the literature and real-world energy market data. Additionally,\nwe estimate upper bounds on the distance between objective values obtained with\nour memetic metaheuristics and reference sets obtained via an exact solver.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-22T07:54:05Z"}
{"aid":"http://arxiv.org/abs/2504.15697v1","title":"Uniqueness of $v$-adic Gamma Functions in the Gross-Koblitz-Thakur\n  Formulas","summary":"In this paper, we determine all continuous non-vanishing functions satisfying\nGross-Koblitz-Thakur formulas in positive characteristic.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T08:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.15705v1","title":"Spin and energy diffusion vs. subdiffusion in disordered spin chains","summary":"While the high-temperature spin diffusion in spin chains with random local\nfields has been the subject of numerous studies concerning the phenomenon of\nmany-body localization (MBL), the energy diffusion in the same models has been\nmuch less explored. We show that energy diffusion is faster at weak random\nfields but becomes essentially equal at strong fields; hence, both diffusions\ndetermine the slowest relaxation time scale (Thouless time) in the system.\nNumerically reachable finite-size systems reveal the anomalously large\ndistribution of diffusion constants with respect to actual field\nconfigurations. Despite the exponential-like dependence of diffusion on field\nstrength, results for the sensitivity to twisted boundary conditions are\nincompatible with the Thouless criterion for localization and the presumable\ntransition to MBL, at least for numerically reachable sizes. In contrast, we\nfind indications for the scenario of subdiffusive transport, in particular in\nthe dynamical diffusivity response.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.str-el","published":"2025-04-22T08:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.15714v1","title":"Autonomous Control of Redundant Hydraulic Manipulator Using\n  Reinforcement Learning with Action Feedback","summary":"This article presents an entirely data-driven approach for autonomous control\nof redundant manipulators with hydraulic actuation. The approach only requires\nminimal system information, which is inherited from a simulation model. The\nnon-linear hydraulic actuation dynamics are modeled using actuator networks\nfrom the data gathered during the manual operation of the manipulator to\neffectively emulate the real system in a simulation environment. A neural\nnetwork control policy for autonomous control, based on end-effector (EE)\nposition tracking is then learned using Reinforcement Learning (RL) with\nOrnstein-Uhlenbeck process noise (OUNoise) for efficient exploration. The RL\nagent also receives feedback based on supervised learning of the forward\nkinematics which facilitates selecting the best suitable action from\nexploration. The control policy directly provides the joint variables as\noutputs based on provided target EE position while taking into account the\nsystem dynamics. The joint variables are then mapped to the hydraulic valve\ncommands, which are then fed to the system without further modifications. The\nproposed approach is implemented on a scaled hydraulic forwarder crane with\nthree revolute and one prismatic joint to track the desired position of the EE\nin 3-Dimensional (3D) space. With the emulated dynamics and extensive learning\nin simulation, the results demonstrate the feasibility of deploying the learned\ncontroller directly on the real system.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T08:55:28Z"}
{"aid":"http://arxiv.org/abs/2504.15718v1","title":"Riesz transform, function spaces and their applications on infinite\n  dimensional compact groups","summary":"On a compact connected group $G$, consider the infinitesimal generator $-L$\nof a central symmetric Gaussian convolution semigroup $(\\mu_t)_{t>0}$. We\nestablish several regularity results of the solution to the Poisson equation\n$LU=F$, both in strong and weak senses. To this end, we introduce two classes\nof Lipschitz spaces for $1\\le p\\le \\infty$: $\\Lambda_{\\theta}^p$, defined via\nthe associated Markov semigroup, and $\\mathrm L_{\\theta}^p$, defined via the\nintrinsic distance. In the strong sense, we prove a priori Sobolev regularity\nand Lipschitz regularity in the class of $\\Lambda_{\\theta}^p$ space. In the\ndistributional sense, we further show local regularity in the class of $\\mathrm\nL_{\\theta}^{\\infty}$ space. These results require some strong assumptions on\n$-L$. Our main techniques build on the differentiability of the associated\nsemigroup, explicit dimension-free $L^p$ ($1<p<\\infty$) boundedness of first\nand second order Riesz transforms, and a comparison between the two Lipschitz\nnorms.","main_category":"math.AP","categories":"math.AP,math.FA,math.PR","published":"2025-04-22T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.15722v1","title":"From predictions to confidence intervals: an empirical study of\n  conformal prediction methods for in-context learning","summary":"Transformers have become a standard architecture in machine learning,\ndemonstrating strong in-context learning (ICL) abilities that allow them to\nlearn from the prompt at inference time. However, uncertainty quantification\nfor ICL remains an open challenge, particularly in noisy regression tasks. This\npaper investigates whether ICL can be leveraged for distribution-free\nuncertainty estimation, proposing a method based on conformal prediction to\nconstruct prediction intervals with guaranteed coverage. While traditional\nconformal methods are computationally expensive due to repeated model fitting,\nwe exploit ICL to efficiently generate confidence intervals in a single forward\npass. Our empirical analysis compares this approach against ridge\nregression-based conformal methods, showing that conformal prediction with\nin-context learning (CP with ICL) achieves robust and scalable uncertainty\nestimates. Additionally, we evaluate its performance under distribution shifts\nand establish scaling laws to guide model training. These findings bridge ICL\nand conformal prediction, providing a theoretically grounded and new framework\nfor uncertainty quantification in transformer-based models.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T09:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15729v1","title":"Strong discrete Morse theory","summary":"The purpose of this work is to develop a version of Forman's discrete Morse\ntheory for simplicial complexes, based on internal strong collapses. Classical\ndiscrete Morse theory can be viewed as a generalization of Whitehead's\ncollapses, where each Morse function on a simplicial complex $K$ defines a\nsequence of elementary internal collapses. This reduction guarantees the\nexistence of a CW-complex that is homotopy equivalent to $K$, with cells\ncorresponding to the critical simplices of the Morse function. However, this\napproach lacks an explicit combinatorial description of the attaching maps,\nwhich limits the reconstruction of the homotopy type of $K$. By restricting\ndiscrete Morse functions to those induced by total orders on the vertices, we\ndevelop a strong discrete Morse theory, generalizing the strong collapses\nintroduced by Barmak and Minian. We show that, in this setting, the resulting\nreduced CW-complex is regular, enabling us to recover its homotopy type\ncombinatorially. We also provide an algorithm to compute this reduction and\napply it to obtain efficient structures for complexes in the library of\ntriangulations by Benedetti and Lutz.","main_category":"math.AT","categories":"math.AT","published":"2025-04-22T09:23:45Z"}
{"aid":"http://arxiv.org/abs/2504.15744v1","title":"Existence and Spectrality of random measures generated by infinite\n  convolutions","summary":"In this paper, we construct a class of random measures $\\mu^{\\mathbf{n}}$ by\ninfinite convolutions. Given infinitely many admissible pairs $\\{(N_{k},\nB_{k})\\}_{k=1}^{\\infty}$ and a positive integral sequence\n$\\boldsymbol{n}=\\{n_{k}\\}_{k=1}^{\\infty}$, for every $\\boldsymbol{\\omega}\\in\n\\mathbb{N}^{\\mathbb{N}}$, we write $\\mu^{\\mathbf{n}}(\\boldsymbol{\\omega}) =\n\\delta_{N_{\\omega_{1}}^{-n_{1}}B_{\\omega_{1}}} *\n\\delta_{N_{\\omega_{1}}^{-n_{1}}N_{\\omega_{2}}^{-n_{2}}B_{\\omega_{2}}} *\n\\cdots$. If $n_{k}=1$ for $k\\geq 1$, write\n$\\mu(\\boldsymbol{\\omega})=\\mu^{\\mathbf{n}}(\\boldsymbol{\\omega})$.\n  First, we show that the mapping $\\mu^{\\mathbf{n}}: (\\boldsymbol{\\omega}, B)\n\\mapsto \\mu^{\\mathbf{n}}(\\boldsymbol{\\omega})(B)$ is a random measure if the\nfamily of Borel probability measures $\\{\\mu(\\boldsymbol{\\omega}) :\n\\boldsymbol{\\omega} \\in \\mathbb{N}^{\\mathbb{N}}\\}$ is tight. Then, for every\nBernoulli measure $\\mathbb{P}$ on $\\mathbb{N}^{\\mathbb{N}}$, the random measure\n$\\mu^{\\mathbf{n}}$ is also a spectral measure $\\mathbb{P}$-a.e.. If the\npositive integral sequence $\\boldsymbol{n}$ is unbounded, the random measure\n$\\mu^{\\mathbf{n}}$ is a spectral measure regardless of the measures on the\nsequence space $\\mathbb{N}^{\\mathbb{N}}$. Moreover, we provide some sufficient\nconditions for the existence of the random measure $\\mu^{\\boldsymbol{n}}$.\nFinally, we verify that random measures have the intermediate-value property.","main_category":"math.FA","categories":"math.FA","published":"2025-04-22T09:46:31Z"}
{"aid":"http://arxiv.org/abs/2504.15746v1","title":"Enhancing Tennis Training with Real-Time Swing Data Visualisation in\n  Immersive Virtual Reality","summary":"Recent advances in immersive technology have opened new possibilities in\nsports training, especially for activities requiring precise motor skills, such\nas tennis. In this paper, we present a virtual reality (VR) tennis training\nsystem integrating real-time performance feedback through a wearable sensor\ndevice. Ten participants wore the sensor on their dominant hand to capture\nmotion data, including swing speed and swing power, while engaging in a VR\ntennis environment. Initially, participants performed baseline tests without\naccess to performance metrics. In subsequent tests, participants executed\nsimilar routines with their swing data displayed in real-time via a VR overlay.\nQualitative and quantitative results indicated that real-time visual feedback\nled to improved performance behaviors and enhanced situational awareness. Some\nparticipants exhibited increased swing consistency and strategic\ndecision-making, though improvements in accuracy varied individually.\nAdditionally, subjective feedback highlighted that the immersive experience,\ncombined with instantaneous performance metrics, enhanced player engagement and\nmotivation. These findings illustrate the effectiveness of VR-based data\nvisualisation in sports training, suggesting broader applicability in\nperformance enhancement.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T09:48:40Z"}
{"aid":"http://arxiv.org/abs/2504.15757v1","title":"Retrieving day- and nightside atmospheric properties of the ultra-hot\n  Jupiter TOI-2109b. Detection of Fe and CO emission lines and evidence for\n  inefficient heat transport","summary":"The ultra-hot Jupiter (UHJ) TOI-2109b marks the lower edge of the equilibrium\ntemperature gap between 3500 K and 4500 K, an unexplored thermal regime that\nseparates KELT-9b, the hottest planet yet discovered, from all other currently\nknown gas giants. To study the structure of TOI-2109b's atmosphere, we obtained\nhigh-resolution emission spectra of both the planetary day- and nightsides with\nCARMENES and CRIRES$^+$. By applying the cross-correlation technique, we\nidentified the emission signatures of Fe I and CO, as well as a thermal\ninversion layer in the dayside atmosphere; no significant H$_2$O signal was\ndetected from the dayside. None of the analyzed species were detectable from\nthe nightside atmosphere. We applied a Bayesian retrieval framework that\ncombines high-resolution spectroscopy with photometric measurements to\nconstrain the dayside atmospheric parameters and derive upper limits for the\nnightside hemisphere. The dayside thermal inversion extends from 3200 K to 4600\nK, with an atmospheric metallicity consistent with that of the host star (0.36\ndex). Only weak constraints could be placed on the C/O ratio ($>$ 0.15). The\nretrieved spectral line broadening is consistent with tidally locked rotation,\nindicating the absence of strong dynamical processes. An upper temperature\nlimit of 2400 K and a maximum atmospheric temperature gradient of 700 K/log bar\ncould be derived for the nightside. Comparison of the retrieved dayside T-p\nprofile with theoretical models, the absence of strong atmospheric dynamics,\nand significant differences in the thermal constraints between the day- and\nnightside hemispheres suggest a limited heat transport efficiency across the\nplanetary atmosphere. Overall, our results place TOI-2109b in a transitional\nregime between the UHJs below the thermal gap, which show both CO and H$_2$O\nemission lines, and KELT-9b, where molecular features are largely absent.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-22T10:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.15795v1","title":"Spontaneous stochasticity and the Armstrong-Vicol passive scalar","summary":"Spontaneous stochasticity refers to the emergence of intrinsic randomness in\ndeterministic systems under singular limits, a phenomenon conjectured to be\nfundamental in turbulence. Armstrong and Vicol \\citep{AV23,AV24} recently\nconstructed a deterministic, divergence-free multiscale vector field\narbitrarily close to a weak Euler solution, proving that a passive scalar\ntransported by this field exhibits anomalous dissipation and lacks a selection\nprinciple in the vanishing diffusivity limit.\n  {\\it This work aims to explain why this passive scalar exhibits both\nLagrangian and Eulerian spontaneous stochasticity.}\n  Part I provides a historical overview of spontaneous stochasticity, details\nthe Armstrong-Vicol passive scalar model, and presents numerical evidence of\nanomalous diffusion, along with a refined description of the Lagrangian flow\nmap.\n  In Part II, we develop a theoretical framework for Eulerian spontaneous\nstochasticity. We define it mathematically, linking it to ill-posedness and\nfinite-time trajectory splitting, and explore its measure-theoretic properties\nand the connection to RG formalism. This leads us to a well-defined {\\it\nmeasure selection principle} in the inviscid limit. This approach allows us to\nrigorously classify universality classes based on the ergodic properties of\nregularisations. To complement our analysis, we provide simple yet insightful\nnumerical examples.\n  Finally, we show that the absence of a selection principle in the\nArmstrong-Vicol model corresponds to Eulerian spontaneous stochasticity of the\npassive scalar. We also numerically compute the probability density of the\neffective renormalised diffusivity in the inviscid limit. We argue that the\nlack of a selection principle should be understood as a measure selection\nprinciple over weak solutions of the inviscid system.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T11:15:21Z"}
{"aid":"http://arxiv.org/abs/2504.15796v1","title":"Locating and Mitigating Gradient Conflicts in Point Cloud Domain\n  Adaptation via Saliency Map Skewness","summary":"Object classification models utilizing point cloud data are fundamental for\n3D media understanding, yet they often struggle with unseen or\nout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain\nadaptation (UDA) methods typically employ a multi-task learning (MTL) framework\nthat combines primary classification tasks with auxiliary self-supervision\ntasks to bridge the gap between cross-domain feature distributions. However,\nour further experiments demonstrate that not all gradients from\nself-supervision tasks are beneficial and some may negatively impact the\nclassification performance. In this paper, we propose a novel solution, termed\nSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient\nconflicts. Specifically, our method designs a new scoring mechanism based on\nthe skewness of 3D saliency maps to estimate gradient conflicts without\nrequiring target labels. Leveraging this, we develop a sample selection\nstrategy that dynamically filters out samples whose self-supervision gradients\nare not beneficial for the classification. Our approach is scalable,\nintroducing modest computational overhead, and can be integrated into all the\npoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that our\nmethod outperforms state-of-the-art approaches. In addition, we provide a new\nperspective on understanding the UDA problem through back-propagation analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-22T11:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.15798v1","title":"Quantum Entanglement Autodistillation in Baryon Pair Decays","summary":"We study the spin-entangled mixed state of a spin-1/2 baryon-antibaryon pair\nproduced in the process e+e- to J/psi, psi(2S) to BBbar. We demonstrate that\nthe spin entanglement of the system can increase following the decays B to b +\nM and Bbar to bbar + Mbar, where b and bbar are spin-1/2 baryons and M, Mbar\nare spin-0 mesons. This phenomenon, known as entanglement autodistillation,\nrepresents a probabilistic amplification of entanglement during the decay\nprocess. We analyze the underlying mechanism and show that it depends only on\nthe initial state of the BBbar system and the decay parameter alphaD, but not\non the phase parameter phiD.","main_category":"hep-ph","categories":"hep-ph,hep-ex,quant-ph","published":"2025-04-22T11:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.15816v1","title":"Toward optimal-scaling DFT: stochastic Hartree theory in the\n  thermodynamic and complete basis set limits at arbitrary temperature","summary":"We present the first mathematical analysis of stochastic density functional\ntheory (DFT) in the context of the Hartree approximation. We motivate our\nanalysis via the notion of nearly-optimal or $\\tilde{O}(n)$ scaling with\nrespect to the number $n$ of computational degrees of freedom, independent of\nthe number of electrons, in both the thermodynamic and complete basis set\nlimits. Indeed, the promise of such scaling is the primary motivation for\nstochastic DFT relative to conventional orbital-based approaches, as well as\ndeterministic orbital-free alternatives. We highlight three key targets for\nmathematical attention, which are synthesized in our algorithm and analysis.\nFirst, we identify a particular stochastic estimator for the Hartree potential\nwhose sample complexity is essentially independent of the discretization size.\nSecond, we reformulate the self-consistent field iteration as a stochastic\nmirror descent method where the Fermi-Dirac entropy plays the role of the\nBregman potential, and we prove a nearly discretization-independent bound on\nthe number of iterations needed to reach fixed accuracy. Third, motivated by\nthe estimator, we introduce a novel pole expansion scheme for the square-root\nFermi-Dirac operator, preserving $\\tilde{O}(n)$ cost per mirror descent\niteration even in the complete basis set limit. Combining these ingredients, we\nestablish nearly-optimal scaling in both limits of interest under reasonable\nassumptions on the basis sets chosen for discretization. Extensive numerical\nexperiments on problems with as many as $10^{6}$ degrees of freedom validate\nour algorithm and support the theory of nearly-optimal scaling.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T11:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.15819v1","title":"Delayed Keen Model with Inflation","summary":"Keen's model describes the dynamics between wage share, employment rate and\ndebt ratio. In literature, the model was extended to represent the effects of\ninflation and also the speculative money flow. Based on the inflationary model,\nwe take into account a time delay in the inflation term which stands for the\nperiod before the effects of inflation are seen. We observe that, the delayed\nsystem may experience a Hopf bifurcation and exhibit cyclic behavior around an\nequilibrium point, although the non-delayed model is stable under the same\nconditions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T12:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.15866v1","title":"On the projective structures given by theta","summary":"Given a compact Riemann surface $C$, the line in $H^0(J_C,\\, 2\\Theta)$\northogonal to the sections vanishing at $0$ produces a natural projective\nstructure on $C$. We investigate the properties of this projective structure.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T13:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.15875v1","title":"Identifying eclipsing binary stars with TESS data based on a new hybrid\n  deep learning model","summary":"Eclipsing binary systems (EBs), as foundational objects in stellar\nastrophysics, have garnered significant attention in recent years. These\nsystems exhibit periodic decreases in light intensity when one star obscures\nthe other from the observer's perspective, producing characteristic light\ncurves (LCs). With the advent of the Transiting Exoplanet Survey Satellite\n(TESS), a vast repository of stellar LCs has become available, offering\nunprecedented opportunities for discovering new EBs. To efficiently identify\nsuch systems, we propose a novel method that combines LC data and generalized\nLomb-Scargle periodograms (GLS) data to classify EBs. At the core of this\nmethod is CNN Attention LSTM Net (CALNet), a hybrid deep learning model\nintegrating Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM)\nnetworks, and an Attention Mechanism based on the Convolutional Block Attention\nModule (CBAM). We collected 4,225 EB samples, utilizing their 2-minute cadence\nLCs for model training and validation. CALNet achieved a recall rate of 99.1%,\ndemonstrating its robustness and effectiveness. Applying it to TESS 2-minute\nLCs from Sectors 1 to 74, we identified 9,351 new EBs after manual visual\ninspection, significantly expanding the known sample size. This work highlights\nthe potential of advanced deep-learning techniques in large-scale astronomical\nsurveys and provides a valuable resource for further studies on EBs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-22T13:22:33Z"}
{"aid":"http://arxiv.org/abs/2504.15906v1","title":"Restricted Repetitive Behaviors in Adolescent Males with Autism:\n  Volatility in Brain Functional Connectivities","summary":"This paper studies subtypes of restricted, repetitive and stereotypical\nbehaviors (RRBs) in adolescent males with autism spectrum disorder (ASD) from\nthe viewpoint of the dynamics of brain functional connectivities (FCs). Data\nfrom the ABIDE-II repository and Repetitive Behavior Scale-Revised (RBS-R)\nmetrics are used to form two ASD groups with tightly controlled demographics;\none comprises subjects with scores above threshold for the self-injurious\nbehaviors (SIBs) subscale, and the other subjects with scores below threshold\nfor SIBs, but above threshold for at least one of the other subscales\n(stereotyped, compulsive, ritualistic, insistence on sameness, restricted\ninterests). The dynamics of the coherence for FCs across distinct frequency\nbands are compared against matched controls, using a novel volatility measure\ncomputed in time-frequency space. We find statistically significant\ndifferences, on average, in the volatility of a relatively small set of FCs,\nmost mapping to either the default mode network or the cerebellum, in the mid-\nand high-frequency bands, and yielding higher volatility in subjects with high\nlevels of SIBs. Results suggest a distinct underlying profile for SIBs\ninvolving multiple brain regions associated with rewards and emotions\nprocessing. The work contributes to the identification of neural substrates\npotentially underlying behavioral subtypes, and may help target interventions.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-22T13:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.15910v1","title":"Consistency between Bulk and Boundary Causalities in Asymptotically\n  Anti-de Sitter Spacetimes","summary":"We investigate the consistency between bulk and boundary causalities in\nstatic, spherically symmetric, asymptotically anti-de Sitter (AdS) spacetimes.\nWe derive a general formula that provides sufficient conditions for time\nadvance, where bulk propagation arrives earlier than any boundary propagation.\nAs an application, we show that in Reissner--Nordstr\\\"{o}m--anti de Sitter\nspacetime, no geodesic satisfies the sufficient conditions for time advance\neven in the super-extremal case. Furthermore, we demonstrate that the\nEinstein--Euler--Heisenberg theory exhibits time advance when one or a linear\ncombination of the coupling constants is positive and below an upper bound\ndetermined by the AdS length scale.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-22T13:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.15913v1","title":"A Massive Gas Outflow Outside the Line-of-Sight: Imaging Polarimetry of\n  the Blue Excess Hot Dust Obscured Galaxy W0204-0506","summary":"(Aims) Hot Dust Obscured Galaxies (Hot DOGs) are a population of\nhyper-luminous, heavily obscured quasars. Although nuclear obscurations close\nto Compton-thick are typical, a fraction show blue UV spectral energy\ndistributions consistent with unobscured quasar activity, albeit two orders of\nmagnitude fainter than expected from their mid-IR luminosity. The origin of the\nUV emission in these Blue excess Hot DOGs (BHDs) has been linked to scattered\nlight from the central engine. Here we study the properties of the UV emission\nin the BHD WISE J020446.13-050640.8 (W0204-0506). (Methods) We use imaging\npolarization observations in the $R_{\\rm Special}$ band obtained with the FORS2\ninstrument at VLT. We compare these data with radiative transfer simulations to\nconstrain the characteristics of the scattering material. (Results) We find a\nspatially integrated polarization fraction of $24.7\\pm 0.7$%, confirming the\nscattered-light nature of the UV emission of W0204-0506. The source is\nspatially resolved in the observations and we find a gradient in polarization\nfraction and angle that is aligned with the extended morphology of the source\nfound in HST/WFC3 imaging. A dusty, conical polar outflow starting at the AGN\nsublimation radius with a half-opening angle $\\lesssim 50~\\rm deg$ viewed at an\ninclination $\\gtrsim 45~\\rm deg$ can reproduce the observed polarization\nfraction if the dust is graphite-rich. We find that the gas mass and outflow\nvelocity are consistent with the range of values found for [OIII] outflows\nthrough spectroscopy in other Hot DOGs, though it is unclear whether the\noutflow is energetic enough to affect the long-term evolution of the host\ngalaxy. Our study highlights the unique potential for polarization imaging to\nstudy dusty quasar outflows, providing complementary constraints to those\nobtained through traditional spectroscopic studies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-22T14:00:11Z"}
{"aid":"http://arxiv.org/abs/2504.15920v1","title":"ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order\n  Neighboring Feature Fusion","summary":"Graph Neural Networks (GNNs) have demonstrated strong performance across\nvarious graph-based tasks by effectively capturing relational information\nbetween nodes. These models rely on iterative message passing to propagate node\nfeatures, enabling nodes to aggregate information from their neighbors. Recent\nresearch has significantly improved the message-passing mechanism, enhancing\nGNN scalability on large-scale graphs. However, GNNs still face two main\nchallenges: over-smoothing, where excessive message passing results in\nindistinguishable node representations, especially in deep networks\nincorporating high-order neighbors; and scalability issues, as traditional\narchitectures suffer from high model complexity and increased inference time\ndue to redundant information aggregation. This paper proposes a novel framework\nfor large-scale graphs named ScaleGNN that simultaneously addresses both\nchallenges by adaptively fusing multi-level graph features. We first construct\nneighbor matrices for each order, learning their relative information through\ntrainable weights through an adaptive high-order feature fusion module. This\nallows the model to selectively emphasize informative high-order neighbors\nwhile reducing unnecessary computational costs. Additionally, we introduce a\nHigh-order redundant feature masking mechanism based on a Local Contribution\nScore (LCS), which enables the model to retain only the most relevant neighbors\nat each order, preventing redundant information propagation. Furthermore,\nlow-order enhanced feature aggregation adaptively integrates low-order and\nhigh-order features based on task relevance, ensuring effective capture of both\nlocal and global structural information without excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that our approach consistently\noutperforms state-of-the-art GNN models in both accuracy and computational\nefficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.15930v1","title":"StreamRL: Scalable, Heterogeneous, and Elastic RL for LLMs with\n  Disaggregated Stream Generation","summary":"Reinforcement learning (RL) has become the core post-training technique for\nlarge language models (LLMs). RL for LLMs involves two stages: generation and\ntraining. The LLM first generates samples online, which are then used to derive\nrewards for training. The conventional view holds that the colocated\narchitecture, where the two stages share resources via temporal multiplexing,\noutperforms the disaggregated architecture, in which dedicated resources are\nassigned to each stage. However, in real-world deployments, we observe that the\ncolocated architecture suffers from resource coupling, where the two stages are\nconstrained to use the same resources. This coupling compromises the\nscalability and cost-efficiency of colocated RL in large-scale training. In\ncontrast, the disaggregated architecture allows for flexible resource\nallocation, supports heterogeneous training setups, and facilitates\ncross-datacenter deployment.\n  StreamRL is designed with disaggregation from first principles and fully\nunlocks its potential by addressing two types of performance bottlenecks in\nexisting disaggregated RL frameworks: pipeline bubbles, caused by stage\ndependencies, and skewness bubbles, resulting from long-tail output length\ndistributions. To address pipeline bubbles, StreamRL breaks the traditional\nstage boundary in synchronous RL algorithms through stream generation and\nachieves full overlapping in asynchronous RL. To address skewness bubbles,\nStreamRL employs an output-length ranker model to identify long-tail samples\nand reduces generation time via skewness-aware dispatching and scheduling.\nExperiments show that StreamRL improves throughput by up to 2.66x compared to\nexisting state-of-the-art systems, and improves cost-effectiveness by up to\n1.33x in a heterogeneous, cross-datacenter setting.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-22T14:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.15980v1","title":"Construction of Butson matrices using Fourier matrices as input","summary":"Butson matrices are square orthogonal matrices, denoted by $BH(m,n)$, whose\nentries are the complex $m$th roots of unity and satisfy the condition\\\\\n$BH(m,n)\\cdot{BH(m,n)}^*=nI_n$, where ${BH(m,n)}^*$ is the conjugate transpose\nof $BH(m,n)$ and $I_n$ is the identity matrix. In this work, we propose\nconstructions for $BH(m,(n-1)n)$ then $BH(m,(\\frac{n}{2}-1)n)$, when $n$ and\n$m$ are even numbers, using the existing $BH(m,n)$. For each case, we provide\ntwo construction methods: one uses a single input Butson matrix, and another\nuses two input Butson matrices. Moreover, we present some results about the\nconstruction of Hadamard matrices.","main_category":"math.CO","categories":"math.CO","published":"2025-04-22T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.15981v1","title":"Differential modules: a perspective on Bass' question","summary":"Guided by the $Q$-shaped derived category framework introduced by Holm and\nJorgensen, we provide a differential module analogue of a classical result that\ncharacterises when a finitely generated module over a local commutative\nnoetherian ring has finite injective dimension. As an application, we\ncharacterise local Cohen-Macaulay rings using the homological algebra of\ndifferential modules.","main_category":"math.RT","categories":"math.RT,math.AC","published":"2025-04-22T15:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.15984v1","title":"Neuroadaptive Haptics: Comparing Reinforcement Learning from Explicit\n  Ratings and Neural Signals for Adaptive XR Systems","summary":"Neuroadaptive haptics offers a path to more immersive extended reality (XR)\nexperiences by dynamically tuning multisensory feedback to user preferences. We\npresent a neuroadaptive haptics system that adapts XR feedback through\nreinforcement learning (RL) from explicit user ratings and brain-decoded neural\nsignals. In a user study, participants interacted with virtual objects in VR\nwhile Electroencephalography (EEG) data were recorded. An RL agent adjusted\nhaptic feedback based either on explicit ratings or on outputs from a neural\ndecoder. Results show that the RL agent's performance was comparable across\nfeedback sources, suggesting that implicit neural feedback can effectively\nguide personalization without requiring active user input. The EEG-based neural\ndecoder achieved a mean F1 score of 0.8, supporting reliable classification of\nuser experience. These findings demonstrate the feasibility of combining\nbrain-computer interfaces (BCI) and RL to autonomously adapt XR interactions,\nreducing cognitive load and enhancing immersion.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T15:34:19Z"}
{"aid":"http://arxiv.org/abs/2504.16005v1","title":"CAPO: Cost-Aware Prompt Optimization","summary":"Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.NE,stat.ML","published":"2025-04-22T16:14:31Z"}
{"aid":"http://arxiv.org/abs/2504.16031v1","title":"VR-based Intervention for Perspective Change: A Case to Investigate\n  Virtual Materiality","summary":"This paper addresses the concept of materiality in virtual environments,\nwhich we define as being composed of objects that can influence user experience\nactively. Such virtual materiality is closely related to its physical\ncounterpart, which is discussed in theoretical frameworks such as\nsociomateriality and actor-network theory. They define phenomena in terms of\nthe entanglement of human and non-human elements. We report on an early\ninvestigation of virtual materiality within the context of reflection and\nperspective change in nature-based virtual environments. We considered the case\nof university students reflecting on the planning and management of their\ntheses and major projects. Inspired by nature's known positive cognitive and\naffective effects and repeated questioning processes, we established a virtual\nreflection intervention to demonstrate the environmental mechanisms and\nmaterial characteristics relevant to virtual materiality. Our work is a\npreliminary step toward understanding virtual materiality and its implications\nfor research and the design of virtual environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T16:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.16037v1","title":"Adaptive Fault-tolerant Control of Underwater Vehicles with Thruster\n  Failures","summary":"This paper presents a fault-tolerant control for the trajectory tracking of\nautonomous underwater vehicles (AUVs) against thruster failures. We formulate\nfaults in AUV thrusters as discrete switching events during a UAV mission, and\ndevelop a soft-switching approach in facilitating shift of control strategies\nacross fault scenarios. We mathematically define AUV thruster fault scenarios,\nand develop the fault-tolerant control that captures the fault scenario via\nBayesian approach. Particularly, when the AUV fault type switches from one to\nanother, the developed control captures the fault states and maintains the\ncontrol by a linear quadratic tracking controller. With the captured fault\nstates by Bayesian approach, we derive the control law by aggregating the\ncontrol outputs for individual fault scenarios weighted by their Bayesian\nposterior probability. The developed fault-tolerant control works in an\nadaptive way and guarantees soft-switching across fault scenarios, and requires\nno complicated fault detection dedicated to different type of faults. The\nentailed soft-switching ensures stable AUV trajectory tracking when fault type\nshifts, which otherwise leads to reduced control under hard-switching control\nstrategies. We conduct numerical simulations with diverse AUV thruster fault\nsettings. The results demonstrate that the proposed control can provide smooth\ntransition across thruster failures, and effectively sustain AUV trajectory\ntracking control in case of thruster failures and failure shifts.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-22T17:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.16413v1","title":"Hierarchical Distributed Architecture for the Least Allan Variance\n  Atomic Timing","summary":"In this paper, we propose a hierarchical distributed timing architecture\nbased on an ensemble of miniature atomic clocks. The goal is to ensure\nsynchronized and accurate timing in a normal operating mode where Global\nNavigation Satellite System (GNSS) signals are available, as well as in an\nemergency operating mode during GNSS failures. At the lower level, the\nminiature atomic clocks employ a distributed control strategy that uses only\nlocal information to ensure synchronization in both modes. The resulting\nsynchronized time or generated time scale has the best frequency stability, as\nmeasured by the Allan variance, over the short control period. In the upper\nlayer, a supervisor controls the long-term behavior of the generated time\nscale. In the normal operating mode, the supervisor periodically anchors the\ngenerated time scale to the standard time based on GNSS signals, while in the\nemergency operating mode, it applies optimal floating control to reduce the\ndivergence rate of the generated time scale, which is not observable from the\nmeasurable time difference between the miniature atomic clocks. This floating\ncontrol aims to explicitly control the generated time scale to have the least\nAllan variance over the long control period. Finally, numerical examples are\nprovided to demonstrate the effectiveness and feasibility of the architecture\nin high-precision, GNSS-resilient atomic timing.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:35:33Z"}
{"aid":"http://arxiv.org/abs/2504.16459v1","title":"Insect-Computer Hybrid Speaker: Speaker using Chirp of the Cicada\n  Controlled by Electrical Muscle Stimulation","summary":"We propose \"Insect-Computer Hybrid Speaker\", which enables us to make musics\nmade from combinations of computer and insects. Lots of studies have proposed\nmethods and interfaces for controlling insects and obtaining feedback. However,\nthere have been less research on the use of insects for interaction with third\nparties. In this paper, we propose a method in which cicadas are used as\nspeakers triggered by using Electrical Muscle Stimulation (EMS). We explored\nand investigated the suitable waveform of chirp to be controlled, the\nappropriate voltage range, and the maximum pitch at which cicadas can chirp.","main_category":"cs.HC","categories":"cs.HC,cs.AR,cs.ET,cs.RO,cs.SD","published":"2025-04-23T07:04:37Z"}
{"aid":"http://arxiv.org/abs/2504.16467v1","title":"MTSGL: Multi-Task Structure Guided Learning for Robust and Interpretable\n  SAR Aircraft Recognition","summary":"Aircraft recognition in synthetic aperture radar (SAR) imagery is a\nfundamental mission in both military and civilian applications. Recently deep\nlearning (DL) has emerged a dominant paradigm for its explosive performance on\nextracting discriminative features. However, current classification algorithms\nfocus primarily on learning decision hyperplane without enough comprehension on\naircraft structural knowledge. Inspired by the fined aircraft annotation\nmethods for optical remote sensing images (RSI), we first introduce a\nstructure-based SAR aircraft annotations approach to provide structural and\ncompositional supplement information. On this basis, we propose a multi-task\nstructure guided learning (MTSGL) network for robust and interpretable SAR\naircraft recognition. Besides the classification task, MTSGL includes a\nstructural semantic awareness (SSA) module and a structural consistency\nregularization (SCR) module. The SSA is designed to capture structure semantic\ninformation, which is conducive to gain human-like comprehension of aircraft\nknowledge. The SCR helps maintain the geometric consistency between the\naircraft structure in SAR imagery and the proposed annotation. In this process,\nthe structural attribute can be disentangled in a geometrically meaningful\nmanner. In conclusion, the MTSGL is presented with the expert-level aircraft\nprior knowledge and structure guided learning paradigm, aiming to comprehend\nthe aircraft concept in a way analogous to the human cognitive process.\nExtensive experiments are conducted on a self-constructed multi-task SAR\naircraft recognition dataset (MT-SARD) and the effective results illustrate the\nsuperiority of robustness and interpretation ability of the proposed MTSGL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:27:08Z"}
{"aid":"http://arxiv.org/abs/2504.16488v1","title":"A strategy for the enhancement of barocaloric performance in plastic\n  crystal solid solutions","summary":"The drive for solid-state heating and cooling technologies is fuelled by\ntheir potential for enhanced sustainability and environmental impact compared\nto traditional vapour compression devices. The recent discovery of colossal\nbarocaloric (BC) effects in the plastic crystal (PC) neopentyl glycol (NPG) has\nhighlighted PCs as promising candidates for future solid-state thermal\nmanagement. However, achieving optimal operational temperatures, low-pressure\nrequirements, and substantial entropy changes in a single material remains\nchallenging. Here, we demonstrate a strategy to address these constraints by\nforming a ternary solid solution of neopentyl PCs: NPG, pentaglycerine (PG) and\npentaerythritol (PE). Notably, by including only a small quantity (2%) of the\nthird component, we observe a seven-fold increase in reversible isothermal\nentropy change (|{\\Delta}Sit,rev| = 13.4 J kg-1 K-1) and twenty-fold increase\nin operational temperature span ({\\Delta}Tspan = 18 K) at pressures of 1 kbar,\ncompared to pure NPG. The origin of these enhancements is revealed by\nquasielastic neutron scattering and synchrotron powder x-ray diffraction. We\nfind a reduction in the activation energies of the rotational modes associated\nwith the main entropic component of the BC effect, linked to a weakening of the\nintermolecular hydrogen bond network. This is proposed to improve the phase\ntransition reversibility and operational temperature span by facilitating a\nbroadened first-order phase transition, characterised by a significant phase\nco-existence region. These findings suggest an effective strategy for\npracticable molecular BCs, which is to design solid solutions that exploit the\nlarge compositional phase space of multi-component molecular systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-23T08:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.16505v1","title":"TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand\n  Urban Scenes and Provide Travel Assistance","summary":"Tourism and travel planning increasingly rely on digital assistance, yet\nexisting multimodal AI systems often lack specialized knowledge and contextual\nunderstanding of urban environments. We present TraveLLaMA, a specialized\nmultimodal language model designed for urban scene understanding and travel\nassistance. Our work addresses the fundamental challenge of developing\npractical AI travel assistants through a novel large-scale dataset of 220k\nquestion-answer pairs. This comprehensive dataset uniquely combines 130k text\nQA pairs meticulously curated from authentic travel forums with GPT-enhanced\nresponses, alongside 90k vision-language QA pairs specifically focused on map\nunderstanding and scene comprehension. Through extensive fine-tuning\nexperiments on state-of-the-art vision-language models (LLaVA, Qwen-VL,\nShikra), we demonstrate significant performance improvements ranging from\n6.5\\%-9.4\\% in both pure text travel understanding and visual question\nanswering tasks. Our model exhibits exceptional capabilities in providing\ncontextual travel recommendations, interpreting map locations, and\nunderstanding place-specific imagery while offering practical information such\nas operating hours and visitor reviews. Comparative evaluations show TraveLLaMA\nsignificantly outperforms general-purpose models in travel-specific tasks,\nestablishing a new benchmark for multi-modal travel assistance systems.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-23T08:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.16524v1","title":"Modality Reliability Guided Multimodal Recommendation","summary":"Multimodal recommendation faces an issue of the performance degradation that\nthe uni-modal recommendation sometimes achieves the better performance. A\npossible reason is that the unreliable item modality data hurts the fusion\nresult. Several existing studies have introduced weights for different\nmodalities to reduce the contribution of the unreliable modality data in\npredicting the final user rating. However, they fail to provide appropriate\nsupervisions for learning the modality weights, making the learned weights\nimprecise. Therefore, we propose a modality reliability guided multimodal\nrecommendation framework that uniquely learns the modality weights supervised\nby the modality reliability. Considering that there is no explicit label\nprovided for modality reliability, we resort to automatically identify it\nthrough the BPR recommendation objective. In particular, we define a modality\nreliability vector as the supervision label by the difference between\nmodality-specific user ratings to positive and negative items, where a larger\ndifference indicates a higher reliability of the modality as the BPR objective\nis better satisfied. Furthermore, to enhance the effectiveness of the\nsupervision, we calculate the confidence level for the modality reliability\nvector, which dynamically adjusts the supervision strength and eliminates the\nharmful supervision. Extensive experiments on three real-world datasets show\nthe effectiveness of the proposed method.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.16537v1","title":"Transformers for Complex Query Answering over Knowledge Hypergraphs","summary":"Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T09:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.16564v1","title":"SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral\n  Adaptive Information Propagation","summary":"Semantic segmentation of remote sensing imagery demands precise spatial\nboundaries and robust intra-class consistency, challenging conventional\nhierarchical models. To address limitations arising from spatial domain feature\nfusion and insufficient receptive fields, this paper introduces SAIP-Net, a\nnovel frequency-aware segmentation framework that leverages Spectral Adaptive\nInformation Propagation. SAIP-Net employs adaptive frequency filtering and\nmulti-scale receptive field enhancement to effectively suppress intra-class\nfeature inconsistencies and sharpen boundary lines. Comprehensive experiments\ndemonstrate significant performance improvements over state-of-the-art methods,\nhighlighting the effectiveness of spectral-adaptive strategies combined with\nexpanded receptive fields for remote sensing image segmentation.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-04-23T09:43:58Z"}
{"aid":"http://arxiv.org/abs/2504.16593v1","title":"$R_{\\rm e}$. II. Understanding (IC 3475)-type galaxy, aka ultra-diffuse\n  galaxy, structural scaling relations","summary":"It is explained why ultra-diffuse galaxies (UDGs), a subset of (IC 3475)-type\ngalaxies, do not have unexpectedly large sizes but large sizes that are in line\nwith expectations from the curved size-luminosity relation defined by brighter\nearly-type galaxies (ETGs). UDGs extend the faint end of the (absolute\nmagnitude, $\\mathfrak{M}$)-log(S\\'ersic index, $n$) and $\\mathfrak{M}$-(central\nsurface brightness, $\\mu_{\\rm 0}$) relations defined by ETGs, leading to the\nlarge effective half-light radii, $R_{\\rm e}$, in UDGs. It is detailed how the\nscatter in $\\mu_{\\rm 0}$, at a given $\\mathfrak{M}$, relates to variations in\nthe galaxies' values of $n$ and effective surface brightness, $\\mu_{\\rm e}$.\nThese variations map into changes in $R_{\\rm e}$ and produce the scatter about\nthe $\\mathfrak{M}$-$R_{\\rm e}$ relation at fixed $\\mathfrak{M}$. Similarly, the\nscatter in $\\mathfrak{M}$, at fixed $\\mu_{\\rm 0}$ and $n$, can be mapped into\nchanges in $R_{\\rm e}$. The increased scatter about the faint end of the\n$\\mathfrak{M}$-$R_{\\rm e}$ relation and the smaller scatter about\n$\\mathfrak{M}$-(isophotal radii, $R_{\\rm iso}$) relations are explained.\nArtificial and potentially misleading size-luminosity relations for UDGs are\nalso addressed. The suggestion that there may be two types of UDG appears\nill-founded, arising from the scatter about the $\\mathfrak{M}$-$\\mu_{\\rm 0}$\nrelation, which persists at all magnitudes. Hopefully, the understanding\npresented here will prove helpful for interpreting the many low surface\nbrightness galaxies that the Large Synoptic Survey Telescope will detect.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T10:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.16602v1","title":"The Balmer spectrum and telescope conjecture for infinite groups","summary":"We determine the Balmer spectrum of dualisable objects in the stable module\ncategory for $\\mathrm{H}_1\\mathfrak{F}$ groups of type $\\mathrm{FP}_{\\infty}$\nand show that the telescope conjecture holds for these categories. We also\ndetermine the spectrum of dualisable objects for certain infinite free products\nof finite groups. Using this, we give examples where the stable category is not\nstratified by the spectrum of dualisable objects and where the telescope\nconjecture does not hold.","main_category":"math.RT","categories":"math.RT,math.CT","published":"2025-04-23T10:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.16611v1","title":"Forms of Nice Functions","summary":"You can invent striking and challenging problems with unique solution by\nbuilding some symmetry into functional equations. Some are suitable for high\nschool; others could generate college-level projects involving computer\nalgebra. The problems are functional equations with group actions in the\nbackground. Interesting examples arise even from small finite groups. Whether a\ngiven problem ``works\" with a given choice of constant coefficients depends on\nwhether a related multilinear form is nonzero. These forms are essentially the\nclassical group determinants studied by Frobenius in the nineteenth century.","main_category":"math.GR","categories":"math.GR","published":"2025-04-23T10:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.16634v1","title":"Quantum algorithm for reducing amplitudes in order to search and filter\n  data","summary":"The method is introduced for fast data processing by reducing the probability\namplitudes of undesirable elements. The algorithm has a mathematical\ndescription and circuit implementation on a quantum processor. The idea is to\nmake a quick decision (down to a single iteration) based on the correspondence\nbetween the data and the desired result, with a probability proportionate to\nthis correspondence. Our approach allows one to calibrate the circuit to\ncontrol specified proportions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T11:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.16657v1","title":"A new characterization of Sobolev spaces on Lipschitz differentiability\n  spaces","summary":"We prove a new characterization of metric Sobolev spaces, in the spirit of\nBrezis--Van Schaftingen--Yung's asymptotic formula. A new feature of our work\nis that we do not need Poincar\\'e inequality which is a common tool in the\nliterature. Another new feature is that we find a direct link between\nBrezis--Van Schaftingen--Yung's asymptotic formula and Cheeger's Lipschitz\ndifferentiability.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-04-23T12:24:33Z"}
{"aid":"http://arxiv.org/abs/2504.16671v1","title":"LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative\n  Analysis","summary":"The use of large language models (LLMs) in qualitative analysis offers\nenhanced efficiency but raises questions about their alignment with the\ncontextual nature of research for design (RfD). This research examines the\ntrustworthiness of LLM-driven design insights, using qualitative coding as a\ncase study to explore the interpretive processes central to RfD. We introduce\nLLMCode, an open-source tool integrating two metrics, namely Intersection over\nUnion (IoU) and Modified Hausdorff Distance, to assess the alignment between\nhuman and LLM-generated insights. Across two studies involving 26 designers, we\nfind that while the model performs well with deductive coding, its ability to\nemulate a designer's deeper interpretive lens over the data is limited,\nemphasising the importance of human-AI collaboration. Our results highlight a\nreciprocal dynamic where users refine LLM outputs and adapt their own\nperspectives based on the model's suggestions. These findings underscore the\nimportance of fostering appropriate reliance on LLMs by designing tools that\npreserve interpretive depth while facilitating intuitive collaboration between\ndesigners and AI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T12:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.16707v1","title":"Hochschild (Co)homology of D-modules on rigid analytic spaces I","summary":"We introduce a formalism of Hochschild (co)-homology for $\\mathcal{D}$-cap\nmodules on smooth rigid analytic spaces based on the homological tools of\nInd-Banach $\\mathcal{D}$-cap modules. We introduce several categories of\n$\\mathcal{D}$-cap bimodules for which this theory is well-behaved. Among these,\nthe most important example is the category of diagonal $\\mathcal{C}$-complexes.\nWe give an explicit calculation of the Hochschild complex for diagonal\n$\\mathcal{C}$-complexes, and show that the Hochschild complex of\n$\\mathcal{D}$-cap is canonically isomorphic to the de Rham complex of $X$. In\nparticular, we obtain a Hodge-de Rham spectral sequence converging to the\nHochschild cohomology groups of $\\mathcal{D}$-cap. We obtain explicit formulas\nrelating the Hochschild cohomology and homology of a given diagonal\n$\\mathcal{C}$-complex.","main_category":"math.NT","categories":"math.NT,math.AG,math.RA,math.RT","published":"2025-04-23T13:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.16717v1","title":"Random walks on random networks of cliques: Inferring the network\n  structure","summary":"We study the properties of discrete-time random walks on networks formed by\nrandomly interconnected cliques, namely, random networks of cliques. Our\npurpose is to derive the parameters that define the network structure --\nspecifically, the distribution of clique size and the abundance of inter-clique\nlinks -- from the observation of selected statistical features along the random\nwalk. To this end, we apply a Bayesian approach based on recording the times\nspent by the walker inside successively visited cliques. The procedure is\nillustrated with some numerical examples of diverse complexity, where the\nrelevant structural parameters are successfully recovered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-23T13:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.16727v1","title":"V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental\n  Visual Variations","summary":"Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.16752v1","title":"Adversarial Knapsack for Sequential Competitive Resource Allocation","summary":"This work addresses competitive resource allocation in a sequential setting,\nwhere two players allocate resources across objects or locations of shared\ninterest. Departing from the simultaneous Colonel Blotto game, our framework\nintroduces a sequential decision-making dynamic, where players act with partial\nor complete knowledge of previous moves. Unlike traditional approaches that\nrely on complex mixed strategies, we focus on deterministic pure strategies,\nstreamlining computation while preserving strategic depth. Additionally, we\nextend the payoff structure to accommodate fractional allocations and payoffs,\nmoving beyond the binary, all-or-nothing paradigm to allow more granular\noutcomes. We model this problem as an adversarial knapsack game, formulating it\nas a bilevel optimization problem that integrates the leader's objective with\nthe follower's best-response. This knapsack-based approach is novel in the\ncontext of competitive resource allocation, with prior work only partially\nleveraging it for follower analysis. Our contributions include: (1) proposing\nan adversarial knapsack formulation for the sequential resource allocation\nproblem, (2) developing efficient heuristics for fractional allocation\nscenarios, and (3) analyzing the 0-1 knapsack case, providing a computational\nhardness result alongside a heuristic solution.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T14:24:17Z"}
{"aid":"http://arxiv.org/abs/2504.16753v1","title":"ViMoTest: A Tool to Specify ViewModel-Based GUI Test Scenarios using\n  Projectional Editing","summary":"Automated GUI testing is crucial in ensuring that presentation logic behaves\nas expected. However, existing tools often apply end-to-end approaches and face\nchallenges such as high specification efforts, maintenance difficulties, and\nflaky tests while coupling to GUI framework specifics. To address these\nchallenges, we introduce the ViMoTest tool, which leverages Behavior-driven\nDevelopment, the ViewModel architectural pattern, and projectional\nDomain-specific Languages (DSLs) to isolate and test presentation logic\nindependently of GUI frameworks. We demonstrate the tool with a small\nJavaFX-based task manager example and generate executable code.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.16771v1","title":"Projective Variety Recovery from Unknown Linear Projections","summary":"We study how a smooth irreducible algebraic variety $X$ of dimension $n$\nembedded in $\\mathbb{C} \\mathbb{P}^{m}$ (with $m \\geq n+2$), which degree is\n$d$, can be recovered using two projections from unknown points onto unknown\nhyperplanes. The centers and the hyperplanes of projection are unknown: the\nonly input is the defining equations of each projected varieties. We show how\nboth the projection operators and the variety in $\\mathbb{C} \\mathbb{P}^{m}$\ncan be recovered modulo some action of the group of projective transformations\nof $\\mathbb{C} \\mathbb{P}^{m}$. This configuration generalizes results obtained\nin the context of curves embedded in $\\mathbb{C} \\mathbb{P}^3$ and results\nconcerning surfaces embedded in $\\mathbb{C} \\mathbb{P}^4$.\n  We show how in a generic situation, a characteristic matrix of the pair of\nprojections can be recovered. In the process we address dimensional issues and\nas a result establish a necessary condition, as well as a sufficient condition\nto compute this characteristic matrix up to a finite-fold ambiguity. These\nconditions are expressed as minimal values of the degree of the dual variety.\n  Then we use this matrix to recover the class of the couple of projections and\nas a consequence to recover the variety. For a generic situation, two\nprojections define a variety with two irreducible components. One component has\ndegree $d(d-1)$ and the other has degree $d$, being the original variety.","main_category":"math.AG","categories":"math.AG,cs.SC","published":"2025-04-23T14:42:43Z"}
{"aid":"http://arxiv.org/abs/2504.16808v1","title":"Desingularization of double covers of regular surfaces","summary":"Let $Z$ be a noetherian integral excellent regular scheme of dimension $2$.\nLet $Y$ be an integral normal scheme endowed with a finite flat morphism $Y\\to\nZ$ of degree $2$. We give a description of Lipman's desingularization of $Y$ by\nexplicit equations, leading to a desingularization algorithm for $Y$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-23T15:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.16812v1","title":"The rigidity statement in the Horowitz-Myers conjecture","summary":"In this paper, we give an alternative proof of the Horowitz-Myers conjecture\nin dimension $3 \\leq N \\leq 7$. Moreover, we show that a metric that achieves\nequality in the Horowitz-Myers conjecture is locally isometric to a\nHorowitz-Myers metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-23T15:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.16822v1","title":"Supersymmetric Warped Solutions from Type IIB Orientifold Reduction","summary":"We construct a family of supersymmetric solutions in Type IIB supergravity of\nthe form ${\\rm WAdS}_3\\times {\\rm WS}^3\\times T^4$, where ${\\rm WAdS}_3$ and\n${\\rm WS^3}$ denote a warped anti-de Sitter spacetime and a warped 3-sphere,\nrespectively, while $T^4$ denotes an internal 4-torus. These backgrounds are\nconstructed by uplifting corresponding solutions in the $D=6$,\n$\\mathcal{N}=(1,1)$ ungauged supergravity resulting from the compactification\nof Type IIB supergravity on a $T^4/\\mathbb{Z}_2$-orientifold. More\nspecifically, the supersymmetric solutions are ${\\rm WAdS}_3\\times {\\rm\nWS}^3\\times T^4$ with lightlike warped AdS$_3$ and ${\\rm WAdS}_3\\times {\\rm\nS}^3\\times T^4$ in which the warping of AdS$_3$ is generic. Moreover, we also\nconstruct solutions in the form of a warped product\n$\\mathrm{LM}^3_{\\zeta,\\omega}\\times_{{\\rm w}} \\mathrm{S}^3\\times T^4$ of a\n2-parameter deformation $\\mathrm{LM}^3_{\\zeta,\\omega}$ of ${\\rm AdS}_3$ and a\nthree-sphere. We discuss the relation of these backgrounds to known solutions.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-23T15:39:19Z"}
{"aid":"http://arxiv.org/abs/2504.16831v1","title":"Evaluating Autoencoders for Parametric and Invertible Multidimensional\n  Projections","summary":"Recently, neural networks have gained attention for creating parametric and\ninvertible multidimensional data projections. Parametric projections allow for\nembedding previously unseen data without recomputing the projection as a whole,\nwhile invertible projections enable the generation of new data points. However,\nthese properties have never been explored simultaneously for arbitrary\nprojection methods. We evaluate three autoencoder (AE) architectures for\ncreating parametric and invertible projections. Based on a given projection, we\ntrain AEs to learn a mapping into 2D space and an inverse mapping into the\noriginal space. We perform a quantitative and qualitative comparison on four\ndatasets of varying dimensionality and pattern complexity using t-SNE. Our\nresults indicate that AEs with a customized loss function can create smoother\nparametric and inverse projections than feed-forward neural networks while\ngiving users control over the strength of the smoothing effect.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T15:47:20Z"}
{"aid":"http://arxiv.org/abs/2504.16859v1","title":"$SO(4)$ gauged $O(5)$ Skyrmion on $\\mathbb{R}^4$","summary":"We have studied an $SO(4)$ gauged $O(5)$ Skyrmion on $\\mathbb{R}^4$ which can\nbe seen as a static soliton in $4+1$ dimension. This is a sequel of the known\n$SO(D)$ gauged $O(D+1)$ Skyrmions on $\\mathbb{R}^D$ in $D=2$ and in $D=3$, with\nboth of which its properties are compared. Two families of solutions are found,\nof these only one possessing a gauge decoupling limit. The curvatures of both\nof these solutions decay as $r^{-3}$, are bounded below by the topological\ncharge, and are localised to an absolute scale. As such, they may have the\npotential of being interpreted as instantons.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T16:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.16867v1","title":"A Bayesian Update Method for Exponential Family Projection Filters with\n  Non-Conjugate Likelihoods","summary":"The projection filter is one of the approximations to the solution of the\noptimal filtering problem. It approximates the filtering density by projecting\nthe dynamics of the square-root filtering density onto the tangent space of the\nsquare-root parametric densities manifold. While the projection filters for\nexponential and mixture families with continuous measurement processes have\nbeen well studied, the continuous-discrete projection filtering algorithm for\nnon-conjugate priors has received less attention.\n  In this paper, we introduce a simple Riemannian optimization method to be\nused for the Bayesian update step in the continuous-discrete projection filter\nfor exponential families. Specifically, we show that the Bayesian update can be\nformulated as an optimization problem of $\\alpha$-R\\'enyi divergence, where the\ncorresponding Riemannian gradient can be easily computed. We demonstrate the\neffectiveness of the proposed method via two highly non-Gaussian Bayesian\nupdate problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T16:43:57Z"}
{"aid":"http://arxiv.org/abs/2504.16871v1","title":"Exploring How LLMs Capture and Represent Domain-Specific Knowledge","summary":"We study whether Large Language Models (LLMs) inherently capture\ndomain-specific nuances in natural language. Our experiments probe the domain\nsensitivity of LLMs by examining their ability to distinguish queries from\ndifferent domains using hidden states generated during the prefill phase. We\nreveal latent domain-related trajectories that indicate the model's internal\nrecognition of query domains. We also study the robustness of these domain\nrepresentations to variations in prompt styles and sources. Our approach\nleverages these representations for model selection, mapping the LLM that best\nmatches the domain trace of the input query (i.e., the model with the highest\nperformance on similar traces). Our findings show that LLMs can differentiate\nqueries for related domains, and that the fine-tuned model is not always the\nmost accurate. Unlike previous work, our interpretations apply to both closed\nand open-ended generative tasks","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T16:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.16894v1","title":"Spectrometer-Free Electron Spectromicroscopy","summary":"We introduce an approach for performing spectrally resolved electron\nmicroscopy without the need for an electron spectrometer. The method involves\nan electron beam prepared as a coherent superposition of multiple paths, one of\nwhich passes near a laser-irradiated specimen. These paths are subsequently\nrecombined, and their interference is measured as a function of laser frequency\nand beam position. Electron--light scattering introduces inelastic components\ninto the interacting path, thereby disturbing the interference pattern. We\nimplement this concept using two masks placed at conjugate image planes. The\nmasks are complementary and act in tandem to fully suppress electron\ntransmission in the absence of a specimen. However, electron interaction with\nan illuminated specimen perturbs the imaging condition, enabling electron\ntransmission through the system. For a fixed external light intensity, the\ntransmitted electron current is proportional to the strength of the local\noptical response in the material. The proposed technique does not require\nmonochromatic electron beams, dramatically simplifying the design of spectrally\nresolved electron microscopes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T17:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16931v1","title":"Lattice study of $cc\\bar u\\bar s$ tetraquark channel in\n  $D^{(*)}D^{(*)}_s$ scattering","summary":"We present the first lattice QCD determination of coupled $DD_s^*$ and\n$D^*D_s$ scattering amplitudes in the $J^{P}=1^{+}$ channel and elastic $DD_s$\nscattering amplitude in the $J^{P}=0^{+}$ channel.The aim is to investigate\nwhether tetraquarks with flavor $cc\\bar u\\bar s$ exist in the region near\nthreshold. Lattice QCD ensembles from the CLS consortium with $m_{\\pi} \\sim\n280$ MeV, $a\\sim0.09$ fm and $L/a = 24, 32$ are utilized. Finite-volume spectra\nare determined via variational analysis of two-point correlation matrices,\ncomputed using large bases of operators resembling bilocal two-meson structures\nwithin the distillation framework. The scattering matrix for partial wave $l=0$\nis determined using lattice eigenenergies from multiple inertial frames\nfollowing L\\\"uscher's formalism as well as following the solutions of\nLippmann-Schwinger Equation in the finite-volume on a plane-wave basis. We\nobserve small nonzero energy shifts in the simulated spectra from the\nnoninteracting scenario in both the channels studied, which points to rather\nweak nontrivial interactions between the mesons involved. Despite the nonzero\nenergy shifts, the lattice-extracted $S$-wave amplitudes do not carry\nsignatures of any hadron pole features in the physical amplitudes in the energy\nregion near the threshold.","main_category":"hep-lat","categories":"hep-lat,hep-ex,hep-ph","published":"2025-04-23T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.17238v1","title":"Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn\n  Supportive Dialogues","summary":"Cognitive Restructuring (CR) is a psychotherapeutic process aimed at\nidentifying and restructuring an individual's negative thoughts, arising from\nmental health challenges, into more helpful and positive ones via multi-turn\ndialogues. Clinician shortage and stigma urge the development of human-LLM\ninteractive psychotherapy for CR. Yet, existing efforts implement CR via simple\ntext rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to\nalign with the psychotherapeutic process for effective CR. To address this gap,\nwe propose CRDial, a novel framework for CR, which creates multi-turn dialogues\nwith specifically designed identification and restructuring stages of negative\nthoughts, integrates sentence-level supportive conversation strategies, and\nadopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we\ndistill Crisp, a large-scale and high-quality bilingual dialogue dataset, from\nLLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and\n14B scales. Extensive human studies show the superiority of Crispers in\npointwise, pairwise, and intervention evaluations.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-24T04:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.17302v1","title":"Non-integrability of charged three-body problem","summary":"We consider the problem of $n$ points with positive masses interacting\npairwise with forces inversely proportional to the distance between them. In\nparticular, it is the classical gravitational, Coulomb or photo-gravitational\n$n$-body problem. Under this general form of interaction, we investigate the\nintegrability problem of three bodies. We show that the system is not\nintegrable except in one case when two among three interaction constants\nvanish. In our investigation, we used the Morales-Ramis theorem concerning the\nintegrability of a natural Hamiltonian system with a homogeneous potential and\nits generalization.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-24T06:56:06Z"}
{"aid":"http://arxiv.org/abs/2504.17313v1","title":"Tokenizing Stock Prices for Enhanced Multi-Step Forecast and Prediction","summary":"Effective stock price forecasting (estimating future prices) and prediction\n(estimating future price changes) are pivotal for investors, regulatory\nagencies, and policymakers. These tasks enable informed decision-making, risk\nmanagement, strategic planning, and superior portfolio returns. Despite their\nimportance, forecasting and prediction are challenging due to the dynamic\nnature of stock price data, which exhibit significant temporal variations in\ndistribution and statistical properties. Additionally, while both forecasting\nand prediction targets are derived from the same dataset, their statistical\ncharacteristics differ significantly. Forecasting targets typically follow a\nlog-normal distribution, characterized by significant shifts in mean and\nvariance over time, whereas prediction targets adhere to a normal distribution.\nFurthermore, although multi-step forecasting and prediction offer a broader\nperspective and richer information compared to single-step approaches, it is\nmuch more challenging due to factors such as cumulative errors and long-term\ntemporal variance. As a result, many previous works have tackled either\nsingle-step stock price forecasting or prediction instead. To address these\nissues, we introduce a novel model, termed Patched Channel Integration Encoder\n(PCIE), to tackle both stock price forecasting and prediction. In this model,\nwe utilize multiple stock channels that cover both historical prices and price\nchanges, and design a novel tokenization method to effectively embed these\nchannels in a cross-channel and temporally efficient manner. Specifically, the\ntokenization process involves univariate patching and temporal learning with a\nchannel-mixing encoder to reduce cumulative errors. Comprehensive experiments\nvalidate that PCIE outperforms current state-of-the-art models in forecast and\nprediction tasks.","main_category":"cs.CE","categories":"cs.CE,q-fin.CP","published":"2025-04-24T07:15:05Z"}
{"aid":"http://arxiv.org/abs/2504.17323v1","title":"CKMDiff: A Generative Diffusion Model for CKM Construction via Inverse\n  Problems with Learned Priors","summary":"Channel knowledge map (CKM) is a promising technology to enable\nenvironment-aware wireless communications and sensing with greatly enhanced\nperformance, by offering location-specific channel prior information for future\nwireless networks. One fundamental problem for CKM-enabled wireless systems\nlies in how to construct high-quality and complete CKM for all locations of\ninterest, based on only limited and noisy on-site channel knowledge data. This\nproblem resembles the long-standing ill-posed inverse problem, which tries to\ninfer from a set of limited and noisy observations the cause factors that\nproduced them. By utilizing the recent advances of solving inverse problems\nwith learned priors using generative artificial intelligence (AI), we propose\nCKMDiff, a conditional diffusion model that can be applied to perform various\ntasks for CKM constructions such as denoising, inpainting, and\nsuper-resolution, without having to know the physical environment maps or\ntransceiver locations. Furthermore, we propose an environment-aware data\naugmentation mechanism to enhance the model's ability to learn implicit\nrelations between electromagnetic propagation patterns and spatial-geometric\nfeatures. Extensive numerical results are provided based on the CKMImageNet and\nRadioMapSeer datasets, which demonstrate that the proposed CKMDiff achieves\nstate-of-the-art performance, outperforming various benchmark methods.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-24T07:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.17352v1","title":"The Riemannian Means Field Classifier for EEG-Based BCI Data","summary":"A substantial amount of research has demonstrated the robustness and accuracy\nof the Riemannian minimum distance to mean (MDM) classifier for all kinds of\nEEG-based brain--computer interfaces (BCIs). This classifier is simple, fully\ndeterministic, robust to noise, computationally efficient, and prone to\ntransfer learning. Its training is very simple, requiring just the computation\nof a geometric mean of a symmetric positive-definite (SPD) matrix per class. We\npropose an improvement of the MDM involving a number of power means of SPD\nmatrices instead of the sole geometric mean. By the analysis of 20 public\ndatabases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCI\nparadigm, comprising 587 individuals in total, we show that the proposed\nclassifier clearly outperforms the MDM, approaching the state-of-the art in\nterms of performance while retaining the simplicity and the deterministic\nbehavior. In order to promote reproducible research, our code will be released\nas open source.","main_category":"cs.HC","categories":"cs.HC,eess.SP","published":"2025-04-24T08:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.17363v1","title":"Sample-Path Large Deviations for Functionals of Poisson Cluster\n  Processes","summary":"We establish sample-path large deviation principles for the centered\ncumulative functional of marked Poisson cluster processes in the Skorokhod\nspace equipped with the M1 topology, under joint regular variation assumptions\non the marks and the offspring distributions governing the propagation\nmechanism. These findings can also be interpreted as hidden regular variation\nof the cluster processes' functionals, extending the results in Dombry et al.\n(2022) to cluster processes with heavy-tailed characteristics, including mixed\nBinomial Poisson cluster processes and Hawkes processes. Notably, by\nrestricting to the adequate subspace of measures on D([0, 1], R+), and applying\nthe correct normalization and scaling to the paths of the centered cumulative\nfunctional, the limit measure concentrates on paths with multiple large jumps.","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T08:26:45Z"}
{"aid":"http://arxiv.org/abs/2504.17376v1","title":"On-Device Qwen2.5: Efficient LLM Inference with Model Compression and\n  Hardware Acceleration","summary":"Transformer-based Large Language Models (LLMs) have significantly advanced AI\ncapabilities but pose considerable challenges for deployment on edge devices\ndue to high computational demands, memory bandwidth constraints, and energy\nconsumption. This paper addresses these challenges by presenting an efficient\nframework for deploying the Qwen2.5-0.5B model on the Xilinx Kria KV260 edge\nplatform, a heterogeneous system integrating an ARM Cortex-A53 CPU with\nreconfigurable FPGA logic. Leveraging Activation-aware Weight Quantization\n(AWQ) with FPGA-accelerated execution pipelines, the proposed approach enhances\nboth model compression rate and system throughput. Additionally, we propose a\nhybrid execution strategy that intelligently offloads compute-intensive\noperations to the FPGA while utilizing the CPU for lighter tasks, effectively\nbalancing the computational workload and maximizing overall performance. Our\nframework achieves a model compression rate of 55.08% compared to the original\nmodel and produces output at a rate of 5.1 tokens per second, outperforming the\nbaseline performance of 2.8 tokens per second.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-24T08:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.17379v1","title":"A Spatially-Aware Multiple Instance Learning Framework for Digital\n  Pathology","summary":"Multiple instance learning (MIL) is a promising approach for weakly\nsupervised classification in pathology using whole slide images (WSIs).\nHowever, conventional MIL methods such as Attention-Based Deep Multiple\nInstance Learning (ABMIL) typically disregard spatial interactions among\npatches that are crucial to pathological diagnosis. Recent advancements, such\nas Transformer based MIL (TransMIL), have incorporated spatial context and\ninter-patch relationships. However, it remains unclear whether explicitly\nmodeling patch relationships yields similar performance gains in ABMIL, which\nrelies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs\nTransformer-based layers, introducing a fundamental architectural shift at the\ncost of substantially increased computational complexity. In this work, we\nenhance the ABMIL framework by integrating interaction-aware representations to\naddress this question. Our proposed model, Global ABMIL (GABMIL), explicitly\ncaptures inter-instance dependencies while preserving computational efficiency.\nExperimental results on two publicly available datasets for tumor subtyping in\nbreast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage\npoint improvement in AUPRC and a 5 percentage point increase in the Kappa score\nover ABMIL, with minimal or no additional computational overhead. These\nfindings underscore the importance of incorporating patch interactions within\nMIL frameworks.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-24T08:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.17386v1","title":"Free Cosmic Density Bispectrum on Small Scales","summary":"We study the asymptotic behaviour of the free, cold-dark matter density\nfluctuation bispectrum in the limit of small scales. From an initially Gaussian\nrandom field, we draw phase-space positions of test particles which then\npropagate along Zel'dovich trajectories. A suitable expansion of the initial\nmomentum auto-correlations of these particles leads to an asymptotic series\nwhose lower-order power-law exponents we calculate. The dominant contribution\nhas an exponent of $-11/2$. For triangle configurations with zero surface area,\nthis exponent is even enhanced to $-9/2$. These power laws can only be revealed\nby a non-perturbative calculation with respect to the initial power spectrum.\nThey are valid for a general class of initial power spectra with a cut-off\nfunction, required to enforce convergence of its moments. We then confirm our\nanalytic results numerically. Finally, we use this asymptotic behaviour to\ninvestigate the shape dependence of the bispectrum in the small-scale limit,\nand to show how different shapes grow over cosmic time. These confirm the usual\nmodel of gravitational collapse within the Zel'dovich picture.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-24T09:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.17418v1","title":"Longitudinal Control for Autonomous Racing with Combustion Engine\n  Vehicles","summary":"Usually, a controller for path- or trajectory tracking is employed in\nautonomous driving. Typically, these controllers generate high-level commands\nlike longitudinal acceleration or force. However, vehicles with combustion\nengines expect different actuation inputs. This paper proposes a longitudinal\ncontrol concept that translates high-level trajectory-tracking commands to the\nrequired low-level vehicle commands such as throttle, brake pressure and a\ndesired gear. We chose a modular structure to easily integrate different\ntrajectory-tracking control algorithms and vehicles. The proposed control\nconcept enables a close tracking of the high-level control command. An\nanti-lock braking system, traction control, and brake warmup control also\nensure a safe operation during real-world tests. We provide experimental\nvalidation of our concept using real world data with longitudinal accelerations\nreaching up to $25 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^2}$. The experiments were\nconducted using the EAV24 racecar during the first event of the Abu Dhabi\nAutonomous Racing League on the Yas Marina Formula 1 Circuit.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-24T10:21:28Z"}
{"aid":"http://arxiv.org/abs/2504.17431v1","title":"The resonance parameters of the vector charmonium-like state $G(3900)$","summary":"Motivated by the updated analysis of the $G(3900)$ by the BESIII\ncollaboration, we perform a global analysis of the cross sections of the\n$e^+e^-\\to D\\bar{D}$, $e^+e^-\\to D\\bar{D}^*+c.c.$, $e^+e^-\\to D^*\\bar{D}^*$\nprocesses, especially focusing on the properties of the $G(3900)$. As the\nenergy region of interest is limited by the next opening threshold, i.e. the\n$D_1\\bar{D}$ threshold, we focus on the energy region\n$[3.7,4.25]~\\mathrm{GeV}$, where three charmonia $\\psi(1D)$, $\\psi(3S)$ and\n$\\psi(2D)$ explicitly contribute to the cross sections. By constructing the\n$P$-wave contact interaction between the $(D,D^*)$ doublet and its antiparticle\nin the heavy quark limit, we extract the physical scattering amplitude by\nsolving the Lippmann-Schwinger equation. No matter whether three or two\ncharmonium states are included in our framework, we always find a dynamically\ngenerated state corresponding to the $G(3900)$, which suggests it to be a\n$P$-wave dynamically generated state. We also predict several dynamically\ngenerated states in the corresponding $1^{-+}$ channel. These states can be\nfurther searched for in the electron-positron annihilation process involving\nthe emission of a single photon.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-24T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.17448v1","title":"CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated\n  Active Learning","summary":"Active learning (AL) reduces human annotation costs for machine learning\nsystems by strategically selecting the most informative unlabeled data for\nannotation, but performing it individually may still be insufficient due to\nrestricted data diversity and annotation budget. Federated Active Learning\n(FAL) addresses this by facilitating collaborative data selection and model\ntraining, while preserving the confidentiality of raw data samples. Yet,\nexisting FAL methods fail to account for the heterogeneity of data distribution\nacross clients and the associated fluctuations in global and local model\nparameters, adversely affecting model accuracy. To overcome these challenges,\nwe propose CHASe (Client Heterogeneity-Aware Data Selection), specifically\ndesigned for FAL. CHASe focuses on identifying those unlabeled samples with\nhigh epistemic variations (EVs), which notably oscillate around the decision\nboundaries during training. To achieve both effectiveness and efficiency,\n\\model{} encompasses techniques for 1) tracking EVs by analyzing inference\ninconsistencies across training epochs, 2) calibrating decision boundaries of\ninaccurate models with a new alignment loss, and 3) enhancing data selection\nefficiency via a data freeze and awaken mechanism with subset sampling.\nExperiments show that CHASe surpasses various established baselines in terms of\neffectiveness and efficiency, validated across diverse datasets, model\ncomplexities, and heterogeneous federation settings.","main_category":"cs.LG","categories":"cs.LG,cs.DB,cs.DC","published":"2025-04-24T11:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.17458v1","title":"Boundedness and Separation in the Graph Covering Number Framework","summary":"For a graph class $\\mathcal G$ and a graph $H$, the four $\\mathcal\nG$-covering numbers of $H$, namely global ${\\rm cn}_{g}^{\\mathcal{G}}(H)$,\nunion ${\\rm cn}_{u}^{\\mathcal{G}}(H)$, local ${\\rm cn}_{l}^{\\mathcal{G}}(H)$,\nand folded ${\\rm cn}_{f}^{\\mathcal{G}}(H)$, each measure in a slightly\ndifferent way how well $H$ can be covered with graphs from $\\mathcal G$. For\nevery $\\mathcal G$ and $H$ it holds \\[\n  {\\rm cn}_{g}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{u}^{\\mathcal{G}}(H) \\geq {\\rm\ncn}_{l}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{f}^{\\mathcal{G}}(H) \\] and in general\neach inequality can be arbitrarily far apart. We investigate structural\nproperties of graph classes $\\mathcal G$ and $\\mathcal H$ such that for all\ngraphs $H \\in \\mathcal{H}$, a larger $\\mathcal G$-covering number of $H$ can be\nbounded in terms of a smaller $\\mathcal G$-covering number of $H$. For example,\nwe prove that if $\\mathcal G$ is hereditary and the chromatic number of graphs\nin $\\mathcal H$ is bounded, then there exists a function $f$ (called a binding\nfunction) such that for all $H \\in \\mathcal{H}$ it holds ${\\rm\ncn}_{u}^{\\mathcal{G}}(H) \\leq f({\\rm cn}_{g}^{\\mathcal{G}}(H))$.\n  For $\\mathcal G$ we consider graph classes that are component-closed,\nhereditary, monotone, sparse, or of bounded chromatic number. For $\\mathcal H$\nwe consider graph classes that are sparse, $M$-minor-free, of bounded chromatic\nnumber, or of bounded treewidth. For each combination and every pair of\n$\\mathcal G$-covering numbers, we either give a binding function $f$ or provide\nan example of such $\\mathcal{G},\\mathcal{H}$ for which no binding function\nexists.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-24T11:43:53Z"}
{"aid":"http://arxiv.org/abs/2504.17487v1","title":"Investigation of student and faculty problem solving: An example from\n  quantum mechanics","summary":"We describe a study focusing on students' and faculty members' reasoning\nabout problems of differing cognitive complexity related to the double-slit\nexperiment (DSE) with single particles. In the first phase of the study,\nstudents in advanced quantum mechanics courses were asked these questions in\nwritten form. Additionally, individual interviews were conducted with ten\nstudents in which they were asked follow-up questions to make their thought\nprocesses explicit on the challenging problems. Students did well on the\nstraightforward problem, showing they had some knowledge of the DSE after\ntraditional instruction, but they struggled on the more complex ones. Even if\nexplicitly asked to do so in interviews, students were often uncomfortable\nperforming calculations or making approximations and simplifications, instead\npreferring to stick with their gut feeling. In the second phase of the study,\nthe problems were broken down into more pointed questions to investigate\nwhether students had knowledge of relevant concepts, whether they would do\ncalculations as part of their solution approach if explicitly asked, and\nwhether they explicitly noted using their gut feeling. While the faculty\nmembers' responses suggest that they could seamlessly move between conceptual\nand quantitative reasoning, most students were unable to combine concepts\nrepresented by different equations to solve the problems quantitatively. We\nconclude with instructional implications.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-24T12:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.17488v1","title":"Microscopic derivation of the stationary Chern-Simons-Schrödinger\n  equation for almost-bosonic anyons","summary":"In this work we consider the $N$-body Hamiltonian describing the microscopic\nstructure of a quantum gas of almost-bosonic anyons. This description includes\nboth extended magnetic flux and spin-orbit/soft-disk interaction between the\nparticles which are confined in a scalar trapping potential. We study a\nphysically well-motivated ansatz for a sequence of trial states, consisting of\nJastrow repulsive short-range correlations and a condensate, with sufficient\nvariational freedom to approximate the ground state (and possibly also\nlow-energy excited states) of the gas. In the limit $N \\to \\infty$, while\ntaking the relative size of the anyons to zero and the total magnetic flux\n$2\\pi\\beta$ to remain finite, we rigorously derive the stationary\nChern-Simons-Schr\\\"odinger/average-field-Pauli effective energy density\nfunctional for the condensate wave function. This includes a scalar\nself-interaction parameter $\\gamma$ which depends both on $\\beta$, the\ndiluteness of the gas, and the spin-orbit coupling strength $g$, but becomes\nindependent of these microscopic details for a particular value of the coupling\n$g=2$ in which supersymmetry is exhibited (on all scales, both microscopic and\nmesoscopic) with $\\gamma=2\\pi|\\beta|$. Our findings confirm and clarify the\npredictions we have found in the physics literature.","main_category":"math-ph","categories":"math-ph,cond-mat.quant-gas,cond-mat.str-el,math.AP,math.MP,quant-ph","published":"2025-04-24T12:29:20Z"}
{"aid":"http://arxiv.org/abs/2504.17517v1","title":"Current phase relation in a planar graphene Josephson junction with\n  spin-orbit coupling","summary":"We study a graphene Josephson junction where the inner graphene layer is\nsubjected to spin-orbit coupling by proximity effect. This could be achieved,\nfor example, by growing the graphene layer on top of a transition metal\ndichalcogenide, such as WS$_2$. Here, we focus on the ballistic, wide, and\nshort junction limits and study the effects of the spin-orbit interaction on\nthe supercurrent. In particular, we analyze the current phase relation using an\nanalytical approach based on the continuum model. We find combinations of types\nof spin-orbit coupling that significantly suppress the supercurrent by opening\na gap in the graphene band structure. At the same time, other combinations\nenhance it, acting as an effective spin-valley resolved chemical potential.\nMoreover, we find that a strong Rashba spin-orbit coupling leads to a junction\nwith a highly voltage tunable harmonic content.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.supr-con,quant-ph","published":"2025-04-24T12:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.17533v1","title":"Relic gravitational waves from cosmological horizon radiation during de\n  Sitter period: as zero-order approximation of inflation","summary":"It is well known that the event horizon of the de Sitter universe can produce\nparticles, and one can get sizable Hawking radiation by considering\ninflationary phases as de Sitter spacetimes with large Hubble rates. In this\ncompact paper, we consider the graviton emission part of these radiations and\nassume that these graviton signals can exist in the current universe in the\nform of gravitational waves. We predict an energy density parameter of\n$\\log_{10}(\\Omega_{\\rm GW} h^2) \\sim \\mathscr{O}(-25) - \\mathscr{O}(-30)$ and\nits associated peak frequency $\\log_{10}(f_{\\rm peak}^0) \\sim\n\\mathscr{O}(6)-\\mathscr{O}(5)$, depending on the reheating temperature. These\nsignals occupy a frequency band below the ultrahigh-frequency regime and\npossess a detectable energy density, offering a promising target for future\ngravitational wave observatories. We believe that the detection of such signals\nwould provide a compelling test of Hawking's radiation theory in a cosmological\ncontext.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-24T13:19:40Z"}
{"aid":"http://arxiv.org/abs/2504.17542v1","title":"Large Language Model-Driven Concolic Execution for Highly Structured\n  Test Input Generation","summary":"How can we perform concolic execution to generate highly structured test\ninputs for systematically testing parsing programs? Existing concolic execution\nengines are significantly restricted by (1) input structure-agnostic path\nconstraint selection, leading to the waste of testing effort or missing\ncoverage; (2) limited constraint-solving capability, yielding many\nsyntactically invalid test inputs; (3) reliance on manual acquisition of highly\nstructured seed inputs, resulting in non-continuous testing.\n  This paper proposes Cottontail, a new Large Language Model (LLM)-driven\nconcolic execution engine, to mitigate the above limitations. A more complete\nprogram path representation, named Expressive Structural Coverage Tree (ESCT),\nis first constructed to select structure-aware path constraints. Later, an\nLLM-driven constraint solver based on a Solve-Complete paradigm is designed to\nsolve the path constraints smartly to get test inputs that are not only\nsatisfiable to the constraints but also valid to the input syntax. Finally, a\nhistory-guided seed acquisition is employed to obtain new highly structured\ntest inputs either before testing starts or after testing is saturated.\n  We implemented Cottontail on top of SymCC and evaluated eight extensively\ntested open-source libraries across four different formats (XML, SQL,\nJavaScript, and JSON). The experimental result is promising: it shows that\nCottontail outperforms state-of-the-art approaches (SymCC and Marco) by 14.15%\nand 14.31% in terms of line coverage. Besides, Cottontail found 6 previously\nunknown vulnerabilities (six new CVEs have been assigned). We have reported\nthese issues to developers, and 4 out of them have been fixed so far.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T13:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.17570v1","title":"Atemporality from Conservation Laws of Physics in Lorentzian-Euclidean\n  Black Hole","summary":"Recent results have shown that singularities can be avoided from the general\nrelativistic standpoint in Lorentzian-Euclidean black holes by means of the\ntransition from a Lorentzian to an Euclidean region where time loses its\nphysical meaning and becomes imaginary. This dynamical mechanism, dubbed\n``atemporality'', prevents the emergence of black hole singularities and the\nviolation of conservation laws. In this paper, the notion of atemporality\ntogether with a detailed discussion of its implications is presented from a\nphilosophical perspective. The main result consists in showing that\natemporality is naturally related to conservation laws.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-24T13:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.17594v1","title":"Tamper-evident Image using JPEG Fixed Points","summary":"An intriguing phenomenon about JPEG compression has been observed since two\ndecades ago- after repeating JPEG compression and decompression, it leads to a\nstable image that does not change anymore, which is a fixed point. In this\nwork, we prove the existence of fixed points in the essential JPEG procedures.\nWe analyze JPEG compression and decompression processes, revealing the\nexistence of fixed points that can be reached within a few iterations. These\nfixed points are diverse and preserve the image's visual quality, ensuring\nminimal distortion. This result is used to develop a method to create a\ntamper-evident image from the original authentic image, which can expose\ntampering operations by showing deviations from the fixed point image.","main_category":"cs.CV","categories":"cs.CV,I.4.7","published":"2025-04-24T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.17599v1","title":"Dynamical gauge invariance of statistical mechanics","summary":"We investigate gauge invariance against phase space shifting in\nnonequilibrium systems, as represented by time-dependent many-body Hamiltonians\nthat drive an initial ensemble out of thermal equilibrium. The theory gives\nrise to gauge correlation functions that characterize spatial and temporal\ninhomogeneity with microscopic resolution on the one-body level. Analyzing the\ndynamical gauge invariance allows one to identify a specific localized shift\ngauge current as a fundamental nonequilibrium observable that characterizes\nparticle-based dynamics. When averaged over the nonequilibrium ensemble, the\nshift current vanishes identically, which constitutes an exact nonequilibrium\nconservation law that generalizes the Yvon-Born-Green equilibrium balance of\nthe vanishing sum of ideal, interparticle, and external forces. Any given\nobservable is associated with a corresponding dynamical hyperforce density and\nhypercurrent correlation function. An exact nonequilibrium sum rule\ninterrelates these one-body functions, in generalization of the recent\nhyperforce balance for equilibrium systems. We demonstrate the physical\nconsequences of the dynamical gauge invariance using both harmonically confined\nideal gas setups, for which we present analytical solutions, and molecular\ndynamics simulations of interacting systems, for which we demonstrate the shift\ncurrent and hypercurrent correlation functions to be accessible both via\nfinite-difference methods and via trajectory-based automatic differentiation.\nWe show that the theory constitutes a starting point for developing\nnonequilibrium reduced-variance sampling algorithms and for investigating\nthermally-activated barrier crossing.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-24T14:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.17601v1","title":"Interpretable non-linear dimensionality reduction using gaussian\n  weighted linear transformation","summary":"Dimensionality reduction techniques are fundamental for analyzing and\nvisualizing high-dimensional data. With established methods like t-SNE and PCA\npresenting a trade-off between representational power and interpretability.\nThis paper introduces a novel approach that bridges this gap by combining the\ninterpretability of linear methods with the expressiveness of non-linear\ntransformations. The proposed algorithm constructs a non-linear mapping between\nhigh-dimensional and low-dimensional spaces through a combination of linear\ntransformations, each weighted by Gaussian functions. This architecture enables\ncomplex non-linear transformations while preserving the interpretability\nadvantages of linear methods, as each transformation can be analyzed\nindependently. The resulting model provides both powerful dimensionality\nreduction and transparent insights into the transformed space. Techniques for\ninterpreting the learned transformations are presented, including methods for\nidentifying suppressed dimensions and how space is expanded and contracted.\nThese tools enable practitioners to understand how the algorithm preserves and\nmodifies geometric relationships during dimensionality reduction. To ensure the\npractical utility of this algorithm, the creation of user-friendly software\npackages is emphasized, facilitating its adoption in both academia and\nindustry.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.17605v1","title":"A Constraint Opinion Model","summary":"This paper introduces a generalised opinion model that extends the standard\nDeGroot model by representing agents' opinions and influences as soft\nconstraints rather than single real values. This allows for modelling scenarios\nbeyond the scope of the DeGroot model, such as agents sharing partial\ninformation and preferences, engaging in discussions on multiple topics\nsimultaneously, and representing opinions with different degrees of\nuncertainty. By considering soft constraints as influences, the proposed model\ncaptures also situations where agents impose conditions on how others' opinions\nare integrated during belief revision. Finally, the flexibility offered by soft\nconstraints allows us to introduce a novel polarisation measure that takes\nadvantage of this generalised framework.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-24T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.17607v1","title":"Time-resolved dynamics of GaN waveguide polaritons","summary":"We implement a new experimental approach to directly measure the lifetime of\nguided polaritons arising from the strong-coupling of GaN excitons and the\nguided photonic modes of a slab waveguide. Using a Fourier imaging setup,\ncombined with spatial filtering of the emission, the emission associated to\npolaritonic modes with well-defined propagation constants can be selectively\nanalyzed in the temporal domain. By directing it to the entrance slit of a\nstreak camera, time-resolved photoluminescence (TRPL) measurements along the\npolariton dispersion branch were performed at 40 K, enabling to assess the time\ndecay of polariton modes. By combining this information with the\nphotonic/excitonic fraction corresponding to each polariton mode, extracted\nfrom a coupled-oscillators model that indicate a Rabi splitting of $\\Omega$ =\n80 meV, we could extract the photon lifetime in the waveguide $\\tau_\\gamma\\,\n=\\, 3\\pm 1$ ps. This corresponds to a record $Q$-factor in the UV of 16 000.\nThe excitonic reservoir lifetime, which contributes to polariton formation, was\ndetermined through TRPL measurements on excitonic luminescence. Finally,\nmeasurements conducted at lower temperature highlight secondary feeding\nmechanisms for the guided polaritonic mode, either via photon recycling from\nthe AlGaN cladding layer or through resonant injection of photons from\ntransitions below the band gap.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T14:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.17611v1","title":"Some Results on Generalized Familywise Error Rate Controlling Procedures\n  under Dependence","summary":"The topic of multiple hypotheses testing now has a potpourri of novel\ntheories and ubiquitous applications in diverse scientific fields. However, the\nuniversal utility of this field often hinders the possibility of having a\ngeneralized theory that accommodates every scenario. This tradeoff is better\nreflected through the lens of dependence, a central piece behind the\ntheoretical and applied developments of multiple testing. Although omnipresent\nin many scientific avenues, the nature and extent of dependence vary\nsubstantially with the context and complexity of the particular scenario.\nPositive dependence is the norm in testing many treatments versus a single\ncontrol or in spatial statistics. On the contrary, negative dependence arises\nnaturally in tests based on split samples and in cyclical, ordered comparisons.\nIn GWAS, the SNP markers are generally considered to be weakly dependent.\nGeneralized familywise error rate (k-FWER) control has been one of the\nprominent frequentist approaches in simultaneous inference. However, the\nperformances of k-FWER controlling procedures are yet unexplored under\ndifferent dependencies. This paper revisits the classical testing problem of\nnormal means in different correlated frameworks. We establish upper bounds on\nthe generalized familywise error rates under each dependence, consequently\ngiving rise to improved testing procedures. Towards this, we present improved\nprobability inequalities, which are of independent theoretical interest","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-04-24T14:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.17624v1","title":"Deciphering the unique dynamic activation pathway in a G protein-coupled\n  receptor enables unveiling biased signaling and identifying cryptic\n  allosteric sites in conformational intermediates","summary":"Neurotensin receptor 1 (NTSR1), a member of the Class A G protein-coupled\nreceptor superfamily, plays an important role in modulating dopaminergic\nneuronal activity and eliciting opioid-independent analgesia. Recent studies\nsuggest that promoting \\{beta}-arrestin-biased signaling in NTSR1 may diminish\ndrugs of abuse, such as psychostimulants, thereby offering a potential avenue\nfor treating human addiction-related disorders. In this study, we utilized a\nnovel computational and experimental approach that combined nudged elastic\nband-based molecular dynamics simulations, Markov state models, temporal\ncommunication network analysis, site-directed mutagenesis, and conformational\nbiosensors, to explore the intricate mechanisms underlying NTSR1 activation and\nbiased signaling. Our study reveals a dynamic stepwise transition mechanism and\nactivated transmission network associated with NTSR1 activation. It also yields\nvaluable insights into the complex interplay between the unique polar network,\nnon-conserved ion locks, and aromatic clusters in NTSR1 signaling. Moreover, we\nidentified a cryptic allosteric site located in the intracellular region of the\nreceptor that exists in an intermediate state within the activation pathway.\nCollectively, these findings contribute to a more profound understanding of\nNTSR1 activation and biased signaling at the atomic level, thereby providing a\npotential strategy for the development of NTSR1 allosteric modulators in the\nrealm of G protein-coupled receptor biology, biophysics, and medicine.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-24T14:46:20Z"}
{"aid":"http://arxiv.org/abs/2504.17628v1","title":"Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with\n  Self-attention Diffusion Models and the Potential for Text-Guided\n  Customization","summary":"Diabetic foot ulcers (DFUs) pose a significant challenge in healthcare,\nrequiring precise and efficient wound assessment to enhance patient outcomes.\nThis study introduces the Attention Diffusion Zero-shot Unsupervised System\n(ADZUS), a novel text-guided diffusion model that performs wound segmentation\nwithout relying on labeled training data. Unlike conventional deep learning\nmodels, which require extensive annotation, ADZUS leverages zero-shot learning\nto dynamically adapt segmentation based on descriptive prompts, offering\nenhanced flexibility and adaptability in clinical applications. Experimental\nevaluations demonstrate that ADZUS surpasses traditional and state-of-the-art\nsegmentation models, achieving an IoU of 86.68\\% and the highest precision of\n94.69\\% on the chronic wound dataset, outperforming supervised approaches such\nas FUSegNet. Further validation on a custom-curated DFU dataset reinforces its\nrobustness, with ADZUS achieving a median DSC of 75\\%, significantly surpassing\nFUSegNet's 45\\%. The model's text-guided segmentation capability enables\nreal-time customization of segmentation outputs, allowing targeted analysis of\nwound characteristics based on clinical descriptions. Despite its competitive\nperformance, the computational cost of diffusion-based inference and the need\nfor potential fine-tuning remain areas for future improvement. ADZUS represents\na transformative step in wound segmentation, providing a scalable, efficient,\nand adaptable AI-driven solution for medical imaging.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-24T14:50:10Z"}
{"aid":"http://arxiv.org/abs/2504.17639v1","title":"Hot Diggity Dog: A complete analysis of the extreme molecular gas and\n  dust properties at kpc scales in the hyper-luminous hot, dust-obscured galaxy\n  W2246-0526","summary":"Hot dust-obscured galaxies (Hot DOGs), the most infrared (IR) luminous\nobjects selected by the WISE all-sky mid-IR survey, have yielded a sample of\nintrinsically luminous quasars (QSOs) with obscured nuclear activity and hot\ndust temperatures. The molecular gas excitation properties have yet to be\nexamined in detail under such extreme conditions. Here we study the most far-IR\nluminous WISE Hot DOG W2246-0526, focusing on the central host galaxy. Multi-J\nCO transition measurements at J=2-1, 5-4, 7-6, 12-11, and 17-16 provide the\nmost well-sampled CO excitation ladder of any WISE Hot DOG to date, providing\nthe first self-consistent modeling constraints on the molecular gas and dust\nproperties. We implement a state-of-the-art TUrbulent Non-Equilibrium Radiative\ntransfer model (TUNER) that simultaneously models both the line and dust\ncontinuum measurements. Due to a combination of high molecular gas densities\nand high kinetic temperatures, this extreme CO spectral line energy\ndistribution peaks at J = 10 to 12, likely making this the most highly excited\ngalaxy ever reported. We derive the alpha_CO conversion factors and conclude\nthat (J=3-7) CO line luminosities trace the bulk of the molecular gas mass.\nW2246-0526 is a rapidly evolving system, with a high value of the molecular gas\nkinetic temperature versus dust temperature T_k / T_d ~ 3.9, reflecting\npreviously reported shocks and outflows injecting kinetic energy within the\ncentral kpc of this host. This first comprehensive simultaneous modeling of\nboth the molecular gas and dust in any object within the WISE-selected Hot DOG\nsample motivates obtaining well-sampled dust and line spectral energy\ndistributions to better understand the conditions within these short-lived\nepisodes in galaxy evolution that are associated with the most obscured\nsupermassive black hole activity.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T15:10:43Z"}
{"aid":"http://arxiv.org/abs/2504.17640v1","title":"A modular framework for generalized Hurwitz class numbers III","summary":"In $2003$, Pei and Wang introduced higher level analogs of the classical\nCohen--Eisenstein series. In recent joint work with Beckwith, we found a weight\n$\\frac{1}{2}$ sesquiharmonic preimage of their weight $\\frac{3}{2}$ Eisenstein\nseries under $\\xi_{\\frac{1}{2}}$ utilizing a construction from seminal work by\nDuke, Imamo\\={g}lu and T\\'{o}th. In further joint work with Beckwith, when\nrestricting to prime level, we realized our preimage as a regularized Siegel\ntheta lift and evaluated its (regularized) Fourier coefficients explicitly.\nThis relied crucially on work by Bruinier, Funke and Imamo\\={g}lu. In this\npaper, we extend both works to higher weights. That is, we provide a harmonic\npreimage of Pei and Wang's generalized Cohen--Eisenstein series under\n$\\xi_{\\frac{3}{2}-k}$, where $k > 1$. Furthermore, when restricting to prime\nlevel, we realize them as outputs of a regularized Shintani theta lift of a\nhigher level holomorphic Eisenstein series, which builds on recent work by\nAlfes and Schwagenscheidt. Lastly, we evaluate the regularized Millson theta\nlift of a higher level Maass--Eisenstein series, which is known to be connected\nto the Shintani theta lift by a differential equation by earlier work of Alfes\nand Schwagenscheidt.","main_category":"math.NT","categories":"math.NT","published":"2025-04-24T15:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.17659v1","title":"Programmable glassy dynamics using tunable disorder in tweezer arrays","summary":"We propose a unifying framework for non-equilibrium relaxation dynamics in\nensembles of positionally disordered interacting quantum spins based on the\nstatistical properties, such as mean and variance, of the underlying disorder\ndistribution. Our framework is validated through extensive exact numerical\ncalculations and we use it to disentangle and understand the importance of\ndimensionality and interaction range for the observation of glassy (i.e.,\nsub-exponential) decay dynamics. Leveraging the deterministic control of qubit\npositioning enabled by modern tweezer array architectures, we also introduce a\nmethod (``J-mapping'') that can be used to emulate the relaxation dynamics of a\ndisordered system with arbitrary dimensionality and interaction range in\nbespoke one-dimensional arrays. Our approach paves the way towards tunable\nrelaxation dynamics that can be explored in quantum simulators based on arrays\nof neutral atoms and molecules.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.dis-nn,quant-ph","published":"2025-04-24T15:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.17667v1","title":"Spectral Irradiance Variability in Lyman-Alpha Emission During Solar\n  Flares","summary":"The Lyman-alpha (Ly{\\alpha};1216 {\\AA}) line is the brightest emission line\nin the quiescent solar spectrum and radiates a significant fraction of the\navailable nonthermal energy during flares. Despite its importance, there is a\nlack of detailed studies of Ly{\\alpha} spectral variability during flares.\nRecently, spectrally resolved Ly{\\alpha} flare observations from the\nSORCE/SOLSTICE instrument have become available. This study examines Ly{\\alpha}\nspectral variability and its relationship with HXR emission from nonthermal\nelectrons, using observations of two M-class flares from SORCE/SOLSTICE and\nRHESSI. Imaging observations from STEREO/SECCHI EUVI and SDO/AIA provide\nfurther context. Enhancements across the Ly{\\alpha} line profile were found to\nclosely correlate with bursts of HXR emission, suggesting a primarily\nnonthermal origin. Red enhancement asymmetries at the peak of each flare were\nattributed to chromospheric evaporation, while blue wing enhancement and blue\nasymmetry were linked to a bright filament-eruption seen in SDO/AIA 1600 {\\AA}\nimages. These findings contribute to the understanding of spectral Ly{\\alpha}\nvariability during flares and highlight the need for future studies using a\nhigher quality and quantity of spectral Ly{\\alpha} flare observations. Such\nstudies will further characterise the physical mechanisms driving Ly{\\alpha}\nflare variability.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-24T15:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.17693v1","title":"BIM-Constrained Optimization for Accurate Localization and Deviation\n  Correction in Construction Monitoring","summary":"Augmented reality (AR) applications for construction monitoring rely on\nreal-time environmental tracking to visualize architectural elements. However,\nconstruction sites present significant challenges for traditional tracking\nmethods due to featureless surfaces, dynamic changes, and drift accumulation,\nleading to misalignment between digital models and the physical world. This\npaper proposes a BIM-aware drift correction method to address these challenges.\nInstead of relying solely on SLAM-based localization, we align ``as-built\"\ndetected planes from the real-world environment with ``as-planned\"\narchitectural planes in BIM. Our method performs robust plane matching and\ncomputes a transformation (TF) between SLAM (S) and BIM (B) origin frames using\noptimization techniques, minimizing drift over time. By incorporating BIM as\nprior structural knowledge, we can achieve improved long-term localization and\nenhanced AR visualization accuracy in noisy construction environments. The\nmethod is evaluated through real-world experiments, showing significant\nreductions in drift-induced errors and optimized alignment consistency. On\naverage, our system achieves a reduction of 52.24% in angular deviations and a\nreduction of 60.8% in the distance error of the matched walls compared to the\ninitial manual alignment by the user.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-24T16:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.17701v1","title":"Network Sampling: An Overview and Comparative Analysis","summary":"Network sampling is a crucial technique for analyzing large or partially\nobservable networks. However, the effectiveness of different sampling methods\ncan vary significantly depending on the context. In this study, we empirically\ncompare representative methods from three main categories: node-based,\nedge-based, and exploration-based sampling. We used two real-world datasets for\nour analysis: a scientific collaboration network and a temporal message-sending\nnetwork. Our results indicate that no single sampling method consistently\noutperforms the others in both datasets. Although advanced methods tend to\nprovide better accuracy on static networks, they often perform poorly on\ntemporal networks, where simpler techniques can be more effective. These\nfindings suggest that the best sampling strategy depends not only on the\nstructural characteristics of the network but also on the specific metrics that\nneed to be preserved or analyzed. Our work offers practical insights for\nresearchers in choosing sampling approaches that are tailored to different\ntypes of networks and analytical objectives.","main_category":"cs.SI","categories":"cs.SI,cond-mat.stat-mech,physics.data-an","published":"2025-04-24T16:10:06Z"}
{"aid":"http://arxiv.org/abs/2504.17736v1","title":"Design and benchmarking of a two degree of freedom tendon driver unit\n  for cable-driven wearable technologies","summary":"Exosuits have recently been developed as alternatives to rigid exoskeletons\nand are increasingly adopted for both upper and lower limb therapy and\nassistance in clinical and home environments. Many cable-driven exosuits have\nbeen developed but little has been published on their electromechanical designs\nand performance. Therefore, this paper presents a comprehensive design and\nperformance analysis of a two degree of freedom tendon driver unit (TDU) for\ncable-driven wearable exosuits. Detailed methodologies are presented to\nbenchmark the functionality of the TDU. A static torque output test compares\nthe commanded and measured torques. A velocity control test evaluates the\nattenuation and phase shift across velocities. A noise test evaluates how loud\nthe TDU is for the wearer under different speeds. A thermal stress test\ncaptures the cooling performance of the TDU to ensure safe operation at higher\nloads. Finally, a battery endurance test evaluates the runtime of the TDU under\nvarious loading conditions to inform the usable time. To demonstrate these\ntests, a modular TDU system for cable-driven applications is introduced, which\nallows components such as motors, pulleys, and sensors to be adapted based on\nthe requirements of the intended application. By sharing detailed methodologies\nand performance results, this study aims to provide a TDU design that may be\nleveraged by others and resources for researchers and engineers to better\ndocument the capabilities of their TDU designs.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T16:49:21Z"}
{"aid":"http://arxiv.org/abs/2504.17745v1","title":"Asymptotic attraction with algebraic rates toward fronts of\n  dispersive-diffusive Burgers equations","summary":"Burgers equation is a classic model, which arises in numerous applications.\nAt its very core it is a simple conservation law, which serves as a toy model\nfor various dynamics phenomena. In particular, it supports explicit\nheteroclinic solutions, both fronts and backs. Their stability has been studied\nin details. There has been substantial interest in considering dispersive\nand/or diffusive modifications, which present novel dynamical paradigms in such\nsimple setting. More specificaly, the KdV-Burgers model has been showed to\nsupport unique fronts (not all of them monotone!) with fixed values at $\\pm\n\\infty$. Many articles, among which \\cite{Pego}, \\cite{NS1}, \\cite{NS2}, have\nstudied the question of stability of monotone (or close to monotone) fronts.\n  In a breakthrough paper, \\cite{BBHY}, the authors have extended these results\nin several different directions. They have considered a wider range of models.\nThe fronts do not need to be monotone, but are subject of a spectral condition\ninstead. Most importantly the method allows for large perturbations, as long as\nthe heteroclinic conditions at $\\pm \\infty$ are met. That is, there is\nasymptotic attraction to the said fronts or equivalently the limit set consist\nof one point.\n  The purpose of this paper is to extend the results of \\cite{BBHY} by\nproviding explicit algebraic rates of convergence as $t\\to \\infty$. We\nbootstrap these results from the results in \\cite{BBHY} using additional energy\nestimates for two important examples namely KdV-Burgers and the fractional\nBurgers problem. These rates are likely not optimal, but we conjecture that\nthey are algebraic nonetheless.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T17:05:50Z"}
{"aid":"http://arxiv.org/abs/2504.17764v1","title":"Orbifolds, higher dagger structures, and idempotents","summary":"The orbifold/condensation completion procedure of defect topological quantum\nfield theories can be seen as carrying out a lattice or state sum model\nconstruction internal to an ambient theory. In this paper, we propose a\nconceptual algebraic description of orbifolds/condensations for arbitrary\ntangential structures in terms of higher dagger structures and higher\nidempotents. In particular, we obtain (oriented) orbifold completion from\n(framed) condensation completion by using a general strictification procedure\nfor higher dagger structures which we describe explicitly in low dimensions; we\nalso discuss the spin and unoriented case. We provide several examples of\nhigher dagger categories, such as those associated to state sum models,\n(orbifolds of) Landau--Ginzburg models, and truncated affine Rozansky--Witten\nmodels. We also explain how their higher dagger structures are naturally\ninduced from rigid symmetric monoidal structures, recontextualizing and\nextending results from the literature.","main_category":"math.QA","categories":"math.QA,hep-th,math-ph,math.CT,math.MP","published":"2025-04-24T17:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.17783v1","title":"Nanoscale infrared and microwave imaging of stacking faults in\n  multilayer graphene","summary":"Graphite occurs in a range of metastable stacking orders characterized by\nboth the number and direction of shifts between adjacent layers by the length\nof a single carbon-carbon bond. At the extremes are Bernal (or ``ABAB...'')\nstacking, where the direction of the interlayer shift alternates with each\nlayer, and rhombohedral (or ``ABCABC...'') stacking order where the shifts are\nalways in the same direction. However, for an N-layer system, there are in\nprinciple $N-1$ unique metastable stacking orders of this type. Recently, it\nhas become clear that stacking order has a strong effect on the low energy\nelectronic band structure with single-layer shifts completely altering the\nelectronic properties. Most experimental work has focused on the extremal\nstacking orders in large part due to the difficulty of isolating and\nidentifying intermediate orders. Motivated by this challenge, here we describe\ntwo atomic force microscopy (AFM) based techniques to unambiguously distinguish\nstacking orders and defects in graphite flakes. Photo-thermal infrared atomic\nforce microscope (AFM-IR) is able to distinguish stacking orders across\nmultiple IR wavelengths and readily provides absolute contrast via IR spectral\nanalysis. Scanning microwave impedance microscopy (sMIM) can distinguish the\nrelative contrast between Bernal, intermediate and rhombohedral domains. We\nshow that both techniques are well suited to characterizing graphite van der\nWaals devices, providing high contrast determination of stacking order,\nsubsurface imaging of graphene flakes buried under a hexagonal boron nitride\n(hBN) dielectric layer, and identifying nanoscale domain walls. Our results\npave the way for the reliable fabrication of graphene multilayer devices of\ndefinite interlayer registry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-24T17:58:30Z"}
{"aid":"http://arxiv.org/abs/2504.17787v1","title":"The Fourth Monocular Depth Estimation Challenge","summary":"This paper presents the results of the fourth edition of the Monocular Depth\nEstimation Challenge (MDEC), which focuses on zero-shot generalization to the\nSYNS-Patches benchmark, a dataset featuring challenging environments in both\nnatural and indoor settings. In this edition, we revised the evaluation\nprotocol to use least-squares alignment with two degrees of freedom to support\ndisparity and affine-invariant predictions. We also revised the baselines and\nincluded popular off-the-shelf methods: Depth Anything v2 and Marigold. The\nchallenge received a total of 24 submissions that outperformed the baselines on\nthe test set; 10 of these included a report describing their approach, with\nmost leading methods relying on affine-invariant predictions. The challenge\nwinners improved the 3D F-Score over the previous edition's best result,\nraising it from 22.58% to 23.05%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.19471v1","title":"Properties of $X(3872)$ from hadronic potentials coupled to quarks","summary":"The concept of compositeness is used to quantitatively discuss the hadronic\nmolecular nature in exotic hadrons. In this work, we develop a formulation to\nexplicitly introduce the compact quark state contribution in the hadronic\npotentials together with the direct four-point interaction. We derive analytic\nexpressions of the compositeness from the effective potential between hadrons\nwhen the system has a bound state. Applying this formulation to the $X(3872)$,\nwe examine the variation of the compositeness with respect to the binding\nenergy, energy of $\\chi_{c1}(2P)$, cutoff momentum, and strength of the direct\n$D^0\\bar{D}^{*0}$ interaction.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-28T04:22:26Z"}
{"aid":"http://arxiv.org/abs/2504.19474v1","title":"Precision Polarization Tuning for Light Shift Mitigation in Trapped-Ion\n  Qubits","summary":"Trapped-ion qubits are among the most promising candidates for quantum\ncomputing, quantum information processing, and quantum simulation. In general,\ntrapped ions are considered to have sufficiently long coherence times, which\nare mainly characterized under laser-free conditions. However, in reality,\nessential laser fields for quantum manipulation introduce residual light shift,\nwhich seriously degrades the coherence due to power fluctuations. Here, we\npresent a comprehensive study of AC Stark shifts in the hyperfine energy levels\nof the $^{171}\\mathrm{Yb}^+$ ion, revealing an asymmetric light shift between\ntwo circular polarizations in the clock qubit and pronounced vector light\nshifts in the Zeeman qubits. By precisely tuning these polarizations, a\nremarkable enhancement in coherence time is observed, reaching over a\nhundredfold for the clock qubit and more than tenfold for the Zeeman qubits,\nwhen comparing conditions of maximum and minimum shifts. These findings advance\nthe practical realization of scalable trapped-ion quantum processors, enabling\ndeep quantum circuit execution and long duration adiabatic operations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T04:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.19490v1","title":"Rapid and efficient wavefront correction for spatially entangled photons\n  using symmetrized optimization","summary":"Spatial entanglement is a key resource in quantum technologies, enabling\napplications in quantum communication, imaging, and computation. However,\npropagation through complex media distorts spatial correlations, posing a\nchallenge for practical implementations. We introduce a symmetrized genetic\nalgorithm (sGA) for adaptive wavefront correction of spatially entangled\nphotons, leveraging the insight that only the even-parity component of\nwavefront distortions affects two-photon correlations. By enforcing symmetry\nconstraints, sGA reduces the optimization parameter space by half, leading to\nfaster convergence and improved enhancement within finite number of generations\ncompared to standard genetic algorithms (GA). Additionally, we establish the\ndependence of enhancement on the signal-to-noise ratio of the feedback signal,\nwhich is controlled by detector integration time. This technique enables\ncorrection of entanglement degradation, enhancing quantum imaging, secure\nquantum communication, and quantum sensing in complex environments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T05:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.19491v1","title":"Self-testing of Nonmaximal Genuine Entangled States using Tripartite\n  Hardy Relations","summary":"We demonstrate that, in the tripartite scenario with all parties' local\nevents being space-like separated, Hardy-type nonlocality constitutes a\nstronger manifestation of nonlocal correlations than those captured by\nMermin-type inequalities, an important distinction that has hitherto remained\nunrecognised. To substantiate this assertion, we develop a general framework\nfor the characterisation of tripartite correlations by extending the notion of\nSettings Independence and Outcome Independence beyond their bipartite\nformulation. This framework highlights the pivotal role of Hardy-type reasoning\nin the detection and certification of genuine multipartite nonlocality.\nFurthermore, we show that the tripartite Hardy-nonlocality enables the\nself-testing of a broad class of pure nonmaximally genuine entangled tripartite\nstates. A key advantage of Hardy-based self-testing over methods based on\ntripartite Bell inequalities is its ability to certify quantum correlations\neven in the presence of nonmaximal violations. This, in turn, facilitates the\ndevice-independent certification of randomness from Hardy-type correlations.\nUnlike Bell functionals, which typically enable self-testing of only a single\nextremal point per inequality, Hardy relation self-tests a set of extremal\nquantum correlations for any nonzero Hardy probability. We find that the\nmaximum certifiable randomness using Hardy-type correlations is $\\log_2\n7\\approx 2.8073$-bits, highlighting both the practical and foundational\nsignificance of Hardy-based techniques for quantum randomness generation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T05:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.19510v1","title":"Neutrino Constraints on Black Hole Formation in M31","summary":"We investigate neutrino signals associated with black hole formation\nresulting from the gravitational collapse of massive stars, motivated by the\ncandidate failed supernova M31-2014-DS1 in the Andromeda Galaxy (M31). By\ncompiling numerical simulation results for stellar collapse, we predict the\nexpected neutrino emission and compare these predictions with observational\nlimits from Super-Kamiokande (SK). The simulations reveal a characteristic\nprecursor signal consisting of a short, intense burst whose average neutrino\nenergy rises rapidly and then ceases abruptly once the black hole forms. We\nexamine several nuclear equations of state, specifically the Lattimer \\&\nSwesty, Shen, Togashi, and SFHo models, to evaluate how the emission depends on\nneutron-star properties and nuclear-physics uncertainties. Comparison of the\npredicted event counts with SK's non-detection of neutrinos coincident with\nM31-2014-DS1 already rules out part of the model space and highlights the\nsensitivity of current neutrino detectors to both progenitor mass and the EOS.\nThese findings demonstrate the capability of neutrino astronomy to probe core\ncollapse and black hole formation in failed supernova scenarios.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-28T06:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.19520v1","title":"Maximizing Infrared Transmission Contrast Upon Phase Transition of\n  Thermally Grown Vanadium Dioxide Thin Films by Rapid Thermal Processing","summary":"Pristine vanadium dioxide (VO2), an insulator-to-metal transition (IMT)\nmaterial, is grown via furnace oxidation followed by rapid thermal annealing\nwith forming gas (5%H2/95%N2) which reduces surface over-oxides such as V2O5\nformed during the oxidation. The evolutional IMT behaviors of the thermochromic\nfilm and vanadium oxide states over different reduction time are systematically\nstudied with temperature-dependent infrared spectrometry, electrical\nresistivity, and X-ray diffraction measurements. After optimally reducing\nsurface over-oxides to VO2, infrared transmission contrast upon phase\ntransition is enhanced to 46% (at 9 um wavelength) compared to 23% from fully\noxidation without any reduction. Moreover, pristine VO2 thin film obtained from\nthermal oxidation and optimal reduction processes exhibits sharp phase\ntransition and narrow thermal hysteresis within 2~4{\\deg}C in both infrared\ntransmission and electrical resistivity, which are comparable to the VO2 of\nbest quality prepared by other sophisticated fabrication techniques. The\nthermally grown method presented here would facilitate the scalable fabrication\nof high-quality VO2 thin films and tunable radiative coatings for\nhigh-performance thermal control applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.optics","published":"2025-04-28T06:38:51Z"}
{"aid":"http://arxiv.org/abs/2504.19538v1","title":"Towards Faster and More Compact Foundation Models for Molecular Property\n  Prediction","summary":"Advancements in machine learning for molecular property prediction have\nimproved accuracy but at the expense of higher computational cost and longer\ntraining times. Recently, the Joint Multi-domain Pre-training (JMP) foundation\nmodel has demonstrated strong performance across various downstream tasks with\nreduced training time over previous models. Despite JMP's advantages,\nfine-tuning it on molecular datasets ranging from small-scale to large-scale\nrequires considerable time and computational resources. In this work, we\ninvestigate strategies to enhance efficiency by reducing model size while\npreserving performance. To better understand the model's efficiency, we analyze\nthe layer contributions of JMP and find that later interaction blocks provide\ndiminishing returns, suggesting an opportunity for model compression. We\nexplore block reduction strategies by pruning the pre-trained model and\nevaluating its impact on efficiency and accuracy during fine-tuning. Our\nanalysis reveals that removing two interaction blocks results in a minimal\nperformance drop, reducing the model size by 32% while increasing inference\nthroughput by 1.3x. These results suggest that JMP-L is over-parameterized and\nthat a smaller, more efficient variant can achieve comparable performance with\nlower computational cost. Our study provides insights for developing lighter,\nfaster, and more scalable foundation models for molecular and materials\ndiscovery. The code is publicly available at:\nhttps://github.com/Yasir-Ghunaim/efficient-jmp.","main_category":"cs.LG","categories":"cs.LG,q-bio.BM","published":"2025-04-28T07:41:03Z"}
{"aid":"http://arxiv.org/abs/2504.19556v1","title":"Detecting Effects of AI-Mediated Communication on Language Complexity\n  and Sentiment","summary":"Given the subtle human-like effects of large language models on linguistic\npatterns, this study examines shifts in language over time to detect the impact\nof AI-mediated communication (AI- MC) on social media. We compare a replicated\ndataset of 970,919 tweets from 2020 (pre-ChatGPT) with 20,000 tweets from the\nsame period in 2024, all of which mention Donald Trump during election periods.\nUsing a combination of Flesch-Kincaid readability and polarity scores, we\nanalyze changes in text complexity and sentiment. Our findings reveal a\nsignificant increase in mean sentiment polarity (0.12 vs. 0.04) and a shift\nfrom predominantly neutral content (54.8% in 2020 to 39.8% in 2024) to more\npositive expressions (28.6% to 45.9%). These findings suggest not only an\nincreasing presence of AI in social media communication but also its impact on\nlanguage and emotional expression patterns.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-28T08:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.19566v1","title":"Metadata-private Messaging without Coordination","summary":"For those seeking end-to-end private communication free from pervasive\nmetadata tracking and censorship, the Tor network has been the de-facto choice\nin practice, despite its susceptibility to traffic analysis attacks. Recently,\nnumerous metadata-private messaging proposals have emerged with the aim to\nsurpass Tor in the messaging context by obscuring the relationships between any\ntwo messaging buddies, even against global and active attackers. However, most\nof these systems face an undesirable usability constraint: they require a\nmetadata-private \"dialing\" phase to establish mutual agreement and timing or\nround coordination before initiating any regular chats among users. This phase\nis not only resource-intensive but also inflexible, limiting users' ability to\nmanage multiple concurrent conversations seamlessly. For stringent privacy\nrequirement, the often-enforced traffic uniformity further exacerbated the\nlimitations of this roadblock.\n  In this paper, we introduce PingPong, a new end-to-end system for\nmetadata-private messaging designed to overcome these limitations. Under the\nsame traffic uniformity requirement, PingPong replaces the rigid\n\"dial-before-converse\" paradigm with a more flexible \"notify-before-retrieval\"\nworkflow. This workflow incorporates a metadata-private notification subsystem,\nPing, and a metadata-private message store, Pong. Both Ping and Pong leverage\nhardware-assisted secure enclaves for performance and operates through a series\nof customized oblivious algorithms, while meeting the uniformity requirements\nfor metadata protection. By allowing users to switch between conversations on\ndemand, PingPong achieves a level of usability akin to modern instant messaging\nsystems, while also offering improved performance and bandwidth utilization for\ngoodput. We have built a prototype of PingPong with 32 8-core servers equipped\nwith enclaves to validate our claims.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-28T08:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.19610v1","title":"Some Laplacian eigenvalues can be computed by matrix perturbation","summary":"Based on matrix perturbation theory, closed-form analytic expansions are\nstudied for a Laplacian eigenvalue of an undirected, possibly weighted graph,\nwhich is close to a unique degree in that graph. An approximation is presented\nto provide an analytic estimate of a Laplacian eigenvalue and complements\nbounds on Laplacian eigenvalues in spectral graph theory. Then, we apply the\nEuler summation and numerically analyze how the structure of graphs influences\nthe convergence of the corresponding Euler series. Moreover, we obtain the\nexplicit form of the perturbation Taylor series and its Euler series of almost\nregular graphs in which only one node has a unique degree and all remaining\nnodes have the same degree. We find that the Euler series possesses a superior\nconvergence range than the perturbation Taylor series for almost regular\ngraphs.","main_category":"math.SP","categories":"math.SP","published":"2025-04-28T09:17:18Z"}
{"aid":"http://arxiv.org/abs/2504.19617v1","title":"The impact of the TMD shape function on matching the transverse momentum\n  spectrum in $J/ψ$ production at the EIC","summary":"The impact of the inclusion of TMD shape functions on the transverse momentum\nspectrum in $J/\\psi$ production at the EIC is investigated by considering the\nmatching of the TMD factorization description at low transverse momentum with\nthe collinear factorization description at high transverse momentum by means of\nthe inverse-error weighting method. Despite large uncertainties from scale\nvariations and the $J/\\psi$ long-distance matrix elements, predictions for the\ndifferential cross section and its $\\cos(2\\phi_\\psi)$ modulation are obtained.\nWe find that physical constraints are satisfied in case a process-dependent\nterm is included for color octet production, but not in all cases when it is\nexcluded. These numerical results support the analytic calculations in\n\\cite{Boer:2023zit}. Future experimental data can thus test the validity of TMD\nfactorization in $J/\\psi$ production and explore the presence of nontrivial\nprocess-dependent effects in the soft-gluon resummation. This will be crucial\nin the extraction of gluon unpolarized and linearly polarized TMD distributions\nof the proton. In addition, we suggest how the sign of the latter can be\ndetermined by investigating the presence of a node in the $\\cos(2\\phi_\\psi)$\nmodulation as a function of transverse momentum.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T09:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.19682v1","title":"Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based\n  Image Classification","summary":"Graph Neural Networks (GNNs) have emerged as an efficient alternative to\nconvolutional approaches for vision tasks such as image classification,\nleveraging patch-based representations instead of raw pixels. These methods\nconstruct graphs where image patches serve as nodes, and edges are established\nbased on patch similarity or classification relevance. Despite their\nefficiency, the explainability of GNN-based vision models remains\nunderexplored, even though graphs are naturally interpretable. In this work, we\nanalyze the semantic consistency of the graphs formed at different layers of\nGNN-based image classifiers, focusing on how well they preserve object\nstructures and meaningful relationships. A comprehensive analysis is presented\nby quantifying the extent to which inter-layer graph connections reflect\nsemantic similarity and spatial coherence. Explanations from standard and\nadversarial settings are also compared to assess whether they reflect the\nclassifiers' robustness. Additionally, we visualize the flow of information\nacross layers through heatmap-based visualization techniques, thereby\nhighlighting the models' explainability. Our findings demonstrate that the\ndecision-making processes of these models can be effectively explained, while\nalso revealing that their reasoning does not necessarily align with human\nperception, especially in deeper layers.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-28T11:13:40Z"}
{"aid":"http://arxiv.org/abs/2504.19704v1","title":"Dynamical decomposition of generalized interval exchange transformations","summary":"We develop a renormalization scheme which extends the classical Rauzy-Veech\ninduction used to study interval exchange tranformations (IETs) and allows to\nstudy generalized interval exchange transformations (GIETs) $T: [0,1) \\to\n[0,1)$ with possibly more than one quasiminimal component (i.e. not\ninfinite-complete, or, equivalently, not semi-conjugated to a minimal IET). The\nrenormalization is defined for more general maps that we call interval exchange\ntransformations with gaps (g-GIETs), namely partially defined GIETs which\nappear naturally as the first return map of $C^r$-flows on two-dimensional\nmanifolds to any transversal segment. We exploit this renormalization scheme to\nfind a decomposition of $[0,1)$ into finite unions of intervals which either\ncontain no recurrent orbits, or contain only recurrent orbits which are closed,\nor contain a unique quasiminimal. This provides an alternative approach to the\ndecomposition results for foliations and flows on surfaces by Levitt, Gutierrez\nand Gardiner from the $1980s$.","main_category":"math.DS","categories":"math.DS","published":"2025-04-28T11:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.19717v1","title":"A high-order recombination algorithm for weak approximation of\n  stochastic differential equations","summary":"The authors present an algorithm for the application of the high-order\nrecombination method first introduced by Terry Lyons and Christian Litterer in\n``high-order recombination and an application to cubature on Wiener space''\n(Ann. Appl. Probab 22(4):1301-1327, 2012), to real-world problems in\nmathematical finance. They also give numerical examples showing that the\nalgorithm presented successfully avoids the explosive increase in the number of\nsupport of the measure that achieves high-order approximations.","main_category":"math.PR","categories":"math.PR,q-fin.CP","published":"2025-04-28T12:12:40Z"}
{"aid":"http://arxiv.org/abs/2504.19741v1","title":"Optimal Stopping of a Brownian Excursion and an $α$-dimensional\n  Bessel Bridge","summary":"We study the optimal stopping of an $\\alpha$-dimensional Bessel bridge for\nthe payoff $\\phi(x)=x^n$, where $\\alpha,n>0$. As a special case we consider the\nBrownian excursion with the identity function as the payoff ($\\alpha=3,n=1$).\nFor the Brownian excursion we can give an explicit solution but in the general\ncase we provide a complete solution via a power series expansion.","main_category":"math.PR","categories":"math.PR","published":"2025-04-28T12:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.19755v1","title":"Hybrid Approach Combining Ultrasound and Blood Test Analysis with a\n  Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment","summary":"Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T12:54:51Z"}
{"aid":"http://arxiv.org/abs/2504.19770v1","title":"Simplicity of Mellin amplitudes for AdS$_3 \\times$S$^3$","summary":"The spectrum of half-BPS single-particle operators of the D1-D5 system in the\nsupergravity regime is dual to the spectrum of Kaluza-Klein modes of tensor and\ngraviton multiplets in AdS$_3\\times$S$^3$. We present simple formulae for all\nfour-point tree-level correlators of scalar half-BPS primary operators in the\nspectrum, and in particular, we bootstrap the four-point correlator of the\ngraviton multiplet for all KK levels. A key insight of our approach is the use\nof generalized Mellin space, and a decomposition of the correlators into\ndistinct subsectors each one characterized by different on-shell constraints\namong the Mellin variables. The resulting Mellin amplitudes involve a small set\nof building blocks with manifest properties under a six-dimensional symmetry.","main_category":"hep-th","categories":"hep-th","published":"2025-04-28T13:12:40Z"}
{"aid":"http://arxiv.org/abs/2504.19781v1","title":"Non-reflexivity of the Banach space $ΛBV^{(p)}$","summary":"It was proven that the Waterman class is non-reflexive. In fact,\nPrus-Wi\\'sniowski and Ruckle, in \\cite{1}, generalized the well-known fact that\nstates the space of bounded variation functions is non-reflexive. Here, an\nimprovement of that result is provided.","main_category":"math.FA","categories":"math.FA,A.0","published":"2025-04-28T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.19783v1","title":"Determining a graph from its reconfiguration graph","summary":"Given a graph $G$ and a natural number $k$, the $k$-recolouring graph\n$\\mathcal{C}_k(G)$ is the graph whose vertices are the $k$-colourings of $G$\nand whose edges link pairs of colourings which differ at exactly one vertex of\n$G$. Recently, Hogan et al. proved that $G$ can be determined from\n$\\mathcal{C}_k(G)$ provided $k$ is large enough (quadratic in the number of\nvertices of $G$). We improve this bound by showing that $k=\\chi(G)+1$ colours\nsuffice, and provide examples of families of graphs for which $k=\\chi(G)$\ncolours do not suffice.\n  We then extend this result to $k$-Kempe-recolouring graphs, whose vertices\nare again the $k$-colourings of a graph $G$ and whose edges link pairs of\ncolourings which differ by swapping the two colours in a connected component\ninduced by selecting those two colours. We show that $k=\\chi(G)+2$ colours\nsuffice to determine $G$ in this case.\n  Finally, we investigate the case of independent set reconfiguration, proving\nthat in only a few trivial cases is one guaranteed to be able to determine a\ngraph $G$.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-28T13:28:02Z"}
{"aid":"http://arxiv.org/abs/2504.19800v1","title":"Long time asymptotics of a perturbed modified KdV equation","summary":"We derive full asymptotics of the modified KdV equation (mKdV) with a\nhigher-order perturbative term. We make use of the perturbative theory of\ninfinite-dimensional integrable systems developed by P. Deift and X. Zhou\n\\cite{DZ-2}, and some new and simpler proofs of certain $L^\\infty$ bounds and\n$L^p$ a priori estimates developed recently in \\cite{CLT}. We show that the\nperturbed equation exhibits the same long-time behavior as the completely\nintegrable mKdV.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T13:44:43Z"}
{"aid":"http://arxiv.org/abs/2504.19813v1","title":"OmicsQ: A User-Friendly Platform for Interactive Quantitative Omics Data\n  Analysis","summary":"Motivation: High-throughput omics technologies generate complex datasets with\nthousands of features that are quantified across multiple experimental\nconditions, but often suffer from incomplete measurements, missing values and\nindividually fluctuating variances. This requires sophisticated analytical\nmethods for accurate, deep and insightful biological interpretations, capable\nof dealing with a large variety of data properties and different amounts of\ncompleteness. Software to handle such data complexity is rare and mostly relies\non programming-based environments, limiting accessibility for researchers\nwithout computational expertise. Results: We present OmicsQ, an interactive,\nweb-based platform designed to streamline quantitative omics data analysis.\nOmicsQ integrates established statistical processing tools with an intuitive,\nbrowser-based visualization interface. It provides robust batch correction,\nautomated experimental design annotation, and missing-data handling without\nimputation, which ensures data integrity and avoids artifacts from a priori\nassumptions. OmicsQ seamlessly interacts with external applications for\nstatistical testing, clustering, analysis of protein complex behavior, and\npathway enrichment, offering a comprehensive and flexible workflow from data\nimport to biological interpretation that is broadly applicable tov data from\ndifferent domains. Availability and Implementation: OmicsQ is implemented in R\nand R Shiny and is available at\nhttps://computproteomics.bmb.sdu.dk/app_direct/OmicsQ. Source code and\ninstallation instructions can be found at\nhttps://github.com/computproteomics/OmicsQ","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-28T14:09:45Z"}
{"aid":"http://arxiv.org/abs/2504.19824v1","title":"Taming the Randomness: Towards Label-Preserving Cropping in Contrastive\n  Learning","summary":"Contrastive learning (CL) approaches have gained great recognition as a very\nsuccessful subset of self-supervised learning (SSL) methods. SSL enables\nlearning from unlabeled data, a crucial step in the advancement of deep\nlearning, particularly in computer vision (CV), given the plethora of unlabeled\nimage data. CL works by comparing different random augmentations (e.g.,\ndifferent crops) of the same image, thus achieving self-labeling. Nevertheless,\nrandomly augmenting images and especially random cropping can result in an\nimage that is semantically very distant from the original and therefore leads\nto false labeling, hence undermining the efficacy of the methods. In this\nresearch, two novel parameterized cropping methods are introduced that increase\nthe robustness of self-labeling and consequently increase the efficacy. The\nresults show that the use of these methods significantly improves the accuracy\nof the model by between 2.7\\% and 12.4\\% on the downstream task of classifying\nCIFAR-10, depending on the crop size compared to that of the non-parameterized\nrandom cropping method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T14:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.19837v1","title":"Finite temperature phase diagram of the extended Bose-Hubbard model in\n  the presence of disorder","summary":"We study the finite- and non-zero temperature phase diagram of the Extended\nBose-Hubbard Model for both pure and disordered systems. Such a system can be\nexperimentally realized by trapping ultracold Rydberg atoms in optical\nlattices. By regulating the Rydberg excitation level and the lattice spacing,\nthe system can be engineered to effectively have (i) only the nearest-neighbor\ninteraction and (ii) both nearest-neighbor and next-nearest-neighbor\ninteractions. For both of these situations, we construct the mean-field phase\ndiagrams. It is found that the presence of a non-zero temperature significantly\nchanges the phase diagram because now there is a competition between quantum\nand thermal fluctuations. We observe that conventional Mott insulator (MI) or\ncharge-density-wave (CDW) lobes vanish at higher temperatures. In a pure\nsystem, they melt into a normal fluid. In contrast, the only insulating phase\nthat survives at high temperatures in the presence of disorder is a Bose glass.\nIt is evident that the CDW lobes melt at a lower temperature and the Mott lobes\nmelt at higher temperatures. These transition temperatures depend on the\non-site and nearest-neighbor interaction strengths, respectively. It is also\nfound that, with the addition of disorder, the insulating lobes are destroyed\nat a relatively lower temperature. The mathematical framework that we present\nhere is capable of treating long-range interactions, disorder, and finite\ntemperature simultaneously, and versatile enough so that it can be extended to\nstudy different forms of disorder or longer-range interactions.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.stat-mech,quant-ph","published":"2025-04-28T14:38:51Z"}
{"aid":"http://arxiv.org/abs/2504.19869v1","title":"Anisotropic supercurrent suppression and revivals in a graphene-based\n  Josephson junction under in-plane magnetic fields","summary":"We report on a tunable Josephson junction formed by a bilayer graphene ribbon\nencapsulated in WSe$_2$ with superconducting niobium contacts. We characterize\nthe junction by measurements of the magnetic field induced interference\npattern, and the AC Josephson effect manifested as \"Shapiro steps\", examining\ncurrent dependent hysteresis and junction dynamics. The latter can be tuned by\ntemperature, gate voltage, and magnetic field. Finally, we examine the\nevolution of the supercurrent when subjected to in-plane magnetic fields.\nNotably, we observe a strong anisotropy in the supercurrent with respect to the\norientation of the in-plane magnetic field. When the field is parallel to the\ncurrent direction, the supercurrent is suppressed, and shows revivals with\nincreasing magnetic field, whereas it remains almost unaffected when the field\nis oriented in a perpendicular direction. We suggest that this anisotropy is\ncaused by the dependence of supercurrent interference on the junction geometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-28T15:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.19903v1","title":"Convergence Analysis of Asynchronous Federated Learning with Gradient\n  Compression for Non-Convex Optimization","summary":"Gradient compression is an effective technique for reducing communication\ncosts in federated learning (FL), and error feedback (EF) is usually adopted to\nremedy the compression errors. However, there remains a lack of systematic\nstudy on these techniques in asynchronous FL. In this paper, we fill this gap\nby analyzing the convergence behaviors of FL under different frameworks. We\nfirstly consider a basic asynchronous FL framework AsynFL, and provide an\nimproved convergence analysis that relies on fewer assumptions and yields a\nsuperior convergence rate than prior studies. Then, we consider a variant\nframework with gradient compression, AsynFLC. We show sufficient conditions for\nits convergence to the optimum, indicating the interaction between asynchronous\ndelay and compression rate. Our analysis also demonstrates that asynchronous\ndelay amplifies the variance caused by compression, thereby hindering\nconvergence, and such an impact is exacerbated by high data heterogeneity.\nFurthermore, we study the convergence of AsynFLC-EF, the framework that further\nintegrates EF. We prove that EF can effectively reduce the variance of gradient\nestimation despite asynchronous delay, which enables AsynFLC-EF to match the\nconvergence rate of AsynFL. We also show that the impact of asynchronous delay\non EF is limited to slowing down the higher-order convergence term.\nExperimental results substantiate our analytical findings very well.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-28T15:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.19904v1","title":"Interpretable additive model for analyzing high-dimensional functional\n  time series","summary":"High-dimensional functional time series offers a powerful framework for\nextending functional time series analysis to settings with multiple\nsimultaneous dimensions, capturing both temporal dynamics and cross-sectional\ndependencies. We propose a novel, interpretable additive model tailored for\nsuch data, designed to deliver both high predictive accuracy and clear\ninterpretability. The model features bivariate coefficient surfaces to\nrepresent relationships across panel dimensions, with sparsity introduced via\npenalized smoothing and group bridge regression. This enables simultaneous\nestimation of the surfaces and identification of significant inter-dimensional\neffects. Through Monte Carlo simulations and an empirical application to\nJapanese subnational age-specific mortality rates, we demonstrate the proposed\nmodel's superior forecasting performance and interpretability compared to\nexisting functional time series approaches.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-28T15:37:15Z"}
{"aid":"http://arxiv.org/abs/2504.19956v1","title":"Securing Agentic AI: A Comprehensive Threat Model and Mitigation\n  Framework for Generative AI Agents","summary":"As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-28T16:29:24Z"}
{"aid":"http://arxiv.org/abs/2504.19957v1","title":"Revisiting Directed Disjoint Paths on tournaments (and relatives)","summary":"In the Directed Disjoint Paths problem ($k$-DDP), we are given a digraph $k$\npairs of terminals, and the goal is to find $k$ pairwise vertex-disjoint paths\nconnecting each pair of terminals. Bang-Jensen and Thomassen [SIAM J. Discrete\nMath. 1992] claimed that $k$-DDP is NP-complete on tournaments, and this result\ntriggered a very active line of research about the complexity of the problem on\ntournaments and natural superclasses. We identify a flaw in their proof, which\nhas been acknowledged by the authors, and provide a new NP-completeness proof.\nFrom an algorithmic point of view, Fomin and Pilipczuk [J. Comb. Theory B 2019]\nprovided an FPT algorithm for the edge-disjoint version of the problem on\nsemicomplete digraphs, and showed that their technique cannot work for the\nvertex-disjoint version. We overcome this obstacle by showing that the version\nof $k$-DDP where we allow congestion $c$ on the vertices is FPT on semicomplete\ndigraphs provided that $c$ is greater than $k/2$. This is based on a quite\nelaborate irrelevant vertex argument inspired by the edge-disjoint version, and\nwe show that our choice of $c$ is best possible for this technique, with a\ncounterexample with no irrelevant vertices when $c \\leq k/2$. We also prove\nthat $k$-DDP on digraphs that can be partitioned into $h$ semicomplete digraphs\nis $W[1]$-hard parameterized by $k+h$, which shows that the XP algorithm\npresented by Chudnovsky, Scott, and Seymour [J. Comb. Theory B 2019] is\nessentially optimal.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T16:30:52Z"}
{"aid":"http://arxiv.org/abs/2504.19965v1","title":"Feelbert: A Feedback Linearization-based Embedded Real-Time Quadrupedal\n  Locomotion Framework","summary":"Quadruped robots have become quite popular for their ability to adapt their\nlocomotion to generic uneven terrains. For this reason, over time, several\nframeworks for quadrupedal locomotion have been proposed, but with little\nattention to ensuring a predictable timing behavior of the controller.\n  To address this issue, this work presents \\NAME, a modular control framework\nfor quadrupedal locomotion suitable for execution on an embedded system under\nhard real-time execution constraints. It leverages the feedback linearization\ncontrol technique to obtain a closed-form control law for the body, valid for\nall configurations of the robot. The control law was derived after defining an\nappropriate rigid body model that uses the accelerations of the feet as control\nvariables, instead of the estimated contact forces. This work also provides a\nnovel algorithm to compute footholds and gait temporal parameters using the\nconcept of imaginary wheels, and a heuristic algorithm to select the best gait\nschedule for the current velocity commands.\n  The proposed framework is developed entirely in C++, with no dependencies on\nthird-party libraries and no dynamic memory allocation, to ensure\npredictability and real-time performance. Its implementation allows \\NAME\\ to\nbe both compiled and executed on an embedded system for critical applications,\nas well as integrated into larger systems such as Robot Operating System 2 (ROS\n2). For this reason, \\NAME\\ has been tested in both scenarios, demonstrating\nsatisfactory results both in terms of reference tracking and temporal\npredictability, whether integrated into ROS 2 or compiled as a standalone\napplication on a Raspberry Pi 5.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-28T16:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.19991v1","title":"Mapping of Weed Management Methods in Orchards using Sentinel-2 and\n  PlanetScope Data","summary":"Effective weed management is crucial for improving agricultural productivity,\nas weeds compete with crops for vital resources like nutrients and water.\nAccurate maps of weed management methods are essential for policymakers to\nassess farmer practices, evaluate impacts on vegetation health, biodiversity,\nand climate, as well as ensure compliance with policies and subsidies. However,\nmonitoring weed management methods is challenging as commonly rely on on-ground\nfield surveys, which are often costly, time-consuming and subject to delays. In\norder to tackle this problem, we leverage Earth Observation (EO) data and\nMachine Learning (ML). Specifically, we developed an ML approach for mapping\nfour distinct weed management methods (Mowing, Tillage, Chemical-spraying, and\nNo practice) in orchards using satellite image time series (SITS) data from two\ndifferent sources: Sentinel-2 (S2) and PlanetScope (PS). The findings\ndemonstrate the potential of ML-driven remote sensing to enhance the efficiency\nand accuracy of weed management mapping in orchards.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-28T17:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.20012v1","title":"exoALMA XV: Interpreting the height of CO emission layer","summary":"The availability of exquisite data and the development of new analysis\ntechniques have enabled the study of emitting heights in proto-planetary disks.\nIn this paper we introduce a simple model linking the emitting height of CO to\nthe disk surface density and temperature structure. We then apply the model to\nmeasurements of the emitting height and disk temperature conducted as part of\nexoALMA, integrated with additional legacy measurements from the MAPS Large\nProgramme, to derive CO column densities and surface density profiles (assuming\na CO abundance) for a total of 14 disks. A unique feature of the method we\nintroduce to measure surface densities is that it can be applied to optically\nthick observations, rather than optically thin as conventionally done. While we\nuse our method on a sample of well studied disks where temperature structures\nhave been derived using two emission lines, we show that reasonably accurate\nestimates can be obtained also when only one molecular transition is available.\nWith our method we obtain independent constraints from $^{12}$CO and $^{13}$CO\nand we find they are in general good agreement using the standard\n$^{12}$C/$^{13}$C isotopic ratio. The masses derived from our method are\nsystematically lower compared with the values derived dynamically from the\nrotation curve if using an ISM CO abundance, implying that CO is depleted by a\nmedian factor $\\sim$20 with respect to the ISM value, in line with other works\nthat find that CO is depleted in proto-planetary disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.SR","published":"2025-04-28T17:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.20038v1","title":"Unified and consistent structure growth measurements from joint ACT, SPT\n  and \\textit{Planck} CMB lensing","summary":"We present the tightest cosmic microwave background (CMB) lensing constraints\nto date on the growth of structure by combining CMB lensing measurements from\nthe Atacama Cosmology Telescope (ACT), the South Pole Telescope (SPT) and\n\\textit{Planck}. Each of these surveys individually provides lensing\nmeasurements with similarly high statistical power, achieving signal-to-noise\nratios of approximately 40. The combined lensing bandpowers represent the most\nprecise CMB lensing power spectrum measurement to date with a signal-to-noise\nratio of 61 and an amplitude of $A_\\mathrm{lens}^\\mathrm{recon} = 1.025 \\pm\n0.017$ with respect to the theory prediction from the best-fit CMB\n\\textit{Planck}-ACT cosmology. The bandpowers from all three lensing datasets,\nanalyzed jointly, yield a $1.6\\%$ measurement of the parameter combination\n$S_8^\\mathrm{CMBL} \\equiv \\sigma_8\\,(\\Omega_m/0.3)^{0.25} =\n0.825^{+0.015}_{-0.013}$. Including Dark Energy Spectroscopic Instrument (DESI)\nBaryon Acoustic Oscillation (BAO) data improves the constraint on the amplitude\nof matter fluctuations to $\\sigma_8 = 0.829 \\pm 0.009$ (a $1.1\\%$\ndetermination). When combining with uncalibrated supernovae from\n\\texttt{Pantheon+}, we present a $4\\%$ sound-horizon-independent estimate of\n$H_0=66.4\\pm2.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}} $. The joint lensing constraints\non structure growth and present-day Hubble rate are fully consistent with a\n$\\Lambda$CDM model fit to the primary CMB data from \\textit{Planck} and ACT.\nWhile the precise upper limit is sensitive to the choice of data and underlying\nmodel assumptions, when varying the neutrino mass sum within the\n$\\Lambda\\mathrm{CDM}$ cosmological model, the combination of primary CMB, BAO\nand CMB lensing drives the probable upper limit for the mass sum towards lower\nvalues, comparable to the minimum mass prior required by neutrino oscillation\nexperiments.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-28T17:58:27Z"}
{"aid":"http://arxiv.org/abs/2504.20394v1","title":"The Problem of No Return Photon Ranging Measurements with Entangled\n  Photons","summary":"We introduce a fascinating problem of light detection and ranging measurement\nwithout necessitating the return of the photon directed towards the target or\nobject. We approach this challenging problem using quantum entanglement - an\nentangled pair of photons; one photon is sent toward the target or object,\nwhile the other is directed into a medium, which undergoes continuous\nmeasurements. We assume the light-matter interaction at the target such that\nthe quantum state collapse is probabilistically biased. We present thought\nexperiments and measurement schemes to conduct correlation measurements and\nexamine the methodology of these measurements to estimate the target's range,\nusing a maximally entangled Bell state ($|\\Psi^+\\rangle = \\frac{1}{\\sqrt{2}}\n(|H_1V_2\\rangle + |V_1H_2\\rangle)$) as an example. When the photon interacts\nwith the target, the Bell state undergoes biased decoherence or state collapse,\nleaving a signature in the spatial correlation G(x) quantity.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-29T03:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.20414v1","title":"Enhancing Leakage Attacks on Searchable Symmetric Encryption Using\n  LLM-Based Synthetic Data Generation","summary":"Searchable Symmetric Encryption (SSE) enables efficient search capabilities\nover encrypted data, allowing users to maintain privacy while utilizing cloud\nstorage. However, SSE schemes are vulnerable to leakage attacks that exploit\naccess patterns, search frequency, and volume information. Existing studies\nfrequently assume that adversaries possess a substantial fraction of the\nencrypted dataset to mount effective inference attacks, implying there is a\ndatabase leakage of such documents, thus, an assumption that may not hold in\nreal-world scenarios. In this work, we investigate the feasibility of enhancing\nleakage attacks under a more realistic threat model in which adversaries have\naccess to minimal leaked data. We propose a novel approach that leverages large\nlanguage models (LLMs), specifically GPT-4 variants, to generate synthetic\ndocuments that statistically and semantically resemble the real-world dataset\nof Enron emails. Using the email corpus as a case study, we evaluate the\neffectiveness of synthetic data generated via random sampling and hierarchical\nclustering methods on the performance of the SAP (Search Access Pattern)\nkeyword inference attack restricted to token volumes only. Our results\ndemonstrate that, while the choice of LLM has limited effect, increasing\ndataset size and employing clustering-based generation significantly improve\nattack accuracy, achieving comparable performance to attacks using larger\namounts of real data. We highlight the growing relevance of LLMs in adversarial\ncontexts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T04:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.20445v1","title":"Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking\n  Neural Networks","summary":"Spiking Neural Networks (SNNs) have emerged as a promising approach for\nenergy-efficient and biologically plausible computation. However, due to\nlimitations in existing training methods and inherent model constraints, SNNs\noften exhibit a performance gap when compared to Artificial Neural Networks\n(ANNs). Knowledge distillation (KD) has been explored as a technique to\ntransfer knowledge from ANN teacher models to SNN student models to mitigate\nthis gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence\nto align output distributions. However, conventional KL-based approaches fail\nto fully exploit the unique characteristics of SNNs, as they tend to\noveremphasize high-probability predictions while neglecting low-probability\nones, leading to suboptimal generalization. To address this, we propose\nHead-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for\nSNNs. HTA-KL introduces a cumulative probability-based mask to dynamically\ndistinguish between high- and low-probability regions. It assigns adaptive\nweights to ensure balanced knowledge transfer, enhancing the overall\nperformance. By integrating forward KL (FKL) and reverse KL (RKL) divergence,\nour method effectively align both head and tail regions of the distribution. We\nevaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our\nmethod outperforms existing methods on most datasets with fewer timesteps.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T05:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.20460v1","title":"Sequence Reconstruction under Channels with Multiple Bursts of\n  Insertions or Deletions","summary":"The sequence reconstruction problem involves a model where a sequence is\ntransmitted over several identical channels. This model investigates the\nminimum number of channels required for the unique reconstruction of the\ntransmitted sequence. Levenshtein established that this number exceeds the\nmaximum size of the intersection between the error balls of any two distinct\ntransmitted sequences by one. In this paper, we consider channels subject to\nmultiple bursts of insertions and multiple bursts of deletions, respectively,\nwhere each burst has an exact length of value b. We provide a complete solution\nfor the insertion case while partially addressing the deletion case.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T06:47:12Z"}
{"aid":"http://arxiv.org/abs/2504.20494v1","title":"An energy-stable minimal deformation rate scheme for mean curvature flow\n  and surface diffusion","summary":"We propose a new parametric finite element method, referred to as the BGN-MDR\nmethod, for simulating both mean curvature flow and surface diffusion for\nclosed hypersurfaces, as well as open hypersurfaces with moving contact lines\nin three dimensions. The method is also applicable to closed and open curves\nwith moving contact points in two dimensions. The proposed scheme inherits the\nenergy stability from the BGN scheme proposed by Barrett, Garcke, and\nN\\\"urnberg in 2008, and offers improved mesh quality similar to the minimal\ndeformation rate (MDR) method proposed by Hu and Li in 2022, especially for\nsmall time step sizes where the BGN scheme may become unstable and result in\ndeteriorated meshes.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-29T07:35:49Z"}
{"aid":"http://arxiv.org/abs/2504.20495v1","title":"A Family of Self-Dual Quasicrystals with Critical Phases","summary":"We propose a general framework for constructing self-dual one-dimensional\nquasiperiodic lattice models with arbitrary-range hoppings and multifractal\nbehaviors. Our framework generates a broad spectrum of quasicrystals, ranging\nfrom the off-diagonal Aubry-Andr\\'e-Harper models on one end, to those with\nlong-range power-law hoppings on another. Focusing on models with off-diagonal\nquasiperiodic hoppings with power-law decay, we exploit the fact that, when the\nself-dual condition is satisfied, the system must be in the critical state with\nmultifractal properties. This enables the engineering of models with competing\nextended, critical, and localized phases, with rich mobility edges in between.\nAs an outstanding example, we show that a limiting case of our family of\nself-dual quasicrystals can be implemented using Rydberg-atom arrays. Our work\noffers a systematic route toward self-duality and critical phases, and would\nfacilitate their experimental simulation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T07:37:42Z"}
{"aid":"http://arxiv.org/abs/2504.20509v1","title":"MambaMoE: Mixture-of-Spectral-Spatial-Experts State Space Model for\n  Hyperspectral Image Classification","summary":"The Mamba model has recently demonstrated strong potential in hyperspectral\nimage (HSI) classification, owing to its ability to perform context modeling\nwith linear computational complexity. However, existing Mamba-based methods\nusually neglect the spectral and spatial directional characteristics related to\nheterogeneous objects in hyperspectral scenes, leading to limited\nclassification performance. To address these issues, we propose MambaMoE, a\nnovel spectral-spatial mixture-of-experts framework, representing the first\nMoE-based approach in the HSI classification community. Specifically, we design\na Mixture of Mamba Expert Block (MoMEB) that leverages sparse expert activation\nto enable adaptive spectral-spatial modeling. Furthermore, we introduce an\nuncertainty-guided corrective learning (UGCL) strategy to encourage the model's\nattention toward complex regions prone to prediction ambiguity. Extensive\nexperiments on multiple public HSI benchmarks demonstrate that MambaMoE\nachieves state-of-the-art performance in both accuracy and efficiency compared\nto existing advanced approaches, especially for Mamba-based methods. Code will\nbe released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:50:36Z"}
{"aid":"http://arxiv.org/abs/2504.20511v1","title":"Challenges of Requirements Communication and Digital Assets Verification\n  in Infrastructure Projects","summary":"Background: Poor communication of requirements between clients and suppliers\ncontributes to project overruns,in both software and infrastructure projects.\nExisting literature offers limited insights into the communication challenges\nat this interface. Aim: Our research aim to explore the processes and\nassociated challenges with requirements activities that include client-supplier\ninteraction and communication. Method: we study requirements validation,\ncommunication, and digital asset verification processes through two case\nstudies in the road and railway sectors, involving interviews with ten experts\nacross three companies. Results: We identify 13 challenges, along with their\ncauses and consequences, and suggest solution areas from existing literature.\nConclusion: Interestingly, the challenges in infrastructure projects mirror\nthose found in software engineering, highlighting a need for further research\nto validate potential solutions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T07:52:08Z"}
{"aid":"http://arxiv.org/abs/2504.20537v1","title":"Quantitative X-ray Schlieren Nanotomography for Hyperspectral Phase and\n  Absorption Imaging","summary":"Hyperspectral X-rays imaging holds promise for three-dimensional (3D)\nchemical analysis but remains limited in simultaneously capturing phase and\nabsorption information due to complex setups and data burdens. We introduce\nquantitative X-ray schlieren nanotomography (XSN), a simple, fast, and\nhigh-resolution X-ray phase imaging technique that overcomes these limitations.\nXSN employs a partially coherent illumination and a pupil-plane cutoff filter\nto encode directional phase contrast, enabling single-shot acquisition. A\nquasi-Newton iterative algorithm reconstructs quantitative phase and absorption\nimages from intensity data, even under strong scattering conditions. Scanning\nacross X-ray energies further allows four-dimensional imaging (3D spatial &\nspectral). We validate the method's accuracy and resolution on reference\nsamples and apply it to lithium battery cathodes, visualizing nanoscale\nmicrocracks and mapping chemical compositions. XSN provides a robust framework\nfor hyperspectral phase nanotomography with broad applicability across\nmaterials science, biology, and energy research.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T08:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.20594v1","title":"Mordell--Lang and disparate Selmer ranks of odd twists of some\n  superelliptic curves over global function fields","summary":"Fix a prime number $\\ell \\geq 5$. Let $K = \\mathbb{F}_q(t)$ be a global\nfunction field of characteristic $p$ coprime to $2,3$, and $q \\equiv 1 \\text{\nmod } \\ell$. Let $C:y^\\ell = F(x)$ be a non-isotrivial superelliptic curve over\n$K$ such that $F$ is a degree $3$ polynomial over $\\mathbb{F}_q(t)$. Denote by\n$C_f: fy^\\ell = F(x)$ the twist of $C$ by a polynomial $f$ over $\\mathbb{F}_q$.\nAssuming some conditions on $C$, we show that the expected number of\n$K$-rational points of $C_f$ is bounded, and at least $99\\%$ of such curves\n$C_f$ have at most $(3p)^{5\\ell} \\cdot \\ell!$ many $K$-rational points, as $f$\nranges over the set of polynomials of sufficiently large degree over\n$\\mathbb{F}_q$. To achieve this, we compute the distribution of dimensions of\n$1-\\zeta_\\ell$ Selmer groups of Jacobians of such superelliptic curves. This is\ndone by generalizing the technique of constructing a governing Markov operator,\nas developed from previous studies by Klagsbrun--Mazur--Rubin, Yu, and the\nauthor. As a byproduct, we prove that the density of odd twist families of such\nsuperelliptic curves with even Selmer ranks cannot be equal to $50\\%$, a\ndisparity phenomena observed in previous works by Klagsbrun--Mazur--Rubin, Yu,\nand Morgan for quadratic twist families of principally polarized abelian\nvarieties.","main_category":"math.NT","categories":"math.NT","published":"2025-04-29T09:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.20607v1","title":"EfficientHuman: Efficient Training and Reconstruction of Moving Human\n  using Articulated 2D Gaussian","summary":"3D Gaussian Splatting (3DGS) has been recognized as a pioneering technique in\nscene reconstruction and novel view synthesis. Recent work on reconstructing\nthe 3D human body using 3DGS attempts to leverage prior information on human\npose to enhance rendering quality and improve training speed. However, it\nstruggles to effectively fit dynamic surface planes due to multi-view\ninconsistency and redundant Gaussians. This inconsistency arises because\nGaussian ellipsoids cannot accurately represent the surfaces of dynamic\nobjects, which hinders the rapid reconstruction of the dynamic human body.\nMeanwhile, the prevalence of redundant Gaussians means that the training time\nof these works is still not ideal for quickly fitting a dynamic human body. To\naddress these, we propose EfficientHuman, a model that quickly accomplishes the\ndynamic reconstruction of the human body using Articulated 2D Gaussian while\nensuring high rendering quality. The key innovation involves encoding Gaussian\nsplats as Articulated 2D Gaussian surfels in canonical space and then\ntransforming them to pose space via Linear Blend Skinning (LBS) to achieve\nefficient pose transformations. Unlike 3D Gaussians, Articulated 2D Gaussian\nsurfels can quickly conform to the dynamic human body while ensuring\nview-consistent geometries. Additionally, we introduce a pose calibration\nmodule and an LBS optimization module to achieve precise fitting of dynamic\nhuman poses, enhancing the model's performance. Extensive experiments on the\nZJU-MoCap dataset demonstrate that EfficientHuman achieves rapid 3D dynamic\nhuman reconstruction in less than a minute on average, which is 20 seconds\nfaster than the current state-of-the-art method, while also reducing the number\nof redundant Gaussians.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T10:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.20613v1","title":"Abelian and Tauberian Results for the Fractional Hankel Transform of\n  Generalized Functions","summary":"This paper aims to explore the quasiasymptotic behavior of distributions\nthrough the fractional Hankel transform. We present Tauberian result that\nconnects the asymptotic behavior of generalized functions in the Zemanian space\nwith the asymptotics of their fractional Hankel transform. Additionally, we\nestablish both the initial and final value theorems for the fractional Hankel\ntransform of distributions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-29T10:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.20621v1","title":"Horizon Thermodynamics on Nice Slices of the Causal Diamond","summary":"There is a deep link between gravity and thermodynamics; in a precise way\ngravity can be derived from entanglement entropy in conformal field theories.\nHowever, this depends crucially on properties of horizons, and asymptotic\nsymmetries of phase space. To explore how this relation behaves under dynamical\nprocesses, we consider covariant gravitational phase space enhanced with bulk\nconformal symmetry. As is well known, the Noether-Wald entropy has an explicit\nform in terms of the Abbott-Deser-Tekin conserved surface charges of gauge\ntheories. We find a new vector contribution to the Abbott-Deser-Tekin charges\nthat arises for conformal symmetries. In applying this to the causal diamond,\nwe derive a general relation for surface gravity, based on the conformal\ninvariance of horizons, that allows us to find slices where the zeroth law\nholds, as well as the degree to which a first law arises on the phase space.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-29T10:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.20634v1","title":"On Stochastic Rounding with Few Random Bits","summary":"Large-scale numerical computations make increasing use of low-precision (LP)\nfloating point formats and mixed precision arithmetic, which can be enhanced by\nthe technique of stochastic rounding (SR), that is, rounding an intermediate\nhigh-precision value up or down randomly as a function of the value's distance\nto the two rounding candidates. Stochastic rounding requires, in addition to\nthe high-precision input value, a source of random bits. As the provision of\nhigh-quality random bits is an additional computational cost, it is of interest\nto require as few bits as possible while maintaining the desirable properties\nof SR in a given computation, or computational domain. This paper examines a\nnumber of possible implementations of few-bit stochastic rounding (FBSR), and\nshows how several natural implementations can introduce sometimes significant\nbias into the rounding process, which are not present in the case of\ninfinite-bit, infinite-precision examinations of these implementations. The\npaper explores the impact of these biases in machine learning examples, and\nhence opens another class of configuration parameters of which practitioners\nshould be aware when developing or adopting low-precision floating point. Code\nis available at\nhttp://github.com/graphcore-research/arith25-stochastic-rounding.","main_category":"math.NA","categories":"math.NA,cs.AI,cs.LG,cs.MS,cs.NA","published":"2025-04-29T11:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.20641v1","title":"Dressed fields for Quantum Chromodynamics","summary":"String-localized QFT allows to explain Standard Model interactions in an\nautonomous way, committed to quantum principles rather than a \"gauge\nprinciple\", thus avoiding an indefinite state space and compensating ghosts.\nThe resulting perturbative scattering matrix is known (at tree-level) to be\ninsensitive to the non-locality of the auxiliary \"string-localized fields\" used\nin the construction. For the examples of Yang-Mills and QCD, we prove that it\nis actually equivalent to the perturbative S-matrix of gauge theory, restricted\nto physical particle states. The role of classical gauge invariance is revealed\nalong the way. The main tool are \"dressed fields\", that are intermediate\nbetween free fields and interacting fields, and for which we give explicit\nformulas at all orders. The renormalization of loops, as well as\nnon-perturbative issues are not adressed, but we hint at the possibility,\nenabled by our approach, that qualitative traces of confinement may be visible\nalready at the level of the dressed fields.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-29T11:11:54Z"}
{"aid":"http://arxiv.org/abs/2504.20662v1","title":"On the Optimal Source Key Size of Secure Gradient Coding","summary":"With gradient coding, a user node can efficiently aggregate gradients from\nserver nodes processing local datasets, achieving low communication costs and\nmaintaining resilience against straggling servers. This paper considers a\nsecure gradient coding problem, where a user aims to compute the sum of the\ngradients from $K$ datasets with the assistance of $N$ distributed servers. The\nuser should recover the sum of gradients by receiving transmissions from any\n$N_r$ servers, and each dataset is assigned to $N - N_r + m$ servers. The\nsecurity constraint guarantees that even if the user receives transmissions\nfrom all servers, it cannot obtain any additional information about the\ndatasets beyond the sum of gradients.\n  It has been shown in the literature that this security constraint does not\nincrease the optimal communication cost of the gradient coding problem,\nprovided enough source keys are shared among the servers. However, the minimum\nrequired source key size that ensures security while maintaining this optimal\ncommunication cost has only been studied for the special case $m = 1$. In this\npaper, we focus on the more general case $m \\geq 1$ and aim to determine the\nminimum required source key size for this purpose.\n  We propose a new information-theoretic converse bound on the source key size,\nas well as a new achievable scheme with carefully designed data assignments.\nOur scheme outperforms the existing optimal scheme based on the widely used\ncyclic data assignment and coincides with the converse bound under certain\nsystem parameters.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T11:37:31Z"}
{"aid":"http://arxiv.org/abs/2504.20665v1","title":"Energy Recovery LINACs -- an Overview","summary":"The seminar on energy recovery linacs (ERLs) is giving an overview of the\nfield: How does an ERL work? What have been important milestones in ERL\nhistory? What are the reasons to use an ERL instead of a conventional\naccelerator? As examples of the landscape of machines, ranging from ancient\nERLs up to future projects, this chapter will give results of the runs from\nCBETA (USA) and S-DALINAC (Germany). The two facilities bERLin-Pro/SEALab\n(Germany) and MESA (Germany) will belong to the next ERLs to be in operation\nand will be introduced briefly. The way to future ERLs will also be addressed.","main_category":"physics.acc-ph","categories":"physics.acc-ph,physics.app-ph","published":"2025-04-29T11:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.20668v1","title":"A Generative-AI-Driven Claim Retrieval System Capable of Detecting and\n  Retrieving Claims from Social Media Platforms in Multiple Languages","summary":"Online disinformation poses a global challenge, placing significant demands\non fact-checkers who must verify claims efficiently to prevent the spread of\nfalse information. A major issue in this process is the redundant verification\nof already fact-checked claims, which increases workload and delays responses\nto newly emerging claims. This research introduces an approach that retrieves\npreviously fact-checked claims, evaluates their relevance to a given input, and\nprovides supplementary information to support fact-checkers. Our method employs\nlarge language models (LLMs) to filter irrelevant fact-checks and generate\nconcise summaries and explanations, enabling fact-checkers to faster assess\nwhether a claim has been verified before. In addition, we evaluate our approach\nthrough both automatic and human assessments, where humans interact with the\ndeveloped tool to review its effectiveness. Our results demonstrate that LLMs\nare able to filter out many irrelevant fact-checks and, therefore, reduce\neffort and streamline the fact-checking process.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T11:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.20689v1","title":"DICOM Compatible, 3D Multimodality Image Encryption using Hyperchaotic\n  Signal","summary":"Medical image encryption plays an important role in protecting sensitive\nhealth information from cyberattacks and unauthorized access. In this paper, we\nintroduce a secure and robust encryption scheme that is multi-modality\ncompatible and works with MRI, CT, X-Ray and Ultrasound images for different\nanatomical region of interest. The method utilizes hyperchaotic signals and\nmulti-level diffusion methods. The encryption starts by taking DICOM image as\ninput, then padding to increase the image area. Chaotic signals are produced by\na logistic map and are used to carry out pixel random permutation. Then,\nmulti-level diffusion is carried out by 4-bit, 8-bit, radial and adjacent\ndiffusion to provide high randomness and immunity against statistical attacks.\nIn addition, we propose a captcha-based authentication scheme to further\nimprove security. An algorithm generates alphanumeric captcha-based image which\nis encrypted with the same chaotic and diffusion methods as the medical image.\nBoth encrypted images(DICOM image and captcha image) are then superimposed to\ncreate a final encrypted output, essentially integrating dual-layer security.\nUpon decryption, the superimposed image is again decomposed back to original\nmedical and captcha images, and inverse operations are performed to obtain the\noriginal unencrypted data. Experimental results show that the proposed method\nprovides strong protection with no loss in image integrity, thereby reducing\nunauthorized data breaches to a significant level. The dual-encryption approach\nnot only protects the confidentiality of the medical images but also enhances\nauthentication by incorporating captcha.","main_category":"cs.CR","categories":"cs.CR,nlin.CD","published":"2025-04-29T12:11:23Z"}
{"aid":"http://arxiv.org/abs/2504.20694v1","title":"The VMC survey -- LIII. Data release #7. Complete survey data and data\n  from additional programmes","summary":"The near-infrared YJKs Visual and Infrared Survey Telescope for Astronomy\n(VISTA) survey of the Magellanic Clouds (VMC) is complete and there are also\ndata from additional programmes enhancing its quality over the original\nfootprint. This work presents the final data release of the VMC survey, which\nincludes additional observations and provides an overview of the scientific\nresults. The overall data quality has been revised and reprocessed standard\ndata products, that already appeared in previous data releases, are made\navailable together with new data products. These include individual stellar\nproper motions, reddening towards red clump stars and source classifications.\nSeveral data products, such as the parameters of some variable stars and of\nbackground galaxies, from the VMC publications are associated to a data release\nfor the first time. The data are processed using the VISTA Data Flow System and\nadditional products, e.g. catalogues with point-spread function photometry or\ntables with stellar proper motions, are obtained with software developed by the\nsurvey team. This release supersedes all previous data releases of the VMC\nsurvey for the combined (deepstacked) data products, whilst providing\nadditional (complementary) images and catalogues of single observations per\nfilter. Overall, it includes about 64 million detections, split nearly evenly\nbetween sources with stellar or galaxy profiles. The VMC survey provides a\nhomogeneous data set resulting from deep and multi-epoch YJKs-band imaging\nobservations of the Large and Small Clouds, the Bridge and two fields in the\nStream. The VMC data represent a valuable counterpart for sources detected at\nother wavelengths for both stars and background galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-29T12:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.20720v1","title":"Learning a General Model: Folding Clothing with Topological Dynamics","summary":"The high degrees of freedom and complex structure of garments present\nsignificant challenges for clothing manipulation. In this paper, we propose a\ngeneral topological dynamics model to fold complex clothing. By utilizing the\nvisible folding structure as the topological skeleton, we design a novel\ntopological graph to represent the clothing state. This topological graph is\nlow-dimensional and applied for complex clothing in various folding states. It\nindicates the constraints of clothing and enables predictions regarding\nclothing movement. To extract graphs from self-occlusion, we apply semantic\nsegmentation to analyze the occlusion relationships and decompose the clothing\nstructure. The decomposed structure is then combined with keypoint detection to\ngenerate the topological graph. To analyze the behavior of the topological\ngraph, we employ an improved Graph Neural Network (GNN) to learn the general\ndynamics. The GNN model can predict the deformation of clothing and is employed\nto calculate the deformation Jacobi matrix for control. Experiments using\njackets validate the algorithm's effectiveness to recognize and fold complex\nclothing with self-occlusion.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-29T13:00:32Z"}
{"aid":"http://arxiv.org/abs/2504.20722v1","title":"Cosmology from LOFAR Two-metre Sky Survey Data Release 2:\n  Cross-correlations with luminous red galaxies from eBOSS","summary":"We cross-correlated galaxies from the LOw-Frequency ARray (LOFAR) Two-metre\nSky Survey (LoTSS) second data release (DR2) radio source with the extended\nBaryon Oscillation Spectroscopic Survey (eBOSS) luminous red galaxy (LRG)\nsample to extract the baryon acoustic oscillation (BAO) signal and constrain\nthe linear clustering bias of radio sources in LoTSS DR2.\n  In the LoTSS DR2 catalogue, employing a flux density limit of $1.5$ mJy at\nthe central LoTSS frequency of 144 MHz and a signal-to-noise ratio (S/N) of\n$7.5$, additionally considering eBOSS LRGs with redshifts between 0.6 and 1, we\nmeasured both the angular LoTSS-eBOSS cross-power spectrum and the angular\neBOSS auto-power spectrum. These measurements were performed across various\neBOSS redshift tomographic bins with a width of $\\Delta z=0.06$. By\nmarginalising over the broadband shape of the angular power spectra, we\nsearched for a BAO signal in cross-correlation with radio galaxies, and\ndetermine the linear clustering bias of LoTSS radio sources for a constant-bias\nand an evolving-bias model. Using the cross-correlation, we measured the\nisotropic BAO dilation parameter as $\\alpha=1.01\\pm 0.11$ at $z_{\\rm\neff}=0.63$. By combining four redshift slices at $z_{\\rm eff}=0.63, 0.69,\n0.75$, and $0.81$, we determined a more constrained value of $\\alpha =\n0.968^{+0.060}_{-0.095}$. For the entire redshift range of $z_{\\rm eff}=0.715$,\nwe measured $b_C = 2.64 \\pm 0.20$ for the constant-bias model, $b(z)=b_C$, and\nthen $b_D = 1.80 \\pm 0.13$ for the evolving-bias model, $b(z) = b_D / D(z)$,\nwith $D(z)$ denoting the growth rate of linear structures. Additionally, we\nmeasured the clustering bias for individual redshift bins.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-29T13:02:28Z"}
{"aid":"http://arxiv.org/abs/2504.20734v1","title":"UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with\n  Diverse Modalities and Granularities","summary":"Retrieval-Augmented Generation (RAG) has shown substantial promise in\nimproving factual accuracy by grounding model responses with external knowledge\nrelevant to queries. However, most existing RAG approaches are limited to a\ntext-only corpus, and while recent efforts have extended RAG to other\nmodalities such as images and videos, they typically operate over a single\nmodality-specific corpus. In contrast, real-world queries vary widely in the\ntype of knowledge they require, which a single type of knowledge source cannot\naddress. To address this, we introduce UniversalRAG, a novel RAG framework\ndesigned to retrieve and integrate knowledge from heterogeneous sources with\ndiverse modalities and granularities. Specifically, motivated by the\nobservation that forcing all modalities into a unified representation space\nderived from a single combined corpus causes a modality gap, where the\nretrieval tends to favor items from the same modality as the query, we propose\na modality-aware routing mechanism that dynamically identifies the most\nappropriate modality-specific corpus and performs targeted retrieval within it.\nAlso, beyond modality, we organize each modality into multiple granularity\nlevels, enabling fine-tuned retrieval tailored to the complexity and scope of\nthe query. We validate UniversalRAG on 8 benchmarks spanning multiple\nmodalities, showing its superiority over modality-specific and unified\nbaselines.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CV,cs.IR,cs.LG","published":"2025-04-29T13:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.20743v1","title":"Nonsymmorphic Topological Phases of Non-Hermitian Systems","summary":"Non-Hermiticity appears ubiquitously in various open classical and quantum\nsystems and enriches classification of topological phases. However, the role of\nnonsymmorphic symmetry, crystalline symmetry accompanying fractional lattice\ntranslations, has remained largely unexplored. Here, we systematically classify\nnon-Hermitian topological crystalline phases protected by nonsymmorphic\nsymmetry and reveal unique phases that have no counterparts in either Hermitian\ntopological crystalline phases or non-Hermitian topological phases protected\nsolely by internal symmetry. Specifically, we elucidate the $\\mathbb{Z}_2$ and\n$\\mathbb{Z}_4$ non-Hermitian topological phases and their associated anomalous\nboundary states characterized by distinctive complex-valued energy dispersions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,math-ph,math.MP,quant-ph","published":"2025-04-29T13:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.20747v1","title":"Performance Evaluation of Efficient Hybrid Compression Methods For\n  Devanagiri-Encoded Hindi Text Using Lossless Algorithms","summary":"This research paper provides a comprehensive performance analysis of five\nstandard lossless compression algorithms-LZMA, Zstd, Brotli, Bzip2, and\nLZ4HC-alongside sixty hybrid combinations on UTF-8 encoded Hindi text datasets,\nwritten in the Devanagari script, across varying sizes-small, medium, and\nlarge. The evaluation covers compression ratio, compression speed,\ndecompression speed, and a derived weighted normalized efficiency score. Hybrid\nalgorithms-especially those combining Zstd with LZ4HC or Brotli-demonstrate\nsuperior performance across all individual parameters. Independent Zstd\nachieves the highest efficiency score for the medium-sized dataset,\nillustrating how a well-balanced algorithm can excel in overall efficiency\ndespite not leading in any single metric. However, in terms of compression\nratio, speed, and decompression speed, hybrid methods consistently outperform\nstandalone approaches. Notably, the hybrid combination Zstd + LZ4HC achieves\nthe highest efficiency, with scores of 0.6764 for small files and 0.8597 for\nlarge files. Independent algorithms such as Zstd and Bzip2 perform well but are\nconsistently surpassed by strategic hybrid pairings. The analysis underscores\nthe significance of combining fast and high-ratio compression techniques,\nparticularly for language-specific data. However, not all hybrids yielded\nsignificant improvements, with some introducing computational overhead. This\ncomparative analysis highlights the potential of hybrid compression in\napplications such as cloud storage, mobile messaging, and NLP-based Hindi text\nprocessing.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T13:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.20751v1","title":"Geometric potential for a Bose-Einstein condensate on a curved surface","summary":"We compute the ground state of a Bose-Einstein condensate confined on a\ncurved surface and unravel the effects of curvatures. Starting with a general\nformulation for any smooth surface, we apply it to a prolate ellipsoid, which\nis inspired by recent bubble trap experiments. Using a perturbative approach to\nthe Gross-Pitaevskii equation and a general Ansatz, followed by a dimensional\nreduction, we derive an effective two-dimensional equation that includes a\ncurvature-dependent geometric potential. We compute the ground state using\nThomas-Fermi approximation and, for an isotropic confinement, we find that the\nhighest accumulation of atoms happens on the regions with the greatest\ndifference between the principal curvatures. For a prolate ellipsoid, this\naccumulation happens on the equator, which is contrary to previous findings\nthat describe accumulation on the poles of a bubble trap. Finally, we explain\nthe reasons for this difference: the higher accumulation of atoms on the poles\nhappens due to anisotropies in the confinement, while the higher accumulation\non the equator happens exclusively due to the geometric properties of the\nsurface.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-29T13:32:10Z"}
{"aid":"http://arxiv.org/abs/2504.20757v1","title":"Refined Predictions for Starobinsky Inflation and Post-inflationary\n  Constraints in Light of ACT","summary":"Recent measurements from the Atacama Cosmology Telescope (ACT), combined with\nPlanck and DESI data, suggest a higher value for the spectral index $n_s$. This\nplaces Starobinsky inflation at the edge of the $2\\sigma$ constraints for a\nnumber of e-folds $N_\\star$ around $60$ when using the usual analytical\napproximations. We present refined predictions for Starobinsky inflation that\ngo beyond the commonly used analytical approximations. By evaluating the model\nwith these improved expressions, we show that for $N_\\star \\gtrsim 60$ it\nremains consistent with current observational constraints at the $2\\sigma$\nlevel. Additionally, we examine the implications of the ACT results for\npost-inflationary reheating parameters. Specifically, we find a lower bound on\nthe effective equation of state parameter during reheating of approximately\n$\\omega \\gtrsim 0.462$; this excludes purely perturbative reheating, which\nleads to $\\omega \\simeq 0$. We also show that the reheating temperature is\nconstrained to be $T_{\\text{rh}} \\lesssim 2 \\times 10^{12}~\\text{GeV}$,\nassuming $\\omega \\leq 1$. Furthermore, we find that the predictions for the\nspectral index and tensor-to-scalar ratio can lie within $1\\sigma$ of the\nrecent ACT constraints if the reheating temperature satisfies $4~\\text{MeV}\n\\lesssim T_{\\text{rh}} \\lesssim 10~\\text{GeV}$ for $0.8 \\lesssim \\omega \\leq\n1$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-29T13:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.20758v1","title":"Influence network reconstruction from discrete time-series of count data\n  modelled by multidimensional Hawkes processes","summary":"Identifying key influencers from time series data without a known prior\nnetwork structure is a challenging problem in various applications, from crime\nanalysis to social media. While much work has focused on event-based time\nseries (timestamp) data, fewer methods address count data, where event counts\nare recorded in fixed intervals. We develop network inference methods for both\nbatched and sequential count data. Here the strong network connection\nrepresents the key influences among the nodes. We introduce an ensemble-based\nalgorithm, rooted in the expectation-maximization (EM) framework, and\ndemonstrate its utility to identify node dynamics and connections through a\ndiscrete-time Cox or Hawkes process. For the linear multidimensional Hawkes\nmodel, we employ a minimization-majorization (MM) approach, allowing for\nparallelized inference of networks. For sequential inference, we use a\nsecond-order approximation of the Bayesian inference problem. Under certain\nassumptions, a rank-1 update for the covariance matrix reduces computational\ncosts. We validate our methods on synthetic data and real-world datasets,\nincluding email communications within European academic communities. Our\napproach effectively reconstructs underlying networks, accounting for both\nexcitation and diffusion influences. This work advances network reconstruction\nfrom count data in real-world scenarios.","main_category":"math.DS","categories":"math.DS","published":"2025-04-29T13:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.20775v1","title":"Upper critical field and pairing symmetry of Ising superconductors","summary":"Motivated by the fact that the measured critical field $H_c$ in various\ntransition metal dichalcogenide (TMD) superconductors is poorly understood, we\nreexamine its scaling behavior with temperature and spin-orbit coupling (SOC).\nBy computing the spin-susceptibility in a multipocket system, we find that\nsegments of the Fermi Surface (FS) at which the SOC has nodal points can have a\ncontribution orders of magnitude larger than the remaining FS, hence setting\nthe $H_c$, assuming the presence of a conventional singlet superconducting\norder parameter. Nodal lines of an Ising SOC in the Brillouin zone are imposed\nby symmetry, so they cause such nodal points whenever they intersect an FS\npocket, which is indeed the case in monolayer NbSe$_2$ and TaS$_2$, but not in\ngated MoS$_2$ and WS$_2$. Our analysis reinterprets existing measurements,\nconcluding that a dominant singlet-order parameter on pockets with SOC nodes is\nconsistent with the $H_c(T)$ data for all monolayer Ising superconductors, in\ncontrast to previous contradictory pairing assumptions. Finally, we show that\nthe theory is also consistent with data on homobilayer TMDs.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-29T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.20776v1","title":"ECOSoundSet: a finely annotated dataset for the automated acoustic\n  identification of Orthoptera and Cicadidae in North, Central and temperate\n  Western Europe","summary":"Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-29T13:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.20782v1","title":"Integrating Human Feedback into a Reinforcement Learning-Based Framework\n  for Adaptive User Interfaces","summary":"Adaptive User Interfaces (AUI) play a crucial role in modern software\napplications by dynamically adjusting interface elements to accommodate users'\ndiverse and evolving needs. However, existing adaptation strategies often lack\nreal-time responsiveness. Reinforcement Learning (RL) has emerged as a\npromising approach for addressing complex, sequential adaptation challenges,\nenabling adaptive systems to learn optimal policies based on previous\nadaptation experiences. Although RL has been applied to AUIs,integrating RL\nagents effectively within user interactions remains a challenge.\n  In this paper, we enhance a RL-based Adaptive User Interface adaption\nframework by incorporating personalized human feedback directly into the\nleaning process. Unlike prior approaches that rely on a single pre-trained RL\nmodel, our approach trains a unique RL agent for each user, allowing\nindividuals to actively shape their personal RL agent's policy, potentially\nleading to more personalized and responsive UI adaptations. To evaluate this\napproach, we conducted an empirical study to assess the impact of integrating\nhuman feedback into the RL-based Adaptive User Interface adaption framework and\nits effect on User Experience (UX). The study involved 33 participants\ninteracting with AUIs incorporating human feedback and non-adaptive user\ninterfaces in two domains: an e-learning platform and a trip-planning\napplication. The results suggest that incorporating human feedback into\nRL-driven adaptations significantly enhances UX, offering promising directions\nfor advancing adaptive capabilities and user-centered design in AUIs.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-29T14:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.20788v1","title":"Critical clusters in liquid crystals: Fractal geometry and conformal\n  invariance","summary":"We study the two-dimensional domain morphology of twisted nematic liquid\ncrystals during their phase-ordering kinetics [R. A. L. Almeida, Phys. Rev.\nLett. 131 (2023) 268101], which is a physical candidate to self-generate\ncritical clusters in the percolation universality class. Here we present\nexperimental evidence that large clusters and their hulls are indeed both\nfractals with dimensions of the corresponding figures in critical percolation\nmodels. The asymptotic decay of a crossing probability, from a region in the\nvicinity of the origin to the boundary of disks, is described by the\nLawler-Schramm-Werner theorem provided that a microscopic length in the\noriginal formulation is replaced by the coarsening length of the liquid\ncrystal. Furthermore, the behavior for the winding angle of large loops is, at\ncertain scales, compatible with that of Schramm-Loewner evolution curves with\ndiffusivity $\\kappa = 6$. These results show an experimental realization of\ncritical clusters in phase ordering.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-29T14:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.20798v1","title":"The role of dark polariton states for electronic strong coupling in\n  molecules","summary":"Polaritonic chemistry investigates the possible modification of chemical and\nphotochemical reactions by means of strong light-matter coupling in optical\ncavities, as demonstrated in numerous experiments over the last few years.\nThese experiments are typically interpreted in terms of the Jaynes-Cummings or\nTavis-Cummings models under the assumption that the molecular ensemble is only\nexcited by a single photon. In such a model, two polariton states compete with\nan overwhelming number of dark states, inhibiting polaritonic reactions\nentropically. We analyze the higher excitation manifolds of the Tavis-Cummings\nmodel along with a three-level system that resembles photochemical reactions.\nWe demonstrate that allowing for more than a single excitation makes the\nreaction of the involved polaritons entropically more favorable.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-04-29T14:13:07Z"}
{"aid":"http://arxiv.org/abs/2504.20841v1","title":"Standard constraints on the shadow radius of black holes in\n  $d$-dimensional space-time: The case of regular Einstein-Gauss-Bonnet\n  solutions","summary":"In this work, we propose a $d$-dimensional constraint formula for the black\nhole shadow radius, providing a standardized framework for using observational\nconfidence intervals to constrain the corresponding characteristic parameters\nin $d$-dimensional black hole solutions. This approach can correct the\nmisapplication of shadow radius constraints in some previous studies.\nSubsequently, we selected two regular Einstein-Gauss-Bonnet (EGB) black hole\nsolutions as a representative example to test the $d$-dimensional shadow\nconstraint formula. Our analysis reveals that the characteristic parameters\nwithin these $d$-dimensional black hole solutions maintain physically\nmeaningful bounded domains under shadow radius constraints. We further propose\nthat this $d$-dimensional shadow constraint formula is universal and can be\napplied to constrain the characteristic parameters in other high-dimensional\nspherically symmetric black hole solutions.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T15:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.20862v1","title":"Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private\n  Data","summary":"The remarkable success of Deep Learning approaches is often based and\ndemonstrated on large public datasets. However, when applying such approaches\nto internal, private datasets, one frequently faces challenges arising from\nstructural differences in the datasets, domain shift, and the lack of labels.\nIn this work, we introduce Tabular Data Adapters (TDA), a novel method for\ngenerating soft labels for unlabeled tabular data in outlier detection tasks.\nBy identifying statistically similar public datasets and transforming private\ndata (based on a shared autoencoder) into a format compatible with\nstate-of-the-art public models, our approach enables the generation of weak\nlabels. It thereby can help to mitigate the cold start problem of labeling by\nbasing on existing outlier detection models for public datasets. In experiments\non 50 tabular datasets across different domains, we demonstrate that our method\nis able to provide more accurate annotations than baseline approaches while\nreducing computational time. Our approach offers a scalable, efficient, and\ncost-effective solution, to bridge the gap between public research models and\nreal-world industrial applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T15:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.20873v1","title":"BV actions for extended geometry","summary":"I review the construction of actions for extended geometry from the grading\nof an underlying tensor hierarchy algebra, which provides the full set of\nBatalin-Vilkovisky fields. The dynamics is neatly encoded in a complex. This\ntalk, presented at the Corfu Summer Institute 2024, is mainly based on joint\nwork with J. Palmkvist, in particular ref. [1].","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-29T15:44:18Z"}
{"aid":"http://arxiv.org/abs/2504.20875v1","title":"Six types of separable integer partitions","summary":"Recently, Andrews introduced separable integer partition classes and studied\nsome well-known theorems. In this atricle, we will investigate six types of\npartitions from the view of the point of separable integer partition classes.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T15:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.20883v1","title":"Guessing Efficiently for Constrained Subspace Approximation","summary":"In this paper we study constrained subspace approximation problem. Given a\nset of $n$ points $\\{a_1,\\ldots,a_n\\}$ in $\\mathbb{R}^d$, the goal of the {\\em\nsubspace approximation} problem is to find a $k$ dimensional subspace that best\napproximates the input points. More precisely, for a given $p\\geq 1$, we aim to\nminimize the $p$th power of the $\\ell_p$ norm of the error vector\n$(\\|a_1-\\bm{P}a_1\\|,\\ldots,\\|a_n-\\bm{P}a_n\\|)$, where $\\bm{P}$ denotes the\nprojection matrix onto the subspace and the norms are Euclidean. In\n\\emph{constrained} subspace approximation (CSA), we additionally have\nconstraints on the projection matrix $\\bm{P}$. In its most general form, we\nrequire $\\bm{P}$ to belong to a given subset $\\mathcal{S}$ that is described\nexplicitly or implicitly.\n  We introduce a general framework for constrained subspace approximation. Our\napproach, that we term coreset-guess-solve, yields either\n$(1+\\varepsilon)$-multiplicative or $\\varepsilon$-additive approximations for a\nvariety of constraints. We show that it provides new algorithms for\npartition-constrained subspace approximation with applications to {\\it fair}\nsubspace approximation, $k$-means clustering, and projected non-negative matrix\nfactorization, among others. Specifically, while we reconstruct the best known\nbounds for $k$-means clustering in Euclidean spaces, we improve the known\nresults for the remainder of the problems.","main_category":"cs.DS","categories":"cs.DS,cs.LG","published":"2025-04-29T15:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.20884v1","title":"Gravitational Form Factors and the QCD Dilaton at Large Momentum\n  Transfer","summary":"We investigate the hard scatterings of hadronic matrix elements corresponding\nto hadronic gravitational form factors (GFFs) of the pion and proton using QCD\nfactorization, applying conformal field theory (CFT) tools. These GFFs are key\nto understanding quark and gluon angular momentum via their connection to DVCS\nmoments. The core object is the non-Abelian \\( TJJ \\) 3-point function, which\nshows an anomaly-induced dilaton exchange in the \\( t \\)-channel. We analyze\nquark, ghost, and gauge-fixing effects through a CFT-based decomposition and\npropose a parameterization useful for future DVCS studies at the Electron-Ion\nCollider. The dilaton interaction is interpolated by a conformal anomaly form\nfactor, defined in the nonconformal case, which is constrained by a (dilaton)\nsum rule.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-29T15:58:32Z"}
{"aid":"http://arxiv.org/abs/2504.20900v1","title":"Evaluating Generative Models for Tabular Data: Novel Metrics and\n  Benchmarking","summary":"Generative models have revolutionized multiple domains, yet their application\nto tabular data remains underexplored. Evaluating generative models for tabular\ndata presents unique challenges due to structural complexity, large-scale\nvariability, and mixed data types, making it difficult to intuitively capture\nintricate patterns. Existing evaluation metrics offer only partial insights,\nlacking a comprehensive measure of generative performance. To address this\nlimitation, we propose three novel evaluation metrics: FAED, FPCAD, and RFIS.\nOur extensive experimental analysis, conducted on three standard network\nintrusion detection datasets, compares these metrics with established\nevaluation methods such as Fidelity, Utility, TSTR, and TRTS. Our results\ndemonstrate that FAED effectively captures generative modeling issues\noverlooked by existing metrics. While FPCAD exhibits promising performance,\nfurther refinements are necessary to enhance its reliability. Our proposed\nframework provides a robust and practical approach for assessing generative\nmodels in tabular data applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T16:16:51Z"}
{"aid":"http://arxiv.org/abs/2504.20910v1","title":"When Testing AI Tests Us: Safeguarding Mental Health on the Digital\n  Frontlines","summary":"Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-29T16:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.20926v1","title":"Bipartite Randomized Response Mechanism for Local Differential Privacy","summary":"With the increasing importance of data privacy, Local Differential Privacy\n(LDP) has recently become a strong measure of privacy for protecting each\nuser's privacy from data analysts without relying on a trusted third party. In\nmany cases, both data providers and data analysts hope to maximize the utility\nof released data. In this paper, we study the fundamental trade-off formulated\nas a constrained optimization problem: maximizing data utility subject to the\nconstraint of LDP budgets. In particular, the Generalized Randomized Response\n(GRR) treats all discrete data equally except for the true data. For this, we\nintroduce an adaptive LDP mechanism called Bipartite Randomized Response (BRR),\nwhich solves the above privacy-utility maximization problem from the global\nstandpoint. We prove that for any utility function and any privacy level,\nsolving the maximization problem is equivalent to confirming how many\nhigh-utility data to be treated equally as the true data on release\nprobability, the outcome of which gives the optimal randomized response.\nFurther, solving this linear program can be computationally cheap in theory.\nSeveral examples of utility functions defined by distance metrics and\napplications in decision trees and deep learning are presented. The results of\nvarious experiments show that our BRR significantly outperforms the\nstate-of-the-art LDP mechanisms of both continuous and distributed types.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T16:39:50Z"}
{"aid":"http://arxiv.org/abs/2504.20927v1","title":"Exploiting inter-agent coupling information for efficient reinforcement\n  learning of cooperative LQR","summary":"Developing scalable and efficient reinforcement learning algorithms for\ncooperative multi-agent control has received significant attention over the\npast years. Existing literature has proposed inexact decompositions of local\nQ-functions based on empirical information structures between the agents. In\nthis paper, we exploit inter-agent coupling information and propose a\nsystematic approach to exactly decompose the local Q-function of each agent. We\ndevelop an approximate least square policy iteration algorithm based on the\nproposed decomposition and identify two architectures to learn the local\nQ-function for each agent. We establish that the worst-case sample complexity\nof the decomposition is equal to the centralized case and derive necessary and\nsufficient graphical conditions on the inter-agent couplings to achieve better\nsample efficiency. We demonstrate the improved sample efficiency and\ncomputational efficiency on numerical examples.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.MA,cs.SY,math.OC","published":"2025-04-29T16:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.20937v1","title":"Mìmir: A real-time interactive visualization library for CUDA programs","summary":"Real-time visualization of computational simulations running over graphics\nprocessing units (GPU) is a valuable feature in modern science and\ntechnological research, as it allows researchers to visually assess the quality\nand correctness of their computational models during the simulation. Due to the\nhigh throughput involved in GPU-based simulations, classical visualization\napproaches such as ones based on copying to RAM or storage are not feasible\nanymore, as they imply large memory transfers between GPU and CPU at each\nmoment, reducing both computational performance and interactivity. Implementing\nreal-time visualizers for GPU simulation codes is a challenging task as it\ninvolves dealing with i) low-level integration of graphics APIs (e.g, OpenGL\nand Vulkan) into the general-purpose GPU code, ii) a careful and efficient\nhandling of memory spaces and iii) finding a balance between rendering and\ncomputing as both need the GPU resources. In this work we present M\\`imir, a\nCUDA/Vulkan interoperability C++ library that allows users to add real-time\n2D/3D visualization to CUDA codes with low programming effort. With M\\`imir,\nresearchers can leverage state-of-the-art CUDA/Vulkan interoperability features\nwithout needing to invest time in learning the complex low-level technical\naspects involved. Internally, M\\`imir streamlines the interoperability mapping\nbetween CUDA device memory containing simulation data and Vulkan graphics\nresources, so that changes on the data are instantly reflected in the\nvisualization. This abstraction scheme allows generating visualizations with\nminimal alteration over the original source code, needing only to replace the\nGPU memory allocation lines of the data to be visualized by the API calls\nprovided by M\\`imir among other optional changes.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-29T17:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.20983v1","title":"LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains","summary":"We study a variant of LTLf synthesis that synthesizes adaptive strategies for\nachieving a multi-tier goal, consisting of multiple increasingly challenging\nLTLf objectives in nondeterministic planning domains. Adaptive strategies are\nstrategies that at any point of their execution (i) enforce the satisfaction of\nas many objectives as possible in the multi-tier goal, and (ii) exploit\npossible cooperation from the environment to satisfy as many as possible of the\nremaining ones. This happens dynamically: if the environment cooperates (ii)\nand an objective becomes enforceable (i), then our strategies will enforce it.\nWe provide a game-theoretic technique to compute adaptive strategies that is\nsound and complete. Notably, our technique is polynomial, in fact quadratic, in\nthe number of objectives. In other words, it handles multi-tier goals with only\na minor overhead compared to standard LTLf synthesis.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T17:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.20993v1","title":"GDP-GFCF Dynamics Across Global Economies: A Comparative Study of Panel\n  Regressions and Random Forest","summary":"This study examines the relationship between GDP growth and Gross Fixed\nCapital Formation (GFCF) across developed economies (G7, EU-15, OECD) and\nemerging markets (BRICS). We integrate Random Forest machine learning\n(non-linear regression) with traditional econometric models (linear regression)\nto better capture non-linear interactions in investment analysis. Our findings\nreveal that while GDP growth positively influences corporate investment, its\nimpact varies significantly by region. Developed economies show stronger\nGDP-GFCF linkages due to stable financial systems, while emerging markets\ndemonstrate weaker connections due to economic heterogeneity and structural\nconstraints. Random Forest models indicate that GDP growth's importance is\nlower than suggested by traditional econometrics, with lagged GFCF emerging as\nthe dominant predictor-confirming investment follows path-dependent patterns\nrather than short-term GDP fluctuations. Regional variations in investment\ndrivers are substantial: taxation significantly influences developed economies\nbut minimally affects BRICS, while unemployment strongly drives investment in\nBRICS but less so elsewhere. We introduce a parallelized p-value importance\nalgorithm for Random Forest that enhances computational efficiency while\nmaintaining statistical rigor through sequential testing methods (SPRT and\nSAPT). The research demonstrates that hybrid methodologies combining machine\nlearning with econometric techniques provide more nuanced understanding of\ninvestment dynamics, supporting region-specific policy design and improving\nforecasting accuracy.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-29T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.21266v1","title":"CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine\n  Text-Co-Guided Latent Diffusion","summary":"In action recognition tasks, feature diversity is essential for enhancing\nmodel generalization and performance. Existing methods typically promote\nfeature diversity by expanding the training data in the sample space, which\noften leads to inefficiencies and semantic inconsistencies. To overcome these\nproblems, we propose a novel Coarse-fine text co-guidance Diffusion model\n(CoCoDiff). CoCoDiff generates diverse yet semantically consistent features in\nthe latent space by leveraging diffusion and multi-granularity textual\nguidance. Specifically, our approach feeds spatio-temporal features extracted\nfrom skeleton sequences into a latent diffusion model to generate diverse\naction representations. Meanwhile, we introduce a coarse-fine text co-guided\nstrategy that leverages textual information from large language models (LLMs)\nto ensure semantic consistency between the generated features and the original\ninputs. It is noted that CoCoDiff operates as a plug-and-play auxiliary module\nduring training, incurring no additional inference cost. Extensive experiments\ndemonstrate that CoCoDiff achieves SOTA performance on skeleton-based action\nrecognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and\nKinetics-Skeleton.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T02:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.21288v1","title":"Algebraic Approach for Orthomax Rotations","summary":"In exploratory factor analysis, rotation techniques are employed to derive\ninterpretable factor loading matrices. Factor rotations deal with\nequality-constrained optimization problems aimed at determining a loading\nmatrix based on measure of simplicity, such as ``perfect simple structure'' and\n``Thurstone simple structure.'' Numerous criteria have been proposed, since the\nconcept of simple structure is fundamentally ambiguous and involves multiple\ndistinct aspects. However, most rotation criteria may fail to consistently\nyield a simple structure that is optimal for analytical purposes, primarily due\nto two challenges. First, existing optimization techniques, including the\ngradient projection descent method, exhibit strong dependence on initial values\nand frequently become trapped in suboptimal local optima. Second, multifaceted\nnature of simple structure complicates the ability of any single criterion to\nensure interpretability across all aspects. In certain cases, even when a\nglobal optimum is achieved, other rotations may exhibit simpler structures in\nspecific aspects. To address these issues, obtaining all equality-constrained\nstationary points -- including both global and local optima -- is advantageous.\nFortunately, many rotation criteria are expressed as algebraic functions, and\nthe constraints in the optimization problems in factor rotations are formulated\nas algebraic equations. Therefore, we can employ computational algebra\ntechniques that utilize operations within polynomial rings to derive exact all\nequality-constrained stationary points. Unlike existing optimization methods,\nthe computational algebraic approach can determine global optima and all\nstationary points, independent of initial values. We conduct Monte Carlo\nsimulations to examine the properties of the orthomax rotation criteria, which\ngeneralizes various orthogonal rotation methods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T03:44:28Z"}
{"aid":"http://arxiv.org/abs/2504.21295v1","title":"Quantization of Anisotropic Topological Yang Mills Theory","summary":"We continue our investigation into anisotropic topological field theories\nwhich arise from a tropical limit of conventional isotropic topological field\ntheories. We analyze both the TBF theory and the tropical analogue of 2D\ntopological Yang-Mills theory (TrYM) through a direct path integral calculation\nwhich probes a deformed analytic torsion and also through canonical\nquantization. The explicit construction of the Hilbert space of TrYM theory\ndemonstrates that the TrYM theory provides an example of a solvable field\ntheory where anisotropy properties and topological invariance can\nsimultaneously hold. We show that the partition function has an asymptotic\nlimit, which verifies that the dimension of the moduli space of tropicalized\nflat connection on a Riemann surface of genus $g>1$ is precisely given by\n$(g-1) \\operatorname{rank}(\\mathfrak{g})$. We conjecture that the large $N$\nexpansion of the associated matrix model of 2D TrYM is associated to the wedge\nregion of nonequilibrium string theory.","main_category":"hep-th","categories":"hep-th","published":"2025-04-30T04:01:54Z"}
{"aid":"http://arxiv.org/abs/2504.21297v1","title":"Participatory AI, Public Sector AI, Differential Privacy, Conversational\n  Interfaces, Explainable AI, Citizen Engagement in AI","summary":"This paper introduces a conversational interface system that enables\nparticipatory design of differentially private AI systems in public sector\napplications. Addressing the challenge of balancing mathematical privacy\nguarantees with democratic accountability, we propose three key contributions:\n(1) an adaptive $\\epsilon$-selection protocol leveraging TOPSIS multi-criteria\ndecision analysis to align citizen preferences with differential privacy (DP)\nparameters, (2) an explainable noise-injection framework featuring real-time\nMean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and\n(3) an integrated legal-compliance mechanism that dynamically modulates privacy\nbudgets based on evolving regulatory constraints. Our results advance\nparticipatory AI practices by demonstrating how conversational interfaces can\nenhance public engagement in algorithmic privacy mechanisms, ensuring that\nprivacy-preserving AI in public sector governance remains both mathematically\nrobust and democratically accountable.","main_category":"cs.IT","categories":"cs.IT,cs.AI,cs.CY,cs.ET,math.IT","published":"2025-04-30T04:10:50Z"}
{"aid":"http://arxiv.org/abs/2504.21300v1","title":"A decomposition lemma in convex integration via classical algebraic\n  geometry","summary":"In this paper, we introduce a decomposition lemma that allows error terms to\nbe expressed using fewer primitive matrices than $\\frac{n(n+1)}{2}$ within the\nconvex integration scheme of constructing flexible $C^{1,\\alpha}$ solutions to\na system of nonlinear PDEs in dimension $n\\geq 2$, which can be viewed as a\nkind of truncation of the codimension one local isometric embedding equation in\nNash-Kuiper Theorem. This leads to flexible solutions with higher H\\\"older\nregularity, and consequently, improved very weak solutions to certain induced\nequations for any $n$, including Monge-Amp\\`ere systems and $2$-Hessian\nsystems. The H\\\"older exponent of the solutions can be taken as any $\\alpha\n<(n^2+1)^{-1}$ for $n=2,4,8,16$, and any\n$\\alpha<(n^2+n-2\\rho(\\frac{n}{2})-1)^{-1}$ for other $n$, thereby improving the\npreviously known bound $\\alpha<(n^2+n+1)^{-1}$ for $n\\geq 3$. Here, $\\rho(n)$\nis the Radon-Hurwitz number, which exhibits an $8$-fold periodicity on $n$ that\nis related to Bott periodicity.\n  Our arguments involve novel applications of several results from algebraic\ngeometry and topology, including Adams' theorem on maximum linearly independent\nvector fields on spheres, the intersection of projective varieties, and\nprojective duality. We also use an elliptic method ingeniously that avoids loss\nof differentiability.","main_category":"math.AP","categories":"math.AP,math.AG,math.DG","published":"2025-04-30T04:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.21321v1","title":"Universal Encryption of Individual Sequences Under Maximal Leakage","summary":"We consider the Shannon cipher system in the framework of individual\nsequences and finite-state encrypters under the metric of maximal leakage of\ninformation. A lower bound and an asymptotically matching upper bound on the\nleakage are derived, which lead to the conclusion that asymptotically minimum\nleakage can be attained by Lempel-Ziv compression followed by one-time pad\nencryption of the compressed bit-stream.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-30T05:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.21344v1","title":"Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early\n  Lung Cancer Detection","summary":"Objective: A number of machine learning models have utilized semantic\nfeatures, deep features, or both to assess lung nodule malignancy. However,\ntheir reliance on manual annotation during inference, limited interpretability,\nand sensitivity to imaging variations hinder their application in real-world\nclinical settings. Thus, this research aims to integrate semantic features\nderived from radiologists' assessments of nodules, allowing the model to learn\nclinically relevant, robust, and explainable features for predicting lung\ncancer. Methods: We obtained 938 low-dose CT scans from the National Lung\nScreening Trial with 1,246 nodules and semantic features. The Lung Image\nDatabase Consortium dataset contains 1,018 CT scans, with 2,625 lesions\nannotated for nodule characteristics. Three external datasets were obtained\nfrom UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We\nfinetuned a pretrained Contrastive Language-Image Pretraining model with a\nparameter-efficient fine-tuning approach to align imaging and semantic features\nand predict the one-year lung cancer diagnosis. Results: We evaluated the\nperformance of the one-year diagnosis of lung cancer with AUROC and AUPRC and\ncompared it to three state-of-the-art models. Our model demonstrated an AUROC\nof 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on\nexternal datasets. Using CLIP, we also obtained predictions on semantic\nfeatures, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and\npleural attachment (0.84), that can be used to explain model predictions.\nConclusion: Our approach accurately classifies lung nodules as benign or\nmalignant, providing explainable outputs, aiding clinicians in comprehending\nthe underlying meaning of model predictions. This approach also prevents the\nmodel from learning shortcuts and generalizes across clinical settings.","main_category":"cs.CV","categories":"cs.CV,cs.AI,q-bio.QM","published":"2025-04-30T06:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.21350v1","title":"Ergodicity for the fractional Magneto-Hydrodynamic equations driven by a\n  degenerate pure jump noise","summary":"This paper is concerned with the ergodicity for stochastic 2D fractional\nmagneto-hydrodynamic equations on the two-dimensional torus driven by a highly\ndegenerate pure jump L\\'{e}vy noise. We focus on the challenging case where the\nnoise acts in as few as four directions, establishing new results for such high\ndegeneracy. We first employ Malliavin calculus and anticipative stochastic\ncalculus to demonstrate the equi-continuity of the semigroup (or so-called the\ne-property), and then verify the weak irreducibility of the solution process.\nTherefore, the uniqueness of invariant measure is proven.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-30T06:18:08Z"}
{"aid":"http://arxiv.org/abs/2504.21358v1","title":"A comparative study of deep learning and ensemble learning to extend the\n  horizon of traffic forecasting","summary":"Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T06:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.21359v1","title":"Ultra-discretization of Yang-Baxter maps, probability distributions and\n  independence preserving property","summary":"We study the relationship between Yang-Baxter maps and the independence\npreserving (IP) property, motivated by their role in integrable systems, from\nthe perspective of ultra-discretization. Yang-Baxter maps satisfy the\nset-theoretic Yang-Baxter equation, while the IP property ensures independence\nof transformed random variables. The relationship between these two seemingly\nunrelated properties has recently started to be studied in arXiv:0911.2895 .\nUltra-discretization is a concept primarily used in the context of integrable\nsystems and is an area of active research, serving as a method for exploring\nthe connections between different integrable systems. However, there are few\nstudies on how the stationary distribution for integrable systems changes\nthrough ultra-discretization. In this paper, we introduce the concept of\nultra-discretization for probability distributions, and prove that the\nproperties of being a Yang-Baxter map and having the IP property are both\npreserved under ultra-discretization. Applying this to quadrirational\nYang-Baxter maps, we confirm that their ultra-discrete versions retain these\nproperties, yielding new examples of piecewise linear maps having the IP\nproperty. We also explore implications of our results for stationary\ndistributions of integrable systems and pose several open questions.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP,math.PR,math.QA","published":"2025-04-30T06:37:21Z"}
{"aid":"http://arxiv.org/abs/2504.21382v1","title":"Robust and Scalable Renaming with Subquadratic Bits","summary":"In the renaming problem, a set of $n$ nodes, each with a unique identity from\na large namespace $[N]$, needs to obtain new unique identities in a smaller\nnamespace $[M]$. A renaming algorithm is strong if $M=n$. Renaming is a\nclassical problem in distributed computing with a range of applications, and\nthere exist many time-efficient solutions for fault-tolerant renaming in\nsynchronous message-passing systems. However, all previous algorithms send\n$\\Omega(n^2)$ messages, and many of them also send large messages each\ncontaining $\\Omega(n)$ bits. Moreover, most algorithms' performance do not\nscale with the actual number of failures. These limitations restrict their\npractical performance.\n  We develop two new strong renaming algorithms, one tolerates up to $n-1$\ncrash failures, and the other tolerates up to $(1/3-\\epsilon_0)n$ Byzantine\nfailures for an arbitrarily small constant $\\epsilon_0>0$. The crash-resilient\nalgorithm is always correct and always finishes within $O(\\log{n})$ rounds. It\nsends $\\tilde{O}((f+1)\\cdot n)$ messages with high probability, where $f$ is\nthe actual number of crashes. This implies that it sends subquadratic messages\nas long as $f=o(n/\\log{n})$. The Byzantine-resilient algorithm trades time for\ncommunication: it finishes within $\\tilde{O}(\\max\\{f,1\\})$ rounds and sends\nonly $\\tilde{O}(f+n)$ messages, with high probability. Here, $f$ is the actual\nnumber of Byzantine nodes. To obtain such strong guarantees, the\nByzantine-resilient algorithm leverages shared randomness and message\nauthentication. Both algorithms only send messages of size $O(\\log{N})$ bits.\nTherefore, our crash-resilient algorithm incurs $o(n^2)$ communication cost as\nlong as $f=o(n/(\\log{n}\\log{N}))$; and our Byzantine resilient algorithm incurs\nalmost-linear communication cost. By deriving a lower bound, we conclude that\nour algorithms achieve near-optimal communication cost in many cases.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-30T07:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.21418v1","title":"Thermodynamic formulation of the spin magnetic octupole moment in bulk\n  crystals","summary":"The discovery of unconventional antiferromagnets, such as altermagnets, has\ndrawn significant attention to higher-rank magnetic multipoles. Despite the\nadvances in research, a fundamental understanding of multipole moments,\nparticularly octupole moments, remains limited due to the challenges of\naccurately treating the position operator in bulk crystals, which is integral\nto their definitions. In this paper, we overcome this problem by using a\nthermodynamic relation and derive a formula of the spin magnetic octupole\nmoment (SMOM) that can be used in bulk crystals. The resulting formula is gauge\ninvariant and satisfies St\\v{r}eda formulas, which relate the SMOM to the spin\nmagnetoelectric dipole-quadrupole susceptibilities. Furthermore, we apply this\nformula to several models and examine the fundamental properties of the SMOM.\nOne particularly important property is that the SMOM of $d$-wave altermagnets\nis dominated by nonrelativistic SMOMs regardless of spin-orbit coupling.\nMoreover, these nonrelativistic SMOMs exhibit a N\\'{e}el order dependence that\nis predicted by the Landau theory of $d$-wave altermagnetism [Phys. Rev. Lett.\n$\\textbf{132}$, 176702 (2024)].","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T08:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.21431v1","title":"Quantum theory of magnetic octupole in periodic crystals and\n  characterization of time-reversal-symmetry breaking antiferromagnetism","summary":"Magnetic multipoles have been recognized as order parameters characterizing\nmagnetic structure in solids, with magnetic dipole serving as canonical\nexamples in ferromagnets. Recently, magnetic octupoles have been proposed as\nthe order parameters of time-reversal-symmetry breaking centrosymmetric\nantiferromagnets exhibiting nonrelativistic spin splitting, which is referred\nto as ``altermagnet''. However, a gauge-invariant formulation of magnetic\noctupoles in crystalline solids remains elusive. Here, we present a\ngauge-invariant expression of spin magnetic octupoles in periodic crystals\nbased on quantum mechanics and thermodynamics. Our expression reveals a\ncontribution from an anisotropic magnetic dipole, which has the same symmetry\nas conventional spin and orbital magnetic dipoles but carries no net\nmagnetization. We demonstrate that such an anisotropic magnetic dipole acts as\nan order parameter for antiferromagnets that exhibit the anomalous Hall effect.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T08:40:38Z"}
{"aid":"http://arxiv.org/abs/2504.21434v1","title":"Integration of a Synthetic Molecular Motor Into a Rotary DNA\n  Nanostructure: A Framework for Single-Molecule Actuation","summary":"Synthetic molecular motors are an appealing means to control motion at the\nnanoscale, but understanding their behaviour as single-molecule actuators and\nintegrating them into larger, functional systems remain technical challenges.\nTranslating molecular actuation into coordinated device-level behaviour\nrequires precise placement and orientation of the motors: DNA origami provides\na powerful platform for positioning molecules with nanometre precision. Here,\nwe demonstrate integration of a light-driven, rotary molecular motor into a\nDNA-based nanoscale actuator through site-specific, four-point conjugation. The\nmotor is labelled with four distinct oligonucleotides, two on each side, using\nDNA-templated chemistry. This modular approach enables stable, oriented\nincorporation of the motor into a DNA assembly through DNA hybridization. Upon\nphotoactivation with UV light, the motor transduces photon energy into rotary\nmotion. By coupling the motor to a fluorescently labelled DNA rotor arm we\namplify its movement and enable real-time observation using total internal\nreflection fluorescence microscopy. A subset of assembled devices exhibits\nlight-induced conformational transitions and directional motion consistent with\nthe expected photochemical mechanism. These results establish a programmable\nframework for integration of light-driven molecular motors into synthetic\nnanomachines and tools for the study of their behaviour.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-30T08:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.21437v1","title":"Identifying Critical Dependencies in Large-Scale Continuous Software\n  Engineering","summary":"Continuous Software Engineering (CSE) is widely adopted in the industry,\nintegrating practices such as Continuous Integration and Continuous Deployment\n(CI/CD). Beyond technical aspects, CSE also encompasses business activities\nlike continuous planning, budgeting, and operational processes. Coordinating\nthese activities in large-scale product development involves multiple\nstakeholders, increasing complexity. This study aims to address this complexity\nby identifying and analyzing critical dependencies in large-scale CSE. Based on\n17 semi-structured interviews conducted at two Nordic fintech companies, our\npreliminary findings indicate that dependencies between software teams and\nsupport functions, as well as between software teams and external entities, are\nthe primary sources of delays and bottlenecks. As a next step, we plan to\nfurther refine our understanding of critical dependencies in large-scale CSE\nand explore coordination mechanisms that can better support software\ndevelopment teams in managing these challenges.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-30T08:52:32Z"}
{"aid":"http://arxiv.org/abs/2504.21460v1","title":"Scalar quasinormal modes, Lyapunov exponents and radii of null geodesics\n  of rotating regular black holes","summary":"The quasinormal modes of massless scalar field in rotating Bardeen and\nHayward regular black holes are studied. The fundamental quasinormal modes and\n$n=1$ first overtone quasinormal modes are calculated with two numerical\nmethods, i.e. WKB method and matrix method. Impacts of model parameters on the\nquasinormal modes are also discussed. It is found that the quasinormal modes in\nrotating Hayward black hole have just percent-level increase compared with that\nin the Kerr black hole case due to the deviation parameter $g$, while there is\nten-percent-level increase for the quasinormal modes in the rotating Bardeen\nblack hole due to $g_*$. It is also found that the monotonicity of fundamental\nand $n=1$ quasinormal modes in the rotating Bardeen black hole is different.\nThe corotating and counterrotating Lyapunov exponents of the equatorial null\ncircular geodesics in the two rotating black holes are also calculated. Then,\nthe connection between the imaginary parts and real parts of the eikonal\nquasinormal modes, particularly the first overtone ones, and the properties of\nthe null geodesics in the two rotating regular black holes are explicitly\nverified.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T09:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.21461v1","title":"Discrete time crystals detected by time-translation twist","summary":"We introduce a boundary condition twisted by time translation as a novel\nprobe to characterize dynamical phases in periodically driven (Floquet) quantum\nsystems. Inspired by twisted boundary conditions in equilibrium systems, this\napproach modifies the temporal evolution of the system upon completing a\nspatial loop, enabling the identification of distinct Floquet phases, including\ndiscrete time crystals (DTCs). By studying the spectral form factor (SFF) and\nits response to the twist, we uncover signatures of time-crystalline order,\nwhich exhibits periodic dependence on the twist parameter analogous to the\nLittle-Parks effect in superconductors. We apply this framework to the kicked\nIsing model, demonstrating that our twist can distinguish time-crystalline\nphases.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-30T09:29:36Z"}
{"aid":"http://arxiv.org/abs/2504.21467v1","title":"Multiview Point Cloud Registration via Optimization in an Autoencoder\n  Latent Space","summary":"Point cloud rigid registration is a fundamental problem in 3D computer\nvision. In the multiview case, we aim to find a set of 6D poses to align a set\nof objects. Methods based on pairwise registration rely on a subsequent\nsynchronization algorithm, which makes them poorly scalable with the number of\nviews. Generative approaches overcome this limitation, but are based on\nGaussian Mixture Models and use an Expectation-Maximization algorithm. Hence,\nthey are not well suited to handle large transformations. Moreover, most\nexisting methods cannot handle high levels of degradations. In this paper, we\nintroduce POLAR (POint cloud LAtent Registration), a multiview registration\nmethod able to efficiently deal with a large number of views, while being\nrobust to a high level of degradations and large initial angles. To achieve\nthis, we transpose the registration problem into the latent space of a\npretrained autoencoder, design a loss taking degradations into account, and\ndevelop an efficient multistart optimization strategy. Our proposed method\nsignificantly outperforms state-of-the-art approaches on synthetic and real\ndata. POLAR is available at github.com/pypolar/polar or as a standalone package\nwhich can be installed with pip install polaregistration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:42:38Z"}
{"aid":"http://arxiv.org/abs/2504.21477v1","title":"A Comprehensive Survey of Electrical Stimulation Haptic Feedback in\n  Human-Computer Interaction","summary":"Haptic perception and feedback play a pivotal role in interactive\nexperiences, forming an essential component of human-computer interaction\n(HCI). In recent years, the field of haptic interaction has witnessed\nsignificant advancements, particularly in the area of electrical haptic\nfeedback, driving innovation across various domains. To gain a comprehensive\nunderstanding of the current state of research and the latest developments in\nelectrical haptic interaction, this study systematically reviews the literature\nin this area. Our investigation covers key aspects including haptic devices,\nhaptic perception mechanisms, the comparison and integration of electrical\nhaptic feedback with other feedback modalities, and their diverse applications.\nSpecifically, we conduct a systematic analysis of 110 research papers to\nexplore the forefront of electrical haptic feedback, providing insights into\nits latest trends, challenges, and future directions.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-30T09:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.21489v1","title":"TRIED: Truly Innovative and Effective Detection Benchmark, developed by\n  WITNESS","summary":"The rise of generative AI and deceptive synthetic media threatens the global\ninformation ecosystem, especially across the Global Majority. This report from\nWITNESS highlights the limitations of current AI detection tools, which often\nunderperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policymakers, and standards bodies to design\naccountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-30T10:18:19Z"}
{"aid":"http://arxiv.org/abs/2504.21493v1","title":"Stabilization of linear systems with multiple unknown time-varying input\n  delays by linear time-varying feedback","summary":"This paper addresses the stabilization of linear systems with multiple\ntime-varying input delays. In scenarios where neither the exact delays\ninformation nor their bound is known, we propose a class of linear time-varying\nstate feedback controllers by using the solution to a parametric Lyapunov\nequation (PLE). By leveraging the properties of the solution to the PLE and\nconstructing a time-varying Lyapunov-Krasovskii-like functional, we prove that\n(the zero solution of) the closed-loop system is asymptotically stable.\nFurthermore, this result is extended to the observer-based output feedback\ncase. The notable characteristic of these controllers is their utilization of\nlinear time-varying gains. Furthermore, they are designed entirely independent\nof any knowledge of the time delays, resulting in controllers that are\nexceedingly easy to implement. Finally, a numerical example demonstrates the\neffectiveness of the proposed approaches.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T10:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.21497v1","title":"MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric\n  Guidance","summary":"In this paper, we propose a method for video face reenactment that integrates\na 3D face parametric model into a latent diffusion framework, aiming to improve\nshape consistency and motion control in existing video-based face generation\napproaches. Our approach employs the FLAME (Faces Learned with an Articulated\nModel and Expressions) model as the 3D face parametric representation,\nproviding a unified framework for modeling face expressions and head pose. This\nenables precise extraction of detailed face geometry and motion features from\ndriving videos. Specifically, we enhance the latent diffusion model with rich\n3D expression and detailed pose information by incorporating depth maps, normal\nmaps, and rendering maps derived from FLAME sequences. A multi-layer face\nmovements fusion module with integrated self-attention mechanisms is used to\ncombine identity and motion latent features within the spatial domain. By\nutilizing the 3D face parametric model as motion guidance, our method enables\nparametric alignment of face identity between the reference image and the\nmotion captured from the driving video. Experimental results on benchmark\ndatasets show that our method excels at generating high-quality face animations\nwith precise expression and head pose variation modeling. In addition, it\ndemonstrates strong generalization performance on out-of-domain images. Code is\npublicly available at https://github.com/weimengting/MagicPortrait.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T10:30:46Z"}
{"aid":"http://arxiv.org/abs/2504.21516v1","title":"Regularity properties of densities of SDEs using the Fourier analytic\n  approach","summary":"We show regularity properties of local densities of solutions of stochastic\ndifferential equations (SDEs) with the Fourier analytic approach. With this\nsimple method, statements that were previously derived with approaches using\nMalliavin calculus or difference operators can be recovered and extended to\ninclude regularity properties with respect to the time variable. For example,\nwe derive the H\\\"older continuity and joint continuity of local densities in\nthe case of drift coefficients that are locally piecewise H\\\"older continuous.\nTo this end, we derive fairly general bounds for the Fourier transform of the\nlocal density of a solution of the SDE when the drift is locally bounded and\nthe diffusion is locally sufficiently regular.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T11:09:49Z"}
{"aid":"http://arxiv.org/abs/2504.21545v1","title":"Meta knowledge assisted Evolutionary Neural Architecture Search","summary":"Evolutionary computation (EC)-based neural architecture search (NAS) has\nachieved remarkable performance in the automatic design of neural\narchitectures. However, the high computational cost associated with evaluating\nsearched architectures poses a challenge for these methods, and a fixed form of\nlearning rate (LR) schedule means greater information loss on diverse searched\narchitectures. This paper introduces an efficient EC-based NAS method to solve\nthese problems via an innovative meta-learning framework. Specifically, a\nmeta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a\nsuitable LR schedule, which guides the training process with lower information\nloss when evaluating each individual. An adaptive surrogate model is designed\nthrough an adaptive threshold to select the potential architectures in a few\nepochs and then evaluate the potential architectures with complete epochs.\nAdditionally, a periodic mutation operator is proposed to increase the\ndiversity of the population, which enhances the generalizability and\nrobustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets\ndemonstrate that the proposed method achieves high performance comparable to\nthat of many state-of-the-art peer methods, with lower computational cost and\ngreater robustness.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-30T11:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.21546v1","title":"Hierarchy of pairing in imbalanced three-component one-dimensional Fermi\n  gas","summary":"We study a one-dimensional, three-component Fermi gas with population\nimbalance using the Bogoliubov-de Gennes mean-field approach. We specifically\nconsider pairing in two channels while deliberately excluding the third by\nsetting its interaction strength to zero. By systematically varying the\ninteraction strength and population imbalance, we identify a rich set of\nspatially modulated superfluid states, including structures akin to the\nLarkin-Ovchinnikov phase and phase-separated domains. A clear hierarchy emerges\nin the pairing behavior, shaped by the competition between the local density of\nstates and the Fermi momentum mismatch. A fidelity-based analysis of the\ndensity further distinguishes smooth crossovers from sharp spatial\nreorganizations. Our results shed light on how pairing symmetry and population\nimbalance determine the structure of spatially inhomogeneous superfluid phases\nin multicomponent systems with reduced dimensionality.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-30T11:43:56Z"}
{"aid":"http://arxiv.org/abs/2504.21565v1","title":"Towards proactive self-adaptive AI for non-stationary environments with\n  dataset shifts","summary":"Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.2.8","published":"2025-04-30T12:09:59Z"}
{"aid":"http://arxiv.org/abs/2504.21573v1","title":"Quantum adaptive imaging by position-correlated biphoton wavefront\n  sensing","summary":"Quantum imaging with spatially entangled photons offers advantages such as\nenhanced spatial resolution, robustness against noise, and counter-intuitive\nphenomena. In quantum adaptive optics, biphoton aberration correction has been\nachieved by using classical beams to detect the aberration source or scanning\nthe correction phase on biphotons if the source is unreachable. Here, we\nintroduce position-correlated biphoton Shack-Hartmann wavefront sensing, where\nthe phase pattern added on photon pairs with a strong position correlation is\nreconstructed from their position centroid distribution at the focal plane of a\nmicrolens array. We experimentally demonstrate this method by performing phase\nmeasurement and adaptive imaging against the disturbance of a plastic film. Our\nmethod involves only one measurement step, so it is a more direct approach to\nbiphoton phase measurement with a greatly improved efficiency, suitable for\nintegration into quantum microscopy and communication.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-30T12:25:26Z"}
{"aid":"http://arxiv.org/abs/2504.21578v1","title":"Glucagon and insulin production in pancreatic cells modeled using Petri\n  nets and Boolean networks","summary":"Diabetes is a civilization chronic disease characterized by a constant\nelevated concentration of glucose in the blood. Many processes are involved in\nthe glucose regulation, and their interactions are very complex. To better\nunderstand those processes we set ourselves a goal to create a Petri net model\nof the glucose regulation in the whole body. So far we have managed to create a\nmodel of glycolysis and synthesis of glucose in the liver, and the general\noverview models of the glucose regulation in a healthy and diabetic person. In\nthis paper we introduce Petri nets models of insulin secretion in beta cell of\nthe pancreas, and glucagon in the pancreas alpha cells. Those two hormones have\nmutually opposite effects: insulin preventing hyperglycemia, and glucagon\npreventing hypoglycemia. Understanding the mechanisms of insulin and glucagon\nsecretion constitutes the basis for understanding diabetes. We also present a\nmodel in which both processes occur together, depending on the blood glucose\nlevel. The dynamics of each model is analysed. Additionally, we transform the\noverall insulin and glucagon secretion system to a Boolean network, following\nstandard transformation rules.","main_category":"q-bio.CB","categories":"q-bio.CB,cs.CL","published":"2025-04-30T12:36:02Z"}
{"aid":"http://arxiv.org/abs/2504.21580v1","title":"Multigenerational Effects of Smallpox Vaccination","summary":"Can the effects of childhood vaccination extend across three generations?\nUsing Swedish data spanning 250 years, we estimate the impact of smallpox\nvaccination on longevity, disability, and occupational achievements. Employing\nmother fixed-effects, difference-in-differences, and shift-share\ninstrumental-variables designs, we find that vaccination improves health and\neconomic outcomes for at least two subsequent generations. Causal mediation\nanalysis reveals that these benefits arise from improved health behaviors and\nepigenetic factors. Even in milder disease environments as seen today,\nvaccination delivers lasting advantages, demonstrating its long-term benefits\nbeyond epidemic contexts. These findings highlight the benefits of early-life\nhealth interventions lasting for subsequent generations.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-30T12:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.21585v1","title":"Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based\n  Reinforcement Learning","summary":"This paper tackles the challenge of learning multi-goal dexterous hand\nmanipulation tasks using model-based Reinforcement Learning. We propose\nGoal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing\nprobabilistic neural network ensembles to describe the high-dimensional\ndexterous hand dynamics and introducing an asynchronous MPC policy to meet the\ncontrol frequency requirements in real-world dexterous hand systems. Extensive\nevaluations on four simulated Shadow Hand manipulation scenarios with randomly\ngenerated goals demonstrate GC-PMPC's superior performance over\nstate-of-the-art baselines. It successfully drives a cable-driven Dexterous\nhand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn\nmanipulating a cubic die to three goal poses within approximately 80 minutes of\ninteractions, demonstrating exceptional learning efficiency and control\nperformance on a cost-effective dexterous hand platform.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.SY,eess.SY","published":"2025-04-30T12:44:38Z"}
{"aid":"http://arxiv.org/abs/2504.21592v1","title":"A Protection-Interoperable Fault Ride-Through Control for Grid-Forming\n  Inverters","summary":"Differing from synchronous generators (SGs), grid-forming inverter-based\nresources (GFM-IBRs) exhibit rapid variations in their output impedances during\ntransmission line faults due to the overcurrent limitation. As a result, the\nsource dynamics during the fault period deviate significantly from those under\npre-fault conditions. This fundamental difference alters the fault responses of\nincremental quantities, thereby jeopardizing the reliability of the supervising\nelements in protective relays that are based on these quantities. To address\nthis challenge, a protection-interoperable fault ride-through (FRT) method for\nGFM-IBRs is proposed. This method dynamically adjusts power control of GFM-IBRs\nin response to the changes in output impedance, effectively mitigating\nvariations in source dynamics and thereby preserving the reliability of\nincremental quantity-based supervising elements. This method also ensures\neffective overcurrent limitation and transient stability of GFM-IBRs.\nController hardware-in-the-loop (CHIL) and experimental tests validate the\neffectiveness of the proposed method.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T12:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.21596v1","title":"Leveraging Pre-trained Large Language Models with Refined Prompting for\n  Online Task and Motion Planning","summary":"With the rapid advancement of artificial intelligence, there is an increasing\ndemand for intelligent robots capable of assisting humans in daily tasks and\nperforming complex operations. Such robots not only require task planning\ncapabilities but must also execute tasks with stability and robustness. In this\npaper, we present a closed-loop task planning and acting system, LLM-PAS, which\nis assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans\nlong-horizon tasks in a manner similar to traditional task and motion planners,\nit also emphasizes the execution phase of the task. By transferring part of the\nconstraint-checking process from the planning phase to the execution phase,\nLLM-PAS enables exploration of the constraint space and delivers more accurate\nfeedback on environmental anomalies during execution. The reasoning\ncapabilities of the LLM allow it to handle anomalies that cannot be addressed\nby the robust executor. To further enhance the system's ability to assist the\nplanner during replanning, we propose the First Look Prompting (FLP) method,\nwhich induces LLM to generate effective PDDL goals. Through comparative\nprompting experiments and systematic experiments, we demonstrate the\neffectiveness and robustness of LLM-PAS in handling anomalous conditions during\ntask execution.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-30T12:53:53Z"}
{"aid":"http://arxiv.org/abs/2504.21643v1","title":"Designing Control Barrier Function via Probabilistic Enumeration for\n  Safe Reinforcement Learning Navigation","summary":"Achieving safe autonomous navigation systems is critical for deploying robots\nin dynamic and uncertain real-world environments. In this paper, we propose a\nhierarchical control framework leveraging neural network verification\ntechniques to design control barrier functions (CBFs) and policy correction\nmechanisms that ensure safe reinforcement learning navigation policies. Our\napproach relies on probabilistic enumeration to identify unsafe regions of\noperation, which are then used to construct a safe CBF-based control layer\napplicable to arbitrary policies. We validate our framework both in simulation\nand on a real robot, using a standard mobile robot benchmark and a highly\ndynamic aquatic environmental monitoring task. These experiments demonstrate\nthe ability of the proposed solution to correct unsafe actions while preserving\nefficient navigation behavior. Our results show the promise of developing\nhierarchical verification-based systems to enable safe and robust navigation\nbehaviors in complex scenarios.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-30T13:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.21653v1","title":"Path Extendable Tournaments","summary":"A digraph $D$ is called \\emph{path extendable} if for every nonhamiltonian\n(directed) path $P$ in $D$, there exists another path $P^\\prime$ with the same\ninitial and terminal vertices as $P$, and $V(P^\\prime) = V (P)\\cup \\{w\\}$ for a\nvertex $w \\in V(D)\\setminus V(P)$. Hence, path extendability implies paths of\ncontinuous lengths between every vertex pair. In earlier works of C. Thomassen\nand K. Zhang, it was shown that the condition of small $i(T)$ or positive\n$\\pi_2(T)$ implies paths of continuous lengths between every vertex pair in a\ntournament $T$, where $i(T)$ is the irregularity of $T$ and $\\pi_2(T)$ denotes\nfor the minimum number of paths of length $2$ from $u$ to $v$ among all vertex\npairs $\\{u,v\\}$. Motivated by these results, we study sufficient conditions in\nterms of $i(T)$ and $\\pi_2(T)$ that guarantee a tournament $T$ is path\nextendable. We prove that (1) a tournament $T$ is path extendable if $i(T)<\n2\\pi_2(T)-(|T|+8)/6$, and (2) a tournament $T$ is path extendable if $\\pi_2(T)\n> (7|T|-10)/36$. As an application, we deduce that almost all random\ntournaments are path extendable.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-30T13:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.21657v1","title":"A p-adaptive polytopal discontinuous Galerkin method for high-order\n  approximation of brain electrophysiology","summary":"Multiscale mathematical models have shown great promise in computational\nbrain electrophysiology but are still hindered by high computational costs due\nto fast dynamics and complex brain geometries, requiring very fine\nspatio-temporal resolution. This paper introduces a novel p-adaptive\ndiscontinuous Galerkin method on polytopal grids (PolyDG) coupled with\nCrank-Nicolson time integration to approximate such models efficiently. The\np-adaptive method enhances local accuracy via dynamic, element-wise polynomial\nrefinement/de-refinement guided by a-posteriori error estimators. A novel\nclustering algorithm automatizes the selection of elements for adaptive\nupdates, further improving efficiency. A wide set of numerical tests, including\nepileptic seizure simulations in a sagittal section of a human brain stem,\ndemonstrate the method's ability to reduce computational load while maintaining\nthe accuracy of the numerical solution in capturing the dynamics of multiple\nwavefronts.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T14:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.21666v1","title":"Quantum Annealing Algorithms for Estimating Ising Partition Functions","summary":"Estimating partition functions of Ising spin glasses is crucial in\nstatistical physics, optimization, and machine learning, yet remains\nclassically intractable due to its #P-hard complexity. While Jarzynski's\nequality offers a theoretical approach, it becomes unreliable at low\ntemperatures due to rare divergent statistical fluctuations. Here, we present a\nprotocol that overcomes this limitation by synergizing reverse quantum\nannealing with tailored nonequilibrium initial distributions. Our method can\ndramatically suppress the estimator variance, achieving saturation in the\nlow-temperature regime. Numerical benchmarks on the Sherrington-Kirkpatrick\nspin glass and the 3-SAT problem demonstrate that our protocol reduces scaling\nexponents by over an order of magnitude (e.g., from ~8.5 to ~0.5), despite\nretaining exponential system-size dependences. Crucially, our protocol\ncircumvents stringent adiabatic constraints, making it feasible for near-term\nquantum devices like superconducting qubits, trapped ions, and Rydberg atom\narrays. This work bridges quantum dynamics with computational complexity,\noffering a practical pathway to quantum advantage in spin glass thermodynamics\nand beyond.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-30T14:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.21675v1","title":"Elimination Distance to Dominated Clusters","summary":"In the Dominated Cluster Deletion problem we are given an undirected graph\n$G$ and integers $k$ and $d$ and the question is to decide whether there exists\na set of at most $k$ vertices whose removal results in a graph in which each\nconnected component has a dominating set of size at most $d$. In the\nElimination Distance to Dominated Clusters problem we are again given an\nundirected graph $G$ and integers $k$ and $d$ and the question is to decide\nwhether we can recursively delete vertices up to depth $k$ such that each\nremaining connected component has a dominating set of size at most $d$. Bentert\net al.~[Bentert et al., MFCS 2024] recently provided an almost complete\nclassification of the parameterized complexity of Dominated Cluster Deletion\nwith respect to the parameters $k$, $d$, $c$, and $\\Delta$, where $c$ and\n$\\Delta$ are the degeneracy, and the maximum degree of the input graph,\nrespectively. In particular, they provided a non-uniform algorithm with running\ntime $f(k,d)\\cdot n^{O(d)}$. They left as an open problem whether the problem\nis fixed-parameter tractable with respect to the parameter $k+d+c$. We provide\na uniform algorithm running in time $f(k,d)\\cdot n^{O(d)}$ for both Dominated\nCluster Deletion and Elimination Distance to Dominated Clusters. We furthermore\nshow that both problems are FPT when parameterized by $k+d+\\ell$, where $\\ell$\nis the semi-ladder index of the input graph, a parameter that is upper bounded\nand may be much smaller than the degeneracy $c$, positively answering the open\nquestion of Bentert et al. We almost complete the picture by providing an\nalmost full classification for the parameterized complexity and kernelization\ncomplexity of Elimination Distance to Dominated Clusters. The one difficult\nbase case that remains open is whether treedepth (the case $d=0$) is NP-hard on\ngraphs of bounded maximum degree.","main_category":"cs.DM","categories":"cs.DM","published":"2025-04-30T14:15:41Z"}
{"aid":"http://arxiv.org/abs/2504.21678v1","title":"Reflections and Drinfeld twists for set-theoretic Yang-Baxter maps","summary":"We prove that reflections, for a solution to the set-theoretic Yang-Baxter\nequation, provide Drinfeld twists in the sense of Kulish and Mudrov. Using De\nCommer's notion of a braided action, we then define group reflections for a\nbraided group, and prove that they provide group Drinfeld twists in the sense\nof Ghobadi. Finally, we characterise when a reflection on a solution (X,r) can\nbe extended to a group reflection on the structure group G(X,r).","main_category":"math.QA","categories":"math.QA","published":"2025-04-30T14:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.21754v1","title":"Virtual Atom-Photon Bound States and Spontaneous Emission Control","summary":"In waveguide quantum electrodynamics systems, atomic radiation emission is\nshaped by the photonic environment and collective atom interactions, offering\npromising applications in quantum technologies. In particular, atom-photon\nbound states, inhibiting complete spontaneous decay of the atom, can be\nrealized through waveguide dispersion engineering or by utilizing giant atoms.\nWhile steady-state bound states are well understood, transient or virtual bound\nstates remain less explored. Here we investigate transient atom-photon bound\nstates, arising from initial atom-photon entanglement, and propose methods to\nslow down spontaneous atomic decay.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-30T15:49:35Z"}
{"aid":"http://arxiv.org/abs/2504.21757v1","title":"A generic dynamical system formulation for Bianchi-I cosmology with\n  isotropic fluid in $f(Q)$ gravity","summary":"In this article, we present for the first time a generic dynamical system\nformulation for Bianchi-I cosmology with an isotropic fluid in $f(Q)$ gravity\ntheory. This generalizes the earlier works in the literature on the Bianchi-I\ndynamical system in $f(Q)$ gravity that started with writing the Bianchi-I\ncosmological field equations specific to a chosen $f(Q)$ form and then\nconstructing suitable dimensionless variables. Instead, we start from the\ngeneric Bianchi-I cosmological field equations in $f(Q)$ and present a\nprescription of how one can construct an autonomous dynamical system in terms\nof the standard Hubble-normalized dimensionless dynamical variables once an\n$f(Q)$ theory is provided. We discuss its application in late-time and early\ntime cosmology. In the context of late-time cosmology, we implement our\nformulation in four examples, computing and analyzing the critical points,\ndetermining their existence conditions, examining their stability, and plotting\nthe phase portraits to illustrate their behavior. Particular care has been\ntaken to single out the physically viable regions in the phase space for each\nmodel. Our findings indicate that the quadratic model is not suitable for\nstudying the late-time anisotropic scenarios, while the other three models\nyield the same evolution as in GR without providing insights into the\ncosmological evolution of anisotropic critical points. In the early time\ncosmology scenario, the isotropization dynamics in vacuum is model independent;\ninflating cosmology always isotropizes, whereas a contracting cosmology is\nalways unstable, making it impossible to obtain a classically stable\nnonsingular bouncing solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T15:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.21760v1","title":"Bounded powers of edge ideals: Gorenstein toric rings","summary":"Let $S=K[x_1, \\ldots,x_n]$ denote the polynomial ring in $n$ variables over a\nfield $K$ and $I \\subset S$ a monomial ideal. Given a vector\n$\\mathfrak{c}\\in\\mathbb{N}^n$, the ideal $I_{\\mathfrak{c}}$ is the ideal\ngenerated by those monomials belonging to $I$ whose exponent vectors are\ncomponentwise bounded above by $\\mathfrak{c}$. Let $\\delta_{\\mathfrak{c}}(I)$\nbe the largest integer $q$ for which $(I^q)_{\\mathfrak{c}}\\neq 0$. For a finite\ngraph $G$, its edge ideal is denoted by $I(G)$. Let\n$\\mathcal{B}(\\mathfrak{c},G)$ be the toric ring which is generated by the\nmonomials belonging to the minimal system of monomial generators of\n$(I(G)^{\\delta_{\\mathfrak{c}}(I)})_{\\mathfrak{c}}$. In a previous work, the\nauthors proved that $(I(G)^{\\delta_{\\mathfrak{c}}(I)})_{\\mathfrak{c}}$ is a\npolymatroidal ideal. It follows that $\\mathcal{B}(\\mathfrak{c},G)$ is a normal\nCohen--Macaulay domain. In this paper, we study the Gorenstein property of\n$\\mathcal{B}(\\mathfrak{c},G)$.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-30T16:00:19Z"}
{"aid":"http://arxiv.org/abs/2504.21784v1","title":"A Comparison of the Consistent and Independent Second Moment Methods\n  Applied to Thermal Radiative Transfer","summary":"The design of efficient numerical methods for modeling thermal radiative\ntransfer (TRT) is challenging due to the stiff, nonlinear coupling between\nradiation and material energies, especially at the time scales of interest in\nhigh energy density physics and astrophysics. Here, we investigate the use of\nthe Second Moment Method (SMM) to accelerate absorption-emission within the\ncontext of the multigroup, Discrete Ordinates transport equations with\ndiscontinuous Galerkin spatial discretization. SMM employs a\nreduced-dimensional, diffusion-based model of radiation transport that, when\ncoupled with suitable discrete closures, serves as a proxy for the transport\nequation, isolating the transport equation from the stiff absorption-emission\nphysics. We use a gray low-order system to reduce the cost of solving the\nlow-order system and leverage SMM low-order discretizations specifically\ndesigned to be scalably solvable with existing linear solver technology. Our\nalgorithm robustly resolves the nonlinear TRT system while only relying on\ntransport sweeps, linearly solving symmetric and positive definite, gray\ndiffusion systems, and nonlinearly solving the spatially pointwise energy\nbalance equation. This algorithm is used as a vehicle to compare the efficacy\nof low-order discretizations developed for steady-state, linear transport on\ngray and multigroup TRT problems in one and two spatial dimensions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T16:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.21802v1","title":"Anosov representations of amalgams","summary":"For uniform lattices $\\Gamma$ in rank 1 Lie groups, we construct Anosov\nrepresentations of virtual doubles of $\\Gamma$ along certain quasiconvex\nsubgroups. We also show that virtual HNN extensions of these lattices over some\ncyclic subgroups admit Anosov embeddings. In addition, we prove that for any\nAnosov subgroup $\\Gamma$ of a real semisimple linear Lie group $\\mathsf{G}$ and\nany infinite abelian subgroup $\\mathrm{H} $ of $ \\Gamma$, there exists a\nfinite-index subgroup $\\Gamma' $ of $ \\Gamma$ containing $\\mathrm{H}$ such that\nthe double $\\Gamma' *_{\\mathrm{H}} \\Gamma'$ admits an Anosov representation,\nthereby confirming a conjecture of [arXiv:2112.05574]. These results yield\nnumerous examples of one-ended hyperbolic groups that do not admit discrete and\nfaithful representations into rank 1 Lie groups but do admit Anosov embeddings\ninto higher-rank Lie groups.","main_category":"math.GR","categories":"math.GR,math.DS,math.GT","published":"2025-04-30T16:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.21836v1","title":"3D Stylization via Large Reconstruction Model","summary":"With the growing success of text or image guided 3D generators, users demand\nmore control over the generation process, appearance stylization being one of\nthem. Given a reference image, this requires adapting the appearance of a\ngenerated 3D asset to reflect the visual style of the reference while\nmaintaining visual consistency from multiple viewpoints. To tackle this\nproblem, we draw inspiration from the success of 2D stylization methods that\nleverage the attention mechanisms in large image generation models to capture\nand transfer visual style. In particular, we probe if large reconstruction\nmodels, commonly used in the context of 3D generation, has a similar\ncapability. We discover that the certain attention blocks in these models\ncapture the appearance specific features. By injecting features from a visual\nstyle image to such blocks, we develop a simple yet effective 3D appearance\nstylization method. Our method does not require training or test time\noptimization. Through both quantitative and qualitative evaluations, we\ndemonstrate that our approach achieves superior results in terms of 3D\nappearance stylization, significantly improving efficiency while maintaining\nhigh-quality visual outcomes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:46:32Z"}
{"aid":"http://arxiv.org/abs/2504.21847v1","title":"Differentiable Room Acoustic Rendering with Multi-View Vision Priors","summary":"An immersive acoustic experience enabled by spatial audio is just as crucial\nas the visual aspect in creating realistic virtual environments. However,\nexisting methods for room impulse response estimation rely either on\ndata-demanding learning-based models or computationally expensive physics-based\nmodeling. In this work, we introduce Audio-Visual Differentiable Room Acoustic\nRendering (AV-DAR), a framework that leverages visual cues extracted from\nmulti-view images and acoustic beam tracing for physics-based room acoustic\nrendering. Experiments across six real-world environments from two datasets\ndemonstrate that our multimodal, physics-based approach is efficient,\ninterpretable, and accurate, significantly outperforming a series of prior\nmethods. Notably, on the Real Acoustic Field dataset, AV-DAR achieves\ncomparable performance to models trained on 10 times more data while delivering\nrelative gains ranging from 16.6% to 50.9% when trained at the same scale.","main_category":"cs.CV","categories":"cs.CV,cs.SD","published":"2025-04-30T17:55:29Z"}
{"aid":"http://arxiv.org/abs/2504.21853v1","title":"A Survey of Interactive Generative Video","summary":"Interactive Generative Video (IGV) has emerged as a crucial technology in\nresponse to the growing demand for high-quality, interactive video content\nacross various domains. In this paper, we define IGV as a technology that\ncombines generative capabilities to produce diverse high-quality video content\nwith interactive features that enable user engagement through control signals\nand responsive feedback. We survey the current landscape of IGV applications,\nfocusing on three major domains: 1) gaming, where IGV enables infinite\nexploration in virtual worlds; 2) embodied AI, where IGV serves as a\nphysics-aware environment synthesizer for training agents in multimodal\ninteraction with dynamically evolving scenes; and 3) autonomous driving, where\nIGV provides closed-loop simulation capabilities for safety-critical testing\nand validation. To guide future development, we propose a comprehensive\nframework that decomposes an ideal IGV system into five essential modules:\nGeneration, Control, Memory, Dynamics, and Intelligence. Furthermore, we\nsystematically analyze the technical challenges and future directions in\nrealizing each component for an ideal IGV system, such as achieving real-time\ngeneration, enabling open-domain control, maintaining long-term coherence,\nsimulating accurate physics, and integrating causal reasoning. We believe that\nthis systematic analysis will facilitate future research and development in the\nfield of IGV, ultimately advancing the technology toward more sophisticated and\npractical applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2505.00259v1","title":"Pack-PTQ: Advancing Post-training Quantization of Neural Networks by\n  Pack-wise Reconstruction","summary":"Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T02:53:46Z"}
{"aid":"http://arxiv.org/abs/2505.00271v1","title":"Dissipative qutrit-mediated stable charging","summary":"In this work, we propose a stable charging scheme mediated by a dissipative\nthree-level system, which allows a unidirectional energy flow from the external\npower source to a finite-dimensional quantum battery. By virtue of the\ndissipation, the battery avoids the spontaneous discharging induced by the\ntime-reversal symmetry in any unitary charging scheme. Irrespective to the\ninitial state, the battery can be eventually stabilized at the\nmaximal-ergotropy state as long as the charger-battery interaction is present.\nWe use a Dyson series of Lindbladian superoperator to obtain an effective\nmaster equation to describe the battery dynamics and extract the optimization\ncondition for charging efficiency. Also it proves that the Fermi's golden rule\ncan adapt to the non-Hermitian Hamiltonian. We justify the outstanding\nperformance of our charging scheme when applied to the finite-size system with\na uniform energy ladder operator, the large spin battery, and the truncated\nharmonic oscillator battery.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T03:35:56Z"}
{"aid":"http://arxiv.org/abs/2505.00335v1","title":"Efficient Neural Video Representation with Temporally Coherent\n  Modulation","summary":"Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T06:20:42Z"}
{"aid":"http://arxiv.org/abs/2505.00357v1","title":"Non-reciprocal anti-aligning active mixtures: deriving the exact\n  Boltzmann collision operator","summary":"We consider the effect of non-reciprocity in a binary mixture of\nself-propelled particles with anti-aligning interactions, where a particle of\ntype A reacts differently to a particle of type B than vice versa. Starting\nfrom a well-known microscopic Langevin-model for the particles, setting up the\ncorresponding exact N-particle Fokker-Planck equation and making Boltzmann's\nassumptions of low density and one-sided molecular chaos, the non-linear active\nBoltzmann equation with the exact collision operator is derived. In this\nderivation, the effect of phase-space compression and the build-up of\npair-correlations during binary interactions is explicitly taken into account,\nleading to a theoretical description beyond mean-field. This extends previous\nresults for reciprocal interactions, where it was found that orientational\norder can emerge in a system with purely anti-aligning interactions. Although\nthe equations of motion are more complex than in the reciprocal system, the\ntheory still leads to analytical expressions and predictions. Comparisons with\nagent-based simulations show excellent quantitative agreement of the dynamic\nand static behavior in the low density and/or small coupling limit.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-05-01T07:00:52Z"}
{"aid":"http://arxiv.org/abs/2505.00367v1","title":"KoACD: The First Korean Adolescent Dataset for Cognitive Distortion\n  Analysis","summary":"Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T07:37:18Z"}
{"aid":"http://arxiv.org/abs/2505.00384v1","title":"Improving the scalability of a high-order atmospheric dynamics solver\n  based on the deal.II library","summary":"We present recent advances on the massively parallel performance of a\nnumerical scheme for atmosphere dynamics applications based on the deal.II\nlibrary. The implicit-explicit discontinuous finite element scheme is based on\na matrix-free approach, meaning that no global sparse matrix is built and only\nthe action of the linear operators on a vector is actually implemented.\nFollowing a profiling analysis, we focus on the performance optimization of the\nnumerical method and describe the impact of different preconditioning and\nsolving techniques in this framework. Moreover, we show how the use of the\nlatest version of the \\texttt{deal.II} library and of suitable execution flags\ncan improve the parallel performance.","main_category":"math.NA","categories":"math.NA,cs.DC,cs.NA,cs.PF","published":"2025-05-01T08:20:10Z"}
{"aid":"http://arxiv.org/abs/2505.00435v1","title":"Modeling Metric Gyrosynchrotron Radio Emission From the Quiet Solar\n  Corona","summary":"The radio emission of the quiet Sun in the metric and decametric bands has\nnot been well studied historically due to limitations of existing instruments.\nIt is nominally dominated by thermal brehmsstrahlung of the solar corona, but\nmay also include significant gyrosynchrotron emission, usually assumed to be\nweak under quiet conditions. In this work, we investigate the expected\ngyrosynchrotron contribution to solar radio emission in the lowest radio\nfrequencies observable by ground instruments, for different regions of the low\nand middle corona. We approximate the coronal conditions by a synoptic\nmagnetohydrodynamic (MHD) model. The thermal emission is estimated from a\nforward model based on the simulated corona. We calculate the expected\ngyrosynchrotron emission with the Fast Gyrosynchrotron Codes framework by\nFleishman & Kuznetsov (2010). The model emissions of different coronal regions\nare compared with quiet-time observations between 20-90 MHz by the LOw\nFrequency ARray (LOFAR) radio telescope. The contribution of gyrosynchrotron\nradiation to low frequency solar radio emission may shed light on effects such\nas the hitherto unexplained brightness variation observed in decametric coronal\nhole emission, and help constrain measurements of the coronal magnetic fields.\nIt can also improve our understanding of electron populations in the middle\ncorona and their relation to the formation of the solar wind.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-01T10:17:31Z"}
{"aid":"http://arxiv.org/abs/2505.00477v1","title":"Orbit-blocking words in free groups","summary":"By strengthening known results about primitivity-blocking words in free\ngroups, we prove that for any nontrivial element w of a free group of finite\nrank, there are words that cannot be subwords of any cyclically reduced\nautomorphic image of w. This has implications for the average-case complexity\nof Whitehead's problem.","main_category":"math.GR","categories":"math.GR,cs.CC","published":"2025-05-01T12:09:19Z"}
{"aid":"http://arxiv.org/abs/2505.00495v1","title":"Enhancing Tropical Cyclone Path Forecasting with an Improved Transformer\n  Network","summary":"A storm is a type of extreme weather. Therefore, forecasting the path of a\nstorm is extremely important for protecting human life and property. However,\nstorm forecasting is very challenging because storm trajectories frequently\nchange. In this study, we propose an improved deep learning method using a\nTransformer network to predict the movement trajectory of a storm over the next\n6 hours. The storm data used to train the model was obtained from the National\nOceanic and Atmospheric Administration (NOAA) [1]. Simulation results show that\nthe proposed method is more accurate than traditional methods. Moreover, the\nproposed method is faster and more cost-effective","main_category":"cs.LG","categories":"cs.LG,cs.PF","published":"2025-05-01T12:48:34Z"}
{"aid":"http://arxiv.org/abs/2505.00496v1","title":"Out of the Loop Again: How Dangerous is Weaponizing Automated Nuclear\n  Systems?","summary":"Are nuclear weapons useful for coercion, and, if so, what factors increase\nthe credibility and effectiveness of nuclear threats? While prominent scholars\nlike Thomas Schelling argue that nuclear brinkmanship, or the manipulation of\nnuclear risk, can effectively coerce adversaries, others contend nuclear\nweapons are not effective tools of coercion, especially coercion designed to\nachieve offensive and revisionist objectives. Simultaneously, there is broad\ndebate about the incorporation of artificial intelligence (AI) into military\nsystems, especially nuclear command and control. We develop a theoretical\nargument that explicit nuclear threats implemented with automated nuclear\nlaunch systems are potentially more credible compared to ambiguous nuclear\nthreats or explicit nuclear threats implemented via non-automated means. By\nreducing human control over nuclear use, leaders can more effectively tie their\nhands and thus signal resolve. While automated nuclear weapons launch systems\nmay seem like something out of science fiction, the Soviet Union deployed such\na system during the Cold War and the technology necessary to automate the use\nof force has developed considerably in recent years due to advances in AI.\nPreregistered survey experiments on an elite sample of United Kingdom Members\nof Parliament and two public samples of UK citizens provide support for these\nexpectations, showing that, in a limited set of circumstances, nuclear threats\nbacked by AI integration have credibility advantages, no matter how dangerous\nthey may be. Our findings contribute to the literatures on coercive bargaining,\nweapons of mass destruction, and emerging technology.","main_category":"cs.CY","categories":"cs.CY","published":"2025-05-01T12:51:06Z"}
{"aid":"http://arxiv.org/abs/2505.00501v1","title":"Minimal Factorization of Chern-Simons Theory - Gravitational Anyonic\n  Edge Modes","summary":"One approach to analyzing entanglement in a gauge theory is embedding it into\na factorized theory with edge modes on the entangling boundary. For topological\nquantum field theories (TQFT), this naturally leads to factorizing a TQFT by\nadding local edge modes associated with the corresponding CFT. In this work, we\ninstead construct a minimal set of edge modes compatible with the topological\ninvariance of Chern-Simons theory. This leads us to propose a minimal\nfactorization map. These minimal edge modes can be interpreted as the degrees\nof freedom of a particle on a quantum group. Of particular interest is\nthree-dimensional gravity as a Chern-Simons theory with gauge group\nSL$(2,\\mathbb{R}) \\times$ SL$(2,\\mathbb{R})$. Our minimal factorization\nproposal uniquely gives rise to quantum group edge modes factorizing the bulk\nstate space of 3d gravity. This agrees with earlier proposals that relate the\nBekenstein-Hawking entropy in 3d gravity to topological entanglement entropy.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,math.QA,math.SG","published":"2025-05-01T13:03:52Z"}
{"aid":"http://arxiv.org/abs/2505.00516v1","title":"First Measurement of the Electron Neutrino Charged-Current Pion\n  Production Cross Section on Carbon with the T2K Near Detector","summary":"The T2K Collaboration presents the first measurement of electron\nneutrino-induced charged-current pion production on carbon in a restricted\nkinematical phase space. This is performed using data from the 2.5$^{\\deg}$\noff-axis near detector, ND280. The differential cross sections with respect to\nthe outgoing electron and pion kinematics, in addition to the total\nflux-integrated cross section, are obtained. Comparisons between the measured\nand predicted cross section results using the Neut, Genie and NuWro Monte Carlo\nevent generators are presented. The measured total flux-integrated cross\nsection is [2.52 $\\pm$ 0.52 (stat) $\\pm$ 0.30 (sys)] x $10^{-39}$ cm$^2$\nnucleon$^{-1}$, which is lower than the event generator predictions.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-01T13:35:18Z"}
{"aid":"http://arxiv.org/abs/2505.00540v1","title":"Emergence of Roles in Robotic Teams with Model Sharing and Limited\n  Communication","summary":"We present a reinforcement learning strategy for use in multi-agent foraging\nsystems in which the learning is centralised to a single agent and its model is\nperiodically disseminated among the population of non-learning agents. In a\ndomain where multi-agent reinforcement learning (MARL) is the common approach,\nthis approach aims to significantly reduce the computational and energy demands\ncompared to approaches such as MARL and centralised learning models. By\ndeveloping high performing foraging agents, these approaches can be translated\ninto real-world applications such as logistics, environmental monitoring, and\nautonomous exploration. A reward function was incorporated into this approach\nthat promotes role development among agents, without explicit directives. This\nled to the differentiation of behaviours among the agents. The implicit\nencouragement of role differentiation allows for dynamic actions in which\nagents can alter roles dependent on their interactions with the environment\nwithout the need for explicit communication between agents.","main_category":"cs.MA","categories":"cs.MA,cs.LG,cs.RO,cs.SY,eess.SY","published":"2025-05-01T14:05:46Z"}
{"aid":"http://arxiv.org/abs/2505.00547v1","title":"From Requirements to Test Cases: An NLP-Based Approach for\n  High-Performance ECU Test Case Automation","summary":"Automating test case specification generation is vital for improving the\nefficiency and accuracy of software testing, particularly in complex systems\nlike high-performance Electronic Control Units (ECUs). This study investigates\nthe use of Natural Language Processing (NLP) techniques, including Rule-Based\nInformation Extraction and Named Entity Recognition (NER), to transform natural\nlanguage requirements into structured test case specifications. A dataset of\n400 feature element documents from the Polarion tool was used to evaluate both\napproaches for extracting key elements such as signal names and values. The\nresults reveal that the Rule-Based method outperforms the NER method, achieving\n95% accuracy for more straightforward requirements with single signals, while\nthe NER method, leveraging SVM and other machine learning algorithms, achieved\n77.3% accuracy but struggled with complex scenarios. Statistical analysis\nconfirmed that the Rule-Based approach significantly enhances efficiency and\naccuracy compared to manual methods. This research highlights the potential of\nNLP-driven automation in improving quality assurance, reducing manual effort,\nand expediting test case generation, with future work focused on refining NER\nand hybrid models to handle greater complexity.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-01T14:23:55Z"}
{"aid":"http://arxiv.org/abs/2505.00593v1","title":"A Novel Feature-Aware Chaotic Image Encryption Scheme For Data Security\n  and Privacy in IoT and Edge Networks","summary":"The security of image data in the Internet of Things (IoT) and edge networks\nis crucial due to the increasing deployment of intelligent systems for\nreal-time decision-making. Traditional encryption algorithms such as AES and\nRSA are computationally expensive for resource-constrained IoT devices and\nineffective for large-volume image data, leading to inefficiencies in\nprivacy-preserving distributed learning applications. To address these\nconcerns, this paper proposes a novel Feature-Aware Chaotic Image Encryption\nscheme that integrates Feature-Aware Pixel Segmentation (FAPS) with Chaotic\nChain Permutation and Confusion mechanisms to enhance security while\nmaintaining efficiency. The proposed scheme consists of three stages: (1) FAPS,\nwhich extracts and reorganizes pixels based on high and low edge intensity\nfeatures for correlation disruption; (2) Chaotic Chain Permutation, which\nemploys a logistic chaotic map with SHA-256-based dynamically updated keys for\nblock-wise permutation; and (3) Chaotic chain Confusion, which utilises\ndynamically generated chaotic seed matrices for bitwise XOR operations.\nExtensive security and performance evaluations demonstrate that the proposed\nscheme significantly reduces pixel correlation -- almost zero, achieves high\nentropy values close to 8, and resists differential cryptographic attacks. The\noptimum design of the proposed scheme makes it suitable for real-time\ndeployment in resource-constrained environments.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2505.00603v1","title":"Can LLMs Help Improve Analogical Reasoning For Strategic Decisions?\n  Experimental Evidence from Humans and GPT-4","summary":"This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems.","main_category":"cs.AI","categories":"cs.AI,cs.HC","published":"2025-05-01T15:35:01Z"}
{"aid":"http://arxiv.org/abs/2505.00619v1","title":"Diverse Semantics-Guided Feature Alignment and Decoupling for\n  Visible-Infrared Person Re-Identification","summary":"Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due\nto the large modality discrepancy between visible and infrared images, which\ncomplicates the alignment of their features into a suitable common space.\nMoreover, style noise, such as illumination and color contrast, reduces the\nidentity discriminability and modality invariance of features. To address these\nchallenges, we propose a novel Diverse Semantics-guided Feature Alignment and\nDecoupling (DSFAD) network to align identity-relevant features from different\nmodalities into a textual embedding space and disentangle identity-irrelevant\nfeatures within each modality. Specifically, we develop a Diverse\nSemantics-guided Feature Alignment (DSFA) module, which generates pedestrian\ndescriptions with diverse sentence structures to guide the cross-modality\nalignment of visual features. Furthermore, to filter out style information, we\npropose a Semantic Margin-guided Feature Decoupling (SMFD) module, which\ndecomposes visual features into pedestrian-related and style-related\ncomponents, and then constrains the similarity between the former and the\ntextual embeddings to be at least a margin higher than that between the latter\nand the textual embeddings. Additionally, to prevent the loss of pedestrian\nsemantics during feature decoupling, we design a Semantic Consistency-guided\nFeature Restitution (SCFR) module, which further excavates useful information\nfor identification from the style-related features and restores it back into\nthe pedestrian-related features, and then constrains the similarity between the\nfeatures after restitution and the textual embeddings to be consistent with\nthat between the features before decoupling and the textual embeddings.\nExtensive experiments on three VI-ReID datasets demonstrate the superiority of\nour DSFAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T15:55:38Z"}
{"aid":"http://arxiv.org/abs/2505.00620v1","title":"Beyond Affine Loops: A Geometric Approach to Program Synthesis","summary":"Ensuring software correctness remains a fundamental challenge in formal\nprogram verification. One promising approach relies on finding polynomial\ninvariants for loops. Polynomial invariants are properties of a program loop\nthat hold before and after each iteration. Generating polynomial invariants is\na crucial task for loops, but it is an undecidable problem in the general case.\nRecently, an alternative approach to this problem has emerged, focusing on\nsynthesizing loops from invariants. However, existing methods only synthesize\naffine loops without guard conditions from polynomial invariants. In this\npaper, we address a more general problem, allowing loops to have polynomial\nupdate maps with a given structure, inequations in the guard condition, and\npolynomial invariants of arbitrary form.\n  In this paper, we use algebraic geometry tools to design and implement an\nalgorithm that computes a finite set of polynomial equations whose solutions\ncorrespond to all loops satisfying the given polynomial invariants. In other\nwords, we reduce the problem of synthesizing loops to finding solutions of\npolynomial systems within a specified subset of the complex numbers. The latter\nis handled in our software using an SMT solver.","main_category":"cs.SC","categories":"cs.SC,math.AG","published":"2025-05-01T15:56:34Z"}
{"aid":"http://arxiv.org/abs/2505.00624v1","title":"FineScope : Precision Pruning for Domain-Specialized Large Language\n  Models Using SAE-Guided Self-Data Cultivation","summary":"Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T16:05:08Z"}
{"aid":"http://arxiv.org/abs/2505.00630v1","title":"Vision Mamba in Remote Sensing: A Comprehensive Survey of Techniques,\n  Applications and Outlook","summary":"Deep learning has profoundly transformed remote sensing, yet prevailing\narchitectures like Convolutional Neural Networks (CNNs) and Vision Transformers\n(ViTs) remain constrained by critical trade-offs: CNNs suffer from limited\nreceptive fields, while ViTs grapple with quadratic computational complexity,\nhindering their scalability for high-resolution remote sensing data. State\nSpace Models (SSMs), particularly the recently proposed Mamba architecture,\nhave emerged as a paradigm-shifting solution, combining linear computational\nscaling with global context modeling. This survey presents a comprehensive\nreview of Mamba-based methodologies in remote sensing, systematically analyzing\nabout 120 studies to construct a holistic taxonomy of innovations and\napplications. Our contributions are structured across five dimensions: (i)\nfoundational principles of vision Mamba architectures, (ii) micro-architectural\nadvancements such as adaptive scan strategies and hybrid SSM formulations,\n(iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids\nand frequency-domain adaptations, (iv) rigorous benchmarking against\nstate-of-the-art methods in multiple application tasks, such as object\ndetection, semantic segmentation, change detection, etc. and (v) critical\nanalysis of unresolved challenges with actionable future directions. By\nbridging the gap between SSM theory and remote sensing practice, this survey\nestablishes Mamba as a transformative framework for remote sensing analysis. To\nour knowledge, this paper is the first systematic review of Mamba architectures\nin remote sensing. Our work provides a structured foundation for advancing\nresearch in remote sensing systems through SSM-based methods. We curate an\nopen-source repository\n(https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster\ncommunity-driven advancements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T16:07:51Z"}
{"aid":"http://arxiv.org/abs/2505.00670v1","title":"TumorTwin: A python framework for patient-specific digital twins in\n  oncology","summary":"Background: Advances in the theory and methods of computational oncology have\nenabled accurate characterization and prediction of tumor growth and treatment\nresponse on a patient-specific basis. This capability can be integrated into a\ndigital twin framework in which bi-directional data-flow between the physical\ntumor and the digital tumor facilitate dynamic model re-calibration,\nuncertainty quantification, and clinical decision-support via recommendation of\noptimal therapeutic interventions. However, many digital twin frameworks rely\non bespoke implementations tailored to each disease site, modeling choice, and\nalgorithmic implementation.\n  Findings: We present TumorTwin, a modular software framework for\ninitializing, updating, and leveraging patient-specific cancer tumor digital\ntwins. TumorTwin is publicly available as a Python package, with associated\ndocumentation, datasets, and tutorials. Novel contributions include the\ndevelopment of a patient-data structure adaptable to different disease sites, a\nmodular architecture to enable the composition of different data, model,\nsolver, and optimization objects, and CPU- or GPU-parallelized implementations\nof forward model solves and gradient computations. We demonstrate the\nfunctionality of TumorTwin via an in silico dataset of high-grade glioma growth\nand response to radiation therapy.\n  Conclusions: The TumorTwin framework enables rapid prototyping and testing of\nimage-guided oncology digital twins. This allows researchers to systematically\ninvestigate different models, algorithms, disease sites, or treatment decisions\nwhile leveraging robust numerical and computational infrastructure.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.MS","published":"2025-05-01T17:20:20Z"}
{"aid":"http://arxiv.org/abs/2505.00704v1","title":"Controllable Weather Synthesis and Removal with Video Diffusion Models","summary":"Generating realistic and controllable weather effects in videos is valuable\nfor many applications. Physics-based weather simulation requires precise\nreconstructions that are hard to scale to in-the-wild videos, while current\nvideo editing often lacks realism and control. In this work, we introduce\nWeatherWeaver, a video diffusion model that synthesizes diverse weather effects\n-- including rain, snow, fog, and clouds -- directly into any input video\nwithout the need for 3D modeling. Our model provides precise control over\nweather effect intensity and supports blending various weather types, ensuring\nboth realism and adaptability. To overcome the scarcity of paired training\ndata, we propose a novel data strategy combining synthetic videos, generative\nimage editing, and auto-labeled real-world videos. Extensive evaluations show\nthat our method outperforms state-of-the-art methods in weather simulation and\nremoval, providing high-quality, physically plausible, and\nscene-identity-preserving results over various real-world videos.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-05-01T17:59:57Z"}
