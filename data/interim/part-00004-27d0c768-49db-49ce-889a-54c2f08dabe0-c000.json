{"aid":"http://arxiv.org/abs/2503.21680v1","title":"Continuous and Discrete Symmetries in a 4D Field-Theoretic Model:\n  Symmetry Operators and Their Algebraic Structures","summary":"Within the framework of Becchi-Rouet-Stora-Tyutin (BRST) formalism, we show\nthe existence of (i) a couple of off-shell nilpotent (i.e. fermionic) BRST and\nco-BRST symmetry transformations, and (ii) a full set of non-nilpotent (i.e.\nbosonic) symmetry transformations for an appropriate Lagrangian density that\ndescribes the combined system of the free Abelian 3-form and 1-form gauge\ntheories in the physical four (3 + 1)-dimensions of the flat Minkowskian\nspacetime. We concentrate on the full algebraic structures of the above\ncontinuous symmetry transformation operators along with a couple of very useful\ndiscrete duality symmetry transformation operators existing in our four (3 +\n1)-dimensional (4D) field-theoretic model. We establish the relevance of the\nalgebraic structures, respected by the above discrete and continuous symmetry\noperators, to the algebraic structures that are obeyed by the de Rham\ncohomological operators of differential geometry. One of the highlights of our\npresent endeavor is the observation that there are no ``exotic'' fields with\nthe negative kinetic terms in our present 4D field-theoretic example for Hodge\ntheory.","main_category":"hep-th","categories":"hep-th","published":"2025-03-27T16:49:23Z"}
{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21690v1","title":"CMED: A Child Micro-Expression Dataset","summary":"Micro-expressions are short bursts of emotion that are difficult to hide.\nTheir detection in children is an important cue to assist psychotherapists in\nconducting better therapy. However, existing research on the detection of\nmicro-expressions has focused on adults, whose expressions differ in their\ncharacteristics from those of children. The lack of research is a direct\nconsequence of the lack of a child-based micro-expressions dataset as it is\nmuch more challenging to capture children's facial expressions due to the lack\nof predictability and controllability. This study compiles a dataset of\nspontaneous child micro-expression videos, the first of its kind, to the best\nof the authors knowledge. The dataset is captured in the wild using video\nconferencing software. This dataset enables us to then explore key features and\ndifferences between adult and child micro-expressions. This study also\nestablishes a baseline for the automated spotting and recognition of\nmicro-expressions in children using three approaches comprising of hand-created\nand learning-based approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:55:32Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21706v1","title":"Flashlights: Prospects for constraining the Initial Mass Function around\n  cosmic noon with caustic-crossing events","summary":"The Flashlights program with the Hubble Space Telescope imaged the six Hubble\nFrontier Fields galaxy clusters in two epochs and detected twenty transients.\nThese are primarily expected to be caustic-crossing events (CCEs) where bright\nstars in distant lensed galaxies, typically at redshift $z\\approx1$--3, get\ntemporarily magnified close to cluster caustics. Since CCEs are generally\nbiased toward more massive and luminous stars, they offer a unique route for\nprobing the high end of the stellar mass function. We take advantage of the\nFlashlights event statistics to place preliminary constraints on the stellar\ninitial mass function (IMF) around cosmic noon. The photometry (along with\nspectral information) of lensed arcs is used to infer their various stellar\nproperties, and stellar synthesis models are used to evolve a recent stellar\npopulation in them. We estimate the microlens surface density near each arc\nand, together with existing lens models and simple formalism for CCEs,\ncalculate the expected rate for a given IMF. We find that, on average, a\nSalpeter-like IMF ($\\alpha=2.35$) underpredicts the number of observed CCEs by\na factor of ${\\sim}0.7$, and a top-heavy IMF ($\\alpha=1.00$) overpredicts by a\nfactor of ${\\sim}1.7$, suggesting that the average IMF slope may lie somewhere\nin between. However, given the large uncertainties associated with estimating\nthe stellar populations, these results are strongly model-dependent.\nNevertheless, we introduce a useful framework for constraining the IMF using\nCCEs. Observations with JWST are already yielding many more CCEs and will soon\nenable more stringent constraints on the IMF at a range of redshifts.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-27T17:20:35Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21712v1","title":"Complex Pressure Node Formation and Resonances Induced by Scatterers in\n  a Standing-Wave Acoustic Cavity","summary":"Acoustic pressure nodes in acoustophoretic devices are crucial for\napplications in tissue engineering, cell analysis, and particle trapping.\nTypically, a single primary node forms at the half-wavelength resonance\ncondition, while its shape and position are constrained by the dimensions of\nthe channel. The generation of additional nodes, along with control over their\npositions and shapes, is highly desirable in biomedical applications and could\nsignificantly enhance particle manipulation capabilities. To explore this\npotential, we numerically demonstrate the formation of additional,\ncomplex-shaped, nodes alongside the primary one, by a circular scatterer within\na rectangular cavity. We identify three distinct types: ring, protuberant, and\ncrescent nodes, whose formation depends on the size of the scatterer, its\nplacement in the middle of the channel, and its corresponding resonant\nfrequency. The key mechanism behind this formation is the enhancement of\ninternal reflections, increasing destructive interference to promote node\ngeneration. To achieve this, we employ three key concepts: using a low-aspect\nratio channel, positioning a rigid circular scatterer in the middle of the\nchannel, and modeling all surfaces as perfect reflectors. Furthermore, we\nanalyze the impact of the scatterer on acoustic pressure and quality factor,\nwhich is defined as the ratio of stored acoustic energy to damped acoustic\nenergy per cycle. We show that additional nodes emerge in the presence of a\nscatterer, but they come at the cost of reduced acoustic pressure and energy in\nthe channel. In summary, this study provides information on generating complex\nnodes in a standing wave acoustic cavity at the fundamental frequency, which\nhas numerous applications for particle manipulation in acoustofluidic devices.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-27T17:24:41Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21732v1","title":"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling","summary":"Creating high-fidelity 3D meshes with arbitrary topology, including open\nsurfaces and complex interiors, remains a significant challenge. Existing\nimplicit field methods often require costly and detail-degrading watertight\nconversion, while other approaches struggle with high resolutions. This paper\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\nsectional voxel training strategy that activates only relevant voxels during\nrendering, dramatically reducing memory consumption and enabling\nhigh-resolution training. This also allows, for the first time, the\nreconstruction of mesh interiors using only rendering supervision. Building\nupon this, we demonstrate a complete shape modeling pipeline by training a\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\n3D shape generation. Our experiments show state-of-the-art reconstruction\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\nF-score compared to previous methods, and demonstrate the generation of\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\nhigh-resolution, differentiable mesh reconstruction and generation with\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\nshape representation and modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.21744v1","title":"Expectation for the MeV Gamma-Ray Emission from Pair-Instability\n  Supernovae","summary":"Pair-instability supernovae (PISNe) are predicted thermonuclear explosions of\nmassive stars with helium core masses exceeding $\\sim 65M_\\odot$ and synthesize\nsubstantial amounts of radioactive $\\mathrm{^{56}Ni}$\n($M(\\mathrm{^{56}Ni})\\sim60M_\\odot$ in extreme cases). To investigate their\nobservational signatures, we developed a 1D Monte Carlo radiation transport\ncode and performed simulations of gamma-ray and hard X-ray emissions from the\ndecay chain $\\mathrm{^{56}Ni}\\to\\mathrm{^{56}Co}\\to\\mathrm{^{56}Fe}$. We find\nthat key gamma-ray lines (847 and 1238 keV) from $\\mathrm{^{56}Co}$ decay in\nthe $130M_\\odot$ helium core model can be detected up to 300-400 Mpc by\nnext-generation MeV gamma-ray telescopes. In contrast, the signals from the\n$100M_\\odot$ model remain below the detection limits. Our results provide the\ntemplate for gamma-ray follow-up observations of PISNe. Considering theoretical\npredictions and observational constraints, we estimate PISN event rates within\n300 Mpc to be approximately 0.1 events per year, highlighting their rarity but\nalso emphasizing their feasibility as targets for future gamma-ray observations\nover the decade.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-03-27T17:52:43Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  Schrödinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21757v1","title":"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck","summary":"In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21759v1","title":"Large Scale Structure and the Cosmic Web","summary":"The formation and evolution of galaxies cannot be separated from large scale\nstructure growth. Dark matter halos (and, therefore, galaxies) form and grow\nwithin the cosmic web - the classification of large-scale structure as distinct\nenvironments, namely voids, walls, filaments and nodes. Thanks to the rapid\ndevelopment of extragalactic spectroscopic redshift surveys and cosmological\nsimulations over the last two decades, we are now able to measure the impact of\nthe cosmic web on galaxies and halos in observations and in simulations. In\nthis chapter we summarise the state of play in our understanding of the link\nbetween dark matter halos, galaxies, and the cosmic web.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:57:19Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.21777v1","title":"Test-Time Visual In-Context Tuning","summary":"Visual in-context learning (VICL), as a new paradigm in computer vision,\nallows the model to rapidly adapt to various tasks with only a handful of\nprompts and examples. While effective, the existing VICL paradigm exhibits poor\ngeneralizability under distribution shifts. In this work, we propose test-time\nVisual In-Context Tuning (VICT), a method that can adapt VICL models on the fly\nwith a single test sample. Specifically, we flip the role between the task\nprompts and the test sample and use a cycle consistency loss to reconstruct the\noriginal task prompt output. Our key insight is that a model should be aware of\na new test distribution if it can successfully recover the original task\nprompts. Extensive experiments on six representative vision tasks ranging from\nhigh-level visual understanding to low-level image processing, with 15 common\ncorruptions, demonstrate that our VICT can improve the generalizability of VICL\nto unseen new domains. In addition, we show the potential of applying VICT for\nunseen tasks at test time. Code: https://github.com/Jiahao000/VICT.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-27T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2503.21778v1","title":"HS-SLAM: Hybrid Representation with Structural Supervision for Improved\n  Dense SLAM","summary":"NeRF-based SLAM has recently achieved promising results in tracking and\nreconstruction. However, existing methods face challenges in providing\nsufficient scene representation, capturing structural information, and\nmaintaining global consistency in scenes emerging significant movement or being\nforgotten. To this end, we present HS-SLAM to tackle these problems. To enhance\nscene representation capacity, we propose a hybrid encoding network that\ncombines the complementary strengths of hash-grid, tri-planes, and one-blob,\nimproving the completeness and smoothness of reconstruction. Additionally, we\nintroduce structural supervision by sampling patches of non-local pixels rather\nthan individual rays to better capture the scene structure. To ensure global\nconsistency, we implement an active global bundle adjustment (BA) to eliminate\ncamera drifts and mitigate accumulative errors. Experimental results\ndemonstrate that HS-SLAM outperforms the baselines in tracking and\nreconstruction accuracy while maintaining the efficiency required for robotics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2503.23684v1","title":"Detail-aware multi-view stereo network for depth estimation","summary":"Multi-view stereo methods have achieved great success for depth estimation\nbased on the coarse-to-fine depth learning frameworks, however, the existing\nmethods perform poorly in recovering the depth of object boundaries and detail\nregions. To address these issues, we propose a detail-aware multi-view stereo\nnetwork (DA-MVSNet) with a coarse-to-fine framework. The geometric depth clues\nhidden in the coarse stage are utilized to maintain the geometric structural\nrelationships between object surfaces and enhance the expressive capability of\nimage features. In addition, an image synthesis loss is employed to constrain\nthe gradient flow for detailed regions and further strengthen the supervision\nof object boundaries and texture-rich areas. Finally, we propose an adaptive\ndepth interval adjustment strategy to improve the accuracy of object\nreconstruction. Extensive experiments on the DTU and Tanks & Temples datasets\ndemonstrate that our method achieves competitive results. The code is available\nat https://github.com/wsmtht520-/DAMVSNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T03:23:39Z"}
{"aid":"http://arxiv.org/abs/2503.23695v1","title":"United States Muon Collider Community White Paper for the European\n  Strategy for Particle Physics Update","summary":"This document is being submitted to the 2024-2026 European Strategy for\nParticle Physics Update (ESPPU) process on behalf of the US Muon Collider\ncommunity, with its preparation coordinated by the interim US Muon Collider\nCoordination Group. The US Muon Collider Community comprises a few hundred\nAmerican scientists. The purpose of the document is to inform ESPPU about the\nUS plans for Muon Collider research and development (R&D), explain how these\nefforts align with the broader international R&D initiatives, and present the\nUS community vision for the future realization of this transformative project.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-03-31T03:48:33Z"}
{"aid":"http://arxiv.org/abs/2503.23719v1","title":"Compact orbital-angular-momentum multiplexing via laser-written glass\n  chips","summary":"Orbital angular momentum (OAM) modes have emerged as a promising solution for\nenhancing the capacity of optical multiplexing systems, leveraging their\ntheoretically unbounded set of orthogonal spatial modes. However, the\ngeneration and detection of OAM multiplexing signals are predominantly reliant\non bulky optical components within complex optical setups. We introduce a\ncompact solution for OAM information processing using laser-written glass\nchips, facilitating efficient multiplexing and demultiplexing of multiple OAM\ninformation channels. During the multiplexing process, OAM channels are managed\nvia laser-scribed single-mode waveguides within a glass chip, with their modes\nconverted using laser-written holograms on the side wall of the glass chip. The\nreverse optical process is employed for OAM demultiplexing. Our chips\nseamlessly interface with commercial optical fibers, ensuring compatibility\nwith existing fiber-optic communication infrastructure. This work not only\nestablishes a novel approach for OAM optical multiplexing but also underscores\nthe potential of laser-writing technology in advancing photonics and its\npractical applications in optical communications.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-03-31T04:40:57Z"}
{"aid":"http://arxiv.org/abs/2503.23729v1","title":"Integral regularization PINNs for evolution equations","summary":"Evolution equations, including both ordinary differential equations (ODEs)\nand partial differential equations (PDEs), play a pivotal role in modeling\ndynamic systems. However, achieving accurate long-time integration for these\nequations remains a significant challenge. While physics-informed neural\nnetworks (PINNs) provide a mesh-free framework for solving PDEs, they often\nsuffer from temporal error accumulation, which limits their effectiveness in\ncapturing long-time behaviors. To alleviate this issue, we propose integral\nregularization PINNs (IR-PINNs), a novel approach that enhances temporal\naccuracy by incorporating an integral-based residual term into the loss\nfunction. This method divides the entire time interval into smaller\nsub-intervals and enforces constraints over these sub-intervals, thereby\nimproving the resolution and correlation of temporal dynamics. Furthermore,\nIR-PINNs leverage adaptive sampling to dynamically refine the distribution of\ncollocation points based on the evolving solution, ensuring higher accuracy in\nregions with sharp gradients or rapid variations. Numerical experiments on\nbenchmark problems demonstrate that IR-PINNs outperform original PINNs and\nother state-of-the-art methods in capturing long-time behaviors, offering a\nrobust and accurate solution for evolution equations.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-03-31T05:02:59Z"}
{"aid":"http://arxiv.org/abs/2503.23734v1","title":"Semantic Packet Aggregation and Repeated Transmission for Text-to-Image\n  Generation","summary":"Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T05:14:40Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23744v1","title":"European Contributions to Fermilab Accelerator Upgrades and Facilities\n  for the DUNE Experiment","summary":"The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the\nLong-Baseline Neutrino Facility (LBNF) will provide the world's most intense\nneutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a\nwide-ranging physics program. This document outlines the significant\ncontributions made by European national laboratories and institutes towards\nrealizing the first phase of the project with a 1.2 MW neutrino beam.\nConstruction of this first phase is well underway. For DUNE Phase II, this will\nbe closely followed by an upgrade of the beam power to > 2 MW, for which the\nEuropean groups again have a key role and which will require the continued\nsupport of the European community for machine aspects of neutrino physics.\nBeyond the neutrino beam aspects, LBNF is also responsible for providing unique\ninfrastructure to install and operate the DUNE neutrino detectors at FNAL and\nat the Sanford Underground Research Facility (SURF). The cryostats for the\nfirst two Liquid Argon Time Projection Chamber detector modules at SURF, a\ncontribution of CERN to LBNF, are central to the success of the ongoing\nexecution of DUNE Phase I. Likewise, successful and timely procurement of\ncryostats for two additional detector modules at SURF will be critical to the\nsuccess of DUNE Phase II and the overall physics program. The DUNE\nCollaboration is submitting four main contributions to the 2026 Update of the\nEuropean Strategy for Particle Physics process. This paper is being submitted\nto the 'Accelerator technologies' and 'Projects and Large Experiments' streams.\nAdditional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and DUNE software and computing, are also being submitted\nto other streams.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.ins-det","published":"2025-03-31T05:47:29Z"}
{"aid":"http://arxiv.org/abs/2503.23747v1","title":"Consistency-aware Self-Training for Iterative-based Stereo Matching","summary":"Iterative-based methods have become mainstream in stereo matching due to\ntheir high performance. However, these methods heavily rely on labeled data and\nface challenges with unlabeled real-world data. To this end, we propose a\nconsistency-aware self-training framework for iterative-based stereo matching\nfor the first time, leveraging real-world unlabeled data in a teacher-student\nmanner. We first observe that regions with larger errors tend to exhibit more\npronounced oscillation characteristics during model prediction.Based on this,\nwe introduce a novel consistency-aware soft filtering module to evaluate the\nreliability of teacher-predicted pseudo-labels, which consists of a\nmulti-resolution prediction consistency filter and an iterative prediction\nconsistency filter to assess the prediction fluctuations of multiple\nresolutions and iterative optimization respectively. Further, we introduce a\nconsistency-aware soft-weighted loss to adjust the weight of pseudo-labels\naccordingly, relieving the error accumulation and performance degradation\nproblem due to incorrect pseudo-labels. Extensive experiments demonstrate that\nour method can improve the performance of various iterative-based stereo\nmatching approaches in various scenarios. In particular, our method can achieve\nfurther enhancements over the current SOTA methods on several benchmark\ndatasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T05:58:25Z"}
{"aid":"http://arxiv.org/abs/2503.23756v1","title":"On a natural L2 metric on the space of Hermitian metrics","summary":"We investigate the space of Hermitian metrics on a fixed complex vector\nbundle. This infinite-dimensional space has appeared in the study of\nHermitian-Einstein structures, where a special L2-type Riemannian metric is\nintroduced. We compute the metric spray, geodesics and curvature associated to\nthis metric, and show that the exponential map is a diffeomorphsim. Though\nbeing geodesically complete, the space of Hermitian metrics is metrically\nincomplete, and its metric completion is proved to be the space of L2\nintegrable singular Hermitian metrics. In addition, both the original space and\nits completion are CAT(0). In the holomorphic case, it turns out that Griffiths\nseminegative/semipositive singular Hermitian metric is always L2 integrable in\nour sense. Also, in the Appendix, the Nash-Moser inverse function theorem is\nused to prove that, for any L2 metric on the space of smooth sections of a\ngiven fiber bundle, the exponential map is always a local diffeomorphism,\nprovided that each fiber is nonpositively curved.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T06:12:40Z"}
{"aid":"http://arxiv.org/abs/2503.23758v1","title":"Exact Solution of the Frustrated Potts Model with Next-Nearest-Neighbor\n  Interactions in One Dimension: An AI-Aided Discovery","summary":"The one-dimensional $J_1$-$J_2$ $q$-state Potts model is solved exactly for\narbitrary $q$, based on using OpenAI's latest reasoning model o3-mini-high to\nexactly solve the $q=3$ case. The exact results provide insights to outstanding\nphysical problems such as the stacking of atomic or electronic orders in\nlayered materials and the formation of a $T_c$-dome-shaped phase often seen in\nunconventional superconductors. The work is anticipated to fuel both the\nresearch in one-dimensional frustrated magnets for recently discovered\nfinite-temperature application potentials and the fast moving topic area of AI\nfor sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-03-31T06:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.23770v1","title":"A new index transform with the square of Whittaker's function","summary":"An index transform, involving the square of Whittaker's function is\nintroduced and investigated. The corresponding inversion formula is\nestablished. Particular cases cover index transforms of the Lebedev type with\nproducts of the modified Bessel functions.","main_category":"math.CA","categories":"math.CA","published":"2025-03-31T06:40:58Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23791v1","title":"LLMigrate: Transforming \"Lazy\" Large Language Models into Efficient\n  Source Code Migrators","summary":"Rewriting C code in Rust provides stronger memory safety, yet migrating large\ncodebases such as the 32-million-line Linux kernel remains challenging. While\nrule-based translators (e.g., C2Rust) provide accurate yet largely unsafe Rust\nprograms, recent Large Language Model (LLM) approaches produce more idiomatic,\nsafe Rust programs but frequently exhibit \"laziness\", omitting significant\nportions of the target code. To address the issue, in this paper, we present\nLLMigrate, an LLM-based C-to-Rust translation tool that splits modules into\ndiscrete functions, translating them individually, and then reintegrating them.\nLLMigrate uses static analysis to retain necessary context, pairs GPT-4o (a\nstate-of-the-art LLM) with compiler-driven translation and program-repair\ntechniques for complex core functions, and leverages call-graph-guided\ntranslation to ensure consistent interfaces. Evaluations on three\nrepresentative Linux kernel modules (math, sort, and ramfs) show that LLMigrate\nrequires modifying less than 15\\% of the target code, significantly\noutperforming a pure GPT-4o-based migration.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-03-31T07:09:07Z"}
{"aid":"http://arxiv.org/abs/2503.23794v1","title":"Force-Free Molecular Dynamics Through Autoregressive Equivariant\n  Networks","summary":"Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-03-31T07:14:32Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23799v1","title":"On the motion of charged particles in constant electromagnetic field:\n  the parallel case","summary":"This paper is devoted to presenting a rigorous mathematical derivation for\nthe classical phenomenon in Maxwell's theory that a charged particle moves\nalong a straight line in a constant electromagnetic field if the initial\nvelocity is parallel to the constant electromagnetic field. The particle is\nmodeled by scaled solitons to a class of nonlinear Klein-Gordon equations and\nthe nonlinear interaction between the charged particle and the electromagnetic\nfield is governed by the Maxwell-Klein-Gordon system. We show that when the\nsize and amplitude of the particle are sufficiently small, the solution to the\ncoupled nonlinear system exists up to any given time and the energy of the\nparticle concentrates along a straight line. The method relies on the\nmodulation approach for the study of stability for solitons and weighted energy\nestimates for the Maxwell-Klein-Gordon equations.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T07:22:27Z"}
{"aid":"http://arxiv.org/abs/2503.23807v1","title":"Measurement-induced phase transitions for free fermions in a\n  quasiperiodic potential","summary":"We study the dynamics under continuous measurements for free fermions in a\nquasiperiodic potential by using the Aubry-Andr\\'{e}-Harper model with hopping\nrate $J$ and potential strength $V$. On the basis of the quantum trajectory\nmethod, we obtain the phase diagram for the steady-state entanglement entropy\nand demonstrate that robust logarithmic system-size scaling emerges up to a\ncritical potential strength $V_c/J \\sim 2.3$. Moreover, we find that the\nmeasurement induces entanglement phase transitions from the logarithmic-law\nphase to the area-law phase for the potential strength $V< V_c$, while any\nfinite measurement stabilizes the area-law phase for $V>V_c$. This result is\ndistinct from the entanglement scaling in the unitary limit, where volume-law\nand area-law phases undergo a transition at $V/J=2$. To further support the\nphase diagram, we analyze the connected correlation function and find that it\nshows algebraic decay in the logarithmic-law phase, while it decays quickly in\nthe area-law phase. Our results can be tested in ultracold atoms by introducing\nquasiperiodic potentials and continuously monitoring the local occupation\nnumber with an off-resonant probe light.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.stat-mech,quant-ph","published":"2025-03-31T07:42:24Z"}
{"aid":"http://arxiv.org/abs/2503.23808v1","title":"Why does tinnitus vary with naps? A polysomnographic prospective study\n  exploring the somatosensory hypothesis","summary":"Background: Tinnitus, defined as the conscious awareness of a noise without\nany identifiable corresponding external acoustic source, can be modulated by\nvarious factors. Among these factors, tinnitus patients commonly report drastic\nincreases of tinnitus loudness following nap sleep. Previous studies have\nsuggested that this clinical pattern could be attributed to a somatosensory\nmodulation of tinnitus. To our knowledge, no polysomnographic study has been\ncarried out to assess this hypothesis. Methods: For this observational\nprospective study, 37 participants reporting frequent increases of tinnitus\nfollowing naps were recruited. They participated to six full-polysomnography\nnap attempts over two days. Audiological and kinesiologic tests were conducted\nbefore and after each nap attempt. Results: 197 naps were collected. Each nap\nat each time of day elicited an overall significant increase in tinnitus\nminimum masking level (MML). Each inter nap period elicited an overall\nsignificant decrease. Tinnitus modulations were found significantly correlated\nwith nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p <\n0.05), with snoring duration (MML, p < 0.001), with snoring average sound level\n(VNS on tinnitus intrusiveness, VNS-I, p < 0.05) and with sleep apnea count\n(VNS-I, p < 0.001). Conclusions: This study confirms objectively that tinnitus\nmay increase following naps. No association was found between these modulations\nand somatosensory modulations involving the temporomandibular joint and\ncervical areas. However, it may be possible that nap-induced tinnitus\nmodulations are a hidden form of somatosensory modulation as snoring and sleep\napnea events are often related to tensor veli palatini muscle dysfunction.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-03-31T07:42:33Z"}
{"aid":"http://arxiv.org/abs/2503.23815v1","title":"Shannon-and Von Neumann-entropy regularizations of linear and\n  semidefinite programs","summary":"We consider the LP in standard form min {c T x : Ax = b; x $\\ge$ 0} and\ninspired by $\\epsilon$-regularization in Optimal Transport, we introduce its\n$\\epsilon$-regularization ''min {c T x + $\\epsilon$ f (x) : Ax = b; x $\\ge$\n0}'' via the (convex) Boltzmann-Shannon entropy f (x) := i x i ln x i . We also\nprovide a similar regularization for the semidefinite program ''min {Tr(C\n$\\bullet$ X) : A(X) = b; X 0}'' but with now the so-called Von Neumann entropy,\nas in Quantum Optimal Transport. Importantly, both are not barriers of the LP\nand SDP cones respectively. We show that this problem admits an equivalent\nunconstrained convex problem max $\\lambda$$\\in$R m G$\\epsilon$($\\lambda$) for\nan explicit concave differentiable function G$\\epsilon$ in dual variables\n$\\lambda$ $\\in$ R m . As $\\epsilon$ goes to zero, its optimal value converges\nto the optimal value of the initial LP. While it resembles the log-barrier\nformulation of interior point algorithm for the initial LP, it has a\ndistinguishing advantage. Namely for fixed $\\lambda$, G$\\epsilon$($\\lambda$) is\nobtained as a minimization over the whole space x $\\in$ R d (and not over x\n$\\ge$ 0) to still obtain a nonnegative solution x($\\lambda$) $\\ge$ 0, whence an\nexplicit form of G$\\epsilon$ very useful for its unconstrained maximization\nover R m.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T07:49:48Z"}
{"aid":"http://arxiv.org/abs/2503.23821v1","title":"Science4Peace: A Plea for Continued Peaceful International Scientific\n  Cooperation (Input to the European Strategy for Particle Physics -- 2026\n  update)","summary":"The European Strategy for Particle Physics (ESPP) - 2026 update is taking\nplace in a turbulent international climate. Many of the norms that have\ngoverned relations between states for decades are being broken or challenged.\nThe future progress of science in general, and particle physics in particular,\nwill depend on our ability to maintain peaceful international scientific\ncollaboration in the face of political pressures. We plead that the ESPP 2026\nupdate acknowledge explicitly the importance of peaceful international\nscientific collaboration, not only for the progress of science, but also as a\nprecious bridge between geopolitical blocs.\n  \"Scientific thought is the common heritage of mankind\" - Abdus Salam","main_category":"physics.soc-ph","categories":"physics.soc-ph,hep-ex,hep-ph,hep-th","published":"2025-03-31T08:15:42Z"}
{"aid":"http://arxiv.org/abs/2503.23822v1","title":"Node Embeddings via Neighbor Embeddings","summary":"Graph layouts and node embeddings are two distinct paradigms for\nnon-parametric graph representation learning. In the former, nodes are embedded\ninto 2D space for visualization purposes. In the latter, nodes are embedded\ninto a high-dimensional vector space for downstream processing.\nState-of-the-art algorithms for these two paradigms, force-directed layouts and\nrandom-walk-based contrastive learning (such as DeepWalk and node2vec), have\nlittle in common. In this work, we show that both paradigms can be approached\nwith a single coherent framework based on established neighbor embedding\nmethods. Specifically, we introduce graph t-SNE, a neighbor embedding method\nfor two-dimensional graph layouts, and graph CNE, a contrastive neighbor\nembedding method that produces high-dimensional node representations by\noptimizing the InfoNCE objective. We show that both graph t-SNE and graph CNE\nstrongly outperform state-of-the-art algorithms in terms of local structure\npreservation, while being conceptually simpler.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T08:16:03Z"}
{"aid":"http://arxiv.org/abs/2503.23823v1","title":"Blockchain for Federated Learning in the Internet of Things: Trustworthy\n  Adaptation, Standards, and the Road Ahead","summary":"As edge computing gains prominence in Internet of Things (IoTs), smart\ncities, and autonomous systems, the demand for real-time machine intelligence\nwith low latency and model reliability continues to grow. Federated Learning\n(FL) addresses these needs by enabling distributed model training without\ncentralizing user data, yet it remains reliant on centralized servers and lacks\nbuilt-in mechanisms for transparency and trust. Blockchain and Distributed\nLedger Technologies (DLTs) can fill this gap by introducing immutability,\ndecentralized coordination, and verifiability into FL workflows. This article\npresents current standardization efforts from 3GPP, ETSI, ITU-T, IEEE, and\nO-RAN that steer the integration of FL and blockchain in IoT ecosystems. We\nthen propose a blockchain-based FL framework that replaces the centralized\naggregator, incorporates reputation monitoring of IoT devices, and minimizes\noverhead via selective on-chain storage of model updates. We validate our\napproach with IOTA Tangle, demonstrating stable throughput and block\nconfirmations, even under increasing FL workloads. Finally, we discuss\narchitectural considerations and future directions for embedding trustworthy\nand resource-efficient FL in emerging 6G networks and vertical IoT\napplications. Our results underscore the potential of DLT-enhanced FL to meet\nstringent trust and energy requirements of next-generation IoT deployments.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T08:19:18Z"}
{"aid":"http://arxiv.org/abs/2503.23835v1","title":"Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as\n  Feedback Enables Pure Simulation Learning","summary":"Grasp-based manipulation tasks are fundamental to robots interacting with\ntheir environments, yet gripper state ambiguity significantly reduces the\nrobustness of imitation learning policies for these tasks. Data-driven\nsolutions face the challenge of high real-world data costs, while simulation\ndata, despite its low costs, is limited by the sim-to-real gap. We identify the\nroot cause of gripper state ambiguity as the lack of tactile feedback. To\naddress this, we propose a novel approach employing pseudo-tactile as feedback,\ninspired by the idea of using a force-controlled gripper as a tactile sensor.\nThis method enhances policy robustness without additional data collection and\nhardware involvement, while providing a noise-free binary gripper state\nobservation for the policy and thus facilitating pure simulation learning to\nunleash the power of simulation. Experimental results across three real-world\ngrasp-based tasks demonstrate the necessity, effectiveness, and efficiency of\nour approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T08:29:17Z"}
{"aid":"http://arxiv.org/abs/2503.23837v1","title":"Transmission resonances in scattering by $δ'$-like combs","summary":"We introduce a new exactly solvable model in quantum mechanics that describes\nthe propagation of particles through a potential field created by regularly\nspaced $\\delta'$-type point interactions, which model the localized dipoles\noften observed in crystal structures. We refer to the corresponding potentials\nas $\\delta'_\\theta$-combs, where the parameter $\\theta$ represents the contrast\nof the resonant wave at zero energy and determines the interface conditions in\nthe Hamiltonians. We explicitly calculate the scattering matrix for these\nsystems and prove that the transmission probability exhibits sharp resonance\npeaks while rapidly decaying at other frequencies. Consequently, Hamiltonians\nwith $\\delta'_\\theta$-comb potentials act as quantum filters, permitting\ntunnelling only for specific wave frequencies.","main_category":"math.SP","categories":"math.SP,math-ph,math.MP","published":"2025-03-31T08:33:37Z"}
{"aid":"http://arxiv.org/abs/2503.23840v1","title":"Investigating nuclear beta decay using lattice quantum Monte Carlo\n  approach","summary":"We present an \\textit{ab initio} calculation of nuclear $\\beta$-decay within\nthe framework of nuclear lattice effective field theory (NLEFT), employing\nauxiliary-field quantum Monte Carlo methods to solve the nuclear many-body\nproblem. Our approach combines next-to-next-to-leading order (NNLO) two- and\nthree-body chiral interactions with one- and two-body axial current operators,\nall consistently derived in chiral effective field theory. Low-energy constants\nare determined exclusively from nucleon-nucleon scattering phase shifts and\nfew-body observables for systems with $A \\leq 3$. Using these interactions and\ntransition operators, we perform two-channel Monte Carlo simulations to compute\nthe $\\beta$-decay matrix element for $^6$He, obtaining results in reasonable\nagreement with experimental measurements. To address the Monte Carlo sign\nproblem, we implement a perturbative expansion around a leading-order\nHamiltonian with approximate Wigner-SU(4) symmetry. This systematic approach\nprovides a foundation for extending NLEFT simulations to precision studies of\nweak processes in medium-mass nuclei.","main_category":"nucl-th","categories":"nucl-th,hep-lat","published":"2025-03-31T08:38:07Z"}
{"aid":"http://arxiv.org/abs/2503.23848v1","title":"SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to\n  Accelerate Your Speech-LLM Development","summary":"High-quality speech dialogue datasets are crucial for Speech-LLM development,\nyet existing acquisition methods face significant limitations. Human recordings\nincur high costs and privacy concerns, while synthetic approaches often lack\nconversational authenticity. To address these challenges, we introduce\n\\textsc{SpeechDialogueFactory}, a production-ready framework for generating\nnatural speech dialogues efficiently. Our solution employs a comprehensive\npipeline including metadata generation, dialogue scripting,\nparalinguistic-enriched utterance simulation, and natural speech synthesis with\nvoice cloning. Additionally, the system provides an interactive UI for detailed\nsample inspection and a high-throughput batch synthesis mode. Evaluations show\nthat dialogues generated by our system achieve a quality comparable to human\nrecordings while significantly reducing production costs. We release our work\nas an open-source toolkit, alongside example datasets available in English and\nChinese, empowering researchers and developers in Speech-LLM research and\ndevelopment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T08:52:21Z"}
{"aid":"http://arxiv.org/abs/2503.23853v1","title":"Theory of hydrodynamic forces in electric double layers","summary":"We present a theory of the hydrodynamic forces in the drainage flow of an\nelectrolyte between a sphere and a plane with charged surfaces. Our theory\nconsiders a thin electrolyte film which is at all times in local equilibrium\nacross its thickness. In addition to the usual lubrication force, we explicit\nthe electro-kinetic force due to the transport of the diffuse electrical\ncharges as well as the diffusio-kinetic force due to the transport of the\nexcess ion concentration in the Electrostatic Double Layers (EDLs). Our general\nformalism covers both the case of non-overlapping EDLs and of overlapping EDLs.\nWe study more specifically the mechanical impedance induced by an oscillatory\nmotion of small amplitude of the surfaces. Among our main results, we show that\nthe increase in damping due to the electro-kinetic effect is not monotonic with\nthe surface charge, and we predict a diffusio-kinetic stiffness with a\nlong-range decay in power minus four of the sphere-plane gap susceptible to\novercoming the stiffness of the equilibrium Derjaguin-Landau-Verwey-Overbeek\nforce. The comparison of our results with experiments could allow one to\nconfront the theories of electrolyte transport in the Electrostatic Double\nLayers without adjustable parameters.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-03-31T08:58:47Z"}
{"aid":"http://arxiv.org/abs/2503.23858v1","title":"Incremental capacity-based multi-feature fusion model for predicting\n  state-of-health of lithium-ion batteries","summary":"Lithium-ion batteries have become an indispensable part of human industrial\nproduction and daily life. For the safe use, management and maintenance of\nlithium-ion batteries, the state of health (SOH) of lithium-ion batteries is an\nimportant indicator so that the SOH estimation is of significant practical\nvalue. In order to accurately predict SOH, this paper proposes a fusion\nprediction model which combines particle swarm optimization (PSO) algorithm,\nbi-directional long-short time memory network (BiLSTM) and adaptive boosting\n(AdaBoost) algorithm. In the proposed prediction model, indirect health\nindicators (HIs), which characterize battery degradation, are obtained with the\nhelp of incremental capacity analysis (ICA), and is fed into BiLSTM to extract\ntime-series features, whose parameters are optimized by employing PSO\nalgorithm. On this basis, the AdaBoost algorithm is applied to reduce the risk\nof overfitting the PSO-BiLSTM model. The study based on lithium-ion battery\ndata from Center for Advanced Life Cycle Engineering (CALCE) shows that the\nPSO-BiLSTM-AdaBoost model has higher accuracy, better robustness, and\ngeneralization ability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:05:56Z"}
{"aid":"http://arxiv.org/abs/2503.23864v1","title":"Hybrid Random Concentrated Optimization Without Convexity Assumption","summary":"We propose a method to minimize a continuous function over a subset\n$\\mathcal{S}$ of high-dimensional space $\\mathbb{R}^K$ without assuming\nconvexity. The method alternates between Global Search (GS) to identify\ncandidates and Concentrated Search (CS) regimes to improve an eligible\ncandidate in $\\mathcal{S}$.Beyond the alternation between regimes, the\noriginality of the method lies in leveraging high dimensionality. We\ndemonstrate concentration properties under the $CS$ regime. In parallel, we\nshow that $GS$ reaches any point in finite time. Finally, two applications are\nproposed. The first is the reduction of the $L_1$ norm in the Lasso to\ndemonstrate the relevance of the method. In a second application, we compress\nneural network by pruning weights while maintaining performance. Our approach\nachieves significant weight reduction with minimal performance loss, offering\nan effective solution for network optimization.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-03-31T09:11:34Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23883v1","title":"Algorithm Design and Prototype Validation for Reconfigurable Intelligent\n  Sensing Surface: Forward-Only Transmission","summary":"Sensing-assisted communication schemes have recently garnered significant\nresearch attention. In this work, we design a dual-function reconfigurable\nintelligent surface (RIS), integrating both active and passive elements,\nreferred to as the reconfigurable intelligent sensing surface (RISS), to\nenhance communication. By leveraging sensing results from the active elements,\nwe propose communication enhancement and robust interference suppression\nschemes for both near-field and far-field models, implemented through the\npassive elements. These schemes remove the need for base station (BS) feedback\nfor RISS control, simplifying the communication process by replacing\ntraditional channel state information (CSI) feedback with real-time sensing\nfrom the active elements. The proposed schemes are theoretically analyzed and\nthen validated using software-defined radio (SDR). Experimental results\ndemonstrate the effectiveness of the sensing algorithms in real-world\nscenarios, such as direction of arrival (DOA) estimation and radio frequency\n(RF) identification recognition. Moreover, the RISS-assisted communication\nsystem shows strong performance in communication enhancement and interference\nsuppression, particularly in near-field models.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T09:36:15Z"}
{"aid":"http://arxiv.org/abs/2503.23886v1","title":"SchemaAgent: A Multi-Agents Framework for Generating Relational Database\n  Schema","summary":"The relational database design would output a schema based on user's\nrequirements, which defines table structures and their interrelated relations.\nTranslating requirements into accurate schema involves several non-trivial\nsubtasks demanding both database expertise and domain-specific knowledge. This\nposes unique challenges for automated design of relational databases. Existing\nefforts are mostly based on customized rules or conventional deep learning\nmodels, often producing suboptimal schema. Recently, large language models\n(LLMs) have significantly advanced intelligent application development across\nvarious domains. In this paper, we propose SchemaAgent, a unified LLM-based\nmulti-agent framework for the automated generation of high-quality database\nschema. SchemaAgent is the first to apply LLMs for schema generation, which\nemulates the workflow of manual schema design by assigning specialized roles to\nagents and enabling effective collaboration to refine their respective\nsubtasks. Schema generation is a streamlined workflow, where directly applying\nthe multi-agent framework may cause compounding impact of errors. To address\nthis, we incorporate dedicated roles for reflection and inspection, alongside\nan innovative error detection and correction mechanism to identify and rectify\nissues across various phases. For evaluation, we present a benchmark named\n\\textit{RSchema}, which contains more than 500 pairs of requirement description\nand schema. Experimental results on this benchmark demonstrate the superiority\nof our approach over mainstream LLMs for relational database schema generation.","main_category":"cs.DB","categories":"cs.DB,cs.AI","published":"2025-03-31T09:39:19Z"}
{"aid":"http://arxiv.org/abs/2503.23891v1","title":"Monodromy of Darboux transformations of polarised curves","summary":"We show that every finite type polarised curve in the conformal $2$-sphere\nwith a polynomial conserved quantity admits a resonance point, under a\nnon-orthogonality assumption on the conserved quantity. Using this fact, we\ndeduce that every finite type curve polarised by space form arc-length in the\nconformal $2$-sphere admits a resonance point, possibly on a multiple cover.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T09:42:15Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23917v1","title":"A construction of curvature-adapted hypersurfaces in the product of\n  symmetric spaces","summary":"In this paper, we give a construction of curvature-adapted hypersurfaces in\nthe product $G_1/K_1\\times G_2/K_2$ of (Riemannian) symmetric spaces $G_i/K_i$\n($i=1,2$). By this construction, we obtain many examples of curvature-adapted\nhypersurfaces in $G_1/K_1\\times G_2/K_2$. Also, we calculate the eigenvalues of\nthe shape operator and the normal Jacobi operator of the curvature-adapted\nhypersurfaces obtained by this construction.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T10:08:02Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23943v1","title":"DOMAC: Differentiable Optimization for High-Speed Multipliers and\n  Multiply-Accumulators","summary":"Multipliers and multiply-accumulators (MACs) are fundamental building blocks\nfor compute-intensive applications such as artificial intelligence. With the\ndiminishing returns of Moore's Law, optimizing multiplier performance now\nnecessitates process-aware architectural innovations rather than relying solely\non technology scaling. In this paper, we introduce DOMAC, a novel approach that\nemploys differentiable optimization for designing multipliers and MACs at\nspecific technology nodes. DOMAC establishes an analogy between optimizing\nmulti-staged parallel compressor trees and training deep neural networks.\nBuilding on this insight, DOMAC reformulates the discrete optimization\nchallenge into a continuous problem by incorporating differentiable timing and\narea objectives. This formulation enables us to utilize existing deep learning\ntoolkit for highly efficient implementation of the differentiable solver.\nExperimental results demonstrate that DOMAC achieves significant enhancements\nin both performance and area efficiency compared to state-of-the-art baselines\nand commercial IPs in multiplier and MAC designs.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T10:49:05Z"}
{"aid":"http://arxiv.org/abs/2503.23951v1","title":"JointTuner: Appearance-Motion Adaptive Joint Training for Customized\n  Video Generation","summary":"Recent text-to-video advancements have enabled coherent video synthesis from\nprompts and expanded to fine-grained control over appearance and motion.\nHowever, existing methods either suffer from concept interference due to\nfeature domain mismatch caused by naive decoupled optimizations or exhibit\nappearance contamination induced by spatial feature leakage resulting from the\nentanglement of motion and appearance in reference video reconstructions. In\nthis paper, we propose JointTuner, a novel adaptive joint training framework,\nto alleviate these issues. Specifically, we develop Adaptive LoRA, which\nincorporates a context-aware gating mechanism, and integrate the gated LoRA\ncomponents into the spatial and temporal Transformers within the diffusion\nmodel. These components enable simultaneous optimization of appearance and\nmotion, eliminating concept interference. In addition, we introduce the\nAppearance-independent Temporal Loss, which decouples motion patterns from\nintrinsic appearance in reference video reconstructions through an\nappearance-agnostic noise prediction task. The key innovation lies in adding\nframe-wise offset noise to the ground-truth Gaussian noise, perturbing its\ndistribution, thereby disrupting spatial attributes associated with frames\nwhile preserving temporal coherence. Furthermore, we construct a benchmark\ncomprising 90 appearance-motion customized combinations and 10 multi-type\nautomatic metrics across four dimensions, facilitating a more comprehensive\nevaluation for this customization task. Extensive experiments demonstrate the\nsuperior performance of our method compared to current advanced approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:04:07Z"}
{"aid":"http://arxiv.org/abs/2503.23959v1","title":"Local Information Matters: Inference Acceleration For Grounded\n  Conversation Generation Models Through Adaptive Local-Aware Token Pruning","summary":"Grounded Conversation Generation (GCG) is an emerging vision-language task\nthat requires models to generate natural language responses seamlessly\nintertwined with corresponding object segmentation masks. Recent models, such\nas GLaMM and OMG-LLaVA, achieve pixel-level grounding but incur significant\ncomputational costs due to processing a large number of visual tokens. Existing\ntoken pruning methods, like FastV and PyramidDrop, fail to preserve the local\nvisual features critical for accurate grounding, leading to substantial\nperformance drops in GCG tasks. To address this, we propose Adaptive\nLocal-Aware Token Pruning (ALTP), a simple yet effective framework that\naccelerates GCG models by prioritizing local object information. ALTP\nintroduces two key components: (1) Detail Density Capture (DDC), which uses\nsuperpixel segmentation to retain tokens in object-centric regions, preserving\nfine-grained details, and (2) Dynamic Density Formation (DDF), which\ndynamically allocates tokens based on information density, ensuring higher\nretention in semantically rich areas. Extensive experiments on the GranDf\ndataset demonstrate that ALTP significantly outperforms existing token pruning\nmethods, such as FastV and PyramidDrop, on both GLaMM and OMG-LLaVA models.\nNotably, when applied to GLaMM, ALTP achieves a 90% reduction in visual tokens\nwith a 4.9% improvement in AP50 and a 5.0% improvement in Recall compared to\nPyramidDrop. Similarly, on OMG-LLaVA, ALTP improves AP by 2.1% and mIOU by 3.0%\nat a 90% token reduction compared with PDrop.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:18:27Z"}
{"aid":"http://arxiv.org/abs/2503.23965v1","title":"Video-based Traffic Light Recognition by Rockchip RV1126 for Autonomous\n  Driving","summary":"Real-time traffic light recognition is fundamental for autonomous driving\nsafety and navigation in urban environments. While existing approaches rely on\nsingle-frame analysis from onboard cameras, they struggle with complex\nscenarios involving occlusions and adverse lighting conditions. We present\n\\textit{ViTLR}, a novel video-based end-to-end neural network that processes\nmultiple consecutive frames to achieve robust traffic light detection and state\nclassification. The architecture leverages a transformer-like design with\nconvolutional self-attention modules, which is optimized specifically for\ndeployment on the Rockchip RV1126 embedded platform. Extensive evaluations on\ntwo real-world datasets demonstrate that \\textit{ViTLR} achieves\nstate-of-the-art performance while maintaining real-time processing\ncapabilities (>25 FPS) on RV1126's NPU. The system shows superior robustness\nacross temporal stability, varying target distances, and challenging\nenvironmental conditions compared to existing single-frame approaches. We have\nsuccessfully integrated \\textit{ViTLR} into an ego-lane traffic light\nrecognition system using HD maps for autonomous driving applications. The\ncomplete implementation, including source code and datasets, is made publicly\navailable to facilitate further research in this domain.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T11:27:48Z"}
{"aid":"http://arxiv.org/abs/2503.23966v1","title":"Machine Learning-assisted High-speed Combinatorial Optimization with\n  Ising Machines for Dynamically Changing Problems","summary":"Quantum or quantum-inspired Ising machines have recently shown promise in\nsolving combinatorial optimization problems in a short time. Real-world\napplications, such as time division multiple access (TDMA) scheduling for\nwireless multi-hop networks and financial trading, require solving those\nproblems sequentially where the size and characteristics change dynamically.\nHowever, using Ising machines involves challenges to shorten system-wide\nlatency due to the transfer of large Ising model or the cloud access and to\ndetermine the parameters for each problem. Here we show a combinatorial\noptimization method using embedded Ising machines, which enables solving\ndiverse problems at high speed without runtime parameter tuning. We customize\nthe algorithm and circuit architecture of the simulated bifurcation-based Ising\nmachine to compress the Ising model and accelerate computation and then built a\nmachine learning model to estimate appropriate parameters using extensive\ntraining data. In TDMA scheduling for wireless multi-hop networks, our\ndemonstration has shown that the sophisticated system can adapt to changes in\nthe problem and showed that it has a speed advantage over conventional methods.","main_category":"cs.ET","categories":"cs.ET,cs.LG","published":"2025-03-31T11:31:36Z"}
{"aid":"http://arxiv.org/abs/2503.23972v1","title":"Noise-based reward-modulated learning","summary":"Recent advances in reinforcement learning (RL) have led to significant\nimprovements in task performance. However, training neural networks in an RL\nregime is typically achieved in combination with backpropagation, limiting\ntheir applicability in resource-constrained environments or when using\nnon-differentiable neural networks. While noise-based alternatives like\nreward-modulated Hebbian learning (RMHL) have been proposed, their performance\nhas remained limited, especially in scenarios with delayed rewards, which\nrequire retrospective credit assignment over time. Here, we derive a novel\nnoise-based learning rule that addresses these challenges. Our approach\ncombines directional derivative theory with Hebbian-like updates to enable\nefficient, gradient-free learning in RL. It features stochastic noisy neurons\nwhich can approximate gradients, and produces local synaptic updates modulated\nby a global reward signal. Drawing on concepts from neuroscience, our method\nuses reward prediction error as its optimization target to generate\nincreasingly advantageous behavior, and incorporates an eligibility trace to\nfacilitate temporal credit assignment in environments with delayed rewards. Its\nformulation relies on local information alone, making it compatible with\nimplementations in neuromorphic hardware. Experimental validation shows that\nour approach significantly outperforms RMHL and is competitive with BP-based\nbaselines, highlighting the promise of noise-based, biologically inspired\nlearning for low-power and real-time applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T11:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.23974v1","title":"Revealing the Low Temperature Phase of FAPbI$_3$ using Machine-Learned\n  Potential","summary":"FAPbI$_3$ is a material of interest for its potential in solar cell\napplications, driven by its remarkable optoelectronic properties. However, the\nlow-temperature phase of FAPbI$_3$ remains poorly understood, with open\nquestions surrounding its crystal structure, octahedral tilting, and the\narrangement of formamidinium (FA) cations. Using our trained machine-learned\npotential in combination with large-scale molecular dynamics simulations, we\nprovide a detailed investigation of this phase, uncovering its structural\ncharacteristics and dynamical behavior. Our analysis reveals the octahedral\ntilt pattern and sheds light on the rotational dynamics of FA cations in the\nlow temperature phase. Strikingly, we find that the FA cations become frozen in\na metastable configuration, unable to reach the thermodynamic ground state. By\ncomparing our simulated results with experimental nuclear magnetic resonance\n(NMR) and inelastic neutron scattering (INS) spectra, we demonstrate good\nagreement, further validating our findings. This phenomenon mirrors\nexperimental observations and offers a compelling explanation for the\nexperimental challenges in accessing the true ground state. These findings\nprovide critical insights into the fundamental physics of FAPbI$_3$ and its\nlow-temperature behavior, advancing our understanding of this technologically\nimportant material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T11:36:16Z"}
{"aid":"http://arxiv.org/abs/2503.23977v1","title":"Directed treewidth is closed under taking butterfly minors","summary":"Butterfly minors are a generalisation of the minor containment relation for\nundirected graphs to directed graphs. Many results in directed structural graph\ntheory use this notion as a central tool next to directed treewidth, a\ngeneralisation of the width measure treewidth to directed graphs. Adler\n[JCTB'07] showed that the directed treewidth is not closed under taking\nbutterfly minors. Over the years, many alternative definitions for directed\ntreewidth appeared throughout the literature, equivalent to the original\ndefinition up to small functions. In this paper, we consider the major ones and\nshow that not all of them share the problem identified by Adler.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-31T11:40:22Z"}
{"aid":"http://arxiv.org/abs/2503.23985v1","title":"An Empirical Study of Rust-Specific Bugs in the rustc Compiler","summary":"Rust is gaining popularity for its well-known memory safety guarantees and\nhigh performance, distinguishing it from C/C++ and JVM-based languages. Its\ncompiler, rustc, enforces these guarantees through specialized mechanisms such\nas trait solving, borrow checking, and specific optimizations. However, Rust's\nunique language mechanisms introduce complexity to its compiler, leading to\nRust-specific compiler bugs that are less common in traditional compilers. With\nRust's increasing adoption in safety-critical domains, understanding these\nlanguage mechanisms and their impact on compiler bugs is essential for\nimproving the reliability of both rustc and Rust programs. Yet, we still lack a\nlarge-scale, detailed, and in-depth study of Rust-specific bugs in rustc.\n  To bridge this gap, this work conducts a comprehensive and systematic study\nof Rust-specific bugs in rustc, with a particular focus on the components that\nsupport its unique language features. Our analysis examines issues and fixes\nreported between 2022 and 2024, with a manual review of 301 valid issues. We\ncategorize these bugs based on their causes, symptoms, affected compilation\nstages, and test case characteristics. Additionally, we evaluate existing rustc\ntesting tools to assess their effectiveness and limitations. Our key findings\ninclude: (1) rustc bugs primarily arise from Rust's type system and lifetime\nmodel, with frequent errors in the High-Level Intermediate Representation (HIR)\nand Mid-Level Intermediate Representation (MIR) modules due to complex checkers\nand optimizations; (2) bug-revealing test cases often involve unstable\nfeatures, advanced trait usages, lifetime annotations, standard APIs, and\nspecific optimization levels; (3) while both valid and invalid programs can\ntrigger bugs, existing testing tools struggle to detect non-crash errors,\nunderscoring the need for further advancements in rustc testing.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T11:55:04Z"}
{"aid":"http://arxiv.org/abs/2503.23998v1","title":"Relevance of the Computational Models of Bacterial Interactions in the\n  simulation of Biofilm Growth","summary":"This study explores the application of elongated particle interaction models,\ntraditionally used in liquid crystal phase research, in the context of early\nbacterial biofilm development. Through computer simulations, using an agent\nbased model, of the repulsive and attractive of Kihara models and Hertz\ninteraction model, we investigate the possibilities and limitations for\nmodelling biofilm formation and growth. Our approach focuses on understanding\nhow mechanical forces due to the interaction between cells, in addition to\ngrowth and diffusive parameters, influence the formation of complex bacterial\ncommunities. By comparing such force models, we evaluate their impact on the\nstructural properties of bacterial microcolonies. The results indicate that,\nalthough the specific force model has some effect on biofilm properties, the\nintensity of the interaction between bacteria is the most important\ndeterminant. This study highlights the importance of properly selecting\ninteraction strength in simulations to obtain realistic representations of\nbiofilm growth, and suggests which adapted models of rod-shaped bacterial\nsystems may offer a valid approach to study the dynamics of complex biofilms.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-03-31T12:21:26Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24029v1","title":"Global Well-Posedness of the 3D Navier-Stokes Equations under\n  Multi-Level Logarithmically Improved Criteria","summary":"This paper extends our previous results on logarithmically improved\nregularity criteria for the three-dimensional Navier-Stokes equations by\nestablishing a comprehensive framework of multi-level logarithmic improvements.\nWe prove that if the initial data $u_0 \\in L^2(\\mathbb{R}^3)$ satisfies a\nnested logarithmically weakened condition\n$\\|(-\\Delta)^{s/2}u_0\\|_{L^q(\\mathbb{R}^3)} \\leq \\frac{C_0}{\\prod_{j=1}^{n} (1\n+ L_j(\\|u_0\\|_{\\dot{H}^s}))^{\\delta_j}}$ for some $s \\in (1/2, 1)$, where $L_j$\nrepresents $j$-fold nested logarithms, then the corresponding solution exists\nglobally in time and is unique. The proof introduces a novel sequence of\nincreasingly precise commutator estimates incorporating multiple layers of\nlogarithmic corrections. We establish the existence of a critical threshold\nfunction $\\Phi(s,q,\\{\\delta_j\\}_{j=1}^n)$ that completely characterizes the\nboundary between global regularity and potential singularity formation, with\nexplicit asymptotics as $s$ approaches the critical value $1/2$. This paper\nfurther provides a rigorous geometric characterization of potential singular\nstructures through refined multi-fractal analysis, showing that any singular\nset must have Hausdorff dimension bounded by $1 - \\sum_{j=1}^n\n\\frac{\\delta_j}{1+\\delta_j} \\cdot \\frac{1}{j+1}$. Our results constitute a\nsignificant advancement toward resolving the global regularity question for the\nNavier-Stokes equations, as we demonstrate that with properly calibrated\nsequences of nested logarithmic improvements, the gap to the critical case can\nbe systematically reduced.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T12:55:30Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24037v1","title":"Digital Nudges Using Emotion Regulation to Reduce Online Disinformation\n  Sharing","summary":"Online disinformation often provokes strong anger, driving social media users\nto spread it; however, few measures specifically target sharing behaviors\ndriven by this emotion to curb the spread of disinformation. This study aimed\nto evaluate whether digital nudges that encourage deliberation by drawing\nattention to emotional information can reduce sharing driven by strong anger\nassociated with online disinformation. We focused on emotion regulation, as a\nmethod for fostering deliberation, which is activated when individuals'\nattention is drawn to their current emotions. Digital nudges were designed to\ndisplay emotional information about disinformation and emotion regulation\nmessages. Among these, we found that distraction and perspective-taking nudges\nmay encourage deliberation in anger-driven sharing. To assess their\neffectiveness, existing nudges mimicking platform functions were used for\ncomparison. Participant responses were measured across four dimensions: sharing\nintentions, type of emotion, intensity of emotion, and authenticity. The\nresults showed that all digital nudges significantly reduced the sharing of\ndisinformation, with distraction nudges being the most effective. These\nfindings suggest that digital nudges addressing emotional responses can serve\nas an effective intervention against the spread disinformation driven by strong\nanger.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-03-31T13:01:05Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24056v1","title":"Moment polytopes of toric exponential families","summary":"We show that the moment polytope of a K\\\"ahler toric manifold, constructed as\nthe torification (in the sense of M. Molitor, K\\\"ahler toric manifolds from\ndually flat spaces, arXiv:2109.04839, 2021) of an exponential family defined on\na finite sample space, is the projection of a higher-dimensional simplex.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T13:17:20Z"}
{"aid":"http://arxiv.org/abs/2503.24057v1","title":"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\n  Micro-Expression Recognition","summary":"Micro-expressions are typically regarded as unconscious manifestations of a\nperson's genuine emotions. However, their short duration and subtle signals\npose significant challenges for downstream recognition. We propose a multi-task\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\nmicro-expressions through self-supervised subtle motion magnification, while\nthe sparse spatial selection Mamba architecture combines sparse activation with\nthe advanced Visual Mamba model to model key motion regions and their valuable\nrepresentations more effectively. Additionally, we employ evolutionary search\nto optimize the magnification factor and the sparsity ratios of spatial\nselection, followed by fine-tuning to improve performance further. Extensive\nexperiments on two standard datasets demonstrate that the proposed AMMSM\nachieves state-of-the-art (SOTA) accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:17:43Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24066v1","title":"Smooth and rough paths in mean derivative estimation for functional data","summary":"In this paper, in a multivariate setting we derive near optimal rates of\nconvergence in the minimax sense for estimating partial derivatives of the mean\nfunction for functional data observed under a fixed synchronous design over\nH\\\"older smoothness classes. We focus on the supremum norm since it corresponds\nto the visualisation of the estimation error, and is closely related to the\nconstruction of uniform confidence bands. In contrast to mean function\nestimation, for derivative estimation the smoothness of the paths of the\nprocesses is crucial for the rates of convergence. On the one hand, if the\npaths have higher-order smoothness than the order of the partial derivative to\nbe estimated, the parametric $\\sqrt n$ rate can be achieved under sufficiently\ndense design. On the other hand, for processes with rough paths of lower-order\nsmoothness, we show that the rates of convergence are necessarily slower than\nthe parametric rate, and determine a near-optimal rate at which estimation is\nstill possible. We implement a multivariate local polynomial derivative\nestimator and illustrate its finite-sample performance in a simulation as well\nas for two real-data sets. To assess the smoothness of the sample paths in the\napplications we further discuss a method based on comparing restricted\nestimates of the partial derivatives of the covariance kernel.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T13:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24075v1","title":"Riemannian Multiplicative Update for Sparse Simplex constraint using\n  oblique rotation manifold","summary":"We propose a new manifold optimization method to solve low-rank problems with\nsparse simplex constraints (variables are simultaneous nonnegativity, sparsity,\nand sum-to-1) that are beneficial in applications. The proposed approach\nexploits oblique rotation manifolds, rewrite the problem, and introduce a new\nRiemannian optimization method. Experiments on synthetic datasets compared to\nthe standard Euclidean method show the effectiveness of the proposed method.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-03-31T13:31:05Z"}
{"aid":"http://arxiv.org/abs/2503.24077v1","title":"Dust in the wind of outbursting young stars","summary":"Context. Young Stellar Objects (YSOs) are observed to undergo powerful\naccretion events known as FU Orionis outbursts (FUors). Such events of episodic\naccretion are now considered to be common during low mass star formation,\nwherein the accretion onto the protostar occurs through a surrounding\ncentrifugal disk. Increasing evidence suggests that the magnetic disk winds are\ncrucial for driving disk accretion, as they carry both mass and momentum away\nfrom the disk. Aims. We aim to investigate the phenomenon of the ejection of\nmagnetic disk winds during episodic accretion, with a focus on the dust\ncontained within these winds. Methods. We conduct magnetohydrodynamic (MHD)\nsimulations of formation and evolution of protoplanetary disk (PPD) in the\nthin-disk limit. We include evolution of dust with two populations and a\nrealistic prescription for viscosity during outbursts, which depends on the\nlocal thermal ionization fraction. The disk evolves with the concurrent action\nof viscosity, self-gravity and magnetic disk winds. Results. The simulated disk\ndisplays outbursting behavior in the early stages, with the duration and\nfrequency of the bursts, their rise times, and brightness amplitudes resembling\nthe observations of FUors. We find that during the outbursts, the winds are\nover an order of magnitude more dusty, as compared to in quiescence. However,\ndespite this increased dust content, the winds are still dust-depleted as the\ndust-to-gas ratio is about an order of magnitude lower than the canonical\ninterstellar value of 0.01. The results of our numerical experiments are in\ngeneral agreement with the available observational findings and they shed a\nlight on the mechanism behind production of dusty winds during outbursting\nevents in YSOs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-03-31T13:32:53Z"}
{"aid":"http://arxiv.org/abs/2503.24081v1","title":"Cell-Free Massive MIMO Under Mobility: A Fairness-Differentiated\n  Handover Scheme","summary":"While cell-free massive MIMO (CF-mMIMO) offers both uniform and high\nnetwork-wide throughput in static networks, its performance in a mobile network\nis not yet fully addressed. In this paper, we evaluate the performance of a\nmobile CF-mMIMO network under a comprehensive throughput model and show that it\nsuffers from large performance degradation due to the combined effect of\nchannel aging and handover delay. To improve the performance of CF-mMIMO under\nmobility, we propose a fairness-differentiated handover scheme. Our scheme\ndifferentiates the handover policy for different users by their channel\nconditions compared to a threshold based on Jain's fairness index, in order to\nprioritize handovers for the poorly served users. We present an extensive\nevaluation of the mobile throughput performance of our handover scheme with\nrealistic urban network distributions and UE mobility patterns. Our results\nshow that our scheme significantly outperforms the existing literature\nbenchmarks when considering both channel aging and handover delay cost.\nImportantly, the advantage of UE-centric over network-centric CF-mMIMO, of\nuniformly good performance over the network, is uniquely preserved under\nmobility by our handover scheme. We thus show that CF-mMIMO can be a feasible\narchitecture for practical mobile networks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T13:35:41Z"}
{"aid":"http://arxiv.org/abs/2503.24085v1","title":"Unraveling tensor structures in correct-by-design controller synthesis","summary":"Formal safety guarantees on the synthesis of controllers for stochastic\nsystems can be obtained using correct-by-design approaches. These approaches\noften use abstractions as finite-state Markov Decision Processes. As the state\nspace of these MDPs grows, the curse of dimensionality makes the computational\nand memory cost of the probabilistic guarantees, quantified with dynamic\nprogramming, scale exponentially. In this work, we leverage decoupled dynamics\nand unravel, via dynamic programming operations, a tree structure in the\nCanonical Polyadic Decomposition (CPD) of the value functions.\n  For discrete-time stochastic systems with syntactically co-safe linear\ntemporal logic (scLTL) specifications, we provide provable probabilistic safety\nguarantees and significantly alleviate the computational burden. We provide an\ninitial validation of the theoretical results on several typical case studies\nand showcase that the uncovered tree structure enables efficient reductions in\nthe computational burden.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:38:09Z"}
{"aid":"http://arxiv.org/abs/2503.24091v1","title":"4D mmWave Radar in Adverse Environments for Autonomous Driving: A Survey","summary":"Autonomous driving systems require accurate and reliable perception. However,\nadverse environments, such as rain, snow, and fog, can significantly degrade\nthe performance of LiDAR and cameras. In contrast, 4D millimeter-wave (mmWave)\nradar not only provides 3D sensing and additional velocity measurements but\nalso maintains robustness in challenging conditions, making it increasingly\nvaluable for autonomous driving. Recently, research on 4D mmWave radar under\nadverse environments has been growing, but a comprehensive survey is still\nlacking. To bridge this gap, this survey comprehensively reviews the current\nresearch on 4D mmWave radar under adverse environments. First, we present an\noverview of existing 4D mmWave radar datasets encompassing diverse weather and\nlighting scenarios. Next, we analyze methods and models according to different\nadverse conditions. Finally, the challenges faced in current studies and\npotential future directions are discussed for advancing 4D mmWave radar\napplications in harsh environments. To the best of our knowledge, this is the\nfirst survey specifically focusing on 4D mmWave radar in adverse environments\nfor autonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:42:50Z"}
{"aid":"http://arxiv.org/abs/2503.24102v1","title":"Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?","summary":"Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T13:56:03Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24133v1","title":"Stability enhanced by transient attractors in a memristive chaotic map","summary":"The introduction of a memristor in a chaotic system can significantly modify\nits dynamical behavior. In this paper, we couple a discrete memristor model\nwith a chaotic map to investigate the memristor's impact on the stability of\nchaotic attractors. Our results reveal that introducing the memristor\nsubstantially enlarges the basin of attraction of a given chaotic attractor,\nthereby enhancing its stability. This phenomenon arises as a direct consequence\nof the memory and switching effects introduced by the memristor, which create\nnew paths to the chaotic attractors.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-03-31T14:17:17Z"}
{"aid":"http://arxiv.org/abs/2503.24134v1","title":"Moving mesh FSI approach for VIV simulation based on DG method with AMR\n  technique","summary":"Vortex-induced vibration (VIV) remains a fundamental yet computationally\n  challenging problem in computational fluid dynamics (CFD). This study\ndevelops a moving mesh Fluid-structure interaction (FSI) algorithm within a\nRunge-Kutta\n  Discontinuous Galerkin (RKDG) adaptive mesh refinement (AMR) framework. The\nviscous term in the compressible Navier-Stokes (NS) equations is discretized\nusing\n  the high-order Interior Penalty Discontinuous Galerkin (IPDG)\n  method. In addition to the above, key numerical advancements encompass\n  the rigorous derivation of the Lax-Friedrichs (L-F) numerical flux\nformulation\n  tailored for moving meshes, an enhanced AMR-driven nodal correction\n  methodology designed for curved surface geometries,\n  and the implementation of a ghost-node boundary condition treatment scheme\n  to address dynamic mesh motion. Numerical validation proceeds through three\nphases:\n  First, Couette flow simulations confirm the IPDG method's spatial\n  convergence order. Subsequent analysis of unsteady flow past a cylinder\n  demonstrate the AMR framework's efficacy in resolving vortex-dominated flow.\n  Finally, six VIV benchmark cases are simulated using third-order IPDG\ndiscretization,\n  establishing the proposed FSI algorithm's accuracy. Furthermore, synthetic\njets (SJs) flow control is investigated through\n  four frequency-variant SJs configurations. The results reveal that SJs can\nachieve completely\n  VIV suppression at a low actuation frequency, while higher actuation\n  frequencies reduce suppression efficiency due\n  to the energy of the SJs is more in the form of acoustic wave.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T14:17:53Z"}
{"aid":"http://arxiv.org/abs/2503.24147v1","title":"Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and\n  DR8 with a CMOS 3 nm SerDes and TFLN Modulators","summary":"We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:33:17Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24164v1","title":"SVLA: A Unified Speech-Vision-Language Assistant with Multimodal\n  Reasoning and Speech Generation","summary":"Large vision and language models show strong performance in tasks like image\ncaptioning, visual question answering, and retrieval. However, challenges\nremain in integrating speech, text, and vision into a unified model, especially\nfor spoken tasks. Speech generation methods vary (some produce speech\ndirectly), others through text (but their impact on quality is unclear).\nEvaluation often relies on automatic speech recognition, which may introduce\nbias. We propose SVLA, a unified speech vision language model based on a\ntransformer architecture that handles multimodal inputs and outputs. We train\nit on 38.2 million speech text image examples, including 64.1 hours of\nsynthetic speech. We also introduce Speech VQA Accuracy, a new metric for\nevaluating spoken responses. SVLA improves multimodal understanding and\ngeneration by better combining speech, vision, and language.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:46:34Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24178v1","title":"Beijing Normal University 12 meter Interferometric kHz GW Detector\n  Prototype","summary":"Gravitational wave (GW) astronomy has opened a new window into the universe,\nenabling the study of extreme astrophysical phenomena that are otherwise\nobscured in traditional electromagnetic observations. While global efforts have\npredominantly focused on low- and mid-frequency GW detection, the\nhigh-frequency regime, particularly in the kilohertz (kHz) range, remains\nunderexplored despite its potential to reveal critical insights into compact\nbinary mergers, neutron star physics, and other exotic astrophysical sources.\nIn this context, the Beijing Normal University (BNU) prototype represents a\npioneering effort to develop a dedicated kHz GW detector. Featuring a 12-meter\nL-shaped resonator within a two-arm vacuum system, the BNU prototype is\ndesigned to test innovative configurations and address key technical challenges\nfor kHz GW detection. Beyond its primary focus on being a technology testbed\nand demonstrator for kHz detection, the prototype is also being evaluated for\nits own sensitivity in the megahertz (MHz) range, offering the potential to\nexplore even higher-frequency signals from e.g., primordial black holes and\ngeontropic fluctuations. This paper provides a comprehensive overview of the\nBNU prototype, detailing its design, key components, and scientific objectives.","main_category":"physics.optics","categories":"physics.optics,astro-ph.IM,gr-qc,physics.ins-det,quant-ph","published":"2025-03-31T14:54:53Z"}
{"aid":"http://arxiv.org/abs/2503.24179v1","title":"Fast enumeration of effective mixed transports for recommending shipper\n  collaboration","summary":"In this study, we focus on a form of joint transportation called mixed\ntransportation and enumerate the combinations with high cooperation effects\nfrom among a number of transport lanes registered in a database (logistics big\ndata). As a measure of the efficiency of mixed transportation, we consider the\nreduction rate that represents how much the total distance of loading trips is\nshortened by cooperation. The proposed algorithm instantly presents the set of\nall mixed transports with a reduction rate of a specified value or less. This\nalgorithm is more than 7,000 times faster than simple brute force.","main_category":"cs.GT","categories":"cs.GT","published":"2025-03-31T14:55:24Z"}
{"aid":"http://arxiv.org/abs/2503.24187v1","title":"NeuRaLaTeX: A machine learning library written in pure LaTeX","summary":"In this paper, we introduce NeuRaLaTeX, which we believe to be the first deep\nlearning library written entirely in LaTeX. As part of your LaTeX document you\ncan specify the architecture of a neural network and its loss functions, define\nhow to generate or load training data, and specify training hyperparameters and\nexperiments. When the document is compiled, the LaTeX compiler will generate or\nload training data, train the network, run experiments, and generate figures.\nThis paper generates a random 100 point spiral dataset, trains a two layer MLP\non it, evaluates on a different random spiral dataset, produces plots and\ntables of results. The paper took 48 hours to compile and the entire source\ncode for NeuRaLaTeX is contained within the source code of the paper. We\npropose two new metrics: the Written In Latex (WIL) metric measures the\nproportion of a machine learning library that is written in pure LaTeX, while\nthe Source Code Of Method in Source Code of Paper (SCOMISCOP) metric measures\nthe proportion of a paper's implementation that is contained within the paper\nsource. We are state-of-the-art for both metrics, outperforming the ResNet and\nTransformer papers, as well as the PyTorch and Tensorflow libraries. Source\ncode, documentation, videos, crypto scams and an invitation to invest in the\ncommercialisation of NeuRaLaTeX are available at https://www.neuralatex.com","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:05:19Z"}
{"aid":"http://arxiv.org/abs/2503.24193v1","title":"Text2Tracks: Prompt-based Music Recommendation via Generative Retrieval","summary":"In recent years, Large Language Models (LLMs) have enabled users to provide\nhighly specific music recommendation requests using natural language prompts\n(e.g. \"Can you recommend some old classics for slow dancing?\"). In this setup,\nthe recommended tracks are predicted by the LLM in an autoregressive way, i.e.\nthe LLM generates the track titles one token at a time. While intuitive, this\napproach has several limitation. First, it is based on a general purpose\ntokenization that is optimized for words rather than for track titles. Second,\nit necessitates an additional entity resolution layer that matches the track\ntitle to the actual track identifier. Third, the number of decoding steps\nscales linearly with the length of the track title, slowing down inference. In\nthis paper, we propose to address the task of prompt-based music recommendation\nas a generative retrieval task. Within this setting, we introduce novel,\neffective, and efficient representations of track identifiers that\nsignificantly outperform commonly used strategies. We introduce Text2Tracks, a\ngenerative retrieval model that learns a mapping from a user's music\nrecommendation prompt to the relevant track IDs directly. Through an offline\nevaluation on a dataset of playlists with language inputs, we find that (1) the\nstrategy to create IDs for music tracks is the most important factor for the\neffectiveness of Text2Tracks and semantic IDs significantly outperform commonly\nused strategies that rely on song titles as identifiers (2) provided with the\nright choice of track identifiers, Text2Tracks outperforms sparse and dense\nretrieval solutions trained to retrieve tracks from language prompts.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T15:09:19Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24204v1","title":"Many-to-Many Matching via Sparsity Controlled Optimal Transport","summary":"Many-to-many matching seeks to match multiple points in one set and multiple\npoints in another set, which is a basis for a wide range of data mining\nproblems. It can be naturally recast in the framework of Optimal Transport\n(OT). However, existing OT methods either lack the ability to accomplish\nmany-to-many matching or necessitate careful tuning of a regularization\nparameter to achieve satisfactory results. This paper proposes a novel\nmany-to-many matching method to explicitly encode many-to-many constraints\nwhile preventing the degeneration into one-to-one matching. The proposed method\nconsists of the following two components. The first component is the matching\nbudget constraints on each row and column of a transport plan, which specify\nhow many points can be matched to a point at most. The second component is the\ndeformed $q$-entropy regularization, which encourages a point to meet the\nmatching budget maximally. While the deformed $q$-entropy was initially\nproposed to sparsify a transport plan, we employ it to avoid the degeneration\ninto one-to-one matching. We optimize the objective via a penalty algorithm,\nwhich is efficient and theoretically guaranteed to converge. Experimental\nresults on various tasks demonstrate that the proposed method achieves good\nperformance by gleaning meaningful many-to-many matchings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.24209v1","title":"Optimal low-rank approximations for linear Gaussian inverse problems on\n  Hilbert spaces, Part II: posterior mean approximation","summary":"In this work, we construct optimal low-rank approximations for the Gaussian\nposterior distribution in linear Gaussian inverse problems. The parameter space\nis a separable Hilbert space of possibly infinite dimension, and the data space\nis assumed to be finite-dimensional. We consider various types of approximation\nfamilies for the posterior. We first consider approximate posteriors in which\nthe means vary among a class of either structure-preserving or\nstructure-ignoring low-rank transformations of the data, and in which the\nposterior covariance is kept fixed. We give necessary and sufficient conditions\nfor these approximating posteriors to be equivalent to the exact posterior, for\nall possible realisations of the data simultaneously. For such approximations,\nwe measure approximation error with the Kullback-Leibler, R\\'enyi and Amari\n$\\alpha$-divergences for $\\alpha\\in(0,1)$, and with the Hellinger distance, all\naveraged over the data distribution. With these losses, we find the optimal\napproximations and formulate an equivalent condition for their uniqueness,\nextending the work in finite dimensions of Spantini et al. (SIAM J. Sci.\nComput. 2015). We then consider joint approximation of the mean and covariance,\nby also varying the posterior covariance over the low-rank updates considered\nin Part I of this work. For the reverse Kullback-Leibler divergence, we show\nthat the separate optimal approximations of the mean and of the covariance can\nbe combined to yield an optimal joint approximation of the mean and covariance.\nIn addition, we interpret the joint approximation with the optimal\nstructure-ignoring approximate mean in terms of an optimal projector in\nparameter space.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-03-31T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2503.24246v1","title":"Quantum phase diagram of the extended spin-3/2 Kitaev-Heisenberg model:\n  A DMRG study","summary":"Recently there has been considerable excitement surrounding the promising\nrealization of high-spin Kitaev material, such as the quasi-2D compound CrI$_3$\nand CrGeTe$_3$. However, the stability of quantum spin liquids (QSL) against\nsingle ion anisotropy (SIA) in these materials and the global quantum phase\ndiagram of the extended spin-3/2 Kitaev model with finite SIA remain unclear.\nIn this study, we perform large-scale density matrix renormalization group\n(DMRG) to explore the quantum phase diagram of the generalized spin-3/2\nKitaev-Heisenberg (K-H) model accompanied with SIA $A_c$. In the $A_c=0$ limit,\nthe spin-3/2 K-H model exhibits a quantum phase diagram similar to that of a\nspin-1/2 system, including two QSLs around antiferromagnetic and ferromagnetic\nKitaev models. For models with finite $A_c$, we map out the quantum phase\ndiagram around two Kitaev points and observe distinct types of in-plane vortex\norders developed from these two QSL phases. Interestingly, series of nearly\ndegenerate vortex configurations are discovered in each vortex phases. Using\nlinear spin-wave theory, we demonstrate that these vortex configurations can be\nunderstood as a consequence of the quantum correction on a continuous family of\ndegenerate classical states.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T15:58:20Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24252v1","title":"A BDG inequality for stochastic Volterra integrals","summary":"We establish Burkholder-Davis-Gundy-type inequalities for stochastic Volterra\nintegrals with a completely monotone convolution kernel, which may exhibit\nsingular behaviour at the origin. When the supremum is taken over a finite\ninterval, the upper bound depends linearly on the $L^\\gamma$-norm of the\nkernel, for any $\\gamma>2$. We demonstrate the utility of this inequality in\nquantifying the pathwise distance between two stochastic Volterra equations\nwith distinct kernels, with a particular emphasis on the multifactor Markovian\napproximation. For kernels that decay sufficiently fast, we derive an\nalternative inequality valid over an infinite time interval, providing\nuniform-in-time bounds for mean-reverting stochastic Volterra equations.\nFinally, we compare our findings with existing results in the literature.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T16:02:11Z"}
{"aid":"http://arxiv.org/abs/2503.24278v1","title":"AutoEval: Autonomous Evaluation of Generalist Robot Manipulation\n  Policies in the Real World","summary":"Scalable and reproducible policy evaluation has been a long-standing\nchallenge in robot learning. Evaluations are critical to assess progress and\nbuild better policies, but evaluation in the real world, especially at a scale\nthat would provide statistically reliable results, is costly in terms of human\ntime and hard to obtain. Evaluation of increasingly generalist robot policies\nrequires an increasingly diverse repertoire of evaluation environments, making\nthe evaluation bottleneck even more pronounced. To make real-world evaluation\nof robotic policies more practical, we propose AutoEval, a system to\nautonomously evaluate generalist robot policies around the clock with minimal\nhuman intervention. Users interact with AutoEval by submitting evaluation jobs\nto the AutoEval queue, much like how software jobs are submitted with a cluster\nscheduling system, and AutoEval will schedule the policies for evaluation\nwithin a framework supplying automatic success detection and automatic scene\nresets. We show that AutoEval can nearly fully eliminate human involvement in\nthe evaluation process, permitting around the clock evaluations, and the\nevaluation results correspond closely to ground truth evaluations conducted by\nhand. To facilitate the evaluation of generalist policies in the robotics\ncommunity, we provide public access to multiple AutoEval scenes in the popular\nBridgeData robot setup with WidowX robot arms. In the future, we hope that\nAutoEval scenes can be set up across institutions to form a diverse and\ndistributed evaluation network.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-03-31T16:23:44Z"}
{"aid":"http://arxiv.org/abs/2503.24279v1","title":"Toward the effective 2-topos","summary":"A candidate for the effective 2-topos is proposed and shown to include the\neffective 1-topos as its subcategory of 0-types.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-03-31T16:23:47Z"}
{"aid":"http://arxiv.org/abs/2503.24289v1","title":"Rec-R1: Bridging Generative Large Language Models and User-Centric\n  Recommendation Systems via Reinforcement Learning","summary":"We propose Rec-R1, a general reinforcement learning framework that bridges\nlarge language models (LLMs) with recommendation systems through closed-loop\noptimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1\ndirectly optimizes LLM generation using feedback from a fixed black-box\nrecommendation model, without relying on synthetic SFT data from proprietary\nmodels such as GPT-4o. This avoids the substantial cost and effort required for\ndata distillation. To verify the effectiveness of Rec-R1, we evaluate it on two\nrepresentative tasks: product search and sequential recommendation.\nExperimental results demonstrate that Rec-R1 not only consistently outperforms\nprompting- and SFT-based methods, but also achieves significant gains over\nstrong discriminative baselines, even when used with simple retrievers such as\nBM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM,\nunlike SFT, which often impairs instruction-following and reasoning. These\nfindings suggest Rec-R1 as a promising foundation for continual task-specific\nadaptation without catastrophic forgetting.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-03-31T16:36:00Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24298v1","title":"Order Matters: On Parameter-Efficient Image-to-Video Probing for\n  Recognizing Nearly Symmetric Actions","summary":"We study parameter-efficient image-to-video probing for the unaddressed\nchallenge of recognizing nearly symmetric actions - visually similar actions\nthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).\nExisting probing mechanisms for image-pretrained models, such as DinoV2 and\nCLIP, rely on attention mechanism for temporal modeling but are inherently\npermutation-invariant, leading to identical predictions regardless of frame\norder. To address this, we introduce Self-attentive Temporal Embedding Probing\n(STEP), a simple yet effective approach designed to enforce temporal\nsensitivity in parameter-efficient image-to-video transfer. STEP enhances\nself-attentive probing with three key modifications: (1) a learnable frame-wise\npositional encoding, explicitly encoding temporal order; (2) a single global\nCLS token, for sequence coherence; and (3) a simplified attention mechanism to\nimprove parameter efficiency. STEP outperforms existing image-to-video probing\nmechanisms by 3-15% across four activity recognition benchmarks with only 1/3\nof the learnable parameters. On two datasets, it surpasses all published\nmethods, including fully fine-tuned models. STEP shows a distinct advantage in\nrecognizing nearly symmetric actions, surpassing other probing mechanisms by\n9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code and\nmodels will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:42:38Z"}
{"aid":"http://arxiv.org/abs/2503.24314v1","title":"Impact of Synchronization Offsets and CSI Feedback Delay in Distributed\n  MIMO Systems","summary":"The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2503.24322v1","title":"NoProp: Training Neural Networks without Back-propagation or\n  Forward-propagation","summary":"The canonical deep learning approach for learning requires computing a\ngradient term at each layer by back-propagating the error signal from the\noutput towards each learnable parameter. Given the stacked structure of neural\nnetworks, where each layer builds on the representation of the layer below,\nthis approach leads to hierarchical representations. More abstract features\nlive on the top layers of the model, while features on lower layers are\nexpected to be less abstract. In contrast to this, we introduce a new learning\nmethod named NoProp, which does not rely on either forward or backwards\npropagation. Instead, NoProp takes inspiration from diffusion and flow matching\nmethods, where each layer independently learns to denoise a noisy target. We\nbelieve this work takes a first step towards introducing a new family of\ngradient-free learning methods, that does not learn hierarchical\nrepresentations -- at least not in the usual sense. NoProp needs to fix the\nrepresentation at each layer beforehand to a noised version of the target,\nlearning a local denoising process that can then be exploited at inference. We\ndemonstrate the effectiveness of our method on MNIST, CIFAR-10, and CIFAR-100\nimage classification benchmarks. Our results show that NoProp is a viable\nlearning algorithm which achieves superior accuracy, is easier to use and\ncomputationally more efficient compared to other existing back-propagation-free\nmethods. By departing from the traditional gradient based learning paradigm,\nNoProp alters how credit assignment is done within the network, enabling more\nefficient distributed learning as well as potentially impacting other\ncharacteristics of the learning process.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-03-31T17:08:57Z"}
{"aid":"http://arxiv.org/abs/2503.24330v1","title":"Quantum algorithms for cooling: a simple case study","summary":"Preparation of low-energy quantum many-body states has a wide range of\napplications in quantum information processing and condensed matter physics.\nQuantum cooling algorithms offer a promising alternative to other methods\nbased, for instance, on variational and adiabatic principles, or on dissipative\nstate preparation. In this work, we investigate a set of cooling algorithms in\na simple, solvable fermionic model which allows us to identify the mechanisms\nwhich underlie the cooling process and, also, those which prevent it. We derive\nanalytical expressions for the cooling dynamics, steady states, and cooling\nrates in the weak coupling limit. We find that multi-frequency and randomized\ncycle strategies can significantly enhance the performance of the quantum\nalgorithm and circumvent some of the obstacles. We also analyze the effects of\nnoise and evaluate the conditions under which cooling remains feasible.\nFurthermore, we present optimized cooling protocols that can significantly\nenhance cooling performance in the presence of noise. Additionally, we compare\ncooling and dissipative state preparation and show that, in the model analyzed\nhere, cooling generally achieves lower energies and is more resilient to noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:19:12Z"}
{"aid":"http://arxiv.org/abs/2503.24344v1","title":"Local basis for interacting topological bands","summary":"The discovery of correlated states in moire materials has challenged the\nestablished methods of projecting interactions into a local Wannier basis due\nto topological obstructions that manifest in extended interactions. This\ndifficulty can sometimes be evaded by decomposing the band into a basis of\nextended itinerant states and a lattice of local states, using the heavy\nfermion prescription. We revisit this framework by systematically identifying\nthe dominant interaction channels guided by the eigenvalues of the projected\ndensity operator. This approach can be applied both to tight-binding and\ncontinuum models, allowing us to identify a hierarchy in interaction scales\nthat can be universally used to reduce the Hilbert space dimension and\ndetermine an appropriate local basis for modeling electronic correlations in\ninteracting topological materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2503.24352v1","title":"CMS Token Transition","summary":"Within the LHC community, a momentous transition has been occurring in\nauthorization. For nearly 20 years, services within the Worldwide LHC Computing\nGrid (WLCG) have authorized based on mapping an identity, derived from an X.509\ncredential, or a group/role, derived from a VOMS extension issued by the\nexperiment. A fundamental shift is occurring to capabilities: the credential, a\nbearer token, asserts the authorizations of the bearer, not the identity. By\nthe HL-LHC era, the CMS experiment plans for the transition to tokens, based on\nthe WLCG Common JSON Web Token profile, to be complete. Services in the\ntechnology architecture include the INDIGO Identity and Access Management\nserver to issue tokens; a HashiCorp Vault server to store and refresh access\ntokens for users and jobs; a managed token bastion server to push credentials\nto the HTCondor CredMon service; and HTCondor to maintain valid tokens in\nlong-running batch jobs. We will describe the transition plans of the\nexperiment, current status, configuration of the central authorization server,\nlessons learned in commissioning token-based access with sites, and operational\nexperience using tokens for both job submissions and file transfers.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-03-31T17:34:56Z"}
{"aid":"http://arxiv.org/abs/2503.24355v1","title":"Modified cosmology though spacetime thermodynamics and generalized\n  mass-to-horizon entropy","summary":"In this work we apply the gravity-thermodynamics approach for the case of\ngeneralized mass-to-horizon entropy, which is a two-parameter extension of\nBekenstein-Hawking entropy that arises from the extended mass-to-horizon\nrelation, that is in turn required in order to have consistency with the\nClausius relation. We extract the modified Friedmann equations and we obtain an\neffective dark energy sector arising from the novel terms. We derive analytical\nsolutions for the dark energy density parameter, the dark energy\nequation-of-state parameter, and the deceleration parameter, and we show that\nthe Universe exhibits the usual thermal history with the succession of matter\nand dark energy epochs. Additionally, depending on the value of the entropy\nparameters, the dark energy equation-of-state parameter can either lie in the\nphantom regime at high redshifts entering into the quintessence regime at small\nredshifts, or it can lie in the quintessence regime at high redshifts and\nexperience the phantom-divide crossing at small redshifts, while in the far\nfuture in all cases it asymptotically obtains the cosmological constant value\n$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\ndatasets, showing that the scenario is in agreement with observations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-03-31T17:35:35Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24377v1","title":"Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for\n  Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24381v1","title":"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in\n  Autonomous Driving","summary":"We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.MA,cs.RO","published":"2025-03-31T17:59:24Z"}
{"aid":"http://arxiv.org/abs/2503.24390v1","title":"Intertwining bulk and surface: the case of UTe$_2$","summary":"UTe$_2$ has been the focus of numerous experimental and theoretical studies\nin recent years, as it is recognized as an odd-parity bulk superconductor. Its\nsurface has also been probed, revealing charge density wave (CDW), pair density\nwave (PDW), and time-reversal symmetry breaking (TRSB). In this work, we\npropose that the interplay between the order parameters observed on the surface\nand in the bulk of UTe$_2$ may be crucial in explaining some of the unusual\nfeatures detected by surface probes in this material. Through a\nphenomenological analysis, we can account for three distinctive experimental\nsignatures observed on the surface of UTe$_2$: i) the apparent suppression of\nCDW order at the upper critical field of the bulk superconducting state; ii)\nthe magnetic field-induced imbalance of the Fourier peaks associated with the\nCDW; iii) the onset of TRSB at the bulk superconducting critical temperature\nand its field-trainability. Furthermore, we propose specific experimental\nchecks to validate our conjecture, which we believe could be promptly achieved.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2503.24391v1","title":"Easi3R: Estimating Disentangled Motion from DUSt3R Without Training","summary":"Recent advances in DUSt3R have enabled robust estimation of dense point\nclouds and camera parameters of static scenes, leveraging Transformer network\narchitectures and direct supervision on large-scale 3D datasets. In contrast,\nthe limited scale and diversity of available 4D datasets present a major\nbottleneck for training a highly generalizable 4D model. This constraint has\ndriven conventional 4D methods to fine-tune 3D models on scalable dynamic video\ndata with additional geometric priors such as optical flow and depths. In this\nwork, we take an opposite path and introduce Easi3R, a simple yet efficient\ntraining-free method for 4D reconstruction. Our approach applies attention\nadaptation during inference, eliminating the need for from-scratch pre-training\nor network fine-tuning. We find that the attention layers in DUSt3R inherently\nencode rich information about camera and object motion. By carefully\ndisentangling these attention maps, we achieve accurate dynamic region\nsegmentation, camera pose estimation, and 4D dense point map reconstruction.\nExtensive experiments on real-world dynamic videos demonstrate that our\nlightweight attention adaptation significantly outperforms previous\nstate-of-the-art methods that are trained or finetuned on extensive dynamic\ndatasets. Our code is publicly available for research purpose at\nhttps://easi3r.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01320v1","title":"A link between covering and coefficient theorems for holomorphic\n  functions","summary":"Recently the author presented a new approach to solving the coefficient\nproblems for various classes of holomorphic functions $f(z) =\n\\sum\\limits_0^\\infty c_n z^n$, not necessarily univalent. This approach is\nbased on lifting the given polynomial coefficient functionals $J(f) =\nJ(c_{m_1}, \\dots, c_{m_s}), 2 < c_{m_1} < \\dots < c_{m_s} < \\infty$, onto the\nBers fiber space over universal Teichmuller space and applying the analytic and\ngeometric features of Teichm\\\"{u}ller spaces, especially the Bers isomorphism\ntheorem for Teichmuller spaces of punctured Riemann surfaces.\n  In this paper, we extend this approach to more general classes of functions.\nIn particular, this provides a strengthening of de Branges' theorem solving the\nBieberbach conjecture.","main_category":"math.CV","categories":"math.CV","published":"2025-04-02T03:12:22Z"}
{"aid":"http://arxiv.org/abs/2504.01321v1","title":"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\n  Tracking","summary":"Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T03:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.01324v1","title":"On Data Synthesis and Post-training for Visual Abstract Reasoning","summary":"This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T03:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.01335v1","title":"A remark on some punctual Quot schemes on smooth projective curves","summary":"For a locally free sheaf $\\mathcal{E}$ on a smooth projective curve, we can\ndefine the punctual Quot scheme which parametrizes torsion quotients of\n$\\mathcal{E}$ of length $n$ supported at a fixed point. It is known that the\npunctual Quot scheme is a normal projective variety with canonical Gorenstein\nsingularities. In this note, we show that the punctual Quot scheme is a\n$\\mathbb{Q}$-factorial Fano variety of Picard number one.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T03:43:27Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01341v1","title":"Uniform convergence to the equilibrium of the homogeneous\n  Boltzmann-Fermi-Dirac Equation with moderately soft potential","summary":"We concern the long-time behavior of mild solutions to the spatially\nhomogeneous Boltzmann--Fermi--Dirac equation with moderately soft potential.\nBased on the well-posedness results in [X-G. Lu, J. Stat. Phys., 105, (2001),\n353-388], we prove that the mild solution decays algebraically to the\nFermi--Dirac statistics with an explicit rate. Under the framework of the level\nset analysis by De Giorgi, we derive an $L^\\infty$ estimate which is uniform\nwith respect to the quantum parameter $\\varepsilon$. All quantitative estimates\nare independent of $\\varepsilon$, which implies that they also hold in the\nclassical limit, i.e., the Boltzmann equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T04:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.01353v1","title":"Subcritical Pitchfork Bifurcation Transition of a Single Nanoparticle in\n  Strong Confinement","summary":"Confinement influences fluid properties. We show, employing molecular\ndynamics simulations with explicit solvents, that slit confinement drives a\nfirst-order transition for a small nanoparticle between staying at the slit\ncenter and binding to the slit surfaces. The transition follows a subcritical\npitchfork bifurcation, accompanying a similar transition of the nanoparticle's\nlateral diffusion, depending on interparticle interactions and confinement\ninterfaces. Our findings underscore the necessity for advancing molecular\nhydrodynamics under strong confinement.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.chem-ph","published":"2025-04-02T04:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.01360v1","title":"A Bayesian approach for inverse potential problem with\n  topological-Gaussian prior","summary":"This paper addresses the reconstruction of a potential coefficient in an\nelliptic problem from distributed observations within the Bayesian framework.\nIn such problems, the selection of an appropriate prior distribution is\ncrucial, particularly when the function to be inferred exhibits sharp\ndiscontinuities, as traditional Gaussian priors often prove inadequate. To\ntackle this challenge, we develop the topological prior (TP), a new prior\nconstructed using persistent homology. The proposed prior utilizes persistent\npairs to characterize and record the topological variations of the functions\nunder reconstruction, thereby encoding prior information about the structure\nand discontinuities of the function. The TP prior, however, only exists in a\ndiscretized formulation, which leads to the absence of a well-defined posterior\nmeasure in function spaces. To resolve this issue, we propose a TP-Gaussian\nhybrid prior, where the TP component detects sharp discontinuities in the\nfunction, while the Gaussian distribution acts as a reference measure, ensuring\na well-defined posterior measure in the function space. The proposed TP prior\ndemonstrates effects similar to the classical total variation (TV) prior but\noffers greater flexibility and broader applicability due to three key\nadvantages. First, it is defined on a general topological space, making it\neasily adaptable to a wider range of applications. Second, the persistent\ndistance captures richer topological information compared to the discrete TV\nprior. Third, it incorporates more adjustable parameters, providing enhanced\nflexibility to achieve robust numerical results. These features make the TP\nprior a powerful tool for addressing inverse problems involving functions with\nsharp discontinuities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T05:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.01369v1","title":"LITE: LLM-Impelled efficient Taxonomy Evaluation","summary":"This paper presents LITE, an LLM-based evaluation method designed for\nefficient and flexible assessment of taxonomy quality. To address challenges in\nlarge-scale taxonomy evaluation, such as efficiency, fairness, and consistency,\nLITE adopts a top-down hierarchical evaluation strategy, breaking down the\ntaxonomy into manageable substructures and ensuring result reliability through\ncross-validation and standardized input formats. LITE also introduces a penalty\nmechanism to handle extreme cases and provides both quantitative performance\nanalysis and qualitative insights by integrating evaluation metrics closely\naligned with task objectives. Experimental results show that LITE demonstrates\nhigh reliability in complex evaluation tasks, effectively identifying semantic\nerrors, logical contradictions, and structural flaws in taxonomies, while\noffering directions for improvement. Code is available at\nhttps://github.com/Zhang-l-i-n/TAXONOMY_DETECT .","main_category":"cs.CL","categories":"cs.CL,cs.IR","published":"2025-04-02T05:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.01376v1","title":"On the dual structure of the Schrödinger dynamics","summary":"This paper elucidates the dual structure of the Schr\\\"{o}dinger dynamics in\ntwo correlated stages: (1) We first derive the real-valued Schr\\\"{o}dinger\nequation from scratch without referring to classical mechanics, wave mechanics,\nnor optics, and thereby attain a concrete and clear interpretation of the\nSchr\\\"{o}dinger (wave) function. Beginning with a factorization of the density\ndistribution function of the particles to two component vectors in\nconfiguration space, we impose very simple conditions on them such as\ntranslational invariance of space-time and the conservation of flux under a\ngiven potential function. A real-valued path-integral is formulated as a Green\nfunction for the real-valued Schr\\\"{o}dinger equation. (2) We then study a\nquantum stochastic path dynamics in a manner compatible with the\nSchr\\\"{o}dinger equation. The relation between them is like the Langevin\ndynamics with the diffusion equation. Each quantum path describes a\n\\textquotedblleft trajectory\\textquotedblright\\ in configuration space\nrepresenting, for instance, a singly launched electron in the double-slit\nexperiment that leaves a spot one by one at the measurement board, while\naccumulated spots give rise to the fringe pattern as predicted by the absolute\nsquare of the Schr\\\"{o}dinger function. We start from the relationship between\nthe Ito stochastic differential equation, the Feynman-Kac formula, and the\nassociated parabolic partial differential equations, to one of which\\ the\nSchr\\\"{o}dinger equation is transformed. The physical significance of the\nquantum intrinsic stochasticity and the indirect correlation among the quantum\npaths and so on are discussed. The self-referential nonlinear interrelationship\nbetween the Schr\\\"{o}dinger functions (regarded as a whole) and the quantum\npaths (as its parts) is identified as the ultimate mystery in quantum dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T05:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.01379v1","title":"DESIL: Detecting Silent Bugs in MLIR Compiler Infrastructure","summary":"MLIR (Multi-Level Intermediate Representation) compiler infrastructure\nprovides an efficient framework for introducing a new abstraction level for\nprogramming languages and domain-specific languages. It has attracted\nwidespread attention in recent years and has been applied in various domains,\nsuch as deep learning compiler construction. Recently, several MLIR compiler\nfuzzing techniques, such as MLIRSmith and MLIRod, have been proposed. However,\nnone of them can detect silent bugs, i.e., bugs that incorrectly optimize code\nsilently. The difficulty in detecting silent bugs arises from two main aspects:\n(1) UB-Free Program Generation: Ensures the generated programs are free from\nundefined behaviors to suit the non-UB assumptions required by compiler\noptimizations. (2) Lowering Support: Converts the given MLIR program into an\nexecutable form, enabling execution result comparisons, and selects a suitable\nlowering path for the program to reduce redundant lowering pass and improve the\nefficiency of fuzzing. To address the above issues, we propose DESIL. DESIL\nenables silent bug detection by defining a set of UB-elimination rules based on\nthe MLIR documentation and applying them to input programs to produce UB-free\nMLIR programs. To convert dialects in MLIR program into the executable form,\nDESIL designs a lowering path optimization strategy to convert the dialects in\ngiven MLIR program into executable form. Furthermore, DESIL incorporates the\ndifferential testing for silent bug detection. To achieve this, it introduces\nan operation-aware optimization recommendation strategy into the compilation\nprocess to generate diverse executable files. We applied DESIL to the latest\nrevisions of the MLIR compiler infrastructure. It detected 23 silent bugs and\n19 crash bugs, of which 12/14 have been confirmed or fixed","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T05:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.01391v1","title":"Enabling Continuous THz Band Coverage via Precise Electron Beam\n  Tailoring in Free-electron Lasers","summary":"High-power, continuously tunable narrowband terahertz (THz) sources are\nessential for advancing nonlinear optics, THz-driven material dynamics, and\nultrafast spectroscopy. Conventional techniques typically impose a trade-off\nbetween pulse energy and frequency tunability. Here, we introduce a novel\nfree-electron laser approach that overcomes these limitations by pre-modulating\na relativistic electron beam with a frequency-beating laser pulse and\nleveraging bunch compression along with collective effects to enhance\nmicrobunching. Experimental results demonstrate that this technique generates\nnarrowband THz emission with continuous frequency tunability from 7.8 to\n30.8THz, achieving pulse energies up to 385{\\mu}J while maintaining spectral\nbandwidths between 7.7% and 14.7%. Moreover, the method exhibits exceptional\nrobustness and scalability, highlighting its unique ability to bridge the\nlong-standing THz gap and offering a promising solution for diverse\ncutting-edge scientific applications.","main_category":"physics.acc-ph","categories":"physics.acc-ph,physics.optics","published":"2025-04-02T06:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.01395v1","title":"From Easy to Hard: Building a Shortcut for Differentially Private Image\n  Synthesis","summary":"Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T06:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.01405v1","title":"Teaching Robots to Handle Nuclear Waste: A Teleoperation-Based Learning\n  Approach<","summary":"This paper presents a Learning from Teleoperation (LfT) framework that\nintegrates human expertise with robotic precision to enable robots to\nautonomously perform skills learned from human operators. The proposed\nframework addresses challenges in nuclear waste handling tasks, which often\ninvolve repetitive and meticulous manipulation operations. By capturing\noperator movements and manipulation forces during teleoperation, the framework\nutilizes this data to train machine learning models capable of replicating and\ngeneralizing human skills. We validate the effectiveness of the LfT framework\nthrough its application to a power plug insertion task, selected as a\nrepresentative scenario that is repetitive yet requires precise trajectory and\nforce control. Experimental results highlight significant improvements in task\nefficiency, while reducing reliance on continuous operator involvement.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T06:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.01406v1","title":"A steady solution to the hydrodynamic equation and incommensurate\n  magnetization in a U(2) invariant superfluid","summary":"At the zero temperature limit, a one-dimensional steady solution to the\nhydrodynamic equation of a U(2) invariant superfluid is obtained. This solution\nreveals that the magnitude of magnetization is always directly proportional to\nthe particle number density. Furthermore, the problem can be interpreted as a\nparticle's motion in a central force field. It is demonstrated that the\nparticle's orbits are elliptical in shape, with a precession angle determined\nby a non-zero mass current. This suggests that the spatial periods of the three\ncomponent magnetizations are not commensurate. These findings indicate that the\ncoupling of mass superflow and magnetization distortions usually results in an\nincommensurate magnetization.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.01407v1","title":"TimeSearch: Hierarchical Video Search with Spotlight and Reflection for\n  Human-like Long Video Understanding","summary":"Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T06:47:19Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01445v1","title":"Enabling Systematic Generalization in Abstract Spatial Reasoning through\n  Meta-Learning for Compositionality","summary":"Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T07:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01451v1","title":"Dynamic Initialization for LiDAR-inertial SLAM","summary":"The accuracy of the initial state, including initial velocity, gravity\ndirection, and IMU biases, is critical for the initialization of LiDAR-inertial\nSLAM systems. Inaccurate initial values can reduce initialization speed or lead\nto failure. When the system faces urgent tasks, robust and fast initialization\nis required while the robot is moving, such as during the swift assessment of\nrescue environments after natural disasters, bomb disposal, and restarting\nLiDAR-inertial SLAM in rescue missions. However, existing initialization\nmethods usually require the platform to remain stationary, which is ineffective\nwhen the robot is in motion. To address this issue, this paper introduces a\nrobust and fast dynamic initialization method for LiDAR-inertial systems\n(D-LI-Init). This method iteratively aligns LiDAR-based odometry with IMU\nmeasurements to achieve system initialization. To enhance the reliability of\nthe LiDAR odometry module, the LiDAR and gyroscope are tightly integrated\nwithin the ESIKF framework. The gyroscope compensates for rotational distortion\nin the point cloud. Translational distortion compensation occurs during the\niterative update phase, resulting in the output of LiDAR-gyroscope odometry.\nThe proposed method can initialize the system no matter the robot is moving or\nstationary. Experiments on public datasets and real-world environments\ndemonstrate that the D-LI-Init algorithm can effectively serve various\nplatforms, including vehicles, handheld devices, and UAVs. D-LI-Init completes\ndynamic initialization regardless of specific motion patterns. To benefit the\nresearch community, we have open-sourced our code and test datasets on GitHub.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T08:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.01457v1","title":"Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object\n  Tracker","summary":"Multi-object tracking plays a crucial role in various applications, such as\nautonomous driving and security surveillance. This study introduces Deep\nLG-Track, a novel multi-object tracker that incorporates three key enhancements\nto improve the tracking accuracy and robustness. First, an adaptive Kalman\nfilter is developed to dynamically update the covariance of measurement noise\nbased on detection confidence and trajectory disappearance. Second, a novel\ncost matrix is formulated to adaptively fuse motion and appearance information,\nleveraging localization confidence and detection confidence as weighting\nfactors. Third, a dynamic appearance feature updating strategy is introduced,\nadjusting the relative weighting of historical and current appearance features\nbased on appearance clarity and localization accuracy. Comprehensive\nevaluations on the MOT17 and MOT20 datasets demonstrate that the proposed Deep\nLG-Track consistently outperforms state-of-the-art trackers across multiple\nperformance metrics, highlighting its effectiveness in multi-object tracking\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.01463v1","title":"Versatile silicon integrated photonic processor: a reconfigurable\n  solution for netx-generation AI clusters","summary":"The Artificial Intelligence models pose serious challenges in intensive\ncomputing and high-bandwidth communication for conventional electronic\ncircuit-based computing clusters. Silicon photonic technologies, owing to their\nhigh speed, low latency, large bandwidth, and complementary\nmetal-oxide-semiconductor compatibility, have been widely implemented for data\ntransfer and actively explored as photonic neural networks in AI clusters.\nHowever, current silicon photonic integrated chips lack adaptability for\nmultifuncional use and hardware-software systematic coordination. Here, we\ndevelop a reconfigurable silicon photonic processor with $40$ programmable unit\ncells integrating over $160$ component, which, to the best of our knowledge, is\nthe first to realize diverse functions with a chip for AI clusters, from\ncomputing acceleration and signal processing to network swtiching and secure\nencryption. Through a self-developed automated testing, compilation, and tuning\nframework to the processor without in-network monitoring photodetectors, we\nimplement $4\\times4$ dual-direction unitary and $3\\times3$ uni-direction\nnon-unitary matrix multiplications, neural networks for image recognition,\nmicro-ring modulator wavelength locking, $4\\times4$ photonic channel switching\n, and silicon photonic physical unclonable functions. This optoelectronic\nprocessing system, incorporating the photonic processor and its software stack,\npaves the way for both advanced photonic system-on-chip design and the\nconstruction of photo-electronic AI clusters.","main_category":"physics.optics","categories":"physics.optics,cs.AR","published":"2025-04-02T08:20:04Z"}
{"aid":"http://arxiv.org/abs/2504.01470v1","title":"Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for\n  Analyzing Mouth Inconsistencies","summary":"Deepfakes are AI-generated media in which the original content is digitally\naltered to create convincing but manipulated images, videos, or audio. Among\nthe various types of deepfakes, lip-syncing deepfakes are one of the most\nchallenging deepfakes to detect. In these videos, a person's lip movements are\nsynthesized to match altered or entirely new audio using AI models. Therefore,\nunlike other types of deepfakes, the artifacts in lip-syncing deepfakes are\nconfined to the mouth region, making them more subtle and, thus harder to\ndiscern. In this paper, we propose LIPINC-V2, a novel detection framework that\nleverages a combination of vision temporal transformer with multihead\ncross-attention to detect lip-syncing deepfakes by identifying spatiotemporal\ninconsistencies in the mouth region. These inconsistencies appear across\nadjacent frames and persist throughout the video. Our model can successfully\ncapture both short-term and long-term variations in mouth movement, enhancing\nits ability to detect these inconsistencies. Additionally, we created a new\nlip-syncing deepfake dataset, LipSyncTIMIT, which was generated using five\nstate-of-the-art lip-syncing models to simulate real-world scenarios. Extensive\nexperiments on our proposed LipSyncTIMIT dataset and two other benchmark\ndeepfake datasets demonstrate that our model achieves state-of-the-art\nperformance. The code and the dataset are available at\nhttps://github.com/skrantidatta/LIPINC-V2 .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:06Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01484v1","title":"Characteristic polynomial of generalized Ewens random permutations","summary":"We show the convergence of the characteristic polynomial for random\npermutation matrices sampled from the generalized Ewens distribution. Under\nthis distribution, the measure of a given permutation depends only on its cycle\nstructure, according to certain weights assigned to each cycle length. The\nproof is based on uniform control of the characteristic polynomial using\nresults from the singularity analysis of generating functions, together with\nthe convergence of traces to explicit random variables expressed via a Poisson\nfamily. The limit function is the exponential of a Poisson series which has\nalready appeared in the case of uniform permutation matrices. It is the Poisson\nanalog of the Gaussian Holomorphic Chaos, related to the limit of\ncharacteristic polynomials for other matrix models such as Circular Ensembles,\ni.i.d. matrices, and Gaussian elliptic matrices.","main_category":"math.CO","categories":"math.CO,math.PR,math.SP","published":"2025-04-02T08:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.01485v1","title":"Diameter Shortcut Sets on Temporal Graphs","summary":"Shortcut sets are a vital instrument for reducing the diameter of a static\ngraph and, consequently, its shortest path complexity, which is relevant in\nnumerous subfields of graph theory. We explore the notion of shortcut sets in\ntemporal graphs, which incorporate a discrete time model into the graph,\nrendering each edge accessible exclusively at specific points in time. This not\nonly alters the underlying assumptions of regular graphs but also substantially\nincreases the complexity of path problems and reachability. In turn, a temporal\ngraph is often a much more realistic and accurate representation of a\nreal-world network. In this thesis we provide a definition for a shortcut set\nin a temporal graph and explore differences to classic shortcut sets. Utilizing\nthis definition, we show that temporal and regular shortcut sets yield the same\nresults on temporal paths, enabling the application of existing construction\nalgorithms for static shortcut sets on paths. The primary contribution of this\nthesis is a translation approach for general temporal graphs that utilizes the\nstatic expansion of a temporal graph, allowing the conversion of static\nshortcut sets into temporal shortcut sets, yielding similar results.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T08:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.01488v1","title":"A Novel Pilot Allocation Technique for Uplink OFDMA in ISAC Systems","summary":"In integrated sensing and communication (ISAC) systems, pilot signals play a\ncrucial role in enhancing sensing performance due to their strong\nautocorrelation properties and high transmission power. However, conventional\ninterleaved pilots inherently constrain the maximum unambiguous range and\nreduce the accuracy of channel impulse response (CIR) estimation compared to\ncontinuous orthogonal frequency-division multiple access (OFDMA) signals. To\naddress this challenge, we propose a novel overlapped block-pilot structure for\nuplink OFDMA-based ISAC systems, called phase-shifted ISAC (PS-ISAC) pilot\nallocation. The proposed method leverages a cyclic prefix (CP)-based\nphase-shifted pilot design, enabling efficient multi-transmitter pilot\nseparation at the receiver. Simulation results confirm that the proposed scheme\nenhances CIR separation, reduces computational complexity, and improves mean\nsquare error (MSE) performance under practical power constraints. Furthermore,\nwe demonstrate that utilizing continuous pilot resources maximizes the\nunambiguous range.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T08:39:28Z"}
{"aid":"http://arxiv.org/abs/2504.01490v1","title":"Deep Learning-Driven Protein Structure Prediction and Design: Key Model\n  Developments by Nobel Laureates and Multi-Domain Applications","summary":"This systematic review outlines pivotal advancements in deep learning-driven\nprotein structure prediction and design, focusing on four core\nmodels-AlphaFold, RoseTTAFold, RFDiffusion, and ProteinMPNN-developed by 2024\nNobel Laureates in Chemistry: David Baker, Demis Hassabis, and John Jumper. We\nanalyze their technological iterations and collaborative design paradigms,\nemphasizing breakthroughs in atomic-level structural accuracy, functional\nprotein engineering, and multi-component biomolecular interaction modeling. Key\ninnovations include AlphaFold3's diffusion-based framework for unified\nbiomolecular prediction, RoseTTAFold's three-track architecture integrating\nsequence and spatial constraints, RFDiffusion's denoising diffusion for de novo\nprotein generation, and ProteinMPNN's inverse folding for sequence-structure\nco-optimization. Despite transformative progress in applications such as binder\ndesign, nanomaterials, and enzyme engineering, challenges persist in dynamic\nconformational sampling, multimodal data integration, and generalization to\nnon-canonical targets. We propose future directions, including hybrid\nphysics-AI frameworks and multimodal learning, to bridge gaps between\ncomputational design and functional validation in cellular environments.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-02T08:44:10Z"}
{"aid":"http://arxiv.org/abs/2504.01492v1","title":"Nagaoka ferromagnetism in semiconductor artificial graphene","summary":"We present the emergence of Nagaoka ferromagnetism in semiconductor-based\nartificial graphene using high-precision variational and diffusion Monte Carlo\nmethods, complemented by exact diagonalization calculations of the extended\nHubbard model. Specifically, we analyze a realistic model of an armchair\nhexagonal geometry comprising $42$ lattice sites, nanopatterned on GaAs quantum\nwells with nearest-neighbor distance of $a = 50$ nm. Our results reveal a\ndistinct magnetic phase transition near $U/t \\approx 60$ driven by the\nabsence/addition of a single electron at half-filling where the ferromagnetic\nphase is further stabilized by Coulomb scattering terms.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-02T08:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.01494v1","title":"Zariski-Closures of Linear Reflection Groups","summary":"We give necessary and sufficient conditions for a linear reflection group in\nthe sense of Vinberg to be Zariski-dense in the ambient projective general\nlinear group. As an application, we show that every irreducible right-angled\nCoxeter group of rank $N \\geq 3$ virtually embeds Zariski-densely in\n$\\mathrm{SL}_n(\\mathbb{Z})$ for all $n \\geq N$. This allows us to settle the\nexistence of Zariski-dense surface subgroups of $\\mathrm{SL}_n(\\mathbb{Z})$ for\nall $n \\geq 3$. Among the other applications are examples of Zariski-dense\none-ended finitely generated subgroups of $\\mathrm{SL}_n(\\mathbb{Z})$ that are\nnot finitely presented for all $n \\geq 6$.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-02T08:46:55Z"}
{"aid":"http://arxiv.org/abs/2504.01506v1","title":"MLKV: Efficiently Scaling up Large Embedding Model Training with\n  Disk-based Key-Value Storage","summary":"Many modern machine learning (ML) methods rely on embedding models to learn\nvector representations (embeddings) for a set of entities (embedding tables).\nAs increasingly diverse ML applications utilize embedding models and embedding\ntables continue to grow in size and number, there has been a surge in the\nad-hoc development of specialized frameworks targeted to train large embedding\nmodels for specific tasks. Although the scalability issues that arise in\ndifferent embedding model training tasks are similar, each of these frameworks\nindependently reinvents and customizes storage components for specific tasks,\nleading to substantial duplicated engineering efforts in both development and\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\ndata storage framework designed to address the scalability challenges in\nembedding model training, specifically data stall and staleness. MLKV augments\ndisk-based key-value storage by democratizing optimizations that were\npreviously exclusive to individual specialized frameworks and provides\neasy-to-use interfaces for embedding model training tasks. Extensive\nexperiments on open-source workloads, as well as applications in eBay's payment\ntransaction risk detection and seller payment risk detection, show that MLKV\noutperforms offloading strategies built on top of industrial-strength key-value\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01518v1","title":"On 2-color partitions where one of the colors is multiples of $7^k$","summary":"In this work, we investigate the arithmetic properties of $p_{1,7^k}(n)$,\nwhich counts 2-color partitions of $n$ where one of the colors appears only in\nparts that are multiples of $7^k$. By constructing generating functions for\n$p_{1,7^k}(n)$ across specific arithmetic progressions, we establish a set of\nRamanujan-type infinite family of congruences modulo powers of $7$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.01534v1","title":"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\n  Domain-Adaptive Pretraining and Match Metadata","summary":"The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01545v1","title":"$T_{cc}$ from finite volume energy levels: the left-hand cut problem and\n  its solution","summary":"Lattice QCD has become a crucial tool for studying hadron-hadron interactions\nfrom first principles. However, significant challenges arise when extracting\ninfinite-volume scattering parameters from finite-volume energy levels using\nthe conventional L\\\"uscher method, particularly due to the presence of\nleft-hand cuts induced by long-range interactions such as the one-pion\nexchange. To address these limitations, we propose a novel framework that\ncombines chiral effective field theory and the plane-wave expansion with the\nHamiltonian approach. By solving a Schr\\\"odinger-like equation in a finite\nvolume, this method establishes a connection between finite-volume energy\nspectra and infinite-volume physical quantities, while effectively handling\nissues caused by left-hand cuts. Furthermore, the adoption of a plane-wave\nbasis helps mitigating complexities associated with partial-wave mixing. Our\npreliminary numerical results at $m_\\pi \\approx 280$ MeV confirm that this\napproach efficiently overcomes the shortcomings of the L\\\"uscher method and\nindicate a resonant interpretation of the $T_{cc}(3875)$ state--in contrast to\nthe virtual state suggested in conventional analyses.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T09:34:10Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01566v1","title":"GPT Adoption and the Impact of Disclosure Policies","summary":"Generative Pre-trained Transformers (GPTs), particularly Large Language\nModels (LLMs) like ChatGPT, have proven effective in content generation and\nproductivity enhancement. However, legal risks associated with these tools lead\nto adoption variance and concealment of AI use within organizations. This study\nexamines the impact of disclosure on ChatGPT adoption in legal, audit and\nadvisory roles in consulting firms through the lens of agency theory. We\nconducted a survey experiment to evaluate agency costs in the context of\nunregulated corporate use of ChatGPT, with a particular focus on how mandatory\ndisclosure influences information asymmetry and misaligned interests. Our\nfindings indicate that in the absence of corporate regulations, such as an AI\npolicy, firms may incur agency costs, which can hinder the full benefits of GPT\nadoption. While disclosure policies reduce information asymmetry, they do not\nsignificantly lower overall agency costs due to managers undervaluing analysts'\ncontributions with GPT use. Finally, we examine the scope of existing\nregulations in Europe and the United States regarding disclosure requirements,\nexplore the sharing of risk and responsibility within firms, and analyze how\nincentive mechanisms promote responsible AI adoption.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-02T10:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.01578v1","title":"Entanglement in the symmetric subspace: mapping multipartite to\n  bipartite states","summary":"We propose a technique to investigate multipartite entanglement in the\nsymmetric subspace. Our approach is to map an $N$-qubit symmetric state onto a\nbipartite symmetric state of higher local dimension. We show that this mapping\npreserves separability and allows to characterize the entanglement of the\noriginal multipartite state. In particular, we provide several bounds to\nestimate the symmetric tensor rank and geometric measure of entanglement.\nAdditionally, we identify multipartite symmetric states whose entanglement\noutperforms that of previously known candidates for maximally entangled\nsymmetric states. Finally, we reveal the existence of entangled symmetric\nsubspaces, where all bipartite states are entangled.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.01586v1","title":"The gravity model for social systems","summary":"Gravity is one of the most prominent models used across various social areas,\nincluding economics, demography, mobility, politics, and other systems where\nspatial interactions are relevant. The model represents a flexible approach\nthat captures important regularities that might be detected when thousands or\nmillions of people are observed, i.e. bigger origins and bigger destinations\nincrease the intensity of interactions, but it tends to decay with longer\ndistances between them. Therefore, the number of interactions between two\nlocations is frequently modelled with an equation that resembles Newton's Law\nof Gravitation (also known as the Law of Gravity). Here, I explore different\naspects, i.e. essential components, techniques for estimating the parameters,\ninterpretation of results, and settings where gravity is a helpful tool,\nincluding mobility and migration.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T10:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01592v1","title":"Sub-second spin and lifetime-limited optical coherences in\n  $^{171}$Yb$^{3+}$:CaWO$_4$","summary":"Optically addressable solid-state spins have been extensively studied for\nquantum technologies, offering unique advantages for quantum computing,\ncommunication, and sensing. Advancing these applications is generally limited\nby finding materials that simultaneously provide lifetime-limited optical and\nlong spin coherences. Here, we introduce $^{171}$Yb$^{3+}$ ions doped into a\nCaWO$_4$ crystal. We perform high-resolution spectroscopy of the excited state,\nand demonstrate all-optical coherent control of the electron-nuclear spin\nensemble. We find narrow inhomogeneous broadening of the optical transitions of\n185 MHz and radiative-lifetime-limited coherence time up to 0.75 ms. Next to\nthis, we measure a spin-transition ensemble line width of 5 kHz and\nelectron-nuclear spin coherence time reaching 0.15 seconds at zero magnetic\nfield between 50 mK and 1 K temperatures. These results demonstrate the\npotential of $^{171}$Yb$^{3+}$:CaWO$_4$ as a low-noise platform for building\nquantum technologies with ensemble-based memories, microwave-to-optical\ntransducers, and optically addressable single-ion spin qubits.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.atom-ph","published":"2025-04-02T10:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01593v1","title":"Integrating experimental feedback improves generative models for\n  biological sequences","summary":"Generative probabilistic models have shown promise in designing artificial\nRNA and protein sequences but often suffer from high rates of false positives,\nwhere sequences predicted as functional fail experimental validation. To\naddress this critical limitation, we explore the impact of reintegrating\nexperimental feedback into the model design process. We propose a\nlikelihood-based reintegration scheme, which we test through extensive\ncomputational experiments on both RNA and protein datasets, as well as through\nwet-lab experiments on the self-splicing ribozyme from the group I intron RNA\nfamily where our approach demonstrates particular efficacy. We show that\nintegrating recent experimental data enhances the model's capacity of\ngenerating functional sequences (e.g. from 6.7\\% to 63.7\\% of active designs at\n45 mutations). This feedback-driven approach thus provides a significant\nimprovement in the design of biomolecular sequences by directly tackling the\nfalse-positive challenge.","main_category":"q-bio.BM","categories":"q-bio.BM,physics.bio-ph,q-bio.QM","published":"2025-04-02T10:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01601v1","title":"Binding energy of $^{3}_Λ\\rm{H}$ and $^{4}_Λ\\rm{H}$ via\n  image analyses of nuclear emulsions using deep-learning","summary":"Subatomic systems are pivotal for understanding fundamental baryonic\ninteractions, as they provide direct access to quark-level degrees of freedom.\nIn particular, introducing a strange quark adds \"strangeness\" as a new\ndimension, offering a powerful tool for exploring nuclear forces. The\nhypertriton, the lightest three-body hypernuclear system, provides an ideal\ntesting ground for investigating baryonic interactions and quark behavior\ninvolving up, down, and strange quarks. However, experimental measurements of\nits lifetime and binding energy, key indicators of baryonic interactions, show\nsignificant deviations in results obtained from energetic collisions of\nheavy-ion beams. Identifying alternative pathways for precisely measuring the\nhypertriton's binding energy and lifetime is thus crucial for advancing\nexperimental and theoretical nuclear physics. Here, we present an experimental\nstudy on the binding energies of $^3_{\\Lambda}\\mathrm{H}$ (hypertriton) and\n$^4_{\\Lambda}\\mathrm{H}$, performed through the analysis of photographic\nnuclear emulsions using modern techniques. By incorporating deep-learning\nmethods, we uncovered systematic uncertainties in conventional nuclear emulsion\nanalyses and established a refined calibration protocol for determining binding\nenergies accurately. Our results are independent of those obtained from\nheavy-ion collision experiments, offering a complementary measurement and\nopening new avenues for investigating few-body hypernuclei interactions.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-02T11:08:40Z"}
{"aid":"http://arxiv.org/abs/2504.01608v1","title":"The Mini-SiTian Array: real-bogus classification using deep learning","summary":"The Mini-SiTian (MST) project is a pathfinder for China's next-generation\nlarge-scale time-domain survey, SiTian, aimed at discovering variable stars,\ntransients, and explosive events. MST generates hundreds of thousands of\ntransient alerts every night, approximately 99\\% of which are false alarms,\nposing a significant challenge to its scientific goals. To mitigate the impact\nof false positives, we propose a deep learning-based solution and\nsystematically evaluate thirteen convolutional neural networks. The results\nshow that ResNet achieves exceptional specificity (99.70\\%),\n  EfficientNet achieves the highest recall rate (98.68\\%), and DenseNet\nprovides balanced performance with a recall rate of 94.55\\% and specificity of\n98.66\\%. Leveraging these complementary strengths, we developed a bagging-based\nensemble classifier that integrates ResNet18, DenseNet121, and EfficientNet\\_B0\nusing a soft voting strategy. This classifier achieved the best AUC value\n(0.9961) among all models, with a recall rate of 95.37\\% and specificity of\n99.25\\%. It has now been successfully deployed in the MST real-time data\nprocessing pipeline. Validation using 5,000 practically processed samples with\na classification threshold of 0.798 showed that the classifier achieved 88.31\\%\naccuracy, 91.89\\% recall rate, and 99.82\\% specificity, confirming its\neffectiveness and robustness under real application conditions.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.01615v1","title":"The Mini-SiTian Array: A Pathfinder for the SiTian Project","summary":"The Mini-SiTian Array serves as a pathfinder for the SiTian project, which\naims to survey the entire sky in $gri$ bands every 30 minutes, reaching a\nlimiting magnitude of 21. This special issue features 11 papers covering the\ndesign, operation, data reduction, and early scientific results from two years\nof Mini-SiTian observations. The insights gained from these pathfinder\nexperiments represent a significant milestone toward the full realization of\nthe SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.01621v1","title":"Two-photon microscopy using picosecond pulses from four-wave mixing in a\n  Yb-doped photonic crystal fiber","summary":"Two-photon microscopy (TPM) enables deep tissue imaging but requires\nexcitation pulses that have a large product of average and peak power,\ntypically supplied by femtosecond solid-state lasers. However, these lasers are\nbulky and femtosecond pulses require careful dispersion management to avoid\npulse broadening, particularly when delivery fibers are used. Here we present a\ncompact, fiber-based picosecond laser source operating at 790 nm for TPM using\na ytterbium-doped photonic crystal fiber (Yb-doped PCF). The Yb-doped PCF\nsimultaneously amplifies 1064 nm input pulses and efficiently converts them to\n790 nm via four-wave mixing, generating pulses with a peak power of up to ~3.8\nkW. The source has a variable repetition rate (1.48 MHz-14.78 MHz), enabling\nthe two-photon excitation fluorescence signal to be maximized in the presence\nof excitation saturation. We benchmark our picosecond laser source against a\nfemtosecond Ti:Sapphire laser for TPM of stained Convallaria majalis samples\nand demonstrate comparable fluorescence signal when the two-photon excitation\nconditions are matched.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.01622v1","title":"Higgs-Modular Inflation","summary":"We investigate the role of the Higgs field as a fundamental scalar in the\nStandard Model within the framework of modular inflation models, where a\nmodulus field acts as the inflaton and its interactions are governed by an\nunderlying modular symmetry. In general, the Higgs field can participate in the\ndynamics of modular inflation, leading to a two-field inflationary\nsystem-termed \\emph{Higgs-Modular inflation}-which exhibits non-trivial\ndynamics and interesting phenomenological implications. We analyze\nHiggs-Modular inflation both analytically and numerically, highlighting its\nattractor behavior and the resulting observational constraints. In particular,\nwe find that Higgs-Modular inflation is favored by the latest data release from\nthe Atacama Cosmology Telescope (ACT) in certain regions of parameter space.\nThis is in contrast to both pure Higgs inflation and pure modular inflation\nwith a Starobinsky-type potential, which tend to predict a relatively low\nspectral index. Additionally, we discuss the cutoff scale of this inflationary\nmodel and the reheating processes induced by the decays of the modulus and the\nHiggs field.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-02T11:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.01642v1","title":"Spanning clique subdivisions in pseudorandom graphs","summary":"In this paper, we study the appearance of a spanning subdivision of a clique\nin graphs satisfying certain pseudorandom conditions. Specifically, we show the\nfollowing three results. Firstly, that there are constants $C>0$ and $c\\in\n(0,1]$ such that, whenever $d/\\lambda\\ge C$, every $(n,d,\\lambda)$-graph\ncontains a spanning subdivision of $K_t$ for all $2\\le t \\le\n\\min\\{cd,c\\sqrt{\\frac{n}{\\log n}}\\}$. Secondly, that there are constants $C>0$\nand $c\\in (0,1]$ such that, whenever $d/\\lambda\\ge C\\log^3n$, every\n$(n,d,\\lambda)$-graph contains a spanning nearly-balanced subdivision of $K_t$\nfor all $2\\le t \\le \\min\\{cd,c\\sqrt{\\frac{n}{\\log^3n}}\\}$. Finally, we show\nthat for every $\\mu>0$, there are constants $c,\\varepsilon\\in (0,1]$ and\n$n_0\\in \\mathbb N$ such that, whenever $n\\ge n_0$, every $n$-vertex graph with\nminimum degree at least $\\mu n$ and no bipartite holes of size $\\varepsilon n$\ncontains a spanning nearly-balanced subdivision of $K_t$ for all $2\\le t \\le\nc\\sqrt{n}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T11:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.01653v1","title":"Quasinormal Modes and Stability Analysis of the JMN-1 Naked Singularity","summary":"In this paper, we perform a comprehensive analysis of the quasinormal modes\nin the Joshi-Malafarina-Narayan (JMN-1) naked singularity by investigating its\nresponse to linear perturbations, including scalar, electromagnetic, and\ngravitational perturbations. To analyze the stability of the JMN-1 naked\nsingularity under axial perturbations, we compute the quasinormal mode\nfrequencies using the Wentzel-Kramers-Brillouin method. The quasinormal mode\nfrequencies provides information about the stability of spacetime, with the\nreal part of the frequency determining the oscillation rate and the imaginary\npart governing the decay or growth of perturbations. Our results indicate that\nby imposing appropriate boundary conditions, we find that the JMN-1 spacetime\nremains dynamically stable under axial perturbations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.GA,astro-ph.HE","published":"2025-04-02T12:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.01666v1","title":"CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign\n  Language Recognition","summary":"Continuous sign language recognition (CSLR) focuses on interpreting and\ntranscribing sequences of sign language gestures in videos. In this work, we\npropose CLIP sign language adaptation (CLIP-SLA), a novel CSLR framework that\nleverages the powerful pre-trained visual encoder from the CLIP model to sign\nlanguage tasks through parameter-efficient fine-tuning (PEFT). We introduce two\nvariants, SLA-Adapter and SLA-LoRA, which integrate PEFT modules into the CLIP\nvisual encoder, enabling fine-tuning with minimal trainable parameters. The\neffectiveness of the proposed frameworks is validated on four datasets:\nPhoenix2014, Phoenix2014-T, CSL-Daily, and Isharah-500, where both CLIP-SLA\nvariants outperformed several SOTA models with fewer trainable parameters.\nExtensive ablation studies emphasize the effectiveness and flexibility of the\nproposed methods with different vision-language models for CSLR. These findings\nshowcase the potential of adapting large-scale pre-trained models for scalable\nand efficient CSLR, which pave the way for future advancements in sign language\nunderstanding.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01678v1","title":"Second-order cone programming for distributionally robust compliance\n  optimization of trusses considering input distribution uncertainty","summary":"Reliability-based design optimization (RBDO) is a methodology for designing\nstructures under the consideration for uncertainty with the assumption that the\ninput distribution is completely known. In practical engineering, the number of\ninput data is often limited, which can damage the validity of the optimal\nresults obtained by RBDO. Confidence-based design optimization (CBDO) has been\nproposed to account for the uncertainty of the input distribution. However,\nthis approach faces challenges, computational cost and accuracy when dealing\nwith highly nonlinear performance constraints. In this paper, we consider the\ncompliance minimization problem of truss structures with uncertain external\nforces. Armed with the advanced risk measure, conditional Value-at-Risk (CVaR),\nwe formulate a bi-objective optimization problem for the worst-case expected\nvalue and the worst-case CVaR of compliance, which allows us to account for the\ntail risk of performance functions not addressed in CBDO. Employing kernel\ndensity estimation for estimation of the input distribution allows us to\neliminate the need for modeling the input distribution. We show that this\nproblem reduces to a second-order cone programming when assigning either\nuniform kernel or triangular kernel. Finally, through numerical experiments, we\nobtain the Pareto front for the bi-objective optimization problem of the\nworst-case expected value and CVaR of compliance of truss structures, and\nconfirm the changes in the Pareto solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T12:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.01694v1","title":"Iterative Interpolation Schedules for Quantum Approximate Optimization\n  Algorithm","summary":"Quantum Approximate Optimization Algorithm (QAOA) is a promising quantum\noptimization heuristic with empirical evidence of speedup over classical\nstate-of-the-art for some problems. QAOA solves optimization problems using a\nparameterized circuit with $p$ layers, with higher $p$ leading to better\nsolutions. Existing methods require optimizing $2p$ independent parameters\nwhich is challenging for large $p$. In this work, we present an iterative\ninterpolation method that exploits the smoothness of optimal parameter\nschedules by expressing them in a basis of orthogonal functions, generalizing\nZhou et al. By optimizing a small number of basis coefficients and iteratively\nincreasing both circuit depth and the number of coefficients until convergence,\nour approach enables construction of high-quality schedules for large $p$. We\ndemonstrate our method achieves better performance with fewer optimization\nsteps than current approaches on three problems: the Sherrington-Kirkpatrick\n(SK) model, portfolio optimization, and Low Autocorrelation Binary Sequences\n(LABS). For the largest LABS instance, we achieve near-optimal merit factors\nwith schedules exceeding 1000 layers, an order of magnitude beyond previous\nmethods. As an application of our technique, we observe a mild growth of QAOA\ndepth sufficient to solve SK model exactly, a result of independent interest.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-02T12:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.01702v1","title":"A Causal Inference Framework for Data Rich Environments","summary":"We propose a formal model for counterfactual estimation with unobserved\nconfounding in \"data-rich\" settings, i.e., where there are a large number of\nunits and a large number of measurements per unit. Our model provides a bridge\nbetween the structural causal model view of causal inference common in the\ngraphical models literature with that of the latent factor model view common in\nthe potential outcomes literature. We show how classic models for potential\noutcomes and treatment assignments fit within our framework. We provide an\nidentification argument for the average treatment effect, the average treatment\neffect on the treated, and the average treatment effect on the untreated. For\nany estimator that has a fast enough estimation error rate for a certain\nnuisance parameter, we establish it is consistent for these various causal\nparameters. We then show principal component regression is one such estimator\nthat leads to consistent estimation, and we analyze the minimal smoothness\nrequired of the potential outcomes function for consistency.","main_category":"econ.EM","categories":"econ.EM,cs.LG,stat.ME","published":"2025-04-02T13:04:26Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01711v1","title":"Exact Borel subalgebras of tensor algebras of quasi-hereditary algebras","summary":"Given two quasi-hereditary algebras, their tensor product is\nquasi-hereditary. In this article, we show that given two exact Borel\nsubalgebras for these quasi-hereditary algebras, their tensor product is an\nexact Borel subalgebra. Moreover, we describe in which cases the tensor product\nof two regular exact Borel subalgebras is again regular. Additionally, we\ninvestigate tensor algebras of generalised species of quasi-hereditary algebras\nand exact Borel subalgebras thereof.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T13:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.01733v1","title":"Epistemic Skills: Reasoning about Knowledge and Oblivion","summary":"This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.","main_category":"cs.AI","categories":"cs.AI,cs.CC,cs.LO","published":"2025-04-02T13:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.01738v1","title":"Style over Substance: Distilled Language Models Reason Via Stylistic\n  Replication","summary":"Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T13:50:20Z"}
{"aid":"http://arxiv.org/abs/2504.01742v1","title":"Doctor: Optimizing Container Rebuild Efficiency by Instruction\n  Re-Orchestration","summary":"Containerization has revolutionized software deployment, with Docker leading\nthe way due to its ease of use and consistent runtime environment. As Docker\nusage grows, optimizing Dockerfile performance, particularly by reducing\nrebuild time, has become essential for maintaining efficient CI/CD pipelines.\nHowever, existing optimization approaches primarily address single builds\nwithout considering the recurring rebuild costs associated with modifications\nand evolution, limiting long-term efficiency gains. To bridge this gap, we\npresent Doctor, a method for improving Dockerfile build efficiency through\ninstruction re-ordering that addresses key challenges: identifying instruction\ndependencies, predicting future modifications, ensuring behavioral equivalence,\nand managing the optimization computational complexity. We developed a\ncomprehensive dependency taxonomy based on Dockerfile syntax and a historical\nmodification analysis to prioritize frequently modified instructions. Using a\nweighted topological sorting algorithm, Doctor optimizes instruction order to\nminimize future rebuild time while maintaining functionality. Experiments on\n2,000 GitHub repositories show that Doctor improves 92.75% of Dockerfiles,\nreducing rebuild time by an average of 26.5%, with 12.82% of files achieving\nover a 50% reduction. Notably, 86.2% of cases preserve functional similarity.\nThese findings highlight best practices for Dockerfile management, enabling\ndevelopers to enhance Docker efficiency through informed optimization\nstrategies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T13:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.01752v1","title":"A Two-Timescale Approach for Wireless Federated Learning with Parameter\n  Freezing and Power Control","summary":"Federated learning (FL) enables distributed devices to train a shared machine\nlearning (ML) model collaboratively while protecting their data privacy.\nHowever, the resource-limited mobile devices suffer from intensive\ncomputation-and-communication costs of model parameters. In this paper, we\nobserve the phenomenon that the model parameters tend to be stabilized long\nbefore convergence during training process. Based on this observation, we\npropose a two-timescale FL framework by joint optimization of freezing\nstabilized parameters and controlling transmit power for the unstable\nparameters to balance the energy consumption and convergence. First, we analyze\nthe impact of model parameter freezing and unreliable transmission on the\nconvergence rate. Next, we formulate a two-timescale optimization problem of\nparameter freezing percentage and transmit power to minimize the model\nconvergence error subject to the energy budget. To solve this problem, we\ndecompose it into parallel sub-problems and decompose each sub-problem into two\ndifferent timescales problems using the Lyapunov optimization method. The\noptimal parameter freezing and power control strategies are derived in an\nonline fashion. Experimental results demonstrate the superiority of the\nproposed scheme compared with the benchmark schemes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T14:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.01767v1","title":"Leveraging Embedding Techniques in Multimodal Machine Learning for\n  Mental Illness Assessment","summary":"The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CV","published":"2025-04-02T14:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.01768v1","title":"Updating the Ephemeris and Physical Properties of Five Long-period\n  Transiting Exoplanets Using TESS and CHEOPS","summary":"The transiting long-period exoplanets are the most interesting follow-up\ntargets for the next-generation instruments, using the most sophisticated\nobservational techniques. However, the scarcity in their transit events often\nleads to larger uncertainties in their known ephemeris, also resulting in\nlarger biases in their known physical properties in many cases. In this work, I\nhave used the newer publicly available observations from TESS and CHEOPS for\nfive very interesting long-period transiting exoplanets, i.e., HD95338 b,\nTOI-2134 c, K2-290 c, TOI-1898 b, and TOI-813 b, combined with the previously\nreported observations, to reanalyze their transit properties and estimate the\nupdated ephemeris. The analyses also incorporated a critical noise treatment\nalgorithm, which uses well-tested techniques such as wavelet denoising and\nGaussian process regression, to effectively reduce the impact of various noise\ncomponents present in the lightcurves on the estimated parameters. The study\nhas resulted in a more precise estimation of ephemeris for all the targets,\nwith the precision in the estimated periods being better than 5 seconds, except\nfor TOI-813 b, for which the precision in the estimated period is better than\n21 seconds. The other transit parameters also got updated, with statistically\nsignificant improvements seen in most of the cases, the major notable\nimprovements being in the estimated value of the impact parameter of TOI-1898\nb, the orbital semi-major axis of TOI-2134 c, and the radius of HD95338 b.\nAlthough long-period exoplanets are expected to show more significant transit\ntiming variations in the presence of other undetected planetary mass objects,\nno such variations were recorded for these targets.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T14:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01781v1","title":"Proper scoring rules for estimation and forecast evaluation","summary":"Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-02T14:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.01782v1","title":"Tensor free probability theory: asymptotic tensor freeness and central\n  limit theorem","summary":"Voiculescu's notion of asymptotic free independence applies to a wide range\nof random matrices, including those that are independent and unitarily\ninvariant. In this work, we generalize this notion by considering random\nmatrices with a tensor product structure that are invariant under the action of\nlocal unitary matrices. Assuming the existence of the \\emph{tensor\ndistribution} limit described by tuples of permutations, we show that an\nindependent family of local unitary invariant random matrices satisfies\nasymptotically a novel form of freeness, which we term \\emph{tensor freeness}.\nIt can be defined via the vanishing of mixed \\emph{tensor free cumulants},\nallowing the joint tensor distribution of tensor free elements to be described\nin terms of that of individual elements. We present several applications of\nthese results in the context of random matrices with a tensor product\nstructure, such as partial transpositions of (local) unitarily invariant random\nmatrices and tensor embeddings of random matrices. Furthermore, we propose a\ntensor free version of the central limit theorem, which extends and recovers\nseveral previous results for tensor products of free variables.","main_category":"math.OA","categories":"math.OA,math-ph,math.MP,math.PR","published":"2025-04-02T14:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.01787v1","title":"The Factors Influencing Well-Being in Software Engineers: A\n  Cross-Country Mixed-Method Study","summary":"The well-being of software engineers is increasingly under strain due to the\nhigh-stress nature of their roles, which involve complex problem-solving, tight\ndeadlines, and the pressures of rapidly evolving technologies.\n  Despite increasing recognition of mental health challenges in software\nengineering, few studies focus on the factors that sustain or undermine\nwell-being. Existing research often overlooks the interaction between personal,\ncollaborative, and organisational influences on this unique population. This\nstudy fills this gap by investigating the specific factors affecting the\nwell-being of software engineers. We conducted 15 qualitative interviews and\ncomplemented them with a confirmatory cross-country survey to validate and\nextend our findings to a broader population. Our mixed-methods approach\nprovides a robust framework to identify key factors influencing well-being,\nincluding personal perceptions of well-being, interpersonal and collaborative\ndynamics, workplace support and recognition, organisational culture, and\nspecific stressors inherent to software engineering.\n  By offering a detailed, context-specific exploration of these factors, our\nstudy builds on existing literature and provides actionable insights for\nimproving well-being in software engineering. We conclude with policy\nrecommendations to inform organisational strategies and develop targeted\ninterventions that address the specific challenges of this field, contributing\nto more sustainable and supportive work environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T14:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.01798v1","title":"A Novel Approach To Implementing Knowledge Distillation In Tsetlin\n  Machines","summary":"The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-02T15:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.01808v1","title":"Coloring of graphs without long odd holes","summary":"A {\\em hole} is an induced cycle of length at least 4, a $k$-hole is a hole\nof length $k$, and an {\\em odd hole} is a hole of odd length. Let $\\ell\\ge 2$\nbe an integer. Let ${\\cal A}_{\\ell}$ be the family of graphs of girth at least\n$2\\ell$ and having no odd holes of length at least $2\\ell+3$, let ${\\cal\nB}_{\\ell}$ be the triangle-free graphs which have no 5-holes and no odd holes\nof length at least $2\\ell+3$, and let ${\\cal G}_{\\ell}$ be the family of graphs\nof girth $2\\ell+1$ and have no odd hole of length at least $2\\ell+5$.\nChudnovsky {\\em et al.} \\cite{CSS2016} proved that every graph in ${\\cal\nA}_{2}$ is 58000-colorable, and every graph in ${\\cal B}_{\\ell}$ is\n$(\\ell+1)4^{\\ell-1}$-colorable. Lan and liu \\cite{LL2023} showed that for\n$\\ell\\geq3$, every graph in ${\\cal G}_{\\ell}$ is 4-colorable. It is not known\nwhether there exists a small constant $c$ such that graphs of ${\\cal G}_2$ are\n$c$-colorable. In this paper, we show that every graph in ${\\cal G}_2$ is\n1456-colorable, and every graph in ${\\cal A}_{3}$ is 4-colorable. We also show\nthat every 7-hole free graph in ${\\cal B}_{\\ell}$ is $(12\\ell+8)$-colorable.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T15:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.01815v1","title":"Multiplexed Control at Scale for Electrode Arrays in Trapped-Ion Quantum\n  Processors","summary":"The scaling up of trapped-ion quantum processors based on the quantum\ncharge-coupled device (QCCD) architecture is difficult owing to the extensive\nelectronics and high-density wiring required to control numerous trap\nelectrodes. In conventional QCCD architectures, each trap electrode is\ncontrolled via a dedicated digital-to-analog converter (DAC). The conventional\napproach places an overwhelming demand on electronic resources and wiring\ncomplexity. This is because the number of trap electrodes typically exceeds the\nnumber of trapped-ion qubits. This study proposes a method that leverages a\nhigh-speed DAC to generate time-division multiplexed signals to control a\nlarge-scale QCCD trapped-ion quantum processor. The proposed method replaces\nconventional DACs with a single high-speed DAC that generates the complete\nvoltage waveforms required to control the trap electrodes, thereby\nsignificantly reducing the wiring complexity and overall resource requirements.\nBased on realistic parameters and commercially available electronics, our\nanalysis demonstrates that a QCCD trapped-ion quantum computer with 10,000 trap\nelectrodes can be controlled using only 13 field-programmable gate arrays and\n104 high-speed DACs. This is in stark contrast to the 10,000 dedicated DACs\nrequired by conventional control methods. Consequently, employing this\napproach, we developed a proof-of-concept electronic system and evaluated its\nanalog output performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T15:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.01817v1","title":"Multi-actuator lens systems for turbulence correction in free-space\n  optical communications","summary":"The implementation of efficient free-space channels is fundamental for both\nclassical and quantum Free-Space Optical (FSO) communication. This can be\nchallenging for fibre-coupled receivers, due to the time variant inhomogeneity\nof the refractive index that can cause strong fluctuations in the power coupled\ninto the Single-Mode Fiber (SMF), and requires the use of Adaptive Optics (AO)\nsystems to correct the atmospheric induced aberrations. In this work, we\npresent two adaptive optic systems, one using a Fast-Steering Prism (FSP) for\nthe correction of tip-tilt and a second one based on a Multi-Actuator\ndeformable Lens (MAL), capable of correcting up to the third order of Zernike's\npolynomials. We test both systems at telecom wavelength both with artificial\nturbulence in the laboratory and on a free-space channel, demonstrating their\neffectiveness in increasing the fibre coupling efficiency.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T15:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.01827v1","title":"What is AI, what is it not, how we use it in physics and how it\n  impacts... you","summary":"Artificial Intelligence (AI) and Machine Learning (ML) have been prevalent in\nparticle physics for over three decades, shaping many aspects of High Energy\nPhysics (HEP) analyses. As AI's influence grows, it is essential for physicists\n$\\unicode{x2013}$ as both researchers and informed citizens $\\unicode{x2013}$\nto critically examine its foundations, misconceptions, and impact. This paper\nexplores AI definitions, examines how ML differs from traditional programming,\nand provides a brief review of AI/ML applications in HEP, highlighting\npromising trends such as Simulation-Based Inference, uncertainty-aware machine\nlearning, and Fast ML for anomaly detection. Beyond physics, it also addresses\nthe broader societal harms of AI systems, underscoring the need for responsible\nengagement. Finally, it stresses the importance of adapting research practices\nto an evolving AI landscape, ensuring that physicists not only benefit from the\nlatest tools but also remain at the forefront of innovation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.LG,hep-ex","published":"2025-04-02T15:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.01831v1","title":"Shape Theory via the Atiyah--Molino Reconstruction and Deformations","summary":"Reconstruction problems lie at the very heart of both mathematics and\nscience, posing the enigmatic challenge: \\emph{How does one resurrect a hidden\nstructure from the shards of incomplete, fragmented, or distorted data?} In\nthis paper, we introduce a new approach that harnesses the profound insights of\nthe Vaisman Atiyah--Molino framework. Our method renders the reconstruction\nproblem computationally tractable while exhibiting exceptional robustness in\nthe presence of noise. Central to our theory is the Hantjies tensor -- a\ncurvature-like invariant that precisely quantifies noise propagation and\nenables error-bounded reconstructions. This synthesis of differential geometry,\nintegral analysis, and algebraic topology not only resolves long-standing\nambiguities in inverse problems but also paves the way for transformative\napplications across a broad spectrum of scientific disciplines.","main_category":"math.DG","categories":"math.DG","published":"2025-04-02T15:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $δ$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01842v1","title":"shapr: Explaining Machine Learning Models with Conditional Shapley\n  Values in R and Python","summary":"This paper introduces the shapr package, a versatile tool for generating\nShapley value explanations for machine learning and statistical regression\nmodels in both R and Python. The package emphasizes conditional Shapley value\nestimates, providing a comprehensive range of approaches for accurately\ncapturing feature dependencies, which is crucial for correct model\ninterpretation and lacking in similar software. In addition to regular tabular\ndata, the shapr R-package includes specialized functionality for explaining\ntime series forecasts. The package offers a minimal set of user functions with\nsensible defaults for most use cases while providing extensive flexibility for\nadvanced users to fine-tune computations. Additional features include\nparallelized computations, iterative estimation with convergence detection, and\nrich visualization tools. shapr also extends its functionality to compute\ncausal and asymmetric Shapley values when causal information is available. In\naddition, we introduce the shaprpy Python library, which brings core\ncapabilities of shapr to the Python ecosystem. Overall, the package aims to\nenhance the interpretability of predictive models within a powerful and\nuser-friendly framework.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-04-02T15:47:30Z"}
{"aid":"http://arxiv.org/abs/2504.01843v1","title":"Towards Compatibly Mitigating Technical Lag in Maven Projects","summary":"Library reuse is a widely adopted practice in software development, however,\nre-used libraries are not always up-to-date, thus including unnecessary bugs or\nvulnerabilities. Brutely upgrading libraries to the latest versions is not\nfeasible because breaking changes and bloated dependencies could be introduced,\nwhich may break the software project or introduce maintenance efforts.\nTherefore, balancing the technical lag reduction and the prevention of newly\nintroduced issues are critical for dependency management. To this end, LagEase\nis introduced as a novel tool designed to address the challenges of mitigating\nthe technical lags and avoid incompatibility risks and bloated dependencies.\nExperimental results show that LagEase outperforms Dependabot, providing a more\neffective solution for managing Maven dependencies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T15:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.01846v1","title":"Many neighbors little entanglement: A curious scaling in the\n  variable-range extended Ising model","summary":"We study the two-point correlation functions and the bipartite entanglement\nin the ground state of the exactly-solvable variable-range extended Ising model\nof qubits in the presence of a transverse field on a one-dimensional lattice.\nWe introduce the variation in the range of interaction by varying the\ncoordination number, $\\mathcal{Z}$, of each qubit, where the interaction\nstrength between a pair of qubits at a distance $r$ varies as $\\sim\nr^{-\\alpha}$. We show that the algebraic nature of the correlation functions is\npresent only up to $r=\\mathcal{Z}$, above which it exhibits short-range\nexponential scaling. We also show that at the critical point, the bipartite\nentanglement exhibits a power-law decrease ($\\sim\\mathcal{Z}^{-\\gamma}$) with\nincreasing coordination number irrespective of the partition size and the value\nof $\\alpha$ for $\\alpha>1$. We further consider a sudden quench of the system\nstarting from the ground state of the infinite-field limit of the system\nHamiltonian via turning on the critical Hamiltonian, and demonstrate that the\nlong-time averaged bipartite entanglement exhibits a qualitatively similar\nvariation ($\\sim\\mathcal{Z}^{-\\gamma}$) with $\\mathcal{Z}$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-02T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2504.01857v1","title":"Cross-Lingual Consistency: A Novel Inference Framework for Advancing\n  Reasoning in Large Language Models","summary":"Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\nreasoning capabilities in large language models (LLMs), with self-consistency\ndemonstrating notable promise in boosting performance. However, inherent\nlinguistic biases in multilingual training corpora frequently cause semantic\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\nhandling complex inference tasks. To overcome these constraints, we propose the\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\nthat integrates multilingual reasoning paths through majority voting to elevate\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\nCLC's superiority over the conventional self-consistency method, delivering\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\nneutralizing linguistic biases in multilingual training corpora through\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\nexploring the broader multilingual solution space. This dual benefits\nempirically enables more globally optimal reasoning paths compared to\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\ngains using Gemma2-9B-Instruct on the MGSM dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T16:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01868v1","title":"Focal Mechanism Uncertainty Quantification In Ground Motion Simulations\n  Of Le Teil Earthquake","summary":"Ensuring the seismic safety of nuclear power plants (NPPs) is essential,\nespecially for facilities that rely on base isolation to reduce earthquake\nimpacts. For understanding the seismic response, accurate models are key to\npredict the ground motions, which are generally sensitive to various factors,\nincluding earthquake source parameters like the focal mechanism, i.e., strike,\ndip, and rake angles. This study examines how uncertainties in these parameters\naffect ground motion predictions. The analysis is based on the SMATCH\nbenchmark, which provides a standardized approach for evaluating the seismic\nresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquake\nof 2019. A set of 27 3D high-fidelity numerical simulations was performed using\na spectral-element method, each incorporating different focal mechanism\nvariations. These simulations provide an effective approach for investigating\nthe factors behind the exceptional ground motion observed during this event. To\nquantify uncertainty, the simulated ground motions were compared to recorded\ndata using two well-established goodness-of-fit criteria: one assessing\ntime-frequency domain characteristics and another focusing on the\ncharacterization of the ground motion signals by intensity measures. Results\nhighlight the significant influence of focal mechanism variability on ground\nmotion predictions, especially on the rake angle, which showed the strongest\ncorrelation with wave and intensity measures.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01901v1","title":"Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness","summary":"The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.RO","published":"2025-04-02T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01909v1","title":"The Trinity of black hole correspondences: Shadows-quasinormal\n  modes-graybody factors and cautionary remarks","summary":"Correspondences between apparently distant concepts are ubiquitous in\ntheoretical physics. In the context of Black Holes (BHs), Quasi-Normal Modes\n(QNMs) were shown to be linked to both the shadows, in the so-called eikonal\nlimit, and Gray-Body Factors (GBFs), using the WKB approximation. We test the\naccuracy of the quasinormal modes-graybody factors correspondence's in the\ncontext of the Hawking spectra for static and rotating black hole\nconfigurations, with particular attention to the superradiant regime. Our\nanalysis reveals the correspondence failure to accurately reproduce the Hawking\nspectrum due to divergences. Furthermore, we bridge the gap between black\nshadows and graybody factors by drawing a correspondence between such\nquantities in the case of generic static and spherically symmetric spacetime\nconfigurations. The shadow-GBF correspondence is tested for some case studies,\nincluding regular BHs, and its limitations and applicability are thereof\ndiscussed. This study opens new perspectives, by introducing a new\ncorrespondence and remarking on the caution needed when considering these\nconnections.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-ph","published":"2025-04-02T17:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.01918v1","title":"Long-eared digraphs","summary":"Let $H$ be a subdigraph of a digraph $D$. An ear of $H$ in $D$ is a path or a\ncycle in $D$ whose ends lie in $H$ but whose internal vertices do not. An\n\\emph{ear decomposition} of a strong digraph $D$ is a nested sequence\n$(D_0,D_1,\\ldots , D_k)$ of strong subdigraphs of $D$ such that: 1) $D_0$ is a\ncycle, 2) $D_{i+1} = D_i\\cup P_i$, where $P_i$ is an ear of $D_i$ in $D$, for\nevery $i\\in \\{0,1,\\ldots,k-1\\}$, and 3) $D_k=D$.\n  In this work, the $\\mathcal{LE}_i$ is defined as the family of strong\ndigraphs, with an ear decomposition such that every ear has a length of at\nleast $i\\geq 1$. It is proved that Seymour's second Neighborhood Conjecture and\nthe Laborde, Payan, and Soung conjecture, are true in the family\n$\\mathcal{LE}_2$, and the Small quasi-kernel conjecture is true for digraphs in\n$\\mathcal{LE}_3$. Also, some sufficient conditions for a strong nonseparable\ndigraph in $\\mathcal{LE}_2$ with a kernel to imply that the previous\n(following) subdigraph in the ear decomposition has a kernel too, are\npresented. It is proved that digraphs in $\\mathcal{LE}_2$ have a chromatic\nnumber at most 3, and a dichromatic number 2 or 3. Finally, the oriented\nchromatic number of asymmetrical digraphs in $\\mathcal{LE}_3$ is bounded by 6,\nand it is shown that the oriented chromatic number of asymmetrical digraphs in\n$\\mathcal{LE}_2$ is not bounded.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T17:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.01927v1","title":"Characterisation of distributions through $δ$-records and\n  martingales","summary":"Given parameters $c>0, \\delta\\ne0$ and a sequence $(X_n)$ of real-valued,\nintegrable, independent and identically $F$-distributed random variables, we\ncharacterise distributions $F$ such that $(N_n-cM_n)$ is a martingale, where\n$N_n$ denotes the number of observations $X_k$ among $X_1,\\ldots,X_n$ such that\n$X_k>M_{k-1}+\\delta$, called $\\delta$-records, and $M_k=\\max\\{X_1,\\ldots,\nX_k\\}$.\n  The problem is recast as $1-F(x+\\delta)=c\\int_{x}^{\\infty}(1-F)(t)dt$, for\n$x\\in T$, with $F(T)=1$. Unlike standard functional equations, where the\nequality must hold for all $x$ in a fixed set, our problem involves a domain\nthat depends on $F$ itself, introducing complexity but allowing for more\npossibilities of solutions.\n  We find the explicit expressions of all solutions when $\\delta < 0$ and, when\n$\\delta > 0$, for distributions with bounded support. In the unbounded support\ncase, we focus attention on continuous and lattice distributions. In the\ncontinuous setting, with support $\\mathbb{R}_+$, we reduce the problem to a\ndelay differential equation, showing that, besides particular cases of the\nexponential distribution, mixtures of exponential and gamma distributions and\nmany others are solutions as well. The lattice case, with support\n$\\mathbb{Z}_+$ is treated analogously and reduced to the study of a difference\nequation. Analogous results are obtained; in particular, mixtures of geometric\nand negative binomial distributions are found to solve the problem.","main_category":"math.PR","categories":"math.PR","published":"2025-04-02T17:37:30Z"}
{"aid":"http://arxiv.org/abs/2504.01933v1","title":"Hessian-aware Training for Enhancing DNNs Resilience to Parameter\n  Corruptions","summary":"Deep neural networks are not resilient to parameter corruptions: even a\nsingle-bitwise error in their parameters in memory can cause an accuracy drop\nof over 10%, and in the worst cases, up to 99%. This susceptibility poses great\nchallenges in deploying models on computing platforms, where adversaries can\ninduce bit-flips through software or bitwise corruptions may occur naturally.\nMost prior work addresses this issue with hardware or system-level approaches,\nsuch as integrating additional hardware components to verify a model's\nintegrity at inference. However, these methods have not been widely deployed as\nthey require infrastructure or platform-wide modifications.\n  In this paper, we propose a new approach to addressing this issue: training\nmodels to be more resilient to bitwise corruptions to their parameters. Our\napproach, Hessian-aware training, promotes models with $flatter$ loss surfaces.\nWe show that, while there have been training methods, designed to improve\ngeneralization through Hessian-based approaches, they do not enhance resilience\nto parameter corruptions. In contrast, models trained with our method\ndemonstrate increased resilience to parameter corruptions, particularly with a\n20$-$50% reduction in the number of bits whose individual flipping leads to a\n90$-$100% accuracy drop. Moreover, we show the synergy between ours and\nexisting hardware and system-level defenses.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-02T17:42:31Z"}
{"aid":"http://arxiv.org/abs/2504.01940v1","title":"Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and\n  Communication Towards 6G","summary":"This paper presents field-tested use cases from Search and Rescue (SAR)\nmissions, highlighting the co-design of mobile robots and communication systems\nto support Edge-Cloud architectures based on 5G Standalone (SA). The main goal\nis to contribute to the effective cooperation of multiple robots and first\nresponders. Our field experience includes the development of Hybrid Wireless\nSensor Networks (H-WSNs) for risk and victim detection, smartphones integrated\ninto the Robot Operating System (ROS) as Edge devices for mission requests and\npath planning, real-time Simultaneous Localization and Mapping (SLAM) via\nMulti-Access Edge Computing (MEC), and implementation of Uncrewed Ground\nVehicles (UGVs) for victim evacuation in different navigation modes. These\nexperiments, conducted in collaboration with actual first responders,\nunderscore the need for intelligent network resource management, balancing\nlow-latency and high-bandwidth demands. Network slicing is key to ensuring\ncritical emergency services are performed despite challenging communication\nconditions. The paper identifies architectural needs, lessons learned, and\nchallenges to be addressed by 6G technologies to enhance emergency response\ncapabilities.","main_category":"cs.RO","categories":"cs.RO,cs.NI","published":"2025-04-02T17:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.01943v1","title":"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding","summary":"Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T17:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.01958v1","title":"Individual halo bias in models of $f(R)$ gravity","summary":"Halo bias links the statistical properties of the spatial distribution of\ndark matter halos to those of the underlying dark matter field, providing\ninsights into clustering properties in both general relativity (GR) and\nmodified-gravity scenarios such as $f(R)$ models. While the primary halo\nmass-dependent bias has been studied in detailed, the secondary bias, which\naccounts for the additional dependencies on other internal halo properties, can\noffer a sensitive probe for testing gravity beyond the $\\Lambda$CDM model. To\nquantify any potential deviations between $\\Lambda$CDM and $f(R)$ gravity\nmodels in halo clustering, at both the primary and secondary level, as well as\nin the distributions of halo properties in the cosmic web. Using $N$-body\nsimulations of $f(R)$ gravity models, we assess the scaling relations and the\nprimary and secondary bias signals of halo populations on the basis of a\nhalo-by-halo estimator of large-scale effective bias. Our analysis is performed\nusing halo number density as the independent variable. The relative difference\nin the effective bias between the $f(R)$ models and $\\Lambda$CDM is sensitive,\nalbeit slightly, to the power index of modified gravity. The largest deviations\nfrom GR are measured for low-mass halos, where the average bias at fixed number\ndensity decreases by up to 5\\% for fixed scaling indices. We also show that the\nscaling relations for some environmental properties, including neighbour\nstatistics, Mach number and local overdensity, exhibit small but non-negligible\ndeviations (~3-5\\%) from GR for a wide range of number densities. Our results\nalso suggests that the properties of halos in sheets and voids show the largest\ndepartures from GR (> 10\\% in some cases). In terms of secondary bias, we do\nnot find any statistically significant deviations with respect to $\\Lambda$CDM\nfor any of the properties explored in this work.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T17:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02221v1","title":"Learning and Improving Backgammon Strategy","summary":"A novel approach to learning is presented, combining features of on-line and\noff-line methods to achieve considerable performance in the task of learning a\nbackgammon value function in a process that exploits the processing power of\nparallel supercomputers. The off-line methods comprise a set of techniques for\nparallelizing neural network training and $TD(\\lambda)$ reinforcement learning;\nhere Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line\npolicy improvement technique which applies resources to the decision points\nencountered during the search of the game tree to further augment the learned\nvalue function estimate. A level of play roughly as good as, or possibly better\nthan, the current champion human and computer backgammon players has been\nachieved in a short period of learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-04-03T02:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.02222v1","title":"APSeg: Auto-Prompt Model with Acquired and Injected Knowledge for\n  Nuclear Instance Segmentation and Classification","summary":"Nuclear instance segmentation and classification provide critical\nquantitative foundations for digital pathology diagnosis. With the advent of\nthe foundational Segment Anything Model (SAM), the accuracy and efficiency of\nnuclear segmentation have improved significantly. However, SAM imposes a strong\nreliance on precise prompts, and its class-agnostic design renders its\nclassification results entirely dependent on the provided prompts. Therefore,\nwe focus on generating prompts with more accurate localization and\nclassification and propose \\textbf{APSeg}, \\textbf{A}uto-\\textbf{P}rompt model\nwith acquired and injected knowledge for nuclear instance \\textbf{Seg}mentation\nand classification. APSeg incorporates two knowledge-aware modules: (1)\nDistribution-Guided Proposal Offset Module (\\textbf{DG-POM}), which learns\ndistribution knowledge through density map guided, and (2) Category Knowledge\nSemantic Injection Module (\\textbf{CK-SIM}), which injects morphological\nknowledge derived from category descriptions. We conducted extensive\nexperiments on the PanNuke and CoNSeP datasets, demonstrating the effectiveness\nof our approach. The code will be released upon acceptance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T02:28:51Z"}
{"aid":"http://arxiv.org/abs/2504.02228v1","title":"Stochastic positivity-preserving symplectic splitting methods for\n  stochastic Lotka--Volterra predator-prey model","summary":"In this paper, we present two stochastic positive-preserving symplectic\nmethods for the stochastic Lotka-Volterra predator-prey model driven by a\nmultiplicative noise. To inherit the intrinsic characteristic of the original\nsystem, the stochastic Lie--Trotter splitting method and the stochastic Strang\nsplitting method are introduced, which are proved to preserve the positivity of\nthe numerical solution and possess the discrete stochastic symplectic\nconservation law as well. By deriving the uniform boundedness of the $p$-th\nmoment of the numerical solution, we prove that the strong convergence orders\nof these two methods are both one in the $L^2(\\Omega)$-norm. Finally, we\nvalidate the theoretical results through two and four dimensional numerical\nexamples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T02:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.02231v1","title":"AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image\n  Generation","summary":"Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T02:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.02232v1","title":"Identify main-sequence binaries from the Chinese Space Station Telescope\n  Survey with machine learning","summary":"The statistical properties of double main sequence (MS) binaries are very\nimportant for binary evolution and binary population synthesis. To obtain these\nproperties, we need to identify these MS binaries. In this paper, we have\ndeveloped a method to differentiate single MS stars from double MS binaries\nfrom the Chinese Space Station Telescope (CSST) Survey with machine learning.\nThis method is reliable and efficient to identify binaries with mass ratios\nbetween 0.20 and 0.80, which is independent of the mass ratio distribution. But\nthe number of binaries identified with this method is not a good approximation\nto the number of binaries in the original sample due to the low detection\nefficiency of binaries with mass ratios smaller than 0.20 or larger than 0.80.\nTherefore, we have improved this point by using the detection efficiencies of\nour method and an empirical mass ratio distribution and then can infer the\nbinary fraction in the sample. Once the CSST data are available, we can\nidentify MS binaries with our trained multi-layer perceptron model and derive\nthe binary fraction of the sample.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-03T02:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.02236v1","title":"Spectral estimates for non-self-adjoint Dirac operators","summary":"The spectrum of a periodic non-self-adjoint Dirac operator is studied, and\nits explicit dependence on a semi-classical parameter is also considered. Using\n``energy'' techniques several new estimates are derived that together confine\nthe spectrum to a subset of the complex plane. Importantly, a sufficient\ncondition is obtained which ensures that the spectrum concentrates on the real\naxis, and a bounded subset of the imaginary axis of the spectral variable as\nthe semi-classical parameter tends to zero.","main_category":"math.SP","categories":"math.SP","published":"2025-04-03T03:08:36Z"}
{"aid":"http://arxiv.org/abs/2504.02240v1","title":"Measurement of charged hadron multiplicity in Au+Au collisions at\n  $\\sqrt{\\text{s}_{\\text{NN}}} = 200$ GeV with the sPHENIX detector","summary":"The pseudorapidity distribution of charged hadrons produced in Au+Au\ncollisions at a center-of-mass energy of $\\sqrt{s_\\mathrm{NN}} = 200$ GeV is\nmeasured using data collected by the sPHENIX detector. Charged hadron yields\nare extracted by counting cluster pairs in the inner and outer layers of the\nIntermediate Silicon Tracker, with corrections applied for detector acceptance,\nreconstruction efficiency, combinatorial pairs, and contributions from\nsecondary decays. The measured distributions cover $|\\eta| < 1.1$ across\nvarious centralities, and the average pseudorapidity density of charged hadrons\nat mid-rapidity is compared to predictions from Monte Carlo heavy-ion event\ngenerators. This result, featuring full azimuthal coverage at mid-rapidity, is\nconsistent with previous experimental measurements at the Relativistic Heavy\nIon Collider, thereby supporting the broader sPHENIX physics program.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-03T03:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.02242v1","title":"Measurement of the transverse energy density in Au+Au collisions at\n  $\\sqrt{s_{NN}} = 200$ GeV with the sPHENIX detector","summary":"This paper reports measurements of the transverse energy per unit\npseudorapidity ($dE_{T}/d\\eta$) produced in Au+Au collisions at $\\sqrt{s_{NN}}\n= 200$ GeV, performed with the sPHENIX detector at the Relativistic Heavy Ion\nCollider (RHIC). The results cover the pseudorapidity range $\\left|\\eta\\right|\n< 1.1$ and constitute the first such measurement performed using a hadronic\ncalorimeter at RHIC. Measurements of $dE_{T}/d\\eta$ are presented for a range\nof centrality intervals and the average $dE_{T}/d\\eta$ as a function of the\nnumber of participating nucleons, $N_{\\mathrm{part}}$, is compared to a variety\nof Monte Carlo heavy-ion event generators. The results are in agreement with\nprevious measurements at RHIC, and feature an improved granularity in $\\eta$\nand improved precision in low-$N_{\\mathrm{part}}$ events.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-03T03:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.02245v1","title":"Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and\n  Low-Rank Tensor Optimization","summary":"Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-03T03:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.02247v1","title":"Electromagnetic Waves Determined by the Tangential Electric Field of\n  Incident Plane Wave at a Charged and Lossy Planar Interface","summary":"Based on the new decomposition of wave vectors and electric fields with\nrespect to a charged planar interface between two isotropic lossy media, the\nincident, reflected, and refracted plane waves are found to be only determined\nby the tangential electric field of the incident plane wave. The complex wave\nvectors and their corresponding complex angles of the incident, reflected and\nrefracted waves are easily calculated from the tangential wave vector based on\nthe phase matching condition and Snell's law. The relationship between two\ndifferent schemes of electric field compositions is interpreted and the\nelectric field magnitudes of the incident, reflected and refracted waves were\ndeduced from the tangential electric field magnitude of the incident wave where\nthe tangential boundary condition of electric fields is directly utilized. The\ntime-averaged Poynting vectors and the surface Joule heat density at the\ninterface are also given to demonstrate the validity of our proposed\nmethodology by the energy balance condition together with a specific example.\nIt is also found that the external surface charges with a practical surface\ncharge density have little effect on the reflection and transmission of\nelectromagnetic waves since the surface conductivity of interface is negligibly\nsmall. Our work opens a new and fast route for calculating the reflected and\ntransmitted waves at a charged and lossy planar interface without the need to\nperform the traditional polarization decomposition of arbitrarily polarized\nincident plane waves.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T03:26:14Z"}
{"aid":"http://arxiv.org/abs/2504.02266v1","title":"Knizhnik-Zamolodchikov equations in Deligne categories","summary":"We consider the Knizhnik-Zamolodchikov equations in Deligne Categories in the\ncontext of $(\\mathfrak{gl}_m,\\mathfrak{gl}_{n})$ and\n$(\\mathfrak{so}_m,\\mathfrak{so}_{2n})$ dualities. We derive integral formulas\nfor the solutions in the first case and compute monodromy in both cases.","main_category":"math.RT","categories":"math.RT,math-ph,math.MP,math.QA","published":"2025-04-03T04:26:43Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02273v1","title":"Reasoning Under 1 Billion: Memory-Augmented Reinforcement Learning for\n  Large Language Models","summary":"Recent advances in fine-tuning large language models (LLMs) with\nreinforcement learning (RL) have shown promising improvements in complex\nreasoning tasks, particularly when paired with chain-of-thought (CoT)\nprompting. However, these successes have been largely demonstrated on\nlarge-scale models with billions of parameters, where a strong pretraining\nfoundation ensures effective initial exploration. In contrast, RL remains\nchallenging for tiny LLMs with 1 billion parameters or fewer because they lack\nthe necessary pretraining strength to explore effectively, often leading to\nsuboptimal reasoning patterns. This work introduces a novel intrinsic\nmotivation approach that leverages episodic memory to address this challenge,\nimproving tiny LLMs in CoT reasoning tasks. Inspired by human memory-driven\nlearning, our method leverages successful reasoning patterns stored in memory\nwhile allowing for controlled exploration to generate novel responses.\nIntrinsic rewards are computed efficiently using a kNN-based episodic memory,\nallowing the model to discover new reasoning strategies while quickly adapting\nto effective past solutions. Experiments on fine-tuning GSM8K and AI-MO\ndatasets demonstrate that our approach significantly enhances smaller LLMs'\nsample efficiency and generalization capability, making RL-based reasoning\nimprovements more accessible in low-resource settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.02283v1","title":"Ga$_2$O$_3$ TCAD Mobility Parameter Calibration using Simulation\n  Augmented Machine Learning with Physics Informed Neural Network","summary":"In this paper, we demonstrate the possibility of performing automatic\nTechnology Computer-Aided-Design (TCAD) parameter calibration using machine\nlearning, verified with experimental data. The machine only needs to be trained\nby TCAD data. Schottky Barrier Diode (SBD) fabricated with emerging\nultra-wide-bandgap material, Gallium Oxide (Ga$_2$O$_3$), is measured and its\ncurrent-voltage (IV) is used for Ga$_2$O$_3$ Philips Unified Mobility (PhuMob)\nmodel parameters, effective anode workfunction, and ambient temperature\nextraction (7 parameters). A machine comprised of an autoencoder (AE) and a\nneural network (NN) (AE-NN) is used. Ga$_2$O$_3$ PhuMob parameters are\nextracted from the noisy experimental curves. TCAD simulation with the\nextracted parameters shows that the quality of the parameters is as good as an\nexpert's calibration at the pre-turned-on regime but not in the on-state\nregime. By using a simple physics-informed neural network (PINN) (AE-PINN), the\nmachine performs as well as the human expert in all regimes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T05:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.02307v1","title":"Solving adhesive rough contact problems with Atomic Force Microscope\n  data","summary":"This study presents an advanced numerical framework that integrates\nexperimentally acquired Atomic Force Microscope (AFM) data into high-fidelity\nsimulations for adhesive rough contact problems, bridging the gap between\nexperimental physics and computational mechanics. The proposed approach extends\nthe eMbedded Profile for Joint Roughness (MPJR) interface finite element method\nto incorporate both surface topography and spatially varying adhesion\nproperties, imported directly from AFM measurements. The adhesion behavior is\nmodeled using a modified Lennard-Jones potential, which is locally\nparameterized based on the AFM-extracted adhesion peak force and energy\ndissipation data. The effectiveness of this method is demonstrated through 2D\nand 3D finite element simulations of a heterogeneous PS-LDPE (polystyrene\nmatrix with low-density polyethylene inclusions) sample, where the bulk elastic\nproperties are also experimentally characterized via AFM. The results highlight\nthe significance of accounting for both surface adhesion variability and\nmaterial bulk heterogeneity in accurately predicting contact responses.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T06:32:06Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02317v1","title":"Temporal Gaussian Copula For Clinical Multivariate Time Series Data\n  Imputation","summary":"The imputation of the Multivariate time series (MTS) is particularly\nchallenging since the MTS typically contains irregular patterns of missing\nvalues due to various factors such as instrument failures, interference from\nirrelevant data, and privacy regulations. Existing statistical methods and deep\nlearning methods have shown promising results in time series imputation. In\nthis paper, we propose a Temporal Gaussian Copula Model (TGC) for three-order\nMTS imputation. The key idea is to leverage the Gaussian Copula to explore the\ncross-variable and temporal relationships based on the latent Gaussian\nrepresentation. Subsequently, we employ an Expectation-Maximization (EM)\nalgorithm to improve robustness in managing data with varying missing rates.\nComprehensive experiments were conducted on three real-world MTS datasets. The\nresults demonstrate that our TGC substantially outperforms the state-of-the-art\nimputation methods. Additionally, the TGC model exhibits stronger robustness to\nthe varying missing ratios in the test dataset. Our code is available at\nhttps://github.com/MVL-Lab/TGC-MTS.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T06:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.02320v1","title":"$β$-decay properties of some astrophysically important Sc-isotopes","summary":"In the late progressive stages of heavy stars, electron capture and\n$\\beta^\\pm$-decay are the governing processes. The weak rates are essential\ninputs for modeling the stages of high-mass stars before supernova explosions.\nAs per results obtained from previous simulations, weak rates of Scandium\nisotopes contribute substantially in changing the lepton-to-baryon ratio\n($Y_e$) of the nuclear matter in the core. In the present analysis, we report\nimportant $\\beta^-$-decay properties of crucial Sc isotopes in an astrophysical\nenvironment with mass numbers $49 \\leq A \\leq 54$. The investigation includes\nGamow-Teller (GT) strength distributions, terrestrial half-lives, and stellar\nrates of electron capture (EC) and $\\beta^-$-decay reactions. The calculations\nare performed using the proton-neutron (pn) quasi-particle random phase\napproximation (QRPA) model over a wide temperature range ($10^7$-$3 \\times\n10^{10}$ K) and density range ($10^1 - 10^{11}$ g/cm$^3$). Additionally, we\ncompare our calculated results with available experimental and theoretical\ndata. A good agreement is observed between our calculated half-lives and\nexperimentally measured values. Our weak $\\beta^-$-decay and EC rates are\ncompared with those from the Independent-Particle Model (IPM) and Large-Scale\nShell Model (LSSM). At high stellar temperatures and densities, our calculated\n$\\beta^-$-decay rates are smaller than those from the other models.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.02325v1","title":"Surgeries between lens spaces of type $L(n,1)$ and the Heegaard Floer\n  $d$-invariant","summary":"We establish a $d$-invariant surgery formula for $L$-space knots that\nprovides an effective tool for studying surgeries between lens spaces. Using\nthis formula, we classify distance one surgeries between lens spaces of the\nform $L(n,1)$. This classification has direct applications to band surgeries\nbetween torus links $T(2,n)$, with connections to DNA topology. In particular,\nwe show that chirally cosmetic banding of torus links can possibly occur only\nwhen $n=1,5,9$ or $10$.","main_category":"math.GT","categories":"math.GT","published":"2025-04-03T06:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.02333v1","title":"Accessing the deuteron source with pion-deuteron femtoscopy in Pb-Pb\n  collisions at $\\sqrt{s_{\\rm NN}} = 5.02$ TeV","summary":"Femtoscopy of non-identical particle pairs has been instrumental for\nprecision measurements of both two-particle sources and the final-state\ninteractions in high-energy elementary and heavy-ion collisions. The majority\nof measurements assessing the source properties are based on identical particle\npairs, providing direct access to the characteristics of the single-particle\nsource. The work in this paper demonstrates, via femtoscopy measurements of\ncharged pion-deuteron pairs in Pb-Pb collisions at $\\sqrt{s_{\\rm NN}} = 5.02$\nTeV, the feasibility of accessing the characteristics of the single-particle\nfemtoscopic source by using particle pairs with large mass differences such as\npions and deuterons. The first experimental results of the measurement of\ndeuteron source sizes in ultrarelativistic heavy-ion collisions are presented.\nThe results show good agreement with the trend derived from other charged\nhadrons such as pions, kaons, and protons as a function of transverse mass,\nindicating similar source properties","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T07:11:18Z"}
{"aid":"http://arxiv.org/abs/2504.02337v1","title":"LPA3D: 3D Room-Level Scene Generation from In-the-Wild Images","summary":"Generating realistic, room-level indoor scenes with semantically plausible\nand detailed appearances from in-the-wild images is crucial for various\napplications in VR, AR, and robotics. The success of NeRF-based generative\nmethods indicates a promising direction to address this challenge. However,\nunlike their success at the object level, existing scene-level generative\nmethods require additional information, such as multiple views, depth images,\nor semantic guidance, rather than relying solely on RGB images. This is because\nNeRF-based methods necessitate prior knowledge of camera poses, which is\nchallenging to approximate for indoor scenes due to the complexity of defining\nalignment and the difficulty of globally estimating poses from a single image,\ngiven the unseen parts behind the camera. To address this challenge, we\nredefine global poses within the framework of Local-Pose-Alignment (LPA) -- an\nanchor-based multi-local-coordinate system that uses a selected number of\nanchors as the roots of these coordinates. Building on this foundation, we\nintroduce LPA-GAN, a novel NeRF-based generative approach that incorporates\nspecific modifications to estimate the priors of camera poses under LPA. It\nalso co-optimizes the pose predictor and scene generation processes. Our\nablation study and comparisons with straightforward extensions of NeRF-based\nobject generative methods demonstrate the effectiveness of our approach.\nFurthermore, visual comparisons with other techniques reveal that our method\nachieves superior view-to-view consistency and semantic normality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02350v1","title":"Inducing contractions of the mother of all continued fractions","summary":"We introduce a new, large class of continued fraction algorithms producing\nwhat are called contracted Farey expansions. These algorithms are defined by\ncoupling two acceleration techniques -- induced transformations and contraction\n-- in the setting of Shunji Ito's natural extension of the Farey tent map,\nwhich generates `slow' continued fraction expansions. In addition to defining\nnew algorithms, we also realise several existing continued fraction algorithms\nin our unifying setting. In particular, we find regular continued fractions,\nthe second-named author's $S$-expansions, and Nakada's parameterised family of\n$\\alpha$-continued fractions for all $0<\\alpha\\le 1$ as examples of contracted\nFarey expansions. Moreover, we give a new description of a planar natural\nextension for each of the $\\alpha$-continued fraction transformations as an\nexplicit induced transformation of Ito's natural extension.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-03T07:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02366v1","title":"Non-Koszulness in a family of properads","summary":"Proving Koszulness of a properad can be very hard, but sometimes one can look\nat its Koszul complex to look for obstructions for Koszulness. In this paper,\nwe present a method and tools to prove non-Koszulness of many properads in a\nfamily of quadratic properads. We illustrate this method on a family of\nassociative and coassociative properads with one quadratic compatibility\nrelation.","main_category":"math.AT","categories":"math.AT","published":"2025-04-03T07:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.02373v1","title":"HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image\n  Enhancement","summary":"In practical applications, conventional methods generate large volumes of\nlow-light images that require compression for efficient storage and\ntransmission. However, most existing methods either disregard the removal of\npotential compression artifacts during the enhancement process or fail to\nestablish a unified framework for joint task enhancement of images with varying\ncompression qualities. To solve this problem, we propose the hybrid\npriors-guided network (HPGN), which enhances compressed low-light images by\nintegrating both compression and illumination priors. Our approach fully\nutilizes the JPEG quality factor (QF) and DCT quantization matrix (QM) to guide\nthe design of efficient joint task plug-and-play modules. Additionally, we\nemploy a random QF generation strategy to guide model training, enabling a\nsingle model to enhance images across different compression levels.\nExperimental results confirm the superiority of our proposed method.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T08:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.02374v1","title":"On an Unnoticed Geometrical Paradox in Plato's Timaeus' Cosmology","summary":"In a previous article, we discussed a paradox in Timaeus' cosmology: that\nthere is no void inside the universe, even though it is entirely filled with\npolyhedra-a mathematical impossibility (Brisson-Ofman 2025). In the present\narticle, we examine another paradox. While the first paradox is well known and\nwas already highlighted by Aristotle as a fundamental mathematical\ncontradiction undermining Plato's cosmology, this new paradox has gone almost\nentirely unnoticed by commentators, both ancient and modern. This oversight may\nsurprise scholars, given the extensive body of work on Timaeus' universe, much\nof which emphasizes discrepancies with astronomical observations or points out\nsupposed internal contradictions. Like the first paradox, this one arises from\nthe premise of a universe entirely filled with polyhedra. However, in this\ncase, the contradiction stems from the absence of void outside it. In the first\nsection, we demonstrate that the shape of the universe cannot be a perfect\nmathematical sphere: that is, its boundary is not smooth but exhibits bumps and\nhollows. Next, we present conceptual arguments from Plato's text that support\nthe necessity of such 'defects' in the universe's shape compared to a perfect\nmathematical sphere. In the third section, we argue that such a universe cannot\nmove at all. Finally, we propose a solution to this mathematical contradiction\nin Timaeus' construction, drawing on the same ideas used to address the earlier\napparent contradiction: the unique feature of Timaeus' universe as a living\nbeing, whose parts are continuously moving, changing, decomposing, and\nreforming. While this problem does not depend on the various schools of\ninterpretation of the Timaeus, it is related to some important issues\nconcerning Plato's philosophy. These issues include the importance of\nobservations in science-particularly in astronomy-the relationship between\nintelligible models and their sensible copies, the mythos/ logos approach of\nPlato's cosmology, and the debate over 'metaphorical' vs 'literal'\ninterpretation. Of course, all these questions fall outside the scope of this\narticle and will not be addressed here.","main_category":"math.HO","categories":"math.HO","published":"2025-04-03T08:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.02390v1","title":"Flag Hardy spaces and partial differential equations","summary":"After a quick introduction to flag geometry on the Heisenberg group, we\ndiscuss the problem of identifying flag atoms, which boils down to a question\nin PDE. We establish a conjecture of E.M.~Stein for the flag Hardy space on the\nHeisenberg group. The key result on which our arguments hinge is due to Baldi,\nFranchi and Pansu.","main_category":"math.CA","categories":"math.CA","published":"2025-04-03T08:31:34Z"}
{"aid":"http://arxiv.org/abs/2504.02402v1","title":"EvMic: Event-based Non-contact sound recovery from effective\n  spatial-temporal modeling","summary":"When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-03T08:51:17Z"}
{"aid":"http://arxiv.org/abs/2504.02404v1","title":"AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in\n  Anesthesiology","summary":"The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.02408v1","title":"Translation of Fetal Brain Ultrasound Images into Pseudo-MRI Images\n  using Artificial Intelligence","summary":"Ultrasound is a widely accessible and cost-effective medical imaging tool\ncommonly used for prenatal evaluation of the fetal brain. However, it has\nlimitations, particularly in the third trimester, where the complexity of the\nfetal brain requires high image quality for extracting quantitative data. In\ncontrast, magnetic resonance imaging (MRI) offers superior image quality and\ntissue differentiation but is less available, expensive, and requires\ntime-consuming acquisition. Thus, transforming ultrasonic images into an\nMRI-mimicking display may be advantageous and allow better tissue anatomy\npresentation. To address this goal, we have examined the use of artificial\nintelligence, implementing a diffusion model renowned for generating\nhigh-quality images. The proposed method, termed \"Dual Diffusion Imposed\nCorrelation\" (DDIC), leverages a diffusion-based translation methodology,\nassuming a shared latent space between ultrasound and MRI domains. Model\ntraining was obtained utilizing the \"HC18\" dataset for ultrasound and the \"CRL\nfetal brain atlas\" along with the \"FeTA \" datasets for MRI. The generated\npseudo-MRI images provide notable improvements in visual discrimination of\nbrain tissue, especially in the lateral ventricles and the Sylvian fissure,\ncharacterized by enhanced contrast clarity. Improvement was demonstrated in\nMutual information, Peak signal-to-noise ratio, Fr\\'echet Inception Distance,\nand Contrast-to-noise ratio. Findings from these evaluations indicate\nstatistically significant superior performance of the DDIC compared to other\ntranslation methodologies. In addition, a Medical Opinion Test was obtained\nfrom 5 gynecologists. The results demonstrated display improvement in 81% of\nthe tested images. In conclusion, the presented pseudo-MRI images hold the\npotential for streamlining diagnosis and enhancing clinical outcomes through\nimproved representation.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-03T08:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.02419v1","title":"Numerical simulations of the pressure-driven flow of pairs of rigid\n  spheres in elastoviscoplastic fluids","summary":"We investigate through numerical simulations the hydrodynamic interactions\nbetween two rigid spherical particles suspended on the axis of a cylindrical\ntube filled with an elastoviscoplastic fluid subjected to pressure-driven flow.\nThe simulations are performed by the finite element method with the arbitrary\nLagrangian-Eulerian formulation. We carry out a parametric analysis to examine\nthe impact of the yield stress and relaxation time of the fluid and of particle\nconfinement on the dynamics of the system. We identify master curves of the\nparticle relative velocity as a function of the inter-particle distance. When\nthe yield stress of the suspending phase is much lower than the viscous stress,\nthose curves highlight short-range attractive interactions and long-range\nrepulsive interactions between particles, with the latter specifically\npromoting their alignment. As the yield stress increases, the attractive\ninteraction is replaced by stasis at short distance, characterized by a\nvanishing relative velocity and the formation of an unyielded region that\nconnects the two spheres, where the fluid behaves like a viscoelastic solid.\nAdditionally, the combined effects of plasticity and elasticity enhance the\nrepulsion between the particles, promoting their ordering. Also increasing the\nconfinement of the particles enhances repulsion, thus allowing to achieve\nordering within shorter lengths in the flow direction. Reducing shear thinning\namplifies peak relative velocities and expands the attractive region due to\nincreased viscoelastic stresses and stress gradients. While a stable\nequilibrium may appear at larger separations, its impact is limited by low\nrelative velocities.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T09:20:24Z"}
{"aid":"http://arxiv.org/abs/2504.02423v1","title":"Quantum effects in piezoelectric semiconductor plasmas : Solitons and\n  transmission feasibility","summary":"A study of the coupling between lattice ion vibrations and electron waves in\na piezoelectric semiconductor quantum plasma is presented. The nonlinearities\nhave been analyzed, and solitons have been studied. The theory is built using\nthe quantum hydrodynamic (QHD) model, incorporating the effects of Fermi\npressure, quantum Bohm potential, and exchange-correlation potentials. The\ndispersion relation for the coupling is established. A set of nonlinear\nevolution equations has been derived using the two-time scale theory, and a\nsoliton solution for the coupled nonlinear evolution equations is obtained\nusing the modified quantum Zakharov equations. The solitons are found to have a\ncusp profile. It is also found that the solitons' field amplitude increases\nsignificantly with particle density and coupling strength in piezoelectric\nsemiconductor quantum plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T09:24:38Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02431v1","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","summary":"System operators responsible for protecting software applications remain\nhesitant to implement cyber deception technology, including methods that place\ntraps to catch attackers, despite its proven benefits. Overcoming their\nconcerns removes a barrier that currently hinders industry adoption of\ndeception technology. Our work introduces deception policy documents to\ndescribe deception technology \"as code\" and pairs them with Koney, a Kubernetes\noperator, which facilitates the setup, rotation, monitoring, and removal of\ntraps in Kubernetes. We leverage cloud-native technologies, such as service\nmeshes and eBPF, to automatically add traps to containerized software\napplications, without having access to the source code. We focus specifically\non operational properties, such as maintainability, scalability, and\nsimplicity, which we consider essential to accelerate the adoption of cyber\ndeception technology and to facilitate further research on cyber deception.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-03T09:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.02436v1","title":"SkyReels-A2: Compose Anything in Video Diffusion Transformers","summary":"This paper presents SkyReels-A2, a controllable video generation framework\ncapable of assembling arbitrary visual elements (e.g., characters, objects,\nbackgrounds) into synthesized videos based on textual prompts while maintaining\nstrict consistency with reference images for each element. We term this task\nelements-to-video (E2V), whose primary challenges lie in preserving the\nfidelity of each reference element, ensuring coherent composition of the scene,\nand achieving natural outputs. To address these, we first design a\ncomprehensive data pipeline to construct prompt-reference-video triplets for\nmodel training. Next, we propose a novel image-text joint embedding model to\ninject multi-element representations into the generative process, balancing\nelement-specific consistency with global coherence and text alignment. We also\noptimize the inference pipeline for both speed and output stability. Moreover,\nwe introduce a carefully curated benchmark for systematic evaluation, i.e, A2\nBench. Experiments demonstrate that our framework can generate diverse,\nhigh-quality videos with precise element control. SkyReels-A2 is the first\nopen-source commercial grade model for the generation of E2V, performing\nfavorably against advanced closed-source commercial models. We anticipate\nSkyReels-A2 will advance creative applications such as drama and virtual\ne-commerce, pushing the boundaries of controllable video generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:50:50Z"}
{"aid":"http://arxiv.org/abs/2504.02439v1","title":"Estimating Scene Flow in Robot Surroundings with Distributed\n  Miniaturized Time-of-Flight Sensors","summary":"Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T09:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.02441v1","title":"Cognitive Memory in Large Language Models","summary":"This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.02445v1","title":"Improved universal approximation with neural networks studied via\n  affine-invariant subspaces of $L_2(\\mathbb{R}^n)$","summary":"We show that there are no non-trivial closed subspaces of $L_2(\\mathbb{R}^n)$\nthat are invariant under invertible affine transformations. We apply this\nresult to neural networks showing that any nonzero $L_2(\\mathbb{R})$ function\nis an adequate activation function in a one hidden layer neural network in\norder to approximate every function in $L_2(\\mathbb{R})$ with any desired\naccuracy. This generalizes the universal approximation properties of neural\nnetworks in $L_2(\\mathbb{R})$ related to Wiener's Tauberian Theorems. Our\nresults extend to the spaces $L_p(\\mathbb{R})$ with $p>1$.","main_category":"math.FA","categories":"math.FA,cs.IT,math.IT","published":"2025-04-03T10:00:40Z"}
{"aid":"http://arxiv.org/abs/2504.02449v1","title":"Strongly regular graphs with parameters (85,14,3,2) do not exist","summary":"We investigate the second smallest unresolved feasible set of parameters of\nstrongly regular graphs, $(v,k,\\lambda,\\mu)=(85,14,3,2)$. Using the\nclassification of cubic graphs of small degree, we restrict possible local\nstructure of such a graph $G$. After that, we exhaustively enumerate possible\nneighbourhoods of a maximal $3$-clique of $G$ and check them against a variety\nof conditions, including the combinatorial ones, coming from $\\lambda=3$ and\n$\\mu=2$, as well as the linear algebra ones, utilising the Euclidean\nrepresentation of $G$. These conditions yield contradiction in all cases, and\nhence, no $\\mathrm{srg}(85,14,3,2)$ exists.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T10:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02458v1","title":"Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation","summary":"Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-03T10:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.02468v1","title":"Enhancing Compton telescope imaging with maximum a posteriori\n  estimation: a modified Richardson-Lucy algorithm for the Compton Spectrometer\n  and Imager","summary":"We present a modified Richardson-Lucy (RL) algorithm tailored for image\nreconstruction in MeV gamma-ray observations, focusing on its application to\nthe upcoming Compton Spectrometer and Imager (COSI) mission. Our method\naddresses key challenges in MeV gamma-ray astronomy by incorporating Bayesian\npriors for sparseness and smoothness while optimizing background components\nsimultaneously. We introduce a novel sparsity term suitable for Poisson-sampled\ndata in addition to a smoothness prior, allowing for flexible reconstruction of\nboth point sources and extended emission. The performance of the algorithm is\nevaluated using simulated three-month COSI observations of gamma-ray lines of\n$^{44}$Ti (1.157 MeV), $^{26}$Al (1.809 MeV), and positron annihilation (0.511\nMeV), respectively, representing various spatial features. Our results\ndemonstrate significant improvements over conventional RL methods, particularly\nin suppressing artificial structures in point source reconstructions and\nretaining diffuse spatial structures. This work represents an important step\ntowards establishing a robust data analysis for studying nucleosynthesis,\npositron annihilation, and other high-energy phenomena in our Galaxy.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.HE","published":"2025-04-03T10:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.02477v1","title":"Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision","summary":"Robot vision has greatly benefited from advancements in multimodal fusion\ntechniques and vision-language models (VLMs). We systematically review the\napplications of multimodal fusion in key robotic vision tasks, including\nsemantic scene understanding, simultaneous localization and mapping (SLAM), 3D\nobject detection, navigation and localization, and robot manipulation. We\ncompare VLMs based on large language models (LLMs) with traditional multimodal\nfusion methods, analyzing their advantages, limitations, and synergies.\nAdditionally, we conduct an in-depth analysis of commonly used datasets,\nevaluating their applicability and challenges in real-world robotic scenarios.\nFurthermore, we identify critical research challenges such as cross-modal\nalignment, efficient fusion strategies, real-time deployment, and domain\nadaptation, and propose future research directions, including self-supervised\nlearning for robust multimodal representations, transformer-based fusion\narchitectures, and scalable multimodal frameworks. Through a comprehensive\nreview, comparative analysis, and forward-looking discussion, we provide a\nvaluable reference for advancing multimodal perception and interaction in\nrobotic vision. A comprehensive list of studies in this survey is available at\nhttps://github.com/Xiaofeng-Han-Res/MF-RV.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.02489v1","title":"The Self-Learning Agent with a Progressive Neural Network Integrated\n  Transformer","summary":"This paper introduces a self-learning agent that integrates LLaMA 3.2 with a\nProgressive Neural Network (PNN) for continual learning in conversational AI\nand code generation. The framework dynamically collects data, fine-tunes tasks\nwith minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA\noptimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances\nknowledge retention. Experimental results demonstrate improved adaptability and\nmemory stability, positioning this approach as a scalable step toward\nArtificial General Intelligence (AGI).","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T11:13:31Z"}
{"aid":"http://arxiv.org/abs/2504.02493v1","title":"On zero-divisor graph of the ring of Gaussian integers modulo $2^n$","summary":"For a commutative ring $R$, the zero-divisor graph of $R$ is a simple graph\nwith the vertex set as the set of all zero-divisors of $R$ and two distinct\nvertices $x$ and $y$ are adjacent if and only if $xy = 0$. This article\nattempts to predict the structure of the zero-divisor graph of the ring of\nGaussian integers modulo $2$ to the power $n$ and determine the size, chromatic\nnumber, clique number, independence number, and matching through associate\nclasses of divisors of $2^n$ in $\\mathbb{Z}_{2^n}[i]$. In addition, a few\ntopological indices of the corresponding zero-divisor graph, are obtained.","main_category":"math.AC","categories":"math.AC,math.CO,math.NT","published":"2025-04-03T11:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.02496v1","title":"Group-based Distinctive Image Captioning with Memory Difference Encoding\n  and Attention","summary":"Recent advances in image captioning have focused on enhancing accuracy by\nsubstantially increasing the dataset and model size. While conventional\ncaptioning models exhibit high performance on established metrics such as BLEU,\nCIDEr, and SPICE, the capability of captions to distinguish the target image\nfrom other similar images is under-explored. To generate distinctive captions,\na few pioneers employed contrastive learning or re-weighted the ground-truth\ncaptions. However, these approaches often overlook the relationships among\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events). In this paper, we introduce a novel approach to\nenhance the distinctiveness of image captions, namely Group-based Differential\nDistinctive Captioning Method, which visually compares each image with other\nimages in one similar group and highlights the uniqueness of each image. In\nparticular, we introduce a Group-based Differential Memory Attention (GDMA)\nmodule, designed to identify and emphasize object features in an image that are\nuniquely distinguishable within its image group, i.e., those exhibiting low\nsimilarity with objects in other images. This mechanism ensures that such\nunique object features are prioritized during caption generation for the image,\nthereby enhancing the distinctiveness of the resulting captions. To further\nrefine this process, we select distinctive words from the ground-truth captions\nto guide both the language decoder and the GDMA module. Additionally, we\npropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to\nquantitatively assess caption distinctiveness. Quantitative results indicate\nthat the proposed method significantly improves the distinctiveness of several\nbaseline models, and achieves state-of-the-art performance on distinctiveness\nwhile not excessively sacrificing accuracy...","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02503v1","title":"Direction switchable single-photon emitter using a Rydberg polariton","summary":"All-optical redirection or routing of single photons is essential for quantum\nnetworks. Although studied in various systems both in theory and experiment,\nthe redirection of single photons with many output ports, compatible with\nlarge-scale photonic circuits, still needs to be explored. Here, we demonstrate\na direction switchable single-photon emitter using a Rydberg polariton. The\nRydberg component of the stored photon is changed using a stimulated Raman\ntransition with a specific intermediate state. By adjusting the direction of\nthe retrieval laser, we can redirect the emitted photon into a rich variety of\nalternative modes. Building upon this scheme, we propose a quantum routing of\nsingle photons with \\textit{N} output channels and unity routing efficiency. In\naddition, the protocol reduces the effect of motional dephasing increasing the\nphoton lifetime to $>10~\\mu$s ($>20$ times photon processing time), enabling\nfunctional quantum devices based on Rydberg polaritons.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T11:35:36Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02507v1","title":"ZClip: Adaptive Spike Mitigation for LLM Pre-Training","summary":"Training large language models (LLMs) presents numerous challenges, including\ngradient instability and loss spikes. These phenomena can lead to catastrophic\ndivergence, requiring costly checkpoint restoration and data batch skipping.\nTraditional gradient clipping techniques, such as constant or norm-based\nmethods, fail to address these issues effectively due to their reliance on\nfixed thresholds or heuristics, leading to inefficient learning and requiring\nfrequent manual intervention. In this work, we propose ZClip, an adaptive\ngradient clipping algorithm that dynamically adjusts the clipping threshold\nbased on statistical properties of gradient norms over time. Unlike prior\nreactive strategies, ZClip proactively adapts to training dynamics without\nmaking any prior assumptions on the scale and the temporal evolution of\ngradient norms. At its core, it leverages z-score-based anomaly detection to\nidentify and mitigate large gradient spikes, preventing malignant loss spikes\nwhile not interfering with convergence otherwise. Our code is available at:\nhttps://github.com/bluorion-com/ZClip.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T11:41:55Z"}
{"aid":"http://arxiv.org/abs/2504.02514v1","title":"The Discriminant of the Characteristic Polynomial of the $k$th Fibonacci\n  sequence is not a member of the $k$th Lucas sequence","summary":"Let $k\\ge 2$ and $\\{L_n^{(k)}\\}_{n\\geq 2-k}$ be the sequence of\n$k$-generalized Lucas numbers whose first $k$ terms are $0,\\ldots,0,2,1$ and\neach term afterwards is the sum of the preceding $k$ terms. In this paper, we\nshow that this sequence does not contain the discriminant of its characteristic\npolynomial.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T11:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.02516v1","title":"A Planning Framework for Stable Robust Multi-Contact Manipulation","summary":"While modeling multi-contact manipulation as a quasi-static mechanical\nprocess transitioning between different contact equilibria, we propose\nformulating it as a planning and optimization problem, explicitly evaluating\n(i) contact stability and (ii) robustness to sensor noise. Specifically, we\nconduct a comprehensive study on multi-manipulator control strategies, focusing\non dual-arm execution in a planar peg-in-hole task and extending it to the\nMulti-Manipulator Multiple Peg-in-Hole (MMPiH) problem to explore increased\ntask complexity. Our framework employs Dynamic Movement Primitives (DMPs) to\nparameterize desired trajectories and Black-Box Optimization (BBO) with a\ncomprehensive cost function incorporating friction cone constraints, squeeze\nforces, and stability considerations. By integrating parallel scenario\ntraining, we enhance the robustness of the learned policies. To evaluate the\nfriction cone cost in experiments, we test the optimal trajectories computed\nfor various contact surfaces, i.e., with different coefficients of friction.\nThe stability cost is analytical explained and tested its necessity in\nsimulation. The robustness performance is quantified through variations of hole\npose and chamfer size in simulation and experiment. Results demonstrate that\nour approach achieves consistently high success rates in both the single\npeg-in-hole and multiple peg-in-hole tasks, confirming its effectiveness and\ngeneralizability. The video can be found at https://youtu.be/IU0pdnSd4tE.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-03T12:05:12Z"}
{"aid":"http://arxiv.org/abs/2504.02532v1","title":"Polynomial Bounds for the Graph Minor Structure Theorem","summary":"The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T12:35:45Z"}
{"aid":"http://arxiv.org/abs/2504.02533v1","title":"ARCANE: Adaptive RISC-V Cache Architecture for Near-memory Extensions","summary":"Modern data-driven applications expose limitations of von Neumann\narchitectures - extensive data movement, low throughput, and poor energy\nefficiency. Accelerators improve performance but lack flexibility and require\ndata transfers. Existing compute in- and near-memory solutions mitigate these\nissues but face usability challenges due to data placement constraints. We\npropose a novel cache architecture that doubles as a tightly-coupled\ncompute-near-memory coprocessor. Our \\riscv cache controller executes custom\ninstructions from the host CPU using vector operations dispatched to\nnear-memory vector processing units within the cache memory subsystem. This\narchitecture abstracts memory synchronization and data mapping from application\nsoftware while offering software-based \\isa extensibility. Our implementation\nshows $30\\times$ to $84\\times$ performance improvement when operating on 8-bit\ndata over the same system with a traditional cache when executing a worst-case\n32-bit CNN workload, with only $41.3\\%$ area overhead.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-03T12:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.02539v1","title":"The restoration of Book X of the Elements to its original Theaetetean\n  form","summary":"In the present work, we aim to restore Book X of the $\\it{Elements}$ to its\noriginal Theaetetean, pre-Eudoxean form in two separate ways. First, we restore\nthe considerable mathematical content of Book X, by correlating Book X with\nPlato's account of Theaetetus' mathematical discoveries and Plato's imitations\nof these discoveries for his philosophy. Thus, Theaetetus proved (i) the\neventual periodicity of the anthyphairesis of lines a to b, satisfying $Ma^2 =\nNb^2$, for MN not square number; (ii) the eventual periodic anthyphairesis of\nlines a to b, satisfying more general quadratic expressions, including the\nApplication of Areas in defect, and employing this to show that the 12 classes\nof alogoi lines, including the minor, despite being alogoi, are determined by\nan eventually periodic Application of Areas in defect; (iii) the anthyphairetic\npalindromic periodicity of the anthyphairesis of the surds $\\sqrt{N}$ for any\nnon-square number N, of relevance to the general Pell's Diophantine problem.\nSecondly, we restore the proofs of all propositions of Book X, in such way that\nthese are proofs based on Theaetetus', and not on Eudoxus' theory of proportion\nof magnitudes, in particular not making any use of Eudoxus' condition (namely\nof definition 4 of Book V). The restoration is based on our reconstruction of\nTheaetetus' theory of proportion for magnitudes, for the limited class of\nratios a/b such that either a, b are commensurable or the anthyphairesis of a\nto b is eventually periodic, without employing Eudoxus' condition, and its\nsuccess provides a confirmation of our reconstruction.\n  The final version of this paper will appear as a chapter in the journal\nGanita Bh\\=arat\\=i, Bulletin of the Indian Society for History of Mathematics,\n(2) 45 (2023).","main_category":"math.HO","categories":"math.HO","published":"2025-04-03T12:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.02541v1","title":"$Λ$CDM from broken diffeomorphisms","summary":"We present a simple field theory model with reduced invariance under\ndiffeomorphisms whose energy-momentum tensor is identical to the sum of\npressureless irrotational matter and a cosmological constant. The model action\nis built from a single scalar field with a canonical kinetic term without any\npotential or Lagrange multiplier terms. The coupling to gravity is realized\nthrough a particular transverse diffeomorphism invariant volume element. The\ncorresponding sound speed is exactly zero in any background geometry and the\nmodel is dynamically identical to $\\Lambda$CDM. By restoring the full\ndiffeomorphism invariance through the introduction of Stueckelberg-like fields,\nwe obtain an equivalent local scalar-vector theory.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-03T12:43:15Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02566v1","title":"Local Flow Estimation at the top of the Earth's Core using Physics\n  Informed Neural Networks","summary":"The Earth's main geomagnetic field arises from the constant motion of the\nfluid outer core. By assuming that the field changes are advection-dominated,\nthe fluid motion at the core surface can be related to the secular variation of\nthe geomagnetic field. The majority of existing core flow models are global,\nshowing features such as an eccentric planetary gyre, with some evidence of\nrapid regional changes. By construction, the flow defined at any location by\nsuch a model depends on all magnetic field variations across the entire\ncore-mantle boundary making it challenging to interpret local structures in the\nflow as due to specific local changes in magnetic field. Here we present an\nalternative strategy in which we construct regional flow models that rely only\non local secular changes. We use a novel technique based on machine learning\ntermed Physics-Informed Neural Networks (PINNs), in which we seek a regional\nflow model that simultaneously fits both the local magnetic field variation and\ndynamical conditions assumed satisfied by the flow. Although we present results\nusing the Tangentially Geostrophic flow constraint, we set out a modelling\nframework for which the physics constraint can be easily changed by altering a\nsingle line of code. After validating the PINN-based method on synthetic flows,\nwe apply our method to the CHAOS-8.1 geomagnetic field model, itself based on\ndata from Swarm. Constructing a global mosaic of regional flows, we reproduce\nthe planetary gyre, providing independent evidence that the strong secular\nchanges at high latitude and in equatorial regions are part of the same global\nfeature. Our models also corroborate regional changes in core flows over the\nlast decade. Furthermore, our models endorse the existence of a dynamic high\nlatitude jet, which began accelerating around 2005 but has been weakening since\n2017.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-03T13:27:45Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02576v1","title":"Derivation of the Landau-Zener formula via functional equations","summary":"The Landau-Zener formula describes the diabatic transition probability of a\ntwo-level system under linear driving. Its rigorous derivation typically relies\non sophisticated mathematical tools, such as special functions, Laplace\ntransforms, or contour integrals. In this work, we present a derivation of the\nLandau-Zener transition probability using a fundamentally different approach\nvia functional equations. By leveraging integrability, we prove that this\ntransition probability satisfies a functional equation, whose solutions\nestablish the exponential form of the formula. The coefficient in the exponent\nis then determined through a lowest-order perturbation calculation. This\nderivation is rigorous and mathematically simple. Our work provides new insight\ninto the origin of the exponential form of the Landau-Zener transition\nprobability.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.SI","published":"2025-04-03T13:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.02579v1","title":"Bridging the Gap between Gaussian Diffusion Models and Universal\n  Quantization for Image Compression","summary":"Generative neural image compression supports data representation at extremely\nlow bitrate, synthesizing details at the client and consistently producing\nhighly realistic images. By leveraging the similarities between quantization\nerror and additive noise, diffusion-based generative image compression codecs\ncan be built using a latent diffusion model to \"denoise\" the artifacts\nintroduced by quantization. However, we identify three critical gaps in\nprevious approaches following this paradigm (namely, the noise level, noise\ntype, and discretization gaps) that result in the quantized data falling out of\nthe data distribution known by the diffusion model. In this work, we propose a\nnovel quantization-based forward diffusion process with theoretical foundations\nthat tackles all three aforementioned gaps. We achieve this through universal\nquantization with a carefully tailored quantization schedule and a diffusion\nmodel trained with uniform noise. Compared to previous work, our proposal\nproduces consistently realistic and detailed reconstructions, even at very low\nbitrates. In such a regime, we achieve the best rate-distortion-realism\nperformance, outperforming previous related works.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T13:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"Ramírez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02589v1","title":"Knowledge Graph Completion with Mixed Geometry Tensor Factorization","summary":"In this paper, we propose a new geometric approach for knowledge graph\ncompletion via low rank tensor approximation. We augment a pretrained and\nwell-established Euclidean model based on a Tucker tensor decomposition with a\nnovel hyperbolic interaction term. This correction enables more nuanced\ncapturing of distributional properties in data better aligned with real-world\nknowledge graphs. By combining two geometries together, our approach improves\nexpressivity of the resulting model achieving new state-of-the-art link\nprediction accuracy with a significantly lower number of parameters compared to\nthe previous Euclidean and hyperbolic models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-03T13:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02593v1","title":"On Average Distance, Level-1 Fourier Weight, and Chang's Lemma","summary":"In this paper, we improve the well-known level-1 weight bound, also known as\nChang's lemma, by using an induction method. Our bounds are close to optimal no\nmatter when the set is large or small. Our bounds can be seen as bounds on the\nminimum average distance problem, since maximizing the level-1 weight is\nequivalent to minimizing the average distance. We apply our new bounds to\nimprove the Friedgut--Kalai--Naor theorem. We also derive the sharp version for\nChang's original lemma for $\\mathbb{F}_{2}^{n}$. That is, we show that in\n$\\mathbb{F}_{2}^{n}$, Hamming balls maximize the dimension of the space spanned\nby large Fourier coefficients.","main_category":"math.CO","categories":"math.CO,cs.DM,cs.IT,math.IT","published":"2025-04-03T13:55:39Z"}
{"aid":"http://arxiv.org/abs/2504.02614v1","title":"Single-Particle Dispersion and Density of States of the Half-Filled 2D\n  Hubbard Model","summary":"Implementing an improved method for analytic continuation and working with\nimaginary-time correlation functions computed using quantum Monte Carlo\nsimulations, we resolve the single-particle dispersion relation and the density\nof states (DOS) of the two-dimensional Hubbard model at half-filling. At\nintermediate interactions of $U/t = 4,6$, we find quadratic dispersion around\nthe gap minimum at wave-vectors $\\mathbf{k} = (\\pm \\pi/2, \\pm \\pi/2)$ (the\n$\\Sigma$ points). We find saddle points at $\\mathbf{k} = (\\pm \\pi,0),(0,\\pm\n\\pi)$ (the X points) where the dispersion is quartic, leading to a sharp DOS\nmaximum above the almost flat ledge arising from the states close to $\\Sigma$.\nThe fraction of quasi-particle states within the ledge is $n_{\\rm ledge}\n\\approx 0.15$. Upon doping, within the rigid-band approximation, these results\nsupport Fermi pockets around the $\\Sigma$ points, with states around the X\npoints becoming filled only at doping fractions $x \\ge n_{\\rm ledge}$. The high\ndensity of states and the associated onset of $(\\pi,\\pi)$ scattering may be an\nimportant clue for a finite minimum doping level for superconductivity in the\ncuprates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-03T14:13:57Z"}
{"aid":"http://arxiv.org/abs/2504.02618v1","title":"Variational Online Mirror Descent for Robust Learning in Schrödinger\n  Bridge","summary":"Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\ngenerative models. In practice, however, estimated learning signals are often\nuncertain, and the reliability promised by existing methods is often based on\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\nalgorithm through mirror descent (MD) have gained attention, revealing\ngeometric insights into solution acquisition of the SB problems. In this paper,\nwe propose a variational online MD (OMD) framework for the SB problems, which\nprovides further stability to SB solvers. We formally prove convergence and a\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\npropose a simulation-free SB algorithm called Variational Mirrored\nSchr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\nthe Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\ndynamics that precisely approximate each OMD step. In experiments, we validate\nthe performance of the proposed VMSB algorithm across an extensive suite of\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\nSB problems, demonstrating the robustness predicted by our theory.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T14:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.02619v1","title":"Existence of solutions for time-dependent Signorini problems in\n  linearised viscoelasticity","summary":"In this paper, we establish the existence of solutions for time-dependent\nlinearly viscoelastic bodies confined to a specified half-space. The\nconfinement condition under consideration is of Signorini type, and is given\nover the boundary of the linearly viscoelastic body under consideration. In\norder to derive a suitable notion of solution that possesses a sufficient\ndegree of regularity, we introduce the concept of ``admissible'' applied body\nforce. In agreement with expectations, the variational problem that solutions\nmust satisfy is a system of hyperbolic variational inequalities, and the\ndisplacement acceleration is a vector-valued measure in the sense of\nDinculeanu.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T14:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.02622v1","title":"Exploring undercurrents of learning tensions in an LLM-enhanced\n  landscape: A student-centered qualitative perspective on LLM vs Search","summary":"Large language models (LLMs) are transforming how students learn by providing\nreadily available tools that can quickly augment or complete various learning\nactivities with non-trivial performance. Similar paradigm shifts have occurred\nin the past with the introduction of search engines and Wikipedia, which\nreplaced or supplemented traditional information sources such as libraries and\nbooks. This study investigates the potential for LLMs to represent the next\nshift in learning, focusing on their role in information discovery and\nsynthesis compared to existing technologies, such as search engines. Using a\nwithin-subjects, counterbalanced design, participants learned new topics using\na search engine (Google) and an LLM (ChatGPT). Post-task follow-up interviews\nexplored students' reflections, preferences, pain points, and overall\nperceptions. We present analysis of their responses that show nuanced insights\ninto when, why, and how students prefer LLMs over search engines, offering\nimplications for educators, policymakers, and technology developers navigating\nthe evolving educational landscape.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02655v1","title":"The early universe is $\\textit{ACT}$-ing $\\textit{warm}$","summary":"The recently released data from the $\\textit{Atacama Cosmology Telescope}$\n(ACT) confirms that the primordial scalar spectrum is extremely flat. This,\ntogether with current upper bounds on the tensor-to-scalar ratio, implies that\nthe simplest models of inflation coming from particle physics (for instance, a\nminimally-coupled scalar with monomial potentials) need additional ingredients\nin order to make them compatible with observations. Instead of invoking\narbitrary new couplings or new interactions that are not protected symmetries,\nwe argue that dissipation of the inflaton field with the radiation bath should\nbe added as a new physical principle. Accordingly, we show that warm inflation\nprovides the correct paradigm to explain the current observations, given very\nnatural choices of dissipative terms.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-03T14:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.02660v1","title":"Complex Langevin Simulations of Supersymmetric Theories","summary":"This review explores the Complex Langevin Method (CLM), a stochastic\nquantization technique designed to address the sign problem in quantum field\ntheories with complex actions. Beginning with foundational principles, the\nreview examines the applications of CLM across a range of models, including\nzero- and two-dimensional systems, supersymmetric quantum mechanics, and the\nIKKT matrix model, a candidate for non-perturbative string theory. Key\nadvancements, such as stabilization techniques and mass deformations, are\nhighlighted as solutions to challenges like numerical instability and singular\ndrift terms. The review emphasizes the capacity of CLM to simulate complex\nsystems and reveal non-perturbative phenomena, positioning it as a powerful\ntool for exploring quantum field theory and string theory. Future directions,\nincluding higher-dimensional applications and benchmarking against quantum\nsimulations, underscore the potential of CLM to advance both theoretical\nunderstanding and computational methodologies.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-03T14:56:53Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02672v1","title":"Certified Model Order Reduction for parametric Hermitian eigenproblems","summary":"This article deals with the efficient and certified numerical approximation\nof the smallest eigenvalue and the associated eigenspace of a large-scale\nparametric Hermitian matrix. For this aim, we rely on projection-based model\norder reduction (MOR), i.e., we approximate the large-scale problem by\nprojecting it onto a suitable subspace and reducing it to one of a much smaller\ndimension. Such a subspace is constructed by means of weak greedy-type\nstrategies. After detailing the connections with the reduced basis method for\nsource problems, we introduce a novel error estimate for the approximation\nerror related to the eigenspace associated with the smallest eigenvalue. Since\nthe difference between the second smallest and the smallest eigenvalue, the\nso-called spectral gap, is crucial for the reliability of the error estimate,\nwe propose efficiently computable upper and lower bounds for higher eigenvalues\nand for the spectral gap, which enable the assembly of a subspace for the MOR\napproximation of the spectral gap. Based on that, a second subspace is then\ngenerated for the MOR approximation of the eigenspace associated with the\nsmallest eigenvalue. We also provide efficiently computable conditions to\nensure that the multiplicity of the smallest eigenvalue is fully captured in\nthe reduced space. This work is motivated by a specific application: the\nrepeated identifications of the states with minimal energy, the so-called\nground states, of parametric quantum spin system models.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T15:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.02685v1","title":"STOOD-X methodology: using statistical nonparametric test for OOD\n  Detection Large-Scale datasets enhanced with explainability","summary":"Out-of-Distribution (OOD) detection is a critical task in machine learning,\nparticularly in safety-sensitive applications where model failures can have\nserious consequences. However, current OOD detection methods often suffer from\nrestrictive distributional assumptions, limited scalability, and a lack of\ninterpretability. To address these challenges, we propose STOOD-X, a two-stage\nmethodology that combines a Statistical nonparametric Test for OOD Detection\nwith eXplainability enhancements. In the first stage, STOOD-X uses\nfeature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD\nsamples without assuming a specific feature distribution. In the second stage,\nit generates user-friendly, concept-based visual explanations that reveal the\nfeatures driving each decision, aligning with the BLUE XAI paradigm. Through\nextensive experiments on benchmark datasets and multiple architectures, STOOD-X\nachieves competitive performance against state-of-the-art post hoc OOD\ndetectors, particularly in high-dimensional and complex settings. In addition,\nits explainability framework enables human oversight, bias detection, and model\ndebugging, fostering trust and collaboration between humans and AI systems. The\nSTOOD-X methodology therefore offers a robust, explainable, and scalable\nsolution for real-world OOD detection tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC,stat.ML","published":"2025-04-03T15:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.02688v1","title":"Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication\n  using DRL","summary":"Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted\nnext-generation wireless networks is critical for mobility management and\nensuring UAV safety and ubiquitous connectivity, especially in dense urban\nenvironments with street canyons and tall buildings. Traditional statistical\nand model-based techniques have been successfully used for path optimization in\ncommunication networks. However, when dynamic channel propagation\ncharacteristics such as line-of-sight (LOS), interference, handover, and\nsignal-to-interference and noise ratio (SINR) are included in path\noptimization, statistical and model-based path planning solutions become\nobsolete since they cannot adapt to the dynamic and time-varying wireless\nchannels, especially in the mmWave bands. In this paper, we propose a novel\nmodel-free actor-critic deep reinforcement learning (AC-DRL) framework for path\noptimization in UAV-assisted 5G mmWave wireless networks, which combines four\nimportant aspects of UAV communication: \\textit{flight time, handover,\nconnectivity and SINR}. We train an AC-RL agent that enables a UAV connected to\na gNB to determine the optimal path to a desired destination in the shortest\npossible time with minimal gNB handover, while maintaining connectivity and the\nhighest possible SINR. We train our model with data from a powerful ray tracing\ntool called Wireless InSite, which uses 3D images of the propagation\nenvironment and provides data that closely resembles the real propagation\nenvironment. The simulation results show that our system has superior\nperformance in tracking high SINR compared to other selected RL algorithms.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-04-03T15:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.02695v1","title":"Mind the Gap? Not for SVP Hardness under ETH!","summary":"We prove new hardness results for fundamental lattice problems under the\nExponential Time Hypothesis (ETH). Building on a recent breakthrough by\nBitansky et al. [BHIRW24], who gave a polynomial-time reduction from\n$\\mathsf{3SAT}$ to the (gap) $\\mathsf{MAXLIN}$ problem-a class of CSPs with\nlinear equations over finite fields-we derive ETH-hardness for several lattice\nproblems.\n  First, we show that for any $p \\in [1, \\infty)$, there exists an explicit\nconstant $\\gamma > 1$ such that $\\mathsf{CVP}_{p,\\gamma}$ (the $\\ell_p$-norm\napproximate Closest Vector Problem) does not admit a $2^{o(n)}$-time algorithm\nunless ETH is false. Our reduction is deterministic and proceeds via a direct\nreduction from (gap) $\\mathsf{MAXLIN}$ to $\\mathsf{CVP}_{p,\\gamma}$.\n  Next, we prove a randomized ETH-hardness result for $\\mathsf{SVP}_{p,\\gamma}$\n(the $\\ell_p$-norm approximate Shortest Vector Problem) for all $p > 2$. This\nresult relies on a novel property of the integer lattice $\\mathbb{Z}^n$ in the\n$\\ell_p$ norm and a randomized reduction from $\\mathsf{CVP}_{p,\\gamma}$ to\n$\\mathsf{SVP}_{p,\\gamma'}$.\n  Finally, we improve over prior reductions from $\\mathsf{3SAT}$ to\n$\\mathsf{BDD}_{p, \\alpha}$ (the Bounded Distance Decoding problem), yielding\nbetter ETH-hardness results for $\\mathsf{BDD}_{p, \\alpha}$ for any $p \\in [1,\n\\infty)$ and $\\alpha > \\alpha_p^{\\ddagger}$, where $\\alpha_p^{\\ddagger}$ is an\nexplicit threshold depending on $p$.\n  We additionally observe that prior work implies ETH hardness for the gap\nminimum distance problem ($\\gamma$-$\\mathsf{MDP}$) in codes.","main_category":"cs.CC","categories":"cs.CC,cs.CR,cs.DS","published":"2025-04-03T15:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02711v1","title":"Anisotropy analysis of bamboo and tooth using 4-angle polarization\n  micro-spectroscopy","summary":"To investigate the anisotropic properties of biomaterials, two distinct\nclasses are considered: polymer-based (e.g., cellulose in plants) and\ncrystalline-based (e.g., enamel in teeth), each demonstrating distinct\nstructural and functional characteristics. Four-angle polarization (4-pol.)\nspectral mapping of sub-1 {\\mu}m bamboo slices was carried out in the mid-IR\nspectral range (2.5-20 {\\mu}m) to reveal the 3D organization of the chemical\nbonding of cellulose using the key characteristic absorption bands associated\nwith C-O-C and C-N vibrational modes. The longitudinal and transverse microtome\nslices revealed a switch between the presence and absence of dichroism in\nparenchyma cell walls and vascular bundles. The cell wall showed continuous\nalignment of the C-O-C stretching vibrational mode (8.6 {\\mu}m/1163 cm-1) down\nto the pixel resolution of ~ 4 {\\mu}m (the step size in imaging) in the\ntransverse slice; the cell wall thickness is ~ 1 {\\mu}m. Thin microtomed slices\nof a tooth were measured in transmission and reflection modes. The single-point\nreflection measurements, performed using two perpendicular orientations,\nrevealed orientational anisotropy in the enamel, which was absent in the dentin\nregion. High sub-diffraction limited lateral resolution was numerically\nvalidated using a simplified-model of a Gaussian beam reading out material\npixels with a defined orientation of absorption. It is shown that the\norientation of small ~ {\\lambda}/10 ~ 1 {\\mu}m objects can be revealed using a\nfocal spot of ~ {\\lambda}/NA ~ 20 {\\mu}m, defining the diffraction limit for\nthe objective lens with a numerical aperture NA ~ 0.5.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.med-ph","published":"2025-04-03T15:51:43Z"}
{"aid":"http://arxiv.org/abs/2504.02713v1","title":"Web3DB: Web 3.0 RDBMS for Individual Data Ownership","summary":"This paper introduces Web3DB, a decentralized relational database management\nsystem (RDBMS) designed to align with the principles of Web 3.0, addressing\ncritical shortcomings of traditional centralized DBMS, such as data privacy,\nsecurity vulnerabilities, and single points of failure. Several similar systems\nhave been proposed, but they are not compatible with the legacy systems based\non RDBMS. Motivated by the necessity for enhanced data sovereignty and the\ndecentralization of data control, Web3DB leverages blockchain technology for\nfine-grained access control and utilizes decentralized data storage. This\nsystem leverages a novel, modular architecture that contributes to enhanced\nflexibility, scalability, and user-centric functionality. Central to the Web3DB\ninnovation is its decentralized query execution, which uses cryptographic\nsortition and blockchain verification to ensure secure and fair query\nprocessing across network nodes. The motivation for integrating relational\ndatabases within decentralized DBMS primarily stems from the need to combine\nthe robustness and ease of use of relational database structures with the\nbenefits of decentralization. This paper outlines the architecture of Web3DB,\nits practical implementation, and the system's ability to support SQL-like\noperations on relational data, manage multi-tenancy, and facilitate open data\nsharing, setting new standards for decentralized databases in the Web 3.0 era.","main_category":"cs.DB","categories":"cs.DB,cs.DC","published":"2025-04-03T15:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02736v1","title":"Parity violation as enforced symmetry breaking in 3D fermionic\n  topological order","summary":"Symmetry can be intrinsically broken in topological phases due to inherent\nincompatibilities, a phenomenon known as enforced symmetry breaking (ESB) in\nthe framework of topological order. In our previous work, we developed a\nsystematic framework to understand ESB within 2D invertible topological order.\nMeanwhile, the origin of parity violation in the Standard Model remains one of\nthe most profound mysteries in physics, with no clear explanation to date. In\nthis study, we explore the ESB of parity symmetry by three-dimensional\nfermionic topological order (fTO), offering potential insights into the origins\nof parity violation. As the simplest example, here we consider an fTO related\nto the intrinsic interacting fermionic SPT phase protected by $Z_2^f\\times\nZ_2\\times Z_8$ symmetry in three dimensions. We show that time-reversal\nsymmetry (TRS) with ${T}^2=1$ on physical fermions is incompatible with such\nfTO; then, through the so-called crystalline equivalence principle, we show\nthat the parity symmetry is also incompatible with it. In comparison,\nconventional TRS with ${T}^2={P}_f$ remains compatible to this fTO. We also\ndiscuss a general framework to study the ESB phenomenon for 3D fTO.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-ph,hep-th","published":"2025-04-03T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02740v1","title":"Faster Mixing of the Jerrum-Sinclair Chain","summary":"We show that the Jerrum-Sinclair Markov chain on matchings mixes in time\n$\\widetilde{O}(\\Delta^2 m)$ on any graph with $n$ vertices, $m$ edges, and\nmaximum degree $\\Delta$, for any constant edge weight $\\lambda>0$. For general\ngraphs with arbitrary, potentially unbounded $\\Delta$, this provides the first\nimprovement over the classic $\\widetilde{O}(n^2 m)$ mixing time bound of Jerrum\nand Sinclair (1989) and Sinclair (1992).\n  To achieve this, we develop a general framework for analyzing mixing times,\ncombining ideas from the classic canonical path method with the\n\"local-to-global\" approaches recently developed in high-dimensional expanders,\nintroducing key innovations to both techniques.","main_category":"cs.DS","categories":"cs.DS,cs.DM,math.PR","published":"2025-04-03T16:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.02744v1","title":"The Ordering Principle and Dependent Choice","summary":"We introduce finite support iterations of symmetric systems, and use them to\nprovide a strongly modernized proof of David Pincus' classical result that the\naxiom of dependent choice is independent over ZF with the ordering principle\ntogether with a failure of the axiom of choice.","main_category":"math.LO","categories":"math.LO","published":"2025-04-03T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.02765v1","title":"Robot-Led Vision Language Model Wellbeing Assessment of Children","summary":"This study presents a novel robot-led approach to assessing children's mental\nwellbeing using a Vision Language Model (VLM). Inspired by the Child\nApperception Test (CAT), the social robot NAO presented children with pictorial\nstimuli to elicit their verbal narratives of the images, which were then\nevaluated by a VLM in accordance with CAT assessment guidelines. The VLM's\nassessments were systematically compared to those provided by a trained\npsychologist. The results reveal that while the VLM demonstrates moderate\nreliability in identifying cases with no wellbeing concerns, its ability to\naccurately classify assessments with clinical concern remains limited.\nMoreover, although the model's performance was generally consistent when\nprompted with varying demographic factors such as age and gender, a\nsignificantly higher false positive rate was observed for girls, indicating\npotential sensitivity to gender attribute. These findings highlight both the\npromise and the challenges of integrating VLMs into robot-led assessments of\nchildren's wellbeing.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-03T17:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.02770v1","title":"Efficient Algorithms for Cardinality Estimation and Conjunctive Query\n  Evaluation With Simple Degree Constraints","summary":"Cardinality estimation and conjunctive query evaluation are two of the most\nfundamental problems in database query processing. Recent work proposed,\nstudied, and implemented a robust and practical information-theoretic\ncardinality estimation framework. In this framework, the estimator is the\ncardinality upper bound of a conjunctive query subject to\n``degree-constraints'', which model a rich set of input data statistics. For\ngeneral degree constraints, computing this bound is computationally hard.\nResearchers have naturally sought efficiently computable relaxed upper bounds\nthat are as tight as possible. The polymatroid bound is the tightest among\nthose relaxed upper bounds. While it is an open question whether the\npolymatroid bound can be computed in polynomial-time in general, it is known to\nbe computable in polynomial-time for some classes of degree constraints.\n  Our focus is on a common class of degree constraints called simple degree\nconstraints. Researchers had not previously determined how to compute the\npolymatroid bound in polynomial time for this class of constraints. Our first\nmain result is a polynomial time algorithm to compute the polymatroid bound\ngiven simple degree constraints. Our second main result is a polynomial-time\nalgorithm to compute a ``proof sequence'' establishing this bound. This proof\nsequence can then be incorporated in the PANDA-framework to give a faster\nalgorithm to evaluate a conjunctive query. In addition, we show computational\nlimitations to extending our results to broader classes of degree constraints.\nFinally, our technique leads naturally to a new relaxed upper bound called the\n{\\em flow bound}, which is computationally tractable.","main_category":"cs.DB","categories":"cs.DB,cs.DS","published":"2025-04-03T17:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02790v1","title":"Dynamic Treewidth in Logarithmic Time","summary":"We present a dynamic data structure that maintains a tree decomposition of\nwidth at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is\nupdated by edge insertions and deletions. The amortized update time of our data\nstructure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data\nstructure also supports maintaining any ``dynamic programming scheme'' on the\ntree decomposition, providing, for example, a dynamic version of Courcelle's\ntheorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation\nhides factors that depend on $k$. This improves upon a result of Korhonen,\nMajewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar\ndata structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.\nFurthermore, our data structure is arguably simpler.\n  Our main novel idea is to maintain a tree decomposition that is ``downwards\nwell-linked'', which allows us to implement local rotations and analysis\nsimilar to those for splay trees.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-03T17:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02791v1","title":"Variability study of classical supergiant X-ray binary 4U 1907+09 using\n  NuSTAR","summary":"We investigate the X-ray variability of the supergiant X-ray binary 4U\n1907+09 using the new NuSTAR observation of 2024. The source had a relatively\nstable flux level during previous NuSTAR observations, but the flux varied\nsignificantly during the current one. The light curve exhibits dips (off-state)\nand flares (on-state). The phase-coherent timing analysis during the on-state\nyields a pulse period of $443.99(4)~\\mathrm{s}$, showing the pulsar's continued\nspin-down. The pulse profiles show an asymmetric double-peaked structure with a\nphase separation of 0.47 between the two peaks. A cyclotron resonance\nscattering feature (CRSF) is also detected at $\\sim 17.6~\\mathrm{keV}$, along\nwith its harmonic at $\\sim 38~\\mathrm{keV}$, persisting across all flux states.\nFlux-resolved spectroscopy reveals that the CRSF remains constant despite a\n25-fold change in flux. The spectral parameters like photon index and e-fold\nenergy are out of phase with the pulse shape, whereas cutoff energy is in phase\nwith the pulse shape. The source's luminosity during the on-state is $2.85\n\\times 10^{35}~\\mathrm{erg~s^{-1}}$, consistent with a \"pencil\" beam radiation\npattern expected at this flux level from a collisionless gas-mediated shock.\nThese results offer further insights into the accretion dynamics and magnetic\nfield geometry of this system.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T17:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.02793v1","title":"A Framework for Situating Innovations, Opportunities, and Challenges in\n  Advancing Vertical Systems with Large AI Models","summary":"Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY,cs.HC","published":"2025-04-03T17:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.02794v1","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies\n  and Emotions","summary":"The need to improve geriatric care quality presents a challenge that requires\ninsights from stakeholders. While simulated trainings can boost competencies,\nextracting meaningful insights from these practices to enhance simulation\neffectiveness remains a challenge. In this study, we introduce Multimodal\nEpistemic Network Analysis (MENA), a novel framework for analyzing caregiver\nattitudes and emotions in an Augmented Reality setting and exploring how the\nawareness of a virtual geriatric patient (VGP) impacts these aspects. MENA\nenhances the capabilities of Epistemic Network Analysis by detecting positive\nemotions, enabling visualization and analysis of complex relationships between\ncaregiving competencies and emotions in dynamic caregiving practices. The\nframework provides visual representations that demonstrate how participants\nprovided more supportive care and engaged more effectively in person-centered\ncaregiving with aware VGP. This method could be applicable in any setting that\ndepends on dynamic interpersonal interactions, as it visualizes connections\nbetween key elements using network graphs and enables the direct comparison of\nmultiple networks, thereby broadening its implications across various fields.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T17:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.02808v1","title":"Quantum theory does not need complex numbers","summary":"The longstanding debate over whether quantum theory fundamentally requires\ncomplex numbers--or if their use is merely a convenient choice--has persisted\nfor decades. Until recently, this question was considered open. However, in\n[M.-O. Renou et al, Nature 600, 625-629, 2021], a decisive argument was\npresented asserting that quantum theory needs complex numbers. In this work, we\ndemonstrate that a formulation of quantum theory based solely on real numbers\nis indeed possible while retaining key features such as theory-representation\nlocality (i.e. local physical operations are represented by local changes to\nthe states) and the positive semi-definiteness of its states and effects. We\nobserve that the standard system combination rule--the tensor product--was\nderived after the development of single-system complex quantum theory. By\nstarting from a single-system quantum theory using only real numbers, we derive\na combination rule that produces a real quantum theory with properties\nanalogous to those of conventional complex quantum theory. We also prove that\nthe conventional tensor product rule can also lead to a real and\nrepresentation-local theory, albeit with a modified characterization of the\nstate space. We thus conclude that complex numbers are a mere convenience in\nquantum theory.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T17:53:19Z"}
{"aid":"http://arxiv.org/abs/2504.02811v1","title":"An Assessment of the CO2 Emission Reduction Potential of Residential\n  Load Management in Developing and Developed Countries","summary":"Intermittent renewable energies are increasingly dominating electricity grids\nand are forecasted to be the main force driving out fossil fuels from the grid\nin most major economies until 2040. However, grids based on intermittent\nrenewables are challenged by diurnal and seasonal mismatch between supply of\nsun and wind and demand for electricity, including for heat pumps and electric\ntwo and four wheelers. Load management and demand response measures promise to\nadjust for this mismatch, utilizing information- and price-based approaches to\nsteer demand towards times with high supply of intermittent renewables. Here,\nwe systematically review the literature estimating CO2 savings from residential\nload management in developing and developed nations. We find that load\nmanagement holds high potential, locally differentiated with energy mix\n(including the respective share of renewables and fossils), climate zone, and\nthe regulatory environment and price mechanism. Most identified studies suggest\na mitigation potential between 1 and 20%. Load management becomes more relevant\nwith higher shares of intermittent renewables, and when electricity prices are\nhigh. Importantly, load management aligns consumers' financial incentives with\nclimate change mitigation, thus rendering accompanying strategies politically\nfeasible. We summarize key regulatory steps to facilitate load management in\neconomies and to realize relevant consumer surplus and mitigation potential.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T17:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.02812v1","title":"BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose\n  Estimation","summary":"We present the evaluation methodology, datasets and results of the BOP\nChallenge 2024, the sixth in a series of public competitions organized to\ncapture the state of the art in 6D object pose estimation and related tasks. In\n2024, our goal was to transition BOP from lab-like setups to real-world\nscenarios. First, we introduced new model-free tasks, where no 3D object models\nare available and methods need to onboard objects just from provided reference\nvideos. Second, we defined a new, more practical 6D object detection task where\nidentities of objects visible in a test image are not provided as input. Third,\nwe introduced new BOP-H3 datasets recorded with high-resolution sensors and\nAR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D\nmodels and onboarding videos to support both model-based and model-free tasks.\nParticipants competed on seven challenge tracks, each defined by a task, object\nonboarding setup, and dataset group. Notably, the best 2024 method for\nmodel-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher\naccuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only\n4% behind the best 2023 method for seen objects (GPose2023) although being\nsignificantly slower (24.9 vs 2.7s per image). A more practical 2024 method for\nthis task is Co-op which takes only 0.8s per image and is 25X faster and 13%\nmore accurate than GenFlow. Methods have a similar ranking on 6D detection as\non 6D localization but higher run time. On model-based 2D detection of unseen\nobjects, the best 2024 method (MUSE) achieves 21% relative improvement compared\nto the best 2023 method (CNOS). However, the 2D detection accuracy for unseen\nobjects is still noticealy (-53%) behind the accuracy for seen objects\n(GDet2023). The online evaluation system stays open and is available at\nhttp://bop.felk.cvut.cz/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.02814v1","title":"Convergence of the Markovian iteration for coupled FBSDEs via a\n  differentiation approach","summary":"In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR,q-fin.CP","published":"2025-04-03T17:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.02816v1","title":"On cycle covers of infinite bipartite graphs","summary":"Given a graph $G$ and a subset $X$ of vertices of $G$ with size at least two,\nwe denote by $N^2_G(X)$ the set of vertices of $G$ that have at least two\nneighbors in $X$. We say that a bipartite graph $G$ with sides $A$ and $B$\nsatisfies the double Hall property if for every subset $X$ of vertices of $A$\nwith size at least 2, $\\vert N^2_G(X)\\vert \\geq \\vert X\\vert$. Salia\nconjectured that if $G$ is a bipartite graph that satisfies the double Hall\nproperty, then there exists a cycle in $G$ that covers all vertices of $A$. In\nthis work, we study this conjecture restricted to infinite graphs. For this, we\nuse the definition of ends and infinite cycles. It is simple to see that\nSalia's conjecture is false for infinite graphs in general. Consequently, all\nour results are partial. Under certain hypothesis it is possible to obtain a\ncollection of pairwise disjoint 2-regular subgraphs that covers $A$. We show\nthat if side $B$ is locally finite and side $A$ is countable, then the\nconjecture is true. Furthermore, assuming the conjecture holds for finite\ngraphs, we show that it holds for infinite graphs with a restriction on the\ndegree of the vertices of $B$. This result is inspired by the result obtained\nby Bar\\'at, Grzesik, Jung, Nagy and P\\'alv\\\"olgyi for finite graphs. Finally,\nwe also show that if Salia's conjecture holds for some cases of infinite\ngraphs, then the conjecture about finite graphs presented by Lavrov and\nVandenbussche is true.","main_category":"math.CO","categories":"math.CO,math.GN","published":"2025-04-03T17:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.02818v1","title":"Universal Log-Optimality for General Classes of e-processes and\n  Sequential Hypothesis Tests","summary":"We consider the problem of sequential hypothesis testing by betting. For a\ngeneral class of composite testing problems -- which include bounded mean\ntesting, equal mean testing for bounded random tuples, and some key ingredients\nof two-sample and independence testing as special cases -- we show that any\n$e$-process satisfying a certain sublinear regret bound is adaptively,\nasymptotically, and almost surely log-optimal for a composite alternative. This\nis a strong notion of optimality that has not previously been established for\nthe aforementioned problems and we provide explicit test supermartingales and\n$e$-processes satisfying this notion in the more general case. Furthermore, we\nderive matching lower and upper bounds on the expected rejection time for the\nresulting sequential tests in all of these cases. The proofs of these results\nmake weak, algorithm-agnostic moment assumptions and rely on a general-purpose\nproof technique involving the aforementioned regret and a family of numeraire\nportfolios. Finally, we discuss how all of these theorems hold in a\ndistribution-uniform sense, a notion of log-optimality that is stronger still\nand seems to be new to the literature.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-04-03T17:58:10Z"}
{"aid":"http://arxiv.org/abs/2504.02824v1","title":"Observation of non-Hermitian dislocation bound states and dislocation\n  skin effects","summary":"The confluence of Non-Hermitian (NH) topology and crystal defects has\nculminated significant interest, yet its experimental exploration has been\nlimited due to the challenges involved in design and measurements. Here, we\nshowcase experimental observation of NH dislocation bound states (NHDS) and the\ndislocation-induced NH skin effect in two-dimensional acoustic NH Chern\nlattices. By embedding edge dislocations in such acoustic lattices and\nimplementing precision-controlled hopping and onsite gain/loss via active\nmeta-atoms, we reveal robust defect-bound states localized at dislocation cores\nwithin the line gap of the complex energy spectrum. These NHDS survive against\nmoderate NH perturbations but gradually delocalize and merge with the bulk\n(skin) states as the system arrives at the shore of fostering exceptional\npoints in the Brillouin zone under periodic (open) boundary conditions.\nFurthermore, our experiments demonstrate that the dislocation core can feature\nweak NH skin effects when its direction is perpendicular to the Burgers vector\nin periodic systems. Our findings pave an experimental pathway for probing NH\ntopology via lattice defects and open new avenues for defect-engineered\ntopological devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.class-ph,quant-ph","published":"2025-04-03T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.02826v1","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual\n  Editing","summary":"Large Multi-modality Models (LMMs) have made significant progress in visual\nunderstanding and generation, but they still face challenges in General Visual\nEditing, particularly in following complex instructions, preserving appearance\nconsistency, and supporting flexible input formats. To address this gap, we\nintroduce RISEBench, the first benchmark for evaluating Reasoning-Informed\nviSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal,\nCausal, Spatial, and Logical Reasoning. We curate high-quality test cases for\neach category and propose an evaluation framework that assesses Instruction\nReasoning, Appearance Consistency, and Visual Plausibility with both human\njudges and an LMM-as-a-judge approach. Our experiments reveal that while\nGPT-4o-Native significantly outperforms other open-source and proprietary\nmodels, even this state-of-the-art system struggles with logical reasoning\ntasks, highlighting an area that remains underexplored. As an initial effort,\nRISEBench aims to provide foundational insights into reasoning-aware visual\nediting and to catalyze future research. Though still in its early stages, we\nare committed to continuously expanding and refining the benchmark to support\nmore comprehensive, reliable, and scalable evaluations of next-generation\nmultimodal systems. Our code and data will be released at\nhttps://github.com/PhoenixZ810/RISEBench.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.04726v1","title":"Can LLM-Driven Hard Negative Sampling Empower Collaborative Filtering?\n  Findings and Potentials","summary":"Hard negative samples can accelerate model convergence and optimize decision\nboundaries, which is key to improving the performance of recommender systems.\nAlthough large language models (LLMs) possess strong semantic understanding and\ngeneration capabilities, systematic research has not yet been conducted on how\nto generate hard negative samples effectively. To fill this gap, this paper\nintroduces the concept of Semantic Negative Sampling and exploreshow to\noptimize LLMs for high-quality, hard negative sampling. Specifically, we design\nan experimental pipeline that includes three main modules, profile generation,\nsemantic negative sampling, and semantic alignment, to verify the potential of\nLLM-driven hard negative sampling in enhancing the accuracy of collaborative\nfiltering (CF). Experimental results indicate that hard negative samples\ngenerated based on LLMs, when semantically aligned and integrated into CF, can\nsignificantly improve CF performance, although there is still a certain gap\ncompared to traditional negative sampling methods. Further analysis reveals\nthat this gap primarily arises from two major challenges: noisy samples and\nlack of behavioral constraints. To address these challenges, we propose a\nframework called HNLMRec, based on fine-tuning LLMs supervised by collaborative\nsignals. Experimental results show that this framework outperforms traditional\nnegative sampling and other LLM-driven recommendation methods across multiple\ndatasets, providing new solutions for empowering traditional RS with LLMs.\nAdditionally, we validate the excellent generalization ability of the LLM-based\nsemantic negative sampling method on new datasets, demonstrating its potential\nin alleviating issues such as data sparsity, popularity bias, and the problem\nof false hard negative samples. Our implementation code is available at\nhttps://github.com/user683/HNLMRec.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T04:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.04737v1","title":"TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction\n  and Explanation in the Indian Legal Context","summary":"In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T05:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04743v1","title":"AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation","summary":"Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.04759v1","title":"Taming Flat Bands with Breathing Superlattices","summary":"Flat bands have become a pillar of modern condensed matter physics and\nphotonics owing to the vanishing group velocity and diverging density of\nstates. Here, we present a paradigmatic scheme to construct arbitrary flat\nbands on demand by introducing a new type breathing superlattice, where both\nthe number and spectral positions of isolated flat bands can be continuously\ntailored by simply controlling the breathing strength. Microscopically, the\nmomentum-independent interband scatterings near the band edge protect them\nrobust against weak intra-cell disorder. By dimensional reduction, we establish\na duality between the one-dimensional (1D) breathing superlattice and the 2D\nHarper-Hofstadter model, where cascade flat bands naturally emerge as the\ndifferent orders of Landau levels in the weak magnetic flux limit. As a proof\nof concept, photonic flat bands at optical frequencies are experimentally\ndemonstrated with all-dielectric photonic crystal slabs. Finally, we generalize\nour scheme to 2D systems to realize partial and omnidirectional flat bands, and\ndiscuss the achievement of high-quality factors. Our findings shed new light on\nthe manipulation of flat bands with high band flatness and large usable\nbandwidth, paving the way for the development of advanced optical devices.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-07T06:14:26Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04769v1","title":"Scalable simulation of random quantum circuits using projected\n  entangled-pair states","summary":"Classical simulation of a programmable quantum processor is crucial in\nidentifying the threshold of a quantum advantage. We use the simple update of\nprojected entangled-pair states (PEPSs) in the Vidal gauge to simulate the\nstates of random quantum circuits (RQCs), which center around recent quantum\nadvantage claims. Applied to square lattices of qubits akin to state-of-the-art\nsuperconducting processors, our PEPS simulation is exact for circuit depths\nless than $D_\\mathrm{tr}$ = $\\beta\\log_2\\chi$, where $\\chi$ is the maximum bond\ndimension and $2 \\lesssim \\beta \\lesssim 4$ depends on the choice of two-qubit\ngates, independent of the qubit number $n$. We find the universal scaling\nbehaviors of the state fidelity by performing large-scale simulations for $n\n\\leq 10^{4}$ or $\\chi \\leq 128$ on a conventional CPU. Our method has\ncomputational cost scaling polynomially with $n$ for circuit depth $D =O(\\log\nn)$ and is more advantageous than matrix product state (MPS) approaches if $n$\nis large. This work underscores PEPSs as a scalable tool for benchmarking\nquantum algorithms, with future potential for sampling applications using\nadvanced contraction techniques.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-07T06:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04779v1","title":"Black hole destabilization via trapped quasi-normal modes","summary":"In the presence of non-minimal gravitational couplings, matter field\nperturbations on a static black hole spacetime may develop unphysical poles in\ntheir linearized equations. Physical solutions confined in the domain between\nthe event horizon and a pole satisfy a boundary value problem, although with\nboundary conditions which are different from standard quasi-normal modes. We\nrefer to them as \"trapped quasi-normal modes\". Focusing on a Schwarzschild\nblack hole in Einstein-Proca theory, we find that trapped quasi-normal modes\naccurately capture the behavior of perturbations under time evolution. In\nparticular, axial-vector modes are unstable, with a growth rate that increases\nwith multipole number. More interestingly, we uncover a new instability that\naffects monopole perturbations. These results confirm the existence of a novel\ndestabilization mechanism of black holes by non-minimally coupled vector\nfields, with potential implications to well-studied models of modified gravity\nand cosmology based on vector particles.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T07:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.04783v1","title":"Playing Non-Embedded Card-Based Games with Reinforcement Learning","summary":"Significant progress has been made in AI for games, including board games,\nMOBA, and RTS games. However, complex agents are typically developed in an\nembedded manner, directly accessing game state information, unlike human\nplayers who rely on noisy visual data, leading to unfair competition.\nDeveloping complex non-embedded agents remains challenging, especially in\ncard-based RTS games with complex features and large state spaces. We propose a\nnon-embedded offline reinforcement learning training strategy using visual\ninputs to achieve real-time autonomous gameplay in the RTS game Clash Royale.\nDue to the lack of a object detection dataset for this game, we designed an\nefficient generative object detection dataset for training. We extract features\nusing state-of-the-art object detection and optical character recognition\nmodels. Our method enables real-time image acquisition, perception feature\nfusion, decision-making, and control on mobile devices, successfully defeating\nbuilt-in AI opponents. All code is open-sourced at\nhttps://github.com/wty-yy/katacr.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T07:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04787v1","title":"Dynamic Vision Mamba","summary":"Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T07:31:28Z"}
{"aid":"http://arxiv.org/abs/2504.04812v1","title":"Sparse Optimization for Transfer Learning: A L0-Regularized Framework\n  for Multi-Source Domain Adaptation","summary":"This paper explores transfer learning in heterogeneous multi-source\nenvironments with distributional divergence between target and auxiliary\ndomains. To address challenges in statistical bias and computational\nefficiency, we propose a Sparse Optimization for Transfer Learning (SOTL)\nframework based on L0-regularization. The method extends the Joint Estimation\nTransferred from Strata (JETS) paradigm with two key innovations: (1)\nL0-constrained exact sparsity for parameter space compression and complexity\nreduction, and (2) refining optimization focus to emphasize target parameters\nover redundant ones. Simulations show that SOTL significantly improves both\nestimation accuracy and computational speed, especially under adversarial\nauxiliary domain conditions. Empirical validation on the Community and Crime\nbenchmarks demonstrates the statistical robustness of the SOTL method in\ncross-domain transfer.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-07T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2504.04813v1","title":"Generalized Fermi-Dirac Distribution of Exclusive Fermions","summary":"A system of exclusive fermions occurs when two fermions of opposite spin are\nprohibited from occupying the same quantum level. We derive the distribution of\nexclusive fermions via the employment of the grand canonical ensemble. Salient\nfeatures of its statistical properties, compared to the free electron gases,\ninclude: larger Fermi energy, higher degeneracy pressure, but the same Pauli\nparamagnetism and Landau diamagnetism. In particular, higher degeneracy\npressure leads to an inflation of the Chandrasekhar limit to 1.6 times when\napplied to white dwarf stars and neutron stars.","main_category":"math-ph","categories":"math-ph,astro-ph.SR,cond-mat.stat-mech,math.MP","published":"2025-04-07T08:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.04816v1","title":"Network Effects of Tariffs","summary":"We develop a model in which country-specific tariffs shape trade flows,\nprices, and welfare in a global economy with one homogeneous good. Trade flows\nform a Directed Acyclic Graph (DAG), and tariffs influence not only market\noutcomes but also the structure of the global trade network. A numerical\nexample illustrates how tariffs may eliminate targeted imports, divert trade\nflows toward third markets, expose domestic firms to intensified foreign\ncompetition abroad, reduce consumer welfare, and ultimately harm the country\nimposing the tariff.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-07T08:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.04842v1","title":"FantasyTalking: Realistic Talking Portrait Generation via Coherent\n  Motion Synthesis","summary":"Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04853v1","title":"Charmonium-nucleon femtoscopic correlation function","summary":"This study investigates the femtoscopic correlation functions of\ncharmonium-nucleon pairs, utilizing the lattice QCD phase shifts provided by\nthe HAL QCD Collaboration. A model-independent formalism is employed to\ntransform scattering phase shifts directly into momentum correlation functions,\nthereby circumventing the approximations inherent in traditional methods, such\nas the Lednick\\'y-Lyuboshits model. The $J/\\psi$-$p$ correlation functions,\nincluding spin-averaged and partial-wave results, are predicted using\nnear-physical pion mass lattice results. The $\\eta_c$-$p$ correlation function\nis calculated for the first time. The derived correlation functions provide\ncritical references for future experiments, such as those at the LHC, where\nhigh-precision measurements of charmonium-nucleon correlations could unveil\nvaluable insights into non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T09:10:58Z"}
{"aid":"http://arxiv.org/abs/2504.04854v1","title":"Traversable wormholes with multiple unstable critical curves","summary":"The number and position of unstable critical curves, as well as the nature of\nthe accretion disk around compact objects, play a fundamental role in their\noptical appearance. Identifying differences in the optical spectrum of various\nobserved compact objects can help classify them as black holes or black hole\nmimickers, such as traversable wormholes. Although multiple unstable critical\ncurves have been reported to appear in asymmetric traversable wormholes, in\nthis work we construct symmetric traversable wormholes with multiple unstable\ncritical curves. We propose a general rational redshift function that allows us\nto trace the number of critical points of the effective potential and determine\ntheir nature as maxima or minima. The ray tracing method is used to study the\ntrajectories of massless particles, particularly their behavior near the\nunstable critical points. Finally, a thin accretion disk model is implemented\nto analyze the optical appearance of the solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T09:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04876v1","title":"Hereditarily and Super Generalized co-Bassian Abelian Groups","summary":"We completely characterize by finding necessary and sufficient conditions\nthose co-Bassian and generalized co-Bassian Abelian groups having,\nrespectively, the hereditary or the super property, thus giving a new insight\nin the full discovery of the structure of these two classes of groups as\nrecently defined in Arch. Math. Basel (2024) by the third author.","main_category":"math.GR","categories":"math.GR,math.AC","published":"2025-04-07T09:36:26Z"}
{"aid":"http://arxiv.org/abs/2504.04878v1","title":"Analysis and Computation of Geodesic Distances on Reductive Homogeneous\n  Spaces","summary":"Many geometric machine learning and image analysis applications, require a\nleft-invariant metric on the 5D homogeneous space of 3D positions and\norientations SE(3)/SO(2). This is done in Equivariant Neural Networks (G-CNNs),\nor in PDE-Based Group Convolutional Neural Networks (PDE-G-CNNs), where the\nRiemannian metric enters in multilayer perceptrons, message passing, and\nmax-pooling over Riemannian balls.\n  In PDE-G-CNNs it is proposed to take the minimum left-invariant Riemannian\ndistance over the fiber in SE(3)/SO(2), whereas in G-CNNs and in many geometric\nimage processing methods an efficient SO(2)-conjugation invariant section is\nadvocated.\n  The conjecture rises whether that computationally much more efficient section\nindeed always selects distance minimizers over the fibers. We show that this\nconjecture does NOT hold in general, and in the logarithmic norm approximation\nsetting used in practice we analyze the small (and sometimes vanishing)\ndifferences. We first prove that the minimal distance section is reached by\nminimal horizontal geodesics with constant momentum and zero acceleration along\nthe fibers, and we generalize this result to (reductive) homogeneous spaces\nwith legal metrics and commutative structure groups.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T09:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.04883v1","title":"How Far do Lindbladians Go?","summary":"We investigate geometric aspects of the space of densities by analyzing\ntransport along paths generated by quantum Markovian semigroups and more\ngenerally locally Markovian, or time-dependent Lindbladian, dynamics. Motivated\nby practical constraints, we also consider a more realistic scenario in which\nonly a restricted set of Lindbladian generators is available. We study the\ncorresponding transitivity properties and characterize the set of states that\ncan be reached using such limited dynamical resources.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.FA,math.MP","published":"2025-04-07T09:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.04923v1","title":"Truncated sequential guaranteed estimation for the Cox-Ingersoll-Ross\n  models","summary":"The drift sequential parameter estimation problems for the Cox-Ingersoll-Ross\n(CIR) processes under the limited duration of observation are studied.\nTruncated sequential estimation methods for both scalar and {two}-dimensional\nparameter cases are proposed. In the non-asymptotic setting, for the proposed\ntruncated estimators, the properties of guaranteed mean-square estimation\naccuracy are established. In the asymptotic formulation, when the observation\ntime tends to infinity, it is shown that the proposed sequential procedures are\nasymptotically optimal among all possible sequential and non-sequential\nestimates with an average estimation time less than the fixed observation\nduration. It also turned out that asymptotically, without degrading the\nestimation quality, they significantly reduce the observation duration compared\nto classical non-sequential maximum likelihood estimations based on a fixed\nobservation duration.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T11:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.04928v1","title":"Advanced Codebook Design for SCMA-aided NTNs With Randomly Distributed\n  Users","summary":"In this letter, a novel class of sparse codebooks is proposed for sparse code\nmultiple access (SCMA) aided non-terrestrial networks (NTN) with randomly\ndistributed users characterized by Rician fading channels. Specifically, we\nfirst exploit the upper bound of bit error probability (BEP) of an SCMA-aided\nNTN with large-scale fading of different users under Rician fading channels.\nThen, the codebook is designed by employing pulse-amplitude modulation\nconstellation, user-specific rotation and power factors. To further reduce the\noptimization complexity while maintaining the power diversity of different\nusers, an orthogonal layer-assisted joint layer and power assignment strategy\nis proposed. Finally, unlike existing SCMA codebook designs that treat all\nusers as one super-user, we propose to minimize the BEP of the worst user to\nensure user fairness. The simulation results show that the proposed scheme is\ncapable of providing a substantial performance gain over conventional\ncodebooks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T11:10:44Z"}
{"aid":"http://arxiv.org/abs/2504.04931v1","title":"The $L_{p}$ dual Christoffel-Minkowski problem for $1<p<q\\leq k+1$ with\n  $1\\leq k\\leq n$","summary":"In this paper, we investigate an $L_{p}$ Christoffel-Minkowski-type problem\nthat prescribes a class of $L_p$ geometric measures, which are mixtures of the\n$k$-th area measure and the $q$-th dual curvature measure. By establishing a\ngradient estimate, we obtain the existence of an even, smooth, strictly convex\nsolution to this problem for $1 < p < q \\leq k + 1$, where $1 \\leq k \\leq n$\nand $n \\geq 1$.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-07T11:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.04935v1","title":"RCCFormer: A Robust Crowd Counting Network Based on Transformer","summary":"Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T11:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.04937v1","title":"Hybrid Control Barrier Functions for Nonholonomic Multi-Agent Systems","summary":"This paper addresses the problem of guaranteeing safety of multiple\ncoordinated agents moving in dynamic environments. It has recently been shown\nthat this problem can be efficiently solved through the notion of Control\nBarrier Functions (CBFs). However, for nonholonomic vehicles that are required\nto keep positive speeds, existing CBFs lose their validity. To overcome this\nlimitation, we propose a hybrid formulation based on synergistic CBFs (SCBFs),\nwhich leverages a discrete switching mechanism to avoid configurations that\nwould render the CBF invalid. Unlike existing approaches, our method ensures\nsafety in the presence of moving obstacles and inter-agent interactions while\nrespecting nonzero speed restrictions. We formally analyze the feasibility of\nthe constraints with respect to actuation limits, and the efficacy of the\nsolution is demonstrated in simulation of a multi-agent coordination problem in\nthe presence of moving obstacles.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2504.04940v1","title":"Fine tuning generative adversarial networks with universal force fields:\n  application to two-dimensional topological insulators","summary":"Despite rapid growth in use cases for generative artificial intelligence, its\nability to design purpose built crystalline materials remains in a nascent\nphase. At the moment inverse design is generally accomplished by either\nconstraining the training data set or producing a vast number of samples from a\ngenerator network and constraining the output via post-processing. We show that\na general adversarial network trained to produce crystal structures from a\nlatent space can be fine tuned through the introduction of advanced graph\nneural networks as discriminators, including a universal force field, to\nintrinsically bias the network towards generation of target materials. This is\nexemplified utilizing two-dimensional topological insulators as a sample target\nspace. While a number of two-dimensional topological insulators have been\npredicted, the size of the band-gap, a measure of topological protection,\nremains a concern in most candidate compounds. The resulting generative network\nis shown to yield novel topological insulators.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T11:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04943v1","title":"Emergence of microbial host dormancy during a persistent virus epidemic","summary":"We study a minimal stochastic individual-based model for a microbial\npopulation challenged by a persistent (lytic) virus epidemic. We focus on the\nsituation in which the resident microbial host population and the virus\npopulation are in stable coexistence upon arrival of a single new ``mutant''\nhost individual. We assume that this mutant is capable of switching to a\nreversible state of dormancy upon contact with virions as a means of avoiding\ninfection by the virus. At the same time, we assume that this new dormancy\ntrait comes with a cost, namely a reduced individual reproduction rate. We\nprove that there is a non-trivial range of parameters where the mutants can\nnevertheless invade the resident population with strictly positive probability\n(bounded away from 0) in the large population limit. Given the reduced\nreproductive rate, such an invasion would be impossible in the absence of\neither the dormancy trait or the virus epidemic. We explicitly characterize the\nparameter regime where this emergence of a (costly) host dormancy trait is\npossible, determine the success probability of a single invader and the typical\namount of time it takes the successful mutants to reach a macroscopic\npopulation size. We conclude this study by an investigation of the fate of the\npopulation after the successful emergence of a dormancy trait. Heuristic\narguments and simulations suggest that after successful invasion, either both\nhost types and the virus will reach coexistence, or the mutants will drive the\nresident hosts to extinction while the virus will stay in the system.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.04957v1","title":"On the Hausdorff dimension of maximal chains and antichains of Turing\n  and Hyperarithmetic degrees","summary":"This paper investigates the Hausdorff dimension properties of chains and\nantichains in Turing degrees and hyperarithmetic degrees. Our main\ncontributions are threefold: First, for antichains in hyperarithmetic degrees,\nwe prove that every maximal antichain necessarily attains Hausdorff dimension\n1. Second, regarding chains in Turing degrees, we establish the existence of a\nmaximal chain with Hausdorff dimension 0. Furthermore, under the assumption\nthat $\\omega_1=(\\omega_1)^L$, we demonstrate the existence of such maximal\nchains with $\\Pi^1_1$ complexity. Third, we extend our investigation to maximal\nantichains of Turing degrees by analyzing both the packing dimension and\neffective Hausdorff dimension.","main_category":"math.LO","categories":"math.LO","published":"2025-04-07T11:44:28Z"}
{"aid":"http://arxiv.org/abs/2504.04961v1","title":"Probing gravity with non-linear clustering in redshift space","summary":"We present the first computation of the gravity model testing parameter $E_G$\non realistic simulated modified gravity galaxy mocks. The analysis is conducted\nusing two twin simulations presented in arXiv:1805.09824(1): one based on\ngeneral relativity (GR) and the other on the $f(R)$ Hu $\\&$ Sawicki model with\n$f=10^{-5}$ (F5). This study aims to measure the $E_G$ estimator in GR and\n$f(R)$ models using high-fidelity simulated galaxy catalogs, with the goal of\nassessing how future galaxy surveys can detect deviations from standard\ngravity. Deriving this estimator requires precise, unbiased measurements of the\ngrowth rate of structure and the linear galaxy bias. We achieve this by\nimplementing an end-to-end cosmological analysis pipeline in configuration\nspace, using the multipoles of the 2-point correlation function. Our analysis\ndemonstrates how to measure the scale-dependent growth rate predicted by\nnon-standard gravity models. We split the estimation of the RSD $\\beta$\nparameter over distinct scale ranges, separating large (quasi-linear) and small\n(non-linear) scales. We show that this estimator can be accurately measured\nusing mock galaxies in low redshift bins ($z < 1$), where it offers strong\ndiscriminating power over competing gravity theories. We find that, for an\nall-sky galaxy survey and neglecting observational systematics, accurate and\nlargely unbiased estimations of $E_G$ can be obtained across all redshifts.\nHowever, the error bars are too large to clearly distinguish between the\ntheories. When measuring the scale-dependence of the $E_G$ estimator, we note\nthat state-of-the-art theory modeling limitations and intrinsic \"prior volume\neffects\" prevent high-accuracy constraints. Alternatively, we propose a null\ntest of gravity using RSD clustering, which, if small scales are modeled\naccurately in future surveys, could detect significant departures from GR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-07T11:49:43Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04964v1","title":"Motivic apsects of a remarkable class of Calabi-Yau threefolds","summary":"In this note we consider the motivic aspect of the middle cohomology of more\nthan 200 classes of quasi-smooth Calabi--Yau threefolds inside weighted\nprojective 4-space which come with an action of a cyclic group of even order.\nThe action induces a self-dual Chow--K\\\"unneth decomposition. All but one\ncomponent correspond to Fano threefolds. For these the generalized Hodge\nconjecture is known, but thanks to the nature of the decomposition we can give\na direct proof for one of the components.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T11:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.04966v1","title":"Few Dimensions are Enough: Fine-tuning BERT with Selected Dimensions\n  Revealed Its Redundant Nature","summary":"When fine-tuning BERT models for specific tasks, it is common to select part\nof the final layer's output and input it into a newly created fully connected\nlayer. However, it remains unclear which part of the final layer should be\nselected and what information each dimension of the layers holds. In this\nstudy, we comprehensively investigated the effectiveness and redundancy of\ntoken vectors, layers, and dimensions through BERT fine-tuning on GLUE tasks.\nThe results showed that outputs other than the CLS vector in the final layer\ncontain equivalent information, most tasks require only 2-3 dimensions, and\nwhile the contribution of lower layers decreases, there is little difference\namong higher layers. We also evaluated the impact of freezing pre-trained\nlayers and conducted cross-fine-tuning, where fine-tuning is applied\nsequentially to different tasks. The findings suggest that hidden layers may\nchange significantly during fine-tuning, BERT has considerable redundancy,\nenabling it to handle multiple tasks simultaneously, and its number of\ndimensions may be excessive.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T11:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04973v1","title":"Ensuring Safety in an Uncertain Environment: Constrained MDPs via\n  Stochastic Thresholds","summary":"This paper studies constrained Markov decision processes (CMDPs) with\nconstraints against stochastic thresholds, aiming at safety of reinforcement\nlearning in unknown and uncertain environments. We leverage a Growing-Window\nestimator sampling from interactions with the uncertain and dynamic environment\nto estimate the thresholds, based on which we design Stochastic\nPessimistic-Optimistic Thresholding (SPOT), a novel model-based primal-dual\nalgorithm for multiple constraints against stochastic thresholds. SPOT enables\nreinforcement learning under both pessimistic and optimistic threshold\nsettings. We prove that our algorithm achieves sublinear regret and constraint\nviolation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$ while\nallowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$\nepisodes. The theoretical guarantees show that our algorithm achieves\nperformance comparable to that of an approach relying on fixed and clear\nthresholds. To the best of our knowledge, SPOT is the first reinforcement\nlearning algorithm that realises theoretical guaranteed performance in an\nuncertain environment where even thresholds are unknown.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-07T11:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04983v1","title":"Congruences modulo powers of $3$ for $6$-colored generalized Frobenius\n  partitions","summary":"In 1984, Andrews introduced the family of partition functions $c\\phi_k(n)$,\nthe number of generalized Frobenius partitions of $n$ with $k$ colors. In 2016,\nGu, Wang, and Xia proved some congruences about $c\\phi_6(n)$ and gave a\nconjecture on congruences modulo powers of 3 for $c\\phi_6(n)$. We solve the\nrevised conjecture proposed by Gu, Wang, and Xia using a method similar to that\nof Banerjee and Smoot.","main_category":"math.CO","categories":"math.CO,math.NT","published":"2025-04-07T12:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05010v1","title":"Some analogues of isoperimetric inequality","summary":"The discrete isoperimetric inequality states that among all n -gons with a\nfixed area, the regular n -gon has the least perimeter. We prove analogues of\nthe discrete isoperimetric inequality (involving circumradius or inradius) for\ncyclic and tangential polygons in hyperbolic geometry, considering both single\nand multiple polygons. Furthermore, we establish two versions of the\nisoperimetric inequality for multiple polygons in hyperbolic geometry with some\nrestriction on their area or perimeter.","main_category":"math.GT","categories":"math.GT","published":"2025-04-07T12:37:48Z"}
{"aid":"http://arxiv.org/abs/2504.05012v1","title":"Descriptive Complexity of Sensitivity of Cellular Automata","summary":"We study the computational complexity of determining whether a cellular\nautomaton is sensitive to initial conditions. We show that this problem is\n$\\Pi^0_2$-complete in dimension 1 and $\\Sigma^0_3$-complete in dimension 2 and\nhigher. This solves a question posed by Sablik and Theyssier.","main_category":"math.DS","categories":"math.DS,cs.CC,math.LO","published":"2025-04-07T12:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05019v1","title":"Mixture-of-Personas Language Models for Population Simulation","summary":"Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-07T12:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05051v1","title":"Chiral optical forces in a slot waveguide for separation of molecules in\n  gas","summary":"Chiral optical forces present an exciting avenue into the separation of\nenantiomers in an all-optical fashion. In this work, we explore via numerical\nsimulations and analytical calculations the feasibility of the separation of\nchiral molecules by using guided light in a dielectric slot waveguide. Our\nresults suggest that it is possible to separate [6]helicene enantiomers\nsuspended in gas within several hours when applying optical powers of 100 mW.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T13:20:20Z"}
{"aid":"http://arxiv.org/abs/2504.05058v1","title":"Not All Data Are Unlearned Equally","summary":"Machine unlearning is concerned with the task of removing knowledge learned\nfrom particular data points from a trained model. In the context of large\nlanguage models (LLMs), unlearning has recently received increased attention,\nparticularly for removing knowledge about named entities from models for\nprivacy purposes. While various approaches have been proposed to address the\nunlearning problem, most existing approaches treat all data points to be\nunlearned equally, i.e., unlearning that Montreal is a city in Canada is\ntreated exactly the same as unlearning the phone number of the first author of\nthis paper. In this work, we show that this all data is equal assumption does\nnot hold for LLM unlearning. We study how the success of unlearning depends on\nthe frequency of the knowledge we want to unlearn in the pre-training data of a\nmodel and find that frequency strongly affects unlearning, i.e., more frequent\nknowledge is harder to unlearn. Additionally, we uncover a misalignment between\nprobability and generation-based evaluations of unlearning and show that this\nproblem worsens as models become larger. Overall, our experiments highlight the\nneed for better evaluation practices and novel methods for LLM unlearning that\ntake the training data of models into account.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:29:02Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05068v1","title":"Global approximations to the error function of real argument for\n  vectorized computation","summary":"The error function of real argument can be uniformly approximated to a given\naccuracy by a single closed-form expression for the whole variable range either\nin terms of addition, multiplication, division, and square root operations\nonly, or also using the exponential function. The coefficients have been\ntabulated for up to 128-bit precision. Tests of a computer code implementation\nusing the standard single- and double-precision floating-point arithmetic show\ngood performance and vectorizability.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-07T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.05074v1","title":"On the Performance of an Explainable Language Model on PubMedQA","summary":"Large language models (LLMs) have shown significant abilities in retrieving\nmedical knowledge, reasoning over it and answering medical questions comparably\nto physicians. However, these models are not interpretable, hallucinate, are\ndifficult to maintain and require enormous compute resources for training and\ninference. In this paper, we report results from Gyan, an explainable language\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\nLLM is a compositional language model and the model is decoupled from\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\nrequire significant training or compute resources. Gyan is easily transferable\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\nDeepMind). We will be reporting results for other medical data sets - MedQA,\nMedMCQA, MMLU - Medicine in the future.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.05075v1","title":"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\n  Video Recognition","summary":"Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:43:51Z"}
{"aid":"http://arxiv.org/abs/2504.05077v1","title":"Transforming Ridesharing: Harnessing Role Flexibility and HOV\n  Integration for Enhanced Mobility Solutions","summary":"While dynamic ridesharing has been extensively studied, there remains a\nsignificant research gap in exploring role flexibility within the many-to-many\nridesharing scheme, where the system allows for several pickups for drivers and\nmultiple transfers for riders. Previous works have predominantly assumed that\nall participants own a car and have focused on one-to-one arrangements.\nAdditionally, there is a scarcity of research on integrating High Occupancy\nVehicle (HOV) lanes and mathematical modelling. This study addresses these gaps\nby presenting a novel Mixed Integer Linear Programming (MILP) model that allows\nfor role flexibility irrespective of car ownership and considers the\nimplications of HOV lanes. Computational analysis highlights the benefits of\nincorporating role flexibility and accommodating non-car-owning participants in\nmany-to-many ridesharing systems. Yet, excessive role shifts may create\nimbalances, impacting service to non-car owners. Further research should\nexplore these correlations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T13:45:19Z"}
{"aid":"http://arxiv.org/abs/2504.05089v1","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","summary":"Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05117v1","title":"On the Origins of \"Hostless'' Supernovae: Testing the Faint-end Galaxy\n  Luminosity Function and Supernova Progenitors with Events in Dwarf Galaxies","summary":"We present arguments on the likely origins of supernovae without associated\nhost galaxies from open field, non-clustered, environments. We show why it is\nunlikely these ``hostless'' supernovae stem from escaped hyper-velocity stars\n(HVS) in any appreciable numbers, especially for core-collapse supernovae. It\nis highly likely that hostless events arise from dwarf host galaxies too faint\nto be detected in their parent surveys. Several detections and numerous upper\nlimits suggest a large number of field dwarfs, to $M_V>-14$, which themselves\nmay be important to constraining the slope of the low-mass end of the UV\nluminosity function, understanding galaxy evolution, and putting $\\Lambda$CDM\ninto context. Moreover, the detailed study of these mass and\nmetallicity-constrained host environments, and the variety of supernovae that\noccur within them, could provide more stringent constraints on the nature of\nprogenitor systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-07T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05124v1","title":"Generators of $H^1(Γ, \\partial Γ^c)$ with $\\partial Γ^c\n  \\subset \\partial Γ$ for Triangulated Surfaces $Γ$: Construction and\n  Classification of Global Loops","summary":"Given a compact surface $\\Gamma$ embedded in $\\mathbb R^3$ with boundary\n$\\partial \\Gamma$, our goal is to construct a set of representatives for a\nbasis of the relative cohomology group $H^1(\\Gamma, \\partial \\Gamma^c)$, where\n$\\Gamma^c$ is a specified subset of $\\partial \\Gamma$. To achieve this, we\npropose a novel graph-based algorithm with two key features: it is applicable\nto non-orientable surfaces, thereby generalizing previous approaches, and it\nhas a worst-case time complexity that is linear in the number of edges of the\nmesh $\\mathcal{K}$ triangulating $\\Gamma$. Importantly, this algorithm serves\nas a critical pre-processing step to address the low-frequency breakdown\nencountered in boundary element discretizations of integral equation\nformulations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T14:28:47Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05138v1","title":"Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated\n  Learning","summary":"Federated learning (FL) allows edge devices to collaboratively train models\nwithout sharing local data. As FL gains popularity, clients may need to train\nmultiple unrelated FL models, but communication constraints limit their ability\nto train all models simultaneously. While clients could train FL models\nsequentially, opportunistically having FL clients concurrently train different\nmodels -- termed multi-model federated learning (MMFL) -- can reduce the\noverall training time. Prior work uses simple client-to-model assignments that\ndo not optimize the contribution of each client to each model over the course\nof its training. Prior work on single-model FL shows that intelligent client\nselection can greatly accelerate convergence, but na\\\"ive extensions to MMFL\ncan violate heterogeneous resource constraints at both the server and the\nclients. In this work, we develop a novel convergence analysis of MMFL with\narbitrary client sampling methods, theoretically demonstrating the strengths\nand limitations of previous well-established gradient-based methods. Motivated\nby this analysis, we propose MMFL-LVR, a loss-based sampling method that\nminimizes training variance while explicitly respecting communication limits at\nthe server and reducing computational costs at the clients. We extend this to\nMMFL-StaleVR, which incorporates stale updates for improved efficiency and\nstability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead\ndeployment. Experiments show our methods improve average accuracy by up to\n19.1% over random sampling, with only a 5.4% gap from the theoretical optimum\n(full client participation).","main_category":"cs.LG","categories":"cs.LG,cs.DC,I.2.11","published":"2025-04-07T14:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05153v1","title":"SparsyFed: Sparse Adaptive Federated Training","summary":"Sparse training is often adopted in cross-device federated learning (FL)\nenvironments where constrained devices collaboratively train a machine learning\nmodel on private data by exchanging pseudo-gradients across heterogeneous\nnetworks. Although sparse training methods can reduce communication overhead\nand computational burden in FL, they are often not used in practice for the\nfollowing key reasons: (1) data heterogeneity makes it harder for clients to\nreach consensus on sparse models compared to dense ones, requiring longer\ntraining; (2) methods for obtaining sparse masks lack adaptivity to accommodate\nvery heterogeneous data distributions, crucial in cross-device FL; and (3)\nadditional hyperparameters are required, which are notably challenging to tune\nin FL. This paper presents SparsyFed, a practical federated sparse training\nmethod that critically addresses the problems above. Previous works have only\nsolved one or two of these challenges at the expense of introducing new\ntrade-offs, such as clients' consensus on masks versus sparsity pattern\nadaptivity. We show that SparsyFed simultaneously (1) can produce 95% sparse\nmodels, with negligible degradation in accuracy, while only needing a single\nhyperparameter, (2) achieves a per-round weight regrowth 200 times smaller than\nprevious methods, and (3) allows the sparse masks to adapt to highly\nheterogeneous data distributions and outperform all baselines under such\nconditions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T14:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.05158v1","title":"Leveraging Label Potential for Enhanced Multimodal Emotion Recognition","summary":"Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-07T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05161v1","title":"DDPM Score Matching and Distribution Learning","summary":"Score estimation is the backbone of score-based generative models (SGMs),\nespecially denoising diffusion probabilistic models (DDPMs). A key result in\nthis area shows that with accurate score estimates, SGMs can efficiently\ngenerate samples from any realistic data distribution (Chen et al., ICLR'23;\nLee et al., ALT'23). This distribution learning result, where the learned\ndistribution is implicitly that of the sampler's output, does not explain how\nscore estimation relates to classical tasks of parameter and density\nestimation.\n  This paper introduces a framework that reduces score estimation to these two\ntasks, with various implications for statistical and computational learning\ntheory:\n  Parameter Estimation: Koehler et al. (ICLR'23) demonstrate that a\nscore-matching variant is statistically inefficient for the parametric\nestimation of multimodal densities common in practice. In contrast, we show\nthat under mild conditions, denoising score-matching in DDPMs is asymptotically\nefficient.\n  Density Estimation: By linking generation to score estimation, we lift\nexisting score estimation guarantees to $(\\epsilon,\\delta)$-PAC density\nestimation, i.e., a function approximating the target log-density within\n$\\epsilon$ on all but a $\\delta$-fraction of the space. We provide (i) minimax\nrates for density estimation over H\\\"older classes and (ii) a quasi-polynomial\nPAC density estimation algorithm for the classical Gaussian location mixture\nmodel, building on and addressing an open problem from Gatmiry et al.\n(arXiv'24).\n  Lower Bounds for Score Estimation: Our framework offers the first principled\nmethod to prove computational lower bounds for score estimation across general\ndistributions. As an application, we establish cryptographic lower bounds for\nscore estimation in general Gaussian mixture models, conceptually recovering\nSong's (NeurIPS'24) result and advancing his key open problem.","main_category":"stat.ML","categories":"stat.ML,cs.DS,cs.LG,math.ST,stat.TH","published":"2025-04-07T15:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.05171v1","title":"A hydro-geomechanical porous-media model to study effects of engineered\n  carbonate precipitation in faults","summary":"Hydro-geomechanical models are required to predict or understand the impact\nof subsurface engineering applications as, for example, in gas storage in\ngeological formations. This study puts a focus on engineered carbonate\nprecipitation through biomineralization in a fault zone of a cap-rock to reduce\ngas leakage from a reservoir. Besides hydraulic properties like porosity and\npermeability, precipitated carbonates also change the mechanical properties of\nthe rock. We present a conceptual modeling approach implemented into the\nopen-source simulator Dumux and, after verification examples, at hand of a\nCO2-storage scenario, we discuss impacts of biomineralization on the stress\ndistribution in the rock and potentially altered risks of fault reactivations\nand induced seismic events.\n  The generic study shows the tendency towards increased stiffness due to\nprecipitated carbonate, which may cause shear failure events to occur earlier\nthan in an untreated setup, while the magnitude of the seismicity is smaller.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-07T15:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05201v1","title":"3D Universal Lesion Detection and Tagging in CT with Self-Training","summary":"Radiologists routinely perform the tedious task of lesion localization,\nclassification, and size measurement in computed tomography (CT) studies.\nUniversal lesion detection and tagging (ULDT) can simultaneously help alleviate\nthe cumbersome nature of lesion measurement and enable tumor burden assessment.\nPrevious ULDT approaches utilize the publicly available DeepLesion dataset,\nhowever it does not provide the full volumetric (3D) extent of lesions and also\ndisplays a severe class imbalance. In this work, we propose a self-training\npipeline to detect 3D lesions and tag them according to the body part they\noccur in. We used a significantly limited 30\\% subset of DeepLesion to train a\nVFNet model for 2D lesion detection and tagging. Next, the 2D lesion context\nwas expanded into 3D, and the mined 3D lesion proposals were integrated back\ninto the baseline training data in order to retrain the model over multiple\nrounds. Through the self-training procedure, our VFNet model learned from its\nown predictions, detected lesions in 3D, and tagged them. Our results indicated\nthat our VFNet model achieved an average sensitivity of 46.9\\% at [0.125:8]\nfalse positives (FP) with a limited 30\\% data subset in comparison to the\n46.8\\% of an existing approach that used the entire DeepLesion dataset. To our\nknowledge, we are the first to jointly detect lesions in 3D and tag them\naccording to the body part label.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05207v1","title":"Correcting Class Imbalances with Self-Training for Improved Universal\n  Lesion Detection and Tagging","summary":"Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.05221v1","title":"Apparent fractional charge signatures in PbTe quantum dots due to\n  capacitively coupled charge trap dynamics","summary":"We report the observation of fractional shifts in the experimental stability\ndiagrams of PbTe nanowire quantum dots. Although this behavior may appear to\nsuggest fractional charge transport, akin to that reported in the fractional\nquantum Hall regime, the quasi-one-dimensionality of the system and absence of\nan applied magnetic field indicate that the presence of fractional charges is\nhighly unlikely. We instead attribute these effects to the presence of one or\nmore spurious dots, or charge traps, capacitively coupled to the primary dot.\nOur findings illustrate how signatures of fractional charge transport may be\nreplicated through trivial mesoscopic Coulombic effects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-07T16:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.05222v1","title":"Security Risks in Vision-Based Beam Prediction: From Spatial Proxy\n  Attacks to Feature Refinement","summary":"The rapid evolution towards the sixth-generation (6G) networks demands\nadvanced beamforming techniques to address challenges in dynamic, high-mobility\nscenarios, such as vehicular communications. Vision-based beam prediction\nutilizing RGB camera images emerges as a promising solution for accurate and\nresponsive beam selection. However, reliance on visual data introduces unique\nvulnerabilities, particularly susceptibility to adversarial attacks, thus\npotentially compromising beam accuracy and overall network reliability. In this\npaper, we conduct the first systematic exploration of adversarial threats\nspecifically targeting vision-based mmWave beam selection systems. Traditional\nwhite-box attacks are impractical in this context because ground-truth beam\nindices are inaccessible and spatial dynamics are complex. To address this, we\npropose a novel black-box adversarial attack strategy, termed Spatial Proxy\nAttack (SPA), which leverages spatial correlations between user positions and\nbeam indices to craft effective perturbations without requiring access to model\nparameters or labels. To counteract these adversarial vulnerabilities, we\nformulate an optimization framework aimed at simultaneously enhancing beam\nselection accuracy under clean conditions and robustness against adversarial\nperturbations. We introduce a hybrid deep learning architecture integrated with\na dedicated Feature Refinement Module (FRM), designed to systematically filter\nirrelevant, noisy and adversarially perturbed visual features. Evaluations\nusing standard backbone models such as ResNet-50 and MobileNetV2 demonstrate\nthat our proposed method significantly improves performance, achieving up to an\n+21.07\\% gain in Top-K accuracy under clean conditions and a 41.31\\% increase\nin Top-1 adversarial robustness compared to different baseline models.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-07T16:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05234v1","title":"Precision DIS thrust predictions for HERA and EIC","summary":"We present predictions for the DIS 1-jettiness event shape $\\tau_1^b$, or DIS\nthrust, using the framework of Soft Collinear Effective Theory (SCET) for\nfactorization, resummation of large logarithms, and rigorous treatment of\nnonperturbative power corrections, matched to fixed-order QCD away from the\nresummation region. Our predictions reach\nnext-to-next-to-next-to-leading-logarithmic (N$^3$LL) accuracy in resummed\nperturbation theory, matched to $O(\\alpha_s^2)$ fixed-order QCD calculations\nobtained using the program NLOJet++. We include a rigorous treatment of\nhadronization corrections, which are universal across different event shapes\nand kinematic variables $x$ and $Q$ at leading power, and supplement them with\na systematic scheme to remove $O(\\Lambda_\\textrm{QCD})$ renormalon ambiguities\nin their definition. The framework of SCET allows us to connect smoothly the\nnonperturbative, resummation, and fixed-order regions, whose relative\nimportance varies with $x$ and $Q$, and to rigorously estimate theoretical\nuncertainties, across a broad range of $x$ and $Q$ covering existing\nexperimental results from HERA as well as expected new measurements from the\nupcoming Electron-Ion-Collider (EIC). Our predictions will serve as an\nimportant benchmark for the EIC program, enabling the precise determination of\nthe QCD strong coupling $\\alpha_s$ and the universal nonperturbative first\nmoment parameter $\\Omega_1$.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T16:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.05237v1","title":"Measuring Rényi entropy using a projected Loschmidt echo","summary":"We present efficient and practical protocols to measure the second R\\'enyi\nentropy (RE), whose exponential is known as the purity. We achieve this by\nestablishing a direct connection to a Loschmidt echo (LE) type measurement\nsequence, applicable to quantum many-body systems. Notably, our approach does\nnot rely on random-noise averaging, a feature that can be extended to protocols\nto measure out-of-time-order correlation functions (OTOCs), as we demonstrate.\nBy way of example, we show that our protocols can be practically implemented in\nsuperconducting qubit-based platforms, as well as in cavity-QED trapped\nultra-cold gases.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,cond-mat.stat-mech,hep-th","published":"2025-04-07T16:21:53Z"}
{"aid":"http://arxiv.org/abs/2504.05243v1","title":"Boundedness of polarized log Calabi-Yau fibrations with bounded bases","summary":"We investigate the boundedness problem for log Calabi-Yau fibrations whose\nbases and general fibers are bounded. We prove that the total spaces of log\nCalabi-Yau fibrations are bounded in codimension one after fixing some natural\ninvariants. We also prove that the total spaces are bounded if, in addition,\nthe irregularity of the general fibers vanishes. Then we apply our results to\nthe boundedness problem for stable minimal models and fibered Calabi-Yau\nvarieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T16:28:38Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05260v1","title":"Manipulating phases in many-body interacting systems with subsystem\n  resetting","summary":"Stabilizing thermodynamically unstable phases in many-body systems -- such as\nsuppressing pathological neuronal synchronization in Parkinson's disease or\nmaintaining magnetic order across broad temperature ranges -- remains a\npersistent challenge. In traditional approaches, such phases are stabilized\nthrough intervening in the dynamics of all system constituents or introducing\nadditional interactions. Here, we offer a hitherto-unexplored alternative --\nsubsystem resetting, whereby intervention in the dynamics of only a part of the\nsystem, and that too only occasionally in time, is implemented through\nresetting its state to a reset configuration. Just playing with a few\nparameters, e.g., the nature of the reset configuration and the size of the\nreset subsystem, one achieves a remarkable and robust control over the phase\ndiagram of the bare dynamics. We demonstrate that these universal effects span\na wide variety of scenarios, including equilibrium and non-equilibrium,\nmean-field and non-mean-field dynamics, with and without quenched disorder.\nDespite the challenges posed by memory effects, we obtain explicit analytical\npredictions, validated by simulations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,nlin.AO","published":"2025-04-07T16:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.05271v1","title":"AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point\n  Detection for Accurate Characterization of Anomalous Diffusion in Video Data","summary":"Anomalous diffusion occurs in a wide range of systems, including protein\ntransport within cells, animal movement in complex habitats, pollutant\ndispersion in groundwater, and nanoparticle motion in synthetic materials.\nAccurately estimating the anomalous diffusion exponent and the diffusion\ncoefficient from the particle trajectories is essential to distinguish between\nsub-diffusive, super-diffusive, or normal diffusion regimes. These estimates\nprovide a deeper insight into the underlying dynamics of the system,\nfacilitating the identification of particle behaviors and the detection of\nchanges in diffusion states. However, analyzing short and noisy video data,\nwhich often yield incomplete and heterogeneous trajectories, poses a\nsignificant challenge for traditional statistical approaches. We introduce a\ndata-driven method that integrates particle tracking, an attention\n  U-Net architecture, and a change-point detection algorithm to address these\nissues. This approach not only infers the anomalous diffusion parameters with\nhigh accuracy but also identifies temporal transitions between different\nstates, even in the presence of noise and limited temporal resolution. Our\nmethodology demonstrated strong performance in the 2nd Anomalous Diffusion\n(AnDi) Challenge benchmark within the top submissions for video tasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T17:08:17Z"}
{"aid":"http://arxiv.org/abs/2504.05274v1","title":"Aggregating time-series and image data: functors and double functors","summary":"Aggregation of time-series or image data over subsets of the domain is a\nfundamental task in data science. We show that many known aggregation\noperations can be interpreted as (double) functors on appropriate (double)\ncategories. Such functorial aggregations are amenable to parallel\nimplementation via straightforward extensions of Blelloch's parallel scan\nalgorithm. In addition to providing a unified viewpoint on existing operations,\nit allows us to propose new aggregation operations for time-series and image\ndata.","main_category":"math.CT","categories":"math.CT,cs.LG","published":"2025-04-07T17:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05276v1","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\n  Generation","summary":"Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05278v1","title":"The challenge of uncertainty quantification of large language models in\n  medicine","summary":"This study investigates uncertainty quantification in large language models\n(LLMs) for medical applications, emphasizing both technical innovations and\nphilosophical implications. As LLMs become integral to clinical\ndecision-making, accurately communicating uncertainty is crucial for ensuring\nreliable, safe, and ethical AI-assisted healthcare. Our research frames\nuncertainty not as a barrier but as an essential part of knowledge that invites\na dynamic and reflective approach to AI design. By integrating advanced\nprobabilistic methods such as Bayesian inference, deep ensembles, and Monte\nCarlo dropout with linguistic analysis that computes predictive and semantic\nentropy, we propose a comprehensive framework that manages both epistemic and\naleatoric uncertainties. The framework incorporates surrogate modeling to\naddress limitations of proprietary APIs, multi-source data integration for\nbetter context, and dynamic calibration via continual and meta-learning.\nExplainability is embedded through uncertainty maps and confidence metrics to\nsupport user trust and clinical interpretability. Our approach supports\ntransparent and ethical decision-making aligned with Responsible and Reflective\nAI principles. Philosophically, we advocate accepting controlled ambiguity\ninstead of striving for absolute predictability, recognizing the inherent\nprovisionality of medical knowledge.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T17:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.05279v1","title":"Covariant Gradient Descent","summary":"We present a manifestly covariant formulation of the gradient descent method,\nensuring consistency across arbitrary coordinate systems and general curved\ntrainable spaces. The optimization dynamics is defined using a covariant force\nvector and a covariant metric tensor, both computed from the first and second\nstatistical moments of the gradients. These moments are estimated through\ntime-averaging with an exponential weight function, which preserves linear\ncomputational complexity. We show that commonly used optimization methods such\nas RMSProp and Adam correspond to special limits of the covariant gradient\ndescent (CGD) and demonstrate how these methods can be further generalized and\nimproved.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T17:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.05282v1","title":"Estimation of Heat Transfer Coefficient in Heat Exchangers from\n  closed-loop data using Neural Networks","summary":"Heat exchangers (HEXs) play a central role in process industries for thermal\nenergy transfer. Fouling, the gradual accumulation of solids on heat transfer\nsurfaces, causes a time-varying decrease in the overall heat transfer\ncoefficient (U(t)), significantly impacting the efficiency of heat transfer.\nGood estimation and modeling of fouling (the heat transfer coefficient) will\nlead to better fouling mitigation strategies. This study investigates the\nidentifiability of the time-varying $U(t)$ in HEXs from closed-loop operational\ndata, without external excitation of reference signals or knowledge of the\ncontroller parameters. We establish that while the complete system model cannot\nbe identified under these given constraints, the time-varying heat transfer\ncoefficient $U(t)$ remains identifiable. Further, we propose a neural network\nbased architecture, called (Per-PINN), for estimation and modeling the heat\ntransfer coefficient from the closed-loop system data. This Per-PINN model is\nshown to perform better than the existing Physics-Informed Neural Networks\n(PINN) based models for inverse parameter learning as it inherently fixes the\nunderlying physical equations and learns only the time-varying parameter U(t).","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T17:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.05290v1","title":"Two-photon resonance single ionization of the K-shell of an atomic ion","summary":"The analytical structure and absolute values of the generalized cross-section\nof the two-photon resonance single ionization of the K-shell of a heavy\nneon-like ion of an iron atom (Fe$^{16+}$) were theoretically predicted. A\npronounced resonant subthreshold structure of the generalized cross-section and\nthe effect of destructive quantum interference of the probability amplitudes of\nradiation transitions into virtual excited states of p-symmetry have been\nestablished. The presence of a valence 2p$^6$-shell in the ion backbone causes\nthe production of an additional giant resonance of the generalized\ncross-section as the effect of the \"reverse\" hard X-ray emission of\nK$\\alpha$-type 1s$^2$(2s$^2$)2p$^5$ + $\\hbar\\omega \\to$ 1s(2s$^2$)2p$^6$. A\nscheme of the proposed experiment with linearly polarized X-ray photons is\npresented to verify the theoretical results obtained.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T17:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05630v1","title":"A new discrimination measure for assessing predictive performance of\n  non-linear survival models","summary":"Non-linear survival models are flexible models in which the proportional\nhazard assumption is not required. This poses difficulties in their evaluation.\nWe introduce a new discrimination measure, time-dependent Uno's C-index, to\nassess the discrimination performance of non-linear survival models. This is an\nunbiased version of Antolini's time-dependent concordance. We prove convergence\nof both measures employing Nolan and Pollard's results on U-statistics. We\nexplore the relationship between these measures and, in particular, the bias of\nAntolini's concordance in the presence of censoring using simulated data. We\ndemonstrate the value of time-dependent Uno's C-index for the evaluation of\nmodels trained on censored real data and for model tuning.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05643v1","title":"Improved Inference of Inverse Ising Problems under Missing Observations\n  in Restricted Boltzmann Machines","summary":"Restricted Boltzmann machines (RBMs) are energy-based models analogous to the\nIsing model and are widely applied in statistical machine learning. The\nstandard inverse Ising problem with a complete dataset requires computing both\ndata and model expectations and is computationally challenging because model\nexpectations have a combinatorial explosion. Furthermore, in many applications,\nthe available datasets are partially incomplete, making it difficult to compute\neven data expectations. In this study, we propose a approximation framework for\nthese expectations in the practical inverse Ising problems that integrates\nmean-field approximation or persistent contrastive divergence to generate\nrefined initial points and spatial Monte Carlo integration to enhance estimator\naccuracy. We demonstrate that the proposed method effectively and accurately\ntunes the model parameters in comparison to the conventional method.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cs.LG,physics.data-an","published":"2025-04-08T03:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.05645v1","title":"A Study of Multiple Molecular Lines at the 3 mm Band toward Gas\n  Infalling Sources","summary":"The study of multiple molecular spectral lines in gas infalling sources can\nprovide the physical and chemical properties of these sources and help us\nestimate their evolutionary stages. We report line detections within the 3 mm\nband using the FTS wide-sideband mode of the IRAM 30 m telescope toward 20\ngas-infalling sources. Using XCLASS, we identify the emission lines of up to 22\nmolecular species (including a few isotopologues) and one hydrogen radio\nrecombination line in these sources. H$^{13}$CO$^+$, HCO$^+$, HCN, HNC,\nc-C$_3$H$_2$, and CCH lines are detected in 15 sources. We estimate the\nrotation temperatures and column densities of these molecular species using the\nLTE radiative transfer model, and compare the molecular abundances of these\nsources with those from nine high-mass star-forming regions reported in\nprevious studies and with those from the chemical model. Our results suggest\nthat G012.79-0.20, G012.87-0.22 clump A and B, and G012.96-0.23 clump A may be\nin the high-mass protostellar object stage, while sources with fewer detected\nspecies may be in the earlier evolutionary stage. Additionally, the CCH and\nc-C$_3$H$_2$ column densities in our sources reveal a linear correlation, with\na ratio of N(CCH)/N(c-C$_3$H$_2$) = 89.2$\\pm$5.6, which is higher than the\nratios reported in the literature. When considering only sources with lower\ncolumn densities, this ratio decreases to 29.0$\\pm$6.1, consistent with those\nof diffuse clouds. Furthermore, a comparison between the N(CCH)/N(c-C$_3$H$_2$)\nratio and the sources' physical parameters reveals a correlation, with sources\nexhibiting higher ratios tending to have higher kinetic temperatures and H$_2$\ncolumn densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T03:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05701v1","title":"On (Some) Gauge Theories of Gravity","summary":"I consider the sense in which teleparallel gravity and symmetric teleparallel\ngravity may be understood as gauge theories of gravity. I first argue that both\ntheories have surplus structure. I then consider the relationship between\nYang-Mills theory and Poincare Gauge Theory and argue that though these use\nsimilar formalisms, there are subtle disanalogies in their interpretation.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc","published":"2025-04-08T05:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.05713v1","title":"Revisiting poverty measures using quantile functions","summary":"In this article we redefine various poverty measures in literature in terms\nof quantile functions instead of distribution functions in the prevailing\napproach. This enables provision for alternative methodology for poverty\nmeasurement and analysis along with some new results that are difficult to\nobtain in the existing framework. Several flexible quantile function models\nthat can enrich the existing ones are proposed and their utility is\ndemonstrated for real data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T06:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05719v1","title":"Mental Geometry","summary":"This article illustrates pedagogy through training in the handling of\nabstractions. Mental arithmetic is not limited to numerical calculation; one\ncan mentally calculate primitives and simplify analytical expressions. Even if\nthere is software that does this very well, this training retains its\npedagogical value. Can we go further and consider geometric mental arithmetic:\nmentally proceeding with transformations of simple figures allowing the\ncalculation of areas or volumes? It turns out that the intuition that allowed\nArchimedes to obtain his main geometric results, if we take only the ideas\nwithout the old-fashioned style, provides the opportunity for a pleasant and\nquite rich mental game that I present here in the form of a short narrative\ndialogue, not a philosophical tale because it does not bring any thesis, simply\na story to be classified among the invitations to exercise the mind. It starts\nwith the area of a triangle and ends with Guldin's two theorems.","main_category":"math.HO","categories":"math.HO,math.MG","published":"2025-04-08T06:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.05720v1","title":"QEMesh: Employing A Quadric Error Metrics-Based Representation for Mesh\n  Generation","summary":"Mesh generation plays a crucial role in 3D content creation, as mesh is\nwidely used in various industrial applications. Recent works have achieved\nimpressive results but still face several issues, such as unrealistic patterns\nor pits on surfaces, thin parts missing, and incomplete structures. Most of\nthese problems stem from the choice of shape representation or the capabilities\nof the generative network. To alleviate these, we extend PoNQ, a Quadric Error\nMetrics (QEM)-based representation, and propose a novel model, QEMesh, for\nhigh-quality mesh generation. PoNQ divides the shape surface into tiny patches,\neach represented by a point with its normal and QEM matrix, which preserves\nfine local geometry information. In our QEMesh, we regard these elements as\ngenerable parameters and design a unique latent diffusion model containing a\nnovel multi-decoder VAE for PoNQ parameters generation. Given the latent code\ngenerated by the diffusion model, three parameter decoders produce several PoNQ\nparameters within each voxel cell, and an occupancy decoder predicts which\nvoxel cells containing parameters to form the final shape. Extensive\nevaluations demonstrate that our method generates results with watertight\nsurfaces and is comparable to state-of-the-art methods in several main metrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T06:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.05721v1","title":"Graph product and the stability of circulant graphs","summary":"A graph $\\Gamma$ is said to be stable if $\\mathrm{Aut}(\\Gamma\\times\nK_2)\\cong\\mathrm{Aut}(\\Gamma)\\times \\mathbb{Z}_{2}$ and unstable otherwise. If\nan unstable graph is connected, non-bipartite and any two of its distinct\nvertices have different neighborhoods, then it is called nontrivially unstable.\nWe establish conditions guaranteeing the instability of various graph products,\nincluding direct products, direct product bundles, Cartesian products, strong\nproducts, semi-strong products, and lexicographic products. Inspired by a\ncondition for the instability of direct product bundles, we propose a new\nsufficient condition for circulant graphs to be unstable. This condition yields\ninfinitely many nontrivially unstable circulant graphs that do not satisfy any\npreviously established instability conditions for circulant graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T06:42:11Z"}
{"aid":"http://arxiv.org/abs/2504.05734v1","title":"An Asymptotic formula for Tate-Shafarevich groups of CM elliptic curves\n  at supersingular primes","summary":"Let $K$ be an imaginary quadratic field and $E/\\mathbb{Q}$ an elliptic curves\nwith complex multiplication by $\\mathcal{O}_K$. Let $K_\\infty/K$ be the\nanticyclotomic $\\mathbb{Z}_p$-extension of $K$ and $K_n$ the intermediate\nlayers. Under additional assumptions on Kobayashi's signed Selmer groups we\nprove an asymptotic formula for the Tate-Shafarevich group over $K_n$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-08T07:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05745v1","title":"Reflections on Chiral Symmetry within QCD","summary":"That chiral symmetry is a crucial feature of the strong force was realized\nbefore the discovery of Quantum Chromodynamics. However, the full power it\nexerts on the structure of the nucleon became apparent only afterwards. We\npresent a high-level and somewhat personal overview of its role in almost every\naspect of proton structure, from its mass and spin to the asymmetry of its\nantimatter content and its strange quark content. The lessons learned from\nstudying the proton are also vital with respect to the modern challenge of the\nnature of baryon excited states.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-08T07:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05763v1","title":"First law of de Sitter thermodynamics","summary":"The de Sitter state has a special symmetry: it is homogeneous, and its\ncurvature is constant in space. Since all the points in the de Sitter space are\nequivalent, this state is described by local thermodynamics. This state has the\nlocal temperature $T=H/\\pi$ (which is twice the Gibbons-Hawking temperature),\nthe local entropy density, the local energy density, and also the local\ngravitational degrees of freedom -- the scalar curvature ${\\cal R}$ and the\neffective gravitational coupling $K$. On the other hand, there is the\ncosmological horizon, which can be also characterized by the thermodynamic\nrelations. We consider the connections between the local thermodynamics and the\nthermodynamics of the cosmological horizon. In particular, there is the\nholographic connection between the entropy density integrated over the Hubble\nvolume and the Gibbons-Hawking entropy of the horizon, $S_{\\rm volume}=S_{\\rm\nhorizon}=A/4G$. We also consider the first law of thermodynamics in these two\napproaches. In the local thermodynamics, on the one hand, the first law is\nvalid for an arbitrary volume $V$ of de Sitter space. On the other hand, the\nfirst law is also applicable to the thermodynamics of the horizon. In both\ncases, the temperature is the same. This consideration is extended to the\ncontracting de Sitter with its negative entropy, $S_{\\rm volume}=S_{\\rm\nhorizon}=-A/4G$.","main_category":"gr-qc","categories":"gr-qc,hep-ph","published":"2025-04-08T07:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.05765v1","title":"Probabilistic Process Discovery with Stochastic Process Trees","summary":"In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.05769v1","title":"A structure theorem for irreducible open graph 3-manifolds","summary":"Graph manifolds are a class of compact, orientable 3-manifolds introduced in\n1967 by Waldhausen as a generalization of Seifert fibered 3-manifolds. From the\npoint of view of Thurston's geometrization program, graph manifolds are exactly\nthe compact, orientable 3-manifolds without any hyperbolic piece in their\ngeometric decomposition. In this article we consider a generalization of the\nnotion of graph manifold that includes some noncompact 3-manifolds. We prove a\nstructure theorem for irreducible open graph manifolds in the form of a\ncanonical 'reduced' decomposition along embedded, incompressible 2-tori.","main_category":"math.GT","categories":"math.GT","published":"2025-04-08T07:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.05772v1","title":"Kronecker scaling of tensors with applications to arithmetic circuits\n  and algorithms","summary":"We show that sufficiently low tensor rank for the balanced tripartitioning\ntensor $P_d(x,y,z)=\\sum_{A,B,C\\in\\binom{[3d]}{d}:A\\cup B\\cup C=[3d]}x_Ay_Bz_C$\nfor a large enough constant $d$ implies uniform arithmetic circuits for the\nmatrix permanent that are exponentially smaller than circuits obtainable from\nRyser's formula.\n  We show that the same low-rank assumption implies exponential time\nimprovements over the state of the art for a wide variety of other related\ncounting and decision problems.\n  As our main methodological contribution, we show that the tensors $P_n$ have\na desirable Kronecker scaling property: They can be decomposed efficiently into\na small sum of restrictions of Kronecker powers of $P_d$ for constant $d$. We\nprove this with a new technique relying on Steinitz's lemma, which we hence\ncall Steinitz balancing.\n  As a consequence of our methods, we show that the mentioned low rank\nassumption (and hence the improved algorithms) is implied by Strassen's\nasymptotic rank conjecture [Progr. Math. 120 (1994)], a bold conjecture that\nhas recently seen intriguing progress.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-08T07:52:16Z"}
{"aid":"http://arxiv.org/abs/2504.05780v1","title":"Magnetic Memory Driven by Orbital Current","summary":"Spin-orbitronics, based on both spin and orbital angular momentum, presents a\npromising pathway for energy-efficient memory and logic devices. Recent studies\nhave demonstrated the emergence of orbital currents in light transition metals\nsuch as Ti, Cr, and Zr, broadening the scope of spin-orbit torque (SOT). In\nparticular, the orbital Hall effect, which arises independently of spin-obit\ncoupling, has shown potential for enhancing torque efficiency in spintronic\ndevices. However, the direct integration of orbital current into magnetic\nrandom-access memory (MRAM) remains unexplored. In this work, we design a light\nmetal/heavy metal/ferromagnet multilayer structure and experimentally\ndemonstrate magnetization switching by orbital current. Furthermore, we have\nrealized a robust SOT-MRAM cell by incorporating a reference layer that is\npinned by a synthetic antiferromagnetic structure. We observed a tunnel\nmagnetoresistance of 66%, evident in both magnetic field and current-driven\nswitching processes. Our findings underscore the potential for employing\norbital current in designing next-generation spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T08:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.05787v1","title":"Finiteness properties of asymptotically rigid handlebody groups","summary":"We introduce asymptotically rigid mapping class groups of handlebodies and\ndetermine their finiteness properties, which vary depending on the space of\nends of the underlying handlebody. As it turns out, in some cases, the homology\nof these groups coincides with the stable homology of handlebody groups, as\nstudied by Hatcher and Wahl.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-08T08:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.05794v1","title":"DefMamba: Deformable Visual State Space Model","summary":"Recently, state space models (SSM), particularly Mamba, have attracted\nsignificant attention from scholars due to their ability to effectively balance\ncomputational efficiency and performance. However, most existing visual Mamba\nmethods flatten images into 1D sequences using predefined scan orders, which\nresults the model being less capable of utilizing the spatial structural\ninformation of the image during the feature extraction process. To address this\nissue, we proposed a novel visual foundation model called DefMamba. This model\nincludes a multi-scale backbone structure and deformable mamba (DM) blocks,\nwhich dynamically adjust the scanning path to prioritize important information,\nthus enhancing the capture and processing of relevant input features. By\ncombining a deformable scanning(DS) strategy, this model significantly improves\nits ability to learn image structures and detects changes in object details.\nNumerous experiments have shown that DefMamba achieves state-of-the-art\nperformance in various visual tasks, including image classification, object\ndetection, instance segmentation, and semantic segmentation. The code is open\nsource on DefMamba.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:54Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05800v1","title":"Storybooth: Training-free Multi-Subject Consistency for Improved Visual\n  Storytelling","summary":"Training-free consistent text-to-image generation depicting the same subjects\nacross different images is a topic of widespread recent interest. Existing\nworks in this direction predominantly rely on cross-frame self-attention; which\nimproves subject-consistency by allowing tokens in each frame to pay attention\nto tokens in other frames during self-attention computation. While useful for\nsingle subjects, we find that it struggles when scaling to multiple characters.\nIn this work, we first analyze the reason for these limitations. Our\nexploration reveals that the primary-issue stems from self-attention-leakage,\nwhich is exacerbated when trying to ensure consistency across\nmultiple-characters. This happens when tokens from one subject pay attention to\nother characters, causing them to appear like each other (e.g., a dog appearing\nlike a duck). Motivated by these findings, we propose StoryBooth: a\ntraining-free approach for improving multi-character consistency. In\nparticular, we first leverage multi-modal chain-of-thought reasoning and\nregion-based generation to apriori localize the different subjects across the\ndesired story outputs. The final outputs are then generated using a modified\ndiffusion model which consists of two novel layers: 1) a bounded cross-frame\nself-attention layer for reducing inter-character attention leakage, and 2)\ntoken-merging layer for improving consistency of fine-grain subject details.\nThrough both qualitative and quantitative results we find that the proposed\napproach surpasses prior state-of-the-art, exhibiting improved consistency\nacross both multiple-characters and fine-grain subject details.","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.MM","published":"2025-04-08T08:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.05803v1","title":"SE4Lip: Speech-Lip Encoder for Talking Head Synthesis to Solve\n  Phoneme-Viseme Alignment Ambiguity","summary":"Speech-driven talking head synthesis tasks commonly use general acoustic\nfeatures (such as HuBERT and DeepSpeech) as guided speech features. However, we\ndiscovered that these features suffer from phoneme-viseme alignment ambiguity,\nwhich refers to the uncertainty and imprecision in matching phonemes (speech)\nwith visemes (lip). To address this issue, we propose the Speech Encoder for\nLip (SE4Lip) to encode lip features from speech directly, aligning speech and\nlip features in the joint embedding space by a cross-modal alignment framework.\nThe STFT spectrogram with the GRU-based model is designed in SE4Lip to preserve\nthe fine-grained speech features. Experimental results show that SE4Lip\nachieves state-of-the-art performance in both NeRF and 3DGS rendering models.\nIts lip sync accuracy improves by 13.7% and 14.2% compared to the best baseline\nand produces results close to the ground truth videos.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-08T08:35:59Z"}
{"aid":"http://arxiv.org/abs/2504.05804v1","title":"StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization","summary":"The integration of large language models (LLMs) into information retrieval\nsystems introduces new attack surfaces, particularly for adversarial ranking\nmanipulations. We present StealthRank, a novel adversarial ranking attack that\nmanipulates LLM-driven product recommendation systems while maintaining textual\nfluency and stealth. Unlike existing methods that often introduce detectable\nanomalies, StealthRank employs an energy-based optimization framework combined\nwith Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text\nsequences embedded within product descriptions that subtly yet effectively\ninfluence LLM ranking mechanisms. We evaluate StealthRank across multiple LLMs,\ndemonstrating its ability to covertly boost the ranking of target products\nwhile avoiding explicit manipulation traces that can be easily detected. Our\nresults show that StealthRank consistently outperforms state-of-the-art\nadversarial ranking baselines in both effectiveness and stealth, highlighting\ncritical vulnerabilities in LLM-driven recommendation systems.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:36:18Z"}
{"aid":"http://arxiv.org/abs/2504.05807v1","title":"Low-Complexity AoI-Optimal Status Update Control with Partial Battery\n  State Information in Energy Harvesting IoT Networks","summary":"For a two-hop IoT system consisting of multiple energy harvesting sensors, a\ncache-enabled edge node, and multiple monitors, the status update control at\nthe edge node, which has partial battery state information (pBSI) of the\nsensors, is formulated as a pBSI problem. The concept of inferred pBSI is\nintroduced to reduce the noiseless single-sensor pBSI problem to a Markov\ndecision process with a moderate state-space size, enabling the optimal policy\nto be obtained through a value iteration algorithm. A lower bound on the\nexpected time-average on-demand age of information performance is established\nfor the general single-sensor status update problem. For the single-sensor pBSI\nproblem, a semi-closed-form policy called the current-next (CN) policy is\nproposed, along with an efficient post-update value iteration algorithm with a\nper-iteration time complexity proportional to the square of the battery\ncapacity. A weighted-update-gain-competition (WUGC) approach is further\nleveraged to extend the CN policy to the multi-sensor case. Numerical results\nin the single-sensor case demonstrate the near-optimal performance of the CN\npolicy across various energy arrival processes. Simulations for an IoT system\nwith $100$ sensors reveal that the WUGC-CN policy outperforms the\nmaximum-age-first policy and the random-scheduling-based CN policy under\nBernoulli energy arrival processes.","main_category":"cs.IT","categories":"cs.IT,cs.SY,eess.SY,math.IT","published":"2025-04-08T08:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05839v1","title":"Accurate Decomposition of Galaxies with Spiral Arms: Dust Properties and\n  Distribution","summary":"We analyze three nearby spiral galaxies - NGC 1097, NGC 1566, and NGC 3627 -\nusing images from the DustPedia database in seven infrared bands (3.6, 8, 24,\n70, 100, 160, and 250 micron). For each image, we perform photometric\ndecomposition and construct a multi-component model, including a detailed\nrepresentation of the spiral arms. Our results show that the light distribution\nis well described by an exponential disk and a Sersic bulge when\nnon-axisymmetric components are properly taken into account. We test the\npredictions of the stationary density wave theory using the derived models in\nbands, tracing both old stars and recent star formation. Our findings suggest\nthat the spiral arms in all three galaxies are unlikely to originate from\nstationary density waves. Additionally, we perform spectral energy distribution\n(SED) modeling using the hierarchical Bayesian code HerBIE, fitting individual\ncomponents to derive dust properties. We find that spiral arms contain a\nsignificant (>10%) fraction of cold dust, with an average temperature of\napproximately 18-20 K. The estimated fraction of polycyclic aromatic\nhydrocarbons (PAHs) declines significantly toward the galactic center but\nremains similar between the arm and interarm regions.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T09:21:12Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05856v1","title":"Analyzing type Ia supernovae near-infrared light curves with Principal\n  Component Analysis","summary":"Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf\nstars in binary systems, are phenomena that remain poorly understood. The\ncomplexity of their progenitor systems, explosion physics and intrinsic\ndiversity poses not only challenges for their understanding as astrophysical\nobjects, but also for their standardization and use as cosmological probes.\nNear-infrared (NIR) observations offer a promising avenue for studying the\nphysics of SNeIa and for reducing systematic uncertainties in distance\nestimations, as they exhibit lower dust extinction and smaller dispersion in\npeak luminosity than optical bands. Here, Principal Component Analysis (PCA) is\napplied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to\nidentify the dominant components of their variability and constrain physical\nunderlying properties. The theoretical models of Kasen2006 are used for the\nphysical interpretation of the PCA components, where we found the 56Ni mass to\ndescribe the dominant variability. Other factors, such as mixing and\nmetallicity, were found to contribute significantly as well. However, some\ndifferences are found between the components of the NIR bands which may be\nattributed to differences in the explosion aspects they each trace.\nAdditionally, the PCA components are compared to various light-curve\nparameters, identifying strong correlations between some components and peak\nbrightness in both the NIR and optical bands, particularly in the Y band. When\napplying PCA to NIR color curves, we found interesting correlations with the\nhost-galaxy mass, where SNeIa with redder NIR colors are predominantly found in\nless massive galaxies. We also investigate the potential for improved\nstandardization in the Y band by incorporating PCA coefficients as correction\nparameters, leading to a reduction in the scatter of the intrinsic luminosity\nof SNeIa.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T09:35:33Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05860v1","title":"Functional matrix product state simulation of continuous variable\n  quantum circuits","summary":"We introduce a functional matrix product state (FMPS) based method for\nsimulating the real-space representation of continuous-variable (CV) quantum\ncomputation. This approach efficiently simulates non-Gaussian CV systems by\nleveraging their functional form. By addressing scaling bottlenecks, FMPS\nenables more efficient simulation of shallow, multi-mode CV quantum circuits\nwith non-Gaussian input states. The method is validated by simulating random\nshallow and cascaded circuits with highly non-Gaussian input states, showing\nsuperior performance compared to existing techniques, also in the presence of\nloss.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.05862v1","title":"Are Generative AI Agents Effective Personalized Financial Advisors?","summary":"Large language model-based agents are becoming increasingly popular as a\nlow-cost mechanism to provide personalized, conversational advice, and have\ndemonstrated impressive capabilities in relatively simple scenarios, such as\nmovie recommendations. But how do these agents perform in complex high-stakes\ndomains, where domain expertise is essential and mistakes carry substantial\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\nwhen users themselves may be unsure of their needs, (2) providing personalized\nguidance for diverse investment preferences, and (3) leveraging advisor\npersonality to build relationships and foster trust. Via a lab-based user study\nwith 64 participants, we show that LLM-advisors often match human advisor\nperformance when eliciting preferences, although they can struggle to resolve\nconflicting user needs. When providing personalized advice, the LLM was able to\npositively influence user behavior, but demonstrated clear failure modes. Our\nresults show that accurate preference elicitation is key, otherwise, the\nLLM-advisor has little impact, or can even direct the investor toward\nunsuitable assets. More worryingly, users appear insensitive to the quality of\nadvice being given, or worse these can have an inverse relationship. Indeed,\nusers reported a preference for and increased satisfaction as well as emotional\ntrust with LLMs adopting an extroverted persona, even though those agents\nprovided worse advice.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.HC,cs.IR,q-fin.CP","published":"2025-04-08T09:41:03Z"}
{"aid":"http://arxiv.org/abs/2504.05884v1","title":"Endoscopic fiber-coupled diamond magnetometer for cancer surgery","summary":"Interoperative measurements using magnetic sensors is a valuable technique in\ncancer surgery for finding magnetic tracers. Here we present a fiber-coupled\nnitrogen-vacancy (N-V) center magnetometer capable of detecting iron oxide\nsuspension (MagTrace from Endomagnetics Ltd.) used in breast cancer surgeries.\nDetection of an iron mass as low as 0.56~mg has been demonstrated, 100 times\nless than that of a recommended dose at a maximum distance of 5.8~mm. Detection\nof an iron concentration as low as 2.8 mg/ml has also been demonstrated, 20\ntimes less than a recommended dose. The maximum working distance from the\nsensor can be as large as 14.6~mm for higher concentrations. The sensor head\nhas a maximum diameter of 10~mm which would allow it to be used for endoscopy,\nlaparoscopy and interoperative surgery.","main_category":"physics.med-ph","categories":"physics.med-ph,cond-mat.mtrl-sci,quant-ph","published":"2025-04-08T10:17:43Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05887v1","title":"Jointly-optimized Trajectory Generation and Camera Control for 3D\n  Coverage Planning","summary":"This work proposes a jointly optimized trajectory generation and camera\ncontrol approach, enabling an autonomous agent, such as an unmanned aerial\nvehicle (UAV) operating in 3D environments, to plan and execute coverage\ntrajectories that maximally cover the surface area of a 3D object of interest.\nSpecifically, the UAV's kinematic and camera control inputs are jointly\noptimized over a rolling planning horizon to achieve complete 3D coverage of\nthe object. The proposed controller incorporates ray-tracing into the planning\nprocess to simulate the propagation of light rays, thereby determining the\nvisible parts of the object through the UAV's camera. This integration enables\nthe generation of precise look-ahead coverage trajectories. The coverage\nplanning problem is formulated as a rolling finite-horizon optimal control\nproblem and solved using mixed-integer programming techniques. Extensive\nreal-world and synthetic experiments validate the performance of the proposed\napproach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05908v1","title":"PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for\n  Uncertainty-Aware Object Interaction in Driving Scene Scenario","summary":"Driving scene understanding is a critical real-world problem that involves\ninterpreting and associating various elements of a driving environment, such as\nvehicles, pedestrians, and traffic signals. Despite advancements in autonomous\ndriving, traditional pipelines rely on deterministic models that fail to\ncapture the probabilistic nature and inherent uncertainty of real-world\ndriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-aware\nmodel for object interaction and Chain-of-Thought (CoT) reasoning in driving\nscenarios. In particular, our approach combines LiDAR-based 3D object detection\nwith multi-view RGB references to ensure interpretable and reliable scene\nunderstanding. Uncertainty and risk assessment, along with object interactions,\nare modelled using Bayesian Graph Neural Networks (BGNNs) for probabilistic\nreasoning under ambiguous conditions. Interpretable decisions are facilitated\nthrough CoT reasoning, leveraging object dynamics and contextual cues, while\nGrad-CAM visualizations highlight attention regions. Extensive evaluations on\nthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperforms\nstate-of-the-art CoT and risk-aware models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-08T11:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.05917v1","title":"Indexing Strings with Utilities","summary":"Applications in domains ranging from bioinformatics to advertising feature\nstrings that come with numerical scores (utilities). The utilities quantify the\nimportance, interest, profit, or risk of the letters occurring at every\nposition of a string. Motivated by the ever-increasing rate of generating such\ndata, as well as by their importance in several domains, we introduce Useful\nString Indexing (USI), a natural generalization of the classic String Indexing\nproblem. Given a string $S$ (the text) of length $n$, USI asks for\npreprocessing $S$ into a compact data structure supporting the following\nqueries efficiently: given a shorter string $P$ (the pattern), return the\nglobal utility $U(P)$ of $P$ in $S$, where $U$ is a function that maps any\nstring $P$ to a utility score based on the utilities of the letters of every\noccurrence of $P$ in $S$. Our work also makes the following contributions: (1)\nWe propose a novel and efficient data structure for USI based on finding the\ntop-$K$ frequent substrings of $S$. (2) We propose a linear-space data\nstructure that can be used to mine the top-$K$ frequent substrings of $S$ or to\ntune the parameters of the USI data structure. (3) We propose a novel\nspace-efficient algorithm for estimating the set of the top-$K$ frequent\nsubstrings of $S$, thus improving the construction space of the data structure\nfor USI. (4) We show that popular space-efficient top-$K$ frequent item mining\nstrategies employed by state-of-the-art algorithms do not smoothly translate\nfrom items to substrings. (5) Using billion-letter datasets, we experimentally\ndemonstrate that: (i) our top-$K$ frequent substring mining algorithms are\naccurate and scalable, unlike two state-of-the-art methods; and (ii) our USI\ndata structures are up to $15$ times faster in querying than $4$ nontrivial\nbaselines while occupying the same space with them.","main_category":"cs.DS","categories":"cs.DS,cs.DB","published":"2025-04-08T11:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05922v1","title":"Thawed Gaussian Ehrenfest dynamics at conical intersections: When can a\n  single mean-field trajectory capture internal conversion?","summary":"The thawed Gaussian Ehrenfest dynamics is a single-trajectory method that\npartially includes both nuclear quantum and electronically nonadiabatic effects\nby combining the thawed Gaussian wavepacket dynamics with Ehrenfest dynamics.\nFirst, we demonstrate the improvement over the parent methods in a\nmultidimensional system consisting of vertically displaced harmonic potentials\nwith constant diabatic couplings, for which the thawed Gaussian Ehrenfest\ndynamics is exact. Then, we show that single-trajectory mean-field methods\ncompletely fail to capture electronic population transfer in the vicinity of\nconical intersections between potential energy surfaces associated with\nelectronic states of different symmetry (i.e., belonging to different\nirreducible representations of the molecular point group). The underlying cause\nof this limitation suggests that the thawed Gaussian Ehrenfest dynamics can be\nuseful for studying nonadiabatic dynamics close to conical intersections of\nelectronic states of the same symmetry, which have been understudied owing to\nthe difficulty in locating them. Using a model of this type of intersection, we\ncompare the thawed Gaussian Ehrenfest dynamics with exact quantum dynamics and\nfind that the approximate mean-field approach yields a molecular wavefunction\nthat remains qualitatively similar to the exact one even after crossing and\nrecrossing the conical intersection.","main_category":"physics.chem-ph","categories":"physics.chem-ph,quant-ph","published":"2025-04-08T11:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.05924v1","title":"A Control-Oriented Simplified Single Particle Model with Grouped\n  Parameter and Sensitivity Analysis for Lithium-Ion Batteries","summary":"Lithium-ion batteries are widely used in transportation, energy storage, and\nconsumer electronics, driving the need for reliable battery management systems\n(BMS) for state estimation and control. The Single Particle Model (SPM)\nbalances computational efficiency and accuracy but faces challenges in\nparameter estimation due to numerous parameters. Current SPM models using\nparabolic approximation introduce intermediate variables and hard to do\nparameter grouping. This study presents a control-oriented SPM reformulation\nthat employs parameter grouping and parabolic approximation to simplify model\nparameters while using average and surface lithium-ion concentrations as model\noutput. By parameter grouping, the original 17 parameters were reduced to 9\ngrouped parameters. The reformulated model achieves a reduced-order ordinary\ndifferential equation form while maintaining mathematical accuracy equivalent\nto the pre-grouped discretized SPM. Through Sobol sensitivity analysis under\nvarious current profiles, the grouped parameters were reduced from 9 to 6\nhighly sensitive parameters. Results demonstrate that estimating these 6\nparameters achieves comparable practical accuracy to estimating all 9\nparameters, with faster convergence. This control-oriented SPM enhances BMS\napplications by facilitating state estimation and control while reducing\nparameter estimation requirements.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.05930v1","title":"Totally equimodular matrices: decomposition and triangulation","summary":"Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-08T11:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.05936v1","title":"Adaptive Extended Kalman Filtering for Battery State of Charge\n  Estimation on STM32","summary":"Accurate and computationally light algorithms for estimating the State of\nCharge (SoC) of a battery's cells are crucial for effective battery management\non embedded systems. In this letter, we propose an Adaptive Extended Kalman\nFilter (AEKF) for SoC estimation using a covariance adaptation technique based\non maximum likelihood estimation - a novelty in this domain. Furthermore, we\ntune a key design parameter - the window size - to obtain an optimal\nmemory-performance trade-off, and experimentally demonstrate our solution\nachieves superior estimation accuracy with respect to existing alternative\nmethods. Finally, we present a fully custom implementation of the AEKF for a\ngeneral-purpose low-cost STM32 microcontroller, showing it can be deployed with\nminimal computational requirements adequate for real-world usage.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:50:14Z"}
{"aid":"http://arxiv.org/abs/2504.05947v1","title":"Multi-modal strain mapping of steel crack tips with micrometer spatial\n  resolution","summary":"Due to their superior fatigue strength, martensitic steels are the material\nof choice for high cyclic loading applications such as coil springs. However,\ncrack propagation is influenced by residual stresses and their interaction is\npoorly understood. In fact, Linear Elastic Fracture Mechanics predicts\nun-physical singularities in the strain around the crack tip. In this study, we\nhave combined synchrotron-based x-ray diffraction, x-ray fluorescence, and\noptical microscopy to map the factual strain fields around crack tips with\nmicrometer spatial resolution. X-ray fluorescence and optical images were\nco-registered to locate the crack in the x-ray diffraction maps. Observed\ncrystal recovery close to cracks confirmed that the diffraction signal\noriginates at least in parts from the cracks. The retrieved local strain field\naround the crack was further improved by averaging information over carefully\nselected diffraction peaks. This procedure provided strain maps around crack\ntips with a spatial resolution of about 1 micro meter and enabled a prediction\nof further crack growth.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-08T11:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.05948v1","title":"Control-Oriented Modelling and Adaptive Parameter Estimation for Hybrid\n  Wind-Wave Energy Systems","summary":"Hybrid wind-wave energy system, integrating floating offshore wind turbine\nand wave energy converters, has received much attention in recent years due to\nits potential benefit in increasing the power harvest density and reducing the\nlevelized cost of electricity. Apart from the design complexities of the hybrid\nwind-wave energy systems, their energy conversion efficiency, power output\nsmoothness and their safe operations introduce new challenges for their control\nsystem designs. Recent studies show that advanced model-based control\nstrategies have the great potential to significantly improve their overall\ncontrol performance. However the performance of these advanced control\nstrategies rely on the computationally efficient control-oriented models with\nsufficient fidelity, which are normally difficult to derive due to the\ncomplexity of the hydro-, aero-dynamic effects and the couplings.In most\navailable results, the hybrid wind-wave energy system models are established by\nusing the Boundary Element Method, devoting to understanding the hydrodynamic\nresponses and performance analysis. However, such models are complex and\ninvolved relatively heavy computational burden, which cannot be directly used\nfor the advanced model-based control methods that are essential for improving\npower capture efficiency from implementing in practice. To overcome this issue,\nthis paper proposes a control-oriented model of the hybrid windwave energy\nsystem with six degrees of freedom. First, ...","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05956v1","title":"Temporal Alignment-Free Video Matching for Few-shot Action Recognition","summary":"Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T12:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05969v1","title":"Extension of derivations to forms","summary":"The problem of extending derivations of a field $F$ to an $F-$algebra $B$ is\nwidely studied in commutative algebra and non-commutative ring theory. For\nexample, every derivation of $F$ extends to $B$ if $B$ is a separable algebraic\nextension or a central simple algebra over $F.$ We unify and generalize these\nresults by showing that a derivation $d$ of $F$ with the field of constants $C$\nextends to a finite dimensional algebra $B$ if $B$ is a form of some\n$C-$algebra having a smooth automorphism scheme $\\rm G$. Furthermore, we show\nthat the set of derivations of $B$ that extend the derivation $d$ of $F$ is in\nbijection with the set of derivations $\\delta$ such that $(Y,\\delta)$ is a\ndifferential $\\rm G_F-$torsor where $Y$ is the $\\rm G_F-$torsor corresponding\nto $B$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-08T12:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.05970v1","title":"MLPROP -- an open interactive web interface for thermophysical property\n  prediction with machine learning","summary":"Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.","main_category":"cs.CE","categories":"cs.CE,cs.LG","published":"2025-04-08T12:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05977v1","title":"Diffusion Based Ambiguous Image Segmentation","summary":"Medical image segmentation often involves inherent uncertainty due to\nvariations in expert annotations. Capturing this uncertainty is an important\ngoal and previous works have used various generative image models for the\npurpose of representing the full distribution of plausible expert ground\ntruths. In this work, we explore the design space of diffusion models for\ngenerative segmentation, investigating the impact of noise schedules,\nprediction types, and loss weightings. Notably, we find that making the noise\nschedule harder with input scaling significantly improves performance. We\nconclude that x- and v-prediction outperform epsilon-prediction, likely because\nthe diffusion process is in the discrete segmentation domain. Many loss\nweightings achieve similar performance as long as they give enough weight to\nthe end of the diffusion process. We base our experiments on the LIDC-IDRI lung\nlesion dataset and obtain state-of-the-art (SOTA) performance. Additionally, we\nintroduce a randomly cropped variant of the LIDC-IDRI dataset that is better\nsuited for uncertainty in image segmentation. Our model also achieves SOTA in\nthis harder setting.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T12:33:26Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06018v1","title":"The hybrid dilemma -- do hybrid technologies play a transitionary or\n  stationary role in transitions processes?","summary":"This research unravels the stationary or transitionary dilemma of hybrid\ntechnologies in transitions processes. A system dynamics technology interaction\nframework is built and simulated based on Technological Innovation System and\nLotka-Volterra to investigate the inter-technology relationship impacts and\nmodes that hybrid technologies establish with incumbent and emerging\ntechnologies. This is conducted for the case of conventional, hybrid and\nbattery electric vehicles under various scenarios . Results reveal that, by\nacting as an exploration-hybrid solution, hybrid technologies maintain a\ntransitionary role by supporting mainly the technological development side of\nemerging technology. On the contrary, by acting as an exploitation-hybrid\nsolution, they hardly (or never) sustain an inhibitive role against both the\ntechnological and market development sides of incumbent technology. While\nhybrid technologies may play a stationary role on the market development side\nin transitions processes, simulation results show that maintaining all\ninter-technology relationship modes as business-as-usual (i.e., baseline\nscenario) but instead simultaneously strengthening the various socio-technical\ndimensions of emerging technology and destabilising the various socio-technical\ndimensions of incumbent technology (i.e., sociotechnical scenario) is a more\npromising pathway in both short term (e.g., an accelerated uptake of emerging\ntechnology and decline of incumbent technology) and long term (e.g., highest\nemission reduction). Findings, additionally, reinforce the existence of both\nspillover and try-harder versions of 'sailing-ship effect', which are either\nseriously doubted in the literature or partially validated using raw\nbibliometric and patents data.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-08T13:25:52Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06028v1","title":"A Mean-Reverting Model of Exchange Rate Risk Premium Using\n  Ornstein-Uhlenbeck Dynamics","summary":"This paper examines the empirical failure of uncovered interest parity (UIP)\nand proposes a structural explanation based on a mean-reverting risk premium.\nWe define a realized premium as the deviation between observed exchange rate\nreturns and the interest rate differential, and demonstrate its strong\nmean-reverting behavior across multiple horizons. Motivated by this pattern, we\nmodel the risk premium using an Ornstein-Uhlenbeck (OU) process embedded within\na stochastic differential equation for the exchange rate.\n  Our model yields closed-form approximations for future exchange rate\ndistributions, which we evaluate using coverage-based backtesting. Applied to\nUSD/KRW data from 2010 to 2025, the model shows strong predictive performance\nat both short-term and long-term horizons, while underperforming at\nintermediate (3-month) horizons and showing conservative behavior in the tails\nof long-term forecasts. These results suggest that exchange rate deviations\nfrom UIP may reflect structured, forecastable dynamics rather than pure noise,\nand point to future modeling improvements via regime-switching or time-varying\nvolatility.","main_category":"q-fin.CP","categories":"q-fin.CP,q-fin.ST","published":"2025-04-08T13:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.06030v1","title":"NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars","summary":"In the hunt for WIMPish dark matter and testing our new theory, we extend the\nresults obtained for the Kepler problem in NQG I and NQG II to the Euler\ntwo-centre problem and to other classical Hamiltonian systems with planar\nperiodic orbits. In the first case our results lead to quantum elliptical\nspirals converging to elliptical orbits where stars and other celestial bodies\ncan form as the corresponding WIMP/molecular clouds condense. The examples\ninevitably involve elliptic integrals as was the case in our earlier work on\nequatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the\nexample on which we focus in this work on quantisation. The main part of our\nanalysis which leans heavily on Hamilton-Jacobi theory is applicable to any\nKLMN integrable planar periodic orbits for Hamiltonian systems. The most useful\nresults on Weierstrass elliptic functions needed in these two works we have\nsummarised with complete proofs in the appendix. This has been one of the most\nenjoyable parts of this research understanding in more detail the genius of\nWeierstrass and Jacobi. However we have to say that the beautiful simplicity of\nthe Euler two-centre results herein transcend even this as far as we are\nconcerned. At the end of the paper we see how the Burgers-Zeldovich fluid model\nrelates to our set-up through Nelson's stochastic mechanics.","main_category":"math-ph","categories":"math-ph,astro-ph.GA,math.MP","published":"2025-04-08T13:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.06031v1","title":"Virtual Agent Tutors in Sheltered Workshops: A Feasibility Study on\n  Attention Training for Individuals with Intellectual Disabilities","summary":"In this work, we evaluate the feasibility of socially assistive virtual\nagent-based cognitive training for people with intellectual disabilities (ID)\nin a sheltered workshop. The Robo- Camp system, originally developed for\nchildren with Attention Deficit Hyperactivity Disorder (ADHD), is adapted based\non the results of a pilot study in which we identified barriers and collected\nfeedback from workshop staff. In a subsequent study, we investigate the aspects\nof usability, technical reliability, attention training capabilities and\nnovelty effect in the feasibility of integrating the RoboCamp system.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T13:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06049v1","title":"Directed LS category and directed parametrized topological complexity","summary":"We introduce and study a parametrized analogue of the directed topological\ncomplexity, originally developed by Goubault, Farber, and Sagnier. We establish\nthe fibrewise basic dihomotopy invariance of directed parametrized topological\ncomplexity and explore its relationship with the parametrized topological\ncomplexity. In addition, we introduce the concept of the directed\nLusternik$-$Schnirelmann (LS) category, prove its basic dihomotopy invariance,\nand investigate its connections with both directed topological complexity and\ndirected parametrized topological complexity. As an application, we show that\nthe directed LS category of the directed spheres is equal to two.","main_category":"math.AT","categories":"math.AT","published":"2025-04-08T13:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.06054v1","title":"Thermodynamic formalism for Quasi-Morphisms: Bounded Cohomology and\n  Statistics","summary":"For a compact negatively curved space, we develop a notion of thermodynamic\nformalism and apply it to study the space of quasi-morphisms of its fundamental\ngroup modulo boundedness. We prove that this space is Banach isomorphic to the\nspace of Bowen functions corresponding to the associated Gromov geodesic flow,\nmodulo a weak notion of Livsic cohomology.\n  The results include that each such unbounded quasi-morphism is associated\nwith a unique invariant measure for the flow, and this measure uniquely\ncharacterizes the cohomology class. As a consequence, we establish the Central\nLimit Theorem for any unbounded quasi-morphism with respect to Markov measures,\nthe invariance principle, and the Bernoulli property of the associated\nequilibrium state.","main_category":"math.DS","categories":"math.DS,math.GT","published":"2025-04-08T13:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.06062v1","title":"A characterization of quasi-homogeneity in terms of liftable vector\n  fields","summary":"We prove under certain conditions that any stable unfolding of a\nquasi-homogeneous map-germ with finite singularity type is substantial. We then\nprove that if an equidimensional map-germ is finitely determined, of corank 1,\nand either it admits a minimal stable unfolding or it is of multipliticy 3,\nthen it admits a substantial unfolding if and only if it is quasi-homogeneous.\nBased on this we pose the following conjecture: a finitely determined map-germ\nis quasi-homogeneous if and only if it admits a substantial unfolding.","main_category":"math.AG","categories":"math.AG,math.DS","published":"2025-04-08T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.06075v1","title":"Collaborative Prediction: Tractable Information Aggregation via\n  Agreement","summary":"We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.","main_category":"cs.LG","categories":"cs.LG,cs.DS,cs.GT","published":"2025-04-08T14:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.06083v1","title":"Security Analysis of Thumbnail-Preserving Image Encryption and a New\n  Framework","summary":"As a primary encryption primitive balancing the privacy and searchability of\ncloud storage images, thumbnail preserving encryption (TPE) enables users to\nquickly identify the privacy personal image on the cloud and request this image\nfrom the owner through a secure channel. In this paper, we have found that two\ndifferent plaintext images may produce the same thumbnail. It results in the\nfailure of search strategy because the collision of thumbnail occurs. To\naddress this serious security issues, we conduct an in-depth analysis on the\ncollision probabilities of thumbnails, and then propose a new TPE framework,\ncalled multi-factor thumbnail preserving encryption (MFTPE). It starts from the\ncollision probability of two blocks, extend to the probabilities of two images\nand ultimately to N images. Then, we in detail describe three specific MFTPE\nconstructions preserving different combinations of factors, i.e., the sum and\nthe geometric mean, the sum and the range, and the sum and the weighted mean.\nThe theoretical and experimental results demonstrate that the proposed MFTPE\nreduces the probability of thumbnails, exhibits strong robustness, and also\neffectively resists face detection and noise attacks.","main_category":"cs.CR","categories":"cs.CR,cs.MM","published":"2025-04-08T14:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.06084v1","title":"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\n  Egocentric Videos","summary":"Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-08T14:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.06097v1","title":"Effective length-projection bounds for hyperbolic 3-manifolds\n  diffeomorphic to $S\\times\\mathbb{R}$","summary":"We give a formula with explicit constants relating the subsurface projection\n$d_Y(\\nu^-,\\nu^+)$ of the end invariants $\\nu^-,\\nu^+$ of a hyperbolic\n3-manifold $Q$ diffeomorphic to $S\\times\\mathbb{R}$ and the length of the\ngeodesic representative in $Q$ of the multicurve $\\partial Y$. This makes\neffective and computable the large projections versus short curves relation\nproved by Minsky. We give an application to closed hyperbolic 3-manifolds\nfibering over the circle providing a geometric analog of the uniform projection\nbound in fibered faces of Minsky and Taylor.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-08T14:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.06108v1","title":"Characterizing direct and indirect causal effects when outcomes are\n  dependent due to treatment spillover and outcome spillover","summary":"We provide novel insight into causal inference when both treatment spillover\nand outcome spillover occur in connected populations, by taking advantage of\nrecent advances in statistical network analysis. Scenarios with treatment\nspillover and outcome spillover are challenging, because both forms of\nspillover affect outcomes and therefore treatment spillover and outcome\nspillover are intertwined, and outcomes are dependent conditional on treatments\nby virtue of outcome spillover. As a result, the direct and indirect causal\neffects arising from spillover have remained black boxes: While the direct and\nindirect causal effects can be identified, it is unknown how these causal\neffects explicitly depend on the effects of treatment, treatment spillover, and\noutcome spillover. We make three contributions, facilitated by low-rank random\ninterference graphs. First, we provide novel insight into direct and indirect\ncausal effects by disentangling the contributions of treatment, treatment\nspillover, and outcome spillover. Second, we provide scalable estimators of\ndirect and indirect causal effects. Third, we establish rates of convergence\nfor estimators of direct and indirect causal effects. These are the first\nconvergence rates in scenarios in which treatment spillover and outcome\nspillover are intertwined and outcomes are dependent conditional on treatments,\nand the interference graph is sparse or dense.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T14:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.06114v1","title":"Computing for Community-Based Economies: A Sociotechnical Ecosystem for\n  Democratic, Egalitarian and Sustainable Futures","summary":"Automation and industrial mass production, particularly in sectors with low\nwages, have harmful consequences that contribute to widening wealth\ndisparities, excessive pollution, and worsened working conditions. Coupled with\na mass consumption society, there is a risk of detrimental social outcomes and\nthreats to democracy, such as misinformation and political polarization. But\nAI, robotics and other emerging technologies could also provide a transition to\ncommunity-based economies, in which more democratic, egalitarian, and\nsustainable value circulations can be established. Based on both a review of\ncase studies, and our own experiments in Detroit, we derive three core\nprinciples for the use of computing in community-based economies. The\nprefigurative principle requires that the development process itself\nincorporates equity goals, rather than viewing equity as something to be\nachieved in the future. The generative principle requires the prevention of\nvalue extraction, and its replacement by circulations in which value is\nreturned back to the aspects of labor, nature, and society by which it is\ngenerated. And third, the solidarity principle requires that deployments at all\nscales and across all domains support both individual freedoms and\nopportunities for mutual aid. Thus we propose the use of computational\ntechnologies to develop a specifically generative form of community-based\neconomy: one that is egalitarian regarding race, class and gender; sustainable\nboth environmentally and socially; and democratic in the deep sense of putting\npeople in control of their own lives and livelihoods.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-08T15:06:10Z"}
{"aid":"http://arxiv.org/abs/2504.06123v1","title":"Equating quantum imaginary time evolution, Riemannian gradient flows,\n  and stochastic implementations","summary":"We identify quantum imaginary time evolution as a Riemannian gradient flow on\nthe unitary group. We develop an upper bound for the error between the two\nevolutions that can be controlled through the step size of the Riemannian\ngradient descent which minimizes the energy of the system. We discuss\nimplementations through adaptive quantum algorithms and present a stochastic\nRiemannian gradient descent algorithm in which each step is efficiently\nimplementable on a quantum computer. We prove that for a sufficiently small\nstep size, the stochastic evolution concentrates around the imaginary time\nevolution, thereby providing performance guarantees for cooling the system\nthrough stochastic Riemannian gradient descent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T15:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.06126v1","title":"Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms","summary":"Vehicle Routing Problems (VRP) are an extension of the Traveling Salesperson\nProblem and are a fundamental NP-hard challenge in combinatorial optimization.\nSolving VRP in real-time at large scale has become critical in numerous\napplications, from growing markets like last-mile delivery to emerging\nuse-cases like interactive logistics planning. Such applications involve\nsolving similar problem instances repeatedly, yet current state-of-the-art\nsolvers treat each instance on its own without leveraging previous examples. We\nintroduce a novel optimization framework that uses a reinforcement learning\nagent - trained on prior instances - to quickly generate initial solutions,\nwhich are then further optimized by genetic algorithms. Our framework,\nEvolutionary Algorithm with Reinforcement Learning Initialization (EARLI),\nconsistently outperforms current state-of-the-art solvers across various time\nscales. For example, EARLI handles vehicle routing with 500 locations within\n1s, 10x faster than current solvers for the same solution quality, enabling\napplications like real-time and interactive routing. EARLI can generalize to\nnew data, as demonstrated on real e-commerce delivery data of a previously\nunseen city. Our hybrid framework presents a new way to combine reinforcement\nlearning and genetic algorithms, paving the road for closer interdisciplinary\ncollaboration between AI and optimization communities towards real-time\noptimization in diverse domains.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T15:21:01Z"}
{"aid":"http://arxiv.org/abs/2504.06139v1","title":"Non-local Boxes","summary":"The study of non-local boxes arose from the study of quantum entanglement and\nfrom the question: \"why isn't entanglement more non-local?\". Correlations\nstronger than quantum entanglement, but that still do not allow for\ninstantaneous transmission of information have been known to exist. This report\nfrom 2011 reviews what was known about these objects at the time.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T15:36:13Z"}
{"aid":"http://arxiv.org/abs/2504.06143v1","title":"ARLO: A Tailorable Approach for Transforming Natural Language Software\n  Requirements into Architecture using LLMs","summary":"Software requirements expressed in natural language (NL) frequently suffer\nfrom verbosity, ambiguity, and inconsistency. This creates a range of\nchallenges, including selecting an appropriate architecture for a system and\nassessing different architectural alternatives. Relying on human expertise to\naccomplish the task of mapping NL requirements to architecture is\ntime-consuming and error-prone. This paper proposes ARLO, an approach that\nautomates this task by leveraging (1) a set of NL requirements for a system,\n(2) an existing standard that specifies architecturally relevant software\nquality attributes, and (3) a readily available Large Language Model (LLM).\nSpecifically, ARLO determines the subset of NL requirements for a given system\nthat is architecturally relevant and maps that subset to a tailorable matrix of\narchitectural choices. ARLO applies integer linear programming on the\narchitectural-choice matrix to determine the optimal architecture for the\ncurrent requirements. We demonstrate ARLO's efficacy using a set of real-world\nexamples. We highlight ARLO's ability (1) to trace the selected architectural\nchoices to the requirements and (2) to isolate NL requirements that exert a\nparticular influence on a system's architecture. This allows the\nidentification, comparative assessment, and exploration of alternative\narchitectural choices based on the requirements and constraints expressed\ntherein.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-08T15:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06162v1","title":"A distributional approach to nonlocal curvature flows","summary":"In \\cite{CMP17} a novel distributional approach has been introduced to\nprovide a well-posed formulation of a class of crystalline mean curvature\nflows. In this paper, such an approach is extended to the nonlocal setting.\nApplications include the fractional mean curvature flow and the Minkowski flow;\ni.e., the geometric flow generated by the $(N-1)$-dimensional Minkowski\npre-content.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06179v1","title":"Plug and Play Distributed Control of Clustered Energy Hub Networks","summary":"The transition to renewable energy is driving the rise of distributed\nmulti-energy systems, in which individual energy hubs and prosumers (e.g.,\nhomes, industrial campuses) generate, store, and trade energy. Economic Model\nPredictive Control (MPC) schemes are widely used to optimize operation of\nenergy hubs by efficiently dispatching resources and minimizing costs while\nensuring operational constraints are met. Peer-to-peer (P2P) energy trading\namong hubs enhances network efficiency and reduces costs but also increases\ncomputational and privacy challenges, especially as the network scales.\nAdditionally, current distributed control techniques require global\nrecomputation whenever the network topology changes, limiting scalability. To\naddress these challenges, we propose a clustering-based P2P trading framework\nthat enables plug-and-play operation, allowing energy hubs to seamlessly join\nor leave without requiring network-wide controller updates. The impact is\nrestricted to the hubs within the affected cluster. The energy trading problem\nis formulated as a bi-level bargaining game, where inter-cluster trading\ncommitments are determined at the cluster level, while energy dispatch and\ncost-sharing among hubs within a cluster are refined at the hub level. Both\nlevels are solved in a distributed manner using ADMM, ensuring computational\nfeasibility and privacy preservation. Moreover, we develop plug-and-play\nprocedures to handle dynamic topology changes at both the hub and cluster\nlevels, minimizing disruptions across the network. Simulation results\ndemonstrate that the proposed bi-level framework reduces operational costs, and\nenables scalable energy management under plug-and-play operation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T16:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.06195v1","title":"Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum\n  Machine Learning Modeling","summary":"We present a full-spectrum machine learning framework for refractive index\nsensing using simulated absorption spectra from meta-grating structures\ncomposed of titanium or silicon nanorods under TE and TM polarizations. Linear\nregression was applied to 80 principal components extracted from each spectrum,\nand model performance was assessed using five-fold cross-validation, simulating\nreal-world biosensing scenarios where unknown patient samples are predicted\nbased on standard calibration data. Titanium-based structures, dominated by\nbroadband intensity changes, yielded the lowest mean squared errors and the\nhighest accuracy improvements: up to a 6065-fold reduction compared to the best\nsingle-feature model. In contrast, silicon-based structures, governed by narrow\nresonances, showed more modest gains due to spectral nonlinearity that limits\nthe effectiveness of global linear models. We also show that even the best\nsingle-wavelength predictor is identified through data-driven analysis, not\nvisual selection, highlighting the value of automated feature preselection.\nThese findings demonstrate that spectral shape plays a key role in modeling\nperformance and that full-spectrum linear approaches are especially effective\nfor intensity-modulated index sensors.","main_category":"physics.optics","categories":"physics.optics,physics.med-ph,q-bio.QM","published":"2025-04-08T16:37:53Z"}
{"aid":"http://arxiv.org/abs/2504.06201v1","title":"Quantum Annealing for Combinatorial Optimization: A Benchmarking Study","summary":"Quantum annealing (QA) has the potential to significantly improve solution\nquality and reduce time complexity in solving combinatorial optimization\nproblems compared to classical optimization methods. However, due to the\nlimited number of qubits and their connectivity, the QA hardware did not show\nsuch an advantage over classical methods in past benchmarking studies. Recent\nadvancements in QA with more than 5,000 qubits, enhanced qubit connectivity,\nand the hybrid architecture promise to realize the quantum advantage. Here, we\nuse a quantum annealer with state-of-the-art techniques and benchmark its\nperformance against classical solvers. To compare their performance, we solve\nover 50 optimization problem instances represented by large and dense\nHamiltonian matrices using quantum and classical solvers. The results\ndemonstrate that a state-of-the-art quantum solver has higher accuracy\n(~0.013%) and a significantly faster problem-solving time (~6,561x) than the\nbest classical solver. Our results highlight the advantages of leveraging QA\nover classical counterparts, particularly in hybrid configurations, for\nachieving high accuracy and substantially reduced problem solving time in\nlarge-scale real-world optimization problems.","main_category":"quant-ph","categories":"quant-ph,cs.CE","published":"2025-04-08T16:43:24Z"}
{"aid":"http://arxiv.org/abs/2504.06217v1","title":"Chernoff Information Bottleneck for Covert Quantum Target Sensing","summary":"Target sensing is a fundamental task with many practical applications,\ne.g.~in LiDaR and radar systems. Quantum strategies with entangled states can\nachieve better sensing accuracies with the same probe energy, yet it is often\nsimpler to use classical probes with higher energy than to take advantage of\nthe quantum regime. Recently, it has been shown that useful quantum advantage\ncan be achieved in covert situations, where sensing has to be performed while\nalso avoiding detection by an adversary: here increasing energy is not a viable\nstratagem, as it facilitates the adversary. In this paper we introduce a\ngeneral framework to assess and quantify quantum advantage in covert\nsituations. This is based on extending the information bottleneck principle,\noriginally developed for communication and machine learning applications, to\ndecision problems via the Chernoff information, with the ultimate goal of\nquantitatively optimizing the trade-off between covertness and sensing ability.\nIn this context we show how quantum resources, namely entangled photonic probes\npaired with photon counting, greatly outperform classical coherent transmitters\nin target detection and ranging, while also maintaining a chosen level of\ncovertness. Our work highlights the great potential of integrating quantum\nsensing in LiDAR systems to enhance the covert performance.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.06219v1","title":"Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling\n  Opt-Outs","summary":"The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T17:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.06220v1","title":"Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of\n  Frequency Adaptation","summary":"Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt\npowerful Foundation Models (FMs) to diverse downstream tasks while preserving\nand unleashing their inherent capabilities. However, we have observed that\nexisting PEFT methods, which are often designed with natural imagery in mind,\nstruggle when applied to Remote Sensing (RS) scenarios. This is primarily due\nto their inability to handle artifact influences, a problem particularly severe\nin RS image features. To tackle this challenge, we introduce Earth-Adapter, the\nfirst PEFT method specifically designed for RS artifacts conquering.\nEarth-Adapter introduces a novel Mixture of Frequency Adaptation process that\ncombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).\nBy utilizing DFT, Earth-Adapter can decompose features into different frequency\ncomponents, precisely separating artifacts from original features. The MoA then\ndynamically assigns weights to each adapter expert, allowing for the\ncombination of features across various frequency domains. These\nsimple-yet-effective approaches enable Earth-Adapter to more efficiently\novercome the disturbances caused by artifacts than previous PEFT methods,\nsignificantly enhancing the FMs' performance on RS scenarios. Experiments on\nDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentation\nbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline\nRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG\nbenchmarks. Our code will be released at\nhttps://github.com/VisionXLab/Earth-Adapter.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06247v1","title":"The Resolved Structure of a Low Metallicity Photodissociation Region","summary":"Photodissociation Regions (PDRs) are key to understanding the feedback\nprocesses that shape interstellar matter in galaxies. One important type of PDR\nis the interface between HII regions and molecular clouds, where\nfar-ultraviolet (FUV) radiation from massive stars heats gas and dissociates\nmolecules. Photochemical models predict that the C/CO transition occurs deeper\nin the PDR compared to the H/H2 transition in low-metallicity environments,\nincreasing the extent of CO-dark H2 gas. This prediction has been difficult to\ntest outside the Milky Way due to the lack of high spatial resolution\nobservations tracing H2 and CO. This study examines a low-metallicity PDR in\nthe N13 region of the Small Magellanic Cloud (SMC) where we spatially resolve\nthe ionization front, the H2 dissociation front, and the C/CO transition using\n12CO J=2-1, 3-2 and [CI] (1-0) observations from the Atacama Large\nMillimeter/sub-mm Array (ALMA) and near-infrared spectroscopy of H2 vibrational\nlines from the James Webb Space Telescope (JWST). Our analysis shows that the\nseparation between the H/H2 and C/CO boundaries is approximately 0.043 +-\n0.013(stat.) +- 0.0036(syst.) pc (equivalent to 0.\"146 +- 0.\"042 (stat.) +-\n0.\"012 (syst.) at the SMC's distance of 62 kpc), defining the spatial extent of\nthe CO-dark H2 region. Compared to our plane-parallel PDR models, we find that\na constant pressure model matches the observed structure better than a constant\ndensity one. Overall, we find that the PDR model does well at predicting the\nextent of the CO-dark H2 layer in N13. This study represents the first resolved\nbenchmark for low metallicity PDRs.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T17:49:33Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06549v1","title":"Societal Impacts Research Requires Benchmarks for Creative Composition\n  Tasks","summary":"Foundation models that are capable of automating cognitive tasks represent a\npivotal technological shift, yet their societal implications remain unclear.\nThese systems promise exciting advances, yet they also risk flooding our\ninformation ecosystem with formulaic, homogeneous, and potentially misleading\nsynthetic content. Developing benchmarks grounded in real use cases where these\nrisks are most significant is therefore critical. Through a thematic analysis\nusing 2 million language model user prompts, we identify creative composition\ntasks as a prevalent usage category where users seek help with personal tasks\nthat require everyday creativity. Our fine-grained analysis identifies\nmismatches between current benchmarks and usage patterns among these tasks.\nCrucially, we argue that the same use cases that currently lack thorough\nevaluations can lead to negative downstream impacts. This position paper argues\nthat benchmarks focused on creative composition tasks is a necessary step\ntowards understanding the societal harms of AI-generated content. We call for\ngreater transparency in usage patterns to inform the development of new\nbenchmarks that can effectively measure both the progress and the impacts of\nmodels with creative capabilities.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-09T03:12:16Z"}
{"aid":"http://arxiv.org/abs/2504.06554v1","title":"Experimental Implementation of a Qubit-Efficient Variational Quantum\n  Eigensolver with Analog Error Mitigation on a Superconducting Quantum\n  Processor","summary":"We experimentally demonstrate a qubit-efficient variational quantum\neigensolver (VQE) algorithm using a superconducting quantum processor,\nemploying minimal quantum resources with only a transmon qubit coupled to a\nhigh-coherence photonic qubit. By leveraging matrix product states to compress\nthe quantum state representation, we simulate an N + 1-spin circular Ising\nmodel with a transverse field. Furthermore, we develop an analog error\nmitigation approach through zero-noise extrapolation by introducing a precise\nnoise injection technique for the transmon qubit. As a validation, we apply our\nerror-mitigated qubit-efficient VQE in determining the ground state energies of\na 4-spin Ising model. Our results demonstrate the feasibility of performing\nquantum algorithms with minimal quantum resources while effectively mitigating\nthe impact of noise, offering a promising pathway to bridge the gap between\ntheoretical advances and practical implementations on current noisy\nintermediate-scale quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T03:23:26Z"}
{"aid":"http://arxiv.org/abs/2504.06560v1","title":"NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables","summary":"Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.06561v1","title":"A Streamable Neural Audio Codec with Residual Scalar-Vector Quantization\n  for Real-Time Communication","summary":"This paper proposes StreamCodec, a streamable neural audio codec designed for\nreal-time communication. StreamCodec adopts a fully causal, symmetric\nencoder-decoder structure and operates in the modified discrete cosine\ntransform (MDCT) domain, aiming for low-latency inference and real-time\nefficient generation. To improve codebook utilization efficiency and compensate\nfor the audio quality loss caused by structural causality, StreamCodec\nintroduces a novel residual scalar-vector quantizer (RSVQ). The RSVQ\nsequentially connects scalar quantizers and improved vector quantizers in a\nresidual manner, constructing coarse audio contours and refining acoustic\ndetails, respectively. Experimental results confirm that the proposed\nStreamCodec achieves decoded audio quality comparable to advanced\nnon-streamable neural audio codecs. Specifically, on the 16 kHz LibriTTS\ndataset, StreamCodec attains a ViSQOL score of 4.30 at 1.5 kbps. It has a fixed\nlatency of only 20 ms and achieves a generation speed nearly 20 times real-time\non a CPU, with a lightweight model size of just 7M parameters, making it highly\nsuitable for real-time communication applications.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-09T03:49:00Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06594v1","title":"Machine Learning for Extrapolating No-Core Shell Model Results to\n  Infinite Basis","summary":"We utilize the machine learning to extrapolate to the infinite model space\nthe no-core shell model (NCSM) results for the energies and rms radii of the\n6He ground state and 6Li lowest states. The extrapolated energies and rms radii\nconverge as the NCSM results from larger model spaces are included in the\ntraining dataset for ensemble of artificial neural networks thus enabling an\naccurate predictions for these observables.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T05:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.06596v1","title":"Overcoming Dynamic Environments: A Hybrid Approach to Motion Planning\n  for Manipulators","summary":"Robotic manipulators operating in dynamic and uncertain environments require\nefficient motion planning to navigate obstacles while maintaining smooth\ntrajectories. Velocity Potential Field (VPF) planners offer real-time\nadaptability but struggle with complex constraints and local minima, leading to\nsuboptimal performance in cluttered spaces. Traditional approaches rely on\npre-planned trajectories, but frequent recomputation is computationally\nexpensive. This study proposes a hybrid motion planning approach, integrating\nan improved VPF with a Sampling-Based Motion Planner (SBMP). The SBMP ensures\noptimal path generation, while VPF provides real-time adaptability to dynamic\nobstacles. This combination enhances motion planning efficiency, stability, and\ncomputational feasibility, addressing key challenges in uncertain environments\nsuch as warehousing and surgical robotics.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T05:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.06598v1","title":"Stochastic Ray Tracing of 3D Transparent Gaussians","summary":"3D Gaussian splatting has recently been widely adopted as a 3D representation\nfor novel-view synthesis, relighting, and text-to-3D generation tasks, offering\nrealistic and detailed results through a collection of explicit 3D Gaussians\ncarrying opacities and view-dependent colors. However, efficient rendering of\nmany transparent primitives remains a significant challenge. Existing\napproaches either rasterize the 3D Gaussians with approximate sorting per view\nor rely on high-end RTX GPUs to exhaustively process all ray-Gaussian\nintersections (bounding Gaussians by meshes). This paper proposes a stochastic\nray tracing method to render 3D clouds of transparent primitives. Instead of\nprocessing all ray-Gaussian intersections in sequential order, each ray\ntraverses the acceleration structure only once, randomly accepting and shading\na single intersection (or N intersections, using a simple extension). This\napproach minimizes shading time and avoids sorting the Gaussians along the ray\nwhile minimizing the register usage and maximizing parallelism even on low-end\nGPUs. The cost of rays through the Gaussian asset is comparable to that of\nstandard mesh-intersection rays. While our method introduces noise, the shading\nis unbiased, and the variance is slight, as stochastic acceptance is\nimportance-sampled based on accumulated opacity. The alignment with the Monte\nCarlo philosophy simplifies implementation and easily integrates our method\ninto a conventional path-tracing framework.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-09T05:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.06600v1","title":"Automated Business Process Analysis: An LLM-Based Approach to Value\n  Assessment","summary":"Business processes are fundamental to organizational operations, yet their\noptimization remains challenging due to the timeconsuming nature of manual\nprocess analysis. Our paper harnesses Large Language Models (LLMs) to automate\nvalue-added analysis, a qualitative process analysis technique that aims to\nidentify steps in the process that do not deliver value. To date, this\ntechnique is predominantly manual, time-consuming, and subjective. Our method\noffers a more principled approach which operates in two phases: first,\ndecomposing high-level activities into detailed steps to enable granular\nanalysis, and second, performing a value-added analysis to classify each step\naccording to Lean principles. This approach enables systematic identification\nof waste while maintaining the semantic understanding necessary for qualitative\nanalysis. We develop our approach using 50 business process models, for which\nwe collect and publish manual ground-truth labels. Our evaluation, comparing\nzero-shot baselines with more structured prompts reveals (a) a consistent\nbenefit of structured prompting and (b) promising performance for both tasks.\nWe discuss the potential for LLMs to augment human expertise in qualitative\nprocess analysis while reducing the time and subjectivity inherent in manual\napproaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SE","published":"2025-04-09T05:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06605v1","title":"Sensing-Oriented Adaptive Resource Allocation Designs for OFDM-ISAC\n  Systems","summary":"Orthogonal frequency division multiplexing - integrated sensing and\ncommunication (OFDM-ISAC) has emerged as a key enabler for future wireless\nnetworks, leveraging the widely adopted OFDM waveform to seamlessly integrate\nwireless communication and radar sensing within a unified framework. In this\npaper, we propose adaptive resource allocation strategies for OFDM-ISAC systems\nto achieve optimal trade-offs between diverse sensing requirements and\ncommunication quality-of-service (QoS). We first develop a comprehensive\nresource allocation framework for OFDM-ISAC systems, deriving closed-form\nexpressions for key sensing performance metrics, including delay resolution,\nDoppler resolution, delay-Doppler peak sidelobe level (PSL), and received\nsignal-to-noise ratio (SNR). Building on this theoretical foundation, we\nintroduce two novel resource allocation algorithms tailored to distinct sensing\nobjectives. The resolution-oriented algorithm aims to maximize the weighted\ndelay-Doppler resolution while satisfying constraints on PSL, sensing SNR,\ncommunication sum-rate, and transmit power. The sidelobe-oriented algorithm\nfocuses on minimizing delay-Doppler PSL while satisfying resolution, SNR, and\ncommunication constraints. To efficiently solve the resulting non-convex\noptimization problems, we develop two adaptive resource allocation algorithms\nbased on Dinkelbach's transform and majorization-minimization (MM). Extensive\nsimulations validate the effectiveness of the proposed sensing-oriented\nadaptive resource allocation strategies in enhancing resolution and sidelobe\nsuppression. Remarkably, these strategies achieve sensing performance nearly\nidentical to that of a radar-only scheme, which dedicates all resources to\nsensing. These results highlight the superior performance of the proposed\nmethods in optimizing the trade-off between sensing and communication\nobjectives within OFDM-ISAC systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T06:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.06607v1","title":"Visually Similar Pair Alignment for Robust Cross-Domain Object Detection","summary":"Domain gaps between training data (source) and real-world environments\n(target) often degrade the performance of object detection models. Most\nexisting methods aim to bridge this gap by aligning features across source and\ntarget domains but often fail to account for visual differences, such as color\nor orientation, in alignment pairs. This limitation leads to less effective\ndomain adaptation, as the model struggles to manage both domain-specific shifts\n(e.g., fog) and visual variations simultaneously. In this work, we demonstrate\nfor the first time, using a custom-built dataset, that aligning visually\nsimilar pairs significantly improves domain adaptation. Based on this insight,\nwe propose a novel memory-based system to enhance domain alignment. This system\nstores precomputed features of foreground objects and background areas from the\nsource domain, which are periodically updated during training. By retrieving\nvisually similar source features for alignment with target foreground and\nbackground features, the model effectively addresses domain-specific\ndifferences while reducing the impact of visual variations. Extensive\nexperiments across diverse domain shift scenarios validate our method's\neffectiveness, achieving 53.1 mAP on Foggy Cityscapes and 62.3 on Sim10k,\nsurpassing prior state-of-the-art methods by 1.2 and 4.1 mAP, respectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.06617v1","title":"Spectrum radii of trees","summary":"For any positive integer $r$ and positive number $\\alpha$, let ${\\mathscr\nW}_r(\\alpha)$ denote the set of positive numbers defined recursively:\n$\\alpha\\in {\\mathscr W}_r(\\alpha)$, and for any multi-set $\\{q_i\\in {\\mathscr\nW}_r(\\alpha): 1\\le i\\le s\\}$, where $1\\le s<r$,\n$\\beta:=\\alpha-\\sum\\limits_{i=1}^sq_i^{-1}$ belongs to ${\\mathscr W}_r(\\alpha)$\nas long as $\\beta>0$. We first show that there exists a tree $T$ such that its\nmaximum degree $\\Delta(T)$ is at most $r$ and its spectrum radius $\\lambda(T)$\nis equal to $\\alpha$ if and only if $\\alpha^{-1}\\in {\\mathscr W}_r(\\alpha)$. It\nfollows that the set of spectrum radii of non-trivial trees is exactly the set\nof positive numbers $\\alpha$ such that $\\alpha^{-1}\\in {\\mathscr\nW}_{\\lfloor\\alpha^2\\rfloor}(\\alpha)$. Applying this conclusion, we then prove\nthat for any positive integers $r$ and $k$, there exists a tree $T$ with\n$\\Delta(T)=r$ and $\\lambda(T)=\\sqrt k$ if and only if $\\frac 14 k+1<r\\le k$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.06621v1","title":"Computation of shape Taylor expansions","summary":"Shape derivative is an important analytical tool for studying scattering\nproblems involving perturbations in scatterers. Many applications, including\ninverse scattering, optimal design, and uncertainty quantification, are based\non shape derivatives. However, computing high order shape derivatives is\nchallenging due to the complexity of shape calculus. This work introduces a\ncomprehensive method for computing shape Taylor expansions in two dimensions\nusing recurrence formulas. The approach is developed under sound-soft,\nsound-hard, impedance, and transmission boundary conditions. Additionally, we\napply the shape Taylor expansion to uncertainty quantification in wave\nscattering, enabling high order moment estimation for the scattered field under\nrandom boundary perturbations. Numerical examples are provided to illustrate\nthe effectiveness of the shape Taylor expansion in achieving high order\napproximations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T06:42:21Z"}
{"aid":"http://arxiv.org/abs/2504.06624v1","title":"An inverse problem for a nonlinear biharmonic operator","summary":"An inverse problem for a nonlinear biharmonic operator is under consideration\nin the spirit of Isakov (1993) and Johansson-Nurminen-Salo (2023). We prove\nthat a general nonlinear term of the $Q= Q(x,u, \\nabla u, \\Delta u)$ associated\nto a nonlinear biharmonic operator can be recovered from the local Cauchy data\nset. The proof uses first order linearization method, Runge approximation, and\nuniqueness results for the linearized inverse problem.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T06:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.06646v1","title":"Beyond the Winding Path of Learning: Exploring Affective, Cognitive, and\n  Action-Oriented Prompts for Communication Skills","summary":"Since high dropout rates in online learning platforms were reported, various\nfactors affecting learner retention have been identified, with learners'\nperceptions of their experiences playing a crucial role in shaping their\npersistence. For instance, Kittur et al. highlight how success expectations are\nshaped by perceived system fit and course difficulty.\n  Recent advances in generative Artificial Intelligence (GenAI) present new\npossibilities for GenAI-mediated learning. AI-generated instructional messages\nare often perceived as clearer than human-written content, but their impact on\nlearners' perceptions of skill-building experiences remains underexplored.\n  This study examines GenAI-mediated learning in a self-directed context,\nfocusing on communication skills. We compare three messaging styles -\nAffective, Cognitive, and Action-Oriented - to investigate their influence on\nlearners' perceptions of the learning process. We applied this approach to ten\ninstructional units, using GenAI to generate 30 learning items. Three\nevaluators assessed them for desirability and appropriateness through numerical\nratings and open-ended feedback. The 180 excerpts were analyzed using reflexive\nthematic analysis, revealing four overarching themes: Prerequisite Common\nGround, Intrinsic Value, User Responses, and Expressed Preferences.\n  We discuss these insights to inform the design of GenAI-mediated,\nself-directed skill-building, with the goal of enhancing engagement,\npersistence, and learning outcomes.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-09T07:34:39Z"}
{"aid":"http://arxiv.org/abs/2504.06654v1","title":"Finiteness of projective pluricanonical representation for automorphisms\n  of complex manifolds","summary":"We study the action of the group of bimeromorphic automorphisms\n$\\mathrm{Bim}(X)$ of a compact complex manifold $X$ on the image of the\npluricanonical map, which we call the projective pluricanonical representation\nof this group. If $X$ is a Moishezon variety, then the image of\n$\\mathrm{Bim}(X)$ via such a representation is a finite group by a classical\nresult due to Deligne and Ueno. We prove that this image is a finite group\nunder the assumption that for the Kodaira dimension $\\kappa(X)$ of $X$ we have\n$\\kappa(X)=\\dim X-1$. To this aim, we prove a version of the canonical bundle\nformula in relative dimension $1$ which works for a proper morphism from a\ncomplex variety to a projective variety. In particular, this establishes the\nanalytic version of Prokhorov--Shokurov conjecture in relative dimension $1$.\nAlso, we observe that the analytic version of this conjecture does not hold in\nrelative dimension $2$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-09T07:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.06657v1","title":"When Pythagoras meets Navier-Stokes","summary":"In this article, we develop a new method, based on a time decomposition of a\nCauchy problem elaborated in [6], to retrieve the well-known $L^\\infty\n([0,T],L^2(\\mathbb{R}^d,\\mathbb{R}^d))$ control of the solution of the\nincompressible Navier-Stokes equation in $\\mathbb{R}^d$. We precisely explain\nhow the Pythagorean theorem in $L^2(\\mathbb{R}^d,\\mathbb{R}^d)$ allows to get\nthe proper energy estimate; however such an argument does not work anymore in\n$L^p(\\mathbb{R}^d,\\mathbb{R}^d)$, $p \\neq 2$. We also deduce, by similar\narguments, an already known $L^\\infty ([0,T],L^1(\\mathbb{R}^3,\\mathbb{R}^3))$\ncontrol of vorticity for $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.06659v1","title":"Bridging the Gap Between Preference Alignment and Machine Unlearning","summary":"Despite advances in Preference Alignment (PA) for Large Language Models\n(LLMs), mainstream methods like Reinforcement Learning with Human Feedback\n(RLHF) face notable challenges. These approaches require high-quality datasets\nof positive preference examples, which are costly to obtain and computationally\nintensive due to training instability, limiting their use in low-resource\nscenarios. LLM unlearning technique presents a promising alternative, by\ndirectly removing the influence of negative examples. However, current research\nhas primarily focused on empirical validation, lacking systematic quantitative\nanalysis. To bridge this gap, we propose a framework to explore the\nrelationship between PA and LLM unlearning. Specifically, we introduce a\nbi-level optimization-based method to quantify the impact of unlearning\nspecific negative examples on PA performance. Our analysis reveals that not all\nnegative examples contribute equally to alignment improvement when unlearned,\nand the effect varies significantly across examples. Building on this insight,\nwe pose a crucial question: how can we optimally select and weight negative\nexamples for unlearning to maximize PA performance? To answer this, we propose\na framework called Unlearning to Align (U2A), which leverages bi-level\noptimization to efficiently select and unlearn examples for optimal PA\nperformance. We validate the proposed method through extensive experiments,\nwith results confirming its effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T07:49:08Z"}
{"aid":"http://arxiv.org/abs/2504.06662v1","title":"RAMBO: RL-augmented Model-based Optimal Control for Whole-body\n  Loco-manipulation","summary":"Loco-manipulation -- coordinated locomotion and physical interaction with\nobjects -- remains a major challenge for legged robots due to the need for both\naccurate force interaction and robustness to unmodeled dynamics. While\nmodel-based controllers provide interpretable dynamics-level planning and\noptimization, they are limited by model inaccuracies and computational cost. In\ncontrast, learning-based methods offer robustness while struggling with precise\nmodulation of interaction forces. We introduce RAMBO -- RL-Augmented\nModel-Based Optimal Control -- a hybrid framework that integrates model-based\nreaction force optimization using a simplified dynamics model and a feedback\npolicy trained with reinforcement learning. The model-based module generates\nfeedforward torques by solving a quadratic program, while the policy provides\nfeedback residuals to enhance robustness in control execution. We validate our\nframework on a quadruped robot across a diverse set of real-world\nloco-manipulation tasks -- such as pushing a shopping cart, balancing a plate,\nand holding soft objects -- in both quadrupedal and bipedal walking. Our\nexperiments demonstrate that RAMBO enables precise manipulation while achieving\nrobust and dynamic locomotion, surpassing the performance of policies trained\nwith end-to-end scheme. In addition, our method enables flexible trade-off\nbetween end-effector tracking accuracy with compliance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.06669v1","title":"NLP Security and Ethics, in the Wild","summary":"As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T08:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.06670v1","title":"Dynamic Residual Safe Reinforcement Learning for Multi-Agent\n  Safety-Critical Scenarios Decision-Making","summary":"In multi-agent safety-critical scenarios, traditional autonomous driving\nframeworks face significant challenges in balancing safety constraints and task\nperformance. These frameworks struggle to quantify dynamic interaction risks in\nreal-time and depend heavily on manual rules, resulting in low computational\nefficiency and conservative strategies. To address these limitations, we\npropose a Dynamic Residual Safe Reinforcement Learning (DRS-RL) framework\ngrounded in a safety-enhanced networked Markov decision process. It's the first\ntime that the weak-to-strong theory is introduced into multi-agent\ndecision-making, enabling lightweight dynamic calibration of safety boundaries\nvia a weak-to-strong safety correction paradigm. Based on the multi-agent\ndynamic conflict zone model, our framework accurately captures spatiotemporal\ncoupling risks among heterogeneous traffic participants and surpasses the\nstatic constraints of conventional geometric rules. Moreover, a risk-aware\nprioritized experience replay mechanism mitigates data distribution bias by\nmapping risk to sampling probability. Experimental results reveal that the\nproposed method significantly outperforms traditional RL algorithms in safety,\nefficiency, and comfort. Specifically, it reduces the collision rate by up to\n92.17%, while the safety model accounts for merely 27% of the main model's\nparameters.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T08:13:14Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06704v1","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-09T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06709v1","title":"Universal profile for cosmic birefringence tomography with radio\n  galaxies","summary":"We propose a new method to tomographically probe cosmic birefringence using\nradio galaxies. We show that the redshift evolution of the cosmic birefringence\nangle induced by a slow-rolling pseudoscalar field, which is a candidate for\ndynamical dark energy, is independent of the detailed model of the pseudoscalor\nfield. This universal profile evolves predominantly at $z\\lesssim10$. In\ncontrast, if the origin is a dark matter-like pseudscalor field, the resulting\nbirefringence angle tends to be negligible in the low-redshift regime. This new\ninsight provides a strong motivation to independently test the cosmic\nbirefringence using polarized astrophysical sources such as radio galaxies. We\nfind that a sample size of $\\order{10^5-10^6}$ is required to distinguish the\nprofiles, which is achievable with ongoing and upcoming radio surveys such as\nASKAP or SKA.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.HE,gr-qc,hep-ph","published":"2025-04-09T09:09:58Z"}
{"aid":"http://arxiv.org/abs/2504.06718v1","title":"Ice-Breakers, Turn-Takers and Fun-Makers: Exploring Robots for Groups\n  with Teenagers","summary":"Successful, enjoyable group interactions are important in public and personal\ncontexts, especially for teenagers whose peer groups are important for\nself-identity and self-esteem. Social robots seemingly have the potential to\npositively shape group interactions, but it seems difficult to effect such\nimpact by designing robot behaviors solely based on related (human interaction)\nliterature. In this article, we take a user-centered approach to explore how\nteenagers envisage a social robot \"group assistant\". We engaged 16 teenagers in\nfocus groups, interviews, and robot testing to capture their views and\nreflections about robots for groups. Over the course of a two-week summer\nschool, participants co-designed the action space for such a robot and\nexperienced working with/wizarding it for 10+ hours. This experience further\naltered and deepened their insights into using robots as group assistants. We\nreport results regarding teenagers' views on the applicability and use of a\nrobot group assistant, how these expectations evolved throughout the study, and\ntheir repeat interactions with the robot. Our results indicate that each group\nmoves on a spectrum of need for the robot, reflected in use of the robot more\n(or less) for ice-breaking, turn-taking, and fun-making as the situation\ndemanded.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T09:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.06720v1","title":"Revealing the ages of metal-rich RR Lyrae via kinematic label transfer","summary":"RR Lyrae stars have long been considered reliable tracers of old, metal-poor\npopulations, primarily due to their prevalence in globular clusters and the\nGalactic halo. However, the discovery of a metal-rich subpopulation in the\nGalactic disc, kinematically colder and more rotationally supported, challenges\nthis classical view. Understanding the age of these metal-rich RR Lyrae stars\nis crucial for constraining their formation pathways and assessing what\nGalactic populations they are tracing. In this work, we leverage the\nunprecedented astrometric precision of Gaia DR3 to infer the age distribution\nof metal-rich RR Lyrae stars through a kinematic comparison with O-rich Mira\nvariables. Mira variables, with their well-established period-age relation,\nserve as a natural clock, allowing us to transfer age information to RR Lyrae\nstars via their phase-space properties. By applying this approach across\ndifferent metallicity bins, we find that the most metal-rich RR Lyrae stars\n($[\\rm Fe/H] > -0.5$) exhibit kinematics consistent with a population\nsignificantly younger ($\\approx 6-7$ Gyr) than typically assumed for RR Lyrae\nstars. In contrast, those with $-1 < [\\rm Fe/H] < -0.5$ show properties more\naligned with older ($\\approx 9-11$ Gyr) populations. Interestingly, we also\nfind evidence of a possible double age populations for the most metal-rich RR\nLyrae, one younger with ages between 3 and 6 Gyr, and another one older ranging\nfrom 8 to 11 Gyr. These results provide strong evidence that metal-rich RR\nLyrae stars in the Galactic field do not exclusively trace ancient populations.\nThis finding challenges the current model of RR Lyrae formation and supports\nalternative formation scenarios, such as binary evolution.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T09:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.06729v1","title":"Optimal Duration of Reserve Capacity Ancillary Services for Distributed\n  Energy Resources","summary":"The increasing integration of distributed energy resources (DERs) into power\nsystems presents opportunities and challenges for ancillary services (AS)\nprovision. Technical requirements of existing AS (i.e., duration, reliability,\nramp rate, and lead time) have been designed for traditional generating units,\nmaking their provision by DER aggregates particularly challenging. This paper\nproposes a method to design the duration of reserve capacity AS products\nconsidering the operational constraints of DERs and the temporal dynamics of\nsystem imbalances. The optimal product duration is determined by maximizing\nproduct availability and aligning the supply profile with the system's\nbalancing needs. We apply the methodology to a realistic Swiss low-voltage\nnetwork with a diverse DER portfolio. The results reveal that (i) shorter\nproduct durations maximize average availability and (ii) long product durations\nimprove the alignment with system balancing needs. This paper offers valuable\ninsights for system operators to design AS products tailored for DER\nparticipation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T09:37:24Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06746v1","title":"Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning","summary":"Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.","main_category":"cs.MA","categories":"cs.MA,cs.RO","published":"2025-04-09T10:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06758v1","title":"Data-Driven RANS Closures Using a Relative Importance Term Analysis\n  Based Classifier for 2D and 3D Separated Flows","summary":"This study presents a novel approach for enhancing Reynolds-averaged\nNavier-Stokes (RANS) turbulence modeling through the application of a Relative\nImportance Term Analysis (RITA) methodology to develop a new zonally-augmented\n$k-\\omega$ SST model. Traditional Linear Eddy Viscosity Models often struggle\nwith separated flows. Our approach introduces a physics-based binary classifier\nthat systematically identifies separated shear layers requiring correction by\nanalyzing the relative magnitudes of terms in the turbulence kinetic energy\nequation. Using symbolic regression, we develop compact correction terms for\nReynolds stress anisotropy and turbulent kinetic energy production. Trained on\ntwo-dimensional configurations, our model demonstrates significant improvements\nin predicting separation dynamics while maintaining baseline performance and\nfully attached flows. Generalization tests on Ahmed body and Faith Hill\nthree-dimensional configurations confirm robust transferability, establishing\nan effective methodology for targeted enhancement of RANS predictions in\nseparated flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T10:22:36Z"}
{"aid":"http://arxiv.org/abs/2504.06770v1","title":"Measuring and predicting galaxy assembly bias across galaxy samples","summary":"One of the most important effects shaping small-scale galaxy clustering is\ngalaxy assembly bias, which refers to the dependence of galaxy clustering on\nhalo properties. We investigate this effect using galaxy samples selected\naccording to stellar mass, r-band magnitude, and broad-band colors from the\nlargest hydrodynamical simulation of the IllustrisTNG suite. We find that\ngalaxy assembly bias depends strongly upon the selection criteria, number\ndensity, and redshift of the sample, increasing or decreasing the clustering by\nas much as 25%. Interestingly, no single secondary halo property fully captures\nthe strength of this effect for any galaxy population. Therefore, empirical\napproaches modeling galaxy assembly bias as a function of a single halo\nproperty cannot reproduce predictions from hydrodynamical simulations. We then\nstudy how galaxy assembly bias emerges from the interplay of halo assembly bias\n-- the dependence of halo clustering on properties other than mass -- and\noccupancy variation -- the correlation between galaxy occupation and secondary\nhalo properties -- and provide an analytical expression that predicts the\namount of galaxy assembly bias caused by any halo property. This expression\nfacilitates understanding the dependence of galaxy assembly bias on halo\nproperties and enables the straightforward incorporation of this effect into\nhalo model approaches.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-09T10:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.06772v1","title":"Towards Efficient Roadside LiDAR Deployment: A Fast Surrogate Metric\n  Based on Entropy-Guided Visibility","summary":"The deployment of roadside LiDAR sensors plays a crucial role in the\ndevelopment of Cooperative Intelligent Transport Systems (C-ITS). However, the\nhigh cost of LiDAR sensors necessitates efficient placement strategies to\nmaximize detection performance. Traditional roadside LiDAR deployment methods\nrely on expert insight, making them time-consuming. Automating this process,\nhowever, demands extensive computation, as it requires not only visibility\nevaluation but also assessing detection performance across different LiDAR\nplacements. To address this challenge, we propose a fast surrogate metric, the\nEntropy-Guided Visibility Score (EGVS), based on information gain to evaluate\nobject detection performance in roadside LiDAR configurations. EGVS leverages\nTraffic Probabilistic Occupancy Grids (TPOG) to prioritize critical areas and\nemploys entropy-based calculations to quantify the information captured by\nLiDAR beams. This eliminates the need for direct detection performance\nevaluation, which typically requires extensive labeling and computational\nresources. By integrating EGVS into the optimization process, we significantly\naccelerate the search for optimal LiDAR configurations. Experimental results\nusing the AWSIM simulator demonstrate that EGVS strongly correlates with\nAverage Precision (AP) scores and effectively predicts object detection\nperformance. This approach offers a computationally efficient solution for\nroadside LiDAR deployment, facilitating scalable smart infrastructure\ndevelopment.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T10:53:03Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06798v1","title":"Probing Remote Nuclear Magnetic Moments in hBN with VB Electron Spin","summary":"Since the initial discovery of optically addressable spins of the negatively\ncharged boron vacancy defect (VB) in hexagonal boron nitride (hBN), substantial\nprogress has been made, enabling promising applications in quantum sensing,\ninformation processing, and simulations. A deep understanding of the VB\n(electron): hBN (nuclear) spin systems is crucial for realizing these\npotentials. In this article, we employ Electron Nuclear Double Resonance\n(ENDOR) to demonstrate the sensing of dis tant nuclear spins via the VB\nelectron spin. We identify the nature and localization of the probed nuclear\nmagnetic moments as 14N spins localized 0.4 nm away from the vacancy and\nresolve the energies of the corresponding interactions. Density Functional\nTheory (DFT) calculations further confirm these findings, providing a detailed\ndescription of the interactions between the VB electron spin and surrounding\nnitrogen atoms in different shells. The results establish the VB electron spin\nas a promising tool for developing novel van der Waals material-based nuclear\nmagnetic resonance (NMR) probes, advancing the understanding of spin physics in\nhBN, and unlocking its potential to study distant nuclear spin interactions in\nthe host.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-09T11:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.06801v1","title":"MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular\n  Detection","summary":"Current monocular 3D detectors are held back by the limited diversity and\nscale of real-world datasets. While data augmentation certainly helps, it's\nparticularly difficult to generate realistic scene-aware augmented data for\noutdoor settings. Most current approaches to synthetic data generation focus on\nrealistic object appearance through improved rendering techniques. However, we\nshow that where and how objects are positioned is just as crucial for training\neffective 3D monocular detectors. The key obstacle lies in automatically\ndetermining realistic object placement parameters - including position,\ndimensions, and directional alignment when introducing synthetic objects into\nactual scenes. To address this, we introduce MonoPlace3D, a novel system that\nconsiders the 3D scene content to create realistic augmentations. Specifically,\ngiven a background scene, MonoPlace3D learns a distribution over plausible 3D\nbounding boxes. Subsequently, we render realistic objects and place them\naccording to the locations sampled from the learned distribution. Our\ncomprehensive evaluation on two standard datasets KITTI and NuScenes,\ndemonstrates that MonoPlace3D significantly improves the accuracy of multiple\nexisting monocular 3D detectors while being highly data efficient.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.06812v1","title":"Semi-classical geometric tensor in multiparameter quantum information","summary":"The quantum geometric tensor (QGT) captures the variations of quantum states\nwith parameters, serving as a central concept in modern quantum physics. Its\nreal part, the quantum Fisher information matrix (QFIM), has a\nmeasurement-dependent counterpart that links statistics to distinguishability.\nHowever, an analogous extension for the QGT is hindered by the fundamental\ninaccessibility of its imaginary part through measurement probabilities. Here\nwe introduce a counterpart to the QGT that includes measurement operators,\ntermed the \\textit{semi-classical} geometric tensor (SCGT). We show that the\nSCGT provides a lower bound to the QGT that is tight for pure states. Moreover,\nwe use the SCGT to derive sharp multiparameter information bounds and discuss\nextensions of the Berry phase.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-09T12:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.06819v1","title":"Developing Modular Grasping and Manipulation Pipeline Infrastructure to\n  Streamline Performance Benchmarking","summary":"The robot manipulation ecosystem currently faces issues with integrating\nopen-source components and reproducing results. This limits the ability of the\ncommunity to benchmark and compare the performance of different solutions to\none another in an effective manner, instead relying on largely holistic\nevaluations. As part of the COMPARE Ecosystem project, we are developing\nmodular grasping and manipulation pipeline infrastructure in order to\nstreamline performance benchmarking. The infrastructure will be used towards\nthe establishment of standards and guidelines for modularity and improved\nopen-source development and benchmarking. This paper provides a high-level\noverview of the architecture of the pipeline infrastructure, experiments\nconducted to exercise it during development, and future work to expand its\nmodularity.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T12:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06843v1","title":"Integrating Cognitive Processing Signals into Language Models: A Review\n  of Advances, Applications and Future Directions","summary":"Recently, the integration of cognitive neuroscience in Natural Language\nProcessing (NLP) has gained significant attention. This article provides a\ncritical and timely overview of recent advancements in leveraging cognitive\nsignals, particularly Eye-tracking (ET) signals, to enhance Language Models\n(LMs) and Multimodal Large Language Models (MLLMs). By incorporating\nuser-centric cognitive signals, these approaches address key challenges,\nincluding data scarcity and the environmental costs of training large-scale\nmodels. Cognitive signals enable efficient data augmentation, faster\nconvergence, and improved human alignment. The review emphasises the potential\nof ET data in tasks like Visual Question Answering (VQA) and mitigating\nhallucinations in MLLMs, and concludes by discussing emerging challenges and\nresearch trends.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06888v1","title":"The Singular CR Yamabe Problem and Hausdorff Dimension","summary":"We consider a compact pseudo-hermitian manifold (M,\\theta, J), that is a\nmanifold equipped with a contact form \\theta and CR structure J. We consider a\nconformal deformation of the contact form to obtain a complete, singular\ncontact form and a corresponding Yamabe problem. We estimate then the Hausdorff\ndimension of the singular set. The conformal geometry analog of this result is\ndue to R. Schoen and S. -T. Yau. Results of this type have their origin in work\nby Huber for Riemann surfaces. In the second part of our paper we investigate\nthe CR developing map for three dimensional CR manifolds. We establish the\ninjectivity of the developing map essentially using the same strategy as Schoen\nand Yau for the conformal case which is based on the positive mass theorem.\nHigher dimensional analogs of Huber's theorem in the conformal case for Q\ncurvature are due to Alice Chang, Jie Qing and P. Yang.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T13:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06896v1","title":"Decays $τ\\to ππην_τ$ and $τ\\to\n  πηην_τ$ in the extended Nambu-Jona-Lasinio model","summary":"In the framework of the extended Nambu-Jona-Lasinio model, the processes\n$\\tau \\to \\pi \\pi \\eta(\\eta')\\nu_\\tau$ and $\\tau \\to\n\\pi\\eta\\eta(\\eta')\\nu_\\tau$ are considered taking into account mesons in the\nground and first radially excited intermediate states. It is shown that in the\nprocesses $\\tau \\to \\pi \\pi \\eta(\\eta')\\nu_\\tau$ the vector channel is\ndominant, and in the processes $\\tau \\to \\pi\\eta\\eta(\\eta')\\nu_\\tau$ the main\ncontribution is given by the axial vector channel. The scalar meson $a_0$ plays\na dominant role in processes with two $\\eta$-mesons in the final state. The\nsignificance of the relative phase between the ground and first radially\nexcited states for these processes is shown. The obtained results for the $\\tau\n\\to \\pi \\pi \\eta\\nu_\\tau$ process are in satisfactory agreement with the recent\nexperimental data from BaBar and CMD-3, which differ from the averaged values\ngiven in the PDG tables.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T13:55:53Z"}
{"aid":"http://arxiv.org/abs/2504.06897v1","title":"MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs","summary":"This paper presents MedSegFactory, a versatile medical synthesis framework\nthat generates high-quality paired medical images and segmentation masks across\nmodalities and tasks. It aims to serve as an unlimited data repository,\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\nmedical images and the other generates corresponding segmentation masks. To\nensure precise alignment between image-mask pairs, we introduce Joint\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\ncross-conditioning between streams. This bidirectional interaction allows both\nrepresentations to guide each other's generation, enhancing consistency between\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\nimages and segmentation masks through user-defined prompts that specify the\ntarget labels, imaging modalities, anatomical regions, and pathological\nconditions, facilitating scalable and high-quality data generation. This new\nparadigm of medical image synthesis enables seamless integration into diverse\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\nexperiments show that MedSegFactory generates data of superior quality and\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\nsegmentation tasks while addressing data scarcity and regulatory constraints.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T13:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06900v1","title":"On Poincaré constants related to isoperimetric problems in convex\n  bodies","summary":"For any convex set $\\Omega \\subset {\\mathbb R} ^N$, we provide a lower bound\nfor the inverse of the Poincar\\'e constant in $W ^ {1, 1}(\\Omega)$: it refines\nan inequality in terms of the diameter due to Acosta-Duran, via the addition of\nan extra term giving account for the flatness of the domain. In dimension $N =\n2$, we are able to make the extra term completely explicit, thus providing a\nnew Bonnesen-type inequality for the Poincar\\'e constant in terms of diameter\nand inradius. Such estimate is sharp, and it is asymptotically attained when\nthe domain is the intersection of a ball with a strip bounded by parallel\nstraight lines, symmetric about the centre of the ball. As a key intermediate\nstep, we prove that the ball maximizes the Poincar\\'e constant in $W ^ {1, 1}\n(\\Omega)$, among convex bodies $\\Omega$ of given constant width.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.06916v1","title":"Semi-Orthogonal Decompositions for Rank Two Imprimitive Reflection\n  Groups","summary":"For every imprimitive complex reflection group of rank 2, we construct a\nsemi-orthogonal decomposition of the derived category of the associated global\nquotient stack which categorifies the usual decomposition of the orbifold\ncohomology indexed by conjugacy classes. This confirms a conjecture of\nPolishchuk and Van den Bergh in these cases. This conjecture was recently also\nproved by Ishii and Nimura for arbitrary complex reflection groups of rank at\nmost 3, but our approach is very different.","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-09T14:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06925v1","title":"Are Vision-Language Models Ready for Dietary Assessment? Exploring the\n  Next Frontier in AI-Powered Food Image Recognition","summary":"Automatic dietary assessment based on food images remains a challenge,\nrequiring precise food detection, segmentation, and classification.\nVision-Language Models (VLMs) offer new possibilities by integrating visual and\ntextual reasoning. In this study, we evaluate six state-of-the-art VLMs\n(ChatGPT, Gemini, Claude, Moondream, DeepSeek, and LLaVA), analyzing their\ncapabilities in food recognition at different levels. For the experimental\nframework, we introduce the FoodNExTDB, a unique food image database that\ncontains 9,263 expert-labeled images across 10 categories (e.g., \"protein\nsource\"), 62 subcategories (e.g., \"poultry\"), and 9 cooking styles (e.g.,\n\"grilled\"). In total, FoodNExTDB includes 50k nutritional labels generated by\nseven experts who manually annotated all images in the database. Also, we\npropose a novel evaluation metric, Expert-Weighted Recall (EWR), that accounts\nfor the inter-annotator variability. Results show that closed-source models\noutperform open-source ones, achieving over 90% EWR in recognizing food\nproducts in images containing a single product. Despite their potential,\ncurrent VLMs face challenges in fine-grained food recognition, particularly in\ndistinguishing subtle differences in cooking styles and visually similar food\nitems, which limits their reliability for automatic dietary assessment. The\nFoodNExTDB database is publicly available at\nhttps://github.com/AI4Food/FoodNExtDB.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T14:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.06929v1","title":"Minimal rational graphs admitting a QHD smoothing","summary":"Using the picture deformation technique of De Jong-Van Straten we show that\nno singularity whose resolution graph has 3 or 4 large nodes, i.e., nodes\nsatisfying d(v)+e(v)\\leq -2, has a QHD smoothing. This is achieved by providing\na general reduction algorithm for graphs with QHD smoothings, and enumeration.\nNew examples and families are presented, which admit a combinatorial QHD\nsmoothing, i.e. the incidence relations for a sandwich presentation can be\nsatisfied. We also give a new proof of the Bhupal-Stipsicz theorem on the\nclassification of weighted homogeneous singularities admitting QHD smoothings\nwith this method by using cusp singularities.","main_category":"math.GT","categories":"math.GT,math.AG","published":"2025-04-09T14:36:41Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06946v1","title":"Uniqueness of Lp Minkowski problem in the supercritical range","summary":"The uniqueness of the $L_p$-Minkowski problem has been a long standing\nproblem in convex geometry. In the groundbreaking paper by\nBrendle-Choi-Daskalopoulos (Acta Math, {\\bf219}, 2017), a full uniqueness\nresult was shown for the subcritical exponents $p\\in(-n-1,1]$. In the\nsupercritical range, the uniqueness problem is much more complicated, even in\nthe planar case $n=1$. One of the famous results was shown by Andrews (J. Amer.\nMath. Soc., {\\bf16}, 2003), where he established that the uniqueness holds in\nthe range $p\\in(-7,-2)$ and fails to hold for the other supercritical exponents\n$p\\in(-\\infty,-7)$. In this paper, we study the same uniqueness problem in the\nfull supercritical range $p\\in(-2n-5,-n-1)$ for all higher dimensional cases\n$n\\geq2$. We will prove that for $p\\in(-2n-5,-n-1)$, the unique strongly\nsymmetric solution is given by the unit sphere ${\\mathbb{S}}^n$. The uniqueness\nrange $(-2n-5,-n-1)$ is optimal due to our recent preprint (arXiv: 2104.07426)\njoint with J. Lu and Y.N. Liu, where we have constructed non-spherical strongly\nsymmetric solutions for all $p\\in(-\\infty,-2n-5)$. When considering general\nsolutions without symmetricity assumption, the uniqueness set $\\Gamma$ of $p$\nfor which the uniqueness holds, is shown to be both relatively open and closed\nin the full interval $(-2n-5,-n-1)$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.06948v1","title":"An improved quantum algorithm for linear autonomous differential\n  equations via Padé approximation","summary":"We propose a novel quantum algorithm for solving linear autonomous ordinary\ndifferential equations (ODEs) using the Pad\\'e approximation. For linear\nautonomous ODEs, the discretized solution can be represented by a product of\nmatrix exponentials. The proposed algorithm approximates the matrix exponential\nby the diagonal Pad\\'e approximation, which is then encoded into a large,\nblock-sparse linear system and solved via quantum linear system algorithms\n(QLSA). The detailed quantum circuit is given based on quantum oracle access to\nthe matrix, the inhomogeneous term, and the initial state. The complexity of\nthe proposed algorithm is analyzed. Compared to the method based on Taylor\napproximation, which approximates the matrix exponential using a $k$-th order\nTaylor series, the proposed algorithm improves the approximation order $k$ from\ntwo perspectives: 1) the explicit complexity dependency on $k$ is improved, and\n2) a smaller $k$ suffices for the same precision. Numerical experiments\ndemonstrate the advantages of the proposed algorithm comparing to other related\nalgorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06962v1","title":"Efficient Self-Supervised Learning for Earth Observation via Dynamic\n  Dataset Curation","summary":"Self-supervised learning (SSL) has enabled the development of vision\nfoundation models for Earth Observation (EO), demonstrating strong\ntransferability across diverse remote sensing tasks. While prior work has\nfocused on network architectures and training strategies, the role of dataset\ncuration, especially in balancing and diversifying pre-training datasets,\nremains underexplored. In EO, this challenge is amplified by the redundancy and\nheavy-tailed distributions common in satellite imagery, which can lead to\nbiased representations and inefficient training.\n  In this work, we propose a dynamic dataset pruning strategy designed to\nimprove SSL pre-training by maximizing dataset diversity and balance. Our\nmethod iteratively refines the training set without requiring a pre-existing\nfeature extractor, making it well-suited for domains where curated datasets are\nlimited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode\n(WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated by\nocean observations. We train models from scratch on the entire Sentinel-1 WV\narchive spanning 10 years. Across three downstream tasks, our results show that\ndynamic pruning improves both computational efficiency and representation\nquality, leading to stronger transferability.\n  We also release the weights of Nereus-SAR-1, the first model in the Nereus\nfamily, a series of foundation models for ocean observation and analysis using\nSAR imagery, at github.com/galeio-research/nereus-sar-models/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T15:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.06984v1","title":"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\n  Theory","summary":"The masses of data now available have opened up the prospect of discovering\nweak signals using machine-learning algorithms, with a view to predictive or\ninterpretation tasks. As this survey of recent results attempts to show,\nbringing multivariate extreme value theory and statistical learning theory\ntogether in a common, non-parametric and non-asymptotic framework makes it\npossible to design and analyze new methods for exploiting the scarce\ninformation located in distribution tails in these purposes. This article\nreviews recently proved theoretical tools for establishing guarantees for\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\nThese are mainly exponential maximal deviation inequalities tailored to\nlow-probability regions and concentration results for stochastic processes\nempirically describing the behavior of extreme observations, their dependence\nstructure in particular. Under appropriate assumptions of regular variation,\nseveral illustrative applications are then examined: classification,\nregression, anomaly detection, model selection via cross-validation. For these,\ngeneralization results are established inspired by the classical bounds in\nstatistical learning theory. In the same spirit, it is also shown how to adapt\nthe popular high-dimensional lasso technique in the context of extreme values\nfor the covariates with generalization guarantees.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T15:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.06986v1","title":"Solving \"pseudo-injective\" polynomial equations over finite dynamical\n  systems","summary":"We consider the semiring of abstract finite dynamical systems up to\nisomorphism, with the operations of alternative and synchronous execution. We\ncontinue searching for efficient algorithms for solving polynomial equations of\nthe form $P(X) = B$, with a constant side B, with the goal of decomposing\ncomplex behaviors into simpler systems. Taking inspiration from the\ncharacterization of injective polynomials P over dynamical systems, which is\nbased on a condition on the lengths of limit cycles of their coefficients, we\nintroduce a more general notion of pseudo-injectivity by relaxing this\nconstraint. We prove that the associated equations can be solved efficiently,\neven in certain cases where the input is encoded in an exponentially more\ncompact way.","main_category":"cs.DM","categories":"cs.DM,math.DS","published":"2025-04-09T15:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07008v1","title":"Latent Diffusion U-Net Representations Contain Positional Embeddings and\n  Anomalies","summary":"Diffusion models have demonstrated remarkable capabilities in synthesizing\nrealistic images, spurring interest in using their representations for various\ndownstream tasks. To better understand the robustness of these representations,\nwe analyze popular Stable Diffusion models using representational similarity\nand norms. Our findings reveal three phenomena: (1) the presence of a learned\npositional embedding in intermediate representations, (2) high-similarity\ncorner artifacts, and (3) anomalous high-norm artifacts. These findings\nunderscore the need to further investigate the properties of diffusion model\nrepresentations before considering them for downstream tasks that require\nrobust features. Project page:\nhttps://jonasloos.github.io/sd-representation-anomalies","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T16:26:26Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07016v1","title":"Bulk metric reconstruction from entanglement data via minimal surface\n  area variations","summary":"We investigate the reconstruction of asymptotically anti-de Sitter (AdS) bulk\ngeometries from boundary entanglement entropy data for ball-shaped entangling\nregions. By deriving an explicit inversion formula, we relate variations in\nentanglement entropy to deviations of the bulk metric about a fixed background.\nApplying this formula, we recover the Schwarzschild-AdS spacetime in the\nlow-temperature regime to first order. We further extend our analysis to\ninclude deformations of the bulk geometry with nontrivial dependence on\nboundary directions, and propose an iterative reconstruction scheme aimed at\nrecovering the full spacetime starting close to a conformal fixed point. We do\nthis by building on recent advances in the mathematics of inverse problems by\nintroducing the higher-order linearization method as a new tool in the context\nof holographic bulk reconstruction.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T16:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.07020v1","title":"Computably discrete represented spaces","summary":"In computable topology, a represented space is called computably discrete if\nits equality predicate is semidecidable. While any such space is classically\nisomorphic to an initial segment of the natural numbers, the\ncomputable-isomorphism types of computably discrete represented spaces exhibit\na rich structure. We show that the widely studied class of computably\nenumerable equivalence relations (ceers) corresponds precisely to the\ncomputably Quasi-Polish computably discrete spaces. We employ computably\ndiscrete spaces to exhibit several separating examples in computable topology.\nWe construct a computably discrete computably Quasi-Polish space admitting no\ndecidable properties, a computably discrete and computably Hausdorff\nprecomputably Quasi-Polish space admitting no computable injection into the\nnatural numbers, a two-point space which is computably Hausdorff but not\ncomputably discrete, and a two-point space which is computably discrete but not\ncomputably Hausdorff. We further expand an example due to Weihrauch that\nseparates computably regular spaces from computably normal spaces.","main_category":"math.LO","categories":"math.LO,cs.LO,math.GN","published":"2025-04-09T16:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07031v1","title":"Identifying Key Challenges of Hardness-Based Resampling","summary":"Performance gap across classes remains a persistent challenge in machine\nlearning, often attributed to variations in class hardness. One way to quantify\nclass hardness is through sample complexity - the minimum number of samples\nrequired to effectively learn a given class. Sample complexity theory suggests\nthat class hardness is driven by differences in the amount of data required for\ngeneralization. That is, harder classes need substantially more samples to\nachieve generalization. Therefore, hardness-based resampling is a promising\napproach to mitigate these performance disparities. While resampling has been\nstudied extensively in data-imbalanced settings, its impact on balanced\ndatasets remains unexplored.\n  This raises the fundamental question whether resampling is effective because\nit addresses data imbalance or hardness imbalance. We begin addressing this\nquestion by introducing class imbalance into balanced datasets and evaluate its\neffect on performance disparities. We oversample hard classes and undersample\neasy classes to bring hard classes closer to their sample complexity\nrequirements while maintaining a constant dataset size for fairness. We\nestimate class-level hardness using the Area Under the Margin (AUM) hardness\nestimator and leverage it to compute resampling ratios. Using these ratios, we\nperform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100\ndatasets.\n  Contrary to theoretical expectations, our results show that hardness-based\nresampling does not meaningfully affect class-wise performance disparities. To\nexplain this discrepancy, we conduct detailed analyses to identify key\nchallenges unique to hardness-based imbalance, distinguishing it from\ntraditional data-based imbalance. Our insights help explain why theoretical\nsample complexity expectations fail to translate into practical performance\ngains and we provide guidelines for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.07035v1","title":"Classification results for totally real surfaces of nearly Kähler\n  $\\mathbb{C}P^3$","summary":"Totally real surfaces in the nearly K\\\"ahler $\\mathbb{C}P^3$ are investigated\nand are completely classified under various additional assumptions, resulting\nin multiple new examples. Among others, the classification includes totally\nreal surfaces that are extrinsically homogeneous; or minimal; or totally\numbilical; or Codazzi-like (including parallel and non-parallel examples).","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T16:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.07038v1","title":"Structured extensions and multi-correlation sequences","summary":"We show that every multi-correlation sequence is the sum of a generalized\nnilsequence and a null-sequence. This proves a conjecture of N. Frantzikinakis.\nA key ingredient is the reduction of ergodic multidimensional inverse theorems\nto analogous finitary inverse theorems, offering a new approach to the\nstructure theory of multidimensional Host-Kra factors. This reduction is proven\nby combining the methods of Tao (2015) with the Furstenberg correspondence\nprinciple. We also prove the analogous multidimensional finitary inverse\ntheorem with quasi-polynomial bounds.","main_category":"math.DS","categories":"math.DS,math.NT","published":"2025-04-09T16:53:25Z"}
{"aid":"http://arxiv.org/abs/2504.07042v1","title":"Towards a Higher Roofline for Matrix-Vector Multiplication in\n  Matrix-Free HOSFEM","summary":"The high-order/spectral finite element method (HOSFEM) is a widely used\nnumerical method for solving PDEs, with its performance primarily relying on\naxhelm, a matrix-free kernel for element-local matrix-vector multiplications.\nIn axhelm, geometric factors account for over half of memory access but\nminimally contribute to computational workload. This imbalance significantly\nconstrains the performance roofline, indicating that further optimization of\ntensor contraction, the core computation in axhelm, yields only minimal\nimprovements. To overcome this bottleneck, we propose a low-cost on-the-fly\nrecalculation of geometric factors for trilinear elements, thereby unlocking\nsubstantial potential for optimizing tensor contraction. The proposed approach\nis implemented in Nekbone, a standard HOSFEM benchmark. With optimizations such\nas merging scalar factors, partial recalculation, Tensor Core acceleration, and\nconstant memory utilization, performance reaches 85%-100% of the higher\nroofline. The optimized kernels achieve speedups of 1.74x-4.10x on NVIDIA A100\nand 1.99x-3.77x on DCU K100. This leads to a 1.12x-1.40x speedup for Nekbone.","main_category":"cs.PF","categories":"cs.PF,cs.MS","published":"2025-04-09T17:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.07049v1","title":"Harnessing non-equilibrium forces to optimize work extraction","summary":"While optimal control theory offers effective strategies for minimizing\nenergetic costs in noisy microscopic systems over finite durations, a\nsignificant opportunity lies in exploiting the temporal structure of\nnon-equilibrium forces. We demonstrate this by presenting exact analytical\nforms for the optimal protocol and the corresponding work for any driving force\nand protocol duration. We also derive a general quasistatic bound on the work,\nrelying only on the coarse-grained, time-integrated characteristics of the\napplied forces. Notably, we show that the optimal protocols often automatically\nact as information engines that harness information about non-equilibrium\nforces and an initial state measurement to extract work. These findings chart\nnew directions for designing adaptive, energy-efficient strategies in noisy,\ntime-dependent environments, as illustrated through our examples of periodic\ndriving forces and active matter systems. By exploiting the temporal structure\nof non-equilibrium forces, this largely unexplored approach holds promise for\nsubstantial performance gains in microscopic devices operating at the nano- and\nmicroscale.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-09T17:06:15Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Π$-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07069v1","title":"HalluciNot: Hallucination Detection Through Context and Common Knowledge\n  Verification","summary":"This paper introduces a comprehensive system for detecting hallucinations in\nlarge language model (LLM) outputs in enterprise settings. We present a novel\ntaxonomy of LLM responses specific to hallucination in enterprise applications,\ncategorizing them into context-based, common knowledge, enterprise-specific,\nand innocuous statements. Our hallucination detection model HDM-2 validates LLM\nresponses with respect to both context and generally known facts (common\nknowledge). It provides both hallucination scores and word-level annotations,\nenabling precise identification of problematic content. To evaluate it on\ncontext-based and common-knowledge hallucinations, we introduce a new dataset\nHDMBench. Experimental results demonstrate that HDM-2 out-performs existing\napproaches across RagTruth, TruthfulQA, and HDMBench datasets. This work\naddresses the specific challenges of enterprise deployment, including\ncomputational efficiency, domain specialization, and fine-grained error\nidentification. Our evaluation dataset, model weights, and inference code are\npublicly available.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T17:39:41Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07076v1","title":"On Fundamental Theorems of Super Invariant Theory","summary":"The purpose of this paper is to prove the First and Second Fundamental\nTheorems of invariant theory for the complex special linear supergroup and\ndiscuss the superalgebra of invariants, via the super Plucker relations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T17:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.07083v1","title":"GenDoP: Auto-regressive Camera Trajectory Generation as a Director of\n  Photography","summary":"Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07417v1","title":"Secure Directional Modulation with Movable Antenna Array Aided by RIS","summary":"In this paper, to fully exploit the performance gains from moveable antennas\n(MAs) and reconfigurable intelligent surface (RIS), a RIS-aided directional\nmodulation \\textcolor{blue}{(DM)} network with movable antenna at base station\n(BS) is established Based on the principle of DM, a BS equipped with MAs\ntransmits legitimate information to a single-antenna user (Bob) while\nexploiting artificial noise (AN) to degrade signal reception at the\neavesdropper (Eve). The combination of AN and transmission beamforming vectors\nis modeled as joint beamforming vector (JBV) to achieve optimal power\nallocation. The objective is to maximize the achievable secrecy rate (SR) by\noptimizing MAs antenna position, phase shift matrix (PSM) of RIS, and JBV. The\nlimited movable range (MR) and discrete candidate positions of the MAs at the\nBS are considered, which renders the optimization problem non-convex. To\naddress these challenges, an optimization method under perfect channel state\ninformation (CSI) is firstly designed, in which the MAs antenna positions are\nobtained using compressive sensing (CS) technology, and JBV and PSM are\niteratively optimized. Then, the design method and SR performance under\nimperfect CSI is investigated. The proposed algorithms have fewer iterations\nand lower complexity. Simulation results demonstrate that MAs outperform\nfixed-position antennas in SR performance when there is an adequately large MR\navailable.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T03:14:30Z"}
{"aid":"http://arxiv.org/abs/2504.07430v1","title":"Nonlinear Optimal Guidance for Intercepting Moving Targets","summary":"This paper introduces a nonlinear optimal guidance framework for guiding a\npursuer to intercept a moving target, with an emphasis on real-time generation\nof optimal feedback control for a nonlinear optimal control problem. Initially,\nconsidering the target moves without maneuvering, we derive the necessary\noptimality conditions using Pontryagin's Maximum Principle. These conditions\nreveal that each extremal trajectory is uniquely determined by two scalar\nparameters. Analyzing the geometric property of the parameterized extremal\ntrajectories not only leads to an additional necessary condition but also\nallows to establish a sufficient condition for local optimality. This enables\nthe generation of a dataset containing at least locally optimal trajectories.\nBy studying the properties of the optimal feedback control, the size of the\ndataset is reduced significantly, allowing training a lightweight neural\nnetwork to predict the optimal guidance command in real time. Furthermore, the\nperformance of the neural network is enhanced by incorporating the target's\nacceleration, making it suitable for intercepting both uniformly moving and\nmaneuvering targets. Finally, numerical simulations validate the proposed\nnonlinear optimal guidance framework, demonstrating its better performance over\nexisting guidance laws.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T03:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.07432v1","title":"A model for cholera with infectiousness of deceased individuals and\n  vaccination","summary":"A cholera transmission model incorporating water-borne and horizontal\ntransmissions as well as infectivity of deceased individuals is formulated and\nstudied. The model also describes an imperfect and waning vaccination. Global\nstability of the disease-free equilibrium is proved when the basic reproduction\nnumber is less than one. It is also proved that there are bistable situations,\nwhere when the vaccination reproduction number is less than one, there are two\nendemic equilibria, although it is shown numerically that the region where this\noccurs is small. The computational analysis also considers the local asymptotic\nstability of endemic equilibria and the interplay between vaccination strategy,\nvaccine efficacy and waning.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-10T04:00:51Z"}
{"aid":"http://arxiv.org/abs/2504.07443v1","title":"Optoelectronic properties of self-trapped holes in orthorhombic Ga2O3\n  and its alloys","summary":"We investigated the influence of valence band holes on the optoelectronic\nproperties of orthorhombic k-Ga2O3 and its alloys with Al and In. Our hybrid\ndensity functional theory calculations show that self-trapped holes (STHs)\nlocalize on oxygen atoms within a single unit cell and exhibit \\emph{p}-orbital\ncharacteristics. The inclusion of isoelectronic dopants such as Al and In\nreduces but does not remove the absorption of visible light due to STH\nformation. The combination of a positive STH formation energy, large lattice\ndistortions, and emergent acceptor levels, coupled with the observed\nred-shifted, visible spectrum, emergent absorption peaks, implies that\nalternative doping/alloying strategies are necessary to achieve effective\np-type conductivity in orthorhombic k-Ga2O3.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.07459v1","title":"Beyond LLMs: A Linguistic Approach to Causal Graph Generation from\n  Narrative Texts","summary":"We propose a novel framework for generating causal graphs from narrative\ntexts, bridging high-level causality and detailed event-specific relationships.\nOur method first extracts concise, agent-centered vertices using large language\nmodel (LLM)-based summarization. We introduce an \"Expert Index,\" comprising\nseven linguistically informed features, integrated into a\nSituation-Task-Action-Consequence (STAC) classification model. This hybrid\nsystem, combining RoBERTa embeddings with the Expert Index, achieves superior\nprecision in causal link identification compared to pure LLM-based approaches.\nFinally, a structured five-iteration prompting process refines and constructs\nconnected causal graphs. Experiments on 100 narrative chapters and short\nstories demonstrate that our approach consistently outperforms GPT-4o and\nClaude 3.5 in causal graph quality, while maintaining readability. The\nopen-source tool provides an interpretable, efficient solution for capturing\nnuanced causal chains in narratives.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07466v1","title":"Personalized and Demand-Based Education Concept: Practical Tools for\n  Control Engineers","summary":"This paper presents a personalized lecture concept using educational blocks\nand its demonstrative application in a new university lecture. Higher education\nfaces daily challenges: deep and specialized knowledge is available from\neverywhere and accessible to almost everyone. University lecturers of\nspecialized master courses confront the problem that their lectures are either\ntoo boring or too complex for the attending students. Additionally, curricula\nare changing more rapidly than they have in the past 10-30 years. The German\neducation system comprises different educational forms, with universities\nproviding less practical content. Consequently, many university students do not\nobtain the practical skills they should ideally gain through university\nlectures. Therefore, in this work, a new lecture concept is proposed based on\nthe extension of the just-in-time teaching paradigm: Personalized and\nDemand-Based Education. This concept includes: 1) an initial assessment of\nstudents' backgrounds, 2) selecting the appropriate educational blocks, and 3)\ncollecting ongoing feedback during the semester. The feedback was gathered via\nPingo, ensuring anonymity for the students. Our concept was exemplarily tested\nin the new lecture \"Practical Tools for Control Engineers\" at the Karlsruhe\nInstitute of Technology. The initial results indicate that our proposed concept\ncould be beneficial in addressing the current challenges in higher education.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,K.3.1","published":"2025-04-10T05:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.07468v1","title":"Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from\n  Imbalanced Chest X-Ray Datasets","summary":"This paper proposes a novel pooling-based VGG-Lite model in order to mitigate\nclass imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia\ndetection from CXR images by deep learning model has emerged as a prominent and\ndynamic area of research, since the inception of the new Covid-19 variant in\n2020. However, the standard Convolutional Neural Network (CNN) models encounter\nchallenges associated with class imbalance, a prevalent issue found in many\nmedical datasets. The innovations introduced in the proposed model architecture\ninclude: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base\nmodel, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this\nbase model, we leverage an ``Edge Enhanced Module (EEM)\" through a parallel\nbranch, consisting of a ``negative image layer\", and a novel custom pooling\nlayer ``2Max-Min Pooling\". This 2Max-Min Pooling layer is entirely novel in\nthis investigation, providing more attention to edge components within\npneumonia CXR images. Thus, it works as an efficient spatial attention module\n(SAM). We have implemented the proposed framework on two separate CXR datasets.\nThe first dataset is obtained from a readily available source on the internet,\nand the second dataset is a more challenging CXR dataset, assembled by our\nresearch team from three different sources. Experimental results reveal that\nour proposed framework has outperformed pre-trained CNN models, and three\nrecent trend existing models ``Vision Transformer\", ``Pooling-based Vision\nTransformer (PiT)'' and ``PneuNet\", by substantial margins on both datasets.\nThe proposed framework VGG-Lite with EEM, has achieved a macro average of 95%\naccuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia\nImbalance CXR dataset\", without employing any pre-processing technique.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T05:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.07471v1","title":"Traversal Learning Coordination For Lossless And Efficient Distributed\n  Learning","summary":"In this paper, we introduce Traversal Learning (TL), a novel approach\ndesigned to address the problem of decreased quality encountered in popular\ndistributed learning (DL) paradigms such as Federated Learning (FL), Split\nLearning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an\naccuracy drop during aggregation due to its averaging function, while SL and\nSFL face increased loss due to the independent gradient updates on each split\nnetwork. TL adopts a unique strategy where the model traverses the nodes during\nforward propagation (FP) and performs backward propagation (BP) on the\norchestrator, effectively implementing centralized learning (CL) principles\nwithin a distributed environment. The orchestrator is tasked with generating\nvirtual batches and planning the sequential node visits of the model during FP,\naligning them with the ordered index of the data within these batches. We\nconducted experiments on six datasets representing diverse characteristics\nacross various domains. Our evaluation demonstrates that TL is on par with\nclassic CL approaches in terms of accurate inference, thereby offering a viable\nand robust solution for DL tasks. TL outperformed other DL methods and improved\naccuracy by 7.85% for independent and identically distributed (IID) datasets,\nmacro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text\nclassification, and AUC by 3.88% and 4.54% for medical and financial datasets,\nrespectively. By effectively preserving data privacy while maintaining\nperformance, TL represents a significant advancement in DL methodologies.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-10T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.07488v1","title":"Mass-subcritical Half-Wave Equation with mixed nonlinearities: existence\n  and non-existence of ground states","summary":"We consider the problem of existence of constrained minimizers for the\nfocusing mass-subcritical Half-Wave equation with a defocusing mass-subcritical\nperturbation. We show the existence of a critical mass such that minimizers do\nexist for any mass larger than or equal to the critical one, and do not exist\nbelow it. At the dynamical level, in the one dimensional case, we show that the\nground states are orbitally stable.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-10T06:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.07491v1","title":"Kimi-VL Technical Report","summary":"We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE)\nvision-language model (VLM) that offers advanced multimodal reasoning,\nlong-context understanding, and strong agent capabilities - all while\nactivating only 2.8B parameters in its language decoder (Kimi-VL-A3B). Kimi-VL\ndemonstrates strong performance across challenging domains: as a\ngeneral-purpose VLM, Kimi-VL excels in multi-turn agent tasks (e.g., OSWorld),\nmatching flagship models. Furthermore, it exhibits remarkable capabilities\nacross diverse challenging vision language tasks, including college-level image\nand video comprehension, OCR, mathematical reasoning, and multi-image\nunderstanding. In comparative evaluations, it effectively competes with\ncutting-edge efficient VLMs such as GPT-4o-mini, Qwen2.5-VL-7B, and\nGemma-3-12B-IT, while surpassing GPT-4o in several key domains. Kimi-VL also\nadvances in processing long contexts and perceiving clearly. With a 128K\nextended context window, Kimi-VL can process diverse long inputs, achieving\nimpressive scores of 64.5 on LongVideoBench and 35.1 on MMLongBench-Doc. Its\nnative-resolution vision encoder, MoonViT, further allows it to see and\nunderstand ultra-high-resolution visual inputs, achieving 83.2 on InfoVQA and\n34.5 on ScreenSpot-Pro, while maintaining lower computational cost for common\ntasks. Building upon Kimi-VL, we introduce an advanced long-thinking variant:\nKimi-VL-Thinking. Developed through long chain-of-thought (CoT) supervised\nfine-tuning (SFT) and reinforcement learning (RL), this model exhibits strong\nlong-horizon reasoning capabilities. It achieves scores of 61.7 on MMMU, 36.8\non MathVision, and 71.3 on MathVista while maintaining the compact 2.8B\nactivated LLM parameters, setting a new standard for efficient multimodal\nthinking models. Code and models are publicly accessible at\nhttps://github.com/MoonshotAI/Kimi-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T06:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.07497v1","title":"Quantum Determinant Estimation","summary":"A quantum algorithm for computing the determinant of a unitary matrix $U\\in\nU(N)$ is given. The algorithm requires no preparation of eigenstates of $U$ and\nestimates the phase of the determinant to $t$ binary digits accuracy with\n$\\mathcal{O}(N\\log^2 N+t^2)$ operations and $tN$ controlled applications of\n$U^{2^m}$ with $m=0,\\ldots,t-1$. For an orthogonal matrix $O\\in O(N)$ the\nalgorithm can determine with certainty the sign of the determinant using\n$\\mathcal{O}(N\\log^2 N)$ operations and $N$ controlled applications of $O$. An\nextension of the algorithm to contractions is discussed.","main_category":"quant-ph","categories":"quant-ph,hep-lat","published":"2025-04-10T06:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07514v1","title":"Probing fluctuating protons using forward neutrons in soft and hard\n  inelastic proton-nucleus scattering","summary":"We present a model for the distribution of the number of forward neutrons\nemitted in soft (minimum bias) and hard inelastic proton-nucleus ($pA$)\nscattering at the LHC. It is based on the Gribov-Glauber model for the\ndistribution over the number of inelastic collisions (wounded nucleons)\ncombined with a parametrization of cross section (color) fluctuations in the\nprojectile proton, which depend on the parton momentum fraction $x_p$, and the\nassumption of independent neutron emissions. It allows us to qualitatively\nexplain the ATLAS data on the ZDC energy spectra of forward neutrons emitted in\ndijet production in inelastic $pA$ scattering at $\\sqrt{s_{NN}}=8.16$ TeV.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex","published":"2025-04-10T07:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07521v1","title":"Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal\n  Large Language Models","summary":"Most existing emotion analysis emphasizes which emotion arises (e.g., happy,\nsad, angry) but neglects the deeper why. We propose Emotion Interpretation\n(EI), focusing on causal factors-whether explicit (e.g., observable objects,\ninterpersonal interactions) or implicit (e.g., cultural context, off-screen\nevents)-that drive emotional responses. Unlike traditional emotion recognition,\nEI tasks require reasoning about triggers instead of mere labeling. To\nfacilitate EI research, we present EIBench, a large-scale benchmark\nencompassing 1,615 basic EI samples and 50 complex EI samples featuring\nmultifaceted emotions. Each instance demands rationale-based explanations\nrather than straightforward categorization. We further propose a Coarse-to-Fine\nSelf-Ask (CFSA) annotation pipeline, which guides Vision-Language Models\n(VLLMs) through iterative question-answer rounds to yield high-quality labels\nat scale. Extensive evaluations on open-source and proprietary large language\nmodels under four experimental settings reveal consistent performance\ngaps-especially for more intricate scenarios-underscoring EI's potential to\nenrich empathetic, context-aware AI applications. Our benchmark and methods are\npublicly available at: https://github.com/Lum1104/EIBench, offering a\nfoundation for advanced multimodal causal analysis and next-generation\naffective computing.","main_category":"cs.AI","categories":"cs.AI,cs.MM","published":"2025-04-10T07:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.07522v1","title":"Adversarial Subspace Generation for Outlier Detection in\n  High-Dimensional Data","summary":"Outlier detection in high-dimensional tabular data is challenging since data\nis often distributed across multiple lower-dimensional subspaces -- a\nphenomenon known as the Multiple Views effect (MV). This effect led to a large\nbody of research focused on mining such subspaces, known as subspace selection.\nHowever, as the precise nature of the MV effect was not well understood,\ntraditional methods had to rely on heuristic-driven search schemes that\nstruggle to accurately capture the true structure of the data. Properly\nidentifying these subspaces is critical for unsupervised tasks such as outlier\ndetection or clustering, where misrepresenting the underlying data structure\ncan hinder the performance. We introduce Myopic Subspace Theory (MST), a new\ntheoretical framework that mathematically formulates the Multiple Views effect\nand writes subspace selection as a stochastic optimization problem. Based on\nMST, we introduce V-GAN, a generative method trained to solve such an\noptimization problem. This approach avoids any exhaustive search over the\nfeature space while ensuring that the intrinsic data structure is preserved.\nExperiments on 42 real-world datasets show that using V-GAN subspaces to build\nensemble methods leads to a significant increase in one-class classification\nperformance -- compared to existing subspace selection, feature selection, and\nembedding methods. Further experiments on synthetic data show that V-GAN\nidentifies subspaces more accurately while scaling better than other relevant\nsubspace selection methods. These results confirm the theoretical guarantees of\nour approach and also highlight its practical viability in high-dimensional\nsettings.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.ST,stat.TH","published":"2025-04-10T07:40:02Z"}
{"aid":"http://arxiv.org/abs/2504.07525v1","title":"Non triviality of the percolation threshold and Gumbel fluctuations for\n  Branching Interlacements","summary":"We consider the model of Branching Interlacements, introduced by Zhu, which\nis a natural analogue of Sznitman's Random Interlacements model, where the\nrandom walk trajectories are replaced by ranges of some suitable tree-indexed\nrandom walks. We first prove a basic decorrelation inequality for events\ndepending on the state of the field on distinct boxes. We then show that in all\nrelevant dimensions, the vacant set undergoes a nontrivial phase transition\nregarding the existence of an infinite connected component. Finally we obtain\nthe Gumbel fluctuations for the cover level of finite sets, which is analogous\nto Belius' result in the setting of Random Interlacements.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T07:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07527v1","title":"Supervised Optimism Correction: Be Confident When LLMs Are Sure","summary":"In this work, we establish a novel theoretical connection between supervised\nfine-tuning and offline reinforcement learning under the token-level Markov\ndecision process, revealing that large language models indeed learn an implicit\n$Q$-function for inference. Through this theoretical lens, we demonstrate that\nthe widely used beam search method suffers from unacceptable over-optimism,\nwhere inference errors are inevitably amplified due to inflated $Q$-value\nestimations of suboptimal steps. To address this limitation, we propose\nSupervised Optimism Correction(SOC), which introduces a simple yet effective\nauxiliary loss for token-level $Q$-value estimations during supervised\nfine-tuning. Specifically, the auxiliary loss employs implicit value\nregularization to boost model confidence in expert-demonstrated responses,\nthereby suppressing over-optimism toward insufficiently supervised responses.\nExtensive experiments on mathematical reasoning benchmarks, including GSM8K,\nMATH, and GAOKAO, showcase the superiority of the proposed SOC with beam search\nacross a series of open-source models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T07:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.07531v1","title":"A taxonomy of epistemic injustice in the context of AI and the case for\n  generative hermeneutical erasure","summary":"Whether related to machine learning models' epistemic opacity, algorithmic\nclassification systems' discriminatory automation of testimonial prejudice, the\ndistortion of human beliefs via the 'hallucinations' of generative AI, the\ninclusion of the global South in global AI governance, the execution of\nbureaucratic violence via algorithmic systems, or located in the interaction\nwith conversational artificial agents epistemic injustice related to AI is a\ngrowing concern. Based on a proposed general taxonomy of epistemic injustice,\nthis paper first sketches a taxonomy of the types of epistemic injustice in the\ncontext of AI, relying on the work of scholars from the fields of philosophy of\ntechnology, political philosophy and social epistemology. Secondly, an\nadditional perspective on epistemic injustice in the context of AI: generative\nhermeneutical erasure. I argue that this injustice that can come about through\nthe application of Large Language Models (LLMs) and contend that generative AI,\nwhen being deployed outside of its Western space of conception, can have\neffects of conceptual erasure, particularly in the epistemic domain, followed\nby forms of conceptual disruption caused by a mismatch between AI system and\nthe interlocutor in terms of conceptual frameworks. AI systems' 'view from\nnowhere' epistemically inferiorizes non-Western epistemologies and thereby\ncontributes to the erosion of their epistemic particulars, gradually\ncontributing to hermeneutical erasure. This work's relevance lies in proposal\nof a taxonomy that allows epistemic injustices to be mapped in the AI domain\nand the proposal of a novel form of AI-related epistemic injustice.","main_category":"cs.AI","categories":"cs.AI,cs.CY,K.4","published":"2025-04-10T07:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07554v1","title":"Efficient Swept Volume-Based Trajectory Generation for Arbitrary-Shaped\n  Ground Robot Navigation","summary":"Navigating an arbitrary-shaped ground robot safely in cluttered environments\nremains a challenging problem. The existing trajectory planners that account\nfor the robot's physical geometry severely suffer from the intractable runtime.\nTo achieve both computational efficiency and Continuous Collision Avoidance\n(CCA) of arbitrary-shaped ground robot planning, we proposed a novel\ncoarse-to-fine navigation framework that significantly accelerates planning. In\nthe first stage, a sampling-based method selectively generates distinct\ntopological paths that guarantee a minimum inflated margin. In the second\nstage, a geometry-aware front-end strategy is designed to discretize these\ntopologies into full-state robot motion sequences while concurrently\npartitioning the paths into SE(2) sub-problems and simpler R2 sub-problems for\nback-end optimization. In the final stage, an SVSDF-based optimizer generates\ntrajectories tailored to these sub-problems and seamlessly splices them into a\ncontinuous final motion plan. Extensive benchmark comparisons show that the\nproposed method is one to several orders of magnitude faster than the\ncutting-edge methods in runtime while maintaining a high planning success rate\nand ensuring CCA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T08:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.07559v1","title":"Axion dark matter search from terrestrial magnetic fields at extremely\n  low frequencies","summary":"The natural environment of the Earth can act as a sensitive detector for dark\nmatter in ultralight axions. When axions with masses between\n$1\\times10^{-15}\\,{\\rm eV}$ and $1\\times10^{-13}\\,{\\rm eV}$ pass through the\nEarth, they interact with the global geomagnetic field, generating\nelectromagnetic (EM) waves in the extremely low-frequency range\n($0.3$--$30\\,{\\rm Hz}$) through axion-photon coupling. This paper is one of a\nseries of companion papers for~\\cite{Taruya:2025zql}, focusing on the data\nanalysis method and search results for an axion signal. Utilizing the\ntheoretical predictions of axion-induced EM spectra from a companion study, we\nanalyzed long-term observational data of terrestrial magnetic fields in this\nfrequency band to search for axion-induced signals. Our analysis identified 65\npersistent signal candidates with a signal-to-noise ratio (SNR) greater than 3.\nAside from these candidates, we placed a new upper bound on the axion-photon\ncoupling parameter, significantly refining the previous constraint from CAST by\nat most two orders of magnitude down to $g_{a\\gamma} \\lesssim 4\\times10^{-13}\n\\,{\\rm GeV}^{-1}$ for the axion mass around $3 \\times 10^{-14}\\,{\\rm eV}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T08:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.07562v1","title":"ReXCL: A Tool for Requirement Document Extraction and Classification","summary":"This paper presents the ReXCL tool, which automates the extraction and\nclassification processes in requirement engineering, enhancing the software\ndevelopment lifecycle. The tool features two main modules: Extraction, which\nprocesses raw requirement documents into a predefined schema using heuristics\nand predictive modeling, and Classification, which assigns class labels to\nrequirements using adaptive fine-tuning of encoder-based models. The final\noutput can be exported to external requirement engineering tools. Performance\nevaluations indicate that ReXCL significantly improves efficiency and accuracy\nin managing requirements, marking a novel approach to automating the\nschematization of semi-structured requirement documents.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-10T08:46:54Z"}
{"aid":"http://arxiv.org/abs/2504.07572v1","title":"Period-Doubling Cascades Invariants: Braided Routes To Chaos","summary":"By a classical result of Kathleen Alligood and James Yorke we know that as we\nisotopically deform a map $f:ABCD\\to\\mathbb{R}^2$ to a Smale horseshoe map we\nshould often expect the dynamical complexity to increase via a period--doubling\nroute to chaos. Inspired by this fact and by how braids force the existence of\ncomplex dynamics, in this paper we introduce three topological invariants that\ndescribe the topology of period--doubling routes to chaos. As an application,\nwe use our methods to ascribe symbolic dynamics to perturbations of the\nShilnikov homoclinic scenario and to study the dynamics of the Henon map.","main_category":"math.DS","categories":"math.DS,math.CV,math.GT","published":"2025-04-10T09:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.07573v1","title":"Additive diameters of group representations","summary":"We explore the concept of additive diameters in the context of group\nrepresentations, unifying various noncommutative Waring-type problems. Given a\nfinite-dimensional representation $\\rho \\colon G \\to \\mathrm{GL}(V)$ and a\nsubspace $U \\leq V$ that generates $V$ as a $G$-module, we define the\n$G$-additive diameter of $V$ with respect to $U$ as the minimal number of\ntranslates of $U$ under the representation $\\rho$ needed to cover $V$. We\ndemonstrate that every irreducible representation of\n$\\mathrm{SL}_2(\\mathbf{C})$ exhibits optimal additive diameters and establish\nsharp bounds for the conjugation representation of $\\mathrm{SL}_n(\\mathbf{C})$\non its Lie algebra $\\mathfrak{sl}_n(\\mathbf{C})$. Additionally, we investigate\nanalogous notions for additive diameters in Lie representations. We provide\napplications to additive diameters with respect to images of equivariant\nalgebraic morphisms, linking them to the corresponding $G$-additive diameters\nof images of their differentials.","main_category":"math.RT","categories":"math.RT,math.AG,math.GR,math.RA","published":"2025-04-10T09:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.07576v1","title":"An exceptional story: Symmetries and dualities between Maximal\n  supergravity and General relativity","summary":"We present the historical path from General relativity to the construction of\nMaximal $\\mathcal{N}_4 = 8$ Supergravity with a detour in D=10 and 11\ndimensions. The supergravities obtained by toric dimensional reduction and/or\nby reducing the number of supersymmetry generators have large exceptional\nduality symmetry groups and exhibit a remarkably uniform pattern across all\nvalues of $\\mathcal{N}_D$ and D. In particular (bosonic) General relativity\nfits in as the simplest case and anchors us to the Real world. Dimensional\nreduction to 2 dimensions brings us to affine Kac-Moody groups and their\nsemi-direct products with a real form of the Witt algebra: there is \"integrable\nMagics\". Integrability of 4D Gravity and of its reduction to 2D is considered\nwith their \"Twisted self-duality\". Hyperbolic Kac-Moody symmetries appear after\nreduction to 1D: this leads to \"chaotic Magics\". We then discover\n\"Borcherds\"-Kac-Moody symmetries that allow us to rewrite in any dimension all\nmatter equations of motion as Twisted self-duality: \"Algebraic geometric\nMagics\". Finally a \"BF\" metasymmetry $\\Sigma$ exchanges negative quartets of\nFermionic dimensions with Bosonic ones inside two Magic triangles. A third\nubiquitous triangle of symmetries from Invariant theory resists unification\ndespite its strong resemblance to the others. The prospective remarks include\nseven Challenges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T09:20:24Z"}
{"aid":"http://arxiv.org/abs/2504.07581v1","title":"Lipschitz continuity and composition operators in pluriharmonic Bloch\n  spaces","summary":"We study the Lipschitz continuity of pluriharmonic Bloch mappings in the unit\nball $\\mathbb{B}^n$ with respect to the Bergman metric. We apply this to obtain\na sufficient condition such that the composition operator on the pluriharmonic\nBloch space is bounded below. As a partial converse, we also give a necessary\ncondition for the boundedness (from below) of the composition operator on the\nBloch space of holomorphic mappings in $\\mathbb{B}^n$.","main_category":"math.CV","categories":"math.CV","published":"2025-04-10T09:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.07586v1","title":"A perspective on totally geodesic submanifolds of the symmetric space\n  $G_2/SO(4)$","summary":"We provide an independent proof of the classification of the maximal totally\ngeodesic submanifolds of the symmetric spaces $G_2$ and $G_2/SO(4)$, jointly\nwith very natural descriptions of all of these submanifolds. The description of\nthe totally geodesic submanifolds of $G_2$ is in terms of (1) principal\nsubalgebras of $\\mathfrak{g}_2$; (2) stabilizers of nonzero points of\n$\\mathbb{R}^7$; (3) stabilizers of associative subalgebras; (4) the set of\norder two elements in $G_2$ (and its translations). The space $G_2/SO(4)$ is\nidentified with the set of associative subalgebras of $\\mathbb{R}^7$ and its\nmaximal totally geodesic submanifolds can be described as the associative\nsubalgebras adapted to a fixed principal subalgebra, the associative\nsubalgebras orthogonal to a fixed nonzero vector, the associative subalgebras\ncontaining a fixed nonzero vector, and the associative subalgebras intersecting\nboth a fixed associative subalgebra and its orthogonal. A second description is\nincluded in terms of Grassmannians, the advantage of which is that the\nassociated Lie triple systems are easily described in matrix form.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T09:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.07592v1","title":"Hardness of 4-Colourings G-Colourable Graphs","summary":"We study the complexity of a class of promise graph homomorphism problems.\nFor a fixed graph H, the H-colouring problem is to decide whether a given graph\nhas a homomorphism to H. By a result of Hell and Ne\\v{s}et\\v{r}il, this problem\nis NP-hard for any non-bipartite loop-less graph H. Brakensiek and Guruswami\n[SODA 2018] conjectured the hardness extends to promise graph homomorphism\nproblems as follows: fix a pair of non-bipartite loop-less graphs G, H such\nthat there is a homomorphism from G to H, it is NP-hard to distinguish between\ngraphs that are G-colourable and those that are not H-colourable. We confirm\nthis conjecture in the cases when both G and H are 4-colourable. This is a\ncommon generalisation of previous results of Khanna, Linial, and Safra [Comb.\n20(3): 393-415 (2000)] and of Krokhin and Opr\\v{s}al [FOCS 2019]. The result is\nobtained by combining the algebraic approach to promise constraint satisfaction\nwith methods of topological combinatorics and equivariant obstruction theory.","main_category":"cs.CC","categories":"cs.CC,math.AT,math.CO","published":"2025-04-10T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07602v1","title":"Parameter extraction of the stochastic gravitational wave background\n  with peak-like templates in millihertz","summary":"We investigate a framework for extracting parameters of stochastic\ngravitational wave background (SGWB) with peak-like templates in the millihertz\nfrequency band, and analyzing transient contamination effects on parameter\nreconstruction. We present the spectrum and spectrogram under different\nconditions and provide the results of parameter reconstruction. Using templates\nfrom the early universe, we demonstrate that the peak-like templates outperform\nthe broken power law (BPL) templates in power-law exponents recovery and peak\nfrequency localization. The reconstruction results obtained using data from\nFast Fourier Transform (FFT) are better than those obtained using data from\nShort-Time Fourier Transform (STFT) which is based on the spectrogram. For the\nsingle-peak template, the estimation accuracy of the exponent and peak\nfrequency surpasses that of the BPL template by an order of magnitude, but\ndemonstrates less precision in amplitude estimation compared to BPL. Regarding\nthe double-peak template, parameter estimation results derived from the FFT\nmethodology consistently outperform those obtained using STFT. Nevertheless,\ntransient signals exhibit a detrimental impact on parameter estimation\nprecision, causing errors to increase by an order of magnitude, particularly in\nmulti-peak scenarios. This framework provides an example for using templates to\nanalyze data from space-based gravitational wave detectors.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-10T09:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.07609v1","title":"Towards a Computational Quantum Logic: An Overview of an Ongoing\n  Research Program","summary":"This invited paper presents an overview of an ongoing research program aimed\nat extending the Curry-Howard-Lambek correspondence to quantum computation. We\nexplore two key frameworks that provide both logical and computational\nfoundations for quantum programming languages. The first framework, the\nLambda-$S$ calculus, extends the lambda calculus by incorporating quantum\nsuperposition, enforcing linearity, and ensuring unitarity, to model quantum\ncontrol. Its categorical semantics establishes a structured connection between\nclassical and quantum computation through an adjunction between Cartesian\nclosed categiries and additive symmetric monoidal closed categories. The second\nframework, the $\\mathcal L^{\\mathbb C}$ calculus, introduces a proof language\nfor intuitionistic linear logic augmented with sum and scalar operations. This\nenables the formal encoding of quantum superpositions and measurements, leading\nto a computational model grounded in categorical structures with biproducts.\nThese approaches suggest a fundamental duality between quantum computation and\nlinear logic, highlighting structural correspondences between logical proofs\nand quantum programs. We discuss ongoing developments, including extensions to\npolymorphism, categorical and realizability models, as well as the integration\nof the modality !, which further solidify the connection between logic and\nquantum programming languages.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-10T10:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07626v1","title":"Upper bounds of focusing light through multimode fibers","summary":"Wavefront shaping enables precise control of light propagation through\nmultimode fibers, facilitating diffraction-limited focusing for applications\nsuch as high-resolution single-fiber imaging and high-power fiber amplifiers.\nWhile the theoretical intensity enhancement at the focal point is dictated by\nthe number of input degrees of freedom, practical constraints such as\nphase-only modulation and experimental noise impose significant limitations.\nDespite its importance, the upper bounds of enhancement under these constraints\nremain largely unexplored. In this work, we establish a theoretical framework\nto predict the fundamental limits of intensity enhancement with phase-only\nmodulation in the presence of noise-induced phase errors, and we experimentally\ndemonstrate wavefront shaping that approaches these limits. Our experimental\nresults confirm an enhancement factor of 5,000 in a large-core multimode fiber,\napproaching the theoretical upper bound, enabled by noise-tolerant wavefront\nshaping. These findings provide key insights into the limits of phase-only\ncontrol in multimode fibers, with profound implications for single-fiber\nimaging, optical communication, high-power broad-area fiber amplification, and\nbeyond.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-10T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.07635v1","title":"Generative Artificial Intelligence for Internet of Things Computing: A\n  Systematic Survey","summary":"The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T10:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.07644v1","title":"Modularity of moments of reciprocal sums for partitions into distinct\n  parts","summary":"In this paper, we determine modularity properties of the generating function\nof $s_k(n)$ which sums $k$-th power of reciprocals of parts throughout all of\nthe partitions of $n$ into distinct parts. In particular, we show that the\ngenerating function for $s_k (n)$ is related to Maass Eisenstein series and\nsesquiharmonic Maass forms.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T10:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.07652v1","title":"Categorical Unsupervised Variational Acoustic Clustering","summary":"We propose a categorical approach for unsupervised variational acoustic\nclustering of audio data in the time-frequency domain. The consideration of a\ncategorical distribution enforces sharper clustering even when data points\nstrongly overlap in time and frequency, which is the case for most datasets of\nurban acoustic scenes. To this end, we use a Gumbel-Softmax distribution as a\nsoft approximation to the categorical distribution, allowing for training via\nbackpropagation. In this settings, the softmax temperature serves as the main\nmechanism to tune clustering performance. The results show that the proposed\nmodel can obtain impressive clustering performance for all considered datasets,\neven when data points strongly overlap in time and frequency.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-10T11:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.07654v1","title":"ms-Mamba: Multi-scale Mamba for Time-Series Forecasting","summary":"The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T11:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.07661v1","title":"Unveiling the Impact of Multimodal Features on Chinese Spelling\n  Correction: From Analysis to Design","summary":"The Chinese Spelling Correction (CSC) task focuses on detecting and\ncorrecting spelling errors in sentences. Current research primarily explores\ntwo approaches: traditional multimodal pre-trained models and large language\nmodels (LLMs). However, LLMs face limitations in CSC, particularly\nover-correction, making them suboptimal for this task. While existing studies\nhave investigated the use of phonetic and graphemic information in multimodal\nCSC models, effectively leveraging these features to enhance correction\nperformance remains a challenge. To address this, we propose the Multimodal\nAnalysis for Character Usage (\\textbf{MACU}) experiment, identifying potential\nimprovements for multimodal correctison. Based on empirical findings, we\nintroduce \\textbf{NamBert}, a novel multimodal model for Chinese spelling\ncorrection. Experiments on benchmark datasets demonstrate NamBert's superiority\nover SOTA methods. We also conduct a comprehensive comparison between NamBert\nand LLMs, systematically evaluating their strengths and limitations in CSC. Our\ncode and model are available at https://github.com/iioSnail/NamBert.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T11:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.07667v1","title":"S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion","summary":"The generalization of learning-based high dynamic range (HDR) fusion is often\nlimited by the availability of training data, as collecting large-scale HDR\nimages from dynamic scenes is both costly and technically challenging. To\naddress these challenges, we propose S2R-HDR, the first large-scale\nhigh-quality synthetic dataset for HDR fusion, with 24,000 HDR samples. Using\nUnreal Engine 5, we design a diverse set of realistic HDR scenes that encompass\nvarious dynamic elements, motion types, high dynamic range scenes, and\nlighting. Additionally, we develop an efficient rendering pipeline to generate\nrealistic HDR images. To further mitigate the domain gap between synthetic and\nreal-world data, we introduce S2R-Adapter, a domain adaptation designed to\nbridge this gap and enhance the generalization ability of models. Experimental\nresults on real-world datasets demonstrate that our approach achieves\nstate-of-the-art HDR reconstruction performance. Dataset and code will be\navailable at https://openimaginglab.github.io/S2R-HDR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T11:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.07672v1","title":"Point processes of the Poisson-Skellam family","summary":"We study a general non-homogeneous Skellam-type process with jumps of\narbitrary fixed size. We express this process in terms of a linear combination\nof Poisson processes and study several properties, including the summation of\nindependent processes of the same family, some possible decompositions (which\npresent particularly interesting characteristics) and the limit behaviors. In\nthe case of homogeneous rate functions, a compound Poisson representation and a\ndiscrete approximation are presented. Then, we study the fractional integral of\nthe process as well as the iterated integral of the running average. Finally,\nwe consider some time-changed versions related to L\\'{e}vy subordinators,\nconnected to the Bernstein functions, and to the inverses of stable\nsubordinators.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T11:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.07707v1","title":"Managing Security Issues in Software Containers: From Practitioners\n  Perspective","summary":"Software development industries are increasingly adopting containers to\nenhance the scalability and flexibility of software applications. Security in\ncontainerized projects is a critical challenge that can lead to data breaches\nand performance degradation, thereby directly affecting the reliability and\noperations of the container services. Despite the ongoing effort to manage the\nsecurity issues in containerized projects in software engineering (SE)\nresearch, more focused investigations are needed to explore the human\nperspective of security management and the technical approaches to security\nmanagement in containerized projects. This research aims to explore security\nmanagement in containerized projects by exploring how SE practitioners perceive\nthe security issues in containerized software projects and their approach to\nmanaging such issues. A clear understanding of security management in\ncontainerized projects will enable industries to develop robust security\nstrategies that enhance software reliability and trust. To achieve this, we\nconducted two separate semi-structured interview studies to examine how\npractitioners approach security management. The first study focused on\npractitioners perceptions of security challenges in containerized environments,\nwhere we interviewed 15 participants between December 2022 and October 2023.\nThe second study explored how to enhance container security, with 20\nparticipants interviewed between October 2024 and December 2024. Analyzing the\ndata from both studies reveals how SE practitioners address the various\nsecurity challenges in containerized projects. Our analysis also identified the\ntechnical and non-technical enablers that can be utilized to enhance security.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T12:49:00Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07714v1","title":"Quasi-Periodic Pulsations in Ionospheric TEC Synchronized with Solar\n  Flare EUV Emission","summary":"The extreme ultraviolet (EUV) and X-ray radiation emitted during solar flares\nhas been shown to significantly increase the electron density of the Earth's\nionosphere. During flares, quasi-periodic pulsations (QPPs) in X-ray flux\noriginating in the corona have previously been linked to subsequent pulsations\nin the Earth's ionospheric D-region. Similar pulsations have been detected in\nchromospheric EUV emission, although their impact on the Earth's ionosphere has\nnot previously been investigated. Here, for the first time, synchronous\npulsations were detected in solar EUV emission and ionospheric Total Electron\nContent (TEC) measurements. Using wavelet and periodogram analysis, we detect\nQPPs with approximately 85 second periods in chromospheric EUV emission lines\n(He II 304 \\AA{}, C III 977 \\AA{} and H I 972 \\AA{}) from the Solar Dynamics\nObservatory Extreme Ultraviolet Variability Experiment (SDO/EVE) during the\nimpulsive phase of an X5.4 flare on March 7, 2012. These lines contribute to\nionization in the ionospheric E- and F-regions, resulting in subsequent\nvariations of electron density with the same periodicity, which was detected in\nTEC measurements. This work demonstrates that the Earth's ionosphere is\nresponsive to fine-scale fluctuations in EUV emission during flares, with a\ntime delay of approximately 30 seconds found. These findings may have\napplications in atmospheric modelling and solar-terrestrial studies, including\nthe calculation of ionospheric recombination rates.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-10T13:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.07715v1","title":"Finite-temperature real-time properties of magnetic polarons in\n  two-dimensional quantum antiferromagnets","summary":"Due to significant progress in quantum gas microscopy in recent years, there\nis a rapidly growing interest in real-space properties of single mobile dopands\ncreated in correlated antiferromagnetic (AFM) Mott insulators. However, a\ndetailed numerical description remains challenging, even for simple toy models.\nAs a consequence, previous numerical simulations for large systems were largely\nlimited to $T=0$. To provide guidance for cold-atom experiments, numerical\ncalculations at finite temperature are required. Here, we numerically study the\nreal-time properties of a single mobile hole in the 2D $t$-$J$ model at finite\ntemperature and draw a comparison to features observed at $T=0$. We find that a\nthree-stage process of hole motion, which was reported at $T=0$, is valid even\nat finite temperature. However, already at low temperatures, the average hole\nvelocity at long times is not simply proportional to the spin coupling,\ncontrary to the $T=0$ behavior. Comparing our finite-temperature numerical\nresults with the experimental data from quantum gas microscopy we find a\nqualitative disagreement: in experiment, hole spreading speeds up with\nincreasing $J/t$, while in our numerics it slows down. The latter is consistent\nwith the numerical findings previously reported at $T=0$.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el","published":"2025-04-10T13:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.07719v1","title":"Counting Hours, Counting Losses: The Toll of Unpredictable Work\n  Schedules on Financial Security","summary":"Financial instability has become a significant issue in today's society.\nWhile research typically focuses on financial aspects, there is a tendency to\noverlook time-related aspects of unstable work schedules. The inability to rely\non consistent work schedules leads to burnout, work-family conflicts, and\nfinancial shocks that directly impact workers' income and assets. Unforeseen\nfluctuations in earnings pose challenges in financial planning, affecting\ndecisions on savings and spending and ultimately undermining individuals'\nlong-term financial stability and well-being.\n  This issue is particularly evident in sectors where workers experience\nfrequently changing schedules without sufficient notice, including those in the\nfood service and retail sectors, part-time and hourly workers, and individuals\nwith lower incomes. These groups are already more financially vulnerable, and\nthe unpredictable nature of their schedules exacerbates their financial\nfragility.\n  Our objective is to understand how unforeseen fluctuations in earnings\nexacerbate financial fragility by investigating the extent to which\nindividuals' financial management depends on their ability to anticipate and\nplan for the future. To address this question, we develop a simulation\nframework that models how individuals optimize utility amidst financial\nuncertainty and the imperative to avoid financial ruin. We employ online\nlearning techniques, specifically adapting workers' consumption policies based\non evolving information about their work schedules.\n  With this framework, we show both theoretically and empirically how a\nworker's capacity to anticipate schedule changes enhances their long-term\nutility. Conversely, the inability to predict future events can worsen workers'\ninstability. Moreover, our framework enables us to explore interventions to\nmitigate the problem of schedule uncertainty and evaluate their effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY","published":"2025-04-10T13:09:56Z"}
{"aid":"http://arxiv.org/abs/2504.07725v1","title":"Approximation Algorithms for Connected Maximum Coverage, Minimum\n  Connected Set Cover, and Node-Weighted Group Steiner Tree","summary":"In the Connected Budgeted maximum Coverage problem (CBC), we are given a\ncollection of subsets $\\mathcal{S}$, defined over a ground set $X$, and an\nundirected graph $G=(V,E)$, where each node is associated with a set of\n$\\mathcal{S}$. Each set in $\\mathcal{S}$ has a different cost and each element\nof $X$ gives a different prize. The goal is to find a subcollection\n$\\mathcal{S}'\\subseteq \\mathcal{S}$ such that $\\mathcal{S}'$ induces a\nconnected subgraph in $G$, the total cost of the sets in $\\mathcal{S}'$ does\nnot exceed a budget $B$, and the total prize of the elements covered by\n$\\mathcal{S}'$ is maximized. The Directed rooted Connected Budgeted maximum\nCoverage problem (DCBC) is a generalization of CBC where the underlying graph\n$G$ is directed and in the subgraph induced by $\\mathcal{S}'$ in $G$ must be an\nout-tree rooted at a given node.\n  The current best algorithms achieve approximation ratios that are linear in\nthe size of $G$ or depend on $B$. In this paper, we provide two algorithms for\nCBC and DCBC that guarantee approximation ratios of\n$O\\left(\\frac{\\log^2|X|}{\\epsilon^2}\\right)$ and\n$O\\left(\\frac{\\sqrt{|V|}\\log^2|X|}{\\epsilon^2}\\right)$, resp., with a budget\nviolation of a factor $1+\\epsilon$, where $\\epsilon\\in (0,1]$.\n  Our algorithms imply improved approximation factors of other related\nproblems. For the particular case of DCBC where the prize function is additive,\nwe improve from $O\\left(\\frac{1}{\\epsilon^2}|V|^{2/3}\\log|V|\\right)$ to\n$O\\left(\\frac{1}{\\epsilon^2}|V|^{1/2}\\log^2|V|\\right)$. For the minimum\nconnected set cover, a minimization version of CBC, and its directed variant,\nwe obtain approximation factors of $O(\\log^3|X|)$ and $O(\\sqrt{|V|}\\log^3|X|)$,\nresp. For the Node-Weighted Group Steiner Tree and and its directed variant, we\nobtain approximation factors of $O(\\log^3k)$ and $O(\\sqrt{|V|}\\log^3k)$, resp.,\nwhere $k$ is the number of groups.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-10T13:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07730v1","title":"Thermodynamics of Reissner-nordstorm black bounce black hole","summary":"Our study focuses on the thermodynamics of Reissner-nordstorm black bounce\nblack hole,we have determined the thermodynamic parameters including entropy,\nmass, temperature, heat capacity and free energies and investigated how those\nparameters are related to entropy and for some insights we additionally focused\non the P V isotherm and the logarithmic correction to the entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.07734v1","title":"On-Chip and Off-Chip TIA Amplifiers for Nanopore Signal Readout Design,\n  Performance and Challenges: A Review","summary":"Advancements in biomedical research have driven continuous innovations in\nsensing and diagnostic technologies. Among these, nanopore based single\nmolecule sensing and sequencing is rapidly emerging as a powerful and versatile\nsensing methodology. Advancements in nanopore based approaches require\nconcomitant improvements in the electronic readout methods employed, from the\npoint of low noise, bandwidth and form factor. This article focuses on current\nsensing circuits designed and employed for ultra low noise nanopore signal\nreadout, addressing the fundamental limitations of traditional off chip\ntransimpedance amplifiers (TIAs), which suffer from high input parasitic\ncapacitance, bandwidth constraints, and increased noise at high frequencies.\nThis review explores the latest design schemes and circuit structures\nclassified into on-chip and off-chip TIA designs, highlighting their design\nimplementation, performance, respective challenges and explores the interplay\nbetween noise performance, capacitance, and bandwidth across diverse\ntransimpedance amplifier (TIA) configurations. Emphasis is placed on\ncharacterizing noise response under varying parasitic capacitance and\noperational frequencies, a systematic evaluation not extensively addressed in\nprior literature while also considering the allowable input current compliance\nrange limitations. The review also compares the widely used Axopatch 200B\nsystem to the designs reported in literature. The findings offer valuable\ninsights into optimizing TIA designs for enhanced signal integrity in high\nspeed and high sensitivity applications focusing on noise reduction, impedance\nmatching, DC blocking, and offset cancellation techniques.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,q-bio.BM,q-bio.GN","published":"2025-04-10T13:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.07737v1","title":"Statistics of power and efficiency for collisional Brownian engines","summary":"Collisional Brownian engines have attracted significant attention due to\ntheir simplicity, experimental accessibility, and amenability to exact\nanalytical solutions. While previous research has predominantly focused on\noptimizing mean values of power and efficiency, the joint statistical\nproperties of these performance metrics remain largely unexplored. Using\nstochastic thermodynamics, we investigate the joint probability distributions\nof power and efficiency for collisional Brownian engines, revealing how\nthermodynamic fluctuations influence the probability of observing values\nexceeding their respective mean maxima. Our conditional probability analysis\ndemonstrates that when power fluctuates above its maximum mean value, the\nprobability of achieving high efficiency increases substantially, suggesting\nfluctuation regimes where the classical power-efficiency trade-off can be\nprobabilistically overcome. Notably, our framework extends to a broader class\nof engines, as the essential features of the statistics of the system are fully\ndetermined by the Onsager coefficients. Our results contribute to a deeper\nunderstanding of the role of fluctuations in Brownian engines, highlighting how\nstochastic behavior can enable performance beyond traditional thermodynamic\nbounds.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-10T13:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07746v1","title":"Upper semi-continuity of metric entropy for $\\mathcal{C}^{1,α}$\n  diffeomorphisms","summary":"We prove that for $\\mathcal{C}^{1,\\alpha}$ diffeomorphisms on a compact\nmanifold $M$ with ${\\rm dim} M\\leq 3$, if an invariant measure $\\mu$ is a\ncontinuity point of the sum of positive Lyapunov exponents, then $\\mu$ is an\nupper semi-continuity point of the entropy map. This gives several\nconsequences, such as the upper-semi continuity of dimensions of measures for\nsurface diffeomorphisms. Furthermore, we know the continuity of dimensions for\nmeasures of maximal entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.07747v1","title":"Antiferromagnetic Chiral Bobber Formation and Topological Proximity\n  Effect in MnBi2Te4","summary":"With topological materials being billed as the key to a new generation of\nnanoelectronics via either functional real-space topological structures (domain\nwalls, skyrmions etc.) or via momentum-space topology (topological insulators),\ntailored and controllable topological properties are of paramount significance,\nsince they lead to topologically protected states with negligible dissipation,\nenabling stable and non-volatile information processing. Here, we report on the\nevolution of topological magnetic textures in the proximity of other\ntopological defects, i.e., antiferromagnetic domain walls in the topological\ninsulator MnBi2Te4. The transition from the antiferromagnetic ground state to a\ncanted antiferromagnetic state at finite magnetic fields is accompanied by the\nformation of chiral bobbers - bulk-terminated topological defects adjacent to\nthe domain walls in this system, leading to a topological proximity effect.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-10T13:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07765v1","title":"Finite pattern problems related to Engel expansion","summary":"Let $\\mathcal{F}$ be a countable collection of functions $f$ defined on the\nintegers with integer values, such that for every $f\\in \\mathcal{F}$, $f(n)\\to\n+\\infty$ as $n\\to +\\infty$. This paper primarily investigates the Hausdorff\ndimension of the set of points whose digit sequences of the Engel expansion are\nstrictly increasing and contain any finite pattern of $\\mathcal{F}$,\ndemonstrating applications with representative examples.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:04:41Z"}
{"aid":"http://arxiv.org/abs/2504.07767v1","title":"Radiative $α$ capture on $^{12}$C in cluster effective field\n  theory: short review","summary":"Study of radiative $\\alpha$ capture on $^{12}$C,\n$^{12}$C($\\alpha$,$\\gamma$)$^{16}$O, in cluster effective field theory (EFT) is\nreviewed. A low energy EFT for $^{12}$C($\\alpha$,$\\gamma$)$^{16}$O at the\nGamow-peak energy, $E_G=0.3$~MeV, is constructed, and the theory is first\napplied to the study of elastic $\\alpha$-$^{12}$C scattering at low energies.\nThe effective range parameters are fitted to the precise phase shift data of\nthe elastic scattering and the astrophysical $S_{E1}$ factor of the $E1$\ntransition of $^{12}$C($\\alpha$,$\\gamma$)$^{16}$O at $E_G$ is estimated. For\nthe study of the $E2$ transition of $^{12}$C($\\alpha$,$\\gamma$)$^{16}$O, we\ndiscuss a difficulty to determine the asymptotic normalization coefficient\n(ANC) of the subthreshold $2_1^+$ state of $^{16}$O from the elastic scattering\ndata, and demonstrate the difficulty with the estimate of the astrophysical\n$S_{E2}$ factor of $^{12}$C($\\alpha$,$\\gamma$)$^{16}$O at $E_G$. We discuss the\nuncertainty in the estimate of the $S$ factors at $E_G$ in the present\napproach.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-10T14:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.07773v1","title":"Monitored quantum transport: full counting statistics of a quantum Hall\n  interferometer","summary":"We generalize the Levitov-Lesovik formula for the probability distribution\nfunction of the electron charge transferred through a phase coherent conductor,\nto include projective measurements that monitor the chiral propagation in\nquantum Hall edge modes. When applied to an electronic Mach-Zehnder\ninterferometer, the monitoring reduces the visibility of the Aharonov-Bohm\nconductance oscillations while preserving the binomial form of the counting\nstatistics, thereby removing a fundamental shortcoming of the dephasing-probe\nmodel of decoherence.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T14:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.07774v1","title":"Bondi Mass, Memory Effect And Balance Law of Polyhomogeneous Spacetime","summary":"Spacetimes with metrics admitting an expansion in terms of a combination of\npowers of 1/r and ln r are known as polyhomogeneous spacetimes. The asymptotic\nbehaviour of the Newman-Penrose quantities for these spacetimes is presented\nunder certain gauges. The Bondi mass is revisited via the Iyer-Wald formalism.\nThe memory effect of the gravitational radiation in the polyhomogeneous\nspacetimes is also discussed. It is found that the appearance of the\nlogarithmic terms does not affect the balance law and it remains unchanged as\nthe one of spacetimes with metrics admitting an expansion in terms of powers of\n1/r.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07798v1","title":"Mechanical Amorphization of Glass-Forming Systems Induced by Oscillatory\n  Deformation: The Energy Absorption and Efficiency Control","summary":"The kinetic process of mechanical amorphization plays a central role in\ntailoring material properties. Therefore, a quantitative understanding of how\nthis process depends on loading parameters is critical for optimizing\nmechanical amorphization and tuning material performance. In this study, we\nemploy molecular dynamics simulations to investigate oscillatory\ndeformation-induced amorphization in three glass-forming intermetallic systems,\naddressing two unresolved challenges: (1) the relationship between\namorphization efficiency and mechanical loading, and (2) energy absorption\ndynamics during crystal-to-amorphous (CTA) transitions. Our results demonstrate\na decoupling between amorphization efficiency--governed by work rate and\ndescribed by an effective temperature model--and energy absorption, which\nadheres to the Herschel-Bulkley constitutive relation. Crucially, the melting\nenthalpy emerges as a key determinant of the energy barrier, establishing a\nthermodynamic analogy between mechanical amorphization and thermally induced\nmelting. This relationship provides a universally applicable metric to quantify\namorphization kinetics. By unifying material properties and loading conditions,\nthis work establishes a predictive framework for controlling amorphization\nprocesses. These findings advance the fundamental understanding of\ndeformation-driven phase transitions and offer practical guidelines for\ndesigning materials with tailored properties for ultrafast fabrication, ball\nmilling, and advanced mechanical processing techniques.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T14:37:56Z"}
{"aid":"http://arxiv.org/abs/2504.07810v1","title":"Nonlocal Retinex-Based Variational Model and its Deep Unfolding Twin for\n  Low-Light Image Enhancement","summary":"Images captured under low-light conditions present significant limitations in\nmany applications, as poor lighting can obscure details, reduce contrast, and\nhide noise. Removing the illumination effects and enhancing the quality of such\nimages is crucial for many tasks, such as image segmentation and object\ndetection. In this paper, we propose a variational method for low-light image\nenhancement based on the Retinex decomposition into illumination, reflectance,\nand noise components. A color correction pre-processing step is applied to the\nlow-light image, which is then used as the observed input in the decomposition.\nMoreover, our model integrates a novel nonlocal gradient-type fidelity term\ndesigned to preserve structural details. Additionally, we propose an automatic\ngamma correction module. Building on the proposed variational approach, we\nextend the model by introducing its deep unfolding counterpart, in which the\nproximal operators are replaced with learnable networks. We propose\ncross-attention mechanisms to capture long-range dependencies in both the\nnonlocal prior of the reflectance and the nonlocal gradient-based constraint.\nExperimental results demonstrate that both methods compare favorably with\nseveral recent and state-of-the-art techniques across different datasets. In\nparticular, despite not relying on learning strategies, the variational model\noutperforms most deep learning approaches both visually and in terms of quality\nmetrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.07837v1","title":"A Review of HPC-Accelerated CFD in National Security and Defense","summary":"Using High-Performance Computing (HPC), Computational Fluid Dynamics (CFD)\nnow serves as an essential component in defense-related national security\napplications including missile interception and hypersonic propulsion as well\nas naval stealth optimization and urban hazard dispersion. This review combines\ntwo decades of open-source and public-domain research on HPC-accelerated CFD in\ndefense, addressing three key questions: Which security-sensitive simulations\nhave utilized open-source CFD frameworks such as OpenFOAM, SU2 and ADflow?\nWhich HPC techniques, such as MPI domain decomposition and GPU acceleration\ntogether with hybrid parallelism best enhance open-source frameworks to manage\nlarge defense CFD simulations? Which technological advancements and research\nvoids currently drive the directional development of the field? Examining\nseveral research studies sourced from NASA, DoD HPC centers, and academic\ninstitutions, scientific contributions have been classified into air, maritime,\nand space domains. Modular frameworks like NavyFOAM and SU2 and ADflow's\nadjoint-based solvers show how custom open-source solutions support workflows\nwith rapid completion of multi-million cell simulations. The conclusion\nhighlights new trends that combine exascale readiness with machine learning\nsurrogate models for real-time CFD applications and interdisciplinary\nHPC-driven multi-physics integration to deliver practical insights for\nimproving CFD use in defense research and development.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-10T15:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.07841v1","title":"Anytime Single-Step MAPF Planning with Anytime PIBT","summary":"PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-10T15:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.07842v1","title":"Data-driven robust UAV position estimation in GPS signal-challenged\n  environment","summary":"In this paper, we consider a position estimation problem for an unmanned\naerial vehicle (UAV) equipped with both proprioceptive sensors, i.e. IMU, and\nexteroceptive sensors, i.e. GPS and a barometer. We propose a data-driven\nposition estimation approach based on a robust estimator which takes into\naccount that the UAV model is affected by uncertainties and thus it belongs to\nan ambiguity set. We propose an approach to learn this ambiguity set from the\ndata.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:21:29Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07873v1","title":"Spectral Periodic Differential Operators of Odd Order","summary":"In this paper, we establish a condition on the coefficients of the\ndifferential operators L generated by an ordinary differential expression of\nodd order with periodic, complex-valued coefficients, under which the operator\nL is a spectral operator.","main_category":"math.SP","categories":"math.SP","published":"2025-04-10T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07899v1","title":"Dislocation Patterning as a Mechanism for Flat Band Formation","summary":"We compute the second-order correction to the electronic dispersion relation\nof a free electron gas interacting with an effective electron-dislocation\npotential, derived from a modern quantized theory of dislocations. Our results\ndemonstrate that dislocation patterning induces anisotropic flat bands in the\nelectronic dispersion under specific strain fields and directions, referred to\nas ``magic'' parameters. These flat bands acquire non-zero curvature as the\nstrain or direction deviates from these magic parameters.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-10T16:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.07904v1","title":"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\n  Learning for Medical Ultrasound","summary":"Data augmentation is a central component of joint embedding self-supervised\nlearning (SSL). Approaches that work for natural images may not always be\neffective in medical imaging tasks. This study systematically investigated the\nimpact of data augmentation and preprocessing strategies in SSL for lung\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\npipeline designed for ultrasound, and (3) a distilled set of the most effective\ntransformations from both pipelines. Pretrained models were evaluated on\nmultiple classification tasks: B-line detection, pleural effusion detection,\nand COVID-19 classification. Experiments revealed that semantics-preserving\ndata augmentation resulted in the greatest performance for COVID-19\nclassification - a diagnostic task requiring global image context.\nCropping-based methods yielded the greatest performance on the B-line and\npleural effusion object classification tasks, which require strong local\npattern recognition. Lastly, semantics-preserving ultrasound image\npreprocessing resulted in increased downstream performance for multiple tasks.\nGuidance regarding data augmentation and preprocessing strategies was\nsynthesized for practitioners working with SSL in ultrasound.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.07907v1","title":"Porting an LLM based Application from ChatGPT to an On-Premise\n  Environment","summary":"Given the data-intensive nature of Machine Learning (ML) systems in general,\nand Large Language Models (LLM) in particular, using them in cloud based\nenvironments can become a challenge due to legislation related to privacy and\nsecurity of data. Taking such aspects into consideration implies porting the\nLLMs to an on-premise environment, where privacy and security can be\ncontrolled. In this paper, we study this porting process of a real-life\napplication using ChatGPT, which runs in a public cloud, to an on-premise\nenvironment. The application being ported is AIPA, a system that leverages\nLarge Language Models (LLMs) and sophisticated data analytics to enhance the\nassessment of procurement call bids. The main considerations in the porting\nprocess include transparency of open source models and cost of hardware, which\nare central design choices of the on-premise environment. In addition to\npresenting the porting process, we evaluate downsides and benefits associated\nwith porting.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T16:29:26Z"}
{"aid":"http://arxiv.org/abs/2504.07912v1","title":"Echo Chamber: RL Post-training Amplifies Behaviors Learned in\n  Pretraining","summary":"Reinforcement learning (RL)-based fine-tuning has become a crucial step in\npost-training language models for advanced mathematical reasoning and coding.\nFollowing the success of frontier reasoning models, recent work has\ndemonstrated that RL fine-tuning consistently improves performance, even in\nsmaller-scale models; however, the underlying mechanisms driving these\nimprovements are not well-understood. Understanding the effects of RL\nfine-tuning requires disentangling its interaction with pretraining data\ncomposition, hyperparameters, and model scale, but such problems are\nexacerbated by the lack of transparency regarding the training data used in\nmany existing models. In this work, we present a systematic end-to-end study of\nRL fine-tuning for mathematical reasoning by training models entirely from\nscratch on different mixtures of fully open datasets. We investigate the\neffects of various RL fine-tuning algorithms (PPO, GRPO, and Expert Iteration)\nacross models of different scales. Our study reveals that RL algorithms\nconsistently converge towards a dominant output distribution, amplifying\npatterns in the pretraining data. We also find that models of different scales\ntrained on the same data mixture will converge to distinct output\ndistributions, suggesting that there are scale-dependent biases in model\ngeneralization. Moreover, we find that RL post-training on simpler questions\ncan lead to performance gains on harder ones, indicating that certain reasoning\ncapabilities generalize across tasks. Our findings show that small-scale\nproxies in controlled settings can elicit interesting insights regarding the\nrole of RL in shaping language model behavior.","main_category":"cs.LG","categories":"cs.LG,I.2.7","published":"2025-04-10T17:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07925v1","title":"Extended Horizontal Tensor Complementarity Problems","summary":"In this paper, we study the nonemptiness, compactness, uniqueness, and\nfiniteness of the solution set of a new type of nonlinear complementarity\nproblem, namely the extended horizontal tensor complementarity problem (EHTCP).\nWe introduce several classes of structured tensors and discuss the\ninterconnections among these tensors. Consequently, we study the properties of\nthe solution set of the EHTCP with the help of degree theory.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T17:41:19Z"}
{"aid":"http://arxiv.org/abs/2504.07927v1","title":"Zero-Shot Low-dose CT Denoising via Sinogram Flicking","summary":"Many low-dose CT imaging methods rely on supervised learning, which requires\na large number of paired noisy and clean images. However, obtaining paired\nimages in clinical practice is challenging. To address this issue, zero-shot\nself-supervised methods train denoising networks using only the information\nwithin a single image, such as ZS-N2N. However, these methods often employ\ndownsampling operations that degrade image resolution. Additionally, the\ntraining dataset is inherently constrained to the image itself. In this paper,\nwe propose a zero-shot low-dose CT imaging method based on sinogram flicking,\nwhich operates within a single image but generates many copies via random\nconjugate ray matching. Specifically, two conjugate X-ray pencil beams measure\nthe same path; their expected values should be identical, while their noise\nlevels vary during measurements. By randomly swapping portions of the conjugate\nX-rays in the sinogram domain, we generate a large set of sinograms with\nconsistent content but varying noise patterns. When displayed dynamically,\nthese sinograms exhibit a flickering effect due to their identical structural\ncontent but differing noise patterns-hence the term sinogram flicking. We train\nthe network on pairs of sinograms with the same content but different noise\ndistributions using a lightweight model adapted from ZS-NSN. This process is\nrepeated to obtain the final results. A simulation study demonstrates that our\nmethod outperforms state-of-the-art approaches such as ZS-N2N.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T17:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.07931v1","title":"Quantum Speed Limit in Driven-dissipative Systems","summary":"Every quantum operation that takes a system from one state to another is\nknown to have bounds on operation time, due to Heisenberg uncertainty\nprinciple. In open quantum systems (OQS), such bounds have been principally\naffected by system environment coupling. In the recent past, drives on OQS have\nshown to give rise to drive-induced dissipation (DID). In this work, we\ninvestigate how DID affects the quantum speed limits. To this end, we use a\nrecently-reported quantum master equation that takes into account environment\nfluctuations and provide a closed form estimate of drive-induced dissipation.\nOn such a system, we use Gradient Ascent Pulse Engineering (GRAPE) to find\noptimal route to move from an initial state to a desired final state. Our key\nresult is that there exists an optimal evolution time that maximizes fidelity.\nThis work enables robust quantum control in open systems, addressing a key\nchallenge in scaling quantum technologies. By improving fidelity and\nefficiency, our method advances practical quantum computing under realistic\ndissipative conditions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07946v1","title":"Characteristic function-based tests for spatial randomness","summary":"We introduce a new type of test for complete spatial randomness that applies\nto mapped point patterns in a rectangle or a cube of any dimension. This is the\nfirst test of its kind to be based on characteristic functions and utilizes a\nweighted L2-distance between the empirical and uniform characteristic\nfunctions. It is simple to calculate and does not require adjusting for edge\neffects. An efficient algorithm is developed to find the asymptotic null\ndistribution of the test statistic under the Cauchy weight function. In a\nsimulation, our test shows varying sensitivity to different levels of spatial\ninteraction depending on the scale parameter of the Cauchy weight function.\nTests with different parameter values can be combined to create a\nBonferroni-corrected omnibus test, which is almost always more powerful than\nthe popular L-test and the Clark-Evans test for detecting heterogeneous and\naggregated alternatives, although less powerful than the L-test for detecting\nregular alternatives. The simplicity of empirical characteristic function makes\nit straightforward to extend our test to non-rectangular or sparsely sampled\npoint patterns.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-10T17:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.07955v1","title":"BoxDreamer: Dreaming Box Corners for Generalizable Object Pose\n  Estimation","summary":"This paper presents a generalizable RGB-based approach for object pose\nestimation, specifically designed to address challenges in sparse-view\nsettings. While existing methods can estimate the poses of unseen objects,\ntheir generalization ability remains limited in scenarios involving occlusions\nand sparse reference views, restricting their real-world applicability. To\novercome these limitations, we introduce corner points of the object bounding\nbox as an intermediate representation of the object pose. The 3D object corners\ncan be reliably recovered from sparse input views, while the 2D corner points\nin the target view are estimated through a novel reference-based point\nsynthesizer, which works well even in scenarios involving occlusions. As object\nsemantic points, object corners naturally establish 2D-3D correspondences for\nobject pose estimation with a PnP algorithm. Extensive experiments on the\nYCB-Video and Occluded-LINEMOD datasets show that our approach outperforms\nstate-of-the-art methods, highlighting the effectiveness of the proposed\nrepresentation and significantly enhancing the generalization capabilities of\nobject pose estimation, which is crucial for real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07960v1","title":"VisualCloze: A Universal Image Generation Framework via Visual\n  In-Context Learning","summary":"Recent progress in diffusion models significantly advances various image\ngeneration tasks. However, the current mainstream approach remains focused on\nbuilding task-specific models, which have limited efficiency when supporting a\nwide range of different needs. While universal models attempt to address this\nlimitation, they face critical challenges, including generalizable task\ninstruction, appropriate task distributions, and unified architectural design.\nTo tackle these challenges, we propose VisualCloze, a universal image\ngeneration framework, which supports a wide range of in-domain tasks,\ngeneralization to unseen ones, unseen unification of multiple tasks, and\nreverse generation. Unlike existing methods that rely on language-based task\ninstruction, leading to task ambiguity and weak generalization, we integrate\nvisual in-context learning, allowing models to identify tasks from visual\ndemonstrations. Meanwhile, the inherent sparsity of visual task distributions\nhampers the learning of transferable knowledge across tasks. To this end, we\nintroduce Graph200K, a graph-structured dataset that establishes various\ninterrelated tasks, enhancing task density and transferable knowledge.\nFurthermore, we uncover that our unified image generation formulation shared a\nconsistent objective with image infilling, enabling us to leverage the strong\ngenerative priors of pre-trained infilling models without modifying the\narchitectures.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.09888v1","title":"Scalable fluxonium qubit architecture with tunable interactions between\n  non-computational levels","summary":"The fluxonium qubit has emerged as a promising candidate for superconducting\nquantum computing due to its long coherence times and high-fidelity gates.\nNonetheless, further scaling up and improving performance remain critical\nchallenges for establishing fluxoniums as a viable alternative to transmons. A\nkey obstacle lies in developing scalable coupling architectures. In this work,\nwe introduce a scalable fluxonium architecture that enables decoupling of qubit\nstates while maintaining tunable couplings between non-computational states.\nBeyond the well-studied ZZ crosstalk, we identify that an always-on interaction\ninvolving non-computational levels can significantly degrade the fidelities of\ninitialization, control, and readout in large systems, thereby impeding\nscalability. We demonstrate that this issue can be mitigated by implementing\ntunable couplings for fluxonium's plasmon transitions, meanwhile enabling fast,\nhigh-fidelity gates with passive ZZ suppression. Furthermore, since fluxonium\ntransitions span multiple frequency octaves, we emphasize the importance of\ncarefully designing coupling mechanisms and parameters to suppress residual\ninteractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T05:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.09909v1","title":"Quantum Natural Language Processing: A Comprehensive Review of Models,\n  Methods, and Applications","summary":"In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T06:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.09912v1","title":"Parameter Convergence Detector Based on VAMP Deep Unfolding: A Novel\n  Radar Constant False Alarm Rate Detection Algorithm","summary":"The sub-Nyquist radar framework exploits the sparsity of signals, which\neffectively alleviates the pressure on system storage and transmission\nbandwidth. Compressed sensing (CS) algorithms, such as the VAMP algorithm, are\nused for sparse signal processing in the sub-Nyquist radar framework. By\ncombining deep unfolding techniques with VAMP, faster convergence and higher\naccuracy than traditional CS algorithms are achieved. However, deep unfolding\ndisrupts the parameter constrains in traditional VAMP algorithm, leading to the\ndistribution of non-sparse noisy estimation in VAMP deep unfolding unknown, and\nits distribution parameter unable to be obtained directly using method of\ntraditional VAMP, which prevents the application of VAMP deep unfolding in\nradar constant false alarm rate (CFAR) detection. To address this problem, we\nexplore the distribution of the non-sparse noisy estimation and propose a\nparameter convergence detector (PCD) to achieve CFAR detection based on VAMP\ndeep unfolding. Compared to the state-of-the-art methods, PCD leverages not\nonly the sparse solution, but also the non-sparse noisy estimation, which is\nused to iteratively estimate the distribution parameter and served as the test\nstatistic in detection process. In this way, the proposed algorithm takes\nadvantage of both the enhanced sparse recovery accuracy from deep unfolding and\nthe distribution property of VAMP, thereby achieving superior CFAR detection\nperformance. Additionally, the PCD requires no information about the power of\nAWGN in the environment, which is more suitable for practical application. The\nconvergence performance and effectiveness of the proposed PCD are analyzed\nbased on the Banach Fixed-Point Theorem. Numerical simulations and practical\ndata experiments demonstrate that PCD can achieve better false alarm control\nand target detection performance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.09925v1","title":"FUSION: Fully Integration of Vision-Language Representations for Deep\n  Cross-Modal Understanding","summary":"We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09954v1","title":"Romanoff's theorem and sums of two squares","summary":"Let $A=\\{a_{n}\\}_{n=1}^{\\infty}$ and $B=\\{b_{n}\\}_{n=1}^{\\infty}$ be two\nsequences of positive integers. Under some restrictions on $A$ and $B$, we\nobtain a lower bound for a number of integers $n$ not exceeding $x$ that can be\nexpressed as a sum $n = a_i + b_j$. In particular, we obtain the result in the\ncase when $A$ is the set of numbers representable as the sum of two squares.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T07:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.09963v1","title":"Towards Unbiased Federated Graph Learning: Label and Topology\n  Perspectives","summary":"Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB,cs.SI","published":"2025-04-14T08:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.09966v1","title":"SemiETS: Integrating Spatial and Content Consistencies for\n  Semi-Supervised End-to-end Text Spotting","summary":"Most previous scene text spotting methods rely on high-quality manual\nannotations to achieve promising performance. To reduce their expensive costs,\nwe study semi-supervised text spotting (SSTS) to exploit useful information\nfrom unlabeled images. However, directly applying existing semi-supervised\nmethods of general scenes to SSTS will face new challenges: 1) inconsistent\npseudo labels between detection and recognition tasks, and 2) sub-optimal\nsupervisions caused by inconsistency between teacher/student. Thus, we propose\na new Semi-supervised framework for End-to-end Text Spotting, namely SemiETS\nthat leverages the complementarity of text detection and recognition.\nSpecifically, it gradually generates reliable hierarchical pseudo labels for\neach task, thereby reducing noisy labels. Meanwhile, it extracts important\ninformation in locations and transcriptions from bidirectional flows to improve\nconsistency. Extensive experiments on three datasets under various settings\ndemonstrate the effectiveness of SemiETS on arbitrary-shaped text. For example,\nit outperforms previous state-of-the-art SSL methods by a large margin on\nend-to-end spotting (+8.7%, +5.6%, and +2.6% H-mean under 0.5%, 1%, and 2%\nlabeled data settings on Total-Text, respectively). More importantly, it still\nimproves upon a strongly supervised text spotter trained with plenty of labeled\ndata by 2.0%. Compelling domain adaptation ability shows practical potential.\nMoreover, our method demonstrates consistent improvement on different text\nspotters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.09977v1","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart\n  Contract","summary":"Poorly designed smart contracts are particularly vulnerable, as they may\nallow attackers to exploit weaknesses and steal the virtual currency they\nmanage. In this study, we train a model using unsupervised learning to identify\nvulnerabilities in the Solidity source code of Ethereum smart contracts. To\naddress the challenges associated with real-world smart contracts, our training\ndata is derived from actual vulnerability samples obtained from datasets such\nas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to\ndevelop a robust unsupervised static analysis method for detecting five\nspecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,\ntx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to\nidentify outliers, which are subsequently classified as vulnerable smart\ncontracts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.09983v1","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\n  Learning Training","summary":"The increasing scale of deep learning models has led to the development of\nvarious parallelization strategies for distributed training across\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\nFSDP partition the parameters of each layer across multiple GPUs and gather\nthem through communication when needed. These methods rely on optimizations\nsuch as prefetching, which initiates communication early to overlap it with\ncomputation and reduce communication overhead, and unsharding, which retains as\nmany parameters in their unsharded form as possible to reduce communication\nvolume. Although the timing of prefetching should be adjusted in response to\ndynamic memory usage during execution, these systems lack the flexibility to\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\nanticipate how memory usage will change after prefetching is applied, making it\ndifficult to combine it effectively with other optimizations such as\nunsharding. We present DeepCompile, which compiles user-defined models into\ncomputation graphs and applies a sequence of profiling-guided optimization\npasses for distributed training. Taking dynamic memory usage into account,\nthese passes flexibly insert, reorder, or remove operations to improve\ncommunication-computation overlap, reduce memory pressure, and coordinate\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\ntop of DeepCompile, along with three optimizations: proactive prefetching,\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\nusing offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10035v1","title":"TT3D: Table Tennis 3D Reconstruction","summary":"Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:37:47Z"}
{"aid":"http://arxiv.org/abs/2504.10046v1","title":"CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code\n  Generation","summary":"Large language models (LLMs) have shown promising performance in automated\ncode generation, especially excelling in simple tasks such as generating\nstandalone codes. Different from simple tasks, real-world code generation\nusually depends on specific programming environment (e.g., code repositories).\nIt contains complex dependencies and domain knowledge, which is needed for LLMs\nwhen generating target code snippets. In this paper, we propose CodeRAG, a\nretrieval-augmented code generation (RAG) framework to comprehensively retrieve\nsupportive codes for real-world code generation. Beginning with the\nrequirement, CodeRAG first constructs a requirement graph for the current\nrepository, and retrieves sub- and similar- requirement nodes of the target\nrequirement on the graph. Meanwhile, it models the repository into a DS-code\ngraph. CodeRAG then maps these relevant requirement nodes into their\ncorresponding code nodes, and treats these code nodes as archors for LLM\nreasoning on DS-code graph. Finally, CodeRAG introduces a code-oriented agentic\nreasoning process, seamlessly allowing LLMs to reason and comprehensively\nretrieve for supportive codes which LLMs' need for generating correct programs.\nExperiments show that CodeRAG achieves significant improvements (i.e.,\nincreasing 40.90 and 37.79 Pass@1 on GPT-4o and Gemini-Pro on DevEval) compared\nto no RAG scenarios. Further tests on reasoning LLMs (i.e., QwQ-32B) confirm\nCodeRAG's adaptability and efficacy across various types of LLMs. In addition,\nCodeRAG outperforms commercial programming products such as Copilit and Cursor.\nWe further investigate the performance of our framework on different dependency\ntypes, and observe that CodeRAG is superior in generating examples where target\ncodes invoke predefined cross-file code snippets. These results demonstrate\nCodeRAG's potential in solving real-world repo-level coding challenges.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T09:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.10047v1","title":"Vibrational structure and symmetry in $^{110-116}$Cd","summary":"We show that a vibrational interpretation and good U(5) symmetry are\nmaintained for the majority of low-lying normal states in\n$^{110,112,114,116}$Cd isotopes, consistent with the empirical data. The\nobserved deviations from this paradigm are properly treated by an interacting\nboson model Hamiltonian which breaks the U(5) symmetry in selected non-yrast\nstates, while securing a weak mixing with coexisting SO(6)-like intruder\nstates. The results demonstrate the relevance of the U(5) partial dynamical\nsymmetry notion to this series of isotopes.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T09:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.10048v1","title":"Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers","summary":"Multi-object grounding in 3D scenes involves localizing multiple objects\nbased on natural language input. While previous work has primarily focused on\nsingle-object grounding, real-world scenarios often demand the localization of\nseveral objects. To tackle this challenge, we propose Hierarchical Contrastive\nSiamese Transformers (H-COST), which employs a Hierarchical Processing strategy\nto progressively refine object localization, enhancing the understanding of\ncomplex language instructions. Additionally, we introduce a Contrastive Siamese\nTransformer framework, where two networks with the identical structure are\nused: one auxiliary network processes robust object relations from ground-truth\nlabels to guide and enhance the second network, the reference network, which\noperates on segmented point-cloud data. This contrastive mechanism strengthens\nthe model' s semantic understanding and significantly enhances its ability to\nprocess complex point-cloud data. Our approach outperforms previous\nstate-of-the-art methods by 9.5% on challenging multi-object grounding\nbenchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10049v1","title":"Summarization of Multimodal Presentations with Vision-Language Models:\n  Study of the Effect of Modalities and Structure","summary":"Vision-Language Models (VLMs) can process visual and textual information in\nmultiple formats: texts, images, interleaved texts and images, or even\nhour-long videos. In this work, we conduct fine-grained quantitative and\nqualitative analyses of automatic summarization of multimodal presentations\nusing VLMs with various representations as input. From these experiments, we\nsuggest cost-effective strategies for generating summaries from text-heavy\nmultimodal documents under different input-length budgets using VLMs. We show\nthat slides extracted from the video stream can be beneficially used as input\nagainst the raw video, and that a structured representation from interleaved\nslides and transcript provides the best performance. Finally, we reflect and\ncomment on the nature of cross-modal interactions in multimodal presentations\nand share suggestions to improve the capabilities of VLMs to understand\ndocuments of this nature.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T09:55:01Z"}
{"aid":"http://arxiv.org/abs/2504.10066v1","title":"A Framework for Adaptive Load Redistribution in Human-Exoskeleton-Cobot\n  Systems","summary":"Wearable devices like exoskeletons are designed to reduce excessive loads on\nspecific joints of the body. Specifically, single- or two-degrees-of-freedom\n(DOF) upper-body industrial exoskeletons typically focus on compensating for\nthe strain on the elbow and shoulder joints. However, during daily activities,\nthere is no assurance that external loads are correctly aligned with the\nsupported joints. Optimizing work processes to ensure that external loads are\nprimarily (to the extent that they can be compensated by the exoskeleton)\ndirected onto the supported joints can significantly enhance the overall\nusability of these devices and the ergonomics of their users. Collaborative\nrobots (cobots) can play a role in this optimization, complementing the\ncollaborative aspects of human work. In this study, we propose an adaptive and\ncoordinated control system for the human-cobot-exoskeleton interaction. This\nsystem adjusts the task coordinates to maximize the utilization of the\nsupported joints. When the torque limits of the exoskeleton are exceeded, the\nframework continuously adapts the task frame, redistributing excessive loads to\nnon-supported body joints to prevent overloading the supported ones. We\nvalidated our approach in an equivalent industrial painting task involving a\nsingle-DOF elbow exoskeleton, a cobot, and four subjects, each tested in four\ndifferent initial arm configurations with five distinct optimisation weight\nmatrices and two different payloads.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T10:09:00Z"}
{"aid":"http://arxiv.org/abs/2504.10067v1","title":"Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph\n  Auto-Encoders","summary":"EdgeIoT represents an approach that brings together mobile edge computing\nwith Internet of Things (IoT) devices, allowing for data processing close to\nthe data source. Sending source data to a server is bandwidth-intensive and may\ncompromise privacy. Instead, federated learning allows each device to upload a\nshared machine-learning model update with locally processed data. However, this\ntechnique, which depends on aggregating model updates from various IoT devices,\nis vulnerable to attacks from malicious entities that may inject harmful data\ninto the learning process. This paper introduces a new attack method targeting\nfederated learning in EdgeIoT, known as data-independent model manipulation\nattack. This attack does not rely on training data from the IoT devices but\ninstead uses an adversarial variational graph auto-encoder (AV-GAE) to create\nmalicious model updates by analyzing benign model updates intercepted during\ncommunication. AV-GAE identifies and exploits structural relationships between\nbenign models and their training data features. By manipulating these\nstructural correlations, the attack maximizes the training loss of the\nfederated learning system, compromising its overall effectiveness.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T10:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.10073v1","title":"Quantum-Classical Comparison of B-cell Epitope Prediction Using QSVM and\n  VQC","summary":"Support Vector Machine (SVM) is a classical and widely applied supervised\nmachine learning algorithm for binary classification. Utilizing the kernel\ntrick enables embedding data into higher-dimensional feature spaces to address\nnon-linear classification tasks effectively.\n  This study investigates the classical SVM and its quantum counterpart, the\nQuantum Support Vector Machine (QSVM), which leverages quantum feature maps to\nembed data into high-dimensional Hilbert spaces. Additionally, we explore the\nVariational Quantum Classifier (VQC), a fully quantum model based on\nparameterized quantum circuits.\n  We apply these quantum and classical models to the task of B-cell epitope\nprediction, a critical problem in immunoinformatics relevant to vaccine design.\nUsing curated data from the Immune Epitope Database (IEDB), we examine\nclassification performance under varying feature dimensionality and sample\nsizes. Dimensionality reduction is performed using Principal Component Analysis\n(PCA), and experiments include both QSVM and VQC under multiple training\nconditions.\n  Our findings show that VQC generally performs better on larger,\nhigh-dimensional datasets, while QSVM maintains more stable accuracy on small,\nnoise-free datasets. This study also highlights the resource trade-offs between\nthe two models: QSVM demands extensive kernel evaluations, while VQC benefits\nfrom shallow circuits and sample-wise training, making it suitable for\nnear-term quantum hardware. These results contribute to understanding how\ndifferent quantum machine learning models perform under practical constraints\nin biomedical sequence classification.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T10:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10075v1","title":"Long-range magnetic interactions in Nd$_2$PdSi$_3$ and the formation of\n  skyrmion phases in centrosymmetric metals","summary":"We present an extensive X-ray and neutron scattering study of the structure\nand magnetic excitations of Nd$_2$PdSi$_3$, a sister compound of Gd$_2$PdSi$_3$\nwhich was recently found to host a skyrmion lattice phase despite its\ncentrosymmetric crystal structure. Dispersive magnetic excitations were\nmeasured throughout the Brillouin zone and modelled using mean-field\nrandom-phase approximation to determine the magnetic interactions between Nd\nions. Our analysis reveals that the magnetic interactions in this system extend\nover large distances and are significantly affected by a crystallographic\nsuperstructure formed by ordering of the Pd and Si atoms. The results suggest\nthat the mechanism for the skyrmion phase formation in this family of\nmaterials, e.g. Gd$_2$PdSi$_3$ is through the long-range RKKY interactions\nrather than short-range triangular-lattice frustration.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-14T10:20:39Z"}
{"aid":"http://arxiv.org/abs/2504.10086v1","title":"Bagci-Hoggan Complete and Orthonormal Sets of ETOs. Results for He-like\n  atoms","summary":"The Hartree-Fock-Rothaan equations are solved for He-like ions using the\niterative self-consistent method. Bagci-Hoggan complete and orthonormal sets of\nexponential-type orbitals are employed as the basis. These orbitals satisfy the\northonormality relationship for quantum numbers with fractional order. They are\nsolution of Schrodinger-like differential equation derived by the author. In a\nrecent study conducted for the calculation of the hydrogen atom energy levels,\nit has been demonstrated that the fractional formalism of the principal and the\nangular momentum quantum numbers converges to the 1s level of the ground state\nenergy of hydrogen atom, obtained from the solution of the standard Schrodinger\nequation. This study examines the effect of fractional values of the quantum\nnumbers for two-electron systems, where electron correlation effects exist.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-14T10:42:04Z"}
{"aid":"http://arxiv.org/abs/2504.10087v1","title":"Joint Localization and Synchronization in Downlink Distributed MIMO","summary":"We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.10099v1","title":"Regularization of Functional Determinants of Radial Operators via Heat\n  Kernel Coefficients","summary":"We propose an efficient regularization method for functional determinants of\nradial operators using heat kernel coefficients. Our key finding is a\nsystematic way to identify heat kernel coefficients in the angular momentum\nspace. We explicitly obtain the formulas up to sixth order in the heat kernel\nexpansion, which suffice to regularize functional determinants in up to 13\ndimensions. We find that the heat kernel coefficients accurately approximate\nthe large angular momentum dependence of functional determinants, and make\nnumerical computations more efficient. In the limit of a large angular\nmomentum, our formulas reduce to the WKB formulas in previous studies, but\nextended to higher orders. All the results are available in both the zeta\nfunction regularization and the dimensional regularization.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-14T11:06:21Z"}
{"aid":"http://arxiv.org/abs/2504.10103v1","title":"Numerical approach for solving problems arising from polynomial analysis","summary":"This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.","main_category":"math.NA","categories":"math.NA,cs.NA,math.CA","published":"2025-04-14T11:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.10104v1","title":"Automated next-to-leading order QCD and electroweak predictions of\n  photon-photon processes in ultraperipheral collisions","summary":"We present automated next-to-leading order QCD and/or electroweak (EW)\npredictions for photon-photon processes in ultraperipheral high-energy\ncollisions of protons and ions, extending the capabilities of the\n\\textsc{MadGraph5\\_aMC@NLO} framework together in combination with the\n\\ttt{gamma-UPC} code. Key aspects of this extension are discussed. We compute\nQCD and/or EW quantum corrections for several phenomenologically interesting\nprocesses at LHC and FCC-hh energies.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-14T11:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.10106v1","title":"SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene\n  Understanding","summary":"Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T11:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.10108v1","title":"A Photometric Comparison of B and Be stars using Gaia DR3","summary":"Previous studies have observed significant photometric differences between\nnon-emission B-type and classical Be stars, however the precise mechanism\nresponsible for these differences is unclear. This study combines the Bright\nStar Catalogue with Tycho and Gaia photometry to create a homogeneous sample of\n1015 of the closest and brightest B and Be-type field stars with 90 per cent of\nobjects at distances < 500pc. Due to their proximity, the extinction towards\nthese objects is very low, ensuring we minimise any obfuscation in the\nreddening correction and final photometry. We present our findings in both\nTycho and Gaia photometry through colour magnitude diagrams and present\nintrinsic colours and absolute magnitudes for each spectral type. We find Be\nstars are on average ~0.5 magnitudes brighter in both Gaia $G$ and Tycho V$_T$\ncompared to non-emission B stars of the same spectral type. Additionally, we\nfind tentative evidence that Be stars are redder in Gaia B$_P$$-$R$_P$,\nparticularly for the earlier types, but have similar Tycho B$_T$$-$V$_T$\ncolours. We test the effects of gravitational darkening due to rapid rotation\nand binarity on the photometry of our sample and find both to be insufficient\nto explain the observed photometric differences between B and Be stars. We\nconclude that the most likely mechanism responsible for the observed\nphotometric differences is the combined effect of the circumstellar disc and\nstellar evolution up the Main Sequence, with the disc dominating early-types\nand evolution dominating late type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T11:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.10109v1","title":"Lightweight Trustworthy Distributed Clustering","summary":"Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-14T11:16:07Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10118v1","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","summary":"We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-14T11:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.10125v1","title":"An initial-boundary corrected splitting method for diffusion-reaction\n  problems","summary":"Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T11:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.10135v1","title":"Exploiting Structure in MIMO Scaled Graph Analysis","summary":"Scaled graphs offer a graphical tool for analysis of nonlinear feedback\nsystems. Although recently substantial progress has been made in scaled graph\nanalysis, at present their use in multivariable feedback systems is limited by\nconservatism. In this paper, we aim to reduce this conservatism by introducing\nmultipliers and exploit system structure in the analysis with scaled graphs. In\nparticular, we use weighted inner products to arrive at a weighted scaled graph\nand combine this with a commutation property to formulate a stability result\nfor multivariable feedback systems. We present a method for computing the\nweighted scaled graph of Lur'e systems based on solving sets of linear matrix\ninequalities, and demonstrate a significant reduction in conservatism through\nan example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T11:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.10138v1","title":"$k$-Fibonacci numbers that are palindromic concatenations of two\n  distinct Repdigits","summary":"Let $k\\ge 2$ and $\\{F_n^{(k)}\\}_{n\\geq 2-k}$ be the sequence of\n$k$--generalized Fibonacci numbers whose first $k$ terms are $0,\\ldots,0,0,1$\nand each term afterwards is the sum of the preceding $k$ terms. In this paper,\nwe determine all $k$-Fibonacci numbers that are palindromic concatenations of\ntwo distinct repdigits.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T11:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.10156v1","title":"The missing elements in the telegraph equations","summary":"The conventional modeling of transmission lines relies on the classical\ntelegraph equations, originally formulated over 150 years ago. These equations\nare typically derived by representing the line as an assembly of infinitesimal\ninductive, capacitive, and resistive elements. However, this formulation is\nfundamentally flawed, as a transmission line cannot be accurately described\nthrough a discretized model of infinitesimal lumped components. Instead, a more\nrigorous approach should derive the governing equations directly from Maxwells\nequations in conjunction with Ohms law. This paper presents such a derivation\nand introduces a corrected formulation, herein referred to as the Trump\nEquations.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-04-14T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.10160v1","title":"MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like\n  Reinforcement Learning","summary":"Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.10166v1","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented\n  LLMs for Social Media Analysis","summary":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with\nExplanation); a novel framework that integrates retrieval-augmented Large\nLanguage Models (LLMs) with clustering techniques to address fact-checking\nchallenges on social media. CRAVE automatically retrieves multimodal evidence\nfrom diverse, often contradictory, sources. Evidence is clustered into coherent\nnarratives, and evaluated via an LLM-based judge to deliver fact-checking\nverdicts explained by evidence summaries. By synthesizing evidence from both\ntext and image modalities and incorporating agent-based refinement, CRAVE\nensures consistency and diversity in evidence representation. Comprehensive\nexperiments demonstrate CRAVE's efficacy in retrieval precision, clustering\nquality, and judgment accuracy, showcasing its potential as a robust\ndecision-support tool for fact-checkers.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T12:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.10171v1","title":"Kullback-Leibler excess risk bounds for exponential weighted aggregation\n  in Generalized linear models","summary":"Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-14T12:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10177v1","title":"Lagrangian averaging of singular stochastic actions for fluid dynamics","summary":"We construct sub-grid scale models of incompressible fluids by considering\nexpectations of semi-martingale Lagrangian particle trajectories. Our\nconstruction is based on the Lagrangian decomposition of flow maps into mean\nand fluctuation parts, and it is separated into the following steps. First,\nthrough Magnus expansion, the fluid velocity field is expressed in terms of\nfluctuation vector fields whose dynamics are assumed to be stochastic. Second,\nwe use Malliavin calculus to give a regularised interpretation of the product\nof white noise when inserting the stochastic velocity field into the Lagrangian\nfor Euler's fluid. Lastly, we consider closures of the mean velocity by making\nstochastic analogues of Talyor's frozen-in turbulence hypothesis to derive a\nversion of the anisotropic Lagrangian averaged Euler equation.","main_category":"math-ph","categories":"math-ph,math.MP,physics.flu-dyn","published":"2025-04-14T12:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10185v1","title":"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in\n  Current Benchmarks","summary":"Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.10195v1","title":"Simulation of TOPCon/PERC Hybrid Bottom Structure for Perovskite/Silicon\n  Tandem Solar Cells using Quokka3","summary":"This work emphasizes the potential of perovskite/silicon tandem solar cells\nfor increased power conversion efficiencies. By employing crystalline silicon\n(c-Si) as the bottom cell, particularly with p-type PERC technology, there are\ncost-effective and advantageous physical properties. However, traditional\nphosphorus-doped emitters in PERC Si bottom cells are hindered by high surface\nrecombination, which limits their performance. This research introduces a novel\nhybrid PERC/TOPCon structure that integrates a phosphorus-doped poly-Si (n+\nTOPCon) layer as the front emitter to address these challenges. Numerical\nsimulations using Quokka3 confirmed the feasibility of the design, focusing on\noptimizing the rear side metallization to enhance implied open-circuit voltage\n(Voc) and fill factor (FF). A two-step process systematically varied local\ncontact openings to examine their impact on performance metrics. Results\nhighlighted optimal rear metallization parameters, achieving optimal metal\nfractions approximately 2%. This innovative approach demonstrates the\neffectiveness of combining TOPCon and PERC technologies for bottom cells in\ntandem structures, providing valuable insights into their development and\noptimization. The study underscores the potential of the hybrid PERC/TOPCon\nstructure in enhancing the functionality and efficiency of perovskite/silicon\ntandem solar cells.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-14T12:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10212v1","title":"WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients","summary":"Partial Differential Equations (PDEs) identification is a data-driven method\nfor mathematical modeling, and has received a lot of attentions recently. The\nstability and precision in identifying PDE from heavily noisy spatiotemporal\ndata present significant difficulties. This problem becomes even more complex\nwhen the coefficients of the PDEs are subject to spatial variation. In this\npaper, we propose a Weak formulation of Group-sparsity-based framework for\nIDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this\nchallenge. Our approach utilizes the weak formulation of PDEs to reduce the\nimpact of noise. We represent test functions and unknown PDE coefficients using\nB-splines, where the knot vectors of test functions are optimally selected\nbased on spectral analysis of the noisy data. To facilitate feature selection,\nwe propose to integrate group sparse regression with a newly designed group\nfeature trimming technique, called GF-trim, to eliminate unimportant features.\nExtensive and comparative ablation studies are conducted to validate our\nproposed method. The proposed method not only demonstrates greater robustness\nto high noise levels compared to state-of-the-art algorithms but also achieves\nsuperior performance while exhibiting reduced sensitivity to hyperparameter\nselection.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T13:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.10217v1","title":"Dissimilar magnetically driven accretion on the components of V4046\n  Sagittarii","summary":"Accretion of pre-main sequence stars (PMS) is a key process in stellar\nformation, governing mass assembly, influencing angular momentum conservation\nand stellar internal structure, and shaping disc evolution, which serves as the\nbirthplace of exoplanets. Classical T Tauri stars (cTTSs), low-mass PMS stars\nactively accreting from a disc, hold a well-described magnetospheric accretion\nmodel. Their strong, inclined dipole magnetic fields truncate the disc at a few\nstellar radii, channelling material along magnetic field lines to fall onto the\nstellar surface near the dipole pole. However, this paradigm assumes the\npresence of a single star, and a complete description of the accretion process\nin multiple systems remains to be achieved. Building on our previous work on DQ\nTau and AK Sco, we aim to describe the accretion processes in cTTS binaries,\naccounting for the influence of stellar magnetic fields. Specifically, we\nsought to explore how the magnetospheric accretion model of cTTSs can be\napplied to V4046 Sgr, a spectroscopic binary composed of equal-mass and coeval\ncTTSs in a circular orbit with synchronous rotation, surrounded by a\ncircumbinary disc. We analysed a time series of ESPaDOnS spectra covering\nseveral orbital cycles. A variability analysis was performed on the radial\nvelocities and on the Balmer, He I D3, and Ca II emission lines, which are\nassociated with the accretion process. We identified the secondary as the\nsystem's main accretor, operating in an unstable regime. Additionally, we\ndetected an accretion funnel flow connecting the dipole pole of the primary\nstar with a nearby bulk of gas. We concluded that the two components exhibit\ndissimilar accretion patterns. The primary operates in an \"ordered chaotic\"\nregime, where accretion funnel flows and accretion tongues coexist. Conversely,\nthe secondary appears to be in a chaotic regime, with accretion tongues\ndominating.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T13:33:44Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10253v1","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for\n  Genetic Programming","summary":"Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.","main_category":"cs.NE","categories":"cs.NE,cs.LG,cs.SC","published":"2025-04-14T14:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10268v1","title":"Theoretical Model of Microparticle-Assisted Super-Resolution Microscopy","summary":"This work presents the development of a three-dimensional model of\nsuper-resolution imaging, which may help resolve the longstanding debate about\nthe nature of this phenomenon and the methods used to describe it. We discuss\nthe approaches that enable an efficient and accurate theoretical description. A\ncomparison between theoretical predictions and experimental results is\npresented for both conventional and confocal microscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T14:33:51Z"}
{"aid":"http://arxiv.org/abs/2504.10271v1","title":"Change Your Perspective, Widen Your Worldview! Societally Beneficial\n  Perceptual Filter Bubbles in Personalized Reality","summary":"Extended Reality (XR) technologies enable the personalized mediation of an\nindividual's perceivable reality across modalities, thereby creating a\nPersonalized Reality (PR). While this may lead to individually beneficial\neffects in the form of more efficient, more fun, and safer experiences, it may\nalso lead to perceptual filter bubbles since individuals are exposed\npredominantly or exclusively to content that is congruent with their existing\nbeliefs and opinions. This undermining of a shared basis for interaction and\ndiscussion through constrained perceptual worldviews may impact society through\nincreased polarization and other well-documented negative effects of filter\nbubbles. In this paper, we argue that this issue can be mitigated by increasing\nindividuals' awareness of their current perspective and providing avenues for\ndevelopment, including through support for engineered serendipity and fostering\nof self-actualization that already show promise for traditional recommender\nsystems. We discuss how these methods may be transferred to XR to yield\nvaluable tools to give people transparency and agency over their perceptual\nworldviews in a responsible manner.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10282v1","title":"Optimal Execution in Intraday Energy Markets under Hawkes Processes with\n  Transient Impact","summary":"This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-14T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.10294v1","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into\n  Biomechanics and Human-Robot Interaction","summary":"Background: Lower limb exoskeletons can enhance quality of life, but\nwidespread adoption is limited by the lack of frameworks to assess their\nbiomechanical and human-robot interaction effects, which are essential for\ndeveloping adaptive and personalized control strategies. Understanding impacts\non kinematics, muscle activity, and HRI dynamics is key to achieve improved\nusability of wearable robots. Objectives: We propose a systematic methodology\nevaluate an ankle exoskeleton's effects on human movement during walking and\nload-carrying (10 kg front pack), focusing on joint kinematics, muscle\nactivity, and HRI torque signals. Materials and Methods: Using Xsens MVN\n(inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three\nexperiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait\nanalysis (two subjects, passive/active modes); and (3) load-carrying under\nassistance. Results and Conclusions: The first experiment confirmed that the\nHRI sensor captured both voluntary and involuntary torques, providing\ndirectional torque insights. The second experiment showed that the device\nslightly restricted ankle range of motion (RoM) but supported normal gait\npatterns across all assistance modes. The exoskeleton reduced muscle activity,\nparticularly in active mode. HRI torque varied according to gait phases and\nhighlighted reduced synchronization, suggesting a need for improved support.\nThe third experiment revealed that load-carrying increased GM and TA muscle\nactivity, but the device partially mitigated user effort by reducing muscle\nactivity compared to unassisted walking. HRI increased during load-carrying,\nproviding insights into user-device dynamics. These results demonstrate the\nimportance of tailoring exoskeleton evaluation methods to specific devices and\nusers, while offering a framework for future studies on exoskeleton\nbiomechanics and HRI.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10310v1","title":"Existence of Nonequilibrium Glasses in the Degenerate Stealthy\n  Hyperuniform Ground-State Manifold","summary":"Stealthy interactions are an emerging class of nontrivial, bounded\nlong-ranged oscillatory pair potentials with classical ground states that can\nbe disordered, hyperuniform, and infinitely degenerate. Their hybrid\ncrystal-liquid nature endows them with novel physical properties with\nadvantages over their crystalline counterparts. Here, we show the existence of\nnonequilibrium hard-sphere glasses within this unusual ground-state manifold as\nthe stealthiness parameter $\\chi$ tends to zero that are remarkably\nconfigurationally extremely close to hyperuniform 3D maximally random jammed\n(MRJ) sphere packings. The latter are prototypical glasses since they are\nmaximally disordered, perfectly rigid, and perfectly nonergodic. Our\noptimization procedure, which leverages the maximum cardinality of the infinite\nground-state set, not only guarantees that our packings are hyperuniform with\nthe same structure-factor scaling exponent as the MRJ state, but they share\nother salient structural attributes, including a packing fraction of $0.638$, a\nmean contact number per particle of 6, gap exponent of $0.44(1)$, and pair\ncorrelation functions $g_2(r)$ and structures factors $S(k)$ that are virtually\nidentical to one another for all $r$ and $k$, respectively. Moreover, we\ndemonstrate that stealthy hyperuniform packings can be created within the\ndisordered regime ($0 < \\chi <1/2$) with heretofore unattained maximal packing\nfractions. As $\\chi$ increases from zero, they always form interparticle\ncontacts, albeit with sparser contact networks as $\\chi$ increases from zero,\nresulting in linear polymer-like chains of contacting particles with\nincreasingly shorter chain lengths. The capacity to generate ultradense\nstealthy hyperuniform packings for all $\\chi$ opens up new materials\napplications in optics and acoustics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-14T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.10314v1","title":"Universal Algebra and Effectful Computation","summary":"Abstract clones serve as an algebraic presentation of the syntax of a simple\ntype theory. From the perspective of universal algebra, they define algebraic\ntheories like those of groups, monoids and rings. This link allows one to study\nthe language of simple type theory from the viewpoint of universal algebra.\n  Programming languages, however, are much more complicated than simple type\ntheory. Many useful features like reading, writing, and exception handling\ninvolve interacting with the environment; these are called side-effects.\nAlgebraic presentations for languages with the appropriate syntax for handling\neffects are given by premulticategories and effectful multicategories. We study\nthese structures with the aim of defining a suitable notion of an algebra.\n  To achieve this goal, we proceed in two steps. First, we define a tensor on\n$[\\to,\\category{Set}]$, and show that this tensor along with the cartesian\nproduct gives the category a duoidal structure. Secondly, we introduce the\nnovel notion of a multicategory enriched in a duoidal category which generalize\nthe traditional notion of a multicategory. Further, we prove that an effectful\nmulticategory is the same as a multicategory enriched in the duoidal category\n$[\\to,\\category{Set}]$. This result places multicategories and effectful\nmulticategories on a similar footing, and provides a mechanism for transporting\nconcepts from the theory of multicategories (which model pure computation) to\nthe theory of effectful multicategories (which model effectful computation). As\nan example of this, we generalize the definition of a 2-morphism for\nmulticategories to the duoidally enriched case. Our equivalence result then\ngives a natural definition of a 2-morphism for effectful multicategories, which\nwe then use to define the notion of an algebra.","main_category":"cs.PL","categories":"cs.PL,math.CT","published":"2025-04-14T15:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10331v1","title":"LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian\n  Splatting for Novel View Synthesis","summary":"Novel view synthesis (NVS) in low-light scenes remains a significant\nchallenge due to degraded inputs characterized by severe noise, low dynamic\nrange (LDR) and unreliable initialization. While recent NeRF-based approaches\nhave shown promising results, most suffer from high computational costs, and\nsome rely on carefully captured or pre-processed data--such as RAW sensor\ninputs or multi-exposure sequences--which severely limits their practicality.\nIn contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with\ncompetitive visual fidelity; however, existing 3DGS-based methods struggle with\nlow-light sRGB inputs, resulting in unstable Gaussian initialization and\nineffective noise suppression. To address these challenges, we propose\nLL-Gaussian, a novel framework for 3D reconstruction and enhancement from\nlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Our\nmethod introduces three key innovations: 1) an end-to-end Low-Light Gaussian\nInitialization Module (LLGIM) that leverages dense priors from learning-based\nMVS approach to generate high-quality initial point clouds; 2) a dual-branch\nGaussian decomposition model that disentangles intrinsic scene properties\n(reflectance and illumination) from transient interference, enabling stable and\ninterpretable optimization; 3) an unsupervised optimization strategy guided by\nboth physical constrains and diffusion prior to jointly steer decomposition and\nenhancement. Additionally, we contribute a challenging dataset collected in\nextreme low-light environments and demonstrate the effectiveness of\nLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian\nachieves up to 2,000 times faster inference and reduces training time to just\n2%, while delivering superior reconstruction and rendering quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:39:31Z"}
{"aid":"http://arxiv.org/abs/2504.10338v1","title":"Classifying Copy Number Variations Using State Space Modeling of\n  Targeted Sequencing Data: A Case Study in Thalassemia","summary":"Thalassemia, a blood disorder and one of the most prevalent hereditary\ngenetic disorders worldwide, is often caused by copy number variations (CNVs)\nin the hemoglobin genes. This disorder has incredible diversity, with a large\nnumber of distinct profiles corresponding to alterations of different regions\nin the genes. Correctly classifying an individual's profile is critical as it\nimpacts treatment, prognosis, and genetic counseling. However, genetic\nclassification is challenging due to the large number of profiles worldwide,\nand often requires a large number of sequential tests. Targeted next generation\nsequencing (NGS), which characterizes segments of an individual's genome, has\nthe potential to dramatically reduce the cost of testing and increase accuracy.\nIn this work, we introduce a probabilistic state space model for profiling\nthalassemia from targeted NGS data, which naturally characterize the spatial\nordering of the genes along the chromosome. We then use decision theory to\nchoose the best profile among the different options. Due to our use of Bayesian\nmethodology, we are also able to detect low-quality samples to be excluded from\nconsideration, an important component of clinical screening. We evaluate our\nmodel on a dataset of 57 individuals, including both controls and cases with a\nvariety of thalassemia profiles. Our model has a sensitivity of 0.99 and\nspecificity of 0.93 for thalassemia detection, and accuracy of 91.5\\% for\ncharacterizing subtypes. Furthermore, the specificity and accuracy rise to\n$0.96$ and 93.9\\% when low-quality samples are excluded using our automated\nquality control method. This approach outperforms alternative methods,\nparticularly in specificity, and is broadly applicable to other disorders.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-14T15:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10354v1","title":"The diagonal and Hadamard grade of hypergeometric functions","summary":"Diagonals of rational functions are an important class of functions arising\nin number theory, algebraic geometry, combinatorics, and physics. In this paper\nwe study the diagonal grade of a function $f$, which is defined to be the\nsmallest $n$ such that $f$ is the diagonal of a rational function in variables\n$x_0,\\dots, x_n$. We relate the diagonal grade of a function to the nilpotence\nof the associated differential equation. This allows us to determine the\ndiagonal grade of many hypergeometric functions and answer affirmatively the\noutstanding question on the existence of functions with diagonal grade greater\nthan $2$. In particular, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\ndiagonal grade $n$ for each $n\\geq 1$. Our method also applies to the\ngenerating function of the Ap\\'ery sequence, which we find to have diagonal\ngrade $3$. We also answer related questions on Hadamard grades posed by\nAllouche and Mend\\`es France. For example, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\nHadamard grade $n$ for all $n\\geq 1$.","main_category":"math.CO","categories":"math.CO,math-ph,math.AG,math.MP,math.NT","published":"2025-04-14T16:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.10357v1","title":"The Communication and Computation Trade-off in Wireless Semantic\n  Communications","summary":"Semantic communications have emerged as a crucial research direction for\nfuture wireless communication networks. However, as wireless systems become\nincreasingly complex, the demands for computation and communication resources\nin semantic communications continue to grow rapidly. This paper investigates\nthe trade-off between computation and communication in wireless semantic\ncommunications, taking into consideration transmission task delay and\nperformance constraints within the semantic communication framework. We propose\na novel tradeoff metric to analyze the balance between computation and\ncommunication in semantic transmissions and employ the deep reinforcement\nlearning (DRL) algorithm to minimize this metric, thereby reducing the cost\nassociated with balancing computation and communication. Through simulations,\nwe analyze the tradeoff between computation and communication and demonstrate\nthe effectiveness of optimizing this trade-off metric.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T16:06:20Z"}
{"aid":"http://arxiv.org/abs/2504.10358v1","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for\n  AI-Generated Videos","summary":"Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T16:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.10364v1","title":"Widely FSR tunable high Q-factor microresonators formed at the\n  intersection of straight optical fibers","summary":"We present a new class of high-Q tunable microresonators formed at the\nintersection of two straight silica optical fibers, whose free spectral range\n(FSR) can be widely tuned by fiber rotation. The proposed configuration avoids\nthe limitations of traditional monolithic microresonators that lack FSR\ntunability required for a wide range of photonic applications. Using small\nrotation angles (1-15 mrad), we demonstrate a tunability of the FSR from 2 pm\nto 10 pm, enabled by microscale fiber displacements that reshape the resonator\nprofile over millimeter scales. The proposed approach minimizes mechanical\nstress, supports miniaturization, and is suitable for integration with MEMS. It\npaves the way for the fabrication of tunable delay lines, ultralow repetition\nrate broadband frequency comb generators, and nonlocal optofluidic sensors on a\nchip.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T16:10:08Z"}
{"aid":"http://arxiv.org/abs/2504.10371v1","title":"Brain-Machine Interfaces & Information Retrieval Challenges and\n  Opportunities","summary":"The fundamental goal of Information Retrieval (IR) systems lies in their\ncapacity to effectively satisfy human information needs - a challenge that\nencompasses not just the technical delivery of information, but the nuanced\nunderstanding of human cognition during information seeking. Contemporary IR\nplatforms rely primarily on observable interaction signals, creating a\nfundamental gap between system capabilities and users' cognitive processes.\nBrain-Machine Interface (BMI) technologies now offer unprecedented potential to\nbridge this gap through direct measurement of previously inaccessible aspects\nof information-seeking behaviour. This perspective paper offers a broad\nexamination of the IR landscape, providing a comprehensive analysis of how BMI\ntechnology could transform IR systems, drawing from advances at the\nintersection of both neuroscience and IR research. We present our analysis\nthrough three identified fundamental vertices: (1) understanding the neural\ncorrelates of core IR concepts to advance theoretical models of search\nbehaviour, (2) enhancing existing IR systems through contextual integration of\nneurophysiological signals, and (3) developing proactive IR capabilities\nthrough direct neurophysiological measurement. For each vertex, we identify\nspecific research opportunities and propose concrete directions for developing\nBMI-enhanced IR systems. We conclude by examining critical technical and\nethical challenges in implementing these advances, providing a structured\nroadmap for future research at the intersection of neuroscience and IR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T16:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10386v1","title":"Universal fault-tolerant logic with heterogeneous holographic codes","summary":"The study of holographic bulk-boundary dualities has led to the construction\nof novel quantum error correcting codes. Although these codes have shed new\nlight on conceptual aspects of these dualities, they have widely been believed\nto lack a crucial feature of practical quantum error correction: The ability to\nsupport universal fault-tolerant quantum logic. In this work, we introduce a\nnew class of holographic codes that realize this feature. These heterogeneous\nholographic codes are constructed by combining two seed codes in a tensor\nnetwork on an alternating hyperbolic tiling. We show how this construction\ngeneralizes previous strategies for fault tolerance in tree-type concatenated\ncodes, allowing one to implement non-Clifford gates fault-tolerantly on the\nholographic boundary. We also demonstrate that these codes allow for high\nerasure thresholds under a suitable heterogeneous combination of specific seed\ncodes. Compared to previous concatenated codes, heterogeneous holographic codes\nachieve large overhead savings in physical qubits, e.g., a $21.8\\%$ reduction\nfor a two-layer Steane/quantum Reed-Muller combination. Unlike standard\nconcatenated codes, we establish that the new codes can encode more than a\nsingle logical qubit per code block by applying ``black hole'' deformations\nwith tunable rate and distance, while possessing fully addressable, universal\nfault-tolerant gate sets. Therefore, our work strengthens the case for the\nutility of holographic quantum codes for practical quantum computing.","main_category":"quant-ph","categories":"quant-ph,hep-th","published":"2025-04-14T16:28:33Z"}
{"aid":"http://arxiv.org/abs/2504.10390v1","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10400v1","title":"Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone","summary":"This work quantitatively evaluates the performance of event-based vision\nsystems (EVS) against conventional RGB-based models for action prediction in\ncollision avoidance on an FPGA accelerator. Our experiments demonstrate that\nthe EVS model achieves a significantly higher effective frame rate (1 kHz) and\nlower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the\nRGB-based model, particularly when tested on out-of-distribution data. The EVS\nmodel also exhibits superior robustness in selecting optimal evasion maneuvers.\nIn particular, in distinguishing between movement and stationary states, it\nachieves a 59 percentage point advantage in precision (78% vs. 19%) and a\nsubstantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility\nof the RGB model to overfitting. Further analysis in different combinations of\nspatial classes confirms the consistent performance of the EVS model in both\ntest data sets. Finally, we evaluated the system end-to-end and achieved a\nlatency of approximately 2.14 ms, with event aggregation (1 ms) and inference\non the processing unit (0.94 ms) accounting for the largest components. These\nresults underscore the advantages of event-based vision for real-time collision\navoidance and demonstrate its potential for deployment in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.10402v1","title":"Can spacetime torsion source an extremely red-tilted cosmological GW\n  background?","summary":"In the presence of spacetime torsion, any generic $f(R)$ model of gravity is\nconformally dual to a scalar-tensor theory augmented with a second rank\nantisymmetric massless degree of freedom. We investigate the stochastic\ngravitational wave background (SGWB) that may be sourced directly at the second\norder by such a torsional field, treated perturbatively during an epoch of\ncanonical, single-field, slow-roll inflation. The resulting second-order\ninduced SGWB, which dominates over the primary inflationary GW background at\nall scales, peaks only at ultra-low frequencies, and is found to be extremely\nred-tilted with an effective tensor spectral index $\\alpha_{\\rm T}\\sim-6$ on\nmatter-dominated scales. The signal is potentially within the reach of upcoming\nindirect GW probes on very large scales $k\\lesssim10^{-2}\\:\\textrm{Mpc}^{-1}$,\ni.e., next-generation CMB experiments like the LiteBIRD. In the near future,\nobservation of such a markedly red-tilted SGWB on CMB scales could hence\nprovide a novel and unique clue in favour of torsional gravity during the\ninflationary era.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-14T16:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10403v1","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI","published":"2025-04-14T16:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10414v1","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","summary":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.10420v1","title":"Role of Coulomb-nuclear breakup of 6,7Li projectiles with heavy deformed\n  232Th target","summary":"The significance of both Coulomb and nuclear couplings and their interference\neffects in the breakup processes of 6,7Li with a non-spherical nucleus 232Th\nhas been evaluated. The continuum discretized coupled channel(CDCC)\ncalculations are carried out in a nonstandard way, using short-range imaginary\npotentials for the fragment-target interaction at energies close to the Coulomb\nbarrier. The present calculations employing short-range imaginary potentials\nexhibit better agreement with the experimental elastic scattering angular\ndistributions than those using standard systematic value (0.78xWSPP ) used to\ndescribe elastic scattering. Including the excitation of the 232Th inelastic\nshows significant coupling effects on the elastic scattering below the barrier\nenergies compared to higher incident energies. Subsequently, the CDCC framework\nwas used to analyze the nuclear, Coulomb, and total breakup predictions\nseparately. The breakup cross sections for the 6Li+232Th system are greater\nthan those for the 7Li+232Th system across various energies. The present study\npredicts destructive Coulomb-nuclear interference in the breakup processes\ninvolving both 6Li and 7Li projectile nuclei with the deformed 232Th target.\nAdditionally, the breakup reaction cross-sections are compared with\nexperimentally measured fusion cross-sections near the barrier energies for\nboth 6,7Li+232Th systems.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T17:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.10421v1","title":"Can We Edit LLMs for Long-Tail Biomedical Knowledge?","summary":"Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T17:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10438v1","title":"Streaming Democratized: Ease Across the Latency Spectrum with Delayed\n  View Semantics and Snowflake Dynamic Tables","summary":"Streaming data pipelines remain challenging and expensive to build and\nmaintain, despite significant advancements in stronger consistency, event time\nsemantics, and SQL support over the last decade. Persistent obstacles continue\nto hinder usability, such as the need for manual incrementalization, semantic\ndiscrepancies across SQL implementations, and the lack of enterprise-grade\noperational features. While the rise of incremental view maintenance (IVM) as a\nway to integrate streaming with databases has been a huge step forward,\ntransaction isolation in the presence of IVM remains underspecified, leaving\nthe maintenance of application-level invariants as a painful exercise for the\nuser. Meanwhile, most streaming systems optimize for latencies of 100 ms to 3\nsec, whereas many practical use cases are well-served by latencies ranging from\nseconds to tens of minutes.\n  We present delayed view semantics (DVS), a conceptual foundation that bridges\nthe semantic gap between streaming and databases, and introduce Dynamic Tables,\nSnowflake's declarative streaming transformation primitive designed to\ndemocratize analytical stream processing. DVS formalizes the intuition that\nstream processing is primarily a technique to eagerly compute derived results\nasynchronously, while also addressing the need to reason about the resulting\nsystem end to end. Dynamic Tables then offer two key advantages: ease of use\nthrough DVS, enterprise-grade features, and simplicity; as well as scalable\ncost efficiency via IVM with an architecture designed for diverse latency\nrequirements.\n  We first develop extensions to transaction isolation that permit the\npreservation of invariants in streaming applications. We then detail the\nimplementation challenges of Dynamic Tables and our experience operating it at\nscale. Finally, we share insights into user adoption and discuss our vision for\nthe future of stream processing.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-14T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.10451v1","title":"Minimizing Functions of Age of Incorrect Information for Remote\n  Estimation","summary":"The age of incorrect information (AoII) process which keeps track of the time\nsince the source and monitor processes are in sync, has been extensively used\nin remote estimation problems. In this paper, we consider a push-based remote\nestimation system with a discrete-time Markov chain (DTMC) information source\ntransmitting status update packets towards the monitor once the AoII process\nexceeds a certain estimation-based threshold. In this paper, the time average\nof an arbitrary function of AoII is taken as the AoII cost, as opposed to using\nthe average AoII as the mismatch metric, whereas this function is also allowed\nto depend on the estimation value. In this very general setting, our goal is to\nminimize a weighted sum of AoII and transmission costs. For this purpose, we\nformulate a discrete-time semi-Markov decision process (SMDP) regarding the\nmulti-threshold status update policy. We propose a novel tool in discrete-time\ncalled 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding\nabsorption time distribution named as 'dual-regime phase-type' (DR-PH)\ndistribution, to obtain the characterizing parameters of the SMDP, which allows\nus to obtain the distribution of the AoII process for a given policy, and hence\nthe average of any function of AoII. The proposed method is validated with\nnumerical results by which we compare our proposed method against other\npolicies obtained by exhaustive-search, and also various benchmark policies.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T17:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10458v1","title":"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI\n  Agents","summary":"Existing efforts in building Graphical User Interface (GUI) agents largely\nrely on the training paradigm of supervised fine-tuning on Large\nVision-Language Models (LVLMs). However, this approach not only demands\nextensive amounts of training data but also struggles to effectively understand\nGUI screenshots and generalize to unseen interfaces. The issue significantly\nlimits its application in real-world scenarios, especially for high-level\ntasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models\n(e.g., DeepSeek-R1), which efficiently enhances the problem-solving\ncapabilities of large language models in real-world settings, we propose \\name,\nthe first reinforcement learning framework designed to enhance the GUI\ncapabilities of LVLMs in high-level real-world task scenarios, through unified\naction space rule modeling. By leveraging a small amount of carefully curated\nhigh-quality data across multiple platforms (including Windows, Linux, MacOS,\nAndroid, and Web) and employing policy optimization algorithms such as Group\nRelative Policy Optimization (GRPO) to update the model, \\name achieves\nsuperior performance using only 0.02\\% of the data (3K vs. 13M) compared to\nprevious state-of-the-art methods like OS-Atlas across eight benchmarks\nspanning three different platforms (mobile, desktop, and web). These results\ndemonstrate the immense potential of reinforcement learning based on unified\naction space rule modeling in improving the execution capabilities of LVLMs for\nreal-world GUI agent tasks.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.HC","published":"2025-04-14T17:45:54Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10466v1","title":"Art3D: Training-Free 3D Generation from Flat-Colored Illustration","summary":"Large-scale pre-trained image-to-3D generative models have exhibited\nremarkable capabilities in diverse shape generations. However, most of them\nstruggle to synthesize plausible 3D assets when the reference image is\nflat-colored like hand drawings due to the lack of 3D illusion, which are often\nthe most user-friendly input modalities in art content creation. To this end,\nwe propose Art3D, a training-free method that can lift flat-colored 2D designs\ninto 3D. By leveraging structural and semantic features with pre- trained 2D\nimage generation models and a VLM-based realism evaluation, Art3D successfully\nenhances the three-dimensional illusion in reference images, thus simplifying\nthe process of generating 3D from 2D, and proves adaptable to a wide range of\npainting styles. To benchmark the generalization performance of existing\nimage-to-3D models on flat-colored images without 3D feeling, we collect a new\ndataset, Flat-2D, with over 100 samples. Experimental results demonstrate the\nperformance and robustness of Art3D, exhibiting superior generalizable capacity\nand promising practical applicability. Our source code and dataset will be\npublicly available on our project page: https://joy-jy11.github.io/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.10468v1","title":"Quantum Barcodes: Persistent Homology for Quantum Phase Transitions","summary":"We introduce \"quantum barcodes,\" a theoretical framework that applies\npersistent homology to classify topological phases in quantum many-body\nsystems. By mapping quantum states to classical data points through strategic\nobservable measurements, we create a \"quantum state cloud\" analyzable via\npersistent homology techniques. Our framework establishes that quantum systems\nin the same topological phase exhibit consistent barcode representations with\nshared persistent homology groups over characteristic intervals. We prove that\nquantum phase transitions manifest as significant changes in these persistent\nhomology features, detectable through discontinuities in the persistent Dirac\noperator spectrum. Using the SSH model as a demonstrative example, we show how\nour approach successfully identifies the topological phase transition and\ndistinguishes between trivial and topological phases. While primarily developed\nfor symmetry-protected topological phases, our framework provides a\nmathematical connection between persistent homology and quantum topology,\noffering new methods for phase classification that complement traditional\ninvariant-based approaches.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.AT,math.MP","published":"2025-04-14T17:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.10472v1","title":"False and genuine decoherence in the early universe: a local observer\n  and time-averaged observables","summary":"We study quantum decoherence of curvature perturbations at superhorizon\nscales caused by the gravitational nonlinearities. We show that cubic\ngravitational couplings, constrained by the spatial diffeomorphism invariance,\nlead to infrared (IR) and ultraviolet (UV) divergences in the decoherence rate\nat one loop. These divergences arise from fluctuations of deep IR modes which\nlook like a background mode for a local observer and violent zero-point\nfluctuations in the deep UV, respectively. We argue that these divergences are\nunobservable, as they vanish when considering proper observables. We consider\ncorrelators defined using the geodesic distance for IR divergences and\ntime-averaged correlators for UV divergences. To account for these observer's\nperspectives, we propose to consider an effective quantum state, defined in\nterms of actual observables, as a more appropriate probe of the quantum\ncoherence of the system measured by an observer. We then evaluate the finite\ndecoherence rate induced by superhorizon environment during inflation and at\nlate universe.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc,hep-ph","published":"2025-04-14T17:54:35Z"}
